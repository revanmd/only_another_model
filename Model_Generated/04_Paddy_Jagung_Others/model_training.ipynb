{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy\n",
    "import tqdm\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE using cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('DEVICE using {}'.format(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model import cnn_model\n",
    "from Model import cnn_model_attention\n",
    "\n",
    "cnn1d = cnn_model.CNN1D\n",
    "cnn1d_lstm = cnn_model.CNNLSTM\n",
    "cnn2d = cnn_model.CNN2D\n",
    "cnn2d_lstm = cnn_model.CNNLSTM2D\n",
    "cnn1d_att = cnn_model_attention.CNN1DATT\n",
    "cnn1dlstm_att = cnn_model_attention.CNNLSTMATT\n",
    "cnn2d_att = cnn_model_attention.CNN2DATT\n",
    "cnn2dlstm_att = cnn_model_attention.CNNLSTM2DATT\n",
    "\n",
    "model_1D = {'model_cnn1d': cnn1d, 'model_cnn1d_lstm': cnn1d_lstm, 'model_cnn1d_att': cnn1d_att, 'model_cnn1dlstm_att': cnn1dlstm_att}\n",
    "model_2D = {'model_cnn2d': cnn2d, 'model_cnn2d_lstm': cnn2d_lstm, 'model_cnn2d_att': cnn2d_att, 'model_cnn2dlstm_att': cnn2dlstm_att}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class2</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>...</th>\n",
       "      <th>V175</th>\n",
       "      <th>V176</th>\n",
       "      <th>V177</th>\n",
       "      <th>V178</th>\n",
       "      <th>V179</th>\n",
       "      <th>V180</th>\n",
       "      <th>V181</th>\n",
       "      <th>V182</th>\n",
       "      <th>V183</th>\n",
       "      <th>V184</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.051166</td>\n",
       "      <td>0.066034</td>\n",
       "      <td>0.063299</td>\n",
       "      <td>0.162909</td>\n",
       "      <td>0.173840</td>\n",
       "      <td>0.103043</td>\n",
       "      <td>0.014811</td>\n",
       "      <td>0.038940</td>\n",
       "      <td>0.054497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.935761</td>\n",
       "      <td>-0.089926</td>\n",
       "      <td>-11.703547</td>\n",
       "      <td>-8.832947</td>\n",
       "      <td>2.870600</td>\n",
       "      <td>1.344082</td>\n",
       "      <td>0.050672</td>\n",
       "      <td>-1.567327</td>\n",
       "      <td>2.481404</td>\n",
       "      <td>2.481186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.041163</td>\n",
       "      <td>0.073449</td>\n",
       "      <td>0.084577</td>\n",
       "      <td>0.097461</td>\n",
       "      <td>0.093803</td>\n",
       "      <td>0.045156</td>\n",
       "      <td>0.029049</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.127593</td>\n",
       "      <td>...</td>\n",
       "      <td>1.269115</td>\n",
       "      <td>-0.145843</td>\n",
       "      <td>-11.510554</td>\n",
       "      <td>-7.380278</td>\n",
       "      <td>4.130276</td>\n",
       "      <td>1.812655</td>\n",
       "      <td>-0.764677</td>\n",
       "      <td>-0.599178</td>\n",
       "      <td>2.482623</td>\n",
       "      <td>2.475474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.072416</td>\n",
       "      <td>0.129937</td>\n",
       "      <td>0.134894</td>\n",
       "      <td>0.097134</td>\n",
       "      <td>0.072244</td>\n",
       "      <td>0.057077</td>\n",
       "      <td>0.070750</td>\n",
       "      <td>0.059574</td>\n",
       "      <td>0.075071</td>\n",
       "      <td>...</td>\n",
       "      <td>1.244691</td>\n",
       "      <td>-0.129092</td>\n",
       "      <td>-11.651522</td>\n",
       "      <td>-7.962222</td>\n",
       "      <td>3.689300</td>\n",
       "      <td>2.267453</td>\n",
       "      <td>-0.142272</td>\n",
       "      <td>-1.590600</td>\n",
       "      <td>2.479603</td>\n",
       "      <td>2.477288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.074673</td>\n",
       "      <td>0.111059</td>\n",
       "      <td>0.101137</td>\n",
       "      <td>0.076099</td>\n",
       "      <td>0.066573</td>\n",
       "      <td>0.047397</td>\n",
       "      <td>0.071096</td>\n",
       "      <td>0.087114</td>\n",
       "      <td>0.106630</td>\n",
       "      <td>...</td>\n",
       "      <td>1.828652</td>\n",
       "      <td>-0.176416</td>\n",
       "      <td>-12.470089</td>\n",
       "      <td>-5.601049</td>\n",
       "      <td>6.869040</td>\n",
       "      <td>1.481105</td>\n",
       "      <td>1.242591</td>\n",
       "      <td>1.165478</td>\n",
       "      <td>2.481270</td>\n",
       "      <td>2.469046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.072276</td>\n",
       "      <td>0.119697</td>\n",
       "      <td>0.113054</td>\n",
       "      <td>0.085009</td>\n",
       "      <td>0.063719</td>\n",
       "      <td>0.042546</td>\n",
       "      <td>0.047473</td>\n",
       "      <td>0.063731</td>\n",
       "      <td>0.077336</td>\n",
       "      <td>...</td>\n",
       "      <td>1.314358</td>\n",
       "      <td>-0.124873</td>\n",
       "      <td>-12.745337</td>\n",
       "      <td>-8.258361</td>\n",
       "      <td>4.486977</td>\n",
       "      <td>1.469534</td>\n",
       "      <td>-0.189085</td>\n",
       "      <td>-1.052814</td>\n",
       "      <td>2.481925</td>\n",
       "      <td>2.477782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class2        V4        V5        V6        V7        V8        V9  \\\n",
       "0       4  0.051166  0.066034  0.063299  0.162909  0.173840  0.103043   \n",
       "1       4  0.041163  0.073449  0.084577  0.097461  0.093803  0.045156   \n",
       "2       3  0.072416  0.129937  0.134894  0.097134  0.072244  0.057077   \n",
       "3       3  0.074673  0.111059  0.101137  0.076099  0.066573  0.047397   \n",
       "4       3  0.072276  0.119697  0.113054  0.085009  0.063719  0.042546   \n",
       "\n",
       "        V10       V11       V12  ...      V175      V176       V177      V178  \\\n",
       "0  0.014811  0.038940  0.054497  ...  0.935761 -0.089926 -11.703547 -8.832947   \n",
       "1  0.029049  0.014436  0.127593  ...  1.269115 -0.145843 -11.510554 -7.380278   \n",
       "2  0.070750  0.059574  0.075071  ...  1.244691 -0.129092 -11.651522 -7.962222   \n",
       "3  0.071096  0.087114  0.106630  ...  1.828652 -0.176416 -12.470089 -5.601049   \n",
       "4  0.047473  0.063731  0.077336  ...  1.314358 -0.124873 -12.745337 -8.258361   \n",
       "\n",
       "       V179      V180      V181      V182      V183      V184  \n",
       "0  2.870600  1.344082  0.050672 -1.567327  2.481404  2.481186  \n",
       "1  4.130276  1.812655 -0.764677 -0.599178  2.482623  2.475474  \n",
       "2  3.689300  2.267453 -0.142272 -1.590600  2.479603  2.477288  \n",
       "3  6.869040  1.481105  1.242591  1.165478  2.481270  2.469046  \n",
       "4  4.486977  1.469534 -0.189085 -1.052814  2.481925  2.477782  \n",
       "\n",
       "[5 rows x 182 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_object = '4class'\n",
    "data = pd.read_csv(\"./merged_data2_{}.csv\".format(mapping_object))\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((703, 181), (79, 181), (703,), (79,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = data.drop(columns=['Class2']).values\n",
    "y = data['Class2'].values\n",
    "\n",
    "y -= y.min()\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# for 1D CNN\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(782, 190)\n"
     ]
    }
   ],
   "source": [
    "padded_arr = numpy.pad(X, ((0, 0), (0, 9)), mode='constant', constant_values=0)\n",
    "print(padded_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((703, 1, 19, 10), (79, 1, 19, 10), (703,), (79,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for 2D CNN\n",
    "X_reshaped = padded_arr.reshape(-1, 1, 19, 10)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_reshaped, y, test_size=0.1, random_state=42)\n",
    "\n",
    "X_train_tensor2 = torch.tensor(X_train2, dtype=torch.float32)\n",
    "y_train_tensor2 = torch.tensor(y_train2, dtype=torch.long)\n",
    "X_test_tensor2 = torch.tensor(X_test2, dtype=torch.float32)\n",
    "y_test_tensor2 = torch.tensor(y_test2, dtype=torch.long)\n",
    "\n",
    "train_dataset2 = TensorDataset(X_train_tensor2, y_train_tensor2)\n",
    "test_dataset2 = TensorDataset(X_test_tensor2, y_test_tensor2)\n",
    "\n",
    "train_loader2 = DataLoader(train_dataset2, batch_size=8, shuffle=True)\n",
    "test_loader2 = DataLoader(test_dataset2, batch_size=8, shuffle=False)\n",
    "\n",
    "X_train2.shape, X_test2.shape, y_train2.shape, y_test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Define training parameters\n",
    "num_epochs = 2500\n",
    "learning_rate = 0.001\n",
    "input_size = X_train_tensor.shape[1] \n",
    "num_classes = len(set(y_train))\n",
    "\n",
    "# Loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "print(input_size)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model_cnn1d\n",
      "Epoch [1/2500], Train Loss: 1.3588, Train Accuracy: 33.85%, Test Loss: 1.2757, Test Accuracy: 49.37%\n",
      "Epoch [2/2500], Train Loss: 1.3227, Train Accuracy: 36.13%, Test Loss: 1.2775, Test Accuracy: 49.37%\n",
      "Epoch [3/2500], Train Loss: 1.3242, Train Accuracy: 36.13%, Test Loss: 1.2280, Test Accuracy: 43.04%\n",
      "Epoch [4/2500], Train Loss: 1.3046, Train Accuracy: 40.54%, Test Loss: 1.1951, Test Accuracy: 55.70%\n",
      "Epoch [5/2500], Train Loss: 1.2746, Train Accuracy: 46.09%, Test Loss: 1.1467, Test Accuracy: 48.10%\n",
      "Epoch [6/2500], Train Loss: 1.2808, Train Accuracy: 43.67%, Test Loss: 1.1448, Test Accuracy: 51.90%\n",
      "Epoch [7/2500], Train Loss: 1.2517, Train Accuracy: 44.95%, Test Loss: 1.0955, Test Accuracy: 55.70%\n",
      "Epoch [8/2500], Train Loss: 1.2234, Train Accuracy: 47.94%, Test Loss: 1.0534, Test Accuracy: 59.49%\n",
      "Epoch [9/2500], Train Loss: 1.2301, Train Accuracy: 46.66%, Test Loss: 1.0579, Test Accuracy: 55.70%\n",
      "Epoch [10/2500], Train Loss: 1.1994, Train Accuracy: 49.22%, Test Loss: 1.0203, Test Accuracy: 58.23%\n",
      "Epoch [11/2500], Train Loss: 1.1980, Train Accuracy: 49.64%, Test Loss: 1.0180, Test Accuracy: 56.96%\n",
      "Epoch [12/2500], Train Loss: 1.1946, Train Accuracy: 48.22%, Test Loss: 0.9986, Test Accuracy: 55.70%\n",
      "Epoch [13/2500], Train Loss: 1.1396, Train Accuracy: 52.92%, Test Loss: 0.9581, Test Accuracy: 55.70%\n",
      "Epoch [14/2500], Train Loss: 1.1499, Train Accuracy: 49.79%, Test Loss: 0.9532, Test Accuracy: 58.23%\n",
      "Epoch [15/2500], Train Loss: 1.1504, Train Accuracy: 51.07%, Test Loss: 0.9938, Test Accuracy: 55.70%\n",
      "Epoch [16/2500], Train Loss: 1.1387, Train Accuracy: 53.20%, Test Loss: 0.9588, Test Accuracy: 56.96%\n",
      "Epoch [17/2500], Train Loss: 1.1087, Train Accuracy: 53.77%, Test Loss: 0.9640, Test Accuracy: 55.70%\n",
      "Epoch [18/2500], Train Loss: 1.0905, Train Accuracy: 54.34%, Test Loss: 0.9474, Test Accuracy: 56.96%\n",
      "Epoch [19/2500], Train Loss: 1.0926, Train Accuracy: 54.62%, Test Loss: 0.9502, Test Accuracy: 56.96%\n",
      "Epoch [20/2500], Train Loss: 1.1049, Train Accuracy: 55.05%, Test Loss: 0.9503, Test Accuracy: 58.23%\n",
      "Epoch [21/2500], Train Loss: 1.0845, Train Accuracy: 54.77%, Test Loss: 0.9450, Test Accuracy: 58.23%\n",
      "Epoch [22/2500], Train Loss: 1.0957, Train Accuracy: 53.63%, Test Loss: 0.9549, Test Accuracy: 56.96%\n",
      "Epoch [23/2500], Train Loss: 1.0938, Train Accuracy: 53.49%, Test Loss: 0.9711, Test Accuracy: 56.96%\n",
      "Epoch [24/2500], Train Loss: 1.0697, Train Accuracy: 53.34%, Test Loss: 0.9718, Test Accuracy: 56.96%\n",
      "Epoch [25/2500], Train Loss: 1.0562, Train Accuracy: 55.62%, Test Loss: 0.9585, Test Accuracy: 56.96%\n",
      "Epoch [26/2500], Train Loss: 1.0683, Train Accuracy: 56.05%, Test Loss: 0.9378, Test Accuracy: 58.23%\n",
      "Epoch [27/2500], Train Loss: 1.0599, Train Accuracy: 55.19%, Test Loss: 0.9668, Test Accuracy: 56.96%\n",
      "Epoch [28/2500], Train Loss: 1.0494, Train Accuracy: 54.48%, Test Loss: 0.9715, Test Accuracy: 56.96%\n",
      "Epoch [29/2500], Train Loss: 1.0591, Train Accuracy: 55.62%, Test Loss: 0.9529, Test Accuracy: 58.23%\n",
      "Epoch [30/2500], Train Loss: 1.0490, Train Accuracy: 54.77%, Test Loss: 0.9617, Test Accuracy: 55.70%\n",
      "Epoch [31/2500], Train Loss: 1.0377, Train Accuracy: 56.05%, Test Loss: 0.9566, Test Accuracy: 59.49%\n",
      "Epoch [32/2500], Train Loss: 1.0583, Train Accuracy: 55.76%, Test Loss: 0.9842, Test Accuracy: 56.96%\n",
      "Epoch [33/2500], Train Loss: 1.0316, Train Accuracy: 56.61%, Test Loss: 0.9606, Test Accuracy: 56.96%\n",
      "Epoch [34/2500], Train Loss: 1.0538, Train Accuracy: 57.04%, Test Loss: 0.9844, Test Accuracy: 56.96%\n",
      "Epoch [35/2500], Train Loss: 1.0666, Train Accuracy: 55.62%, Test Loss: 0.9435, Test Accuracy: 59.49%\n",
      "Epoch [36/2500], Train Loss: 1.0280, Train Accuracy: 56.90%, Test Loss: 0.9624, Test Accuracy: 58.23%\n",
      "Epoch [37/2500], Train Loss: 1.0346, Train Accuracy: 55.33%, Test Loss: 0.9711, Test Accuracy: 58.23%\n",
      "Epoch [38/2500], Train Loss: 1.0311, Train Accuracy: 57.89%, Test Loss: 0.9841, Test Accuracy: 58.23%\n",
      "Epoch [39/2500], Train Loss: 1.0305, Train Accuracy: 56.76%, Test Loss: 0.9817, Test Accuracy: 58.23%\n",
      "Epoch [40/2500], Train Loss: 1.0444, Train Accuracy: 56.19%, Test Loss: 0.9693, Test Accuracy: 58.23%\n",
      "Epoch [41/2500], Train Loss: 1.0628, Train Accuracy: 55.76%, Test Loss: 0.9763, Test Accuracy: 56.96%\n",
      "Epoch [42/2500], Train Loss: 1.0247, Train Accuracy: 57.18%, Test Loss: 0.9484, Test Accuracy: 59.49%\n",
      "Epoch [43/2500], Train Loss: 1.0325, Train Accuracy: 55.33%, Test Loss: 0.9858, Test Accuracy: 58.23%\n",
      "Epoch [44/2500], Train Loss: 1.0296, Train Accuracy: 56.61%, Test Loss: 0.9769, Test Accuracy: 58.23%\n",
      "Epoch [45/2500], Train Loss: 1.0344, Train Accuracy: 56.33%, Test Loss: 0.9562, Test Accuracy: 59.49%\n",
      "Epoch [46/2500], Train Loss: 1.0373, Train Accuracy: 56.47%, Test Loss: 0.9686, Test Accuracy: 59.49%\n",
      "Epoch [47/2500], Train Loss: 1.0118, Train Accuracy: 57.61%, Test Loss: 0.9708, Test Accuracy: 58.23%\n",
      "Epoch [48/2500], Train Loss: 1.0206, Train Accuracy: 56.76%, Test Loss: 0.9629, Test Accuracy: 59.49%\n",
      "Epoch [49/2500], Train Loss: 1.0170, Train Accuracy: 56.33%, Test Loss: 0.9753, Test Accuracy: 59.49%\n",
      "Epoch [50/2500], Train Loss: 1.0277, Train Accuracy: 57.18%, Test Loss: 0.9814, Test Accuracy: 56.96%\n",
      "Epoch [51/2500], Train Loss: 1.0155, Train Accuracy: 57.47%, Test Loss: 0.9797, Test Accuracy: 56.96%\n",
      "Epoch [52/2500], Train Loss: 0.9994, Train Accuracy: 56.19%, Test Loss: 0.9718, Test Accuracy: 59.49%\n",
      "Epoch [53/2500], Train Loss: 1.0211, Train Accuracy: 56.33%, Test Loss: 0.9902, Test Accuracy: 56.96%\n",
      "Epoch [54/2500], Train Loss: 1.0273, Train Accuracy: 55.33%, Test Loss: 0.9720, Test Accuracy: 59.49%\n",
      "Epoch [55/2500], Train Loss: 1.0146, Train Accuracy: 56.47%, Test Loss: 0.9692, Test Accuracy: 59.49%\n",
      "Epoch [56/2500], Train Loss: 1.0164, Train Accuracy: 57.89%, Test Loss: 0.9714, Test Accuracy: 59.49%\n",
      "Epoch [57/2500], Train Loss: 0.9990, Train Accuracy: 57.33%, Test Loss: 0.9747, Test Accuracy: 59.49%\n",
      "Epoch [58/2500], Train Loss: 1.0145, Train Accuracy: 56.19%, Test Loss: 0.9810, Test Accuracy: 59.49%\n",
      "Epoch [59/2500], Train Loss: 1.0197, Train Accuracy: 57.33%, Test Loss: 0.9837, Test Accuracy: 59.49%\n",
      "Epoch [60/2500], Train Loss: 0.9946, Train Accuracy: 56.90%, Test Loss: 0.9984, Test Accuracy: 58.23%\n",
      "Epoch [61/2500], Train Loss: 1.0147, Train Accuracy: 56.90%, Test Loss: 0.9776, Test Accuracy: 58.23%\n",
      "Epoch [62/2500], Train Loss: 0.9845, Train Accuracy: 58.46%, Test Loss: 0.9694, Test Accuracy: 59.49%\n",
      "Epoch [63/2500], Train Loss: 0.9953, Train Accuracy: 57.61%, Test Loss: 0.9623, Test Accuracy: 58.23%\n",
      "Epoch [64/2500], Train Loss: 1.0170, Train Accuracy: 57.04%, Test Loss: 0.9692, Test Accuracy: 60.76%\n",
      "Epoch [65/2500], Train Loss: 1.0091, Train Accuracy: 56.90%, Test Loss: 1.0107, Test Accuracy: 58.23%\n",
      "Epoch [66/2500], Train Loss: 0.9823, Train Accuracy: 56.47%, Test Loss: 0.9877, Test Accuracy: 58.23%\n",
      "Epoch [67/2500], Train Loss: 0.9767, Train Accuracy: 57.75%, Test Loss: 0.9932, Test Accuracy: 59.49%\n",
      "Epoch [68/2500], Train Loss: 0.9844, Train Accuracy: 58.32%, Test Loss: 0.9890, Test Accuracy: 59.49%\n",
      "Epoch [69/2500], Train Loss: 0.9920, Train Accuracy: 55.90%, Test Loss: 0.9912, Test Accuracy: 58.23%\n",
      "Epoch [70/2500], Train Loss: 0.9834, Train Accuracy: 56.19%, Test Loss: 0.9670, Test Accuracy: 62.03%\n",
      "Epoch [71/2500], Train Loss: 0.9934, Train Accuracy: 57.61%, Test Loss: 1.0161, Test Accuracy: 58.23%\n",
      "Epoch [72/2500], Train Loss: 1.0066, Train Accuracy: 57.75%, Test Loss: 1.0112, Test Accuracy: 58.23%\n",
      "Epoch [73/2500], Train Loss: 0.9886, Train Accuracy: 58.04%, Test Loss: 0.9898, Test Accuracy: 56.96%\n",
      "Epoch [74/2500], Train Loss: 0.9765, Train Accuracy: 57.04%, Test Loss: 1.0176, Test Accuracy: 58.23%\n",
      "Epoch [75/2500], Train Loss: 1.0034, Train Accuracy: 57.18%, Test Loss: 0.9846, Test Accuracy: 60.76%\n",
      "Epoch [76/2500], Train Loss: 0.9828, Train Accuracy: 57.47%, Test Loss: 1.0193, Test Accuracy: 59.49%\n",
      "Epoch [77/2500], Train Loss: 0.9898, Train Accuracy: 57.61%, Test Loss: 1.0039, Test Accuracy: 56.96%\n",
      "Epoch [78/2500], Train Loss: 0.9875, Train Accuracy: 57.18%, Test Loss: 0.9795, Test Accuracy: 59.49%\n",
      "Epoch [79/2500], Train Loss: 0.9711, Train Accuracy: 58.32%, Test Loss: 0.9862, Test Accuracy: 60.76%\n",
      "Epoch [80/2500], Train Loss: 0.9759, Train Accuracy: 58.32%, Test Loss: 0.9883, Test Accuracy: 60.76%\n",
      "Epoch [81/2500], Train Loss: 0.9980, Train Accuracy: 58.75%, Test Loss: 0.9615, Test Accuracy: 60.76%\n",
      "Epoch [82/2500], Train Loss: 0.9828, Train Accuracy: 58.04%, Test Loss: 0.9798, Test Accuracy: 59.49%\n",
      "Epoch [83/2500], Train Loss: 1.0099, Train Accuracy: 55.76%, Test Loss: 0.9655, Test Accuracy: 60.76%\n",
      "Epoch [84/2500], Train Loss: 0.9902, Train Accuracy: 57.33%, Test Loss: 0.9876, Test Accuracy: 60.76%\n",
      "Epoch [85/2500], Train Loss: 0.9658, Train Accuracy: 58.18%, Test Loss: 0.9758, Test Accuracy: 60.76%\n",
      "Epoch [86/2500], Train Loss: 0.9767, Train Accuracy: 58.18%, Test Loss: 0.9765, Test Accuracy: 60.76%\n",
      "Epoch [87/2500], Train Loss: 0.9673, Train Accuracy: 57.18%, Test Loss: 1.0131, Test Accuracy: 56.96%\n",
      "Epoch [88/2500], Train Loss: 0.9662, Train Accuracy: 56.33%, Test Loss: 0.9798, Test Accuracy: 60.76%\n",
      "Epoch [89/2500], Train Loss: 0.9868, Train Accuracy: 57.89%, Test Loss: 1.0018, Test Accuracy: 59.49%\n",
      "Epoch [90/2500], Train Loss: 0.9813, Train Accuracy: 56.61%, Test Loss: 0.9899, Test Accuracy: 59.49%\n",
      "Epoch [91/2500], Train Loss: 0.9774, Train Accuracy: 56.33%, Test Loss: 1.0078, Test Accuracy: 56.96%\n",
      "Epoch [92/2500], Train Loss: 0.9713, Train Accuracy: 57.89%, Test Loss: 0.9931, Test Accuracy: 59.49%\n",
      "Epoch [93/2500], Train Loss: 0.9851, Train Accuracy: 58.32%, Test Loss: 0.9915, Test Accuracy: 59.49%\n",
      "Epoch [94/2500], Train Loss: 0.9629, Train Accuracy: 58.32%, Test Loss: 0.9782, Test Accuracy: 59.49%\n",
      "Epoch [95/2500], Train Loss: 0.9745, Train Accuracy: 58.18%, Test Loss: 0.9795, Test Accuracy: 60.76%\n",
      "Epoch [96/2500], Train Loss: 0.9724, Train Accuracy: 58.46%, Test Loss: 0.9761, Test Accuracy: 60.76%\n",
      "Epoch [97/2500], Train Loss: 0.9601, Train Accuracy: 57.75%, Test Loss: 0.9754, Test Accuracy: 60.76%\n",
      "Epoch [98/2500], Train Loss: 0.9733, Train Accuracy: 58.18%, Test Loss: 0.9777, Test Accuracy: 59.49%\n",
      "Epoch [99/2500], Train Loss: 0.9901, Train Accuracy: 56.61%, Test Loss: 0.9800, Test Accuracy: 59.49%\n",
      "Epoch [100/2500], Train Loss: 0.9669, Train Accuracy: 58.18%, Test Loss: 0.9741, Test Accuracy: 62.03%\n",
      "Epoch [101/2500], Train Loss: 0.9596, Train Accuracy: 58.61%, Test Loss: 0.9901, Test Accuracy: 60.76%\n",
      "Epoch [102/2500], Train Loss: 0.9617, Train Accuracy: 58.61%, Test Loss: 0.9723, Test Accuracy: 60.76%\n",
      "Epoch [103/2500], Train Loss: 0.9656, Train Accuracy: 57.04%, Test Loss: 0.9856, Test Accuracy: 59.49%\n",
      "Epoch [104/2500], Train Loss: 0.9707, Train Accuracy: 58.18%, Test Loss: 0.9931, Test Accuracy: 59.49%\n",
      "Epoch [105/2500], Train Loss: 0.9558, Train Accuracy: 58.46%, Test Loss: 0.9770, Test Accuracy: 60.76%\n",
      "Epoch [106/2500], Train Loss: 0.9767, Train Accuracy: 59.17%, Test Loss: 0.9639, Test Accuracy: 60.76%\n",
      "Epoch [107/2500], Train Loss: 0.9372, Train Accuracy: 57.47%, Test Loss: 0.9858, Test Accuracy: 60.76%\n",
      "Epoch [108/2500], Train Loss: 0.9727, Train Accuracy: 56.76%, Test Loss: 0.9697, Test Accuracy: 60.76%\n",
      "Epoch [109/2500], Train Loss: 0.9563, Train Accuracy: 57.75%, Test Loss: 0.9765, Test Accuracy: 60.76%\n",
      "Epoch [110/2500], Train Loss: 0.9683, Train Accuracy: 56.76%, Test Loss: 0.9891, Test Accuracy: 60.76%\n",
      "Epoch [111/2500], Train Loss: 0.9856, Train Accuracy: 57.75%, Test Loss: 0.9811, Test Accuracy: 60.76%\n",
      "Epoch [112/2500], Train Loss: 0.9545, Train Accuracy: 57.33%, Test Loss: 0.9973, Test Accuracy: 59.49%\n",
      "Epoch [113/2500], Train Loss: 0.9475, Train Accuracy: 58.46%, Test Loss: 0.9951, Test Accuracy: 60.76%\n",
      "Epoch [114/2500], Train Loss: 0.9552, Train Accuracy: 59.60%, Test Loss: 0.9964, Test Accuracy: 60.76%\n",
      "Epoch [115/2500], Train Loss: 0.9600, Train Accuracy: 58.75%, Test Loss: 0.9895, Test Accuracy: 60.76%\n",
      "Epoch [116/2500], Train Loss: 0.9601, Train Accuracy: 58.46%, Test Loss: 0.9858, Test Accuracy: 60.76%\n",
      "Epoch [117/2500], Train Loss: 0.9646, Train Accuracy: 58.18%, Test Loss: 0.9769, Test Accuracy: 60.76%\n",
      "Epoch [118/2500], Train Loss: 0.9581, Train Accuracy: 57.47%, Test Loss: 0.9901, Test Accuracy: 60.76%\n",
      "Epoch [119/2500], Train Loss: 0.9588, Train Accuracy: 57.89%, Test Loss: 1.0143, Test Accuracy: 59.49%\n",
      "Epoch [120/2500], Train Loss: 0.9600, Train Accuracy: 59.17%, Test Loss: 0.9822, Test Accuracy: 60.76%\n",
      "Epoch [121/2500], Train Loss: 0.9689, Train Accuracy: 57.33%, Test Loss: 0.9932, Test Accuracy: 60.76%\n",
      "Epoch [122/2500], Train Loss: 0.9438, Train Accuracy: 57.33%, Test Loss: 0.9994, Test Accuracy: 60.76%\n",
      "Epoch [123/2500], Train Loss: 0.9625, Train Accuracy: 59.17%, Test Loss: 0.9947, Test Accuracy: 60.76%\n",
      "Epoch [124/2500], Train Loss: 0.9565, Train Accuracy: 57.33%, Test Loss: 0.9958, Test Accuracy: 60.76%\n",
      "Epoch [125/2500], Train Loss: 0.9613, Train Accuracy: 58.32%, Test Loss: 0.9729, Test Accuracy: 60.76%\n",
      "Epoch [126/2500], Train Loss: 0.9618, Train Accuracy: 59.60%, Test Loss: 0.9730, Test Accuracy: 60.76%\n",
      "Epoch [127/2500], Train Loss: 0.9413, Train Accuracy: 59.17%, Test Loss: 0.9844, Test Accuracy: 60.76%\n",
      "Epoch [128/2500], Train Loss: 0.9757, Train Accuracy: 56.61%, Test Loss: 0.9749, Test Accuracy: 60.76%\n",
      "Epoch [129/2500], Train Loss: 0.9302, Train Accuracy: 59.32%, Test Loss: 1.0169, Test Accuracy: 59.49%\n",
      "Epoch [130/2500], Train Loss: 0.9374, Train Accuracy: 59.03%, Test Loss: 0.9787, Test Accuracy: 60.76%\n",
      "Epoch [131/2500], Train Loss: 0.9441, Train Accuracy: 57.75%, Test Loss: 1.0013, Test Accuracy: 60.76%\n",
      "Epoch [132/2500], Train Loss: 0.9567, Train Accuracy: 58.32%, Test Loss: 0.9824, Test Accuracy: 60.76%\n",
      "Epoch [133/2500], Train Loss: 0.9683, Train Accuracy: 57.75%, Test Loss: 0.9820, Test Accuracy: 60.76%\n",
      "Epoch [134/2500], Train Loss: 0.9530, Train Accuracy: 58.46%, Test Loss: 0.9878, Test Accuracy: 60.76%\n",
      "Epoch [135/2500], Train Loss: 0.9510, Train Accuracy: 58.18%, Test Loss: 0.9763, Test Accuracy: 60.76%\n",
      "Epoch [136/2500], Train Loss: 0.9205, Train Accuracy: 58.75%, Test Loss: 1.0012, Test Accuracy: 59.49%\n",
      "Epoch [137/2500], Train Loss: 0.9617, Train Accuracy: 58.89%, Test Loss: 0.9932, Test Accuracy: 60.76%\n",
      "Epoch [138/2500], Train Loss: 0.9592, Train Accuracy: 58.61%, Test Loss: 0.9865, Test Accuracy: 60.76%\n",
      "Epoch [139/2500], Train Loss: 0.9477, Train Accuracy: 58.04%, Test Loss: 0.9946, Test Accuracy: 60.76%\n",
      "Epoch [140/2500], Train Loss: 0.9457, Train Accuracy: 59.46%, Test Loss: 1.0247, Test Accuracy: 59.49%\n",
      "Epoch [141/2500], Train Loss: 0.9296, Train Accuracy: 59.32%, Test Loss: 0.9827, Test Accuracy: 62.03%\n",
      "Epoch [142/2500], Train Loss: 0.9438, Train Accuracy: 57.89%, Test Loss: 0.9884, Test Accuracy: 60.76%\n",
      "Epoch [143/2500], Train Loss: 0.9283, Train Accuracy: 58.32%, Test Loss: 1.0022, Test Accuracy: 62.03%\n",
      "Epoch [144/2500], Train Loss: 0.9454, Train Accuracy: 57.89%, Test Loss: 0.9797, Test Accuracy: 60.76%\n",
      "Epoch [145/2500], Train Loss: 0.9239, Train Accuracy: 60.17%, Test Loss: 0.9997, Test Accuracy: 60.76%\n",
      "Epoch [146/2500], Train Loss: 0.9135, Train Accuracy: 59.89%, Test Loss: 1.0226, Test Accuracy: 60.76%\n",
      "Epoch [147/2500], Train Loss: 0.9554, Train Accuracy: 59.60%, Test Loss: 0.9709, Test Accuracy: 60.76%\n",
      "Epoch [148/2500], Train Loss: 0.9511, Train Accuracy: 59.17%, Test Loss: 0.9733, Test Accuracy: 60.76%\n",
      "Epoch [149/2500], Train Loss: 0.9169, Train Accuracy: 60.31%, Test Loss: 0.9945, Test Accuracy: 60.76%\n",
      "Epoch [150/2500], Train Loss: 0.9367, Train Accuracy: 59.32%, Test Loss: 0.9952, Test Accuracy: 60.76%\n",
      "Epoch [151/2500], Train Loss: 0.9238, Train Accuracy: 59.03%, Test Loss: 0.9996, Test Accuracy: 62.03%\n",
      "Epoch [152/2500], Train Loss: 0.9549, Train Accuracy: 59.32%, Test Loss: 0.9635, Test Accuracy: 60.76%\n",
      "Epoch [153/2500], Train Loss: 0.9233, Train Accuracy: 59.46%, Test Loss: 0.9840, Test Accuracy: 60.76%\n",
      "Epoch [154/2500], Train Loss: 0.9221, Train Accuracy: 58.61%, Test Loss: 0.9726, Test Accuracy: 60.76%\n",
      "Epoch [155/2500], Train Loss: 0.9411, Train Accuracy: 59.46%, Test Loss: 0.9676, Test Accuracy: 60.76%\n",
      "Epoch [156/2500], Train Loss: 0.9280, Train Accuracy: 59.46%, Test Loss: 0.9853, Test Accuracy: 62.03%\n",
      "Epoch [157/2500], Train Loss: 0.9259, Train Accuracy: 59.89%, Test Loss: 0.9936, Test Accuracy: 62.03%\n",
      "Epoch [158/2500], Train Loss: 0.9301, Train Accuracy: 59.17%, Test Loss: 0.9977, Test Accuracy: 60.76%\n",
      "Epoch [159/2500], Train Loss: 0.9108, Train Accuracy: 58.89%, Test Loss: 0.9944, Test Accuracy: 60.76%\n",
      "Epoch [160/2500], Train Loss: 0.9537, Train Accuracy: 57.33%, Test Loss: 0.9848, Test Accuracy: 60.76%\n",
      "Epoch [161/2500], Train Loss: 0.9436, Train Accuracy: 58.89%, Test Loss: 0.9704, Test Accuracy: 60.76%\n",
      "Epoch [162/2500], Train Loss: 0.9076, Train Accuracy: 60.03%, Test Loss: 0.9884, Test Accuracy: 62.03%\n",
      "Epoch [163/2500], Train Loss: 0.9428, Train Accuracy: 60.17%, Test Loss: 0.9983, Test Accuracy: 60.76%\n",
      "Epoch [164/2500], Train Loss: 0.9410, Train Accuracy: 59.17%, Test Loss: 0.9761, Test Accuracy: 60.76%\n",
      "Epoch [165/2500], Train Loss: 0.9359, Train Accuracy: 58.32%, Test Loss: 1.0020, Test Accuracy: 60.76%\n",
      "Epoch [166/2500], Train Loss: 0.9406, Train Accuracy: 58.46%, Test Loss: 0.9789, Test Accuracy: 60.76%\n",
      "Epoch [167/2500], Train Loss: 0.9116, Train Accuracy: 58.32%, Test Loss: 0.9938, Test Accuracy: 62.03%\n",
      "Epoch [168/2500], Train Loss: 0.9270, Train Accuracy: 60.03%, Test Loss: 0.9807, Test Accuracy: 60.76%\n",
      "Epoch [169/2500], Train Loss: 0.9155, Train Accuracy: 58.89%, Test Loss: 0.9857, Test Accuracy: 60.76%\n",
      "Epoch [170/2500], Train Loss: 0.9314, Train Accuracy: 59.60%, Test Loss: 0.9626, Test Accuracy: 62.03%\n",
      "Epoch [171/2500], Train Loss: 0.9153, Train Accuracy: 60.74%, Test Loss: 1.0277, Test Accuracy: 60.76%\n",
      "Epoch [172/2500], Train Loss: 0.9316, Train Accuracy: 58.75%, Test Loss: 0.9886, Test Accuracy: 62.03%\n",
      "Epoch [173/2500], Train Loss: 0.9241, Train Accuracy: 59.46%, Test Loss: 0.9995, Test Accuracy: 60.76%\n",
      "Epoch [174/2500], Train Loss: 0.9262, Train Accuracy: 60.31%, Test Loss: 0.9662, Test Accuracy: 62.03%\n",
      "Epoch [175/2500], Train Loss: 0.9199, Train Accuracy: 60.46%, Test Loss: 1.0134, Test Accuracy: 60.76%\n",
      "Epoch [176/2500], Train Loss: 0.9249, Train Accuracy: 58.61%, Test Loss: 0.9827, Test Accuracy: 59.49%\n",
      "Epoch [177/2500], Train Loss: 0.9184, Train Accuracy: 59.32%, Test Loss: 0.9959, Test Accuracy: 62.03%\n",
      "Epoch [178/2500], Train Loss: 0.9234, Train Accuracy: 60.17%, Test Loss: 0.9912, Test Accuracy: 60.76%\n",
      "Epoch [179/2500], Train Loss: 0.9301, Train Accuracy: 59.32%, Test Loss: 0.9632, Test Accuracy: 60.76%\n",
      "Epoch [180/2500], Train Loss: 0.9139, Train Accuracy: 59.46%, Test Loss: 0.9965, Test Accuracy: 60.76%\n",
      "Epoch [181/2500], Train Loss: 0.8949, Train Accuracy: 58.61%, Test Loss: 0.9819, Test Accuracy: 60.76%\n",
      "Epoch [182/2500], Train Loss: 0.9277, Train Accuracy: 59.89%, Test Loss: 0.9896, Test Accuracy: 62.03%\n",
      "Epoch [183/2500], Train Loss: 0.9177, Train Accuracy: 61.02%, Test Loss: 0.9758, Test Accuracy: 60.76%\n",
      "Epoch [184/2500], Train Loss: 0.9252, Train Accuracy: 59.46%, Test Loss: 0.9633, Test Accuracy: 60.76%\n",
      "Epoch [185/2500], Train Loss: 0.9379, Train Accuracy: 58.75%, Test Loss: 0.9623, Test Accuracy: 62.03%\n",
      "Epoch [186/2500], Train Loss: 0.9497, Train Accuracy: 59.32%, Test Loss: 0.9809, Test Accuracy: 60.76%\n",
      "Epoch [187/2500], Train Loss: 0.9275, Train Accuracy: 60.31%, Test Loss: 0.9686, Test Accuracy: 62.03%\n",
      "Epoch [188/2500], Train Loss: 0.9047, Train Accuracy: 60.74%, Test Loss: 0.9673, Test Accuracy: 62.03%\n",
      "Epoch [189/2500], Train Loss: 0.9165, Train Accuracy: 58.75%, Test Loss: 1.0284, Test Accuracy: 60.76%\n",
      "Epoch [190/2500], Train Loss: 0.9166, Train Accuracy: 60.74%, Test Loss: 0.9963, Test Accuracy: 62.03%\n",
      "Epoch [191/2500], Train Loss: 0.9190, Train Accuracy: 58.32%, Test Loss: 0.9673, Test Accuracy: 62.03%\n",
      "Epoch [192/2500], Train Loss: 0.9229, Train Accuracy: 60.03%, Test Loss: 0.9816, Test Accuracy: 60.76%\n",
      "Epoch [193/2500], Train Loss: 0.8720, Train Accuracy: 60.74%, Test Loss: 1.0090, Test Accuracy: 62.03%\n",
      "Epoch [194/2500], Train Loss: 0.8949, Train Accuracy: 60.74%, Test Loss: 1.0185, Test Accuracy: 62.03%\n",
      "Epoch [195/2500], Train Loss: 0.9040, Train Accuracy: 60.88%, Test Loss: 0.9864, Test Accuracy: 60.76%\n",
      "Epoch [196/2500], Train Loss: 0.9260, Train Accuracy: 59.03%, Test Loss: 0.9917, Test Accuracy: 60.76%\n",
      "Epoch [197/2500], Train Loss: 0.8993, Train Accuracy: 61.02%, Test Loss: 0.9936, Test Accuracy: 60.76%\n",
      "Epoch [198/2500], Train Loss: 0.9114, Train Accuracy: 58.75%, Test Loss: 1.0035, Test Accuracy: 62.03%\n",
      "Epoch [199/2500], Train Loss: 0.9194, Train Accuracy: 60.03%, Test Loss: 0.9821, Test Accuracy: 62.03%\n",
      "Epoch [200/2500], Train Loss: 0.9201, Train Accuracy: 60.74%, Test Loss: 0.9770, Test Accuracy: 60.76%\n",
      "Epoch [201/2500], Train Loss: 0.9041, Train Accuracy: 58.18%, Test Loss: 0.9831, Test Accuracy: 63.29%\n",
      "Epoch [202/2500], Train Loss: 0.9103, Train Accuracy: 60.17%, Test Loss: 0.9961, Test Accuracy: 62.03%\n",
      "Epoch [203/2500], Train Loss: 0.9072, Train Accuracy: 59.60%, Test Loss: 1.0072, Test Accuracy: 60.76%\n",
      "Epoch [204/2500], Train Loss: 0.9085, Train Accuracy: 59.60%, Test Loss: 0.9941, Test Accuracy: 60.76%\n",
      "Epoch [205/2500], Train Loss: 0.9097, Train Accuracy: 59.74%, Test Loss: 1.0179, Test Accuracy: 63.29%\n",
      "Epoch [206/2500], Train Loss: 0.9281, Train Accuracy: 58.75%, Test Loss: 0.9936, Test Accuracy: 62.03%\n",
      "Epoch [207/2500], Train Loss: 0.8931, Train Accuracy: 61.59%, Test Loss: 0.9779, Test Accuracy: 60.76%\n",
      "Epoch [208/2500], Train Loss: 0.9112, Train Accuracy: 60.74%, Test Loss: 0.9832, Test Accuracy: 60.76%\n",
      "Epoch [209/2500], Train Loss: 0.9104, Train Accuracy: 60.17%, Test Loss: 0.9647, Test Accuracy: 62.03%\n",
      "Epoch [210/2500], Train Loss: 0.8929, Train Accuracy: 60.88%, Test Loss: 0.9751, Test Accuracy: 62.03%\n",
      "Epoch [211/2500], Train Loss: 0.9194, Train Accuracy: 59.74%, Test Loss: 0.9869, Test Accuracy: 62.03%\n",
      "Epoch [212/2500], Train Loss: 0.9080, Train Accuracy: 59.60%, Test Loss: 0.9531, Test Accuracy: 62.03%\n",
      "Epoch [213/2500], Train Loss: 0.8917, Train Accuracy: 61.02%, Test Loss: 0.9749, Test Accuracy: 60.76%\n",
      "Epoch [214/2500], Train Loss: 0.8970, Train Accuracy: 59.89%, Test Loss: 0.9872, Test Accuracy: 60.76%\n",
      "Epoch [215/2500], Train Loss: 0.9034, Train Accuracy: 60.31%, Test Loss: 0.9748, Test Accuracy: 62.03%\n",
      "Epoch [216/2500], Train Loss: 0.9026, Train Accuracy: 58.18%, Test Loss: 0.9623, Test Accuracy: 60.76%\n",
      "Epoch [217/2500], Train Loss: 0.8890, Train Accuracy: 60.31%, Test Loss: 0.9880, Test Accuracy: 63.29%\n",
      "Epoch [218/2500], Train Loss: 0.8976, Train Accuracy: 60.46%, Test Loss: 0.9487, Test Accuracy: 62.03%\n",
      "Epoch [219/2500], Train Loss: 0.9226, Train Accuracy: 59.32%, Test Loss: 0.9856, Test Accuracy: 62.03%\n",
      "Epoch [220/2500], Train Loss: 0.9022, Train Accuracy: 60.88%, Test Loss: 0.9741, Test Accuracy: 62.03%\n",
      "Epoch [221/2500], Train Loss: 0.9083, Train Accuracy: 58.89%, Test Loss: 0.9599, Test Accuracy: 63.29%\n",
      "Epoch [222/2500], Train Loss: 0.9189, Train Accuracy: 59.03%, Test Loss: 0.9652, Test Accuracy: 60.76%\n",
      "Epoch [223/2500], Train Loss: 0.8948, Train Accuracy: 60.17%, Test Loss: 0.9734, Test Accuracy: 62.03%\n",
      "Epoch [224/2500], Train Loss: 0.8891, Train Accuracy: 61.59%, Test Loss: 0.9685, Test Accuracy: 63.29%\n",
      "Epoch [225/2500], Train Loss: 0.8980, Train Accuracy: 60.46%, Test Loss: 0.9662, Test Accuracy: 62.03%\n",
      "Epoch [226/2500], Train Loss: 0.8774, Train Accuracy: 61.45%, Test Loss: 0.9611, Test Accuracy: 62.03%\n",
      "Epoch [227/2500], Train Loss: 0.8856, Train Accuracy: 61.45%, Test Loss: 0.9790, Test Accuracy: 63.29%\n",
      "Epoch [228/2500], Train Loss: 0.8703, Train Accuracy: 60.88%, Test Loss: 0.9732, Test Accuracy: 62.03%\n",
      "Epoch [229/2500], Train Loss: 0.8908, Train Accuracy: 61.31%, Test Loss: 0.9797, Test Accuracy: 64.56%\n",
      "Epoch [230/2500], Train Loss: 0.8891, Train Accuracy: 59.46%, Test Loss: 0.9364, Test Accuracy: 60.76%\n",
      "Epoch [231/2500], Train Loss: 0.9117, Train Accuracy: 60.31%, Test Loss: 0.9590, Test Accuracy: 60.76%\n",
      "Epoch [232/2500], Train Loss: 0.9020, Train Accuracy: 61.02%, Test Loss: 0.9717, Test Accuracy: 62.03%\n",
      "Epoch [233/2500], Train Loss: 0.8955, Train Accuracy: 60.60%, Test Loss: 0.9882, Test Accuracy: 62.03%\n",
      "Epoch [234/2500], Train Loss: 0.8779, Train Accuracy: 59.89%, Test Loss: 0.9815, Test Accuracy: 64.56%\n",
      "Epoch [235/2500], Train Loss: 0.9122, Train Accuracy: 58.61%, Test Loss: 0.9719, Test Accuracy: 63.29%\n",
      "Epoch [236/2500], Train Loss: 0.8859, Train Accuracy: 60.46%, Test Loss: 0.9690, Test Accuracy: 62.03%\n",
      "Epoch [237/2500], Train Loss: 0.8625, Train Accuracy: 62.87%, Test Loss: 0.9792, Test Accuracy: 63.29%\n",
      "Epoch [238/2500], Train Loss: 0.8801, Train Accuracy: 60.17%, Test Loss: 0.9797, Test Accuracy: 63.29%\n",
      "Epoch [239/2500], Train Loss: 0.8928, Train Accuracy: 61.31%, Test Loss: 0.9644, Test Accuracy: 63.29%\n",
      "Epoch [240/2500], Train Loss: 0.8806, Train Accuracy: 62.73%, Test Loss: 0.9699, Test Accuracy: 60.76%\n",
      "Epoch [241/2500], Train Loss: 0.8883, Train Accuracy: 61.59%, Test Loss: 0.9804, Test Accuracy: 60.76%\n",
      "Epoch [242/2500], Train Loss: 0.8791, Train Accuracy: 60.60%, Test Loss: 0.9795, Test Accuracy: 62.03%\n",
      "Epoch [243/2500], Train Loss: 0.8635, Train Accuracy: 61.45%, Test Loss: 0.9744, Test Accuracy: 62.03%\n",
      "Epoch [244/2500], Train Loss: 0.9135, Train Accuracy: 59.89%, Test Loss: 0.9799, Test Accuracy: 64.56%\n",
      "Epoch [245/2500], Train Loss: 0.8991, Train Accuracy: 60.17%, Test Loss: 0.9746, Test Accuracy: 63.29%\n",
      "Epoch [246/2500], Train Loss: 0.8807, Train Accuracy: 61.59%, Test Loss: 0.9841, Test Accuracy: 63.29%\n",
      "Epoch [247/2500], Train Loss: 0.9082, Train Accuracy: 60.46%, Test Loss: 0.9458, Test Accuracy: 64.56%\n",
      "Epoch [248/2500], Train Loss: 0.8864, Train Accuracy: 59.74%, Test Loss: 0.9967, Test Accuracy: 64.56%\n",
      "Epoch [249/2500], Train Loss: 0.8673, Train Accuracy: 59.60%, Test Loss: 0.9884, Test Accuracy: 63.29%\n",
      "Epoch [250/2500], Train Loss: 0.8927, Train Accuracy: 60.31%, Test Loss: 0.9939, Test Accuracy: 63.29%\n",
      "Epoch [251/2500], Train Loss: 0.8701, Train Accuracy: 62.73%, Test Loss: 0.9813, Test Accuracy: 63.29%\n",
      "Epoch [252/2500], Train Loss: 0.9030, Train Accuracy: 60.03%, Test Loss: 0.9724, Test Accuracy: 62.03%\n",
      "Epoch [253/2500], Train Loss: 0.9107, Train Accuracy: 59.60%, Test Loss: 0.9680, Test Accuracy: 63.29%\n",
      "Epoch [254/2500], Train Loss: 0.8870, Train Accuracy: 60.60%, Test Loss: 0.9701, Test Accuracy: 63.29%\n",
      "Epoch [255/2500], Train Loss: 0.8688, Train Accuracy: 61.74%, Test Loss: 0.9806, Test Accuracy: 64.56%\n",
      "Epoch [256/2500], Train Loss: 0.8896, Train Accuracy: 60.60%, Test Loss: 0.9753, Test Accuracy: 63.29%\n",
      "Epoch [257/2500], Train Loss: 0.8828, Train Accuracy: 60.88%, Test Loss: 0.9704, Test Accuracy: 63.29%\n",
      "Epoch [258/2500], Train Loss: 0.8830, Train Accuracy: 61.45%, Test Loss: 1.0001, Test Accuracy: 63.29%\n",
      "Epoch [259/2500], Train Loss: 0.8856, Train Accuracy: 61.59%, Test Loss: 0.9889, Test Accuracy: 64.56%\n",
      "Epoch [260/2500], Train Loss: 0.8688, Train Accuracy: 61.59%, Test Loss: 0.9904, Test Accuracy: 62.03%\n",
      "Epoch [261/2500], Train Loss: 0.8792, Train Accuracy: 60.31%, Test Loss: 0.9801, Test Accuracy: 64.56%\n",
      "Epoch [262/2500], Train Loss: 0.8747, Train Accuracy: 63.02%, Test Loss: 0.9868, Test Accuracy: 60.76%\n",
      "Epoch [263/2500], Train Loss: 0.8793, Train Accuracy: 60.60%, Test Loss: 0.9664, Test Accuracy: 64.56%\n",
      "Epoch [264/2500], Train Loss: 0.8623, Train Accuracy: 61.31%, Test Loss: 0.9850, Test Accuracy: 64.56%\n",
      "Epoch [265/2500], Train Loss: 0.8981, Train Accuracy: 59.46%, Test Loss: 0.9851, Test Accuracy: 64.56%\n",
      "Epoch [266/2500], Train Loss: 0.8728, Train Accuracy: 62.02%, Test Loss: 0.9830, Test Accuracy: 64.56%\n",
      "Epoch [267/2500], Train Loss: 0.8580, Train Accuracy: 60.60%, Test Loss: 0.9768, Test Accuracy: 64.56%\n",
      "Epoch [268/2500], Train Loss: 0.8829, Train Accuracy: 60.31%, Test Loss: 1.0026, Test Accuracy: 63.29%\n",
      "Epoch [269/2500], Train Loss: 0.8671, Train Accuracy: 61.59%, Test Loss: 0.9766, Test Accuracy: 63.29%\n",
      "Epoch [270/2500], Train Loss: 0.8772, Train Accuracy: 60.88%, Test Loss: 0.9890, Test Accuracy: 63.29%\n",
      "Epoch [271/2500], Train Loss: 0.8717, Train Accuracy: 61.59%, Test Loss: 0.9760, Test Accuracy: 64.56%\n",
      "Epoch [272/2500], Train Loss: 0.8919, Train Accuracy: 60.46%, Test Loss: 0.9600, Test Accuracy: 64.56%\n",
      "Epoch [273/2500], Train Loss: 0.8639, Train Accuracy: 61.74%, Test Loss: 0.9648, Test Accuracy: 64.56%\n",
      "Epoch [274/2500], Train Loss: 0.8694, Train Accuracy: 61.17%, Test Loss: 0.9738, Test Accuracy: 64.56%\n",
      "Epoch [275/2500], Train Loss: 0.8730, Train Accuracy: 61.17%, Test Loss: 0.9881, Test Accuracy: 64.56%\n",
      "Epoch [276/2500], Train Loss: 0.8787, Train Accuracy: 60.88%, Test Loss: 0.9858, Test Accuracy: 64.56%\n",
      "Epoch [277/2500], Train Loss: 0.8974, Train Accuracy: 61.17%, Test Loss: 0.9768, Test Accuracy: 64.56%\n",
      "Epoch [278/2500], Train Loss: 0.8756, Train Accuracy: 62.16%, Test Loss: 0.9944, Test Accuracy: 63.29%\n",
      "Epoch [279/2500], Train Loss: 0.8717, Train Accuracy: 62.16%, Test Loss: 0.9976, Test Accuracy: 64.56%\n",
      "Epoch [280/2500], Train Loss: 0.8765, Train Accuracy: 59.32%, Test Loss: 0.9834, Test Accuracy: 64.56%\n",
      "Epoch [281/2500], Train Loss: 0.8622, Train Accuracy: 61.02%, Test Loss: 0.9799, Test Accuracy: 64.56%\n",
      "Epoch [282/2500], Train Loss: 0.8715, Train Accuracy: 61.02%, Test Loss: 0.9423, Test Accuracy: 64.56%\n",
      "Epoch [283/2500], Train Loss: 0.8772, Train Accuracy: 61.45%, Test Loss: 0.9736, Test Accuracy: 64.56%\n",
      "Epoch [284/2500], Train Loss: 0.8720, Train Accuracy: 60.88%, Test Loss: 0.9671, Test Accuracy: 64.56%\n",
      "Epoch [285/2500], Train Loss: 0.8924, Train Accuracy: 61.02%, Test Loss: 0.9570, Test Accuracy: 64.56%\n",
      "Epoch [286/2500], Train Loss: 0.8783, Train Accuracy: 60.31%, Test Loss: 0.9849, Test Accuracy: 62.03%\n",
      "Epoch [287/2500], Train Loss: 0.8373, Train Accuracy: 63.02%, Test Loss: 0.9813, Test Accuracy: 62.03%\n",
      "Epoch [288/2500], Train Loss: 0.8680, Train Accuracy: 60.74%, Test Loss: 0.9531, Test Accuracy: 64.56%\n",
      "Epoch [289/2500], Train Loss: 0.8840, Train Accuracy: 61.17%, Test Loss: 0.9615, Test Accuracy: 64.56%\n",
      "Epoch [290/2500], Train Loss: 0.8729, Train Accuracy: 60.60%, Test Loss: 0.9563, Test Accuracy: 60.76%\n",
      "Epoch [291/2500], Train Loss: 0.8588, Train Accuracy: 62.16%, Test Loss: 0.9698, Test Accuracy: 63.29%\n",
      "Epoch [292/2500], Train Loss: 0.8705, Train Accuracy: 61.45%, Test Loss: 0.9788, Test Accuracy: 62.03%\n",
      "Epoch [293/2500], Train Loss: 0.8631, Train Accuracy: 63.44%, Test Loss: 0.9769, Test Accuracy: 64.56%\n",
      "Epoch [294/2500], Train Loss: 0.8647, Train Accuracy: 62.45%, Test Loss: 0.9862, Test Accuracy: 62.03%\n",
      "Epoch [295/2500], Train Loss: 0.8509, Train Accuracy: 61.59%, Test Loss: 0.9884, Test Accuracy: 60.76%\n",
      "Epoch [296/2500], Train Loss: 0.8606, Train Accuracy: 60.46%, Test Loss: 0.9611, Test Accuracy: 64.56%\n",
      "Epoch [297/2500], Train Loss: 0.8645, Train Accuracy: 60.17%, Test Loss: 0.9801, Test Accuracy: 62.03%\n",
      "Epoch [298/2500], Train Loss: 0.8638, Train Accuracy: 60.60%, Test Loss: 0.9627, Test Accuracy: 64.56%\n",
      "Epoch [299/2500], Train Loss: 0.8559, Train Accuracy: 62.59%, Test Loss: 0.9982, Test Accuracy: 62.03%\n",
      "Epoch [300/2500], Train Loss: 0.8567, Train Accuracy: 62.45%, Test Loss: 0.9573, Test Accuracy: 62.03%\n",
      "Epoch [301/2500], Train Loss: 0.8617, Train Accuracy: 61.59%, Test Loss: 0.9794, Test Accuracy: 62.03%\n",
      "Epoch [302/2500], Train Loss: 0.8708, Train Accuracy: 61.45%, Test Loss: 0.9562, Test Accuracy: 62.03%\n",
      "Epoch [303/2500], Train Loss: 0.8643, Train Accuracy: 61.45%, Test Loss: 0.9779, Test Accuracy: 60.76%\n",
      "Epoch [304/2500], Train Loss: 0.8595, Train Accuracy: 62.02%, Test Loss: 1.0056, Test Accuracy: 62.03%\n",
      "Epoch [305/2500], Train Loss: 0.8534, Train Accuracy: 61.88%, Test Loss: 0.9727, Test Accuracy: 63.29%\n",
      "Epoch [306/2500], Train Loss: 0.8669, Train Accuracy: 61.17%, Test Loss: 0.9701, Test Accuracy: 64.56%\n",
      "Epoch [307/2500], Train Loss: 0.8635, Train Accuracy: 62.87%, Test Loss: 0.9592, Test Accuracy: 62.03%\n",
      "Epoch [308/2500], Train Loss: 0.8686, Train Accuracy: 61.74%, Test Loss: 0.9794, Test Accuracy: 60.76%\n",
      "Epoch [309/2500], Train Loss: 0.8630, Train Accuracy: 61.74%, Test Loss: 0.9696, Test Accuracy: 62.03%\n",
      "Epoch [310/2500], Train Loss: 0.8533, Train Accuracy: 63.16%, Test Loss: 0.9873, Test Accuracy: 59.49%\n",
      "Epoch [311/2500], Train Loss: 0.8454, Train Accuracy: 62.87%, Test Loss: 0.9896, Test Accuracy: 60.76%\n",
      "Epoch [312/2500], Train Loss: 0.8953, Train Accuracy: 59.46%, Test Loss: 0.9548, Test Accuracy: 62.03%\n",
      "Epoch [313/2500], Train Loss: 0.8834, Train Accuracy: 60.17%, Test Loss: 0.9670, Test Accuracy: 63.29%\n",
      "Epoch [314/2500], Train Loss: 0.8469, Train Accuracy: 60.31%, Test Loss: 0.9676, Test Accuracy: 60.76%\n",
      "Epoch [315/2500], Train Loss: 0.8693, Train Accuracy: 62.87%, Test Loss: 0.9817, Test Accuracy: 62.03%\n",
      "Epoch [316/2500], Train Loss: 0.8747, Train Accuracy: 62.87%, Test Loss: 0.9579, Test Accuracy: 64.56%\n",
      "Epoch [317/2500], Train Loss: 0.8493, Train Accuracy: 61.31%, Test Loss: 0.9665, Test Accuracy: 64.56%\n",
      "Epoch [318/2500], Train Loss: 0.8707, Train Accuracy: 60.88%, Test Loss: 0.9635, Test Accuracy: 62.03%\n",
      "Epoch [319/2500], Train Loss: 0.8644, Train Accuracy: 62.73%, Test Loss: 0.9707, Test Accuracy: 62.03%\n",
      "Epoch [320/2500], Train Loss: 0.8359, Train Accuracy: 63.30%, Test Loss: 0.9808, Test Accuracy: 64.56%\n",
      "Epoch [321/2500], Train Loss: 0.8543, Train Accuracy: 61.17%, Test Loss: 0.9773, Test Accuracy: 60.76%\n",
      "Epoch [322/2500], Train Loss: 0.8629, Train Accuracy: 60.88%, Test Loss: 0.9723, Test Accuracy: 63.29%\n",
      "Epoch [323/2500], Train Loss: 0.8581, Train Accuracy: 61.88%, Test Loss: 0.9541, Test Accuracy: 63.29%\n",
      "Epoch [324/2500], Train Loss: 0.8499, Train Accuracy: 62.45%, Test Loss: 0.9660, Test Accuracy: 63.29%\n",
      "Epoch [325/2500], Train Loss: 0.8435, Train Accuracy: 63.44%, Test Loss: 0.9725, Test Accuracy: 64.56%\n",
      "Epoch [326/2500], Train Loss: 0.8643, Train Accuracy: 61.74%, Test Loss: 0.9765, Test Accuracy: 64.56%\n",
      "Epoch [327/2500], Train Loss: 0.8879, Train Accuracy: 60.74%, Test Loss: 0.9491, Test Accuracy: 60.76%\n",
      "Epoch [328/2500], Train Loss: 0.8526, Train Accuracy: 61.45%, Test Loss: 0.9586, Test Accuracy: 64.56%\n",
      "Epoch [329/2500], Train Loss: 0.8646, Train Accuracy: 61.59%, Test Loss: 0.9679, Test Accuracy: 59.49%\n",
      "Epoch [330/2500], Train Loss: 0.8550, Train Accuracy: 63.30%, Test Loss: 0.9450, Test Accuracy: 63.29%\n",
      "Epoch [331/2500], Train Loss: 0.8492, Train Accuracy: 60.60%, Test Loss: 0.9502, Test Accuracy: 64.56%\n",
      "Epoch [332/2500], Train Loss: 0.8456, Train Accuracy: 63.02%, Test Loss: 0.9560, Test Accuracy: 63.29%\n",
      "Epoch [333/2500], Train Loss: 0.8385, Train Accuracy: 64.01%, Test Loss: 0.9538, Test Accuracy: 63.29%\n",
      "Epoch [334/2500], Train Loss: 0.8578, Train Accuracy: 62.16%, Test Loss: 0.9771, Test Accuracy: 63.29%\n",
      "Epoch [335/2500], Train Loss: 0.8638, Train Accuracy: 61.02%, Test Loss: 0.9494, Test Accuracy: 63.29%\n",
      "Epoch [336/2500], Train Loss: 0.8277, Train Accuracy: 62.87%, Test Loss: 0.9922, Test Accuracy: 60.76%\n",
      "Epoch [337/2500], Train Loss: 0.8443, Train Accuracy: 62.59%, Test Loss: 0.9491, Test Accuracy: 62.03%\n",
      "Epoch [338/2500], Train Loss: 0.8456, Train Accuracy: 63.30%, Test Loss: 0.9643, Test Accuracy: 63.29%\n",
      "Epoch [339/2500], Train Loss: 0.8577, Train Accuracy: 61.31%, Test Loss: 0.9635, Test Accuracy: 63.29%\n",
      "Epoch [340/2500], Train Loss: 0.8444, Train Accuracy: 60.60%, Test Loss: 0.9711, Test Accuracy: 59.49%\n",
      "Epoch [341/2500], Train Loss: 0.8299, Train Accuracy: 63.58%, Test Loss: 0.9579, Test Accuracy: 63.29%\n",
      "Epoch [342/2500], Train Loss: 0.8475, Train Accuracy: 63.87%, Test Loss: 0.9636, Test Accuracy: 62.03%\n",
      "Epoch [343/2500], Train Loss: 0.8708, Train Accuracy: 61.88%, Test Loss: 0.9455, Test Accuracy: 62.03%\n",
      "Epoch [344/2500], Train Loss: 0.8368, Train Accuracy: 63.02%, Test Loss: 0.9675, Test Accuracy: 62.03%\n",
      "Epoch [345/2500], Train Loss: 0.8866, Train Accuracy: 61.88%, Test Loss: 0.9633, Test Accuracy: 62.03%\n",
      "Epoch [346/2500], Train Loss: 0.8340, Train Accuracy: 63.44%, Test Loss: 0.9420, Test Accuracy: 63.29%\n",
      "Epoch [347/2500], Train Loss: 0.8568, Train Accuracy: 61.17%, Test Loss: 0.9494, Test Accuracy: 64.56%\n",
      "Epoch [348/2500], Train Loss: 0.8414, Train Accuracy: 63.02%, Test Loss: 0.9565, Test Accuracy: 63.29%\n",
      "Epoch [349/2500], Train Loss: 0.8435, Train Accuracy: 62.45%, Test Loss: 0.9652, Test Accuracy: 64.56%\n",
      "Epoch [350/2500], Train Loss: 0.8460, Train Accuracy: 62.45%, Test Loss: 0.9629, Test Accuracy: 62.03%\n",
      "Epoch [351/2500], Train Loss: 0.8514, Train Accuracy: 61.88%, Test Loss: 0.9651, Test Accuracy: 63.29%\n",
      "Epoch [352/2500], Train Loss: 0.8467, Train Accuracy: 63.02%, Test Loss: 0.9646, Test Accuracy: 63.29%\n",
      "Epoch [353/2500], Train Loss: 0.8507, Train Accuracy: 62.45%, Test Loss: 0.9799, Test Accuracy: 59.49%\n",
      "Epoch [354/2500], Train Loss: 0.8361, Train Accuracy: 65.15%, Test Loss: 0.9750, Test Accuracy: 62.03%\n",
      "Epoch [355/2500], Train Loss: 0.8535, Train Accuracy: 63.73%, Test Loss: 0.9548, Test Accuracy: 63.29%\n",
      "Epoch [356/2500], Train Loss: 0.8447, Train Accuracy: 62.87%, Test Loss: 0.9733, Test Accuracy: 62.03%\n",
      "Epoch [357/2500], Train Loss: 0.8349, Train Accuracy: 63.73%, Test Loss: 0.9653, Test Accuracy: 63.29%\n",
      "Epoch [358/2500], Train Loss: 0.8270, Train Accuracy: 61.59%, Test Loss: 0.9626, Test Accuracy: 63.29%\n",
      "Epoch [359/2500], Train Loss: 0.8441, Train Accuracy: 62.87%, Test Loss: 0.9764, Test Accuracy: 64.56%\n",
      "Epoch [360/2500], Train Loss: 0.8396, Train Accuracy: 63.30%, Test Loss: 0.9625, Test Accuracy: 63.29%\n",
      "Epoch [361/2500], Train Loss: 0.8408, Train Accuracy: 63.87%, Test Loss: 0.9634, Test Accuracy: 63.29%\n",
      "Epoch [362/2500], Train Loss: 0.8420, Train Accuracy: 64.15%, Test Loss: 1.0015, Test Accuracy: 62.03%\n",
      "Epoch [363/2500], Train Loss: 0.8469, Train Accuracy: 62.16%, Test Loss: 0.9605, Test Accuracy: 63.29%\n",
      "Epoch [364/2500], Train Loss: 0.8154, Train Accuracy: 64.01%, Test Loss: 0.9719, Test Accuracy: 63.29%\n",
      "Epoch [365/2500], Train Loss: 0.8650, Train Accuracy: 63.16%, Test Loss: 0.9619, Test Accuracy: 63.29%\n",
      "Epoch [366/2500], Train Loss: 0.8673, Train Accuracy: 62.30%, Test Loss: 0.9583, Test Accuracy: 63.29%\n",
      "Epoch [367/2500], Train Loss: 0.8327, Train Accuracy: 63.16%, Test Loss: 0.9646, Test Accuracy: 62.03%\n",
      "Epoch [368/2500], Train Loss: 0.8367, Train Accuracy: 64.58%, Test Loss: 0.9314, Test Accuracy: 63.29%\n",
      "Epoch [369/2500], Train Loss: 0.8310, Train Accuracy: 62.30%, Test Loss: 0.9524, Test Accuracy: 63.29%\n",
      "Epoch [370/2500], Train Loss: 0.8622, Train Accuracy: 62.02%, Test Loss: 0.9460, Test Accuracy: 62.03%\n",
      "Epoch [371/2500], Train Loss: 0.8413, Train Accuracy: 63.87%, Test Loss: 0.9442, Test Accuracy: 64.56%\n",
      "Epoch [372/2500], Train Loss: 0.8550, Train Accuracy: 62.59%, Test Loss: 0.9573, Test Accuracy: 62.03%\n",
      "Epoch [373/2500], Train Loss: 0.8557, Train Accuracy: 62.59%, Test Loss: 0.9286, Test Accuracy: 63.29%\n",
      "Epoch [374/2500], Train Loss: 0.8409, Train Accuracy: 63.44%, Test Loss: 0.9549, Test Accuracy: 62.03%\n",
      "Epoch [375/2500], Train Loss: 0.8296, Train Accuracy: 62.73%, Test Loss: 0.9548, Test Accuracy: 62.03%\n",
      "Epoch [376/2500], Train Loss: 0.8400, Train Accuracy: 63.58%, Test Loss: 0.9393, Test Accuracy: 64.56%\n",
      "Epoch [377/2500], Train Loss: 0.8194, Train Accuracy: 62.16%, Test Loss: 0.9502, Test Accuracy: 63.29%\n",
      "Epoch [378/2500], Train Loss: 0.8190, Train Accuracy: 65.01%, Test Loss: 0.9730, Test Accuracy: 62.03%\n",
      "Epoch [379/2500], Train Loss: 0.8265, Train Accuracy: 63.87%, Test Loss: 0.9547, Test Accuracy: 63.29%\n",
      "Epoch [380/2500], Train Loss: 0.8458, Train Accuracy: 64.30%, Test Loss: 0.9427, Test Accuracy: 62.03%\n",
      "Epoch [381/2500], Train Loss: 0.8445, Train Accuracy: 63.58%, Test Loss: 0.9667, Test Accuracy: 62.03%\n",
      "Epoch [382/2500], Train Loss: 0.8365, Train Accuracy: 64.44%, Test Loss: 0.9537, Test Accuracy: 62.03%\n",
      "Epoch [383/2500], Train Loss: 0.8505, Train Accuracy: 61.88%, Test Loss: 0.9364, Test Accuracy: 63.29%\n",
      "Epoch [384/2500], Train Loss: 0.8322, Train Accuracy: 62.16%, Test Loss: 0.9504, Test Accuracy: 62.03%\n",
      "Epoch [385/2500], Train Loss: 0.8333, Train Accuracy: 61.88%, Test Loss: 0.9258, Test Accuracy: 67.09%\n",
      "Epoch [386/2500], Train Loss: 0.8204, Train Accuracy: 62.87%, Test Loss: 0.9625, Test Accuracy: 62.03%\n",
      "Epoch [387/2500], Train Loss: 0.8343, Train Accuracy: 62.59%, Test Loss: 0.9536, Test Accuracy: 62.03%\n",
      "Epoch [388/2500], Train Loss: 0.8388, Train Accuracy: 63.73%, Test Loss: 0.9451, Test Accuracy: 63.29%\n",
      "Epoch [389/2500], Train Loss: 0.8393, Train Accuracy: 63.58%, Test Loss: 0.9588, Test Accuracy: 60.76%\n",
      "Epoch [390/2500], Train Loss: 0.8533, Train Accuracy: 63.73%, Test Loss: 0.9553, Test Accuracy: 60.76%\n",
      "Epoch [391/2500], Train Loss: 0.8281, Train Accuracy: 63.58%, Test Loss: 0.9504, Test Accuracy: 63.29%\n",
      "Epoch [392/2500], Train Loss: 0.8133, Train Accuracy: 64.30%, Test Loss: 0.9653, Test Accuracy: 62.03%\n",
      "Epoch [393/2500], Train Loss: 0.8270, Train Accuracy: 62.87%, Test Loss: 0.9534, Test Accuracy: 62.03%\n",
      "Epoch [394/2500], Train Loss: 0.8265, Train Accuracy: 65.72%, Test Loss: 0.9244, Test Accuracy: 67.09%\n",
      "Epoch [395/2500], Train Loss: 0.8344, Train Accuracy: 63.44%, Test Loss: 0.9475, Test Accuracy: 62.03%\n",
      "Epoch [396/2500], Train Loss: 0.8292, Train Accuracy: 63.30%, Test Loss: 0.9401, Test Accuracy: 64.56%\n",
      "Epoch [397/2500], Train Loss: 0.8154, Train Accuracy: 64.01%, Test Loss: 0.9547, Test Accuracy: 63.29%\n",
      "Epoch [398/2500], Train Loss: 0.7879, Train Accuracy: 64.86%, Test Loss: 0.9643, Test Accuracy: 63.29%\n",
      "Epoch [399/2500], Train Loss: 0.8064, Train Accuracy: 65.58%, Test Loss: 0.9643, Test Accuracy: 62.03%\n",
      "Epoch [400/2500], Train Loss: 0.8329, Train Accuracy: 62.87%, Test Loss: 0.9434, Test Accuracy: 62.03%\n",
      "Epoch [401/2500], Train Loss: 0.8466, Train Accuracy: 62.87%, Test Loss: 0.9178, Test Accuracy: 63.29%\n",
      "Epoch [402/2500], Train Loss: 0.8218, Train Accuracy: 63.30%, Test Loss: 0.9388, Test Accuracy: 62.03%\n",
      "Epoch [403/2500], Train Loss: 0.8261, Train Accuracy: 63.30%, Test Loss: 0.9186, Test Accuracy: 62.03%\n",
      "Epoch [404/2500], Train Loss: 0.8029, Train Accuracy: 64.30%, Test Loss: 0.9355, Test Accuracy: 63.29%\n",
      "Epoch [405/2500], Train Loss: 0.8164, Train Accuracy: 63.02%, Test Loss: 0.9671, Test Accuracy: 62.03%\n",
      "Epoch [406/2500], Train Loss: 0.8138, Train Accuracy: 63.58%, Test Loss: 0.9634, Test Accuracy: 62.03%\n",
      "Epoch [407/2500], Train Loss: 0.8191, Train Accuracy: 65.29%, Test Loss: 0.9440, Test Accuracy: 62.03%\n",
      "Epoch [408/2500], Train Loss: 0.8402, Train Accuracy: 63.16%, Test Loss: 0.9331, Test Accuracy: 62.03%\n",
      "Epoch [409/2500], Train Loss: 0.8369, Train Accuracy: 63.02%, Test Loss: 0.9674, Test Accuracy: 62.03%\n",
      "Epoch [410/2500], Train Loss: 0.8457, Train Accuracy: 61.74%, Test Loss: 0.9256, Test Accuracy: 62.03%\n",
      "Epoch [411/2500], Train Loss: 0.8182, Train Accuracy: 64.86%, Test Loss: 0.9429, Test Accuracy: 62.03%\n",
      "Epoch [412/2500], Train Loss: 0.8068, Train Accuracy: 64.30%, Test Loss: 0.9402, Test Accuracy: 62.03%\n",
      "Epoch [413/2500], Train Loss: 0.8290, Train Accuracy: 63.02%, Test Loss: 0.9401, Test Accuracy: 62.03%\n",
      "Epoch [414/2500], Train Loss: 0.8221, Train Accuracy: 62.02%, Test Loss: 0.9520, Test Accuracy: 62.03%\n",
      "Epoch [415/2500], Train Loss: 0.8209, Train Accuracy: 65.01%, Test Loss: 0.9412, Test Accuracy: 62.03%\n",
      "Epoch [416/2500], Train Loss: 0.8210, Train Accuracy: 64.86%, Test Loss: 0.9407, Test Accuracy: 62.03%\n",
      "Epoch [417/2500], Train Loss: 0.8166, Train Accuracy: 65.72%, Test Loss: 0.9569, Test Accuracy: 62.03%\n",
      "Epoch [418/2500], Train Loss: 0.8133, Train Accuracy: 65.86%, Test Loss: 0.9542, Test Accuracy: 62.03%\n",
      "Epoch [419/2500], Train Loss: 0.7947, Train Accuracy: 64.72%, Test Loss: 0.9410, Test Accuracy: 62.03%\n",
      "Epoch [420/2500], Train Loss: 0.8333, Train Accuracy: 66.00%, Test Loss: 0.9381, Test Accuracy: 62.03%\n",
      "Epoch [421/2500], Train Loss: 0.8348, Train Accuracy: 62.02%, Test Loss: 0.9383, Test Accuracy: 62.03%\n",
      "Epoch [422/2500], Train Loss: 0.8131, Train Accuracy: 65.43%, Test Loss: 0.9371, Test Accuracy: 62.03%\n",
      "Epoch [423/2500], Train Loss: 0.8214, Train Accuracy: 64.72%, Test Loss: 0.9337, Test Accuracy: 62.03%\n",
      "Epoch [424/2500], Train Loss: 0.8187, Train Accuracy: 64.44%, Test Loss: 0.9291, Test Accuracy: 60.76%\n",
      "Epoch [425/2500], Train Loss: 0.8215, Train Accuracy: 63.02%, Test Loss: 0.9344, Test Accuracy: 62.03%\n",
      "Epoch [426/2500], Train Loss: 0.8268, Train Accuracy: 63.02%, Test Loss: 0.9201, Test Accuracy: 62.03%\n",
      "Epoch [427/2500], Train Loss: 0.8049, Train Accuracy: 65.58%, Test Loss: 0.9465, Test Accuracy: 63.29%\n",
      "Epoch [428/2500], Train Loss: 0.8169, Train Accuracy: 64.15%, Test Loss: 0.9346, Test Accuracy: 62.03%\n",
      "Epoch [429/2500], Train Loss: 0.8163, Train Accuracy: 66.57%, Test Loss: 0.9382, Test Accuracy: 63.29%\n",
      "Epoch [430/2500], Train Loss: 0.8150, Train Accuracy: 66.15%, Test Loss: 0.9386, Test Accuracy: 62.03%\n",
      "Epoch [431/2500], Train Loss: 0.8146, Train Accuracy: 62.73%, Test Loss: 0.9325, Test Accuracy: 62.03%\n",
      "Epoch [432/2500], Train Loss: 0.7956, Train Accuracy: 65.29%, Test Loss: 0.9607, Test Accuracy: 62.03%\n",
      "Epoch [433/2500], Train Loss: 0.7887, Train Accuracy: 65.29%, Test Loss: 0.9607, Test Accuracy: 62.03%\n",
      "Epoch [434/2500], Train Loss: 0.8087, Train Accuracy: 64.01%, Test Loss: 0.9642, Test Accuracy: 62.03%\n",
      "Epoch [435/2500], Train Loss: 0.8188, Train Accuracy: 64.15%, Test Loss: 0.9270, Test Accuracy: 62.03%\n",
      "Epoch [436/2500], Train Loss: 0.8505, Train Accuracy: 61.74%, Test Loss: 0.9051, Test Accuracy: 62.03%\n",
      "Epoch [437/2500], Train Loss: 0.8079, Train Accuracy: 64.30%, Test Loss: 0.9191, Test Accuracy: 62.03%\n",
      "Epoch [438/2500], Train Loss: 0.7909, Train Accuracy: 64.72%, Test Loss: 0.9260, Test Accuracy: 63.29%\n",
      "Epoch [439/2500], Train Loss: 0.8133, Train Accuracy: 63.87%, Test Loss: 0.9152, Test Accuracy: 63.29%\n",
      "Epoch [440/2500], Train Loss: 0.8159, Train Accuracy: 64.72%, Test Loss: 0.9252, Test Accuracy: 62.03%\n",
      "Epoch [441/2500], Train Loss: 0.8153, Train Accuracy: 64.01%, Test Loss: 0.9117, Test Accuracy: 60.76%\n",
      "Epoch [442/2500], Train Loss: 0.8441, Train Accuracy: 63.16%, Test Loss: 0.9435, Test Accuracy: 63.29%\n",
      "Epoch [443/2500], Train Loss: 0.8144, Train Accuracy: 63.30%, Test Loss: 0.9391, Test Accuracy: 63.29%\n",
      "Epoch [444/2500], Train Loss: 0.8079, Train Accuracy: 64.72%, Test Loss: 0.9159, Test Accuracy: 60.76%\n",
      "Epoch [445/2500], Train Loss: 0.8185, Train Accuracy: 64.01%, Test Loss: 0.9212, Test Accuracy: 62.03%\n",
      "Epoch [446/2500], Train Loss: 0.8080, Train Accuracy: 64.72%, Test Loss: 0.9055, Test Accuracy: 64.56%\n",
      "Epoch [447/2500], Train Loss: 0.8203, Train Accuracy: 65.43%, Test Loss: 0.9142, Test Accuracy: 63.29%\n",
      "Epoch [448/2500], Train Loss: 0.8176, Train Accuracy: 62.30%, Test Loss: 0.9081, Test Accuracy: 60.76%\n",
      "Epoch [449/2500], Train Loss: 0.7920, Train Accuracy: 64.86%, Test Loss: 0.9452, Test Accuracy: 62.03%\n",
      "Epoch [450/2500], Train Loss: 0.8143, Train Accuracy: 64.15%, Test Loss: 0.9487, Test Accuracy: 62.03%\n",
      "Epoch [451/2500], Train Loss: 0.7854, Train Accuracy: 65.43%, Test Loss: 0.9278, Test Accuracy: 64.56%\n",
      "Epoch [452/2500], Train Loss: 0.7967, Train Accuracy: 64.72%, Test Loss: 0.9330, Test Accuracy: 63.29%\n",
      "Epoch [453/2500], Train Loss: 0.7844, Train Accuracy: 66.57%, Test Loss: 0.9505, Test Accuracy: 62.03%\n",
      "Epoch [454/2500], Train Loss: 0.7914, Train Accuracy: 66.57%, Test Loss: 0.9695, Test Accuracy: 62.03%\n",
      "Epoch [455/2500], Train Loss: 0.7896, Train Accuracy: 65.29%, Test Loss: 0.9482, Test Accuracy: 62.03%\n",
      "Epoch [456/2500], Train Loss: 0.8010, Train Accuracy: 65.15%, Test Loss: 0.9458, Test Accuracy: 62.03%\n",
      "Epoch [457/2500], Train Loss: 0.8048, Train Accuracy: 64.58%, Test Loss: 0.9459, Test Accuracy: 63.29%\n",
      "Epoch [458/2500], Train Loss: 0.7948, Train Accuracy: 62.87%, Test Loss: 0.9344, Test Accuracy: 62.03%\n",
      "Epoch [459/2500], Train Loss: 0.7977, Train Accuracy: 66.15%, Test Loss: 0.9267, Test Accuracy: 62.03%\n",
      "Epoch [460/2500], Train Loss: 0.8233, Train Accuracy: 66.15%, Test Loss: 0.9475, Test Accuracy: 62.03%\n",
      "Epoch [461/2500], Train Loss: 0.7850, Train Accuracy: 65.72%, Test Loss: 0.9282, Test Accuracy: 62.03%\n",
      "Epoch [462/2500], Train Loss: 0.8003, Train Accuracy: 64.72%, Test Loss: 0.9263, Test Accuracy: 62.03%\n",
      "Epoch [463/2500], Train Loss: 0.8027, Train Accuracy: 64.15%, Test Loss: 0.9191, Test Accuracy: 64.56%\n",
      "Epoch [464/2500], Train Loss: 0.8087, Train Accuracy: 63.73%, Test Loss: 0.9189, Test Accuracy: 63.29%\n",
      "Epoch [465/2500], Train Loss: 0.8041, Train Accuracy: 64.30%, Test Loss: 0.9213, Test Accuracy: 62.03%\n",
      "Epoch [466/2500], Train Loss: 0.7966, Train Accuracy: 65.29%, Test Loss: 0.9194, Test Accuracy: 63.29%\n",
      "Epoch [467/2500], Train Loss: 0.7872, Train Accuracy: 64.58%, Test Loss: 0.9436, Test Accuracy: 62.03%\n",
      "Epoch [468/2500], Train Loss: 0.7772, Train Accuracy: 66.15%, Test Loss: 0.9425, Test Accuracy: 62.03%\n",
      "Epoch [469/2500], Train Loss: 0.8040, Train Accuracy: 66.29%, Test Loss: 0.9384, Test Accuracy: 63.29%\n",
      "Epoch [470/2500], Train Loss: 0.7960, Train Accuracy: 64.15%, Test Loss: 0.9134, Test Accuracy: 60.76%\n",
      "Epoch [471/2500], Train Loss: 0.8170, Train Accuracy: 64.01%, Test Loss: 0.9168, Test Accuracy: 63.29%\n",
      "Epoch [472/2500], Train Loss: 0.7981, Train Accuracy: 63.44%, Test Loss: 0.9345, Test Accuracy: 63.29%\n",
      "Epoch [473/2500], Train Loss: 0.8129, Train Accuracy: 64.58%, Test Loss: 0.9322, Test Accuracy: 63.29%\n",
      "Epoch [474/2500], Train Loss: 0.7998, Train Accuracy: 66.15%, Test Loss: 0.9271, Test Accuracy: 63.29%\n",
      "Epoch [475/2500], Train Loss: 0.8131, Train Accuracy: 66.43%, Test Loss: 0.9112, Test Accuracy: 64.56%\n",
      "Epoch [476/2500], Train Loss: 0.8281, Train Accuracy: 63.02%, Test Loss: 0.9167, Test Accuracy: 64.56%\n",
      "Epoch [477/2500], Train Loss: 0.8026, Train Accuracy: 64.30%, Test Loss: 0.9179, Test Accuracy: 62.03%\n",
      "Epoch [478/2500], Train Loss: 0.8014, Train Accuracy: 66.00%, Test Loss: 0.9198, Test Accuracy: 63.29%\n",
      "Epoch [479/2500], Train Loss: 0.8186, Train Accuracy: 66.15%, Test Loss: 0.9098, Test Accuracy: 65.82%\n",
      "Epoch [480/2500], Train Loss: 0.7892, Train Accuracy: 64.86%, Test Loss: 0.9146, Test Accuracy: 64.56%\n",
      "Epoch [481/2500], Train Loss: 0.7729, Train Accuracy: 66.29%, Test Loss: 0.9198, Test Accuracy: 62.03%\n",
      "Epoch [482/2500], Train Loss: 0.8032, Train Accuracy: 65.43%, Test Loss: 0.9035, Test Accuracy: 64.56%\n",
      "Epoch [483/2500], Train Loss: 0.8059, Train Accuracy: 65.29%, Test Loss: 0.9069, Test Accuracy: 63.29%\n",
      "Epoch [484/2500], Train Loss: 0.7891, Train Accuracy: 64.01%, Test Loss: 0.9233, Test Accuracy: 62.03%\n",
      "Epoch [485/2500], Train Loss: 0.7992, Train Accuracy: 64.30%, Test Loss: 0.9457, Test Accuracy: 65.82%\n",
      "Epoch [486/2500], Train Loss: 0.7901, Train Accuracy: 66.15%, Test Loss: 0.9139, Test Accuracy: 62.03%\n",
      "Epoch [487/2500], Train Loss: 0.8123, Train Accuracy: 65.15%, Test Loss: 0.9194, Test Accuracy: 63.29%\n",
      "Epoch [488/2500], Train Loss: 0.7875, Train Accuracy: 66.29%, Test Loss: 0.9140, Test Accuracy: 63.29%\n",
      "Epoch [489/2500], Train Loss: 0.8257, Train Accuracy: 62.73%, Test Loss: 0.9163, Test Accuracy: 63.29%\n",
      "Epoch [490/2500], Train Loss: 0.7868, Train Accuracy: 67.00%, Test Loss: 0.9245, Test Accuracy: 62.03%\n",
      "Epoch [491/2500], Train Loss: 0.8007, Train Accuracy: 65.15%, Test Loss: 0.9258, Test Accuracy: 64.56%\n",
      "Epoch [492/2500], Train Loss: 0.7986, Train Accuracy: 66.29%, Test Loss: 0.9331, Test Accuracy: 60.76%\n",
      "Epoch [493/2500], Train Loss: 0.8134, Train Accuracy: 64.30%, Test Loss: 0.9090, Test Accuracy: 65.82%\n",
      "Epoch [494/2500], Train Loss: 0.7753, Train Accuracy: 65.43%, Test Loss: 0.9331, Test Accuracy: 64.56%\n",
      "Epoch [495/2500], Train Loss: 0.7791, Train Accuracy: 67.00%, Test Loss: 0.9293, Test Accuracy: 63.29%\n",
      "Epoch [496/2500], Train Loss: 0.7961, Train Accuracy: 66.29%, Test Loss: 0.9118, Test Accuracy: 63.29%\n",
      "Epoch [497/2500], Train Loss: 0.7845, Train Accuracy: 64.01%, Test Loss: 0.9155, Test Accuracy: 63.29%\n",
      "Epoch [498/2500], Train Loss: 0.7974, Train Accuracy: 65.72%, Test Loss: 0.9257, Test Accuracy: 64.56%\n",
      "Epoch [499/2500], Train Loss: 0.7805, Train Accuracy: 66.00%, Test Loss: 0.9108, Test Accuracy: 63.29%\n",
      "Epoch [500/2500], Train Loss: 0.8239, Train Accuracy: 62.02%, Test Loss: 0.8935, Test Accuracy: 64.56%\n",
      "Epoch [501/2500], Train Loss: 0.8085, Train Accuracy: 63.44%, Test Loss: 0.9288, Test Accuracy: 63.29%\n",
      "Epoch [502/2500], Train Loss: 0.8099, Train Accuracy: 64.15%, Test Loss: 0.9279, Test Accuracy: 65.82%\n",
      "Epoch [503/2500], Train Loss: 0.8009, Train Accuracy: 65.43%, Test Loss: 0.9103, Test Accuracy: 64.56%\n",
      "Epoch [504/2500], Train Loss: 0.8037, Train Accuracy: 65.01%, Test Loss: 0.9297, Test Accuracy: 62.03%\n",
      "Epoch [505/2500], Train Loss: 0.8135, Train Accuracy: 64.30%, Test Loss: 0.9039, Test Accuracy: 63.29%\n",
      "Epoch [506/2500], Train Loss: 0.8251, Train Accuracy: 63.30%, Test Loss: 0.8810, Test Accuracy: 63.29%\n",
      "Epoch [507/2500], Train Loss: 0.8196, Train Accuracy: 65.29%, Test Loss: 0.9113, Test Accuracy: 63.29%\n",
      "Epoch [508/2500], Train Loss: 0.7774, Train Accuracy: 65.72%, Test Loss: 0.9295, Test Accuracy: 63.29%\n",
      "Epoch [509/2500], Train Loss: 0.8024, Train Accuracy: 64.15%, Test Loss: 0.9193, Test Accuracy: 62.03%\n",
      "Epoch [510/2500], Train Loss: 0.7821, Train Accuracy: 65.29%, Test Loss: 0.9178, Test Accuracy: 64.56%\n",
      "Epoch [511/2500], Train Loss: 0.7989, Train Accuracy: 64.30%, Test Loss: 0.9183, Test Accuracy: 64.56%\n",
      "Epoch [512/2500], Train Loss: 0.7684, Train Accuracy: 65.43%, Test Loss: 0.9291, Test Accuracy: 64.56%\n",
      "Epoch [513/2500], Train Loss: 0.7806, Train Accuracy: 64.86%, Test Loss: 0.8917, Test Accuracy: 67.09%\n",
      "Epoch [514/2500], Train Loss: 0.8109, Train Accuracy: 64.30%, Test Loss: 0.9068, Test Accuracy: 62.03%\n",
      "Epoch [515/2500], Train Loss: 0.8036, Train Accuracy: 65.72%, Test Loss: 0.8934, Test Accuracy: 65.82%\n",
      "Epoch [516/2500], Train Loss: 0.7825, Train Accuracy: 67.00%, Test Loss: 0.9297, Test Accuracy: 65.82%\n",
      "Epoch [517/2500], Train Loss: 0.7826, Train Accuracy: 65.15%, Test Loss: 0.9179, Test Accuracy: 65.82%\n",
      "Epoch [518/2500], Train Loss: 0.7870, Train Accuracy: 65.86%, Test Loss: 0.9246, Test Accuracy: 64.56%\n",
      "Epoch [519/2500], Train Loss: 0.8021, Train Accuracy: 65.72%, Test Loss: 0.9271, Test Accuracy: 64.56%\n",
      "Epoch [520/2500], Train Loss: 0.7734, Train Accuracy: 65.43%, Test Loss: 0.9315, Test Accuracy: 64.56%\n",
      "Epoch [521/2500], Train Loss: 0.7845, Train Accuracy: 66.57%, Test Loss: 0.9470, Test Accuracy: 63.29%\n",
      "Epoch [522/2500], Train Loss: 0.7880, Train Accuracy: 65.86%, Test Loss: 0.9219, Test Accuracy: 65.82%\n",
      "Epoch [523/2500], Train Loss: 0.7716, Train Accuracy: 65.58%, Test Loss: 0.9283, Test Accuracy: 65.82%\n",
      "Epoch [524/2500], Train Loss: 0.7913, Train Accuracy: 64.44%, Test Loss: 0.9078, Test Accuracy: 64.56%\n",
      "Epoch [525/2500], Train Loss: 0.7781, Train Accuracy: 64.30%, Test Loss: 0.9175, Test Accuracy: 65.82%\n",
      "Epoch [526/2500], Train Loss: 0.7768, Train Accuracy: 66.43%, Test Loss: 0.9148, Test Accuracy: 63.29%\n",
      "Epoch [527/2500], Train Loss: 0.7767, Train Accuracy: 66.57%, Test Loss: 0.9274, Test Accuracy: 64.56%\n",
      "Epoch [528/2500], Train Loss: 0.7776, Train Accuracy: 67.28%, Test Loss: 0.9180, Test Accuracy: 64.56%\n",
      "Epoch [529/2500], Train Loss: 0.7915, Train Accuracy: 65.29%, Test Loss: 0.8994, Test Accuracy: 65.82%\n",
      "Epoch [530/2500], Train Loss: 0.7937, Train Accuracy: 65.01%, Test Loss: 0.9214, Test Accuracy: 63.29%\n",
      "Epoch [531/2500], Train Loss: 0.8095, Train Accuracy: 64.72%, Test Loss: 0.9211, Test Accuracy: 63.29%\n",
      "Epoch [532/2500], Train Loss: 0.7938, Train Accuracy: 63.58%, Test Loss: 0.9138, Test Accuracy: 63.29%\n",
      "Epoch [533/2500], Train Loss: 0.7739, Train Accuracy: 65.72%, Test Loss: 0.9133, Test Accuracy: 63.29%\n",
      "Epoch [534/2500], Train Loss: 0.7854, Train Accuracy: 65.58%, Test Loss: 0.8743, Test Accuracy: 64.56%\n",
      "Epoch [535/2500], Train Loss: 0.7931, Train Accuracy: 66.15%, Test Loss: 0.8775, Test Accuracy: 64.56%\n",
      "Epoch [536/2500], Train Loss: 0.7635, Train Accuracy: 66.00%, Test Loss: 0.9125, Test Accuracy: 64.56%\n",
      "Epoch [537/2500], Train Loss: 0.7947, Train Accuracy: 66.43%, Test Loss: 0.9285, Test Accuracy: 62.03%\n",
      "Epoch [538/2500], Train Loss: 0.7693, Train Accuracy: 66.29%, Test Loss: 0.9109, Test Accuracy: 64.56%\n",
      "Epoch [539/2500], Train Loss: 0.7679, Train Accuracy: 64.58%, Test Loss: 0.8957, Test Accuracy: 64.56%\n",
      "Epoch [540/2500], Train Loss: 0.7785, Train Accuracy: 65.72%, Test Loss: 0.8982, Test Accuracy: 64.56%\n",
      "Epoch [541/2500], Train Loss: 0.7930, Train Accuracy: 66.86%, Test Loss: 0.9230, Test Accuracy: 63.29%\n",
      "Epoch [542/2500], Train Loss: 0.7898, Train Accuracy: 66.57%, Test Loss: 0.9188, Test Accuracy: 64.56%\n",
      "Epoch [543/2500], Train Loss: 0.7824, Train Accuracy: 67.00%, Test Loss: 0.9097, Test Accuracy: 64.56%\n",
      "Epoch [544/2500], Train Loss: 0.7731, Train Accuracy: 65.58%, Test Loss: 0.9066, Test Accuracy: 63.29%\n",
      "Epoch [545/2500], Train Loss: 0.7940, Train Accuracy: 64.58%, Test Loss: 0.8915, Test Accuracy: 64.56%\n",
      "Epoch [546/2500], Train Loss: 0.7755, Train Accuracy: 67.28%, Test Loss: 0.9045, Test Accuracy: 64.56%\n",
      "Epoch [547/2500], Train Loss: 0.7744, Train Accuracy: 66.43%, Test Loss: 0.9179, Test Accuracy: 63.29%\n",
      "Epoch [548/2500], Train Loss: 0.7884, Train Accuracy: 65.43%, Test Loss: 0.9065, Test Accuracy: 63.29%\n",
      "Epoch [549/2500], Train Loss: 0.7689, Train Accuracy: 64.44%, Test Loss: 0.9400, Test Accuracy: 63.29%\n",
      "Epoch [550/2500], Train Loss: 0.7619, Train Accuracy: 66.00%, Test Loss: 0.9071, Test Accuracy: 64.56%\n",
      "Epoch [551/2500], Train Loss: 0.7750, Train Accuracy: 65.01%, Test Loss: 0.9129, Test Accuracy: 63.29%\n",
      "Epoch [552/2500], Train Loss: 0.7648, Train Accuracy: 66.57%, Test Loss: 0.9344, Test Accuracy: 64.56%\n",
      "Epoch [553/2500], Train Loss: 0.7946, Train Accuracy: 66.71%, Test Loss: 0.9175, Test Accuracy: 64.56%\n",
      "Epoch [554/2500], Train Loss: 0.7716, Train Accuracy: 65.01%, Test Loss: 0.9264, Test Accuracy: 63.29%\n",
      "Epoch [555/2500], Train Loss: 0.7841, Train Accuracy: 64.86%, Test Loss: 0.8921, Test Accuracy: 64.56%\n",
      "Epoch [556/2500], Train Loss: 0.7741, Train Accuracy: 66.29%, Test Loss: 0.8987, Test Accuracy: 64.56%\n",
      "Epoch [557/2500], Train Loss: 0.7793, Train Accuracy: 64.86%, Test Loss: 0.9039, Test Accuracy: 64.56%\n",
      "Epoch [558/2500], Train Loss: 0.7566, Train Accuracy: 66.86%, Test Loss: 0.9240, Test Accuracy: 64.56%\n",
      "Epoch [559/2500], Train Loss: 0.7536, Train Accuracy: 66.86%, Test Loss: 0.9232, Test Accuracy: 65.82%\n",
      "Epoch [560/2500], Train Loss: 0.7384, Train Accuracy: 66.43%, Test Loss: 0.9577, Test Accuracy: 63.29%\n",
      "Epoch [561/2500], Train Loss: 0.7680, Train Accuracy: 66.86%, Test Loss: 0.9145, Test Accuracy: 65.82%\n",
      "Epoch [562/2500], Train Loss: 0.7707, Train Accuracy: 65.01%, Test Loss: 0.9171, Test Accuracy: 65.82%\n",
      "Epoch [563/2500], Train Loss: 0.7847, Train Accuracy: 64.58%, Test Loss: 0.9016, Test Accuracy: 65.82%\n",
      "Epoch [564/2500], Train Loss: 0.7736, Train Accuracy: 65.29%, Test Loss: 0.9058, Test Accuracy: 65.82%\n",
      "Epoch [565/2500], Train Loss: 0.8011, Train Accuracy: 68.42%, Test Loss: 0.9358, Test Accuracy: 65.82%\n",
      "Epoch [566/2500], Train Loss: 0.7826, Train Accuracy: 66.57%, Test Loss: 0.9241, Test Accuracy: 65.82%\n",
      "Epoch [567/2500], Train Loss: 0.7873, Train Accuracy: 64.15%, Test Loss: 0.9031, Test Accuracy: 64.56%\n",
      "Epoch [568/2500], Train Loss: 0.7702, Train Accuracy: 65.58%, Test Loss: 0.9413, Test Accuracy: 64.56%\n",
      "Epoch [569/2500], Train Loss: 0.7712, Train Accuracy: 65.29%, Test Loss: 0.9396, Test Accuracy: 63.29%\n",
      "Epoch [570/2500], Train Loss: 0.7860, Train Accuracy: 64.86%, Test Loss: 0.9171, Test Accuracy: 65.82%\n",
      "Epoch [571/2500], Train Loss: 0.7786, Train Accuracy: 65.58%, Test Loss: 0.9260, Test Accuracy: 63.29%\n",
      "Epoch [572/2500], Train Loss: 0.7807, Train Accuracy: 66.71%, Test Loss: 0.9105, Test Accuracy: 63.29%\n",
      "Epoch [573/2500], Train Loss: 0.7763, Train Accuracy: 65.72%, Test Loss: 0.9245, Test Accuracy: 64.56%\n",
      "Epoch [574/2500], Train Loss: 0.7709, Train Accuracy: 64.72%, Test Loss: 0.9081, Test Accuracy: 67.09%\n",
      "Epoch [575/2500], Train Loss: 0.7798, Train Accuracy: 65.01%, Test Loss: 0.9248, Test Accuracy: 62.03%\n",
      "Epoch [576/2500], Train Loss: 0.7764, Train Accuracy: 65.15%, Test Loss: 0.9150, Test Accuracy: 65.82%\n",
      "Epoch [577/2500], Train Loss: 0.7860, Train Accuracy: 66.86%, Test Loss: 0.9185, Test Accuracy: 65.82%\n",
      "Epoch [578/2500], Train Loss: 0.7865, Train Accuracy: 65.15%, Test Loss: 0.8989, Test Accuracy: 64.56%\n",
      "Epoch [579/2500], Train Loss: 0.7581, Train Accuracy: 66.15%, Test Loss: 0.9280, Test Accuracy: 64.56%\n",
      "Epoch [580/2500], Train Loss: 0.7525, Train Accuracy: 67.57%, Test Loss: 0.9272, Test Accuracy: 63.29%\n",
      "Epoch [581/2500], Train Loss: 0.7622, Train Accuracy: 66.57%, Test Loss: 0.9364, Test Accuracy: 60.76%\n",
      "Epoch [582/2500], Train Loss: 0.7542, Train Accuracy: 67.71%, Test Loss: 0.9377, Test Accuracy: 65.82%\n",
      "Epoch [583/2500], Train Loss: 0.7856, Train Accuracy: 66.29%, Test Loss: 0.9220, Test Accuracy: 63.29%\n",
      "Epoch [584/2500], Train Loss: 0.7653, Train Accuracy: 66.86%, Test Loss: 0.9303, Test Accuracy: 63.29%\n",
      "Epoch [585/2500], Train Loss: 0.7970, Train Accuracy: 64.58%, Test Loss: 0.9187, Test Accuracy: 64.56%\n",
      "Epoch [586/2500], Train Loss: 0.7570, Train Accuracy: 65.72%, Test Loss: 0.9128, Test Accuracy: 64.56%\n",
      "Epoch [587/2500], Train Loss: 0.7609, Train Accuracy: 65.01%, Test Loss: 0.9169, Test Accuracy: 63.29%\n",
      "Epoch [588/2500], Train Loss: 0.7692, Train Accuracy: 65.72%, Test Loss: 0.9196, Test Accuracy: 64.56%\n",
      "Epoch [589/2500], Train Loss: 0.7804, Train Accuracy: 66.29%, Test Loss: 0.9219, Test Accuracy: 62.03%\n",
      "Epoch [590/2500], Train Loss: 0.7512, Train Accuracy: 67.85%, Test Loss: 0.9027, Test Accuracy: 63.29%\n",
      "Epoch [591/2500], Train Loss: 0.7373, Train Accuracy: 67.43%, Test Loss: 0.9065, Test Accuracy: 64.56%\n",
      "Epoch [592/2500], Train Loss: 0.7914, Train Accuracy: 68.14%, Test Loss: 0.9218, Test Accuracy: 65.82%\n",
      "Epoch [593/2500], Train Loss: 0.7490, Train Accuracy: 65.72%, Test Loss: 0.9525, Test Accuracy: 64.56%\n",
      "Epoch [594/2500], Train Loss: 0.7306, Train Accuracy: 67.99%, Test Loss: 0.9382, Test Accuracy: 65.82%\n",
      "Epoch [595/2500], Train Loss: 0.7611, Train Accuracy: 66.15%, Test Loss: 0.9457, Test Accuracy: 63.29%\n",
      "Epoch [596/2500], Train Loss: 0.7594, Train Accuracy: 65.72%, Test Loss: 0.9144, Test Accuracy: 65.82%\n",
      "Epoch [597/2500], Train Loss: 0.7440, Train Accuracy: 67.99%, Test Loss: 0.9462, Test Accuracy: 63.29%\n",
      "Epoch [598/2500], Train Loss: 0.7696, Train Accuracy: 66.15%, Test Loss: 0.9276, Test Accuracy: 64.56%\n",
      "Epoch [599/2500], Train Loss: 0.7615, Train Accuracy: 66.15%, Test Loss: 0.9238, Test Accuracy: 64.56%\n",
      "Epoch [600/2500], Train Loss: 0.7730, Train Accuracy: 64.30%, Test Loss: 0.9221, Test Accuracy: 64.56%\n",
      "Epoch [601/2500], Train Loss: 0.7718, Train Accuracy: 66.57%, Test Loss: 0.9069, Test Accuracy: 65.82%\n",
      "Epoch [602/2500], Train Loss: 0.7725, Train Accuracy: 66.57%, Test Loss: 0.9247, Test Accuracy: 64.56%\n",
      "Epoch [603/2500], Train Loss: 0.7672, Train Accuracy: 67.00%, Test Loss: 0.9364, Test Accuracy: 64.56%\n",
      "Epoch [604/2500], Train Loss: 0.7511, Train Accuracy: 67.00%, Test Loss: 0.9439, Test Accuracy: 64.56%\n",
      "Epoch [605/2500], Train Loss: 0.7474, Train Accuracy: 67.85%, Test Loss: 0.9668, Test Accuracy: 63.29%\n",
      "Epoch [606/2500], Train Loss: 0.7737, Train Accuracy: 67.57%, Test Loss: 0.9572, Test Accuracy: 65.82%\n",
      "Epoch [607/2500], Train Loss: 0.7608, Train Accuracy: 67.99%, Test Loss: 0.9661, Test Accuracy: 60.76%\n",
      "Epoch [608/2500], Train Loss: 0.7393, Train Accuracy: 68.28%, Test Loss: 0.9420, Test Accuracy: 64.56%\n",
      "Epoch [609/2500], Train Loss: 0.7641, Train Accuracy: 67.14%, Test Loss: 0.9212, Test Accuracy: 64.56%\n",
      "Epoch [610/2500], Train Loss: 0.7757, Train Accuracy: 64.58%, Test Loss: 0.9143, Test Accuracy: 64.56%\n",
      "Epoch [611/2500], Train Loss: 0.7525, Train Accuracy: 66.86%, Test Loss: 0.9217, Test Accuracy: 64.56%\n",
      "Epoch [612/2500], Train Loss: 0.7482, Train Accuracy: 67.28%, Test Loss: 0.9158, Test Accuracy: 64.56%\n",
      "Epoch [613/2500], Train Loss: 0.7751, Train Accuracy: 65.29%, Test Loss: 0.9131, Test Accuracy: 65.82%\n",
      "Epoch [614/2500], Train Loss: 0.7446, Train Accuracy: 67.57%, Test Loss: 0.9108, Test Accuracy: 68.35%\n",
      "Epoch [615/2500], Train Loss: 0.7728, Train Accuracy: 66.57%, Test Loss: 0.9164, Test Accuracy: 64.56%\n",
      "Epoch [616/2500], Train Loss: 0.7481, Train Accuracy: 66.15%, Test Loss: 0.9472, Test Accuracy: 63.29%\n",
      "Epoch [617/2500], Train Loss: 0.7443, Train Accuracy: 67.85%, Test Loss: 0.9278, Test Accuracy: 64.56%\n",
      "Epoch [618/2500], Train Loss: 0.7463, Train Accuracy: 68.42%, Test Loss: 0.9476, Test Accuracy: 64.56%\n",
      "Epoch [619/2500], Train Loss: 0.7828, Train Accuracy: 66.00%, Test Loss: 0.9149, Test Accuracy: 64.56%\n",
      "Epoch [620/2500], Train Loss: 0.7761, Train Accuracy: 67.00%, Test Loss: 0.9231, Test Accuracy: 64.56%\n",
      "Epoch [621/2500], Train Loss: 0.7410, Train Accuracy: 66.86%, Test Loss: 0.9605, Test Accuracy: 65.82%\n",
      "Epoch [622/2500], Train Loss: 0.7420, Train Accuracy: 65.58%, Test Loss: 0.9387, Test Accuracy: 63.29%\n",
      "Epoch [623/2500], Train Loss: 0.7242, Train Accuracy: 68.71%, Test Loss: 0.9553, Test Accuracy: 64.56%\n",
      "Epoch [624/2500], Train Loss: 0.7598, Train Accuracy: 67.57%, Test Loss: 0.9633, Test Accuracy: 64.56%\n",
      "Epoch [625/2500], Train Loss: 0.7555, Train Accuracy: 67.28%, Test Loss: 0.9608, Test Accuracy: 64.56%\n",
      "Epoch [626/2500], Train Loss: 0.7495, Train Accuracy: 67.28%, Test Loss: 0.9247, Test Accuracy: 65.82%\n",
      "Epoch [627/2500], Train Loss: 0.7536, Train Accuracy: 66.71%, Test Loss: 0.9307, Test Accuracy: 64.56%\n",
      "Epoch [628/2500], Train Loss: 0.7696, Train Accuracy: 66.43%, Test Loss: 0.9242, Test Accuracy: 64.56%\n",
      "Epoch [629/2500], Train Loss: 0.7705, Train Accuracy: 66.15%, Test Loss: 0.9085, Test Accuracy: 65.82%\n",
      "Epoch [630/2500], Train Loss: 0.7549, Train Accuracy: 67.14%, Test Loss: 0.9023, Test Accuracy: 65.82%\n",
      "Epoch [631/2500], Train Loss: 0.7714, Train Accuracy: 64.86%, Test Loss: 0.9232, Test Accuracy: 65.82%\n",
      "Epoch [632/2500], Train Loss: 0.7866, Train Accuracy: 67.85%, Test Loss: 0.9383, Test Accuracy: 63.29%\n",
      "Epoch [633/2500], Train Loss: 0.7398, Train Accuracy: 66.29%, Test Loss: 0.9608, Test Accuracy: 63.29%\n",
      "Epoch [634/2500], Train Loss: 0.7309, Train Accuracy: 66.29%, Test Loss: 0.9567, Test Accuracy: 64.56%\n",
      "Epoch [635/2500], Train Loss: 0.7621, Train Accuracy: 66.29%, Test Loss: 0.9217, Test Accuracy: 64.56%\n",
      "Epoch [636/2500], Train Loss: 0.7415, Train Accuracy: 66.71%, Test Loss: 0.9353, Test Accuracy: 65.82%\n",
      "Epoch [637/2500], Train Loss: 0.7420, Train Accuracy: 66.71%, Test Loss: 0.9153, Test Accuracy: 64.56%\n",
      "Epoch [638/2500], Train Loss: 0.7400, Train Accuracy: 68.56%, Test Loss: 0.9175, Test Accuracy: 65.82%\n",
      "Epoch [639/2500], Train Loss: 0.7503, Train Accuracy: 67.14%, Test Loss: 0.9287, Test Accuracy: 65.82%\n",
      "Epoch [640/2500], Train Loss: 0.7660, Train Accuracy: 65.29%, Test Loss: 0.9245, Test Accuracy: 64.56%\n",
      "Epoch [641/2500], Train Loss: 0.7526, Train Accuracy: 63.58%, Test Loss: 0.9243, Test Accuracy: 67.09%\n",
      "Epoch [642/2500], Train Loss: 0.7629, Train Accuracy: 65.29%, Test Loss: 0.9377, Test Accuracy: 65.82%\n",
      "Epoch [643/2500], Train Loss: 0.7479, Train Accuracy: 66.29%, Test Loss: 0.9273, Test Accuracy: 67.09%\n",
      "Epoch [644/2500], Train Loss: 0.7528, Train Accuracy: 66.71%, Test Loss: 0.9482, Test Accuracy: 64.56%\n",
      "Epoch [645/2500], Train Loss: 0.7562, Train Accuracy: 67.71%, Test Loss: 0.9328, Test Accuracy: 63.29%\n",
      "Epoch [646/2500], Train Loss: 0.7255, Train Accuracy: 69.99%, Test Loss: 0.9342, Test Accuracy: 62.03%\n",
      "Epoch [647/2500], Train Loss: 0.7610, Train Accuracy: 67.43%, Test Loss: 0.9318, Test Accuracy: 64.56%\n",
      "Epoch [648/2500], Train Loss: 0.7508, Train Accuracy: 67.43%, Test Loss: 0.9191, Test Accuracy: 64.56%\n",
      "Epoch [649/2500], Train Loss: 0.7450, Train Accuracy: 65.29%, Test Loss: 0.9606, Test Accuracy: 65.82%\n",
      "Epoch [650/2500], Train Loss: 0.7671, Train Accuracy: 67.28%, Test Loss: 0.8969, Test Accuracy: 64.56%\n",
      "Epoch [651/2500], Train Loss: 0.7526, Train Accuracy: 66.00%, Test Loss: 0.9216, Test Accuracy: 64.56%\n",
      "Epoch [652/2500], Train Loss: 0.7436, Train Accuracy: 68.56%, Test Loss: 0.9097, Test Accuracy: 64.56%\n",
      "Epoch [653/2500], Train Loss: 0.7447, Train Accuracy: 67.85%, Test Loss: 0.9292, Test Accuracy: 64.56%\n",
      "Epoch [654/2500], Train Loss: 0.7534, Train Accuracy: 69.27%, Test Loss: 0.9411, Test Accuracy: 65.82%\n",
      "Epoch [655/2500], Train Loss: 0.7461, Train Accuracy: 66.29%, Test Loss: 0.8934, Test Accuracy: 63.29%\n",
      "Epoch [656/2500], Train Loss: 0.7654, Train Accuracy: 64.86%, Test Loss: 0.9403, Test Accuracy: 65.82%\n",
      "Epoch [657/2500], Train Loss: 0.7610, Train Accuracy: 65.29%, Test Loss: 0.9179, Test Accuracy: 65.82%\n",
      "Epoch [658/2500], Train Loss: 0.7390, Train Accuracy: 67.71%, Test Loss: 0.9028, Test Accuracy: 65.82%\n",
      "Epoch [659/2500], Train Loss: 0.7747, Train Accuracy: 66.29%, Test Loss: 0.9358, Test Accuracy: 64.56%\n",
      "Epoch [660/2500], Train Loss: 0.7625, Train Accuracy: 67.28%, Test Loss: 0.8946, Test Accuracy: 64.56%\n",
      "Epoch [661/2500], Train Loss: 0.7611, Train Accuracy: 68.28%, Test Loss: 0.9085, Test Accuracy: 65.82%\n",
      "Epoch [662/2500], Train Loss: 0.7625, Train Accuracy: 67.14%, Test Loss: 0.9300, Test Accuracy: 64.56%\n",
      "Epoch [663/2500], Train Loss: 0.7422, Train Accuracy: 68.42%, Test Loss: 0.9009, Test Accuracy: 64.56%\n",
      "Epoch [664/2500], Train Loss: 0.7366, Train Accuracy: 66.57%, Test Loss: 0.9412, Test Accuracy: 64.56%\n",
      "Epoch [665/2500], Train Loss: 0.7562, Train Accuracy: 65.86%, Test Loss: 0.9178, Test Accuracy: 63.29%\n",
      "Epoch [666/2500], Train Loss: 0.7201, Train Accuracy: 69.42%, Test Loss: 0.9272, Test Accuracy: 63.29%\n",
      "Epoch [667/2500], Train Loss: 0.7442, Train Accuracy: 68.28%, Test Loss: 0.9615, Test Accuracy: 62.03%\n",
      "Epoch [668/2500], Train Loss: 0.7744, Train Accuracy: 65.15%, Test Loss: 0.8854, Test Accuracy: 64.56%\n",
      "Epoch [669/2500], Train Loss: 0.7689, Train Accuracy: 67.00%, Test Loss: 0.8941, Test Accuracy: 65.82%\n",
      "Epoch [670/2500], Train Loss: 0.7244, Train Accuracy: 68.85%, Test Loss: 0.9120, Test Accuracy: 64.56%\n",
      "Epoch [671/2500], Train Loss: 0.7507, Train Accuracy: 66.57%, Test Loss: 0.9265, Test Accuracy: 64.56%\n",
      "Epoch [672/2500], Train Loss: 0.7485, Train Accuracy: 66.86%, Test Loss: 0.8996, Test Accuracy: 64.56%\n",
      "Epoch [673/2500], Train Loss: 0.7474, Train Accuracy: 67.71%, Test Loss: 0.8809, Test Accuracy: 64.56%\n",
      "Epoch [674/2500], Train Loss: 0.7355, Train Accuracy: 68.42%, Test Loss: 0.9284, Test Accuracy: 62.03%\n",
      "Epoch [675/2500], Train Loss: 0.7461, Train Accuracy: 67.14%, Test Loss: 0.9515, Test Accuracy: 63.29%\n",
      "Epoch [676/2500], Train Loss: 0.7549, Train Accuracy: 66.29%, Test Loss: 0.9097, Test Accuracy: 64.56%\n",
      "Epoch [677/2500], Train Loss: 0.7394, Train Accuracy: 67.71%, Test Loss: 0.9258, Test Accuracy: 65.82%\n",
      "Epoch [678/2500], Train Loss: 0.7415, Train Accuracy: 66.43%, Test Loss: 0.9270, Test Accuracy: 65.82%\n",
      "Epoch [679/2500], Train Loss: 0.7473, Train Accuracy: 65.15%, Test Loss: 0.9026, Test Accuracy: 65.82%\n",
      "Epoch [680/2500], Train Loss: 0.7287, Train Accuracy: 68.42%, Test Loss: 0.9312, Test Accuracy: 64.56%\n",
      "Epoch [681/2500], Train Loss: 0.7440, Train Accuracy: 67.99%, Test Loss: 0.9276, Test Accuracy: 62.03%\n",
      "Epoch [682/2500], Train Loss: 0.7557, Train Accuracy: 63.73%, Test Loss: 0.9199, Test Accuracy: 65.82%\n",
      "Epoch [683/2500], Train Loss: 0.7494, Train Accuracy: 68.14%, Test Loss: 0.9283, Test Accuracy: 62.03%\n",
      "Epoch [684/2500], Train Loss: 0.7518, Train Accuracy: 67.28%, Test Loss: 0.9021, Test Accuracy: 65.82%\n",
      "Epoch [685/2500], Train Loss: 0.7388, Train Accuracy: 66.29%, Test Loss: 0.9024, Test Accuracy: 64.56%\n",
      "Epoch [686/2500], Train Loss: 0.7298, Train Accuracy: 68.85%, Test Loss: 0.9350, Test Accuracy: 62.03%\n",
      "Epoch [687/2500], Train Loss: 0.7211, Train Accuracy: 67.71%, Test Loss: 0.9381, Test Accuracy: 63.29%\n",
      "Epoch [688/2500], Train Loss: 0.7642, Train Accuracy: 64.44%, Test Loss: 0.9414, Test Accuracy: 63.29%\n",
      "Epoch [689/2500], Train Loss: 0.7632, Train Accuracy: 67.00%, Test Loss: 0.8976, Test Accuracy: 64.56%\n",
      "Epoch [690/2500], Train Loss: 0.7503, Train Accuracy: 66.29%, Test Loss: 0.9439, Test Accuracy: 60.76%\n",
      "Epoch [691/2500], Train Loss: 0.7447, Train Accuracy: 66.86%, Test Loss: 0.9256, Test Accuracy: 64.56%\n",
      "Epoch [692/2500], Train Loss: 0.7466, Train Accuracy: 67.28%, Test Loss: 0.9053, Test Accuracy: 63.29%\n",
      "Epoch [693/2500], Train Loss: 0.7285, Train Accuracy: 68.42%, Test Loss: 0.9439, Test Accuracy: 62.03%\n",
      "Epoch [694/2500], Train Loss: 0.7516, Train Accuracy: 66.86%, Test Loss: 0.9285, Test Accuracy: 64.56%\n",
      "Epoch [695/2500], Train Loss: 0.7386, Train Accuracy: 68.28%, Test Loss: 0.9251, Test Accuracy: 65.82%\n",
      "Epoch [696/2500], Train Loss: 0.7344, Train Accuracy: 68.14%, Test Loss: 0.9129, Test Accuracy: 67.09%\n",
      "Epoch [697/2500], Train Loss: 0.7490, Train Accuracy: 66.00%, Test Loss: 0.9406, Test Accuracy: 63.29%\n",
      "Epoch [698/2500], Train Loss: 0.7183, Train Accuracy: 68.99%, Test Loss: 0.9563, Test Accuracy: 65.82%\n",
      "Epoch [699/2500], Train Loss: 0.7488, Train Accuracy: 67.57%, Test Loss: 0.9187, Test Accuracy: 63.29%\n",
      "Epoch [700/2500], Train Loss: 0.7498, Train Accuracy: 68.56%, Test Loss: 0.9215, Test Accuracy: 64.56%\n",
      "Epoch [701/2500], Train Loss: 0.7384, Train Accuracy: 65.72%, Test Loss: 0.9439, Test Accuracy: 65.82%\n",
      "Epoch [702/2500], Train Loss: 0.7447, Train Accuracy: 68.85%, Test Loss: 0.9176, Test Accuracy: 64.56%\n",
      "Epoch [703/2500], Train Loss: 0.7263, Train Accuracy: 68.14%, Test Loss: 0.9361, Test Accuracy: 65.82%\n",
      "Epoch [704/2500], Train Loss: 0.7371, Train Accuracy: 68.42%, Test Loss: 0.9213, Test Accuracy: 65.82%\n",
      "Epoch [705/2500], Train Loss: 0.7527, Train Accuracy: 65.72%, Test Loss: 0.9247, Test Accuracy: 65.82%\n",
      "Epoch [706/2500], Train Loss: 0.7513, Train Accuracy: 67.99%, Test Loss: 0.9365, Test Accuracy: 63.29%\n",
      "Epoch [707/2500], Train Loss: 0.7297, Train Accuracy: 68.14%, Test Loss: 0.9156, Test Accuracy: 65.82%\n",
      "Epoch [708/2500], Train Loss: 0.7473, Train Accuracy: 67.14%, Test Loss: 0.9274, Test Accuracy: 65.82%\n",
      "Epoch [709/2500], Train Loss: 0.7395, Train Accuracy: 66.29%, Test Loss: 0.9129, Test Accuracy: 65.82%\n",
      "Epoch [710/2500], Train Loss: 0.7258, Train Accuracy: 67.57%, Test Loss: 0.9061, Test Accuracy: 64.56%\n",
      "Epoch [711/2500], Train Loss: 0.7635, Train Accuracy: 66.15%, Test Loss: 0.9336, Test Accuracy: 63.29%\n",
      "Epoch [712/2500], Train Loss: 0.7367, Train Accuracy: 66.57%, Test Loss: 0.9092, Test Accuracy: 63.29%\n",
      "Epoch [713/2500], Train Loss: 0.7440, Train Accuracy: 68.56%, Test Loss: 0.8912, Test Accuracy: 65.82%\n",
      "Epoch [714/2500], Train Loss: 0.7500, Train Accuracy: 69.42%, Test Loss: 0.9343, Test Accuracy: 65.82%\n",
      "Epoch [715/2500], Train Loss: 0.7290, Train Accuracy: 68.28%, Test Loss: 0.9375, Test Accuracy: 67.09%\n",
      "Epoch [716/2500], Train Loss: 0.7461, Train Accuracy: 64.72%, Test Loss: 0.9244, Test Accuracy: 67.09%\n",
      "Epoch [717/2500], Train Loss: 0.7312, Train Accuracy: 68.99%, Test Loss: 0.8979, Test Accuracy: 67.09%\n",
      "Epoch [718/2500], Train Loss: 0.7405, Train Accuracy: 67.99%, Test Loss: 0.9284, Test Accuracy: 67.09%\n",
      "Epoch [719/2500], Train Loss: 0.7350, Train Accuracy: 67.99%, Test Loss: 0.9172, Test Accuracy: 65.82%\n",
      "Epoch [720/2500], Train Loss: 0.7546, Train Accuracy: 66.00%, Test Loss: 0.9112, Test Accuracy: 67.09%\n",
      "Epoch [721/2500], Train Loss: 0.7652, Train Accuracy: 64.72%, Test Loss: 0.9006, Test Accuracy: 65.82%\n",
      "Epoch [722/2500], Train Loss: 0.7614, Train Accuracy: 67.85%, Test Loss: 0.8853, Test Accuracy: 65.82%\n",
      "Epoch [723/2500], Train Loss: 0.7254, Train Accuracy: 66.86%, Test Loss: 0.9118, Test Accuracy: 69.62%\n",
      "Epoch [724/2500], Train Loss: 0.7306, Train Accuracy: 68.42%, Test Loss: 0.9102, Test Accuracy: 64.56%\n",
      "Epoch [725/2500], Train Loss: 0.7391, Train Accuracy: 68.28%, Test Loss: 0.9312, Test Accuracy: 67.09%\n",
      "Epoch [726/2500], Train Loss: 0.7162, Train Accuracy: 67.71%, Test Loss: 0.9039, Test Accuracy: 69.62%\n",
      "Epoch [727/2500], Train Loss: 0.7174, Train Accuracy: 68.28%, Test Loss: 0.9252, Test Accuracy: 63.29%\n",
      "Epoch [728/2500], Train Loss: 0.7212, Train Accuracy: 68.99%, Test Loss: 0.9135, Test Accuracy: 65.82%\n",
      "Epoch [729/2500], Train Loss: 0.7292, Train Accuracy: 69.70%, Test Loss: 0.9202, Test Accuracy: 65.82%\n",
      "Epoch [730/2500], Train Loss: 0.7521, Train Accuracy: 68.14%, Test Loss: 0.9055, Test Accuracy: 67.09%\n",
      "Epoch [731/2500], Train Loss: 0.7346, Train Accuracy: 68.28%, Test Loss: 0.9408, Test Accuracy: 63.29%\n",
      "Epoch [732/2500], Train Loss: 0.7440, Train Accuracy: 66.43%, Test Loss: 0.9013, Test Accuracy: 68.35%\n",
      "Epoch [733/2500], Train Loss: 0.7485, Train Accuracy: 67.43%, Test Loss: 0.9172, Test Accuracy: 69.62%\n",
      "Epoch [734/2500], Train Loss: 0.7476, Train Accuracy: 66.86%, Test Loss: 0.9246, Test Accuracy: 67.09%\n",
      "Epoch [735/2500], Train Loss: 0.7172, Train Accuracy: 67.14%, Test Loss: 0.9322, Test Accuracy: 67.09%\n",
      "Epoch [736/2500], Train Loss: 0.7288, Train Accuracy: 69.13%, Test Loss: 0.9314, Test Accuracy: 64.56%\n",
      "Epoch [737/2500], Train Loss: 0.7301, Train Accuracy: 68.71%, Test Loss: 0.9379, Test Accuracy: 67.09%\n",
      "Epoch [738/2500], Train Loss: 0.7085, Train Accuracy: 67.99%, Test Loss: 0.9320, Test Accuracy: 67.09%\n",
      "Epoch [739/2500], Train Loss: 0.7289, Train Accuracy: 67.57%, Test Loss: 0.9422, Test Accuracy: 67.09%\n",
      "Epoch [740/2500], Train Loss: 0.7260, Train Accuracy: 67.14%, Test Loss: 0.9047, Test Accuracy: 69.62%\n",
      "Epoch [741/2500], Train Loss: 0.7448, Train Accuracy: 66.57%, Test Loss: 0.9402, Test Accuracy: 67.09%\n",
      "Epoch [742/2500], Train Loss: 0.7210, Train Accuracy: 68.14%, Test Loss: 0.9098, Test Accuracy: 67.09%\n",
      "Epoch [743/2500], Train Loss: 0.7442, Train Accuracy: 65.43%, Test Loss: 0.9375, Test Accuracy: 68.35%\n",
      "Epoch [744/2500], Train Loss: 0.7420, Train Accuracy: 67.71%, Test Loss: 0.8881, Test Accuracy: 67.09%\n",
      "Epoch [745/2500], Train Loss: 0.7451, Train Accuracy: 67.99%, Test Loss: 0.9004, Test Accuracy: 65.82%\n",
      "Epoch [746/2500], Train Loss: 0.7508, Train Accuracy: 66.71%, Test Loss: 0.9068, Test Accuracy: 64.56%\n",
      "Epoch [747/2500], Train Loss: 0.7669, Train Accuracy: 66.15%, Test Loss: 0.9039, Test Accuracy: 65.82%\n",
      "Epoch [748/2500], Train Loss: 0.7201, Train Accuracy: 69.13%, Test Loss: 0.9022, Test Accuracy: 65.82%\n",
      "Epoch [749/2500], Train Loss: 0.7152, Train Accuracy: 69.27%, Test Loss: 0.9134, Test Accuracy: 64.56%\n",
      "Epoch [750/2500], Train Loss: 0.7332, Train Accuracy: 68.99%, Test Loss: 0.9414, Test Accuracy: 65.82%\n",
      "Epoch [751/2500], Train Loss: 0.7206, Train Accuracy: 69.13%, Test Loss: 0.9352, Test Accuracy: 65.82%\n",
      "Epoch [752/2500], Train Loss: 0.7312, Train Accuracy: 66.15%, Test Loss: 0.9289, Test Accuracy: 65.82%\n",
      "Epoch [753/2500], Train Loss: 0.7375, Train Accuracy: 68.14%, Test Loss: 0.9299, Test Accuracy: 65.82%\n",
      "Epoch [754/2500], Train Loss: 0.7289, Train Accuracy: 69.99%, Test Loss: 0.9380, Test Accuracy: 64.56%\n",
      "Epoch [755/2500], Train Loss: 0.7362, Train Accuracy: 68.56%, Test Loss: 0.9349, Test Accuracy: 65.82%\n",
      "Epoch [756/2500], Train Loss: 0.7266, Train Accuracy: 68.14%, Test Loss: 0.9172, Test Accuracy: 67.09%\n",
      "Epoch [757/2500], Train Loss: 0.7358, Train Accuracy: 68.99%, Test Loss: 0.9235, Test Accuracy: 65.82%\n",
      "Epoch [758/2500], Train Loss: 0.7351, Train Accuracy: 67.28%, Test Loss: 0.9081, Test Accuracy: 65.82%\n",
      "Epoch [759/2500], Train Loss: 0.7468, Train Accuracy: 67.85%, Test Loss: 0.9142, Test Accuracy: 64.56%\n",
      "Epoch [760/2500], Train Loss: 0.7202, Train Accuracy: 69.42%, Test Loss: 0.9177, Test Accuracy: 68.35%\n",
      "Epoch [761/2500], Train Loss: 0.7281, Train Accuracy: 68.99%, Test Loss: 0.9091, Test Accuracy: 65.82%\n",
      "Epoch [762/2500], Train Loss: 0.7258, Train Accuracy: 68.56%, Test Loss: 0.9192, Test Accuracy: 67.09%\n",
      "Epoch [763/2500], Train Loss: 0.7052, Train Accuracy: 68.99%, Test Loss: 0.9218, Test Accuracy: 65.82%\n",
      "Epoch [764/2500], Train Loss: 0.7049, Train Accuracy: 67.99%, Test Loss: 0.9322, Test Accuracy: 65.82%\n",
      "Epoch [765/2500], Train Loss: 0.7367, Train Accuracy: 67.43%, Test Loss: 0.9299, Test Accuracy: 63.29%\n",
      "Epoch [766/2500], Train Loss: 0.7446, Train Accuracy: 68.71%, Test Loss: 0.9292, Test Accuracy: 63.29%\n",
      "Epoch [767/2500], Train Loss: 0.7281, Train Accuracy: 68.56%, Test Loss: 0.9241, Test Accuracy: 65.82%\n",
      "Epoch [768/2500], Train Loss: 0.7147, Train Accuracy: 68.71%, Test Loss: 0.9292, Test Accuracy: 65.82%\n",
      "Epoch [769/2500], Train Loss: 0.7350, Train Accuracy: 68.56%, Test Loss: 0.9228, Test Accuracy: 62.03%\n",
      "Epoch [770/2500], Train Loss: 0.7275, Train Accuracy: 67.57%, Test Loss: 0.9354, Test Accuracy: 65.82%\n",
      "Epoch [771/2500], Train Loss: 0.7097, Train Accuracy: 68.42%, Test Loss: 0.9652, Test Accuracy: 62.03%\n",
      "Epoch [772/2500], Train Loss: 0.7181, Train Accuracy: 68.85%, Test Loss: 0.9165, Test Accuracy: 67.09%\n",
      "Epoch [773/2500], Train Loss: 0.7124, Train Accuracy: 68.99%, Test Loss: 0.9112, Test Accuracy: 68.35%\n",
      "Epoch [774/2500], Train Loss: 0.7125, Train Accuracy: 70.55%, Test Loss: 0.9498, Test Accuracy: 64.56%\n",
      "Epoch [775/2500], Train Loss: 0.7293, Train Accuracy: 67.99%, Test Loss: 0.9175, Test Accuracy: 64.56%\n",
      "Epoch [776/2500], Train Loss: 0.7444, Train Accuracy: 67.99%, Test Loss: 0.9496, Test Accuracy: 62.03%\n",
      "Epoch [777/2500], Train Loss: 0.7135, Train Accuracy: 68.28%, Test Loss: 0.9255, Test Accuracy: 64.56%\n",
      "Epoch [778/2500], Train Loss: 0.7363, Train Accuracy: 68.14%, Test Loss: 0.9170, Test Accuracy: 64.56%\n",
      "Epoch [779/2500], Train Loss: 0.7463, Train Accuracy: 67.28%, Test Loss: 0.9059, Test Accuracy: 65.82%\n",
      "Epoch [780/2500], Train Loss: 0.7472, Train Accuracy: 67.14%, Test Loss: 0.9254, Test Accuracy: 65.82%\n",
      "Epoch [781/2500], Train Loss: 0.7570, Train Accuracy: 67.99%, Test Loss: 0.9023, Test Accuracy: 64.56%\n",
      "Epoch [782/2500], Train Loss: 0.7102, Train Accuracy: 68.28%, Test Loss: 0.9352, Test Accuracy: 67.09%\n",
      "Epoch [783/2500], Train Loss: 0.7027, Train Accuracy: 69.99%, Test Loss: 0.9108, Test Accuracy: 69.62%\n",
      "Epoch [784/2500], Train Loss: 0.6996, Train Accuracy: 69.27%, Test Loss: 0.9484, Test Accuracy: 64.56%\n",
      "Epoch [785/2500], Train Loss: 0.6982, Train Accuracy: 71.12%, Test Loss: 0.9228, Test Accuracy: 67.09%\n",
      "Epoch [786/2500], Train Loss: 0.7401, Train Accuracy: 66.00%, Test Loss: 0.9494, Test Accuracy: 64.56%\n",
      "Epoch [787/2500], Train Loss: 0.7553, Train Accuracy: 66.57%, Test Loss: 0.9458, Test Accuracy: 62.03%\n",
      "Epoch [788/2500], Train Loss: 0.7232, Train Accuracy: 66.86%, Test Loss: 0.9359, Test Accuracy: 63.29%\n",
      "Epoch [789/2500], Train Loss: 0.7096, Train Accuracy: 68.85%, Test Loss: 0.9530, Test Accuracy: 64.56%\n",
      "Epoch [790/2500], Train Loss: 0.7106, Train Accuracy: 69.13%, Test Loss: 0.9684, Test Accuracy: 67.09%\n",
      "Epoch [791/2500], Train Loss: 0.7166, Train Accuracy: 69.84%, Test Loss: 0.9457, Test Accuracy: 65.82%\n",
      "Epoch [792/2500], Train Loss: 0.6989, Train Accuracy: 68.28%, Test Loss: 0.9877, Test Accuracy: 64.56%\n",
      "Epoch [793/2500], Train Loss: 0.7177, Train Accuracy: 69.27%, Test Loss: 0.9363, Test Accuracy: 64.56%\n",
      "Epoch [794/2500], Train Loss: 0.7121, Train Accuracy: 67.00%, Test Loss: 0.9548, Test Accuracy: 64.56%\n",
      "Epoch [795/2500], Train Loss: 0.7250, Train Accuracy: 68.85%, Test Loss: 0.9562, Test Accuracy: 63.29%\n",
      "Epoch [796/2500], Train Loss: 0.7295, Train Accuracy: 69.70%, Test Loss: 0.9635, Test Accuracy: 64.56%\n",
      "Epoch [797/2500], Train Loss: 0.7320, Train Accuracy: 67.57%, Test Loss: 0.9449, Test Accuracy: 65.82%\n",
      "Epoch [798/2500], Train Loss: 0.7257, Train Accuracy: 70.98%, Test Loss: 0.9322, Test Accuracy: 64.56%\n",
      "Epoch [799/2500], Train Loss: 0.7307, Train Accuracy: 66.86%, Test Loss: 0.9005, Test Accuracy: 65.82%\n",
      "Epoch [800/2500], Train Loss: 0.7238, Train Accuracy: 69.70%, Test Loss: 0.9581, Test Accuracy: 67.09%\n",
      "Epoch [801/2500], Train Loss: 0.7468, Train Accuracy: 66.86%, Test Loss: 0.9556, Test Accuracy: 64.56%\n",
      "Epoch [802/2500], Train Loss: 0.7032, Train Accuracy: 68.71%, Test Loss: 0.9450, Test Accuracy: 65.82%\n",
      "Epoch [803/2500], Train Loss: 0.7338, Train Accuracy: 66.86%, Test Loss: 0.9258, Test Accuracy: 67.09%\n",
      "Epoch [804/2500], Train Loss: 0.7289, Train Accuracy: 67.57%, Test Loss: 0.9206, Test Accuracy: 65.82%\n",
      "Epoch [805/2500], Train Loss: 0.7416, Train Accuracy: 67.71%, Test Loss: 0.9178, Test Accuracy: 65.82%\n",
      "Epoch [806/2500], Train Loss: 0.7054, Train Accuracy: 69.56%, Test Loss: 0.9365, Test Accuracy: 63.29%\n",
      "Epoch [807/2500], Train Loss: 0.6943, Train Accuracy: 69.13%, Test Loss: 0.9620, Test Accuracy: 67.09%\n",
      "Epoch [808/2500], Train Loss: 0.7080, Train Accuracy: 70.13%, Test Loss: 0.9414, Test Accuracy: 65.82%\n",
      "Epoch [809/2500], Train Loss: 0.7397, Train Accuracy: 68.85%, Test Loss: 0.9674, Test Accuracy: 65.82%\n",
      "Epoch [810/2500], Train Loss: 0.7210, Train Accuracy: 68.56%, Test Loss: 0.9335, Test Accuracy: 68.35%\n",
      "Epoch [811/2500], Train Loss: 0.7263, Train Accuracy: 68.99%, Test Loss: 0.9146, Test Accuracy: 65.82%\n",
      "Epoch [812/2500], Train Loss: 0.7200, Train Accuracy: 68.71%, Test Loss: 0.9182, Test Accuracy: 65.82%\n",
      "Epoch [813/2500], Train Loss: 0.7133, Train Accuracy: 69.13%, Test Loss: 0.9848, Test Accuracy: 64.56%\n",
      "Epoch [814/2500], Train Loss: 0.7064, Train Accuracy: 69.84%, Test Loss: 0.9483, Test Accuracy: 67.09%\n",
      "Epoch [815/2500], Train Loss: 0.7165, Train Accuracy: 69.27%, Test Loss: 0.9368, Test Accuracy: 65.82%\n",
      "Epoch [816/2500], Train Loss: 0.6915, Train Accuracy: 70.27%, Test Loss: 0.9608, Test Accuracy: 67.09%\n",
      "Epoch [817/2500], Train Loss: 0.6931, Train Accuracy: 69.56%, Test Loss: 0.9467, Test Accuracy: 67.09%\n",
      "Epoch [818/2500], Train Loss: 0.7316, Train Accuracy: 68.42%, Test Loss: 0.9191, Test Accuracy: 65.82%\n",
      "Epoch [819/2500], Train Loss: 0.7236, Train Accuracy: 68.71%, Test Loss: 0.9069, Test Accuracy: 68.35%\n",
      "Epoch [820/2500], Train Loss: 0.7084, Train Accuracy: 67.71%, Test Loss: 0.9474, Test Accuracy: 64.56%\n",
      "Epoch [821/2500], Train Loss: 0.7450, Train Accuracy: 68.28%, Test Loss: 0.9251, Test Accuracy: 65.82%\n",
      "Epoch [822/2500], Train Loss: 0.7260, Train Accuracy: 67.43%, Test Loss: 0.8991, Test Accuracy: 65.82%\n",
      "Epoch [823/2500], Train Loss: 0.7284, Train Accuracy: 68.85%, Test Loss: 0.9186, Test Accuracy: 64.56%\n",
      "Epoch [824/2500], Train Loss: 0.7189, Train Accuracy: 69.99%, Test Loss: 0.9302, Test Accuracy: 67.09%\n",
      "Epoch [825/2500], Train Loss: 0.6996, Train Accuracy: 68.71%, Test Loss: 0.9722, Test Accuracy: 68.35%\n",
      "Epoch [826/2500], Train Loss: 0.7111, Train Accuracy: 68.99%, Test Loss: 0.9579, Test Accuracy: 67.09%\n",
      "Epoch [827/2500], Train Loss: 0.7164, Train Accuracy: 67.85%, Test Loss: 0.9623, Test Accuracy: 63.29%\n",
      "Epoch [828/2500], Train Loss: 0.7209, Train Accuracy: 68.99%, Test Loss: 0.9703, Test Accuracy: 64.56%\n",
      "Epoch [829/2500], Train Loss: 0.6974, Train Accuracy: 68.71%, Test Loss: 0.9426, Test Accuracy: 64.56%\n",
      "Epoch [830/2500], Train Loss: 0.7220, Train Accuracy: 69.99%, Test Loss: 0.9539, Test Accuracy: 63.29%\n",
      "Epoch [831/2500], Train Loss: 0.7153, Train Accuracy: 69.56%, Test Loss: 0.9374, Test Accuracy: 65.82%\n",
      "Epoch [832/2500], Train Loss: 0.7174, Train Accuracy: 68.56%, Test Loss: 0.9241, Test Accuracy: 65.82%\n",
      "Epoch [833/2500], Train Loss: 0.7205, Train Accuracy: 68.14%, Test Loss: 0.9126, Test Accuracy: 67.09%\n",
      "Epoch [834/2500], Train Loss: 0.7203, Train Accuracy: 67.99%, Test Loss: 0.9409, Test Accuracy: 64.56%\n",
      "Epoch [835/2500], Train Loss: 0.7549, Train Accuracy: 67.43%, Test Loss: 0.9103, Test Accuracy: 68.35%\n",
      "Epoch [836/2500], Train Loss: 0.7042, Train Accuracy: 70.13%, Test Loss: 0.9295, Test Accuracy: 67.09%\n",
      "Epoch [837/2500], Train Loss: 0.7035, Train Accuracy: 71.12%, Test Loss: 0.9194, Test Accuracy: 70.89%\n",
      "Epoch [838/2500], Train Loss: 0.7084, Train Accuracy: 68.71%, Test Loss: 0.9428, Test Accuracy: 67.09%\n",
      "Epoch [839/2500], Train Loss: 0.7101, Train Accuracy: 67.43%, Test Loss: 0.9201, Test Accuracy: 67.09%\n",
      "Epoch [840/2500], Train Loss: 0.7115, Train Accuracy: 69.70%, Test Loss: 0.8941, Test Accuracy: 67.09%\n",
      "Epoch [841/2500], Train Loss: 0.7156, Train Accuracy: 68.28%, Test Loss: 0.9153, Test Accuracy: 65.82%\n",
      "Epoch [842/2500], Train Loss: 0.6861, Train Accuracy: 69.84%, Test Loss: 0.9293, Test Accuracy: 63.29%\n",
      "Epoch [843/2500], Train Loss: 0.7148, Train Accuracy: 70.41%, Test Loss: 0.9326, Test Accuracy: 65.82%\n",
      "Epoch [844/2500], Train Loss: 0.7079, Train Accuracy: 70.27%, Test Loss: 0.9093, Test Accuracy: 67.09%\n",
      "Epoch [845/2500], Train Loss: 0.6726, Train Accuracy: 70.13%, Test Loss: 0.9408, Test Accuracy: 64.56%\n",
      "Epoch [846/2500], Train Loss: 0.6921, Train Accuracy: 71.27%, Test Loss: 0.9460, Test Accuracy: 65.82%\n",
      "Epoch [847/2500], Train Loss: 0.6978, Train Accuracy: 67.43%, Test Loss: 0.9842, Test Accuracy: 63.29%\n",
      "Epoch [848/2500], Train Loss: 0.6986, Train Accuracy: 68.42%, Test Loss: 0.9495, Test Accuracy: 62.03%\n",
      "Epoch [849/2500], Train Loss: 0.6975, Train Accuracy: 69.99%, Test Loss: 0.9349, Test Accuracy: 64.56%\n",
      "Epoch [850/2500], Train Loss: 0.7018, Train Accuracy: 67.99%, Test Loss: 0.9496, Test Accuracy: 67.09%\n",
      "Epoch [851/2500], Train Loss: 0.7317, Train Accuracy: 69.56%, Test Loss: 0.9377, Test Accuracy: 65.82%\n",
      "Epoch [852/2500], Train Loss: 0.7055, Train Accuracy: 69.70%, Test Loss: 0.9183, Test Accuracy: 65.82%\n",
      "Epoch [853/2500], Train Loss: 0.7086, Train Accuracy: 69.27%, Test Loss: 0.9240, Test Accuracy: 64.56%\n",
      "Epoch [854/2500], Train Loss: 0.7167, Train Accuracy: 68.28%, Test Loss: 0.9244, Test Accuracy: 65.82%\n",
      "Epoch [855/2500], Train Loss: 0.6909, Train Accuracy: 71.83%, Test Loss: 0.9045, Test Accuracy: 67.09%\n",
      "Epoch [856/2500], Train Loss: 0.6914, Train Accuracy: 68.99%, Test Loss: 0.9224, Test Accuracy: 65.82%\n",
      "Epoch [857/2500], Train Loss: 0.7273, Train Accuracy: 68.99%, Test Loss: 0.9261, Test Accuracy: 64.56%\n",
      "Epoch [858/2500], Train Loss: 0.6934, Train Accuracy: 69.84%, Test Loss: 0.9496, Test Accuracy: 67.09%\n",
      "Epoch [859/2500], Train Loss: 0.7069, Train Accuracy: 70.70%, Test Loss: 0.9699, Test Accuracy: 64.56%\n",
      "Epoch [860/2500], Train Loss: 0.7336, Train Accuracy: 67.57%, Test Loss: 0.9234, Test Accuracy: 65.82%\n",
      "Epoch [861/2500], Train Loss: 0.7118, Train Accuracy: 68.28%, Test Loss: 0.9407, Test Accuracy: 68.35%\n",
      "Epoch [862/2500], Train Loss: 0.7155, Train Accuracy: 69.42%, Test Loss: 0.9463, Test Accuracy: 68.35%\n",
      "Epoch [863/2500], Train Loss: 0.7076, Train Accuracy: 71.12%, Test Loss: 0.9122, Test Accuracy: 68.35%\n",
      "Epoch [864/2500], Train Loss: 0.7227, Train Accuracy: 67.00%, Test Loss: 0.9175, Test Accuracy: 67.09%\n",
      "Epoch [865/2500], Train Loss: 0.7244, Train Accuracy: 67.14%, Test Loss: 0.9412, Test Accuracy: 67.09%\n",
      "Epoch [866/2500], Train Loss: 0.6983, Train Accuracy: 68.99%, Test Loss: 0.9517, Test Accuracy: 65.82%\n",
      "Epoch [867/2500], Train Loss: 0.7140, Train Accuracy: 67.57%, Test Loss: 0.9349, Test Accuracy: 67.09%\n",
      "Epoch [868/2500], Train Loss: 0.7180, Train Accuracy: 66.71%, Test Loss: 0.9361, Test Accuracy: 67.09%\n",
      "Epoch [869/2500], Train Loss: 0.7058, Train Accuracy: 68.99%, Test Loss: 0.9414, Test Accuracy: 67.09%\n",
      "Epoch [870/2500], Train Loss: 0.7103, Train Accuracy: 67.57%, Test Loss: 0.9326, Test Accuracy: 67.09%\n",
      "Epoch [871/2500], Train Loss: 0.6939, Train Accuracy: 69.13%, Test Loss: 0.9098, Test Accuracy: 69.62%\n",
      "Epoch [872/2500], Train Loss: 0.6916, Train Accuracy: 69.27%, Test Loss: 0.9454, Test Accuracy: 65.82%\n",
      "Epoch [873/2500], Train Loss: 0.6979, Train Accuracy: 69.27%, Test Loss: 0.9305, Test Accuracy: 68.35%\n",
      "Epoch [874/2500], Train Loss: 0.7107, Train Accuracy: 69.99%, Test Loss: 0.9425, Test Accuracy: 65.82%\n",
      "Epoch [875/2500], Train Loss: 0.6838, Train Accuracy: 71.27%, Test Loss: 0.9657, Test Accuracy: 67.09%\n",
      "Epoch [876/2500], Train Loss: 0.7028, Train Accuracy: 69.27%, Test Loss: 0.9428, Test Accuracy: 67.09%\n",
      "Epoch [877/2500], Train Loss: 0.7156, Train Accuracy: 66.57%, Test Loss: 0.9333, Test Accuracy: 65.82%\n",
      "Epoch [878/2500], Train Loss: 0.7264, Train Accuracy: 68.99%, Test Loss: 0.9458, Test Accuracy: 67.09%\n",
      "Epoch [879/2500], Train Loss: 0.7340, Train Accuracy: 69.13%, Test Loss: 0.9337, Test Accuracy: 67.09%\n",
      "Epoch [880/2500], Train Loss: 0.7046, Train Accuracy: 68.42%, Test Loss: 0.9204, Test Accuracy: 68.35%\n",
      "Epoch [881/2500], Train Loss: 0.6924, Train Accuracy: 69.13%, Test Loss: 0.9380, Test Accuracy: 67.09%\n",
      "Epoch [882/2500], Train Loss: 0.7012, Train Accuracy: 70.70%, Test Loss: 0.9362, Test Accuracy: 68.35%\n",
      "Epoch [883/2500], Train Loss: 0.7151, Train Accuracy: 69.70%, Test Loss: 0.9478, Test Accuracy: 68.35%\n",
      "Epoch [884/2500], Train Loss: 0.7043, Train Accuracy: 69.84%, Test Loss: 0.9358, Test Accuracy: 68.35%\n",
      "Epoch [885/2500], Train Loss: 0.7149, Train Accuracy: 69.99%, Test Loss: 0.9539, Test Accuracy: 65.82%\n",
      "Epoch [886/2500], Train Loss: 0.7065, Train Accuracy: 68.99%, Test Loss: 0.9386, Test Accuracy: 67.09%\n",
      "Epoch [887/2500], Train Loss: 0.6985, Train Accuracy: 70.70%, Test Loss: 0.9436, Test Accuracy: 63.29%\n",
      "Epoch [888/2500], Train Loss: 0.6751, Train Accuracy: 70.13%, Test Loss: 0.9808, Test Accuracy: 64.56%\n",
      "Epoch [889/2500], Train Loss: 0.7161, Train Accuracy: 69.13%, Test Loss: 0.9337, Test Accuracy: 69.62%\n",
      "Epoch [890/2500], Train Loss: 0.6917, Train Accuracy: 70.98%, Test Loss: 0.9170, Test Accuracy: 69.62%\n",
      "Epoch [891/2500], Train Loss: 0.7116, Train Accuracy: 69.42%, Test Loss: 0.9259, Test Accuracy: 65.82%\n",
      "Epoch [892/2500], Train Loss: 0.6840, Train Accuracy: 69.27%, Test Loss: 0.9332, Test Accuracy: 67.09%\n",
      "Epoch [893/2500], Train Loss: 0.7210, Train Accuracy: 68.14%, Test Loss: 0.9466, Test Accuracy: 67.09%\n",
      "Epoch [894/2500], Train Loss: 0.7164, Train Accuracy: 68.85%, Test Loss: 0.9335, Test Accuracy: 67.09%\n",
      "Epoch [895/2500], Train Loss: 0.6964, Train Accuracy: 68.28%, Test Loss: 0.9396, Test Accuracy: 67.09%\n",
      "Epoch [896/2500], Train Loss: 0.7106, Train Accuracy: 68.28%, Test Loss: 0.9524, Test Accuracy: 69.62%\n",
      "Epoch [897/2500], Train Loss: 0.6997, Train Accuracy: 69.99%, Test Loss: 0.9419, Test Accuracy: 65.82%\n",
      "Epoch [898/2500], Train Loss: 0.6891, Train Accuracy: 69.42%, Test Loss: 0.9512, Test Accuracy: 67.09%\n",
      "Epoch [899/2500], Train Loss: 0.6864, Train Accuracy: 68.71%, Test Loss: 0.9249, Test Accuracy: 67.09%\n",
      "Epoch [900/2500], Train Loss: 0.7111, Train Accuracy: 68.56%, Test Loss: 0.9497, Test Accuracy: 65.82%\n",
      "Epoch [901/2500], Train Loss: 0.7057, Train Accuracy: 69.27%, Test Loss: 0.9498, Test Accuracy: 65.82%\n",
      "Epoch [902/2500], Train Loss: 0.6927, Train Accuracy: 69.99%, Test Loss: 0.9518, Test Accuracy: 69.62%\n",
      "Epoch [903/2500], Train Loss: 0.7105, Train Accuracy: 69.84%, Test Loss: 0.9222, Test Accuracy: 68.35%\n",
      "Epoch [904/2500], Train Loss: 0.7087, Train Accuracy: 69.56%, Test Loss: 0.9272, Test Accuracy: 70.89%\n",
      "Epoch [905/2500], Train Loss: 0.7200, Train Accuracy: 68.71%, Test Loss: 0.9054, Test Accuracy: 68.35%\n",
      "Epoch [906/2500], Train Loss: 0.7219, Train Accuracy: 67.99%, Test Loss: 0.9352, Test Accuracy: 69.62%\n",
      "Epoch [907/2500], Train Loss: 0.7096, Train Accuracy: 67.14%, Test Loss: 0.9568, Test Accuracy: 69.62%\n",
      "Epoch [908/2500], Train Loss: 0.7155, Train Accuracy: 69.13%, Test Loss: 0.9423, Test Accuracy: 67.09%\n",
      "Epoch [909/2500], Train Loss: 0.7093, Train Accuracy: 69.13%, Test Loss: 0.9547, Test Accuracy: 65.82%\n",
      "Epoch [910/2500], Train Loss: 0.6987, Train Accuracy: 68.99%, Test Loss: 0.9470, Test Accuracy: 69.62%\n",
      "Epoch [911/2500], Train Loss: 0.7048, Train Accuracy: 70.84%, Test Loss: 0.9504, Test Accuracy: 67.09%\n",
      "Epoch [912/2500], Train Loss: 0.7338, Train Accuracy: 68.71%, Test Loss: 0.9416, Test Accuracy: 68.35%\n",
      "Epoch [913/2500], Train Loss: 0.6938, Train Accuracy: 70.27%, Test Loss: 0.9403, Test Accuracy: 68.35%\n",
      "Epoch [914/2500], Train Loss: 0.6738, Train Accuracy: 69.99%, Test Loss: 0.9436, Test Accuracy: 68.35%\n",
      "Epoch [915/2500], Train Loss: 0.7029, Train Accuracy: 69.70%, Test Loss: 0.9577, Test Accuracy: 68.35%\n",
      "Epoch [916/2500], Train Loss: 0.6936, Train Accuracy: 70.13%, Test Loss: 0.9504, Test Accuracy: 67.09%\n",
      "Epoch [917/2500], Train Loss: 0.7188, Train Accuracy: 68.99%, Test Loss: 0.9620, Test Accuracy: 67.09%\n",
      "Epoch [918/2500], Train Loss: 0.7018, Train Accuracy: 67.85%, Test Loss: 0.9670, Test Accuracy: 65.82%\n",
      "Epoch [919/2500], Train Loss: 0.6909, Train Accuracy: 72.83%, Test Loss: 0.9200, Test Accuracy: 69.62%\n",
      "Epoch [920/2500], Train Loss: 0.7221, Train Accuracy: 68.71%, Test Loss: 0.9520, Test Accuracy: 65.82%\n",
      "Epoch [921/2500], Train Loss: 0.7134, Train Accuracy: 69.27%, Test Loss: 0.9453, Test Accuracy: 67.09%\n",
      "Epoch [922/2500], Train Loss: 0.7052, Train Accuracy: 69.13%, Test Loss: 0.9238, Test Accuracy: 68.35%\n",
      "Epoch [923/2500], Train Loss: 0.7159, Train Accuracy: 68.42%, Test Loss: 0.9537, Test Accuracy: 67.09%\n",
      "Epoch [924/2500], Train Loss: 0.7017, Train Accuracy: 69.84%, Test Loss: 0.9465, Test Accuracy: 64.56%\n",
      "Epoch [925/2500], Train Loss: 0.6949, Train Accuracy: 69.13%, Test Loss: 0.9546, Test Accuracy: 67.09%\n",
      "Epoch [926/2500], Train Loss: 0.6899, Train Accuracy: 70.55%, Test Loss: 0.9427, Test Accuracy: 68.35%\n",
      "Epoch [927/2500], Train Loss: 0.7260, Train Accuracy: 69.70%, Test Loss: 0.9617, Test Accuracy: 68.35%\n",
      "Epoch [928/2500], Train Loss: 0.7068, Train Accuracy: 69.70%, Test Loss: 0.9189, Test Accuracy: 69.62%\n",
      "Epoch [929/2500], Train Loss: 0.7030, Train Accuracy: 70.41%, Test Loss: 0.9459, Test Accuracy: 67.09%\n",
      "Epoch [930/2500], Train Loss: 0.6838, Train Accuracy: 69.27%, Test Loss: 0.9567, Test Accuracy: 70.89%\n",
      "Epoch [931/2500], Train Loss: 0.6808, Train Accuracy: 70.27%, Test Loss: 0.9360, Test Accuracy: 69.62%\n",
      "Epoch [932/2500], Train Loss: 0.7046, Train Accuracy: 69.56%, Test Loss: 0.9701, Test Accuracy: 67.09%\n",
      "Epoch [933/2500], Train Loss: 0.6929, Train Accuracy: 70.84%, Test Loss: 0.9532, Test Accuracy: 67.09%\n",
      "Epoch [934/2500], Train Loss: 0.7063, Train Accuracy: 66.57%, Test Loss: 0.9385, Test Accuracy: 67.09%\n",
      "Epoch [935/2500], Train Loss: 0.6969, Train Accuracy: 69.27%, Test Loss: 0.9589, Test Accuracy: 67.09%\n",
      "Epoch [936/2500], Train Loss: 0.6858, Train Accuracy: 69.84%, Test Loss: 0.9143, Test Accuracy: 65.82%\n",
      "Epoch [937/2500], Train Loss: 0.7067, Train Accuracy: 68.14%, Test Loss: 0.9376, Test Accuracy: 68.35%\n",
      "Epoch [938/2500], Train Loss: 0.7012, Train Accuracy: 69.99%, Test Loss: 0.9258, Test Accuracy: 68.35%\n",
      "Epoch [939/2500], Train Loss: 0.7031, Train Accuracy: 69.56%, Test Loss: 0.9241, Test Accuracy: 70.89%\n",
      "Epoch [940/2500], Train Loss: 0.7145, Train Accuracy: 68.56%, Test Loss: 0.9266, Test Accuracy: 70.89%\n",
      "Epoch [941/2500], Train Loss: 0.6995, Train Accuracy: 68.28%, Test Loss: 0.9522, Test Accuracy: 67.09%\n",
      "Epoch [942/2500], Train Loss: 0.7060, Train Accuracy: 68.14%, Test Loss: 0.9654, Test Accuracy: 68.35%\n",
      "Epoch [943/2500], Train Loss: 0.7189, Train Accuracy: 68.56%, Test Loss: 0.9719, Test Accuracy: 65.82%\n",
      "Epoch [944/2500], Train Loss: 0.6974, Train Accuracy: 70.13%, Test Loss: 0.9574, Test Accuracy: 65.82%\n",
      "Epoch [945/2500], Train Loss: 0.7185, Train Accuracy: 68.85%, Test Loss: 0.9111, Test Accuracy: 68.35%\n",
      "Epoch [946/2500], Train Loss: 0.6886, Train Accuracy: 72.26%, Test Loss: 0.9271, Test Accuracy: 65.82%\n",
      "Epoch [947/2500], Train Loss: 0.7154, Train Accuracy: 68.14%, Test Loss: 0.9458, Test Accuracy: 67.09%\n",
      "Epoch [948/2500], Train Loss: 0.6963, Train Accuracy: 69.99%, Test Loss: 0.9806, Test Accuracy: 65.82%\n",
      "Epoch [949/2500], Train Loss: 0.7063, Train Accuracy: 68.56%, Test Loss: 0.9437, Test Accuracy: 68.35%\n",
      "Epoch [950/2500], Train Loss: 0.7042, Train Accuracy: 69.27%, Test Loss: 0.9436, Test Accuracy: 67.09%\n",
      "Epoch [951/2500], Train Loss: 0.6982, Train Accuracy: 69.56%, Test Loss: 0.9467, Test Accuracy: 67.09%\n",
      "Epoch [952/2500], Train Loss: 0.7011, Train Accuracy: 69.13%, Test Loss: 0.9072, Test Accuracy: 67.09%\n",
      "Epoch [953/2500], Train Loss: 0.6916, Train Accuracy: 69.13%, Test Loss: 0.9472, Test Accuracy: 69.62%\n",
      "Epoch [954/2500], Train Loss: 0.7095, Train Accuracy: 68.99%, Test Loss: 0.9312, Test Accuracy: 70.89%\n",
      "Epoch [955/2500], Train Loss: 0.6927, Train Accuracy: 71.55%, Test Loss: 0.9232, Test Accuracy: 72.15%\n",
      "Epoch [956/2500], Train Loss: 0.7043, Train Accuracy: 69.84%, Test Loss: 0.9554, Test Accuracy: 68.35%\n",
      "Epoch [957/2500], Train Loss: 0.6926, Train Accuracy: 70.13%, Test Loss: 0.8937, Test Accuracy: 72.15%\n",
      "Epoch [958/2500], Train Loss: 0.6620, Train Accuracy: 69.42%, Test Loss: 0.8974, Test Accuracy: 73.42%\n",
      "Epoch [959/2500], Train Loss: 0.7080, Train Accuracy: 70.98%, Test Loss: 0.9299, Test Accuracy: 72.15%\n",
      "Epoch [960/2500], Train Loss: 0.6930, Train Accuracy: 70.13%, Test Loss: 0.9549, Test Accuracy: 69.62%\n",
      "Epoch [961/2500], Train Loss: 0.7142, Train Accuracy: 69.42%, Test Loss: 0.9629, Test Accuracy: 68.35%\n",
      "Epoch [962/2500], Train Loss: 0.7026, Train Accuracy: 69.70%, Test Loss: 0.9127, Test Accuracy: 70.89%\n",
      "Epoch [963/2500], Train Loss: 0.6779, Train Accuracy: 70.84%, Test Loss: 0.9372, Test Accuracy: 70.89%\n",
      "Epoch [964/2500], Train Loss: 0.6928, Train Accuracy: 69.56%, Test Loss: 0.9472, Test Accuracy: 69.62%\n",
      "Epoch [965/2500], Train Loss: 0.6853, Train Accuracy: 68.14%, Test Loss: 0.9426, Test Accuracy: 69.62%\n",
      "Epoch [966/2500], Train Loss: 0.7048, Train Accuracy: 69.27%, Test Loss: 0.9182, Test Accuracy: 67.09%\n",
      "Epoch [967/2500], Train Loss: 0.6800, Train Accuracy: 70.84%, Test Loss: 0.9652, Test Accuracy: 68.35%\n",
      "Epoch [968/2500], Train Loss: 0.6725, Train Accuracy: 69.99%, Test Loss: 0.9576, Test Accuracy: 67.09%\n",
      "Epoch [969/2500], Train Loss: 0.6868, Train Accuracy: 69.27%, Test Loss: 0.9889, Test Accuracy: 67.09%\n",
      "Epoch [970/2500], Train Loss: 0.6684, Train Accuracy: 70.98%, Test Loss: 1.0048, Test Accuracy: 68.35%\n",
      "Epoch [971/2500], Train Loss: 0.6658, Train Accuracy: 72.26%, Test Loss: 0.9703, Test Accuracy: 69.62%\n",
      "Epoch [972/2500], Train Loss: 0.7045, Train Accuracy: 68.99%, Test Loss: 0.9476, Test Accuracy: 68.35%\n",
      "Epoch [973/2500], Train Loss: 0.6851, Train Accuracy: 71.55%, Test Loss: 0.9599, Test Accuracy: 68.35%\n",
      "Epoch [974/2500], Train Loss: 0.7048, Train Accuracy: 68.99%, Test Loss: 0.8922, Test Accuracy: 70.89%\n",
      "Epoch [975/2500], Train Loss: 0.7066, Train Accuracy: 68.56%, Test Loss: 0.9549, Test Accuracy: 67.09%\n",
      "Epoch [976/2500], Train Loss: 0.7005, Train Accuracy: 68.85%, Test Loss: 0.9391, Test Accuracy: 70.89%\n",
      "Epoch [977/2500], Train Loss: 0.6911, Train Accuracy: 69.27%, Test Loss: 0.9462, Test Accuracy: 69.62%\n",
      "Epoch [978/2500], Train Loss: 0.6964, Train Accuracy: 69.42%, Test Loss: 0.9584, Test Accuracy: 65.82%\n",
      "Epoch [979/2500], Train Loss: 0.6717, Train Accuracy: 69.56%, Test Loss: 0.9580, Test Accuracy: 67.09%\n",
      "Epoch [980/2500], Train Loss: 0.6764, Train Accuracy: 69.27%, Test Loss: 0.9335, Test Accuracy: 67.09%\n",
      "Epoch [981/2500], Train Loss: 0.6750, Train Accuracy: 70.84%, Test Loss: 0.9975, Test Accuracy: 64.56%\n",
      "Epoch [982/2500], Train Loss: 0.6808, Train Accuracy: 69.70%, Test Loss: 0.9578, Test Accuracy: 68.35%\n",
      "Epoch [983/2500], Train Loss: 0.6874, Train Accuracy: 70.41%, Test Loss: 0.9656, Test Accuracy: 67.09%\n",
      "Epoch [984/2500], Train Loss: 0.7024, Train Accuracy: 69.27%, Test Loss: 0.9719, Test Accuracy: 68.35%\n",
      "Epoch [985/2500], Train Loss: 0.6967, Train Accuracy: 70.55%, Test Loss: 0.9562, Test Accuracy: 69.62%\n",
      "Epoch [986/2500], Train Loss: 0.7063, Train Accuracy: 68.14%, Test Loss: 0.9447, Test Accuracy: 68.35%\n",
      "Epoch [987/2500], Train Loss: 0.6668, Train Accuracy: 71.27%, Test Loss: 0.9634, Test Accuracy: 67.09%\n",
      "Epoch [988/2500], Train Loss: 0.7033, Train Accuracy: 68.99%, Test Loss: 0.9839, Test Accuracy: 68.35%\n",
      "Epoch [989/2500], Train Loss: 0.6609, Train Accuracy: 70.55%, Test Loss: 1.0058, Test Accuracy: 65.82%\n",
      "Epoch [990/2500], Train Loss: 0.7112, Train Accuracy: 68.71%, Test Loss: 1.0044, Test Accuracy: 65.82%\n",
      "Epoch [991/2500], Train Loss: 0.6869, Train Accuracy: 69.70%, Test Loss: 0.9535, Test Accuracy: 68.35%\n",
      "Epoch [992/2500], Train Loss: 0.6995, Train Accuracy: 70.13%, Test Loss: 0.9114, Test Accuracy: 69.62%\n",
      "Epoch [993/2500], Train Loss: 0.7055, Train Accuracy: 69.84%, Test Loss: 0.9734, Test Accuracy: 67.09%\n",
      "Epoch [994/2500], Train Loss: 0.6938, Train Accuracy: 69.56%, Test Loss: 1.0074, Test Accuracy: 64.56%\n",
      "Epoch [995/2500], Train Loss: 0.6718, Train Accuracy: 72.26%, Test Loss: 0.9663, Test Accuracy: 70.89%\n",
      "Epoch [996/2500], Train Loss: 0.6967, Train Accuracy: 70.27%, Test Loss: 0.9660, Test Accuracy: 70.89%\n",
      "Epoch [997/2500], Train Loss: 0.6677, Train Accuracy: 70.98%, Test Loss: 1.0176, Test Accuracy: 65.82%\n",
      "Epoch [998/2500], Train Loss: 0.7124, Train Accuracy: 69.99%, Test Loss: 0.9691, Test Accuracy: 68.35%\n",
      "Epoch [999/2500], Train Loss: 0.6759, Train Accuracy: 69.84%, Test Loss: 0.9569, Test Accuracy: 67.09%\n",
      "Epoch [1000/2500], Train Loss: 0.6806, Train Accuracy: 68.85%, Test Loss: 0.9880, Test Accuracy: 65.82%\n",
      "Epoch [1001/2500], Train Loss: 0.6771, Train Accuracy: 70.27%, Test Loss: 1.0196, Test Accuracy: 68.35%\n",
      "Epoch [1002/2500], Train Loss: 0.7083, Train Accuracy: 69.84%, Test Loss: 0.9727, Test Accuracy: 69.62%\n",
      "Epoch [1003/2500], Train Loss: 0.6919, Train Accuracy: 68.14%, Test Loss: 0.9961, Test Accuracy: 68.35%\n",
      "Epoch [1004/2500], Train Loss: 0.7044, Train Accuracy: 70.27%, Test Loss: 0.9591, Test Accuracy: 67.09%\n",
      "Epoch [1005/2500], Train Loss: 0.6917, Train Accuracy: 71.55%, Test Loss: 0.9434, Test Accuracy: 69.62%\n",
      "Epoch [1006/2500], Train Loss: 0.6722, Train Accuracy: 72.12%, Test Loss: 0.9986, Test Accuracy: 68.35%\n",
      "Epoch [1007/2500], Train Loss: 0.7005, Train Accuracy: 68.85%, Test Loss: 0.9372, Test Accuracy: 70.89%\n",
      "Epoch [1008/2500], Train Loss: 0.6709, Train Accuracy: 70.70%, Test Loss: 0.9598, Test Accuracy: 68.35%\n",
      "Epoch [1009/2500], Train Loss: 0.7017, Train Accuracy: 68.71%, Test Loss: 0.9789, Test Accuracy: 69.62%\n",
      "Epoch [1010/2500], Train Loss: 0.7069, Train Accuracy: 69.99%, Test Loss: 0.9519, Test Accuracy: 70.89%\n",
      "Epoch [1011/2500], Train Loss: 0.6863, Train Accuracy: 69.84%, Test Loss: 0.9564, Test Accuracy: 70.89%\n",
      "Epoch [1012/2500], Train Loss: 0.6631, Train Accuracy: 71.41%, Test Loss: 1.0064, Test Accuracy: 68.35%\n",
      "Epoch [1013/2500], Train Loss: 0.6732, Train Accuracy: 70.55%, Test Loss: 1.0037, Test Accuracy: 67.09%\n",
      "Epoch [1014/2500], Train Loss: 0.6975, Train Accuracy: 70.55%, Test Loss: 0.9622, Test Accuracy: 68.35%\n",
      "Epoch [1015/2500], Train Loss: 0.7087, Train Accuracy: 69.70%, Test Loss: 1.0015, Test Accuracy: 69.62%\n",
      "Epoch [1016/2500], Train Loss: 0.7120, Train Accuracy: 67.71%, Test Loss: 0.9445, Test Accuracy: 68.35%\n",
      "Epoch [1017/2500], Train Loss: 0.7000, Train Accuracy: 68.85%, Test Loss: 0.9512, Test Accuracy: 67.09%\n",
      "Epoch [1018/2500], Train Loss: 0.6791, Train Accuracy: 71.27%, Test Loss: 0.9726, Test Accuracy: 70.89%\n",
      "Epoch [1019/2500], Train Loss: 0.6759, Train Accuracy: 70.55%, Test Loss: 0.9885, Test Accuracy: 69.62%\n",
      "Epoch [1020/2500], Train Loss: 0.6885, Train Accuracy: 69.84%, Test Loss: 1.0306, Test Accuracy: 65.82%\n",
      "Epoch [1021/2500], Train Loss: 0.6953, Train Accuracy: 69.99%, Test Loss: 0.9957, Test Accuracy: 67.09%\n",
      "Epoch [1022/2500], Train Loss: 0.6988, Train Accuracy: 71.69%, Test Loss: 0.9852, Test Accuracy: 67.09%\n",
      "Epoch [1023/2500], Train Loss: 0.6804, Train Accuracy: 70.70%, Test Loss: 0.9737, Test Accuracy: 68.35%\n",
      "Epoch [1024/2500], Train Loss: 0.6931, Train Accuracy: 69.56%, Test Loss: 0.9770, Test Accuracy: 67.09%\n",
      "Epoch [1025/2500], Train Loss: 0.6819, Train Accuracy: 68.28%, Test Loss: 0.9704, Test Accuracy: 67.09%\n",
      "Epoch [1026/2500], Train Loss: 0.6600, Train Accuracy: 71.55%, Test Loss: 0.9746, Test Accuracy: 67.09%\n",
      "Epoch [1027/2500], Train Loss: 0.6869, Train Accuracy: 68.56%, Test Loss: 0.9191, Test Accuracy: 70.89%\n",
      "Epoch [1028/2500], Train Loss: 0.6890, Train Accuracy: 71.69%, Test Loss: 0.9815, Test Accuracy: 67.09%\n",
      "Epoch [1029/2500], Train Loss: 0.6854, Train Accuracy: 69.70%, Test Loss: 0.9545, Test Accuracy: 65.82%\n",
      "Epoch [1030/2500], Train Loss: 0.6911, Train Accuracy: 69.84%, Test Loss: 0.9355, Test Accuracy: 68.35%\n",
      "Epoch [1031/2500], Train Loss: 0.6964, Train Accuracy: 69.84%, Test Loss: 0.9327, Test Accuracy: 68.35%\n",
      "Epoch [1032/2500], Train Loss: 0.6656, Train Accuracy: 70.98%, Test Loss: 0.9654, Test Accuracy: 68.35%\n",
      "Epoch [1033/2500], Train Loss: 0.6850, Train Accuracy: 68.56%, Test Loss: 0.9230, Test Accuracy: 68.35%\n",
      "Epoch [1034/2500], Train Loss: 0.6967, Train Accuracy: 67.28%, Test Loss: 0.9424, Test Accuracy: 69.62%\n",
      "Epoch [1035/2500], Train Loss: 0.6810, Train Accuracy: 70.13%, Test Loss: 0.9724, Test Accuracy: 67.09%\n",
      "Epoch [1036/2500], Train Loss: 0.6940, Train Accuracy: 68.71%, Test Loss: 0.9278, Test Accuracy: 70.89%\n",
      "Epoch [1037/2500], Train Loss: 0.6849, Train Accuracy: 69.27%, Test Loss: 0.9881, Test Accuracy: 65.82%\n",
      "Epoch [1038/2500], Train Loss: 0.6741, Train Accuracy: 71.83%, Test Loss: 0.9756, Test Accuracy: 69.62%\n",
      "Epoch [1039/2500], Train Loss: 0.6858, Train Accuracy: 69.70%, Test Loss: 0.9565, Test Accuracy: 68.35%\n",
      "Epoch [1040/2500], Train Loss: 0.6739, Train Accuracy: 69.99%, Test Loss: 0.9563, Test Accuracy: 67.09%\n",
      "Epoch [1041/2500], Train Loss: 0.6859, Train Accuracy: 69.70%, Test Loss: 0.9608, Test Accuracy: 67.09%\n",
      "Epoch [1042/2500], Train Loss: 0.6765, Train Accuracy: 70.13%, Test Loss: 0.9528, Test Accuracy: 67.09%\n",
      "Epoch [1043/2500], Train Loss: 0.6890, Train Accuracy: 68.71%, Test Loss: 0.9385, Test Accuracy: 65.82%\n",
      "Epoch [1044/2500], Train Loss: 0.6834, Train Accuracy: 71.27%, Test Loss: 0.9663, Test Accuracy: 65.82%\n",
      "Epoch [1045/2500], Train Loss: 0.7079, Train Accuracy: 70.41%, Test Loss: 0.9620, Test Accuracy: 67.09%\n",
      "Epoch [1046/2500], Train Loss: 0.6897, Train Accuracy: 71.55%, Test Loss: 0.9535, Test Accuracy: 65.82%\n",
      "Epoch [1047/2500], Train Loss: 0.6625, Train Accuracy: 69.56%, Test Loss: 0.9563, Test Accuracy: 67.09%\n",
      "Epoch [1048/2500], Train Loss: 0.6901, Train Accuracy: 71.55%, Test Loss: 0.9871, Test Accuracy: 65.82%\n",
      "Epoch [1049/2500], Train Loss: 0.6416, Train Accuracy: 70.41%, Test Loss: 0.9855, Test Accuracy: 67.09%\n",
      "Epoch [1050/2500], Train Loss: 0.7153, Train Accuracy: 68.71%, Test Loss: 0.9670, Test Accuracy: 68.35%\n",
      "Epoch [1051/2500], Train Loss: 0.6728, Train Accuracy: 70.55%, Test Loss: 0.9888, Test Accuracy: 64.56%\n",
      "Epoch [1052/2500], Train Loss: 0.6992, Train Accuracy: 70.13%, Test Loss: 0.9809, Test Accuracy: 65.82%\n",
      "Epoch [1053/2500], Train Loss: 0.7017, Train Accuracy: 69.99%, Test Loss: 0.9238, Test Accuracy: 69.62%\n",
      "Epoch [1054/2500], Train Loss: 0.6910, Train Accuracy: 70.27%, Test Loss: 0.9595, Test Accuracy: 69.62%\n",
      "Epoch [1055/2500], Train Loss: 0.6812, Train Accuracy: 70.55%, Test Loss: 0.9620, Test Accuracy: 69.62%\n",
      "Epoch [1056/2500], Train Loss: 0.7157, Train Accuracy: 70.98%, Test Loss: 0.9138, Test Accuracy: 73.42%\n",
      "Epoch [1057/2500], Train Loss: 0.6789, Train Accuracy: 71.27%, Test Loss: 0.9796, Test Accuracy: 68.35%\n",
      "Epoch [1058/2500], Train Loss: 0.7081, Train Accuracy: 71.27%, Test Loss: 0.9977, Test Accuracy: 69.62%\n",
      "Epoch [1059/2500], Train Loss: 0.6865, Train Accuracy: 70.70%, Test Loss: 0.9776, Test Accuracy: 69.62%\n",
      "Epoch [1060/2500], Train Loss: 0.6870, Train Accuracy: 70.41%, Test Loss: 0.9541, Test Accuracy: 69.62%\n",
      "Epoch [1061/2500], Train Loss: 0.6536, Train Accuracy: 71.41%, Test Loss: 0.9858, Test Accuracy: 67.09%\n",
      "Epoch [1062/2500], Train Loss: 0.6932, Train Accuracy: 69.84%, Test Loss: 0.9571, Test Accuracy: 69.62%\n",
      "Epoch [1063/2500], Train Loss: 0.6738, Train Accuracy: 71.83%, Test Loss: 0.9661, Test Accuracy: 67.09%\n",
      "Epoch [1064/2500], Train Loss: 0.7029, Train Accuracy: 69.84%, Test Loss: 0.9539, Test Accuracy: 69.62%\n",
      "Epoch [1065/2500], Train Loss: 0.6957, Train Accuracy: 69.84%, Test Loss: 0.9708, Test Accuracy: 65.82%\n",
      "Epoch [1066/2500], Train Loss: 0.6802, Train Accuracy: 69.84%, Test Loss: 0.9751, Test Accuracy: 68.35%\n",
      "Epoch [1067/2500], Train Loss: 0.6722, Train Accuracy: 71.12%, Test Loss: 0.9935, Test Accuracy: 67.09%\n",
      "Epoch [1068/2500], Train Loss: 0.6628, Train Accuracy: 70.13%, Test Loss: 0.9953, Test Accuracy: 64.56%\n",
      "Epoch [1069/2500], Train Loss: 0.6968, Train Accuracy: 69.27%, Test Loss: 0.9454, Test Accuracy: 68.35%\n",
      "Epoch [1070/2500], Train Loss: 0.6797, Train Accuracy: 69.84%, Test Loss: 0.9582, Test Accuracy: 68.35%\n",
      "Epoch [1071/2500], Train Loss: 0.6755, Train Accuracy: 70.98%, Test Loss: 0.9676, Test Accuracy: 68.35%\n",
      "Epoch [1072/2500], Train Loss: 0.6964, Train Accuracy: 68.28%, Test Loss: 0.9756, Test Accuracy: 67.09%\n",
      "Epoch [1073/2500], Train Loss: 0.6835, Train Accuracy: 70.13%, Test Loss: 0.9694, Test Accuracy: 67.09%\n",
      "Epoch [1074/2500], Train Loss: 0.6826, Train Accuracy: 70.98%, Test Loss: 0.9850, Test Accuracy: 67.09%\n",
      "Epoch [1075/2500], Train Loss: 0.6795, Train Accuracy: 70.98%, Test Loss: 0.9762, Test Accuracy: 68.35%\n",
      "Epoch [1076/2500], Train Loss: 0.6600, Train Accuracy: 71.27%, Test Loss: 0.9806, Test Accuracy: 67.09%\n",
      "Epoch [1077/2500], Train Loss: 0.6599, Train Accuracy: 71.69%, Test Loss: 0.9757, Test Accuracy: 67.09%\n",
      "Epoch [1078/2500], Train Loss: 0.6851, Train Accuracy: 70.13%, Test Loss: 0.9715, Test Accuracy: 68.35%\n",
      "Epoch [1079/2500], Train Loss: 0.6808, Train Accuracy: 69.13%, Test Loss: 0.9497, Test Accuracy: 69.62%\n",
      "Epoch [1080/2500], Train Loss: 0.6884, Train Accuracy: 68.28%, Test Loss: 0.9683, Test Accuracy: 67.09%\n",
      "Epoch [1081/2500], Train Loss: 0.6850, Train Accuracy: 69.27%, Test Loss: 0.9591, Test Accuracy: 67.09%\n",
      "Epoch [1082/2500], Train Loss: 0.6778, Train Accuracy: 72.26%, Test Loss: 0.9758, Test Accuracy: 68.35%\n",
      "Epoch [1083/2500], Train Loss: 0.6811, Train Accuracy: 70.27%, Test Loss: 0.9615, Test Accuracy: 67.09%\n",
      "Epoch [1084/2500], Train Loss: 0.6638, Train Accuracy: 70.84%, Test Loss: 1.0171, Test Accuracy: 65.82%\n",
      "Epoch [1085/2500], Train Loss: 0.7218, Train Accuracy: 67.99%, Test Loss: 0.9568, Test Accuracy: 65.82%\n",
      "Epoch [1086/2500], Train Loss: 0.6756, Train Accuracy: 70.27%, Test Loss: 0.9585, Test Accuracy: 69.62%\n",
      "Epoch [1087/2500], Train Loss: 0.6828, Train Accuracy: 71.55%, Test Loss: 0.9680, Test Accuracy: 68.35%\n",
      "Epoch [1088/2500], Train Loss: 0.7145, Train Accuracy: 68.28%, Test Loss: 0.9215, Test Accuracy: 68.35%\n",
      "Epoch [1089/2500], Train Loss: 0.6826, Train Accuracy: 69.99%, Test Loss: 0.9519, Test Accuracy: 67.09%\n",
      "Epoch [1090/2500], Train Loss: 0.6933, Train Accuracy: 69.42%, Test Loss: 0.9607, Test Accuracy: 68.35%\n",
      "Epoch [1091/2500], Train Loss: 0.7070, Train Accuracy: 70.70%, Test Loss: 0.9486, Test Accuracy: 67.09%\n",
      "Epoch [1092/2500], Train Loss: 0.6574, Train Accuracy: 70.13%, Test Loss: 1.0406, Test Accuracy: 64.56%\n",
      "Epoch [1093/2500], Train Loss: 0.6922, Train Accuracy: 70.70%, Test Loss: 0.9610, Test Accuracy: 67.09%\n",
      "Epoch [1094/2500], Train Loss: 0.6841, Train Accuracy: 69.70%, Test Loss: 0.9080, Test Accuracy: 67.09%\n",
      "Epoch [1095/2500], Train Loss: 0.6864, Train Accuracy: 70.98%, Test Loss: 0.9091, Test Accuracy: 67.09%\n",
      "Epoch [1096/2500], Train Loss: 0.6679, Train Accuracy: 71.12%, Test Loss: 0.9370, Test Accuracy: 70.89%\n",
      "Epoch [1097/2500], Train Loss: 0.6963, Train Accuracy: 67.99%, Test Loss: 0.9809, Test Accuracy: 67.09%\n",
      "Epoch [1098/2500], Train Loss: 0.6749, Train Accuracy: 70.70%, Test Loss: 0.9854, Test Accuracy: 65.82%\n",
      "Epoch [1099/2500], Train Loss: 0.6685, Train Accuracy: 71.83%, Test Loss: 0.9456, Test Accuracy: 68.35%\n",
      "Epoch [1100/2500], Train Loss: 0.6766, Train Accuracy: 70.13%, Test Loss: 1.0179, Test Accuracy: 67.09%\n",
      "Epoch [1101/2500], Train Loss: 0.6453, Train Accuracy: 70.70%, Test Loss: 1.0728, Test Accuracy: 64.56%\n",
      "Epoch [1102/2500], Train Loss: 0.7008, Train Accuracy: 70.41%, Test Loss: 0.9647, Test Accuracy: 67.09%\n",
      "Epoch [1103/2500], Train Loss: 0.6560, Train Accuracy: 72.12%, Test Loss: 0.9664, Test Accuracy: 68.35%\n",
      "Epoch [1104/2500], Train Loss: 0.6667, Train Accuracy: 70.70%, Test Loss: 1.0199, Test Accuracy: 67.09%\n",
      "Epoch [1105/2500], Train Loss: 0.6838, Train Accuracy: 68.71%, Test Loss: 1.0265, Test Accuracy: 67.09%\n",
      "Epoch [1106/2500], Train Loss: 0.6939, Train Accuracy: 68.71%, Test Loss: 1.0388, Test Accuracy: 65.82%\n",
      "Epoch [1107/2500], Train Loss: 0.6700, Train Accuracy: 70.55%, Test Loss: 0.9661, Test Accuracy: 67.09%\n",
      "Epoch [1108/2500], Train Loss: 0.6890, Train Accuracy: 71.12%, Test Loss: 0.9476, Test Accuracy: 65.82%\n",
      "Epoch [1109/2500], Train Loss: 0.7014, Train Accuracy: 71.55%, Test Loss: 0.9690, Test Accuracy: 67.09%\n",
      "Epoch [1110/2500], Train Loss: 0.6619, Train Accuracy: 73.12%, Test Loss: 1.0201, Test Accuracy: 67.09%\n",
      "Epoch [1111/2500], Train Loss: 0.7062, Train Accuracy: 68.28%, Test Loss: 0.9541, Test Accuracy: 68.35%\n",
      "Epoch [1112/2500], Train Loss: 0.6742, Train Accuracy: 69.56%, Test Loss: 0.9954, Test Accuracy: 69.62%\n",
      "Epoch [1113/2500], Train Loss: 0.6781, Train Accuracy: 69.84%, Test Loss: 0.9962, Test Accuracy: 65.82%\n",
      "Epoch [1114/2500], Train Loss: 0.6606, Train Accuracy: 70.55%, Test Loss: 1.0159, Test Accuracy: 65.82%\n",
      "Epoch [1115/2500], Train Loss: 0.6724, Train Accuracy: 71.69%, Test Loss: 1.0065, Test Accuracy: 67.09%\n",
      "Epoch [1116/2500], Train Loss: 0.6879, Train Accuracy: 70.13%, Test Loss: 0.9712, Test Accuracy: 69.62%\n",
      "Epoch [1117/2500], Train Loss: 0.6674, Train Accuracy: 70.84%, Test Loss: 0.9905, Test Accuracy: 68.35%\n",
      "Epoch [1118/2500], Train Loss: 0.6715, Train Accuracy: 70.27%, Test Loss: 1.0217, Test Accuracy: 65.82%\n",
      "Epoch [1119/2500], Train Loss: 0.6806, Train Accuracy: 68.71%, Test Loss: 0.9926, Test Accuracy: 67.09%\n",
      "Epoch [1120/2500], Train Loss: 0.6946, Train Accuracy: 68.85%, Test Loss: 0.9947, Test Accuracy: 68.35%\n",
      "Epoch [1121/2500], Train Loss: 0.6567, Train Accuracy: 71.41%, Test Loss: 0.9989, Test Accuracy: 64.56%\n",
      "Epoch [1122/2500], Train Loss: 0.6623, Train Accuracy: 70.98%, Test Loss: 0.9739, Test Accuracy: 69.62%\n",
      "Epoch [1123/2500], Train Loss: 0.6801, Train Accuracy: 70.55%, Test Loss: 1.0156, Test Accuracy: 70.89%\n",
      "Epoch [1124/2500], Train Loss: 0.6578, Train Accuracy: 70.84%, Test Loss: 0.9543, Test Accuracy: 68.35%\n",
      "Epoch [1125/2500], Train Loss: 0.6945, Train Accuracy: 69.70%, Test Loss: 1.0249, Test Accuracy: 64.56%\n",
      "Epoch [1126/2500], Train Loss: 0.6552, Train Accuracy: 71.12%, Test Loss: 0.9991, Test Accuracy: 65.82%\n",
      "Epoch [1127/2500], Train Loss: 0.6741, Train Accuracy: 68.56%, Test Loss: 1.0225, Test Accuracy: 68.35%\n",
      "Epoch [1128/2500], Train Loss: 0.6760, Train Accuracy: 70.98%, Test Loss: 1.0076, Test Accuracy: 65.82%\n",
      "Epoch [1129/2500], Train Loss: 0.6566, Train Accuracy: 70.98%, Test Loss: 0.9982, Test Accuracy: 67.09%\n",
      "Epoch [1130/2500], Train Loss: 0.6619, Train Accuracy: 70.84%, Test Loss: 1.0415, Test Accuracy: 68.35%\n",
      "Epoch [1131/2500], Train Loss: 0.6911, Train Accuracy: 69.70%, Test Loss: 1.0204, Test Accuracy: 68.35%\n",
      "Epoch [1132/2500], Train Loss: 0.6770, Train Accuracy: 71.55%, Test Loss: 0.9587, Test Accuracy: 68.35%\n",
      "Epoch [1133/2500], Train Loss: 0.6552, Train Accuracy: 70.98%, Test Loss: 0.9807, Test Accuracy: 68.35%\n",
      "Epoch [1134/2500], Train Loss: 0.6515, Train Accuracy: 71.83%, Test Loss: 1.0105, Test Accuracy: 69.62%\n",
      "Epoch [1135/2500], Train Loss: 0.6663, Train Accuracy: 72.69%, Test Loss: 1.0102, Test Accuracy: 67.09%\n",
      "Epoch [1136/2500], Train Loss: 0.6810, Train Accuracy: 70.55%, Test Loss: 1.0234, Test Accuracy: 65.82%\n",
      "Epoch [1137/2500], Train Loss: 0.6872, Train Accuracy: 69.56%, Test Loss: 0.9745, Test Accuracy: 69.62%\n",
      "Epoch [1138/2500], Train Loss: 0.6778, Train Accuracy: 70.70%, Test Loss: 1.0339, Test Accuracy: 68.35%\n",
      "Epoch [1139/2500], Train Loss: 0.6630, Train Accuracy: 69.70%, Test Loss: 0.9820, Test Accuracy: 68.35%\n",
      "Epoch [1140/2500], Train Loss: 0.6438, Train Accuracy: 72.26%, Test Loss: 0.9874, Test Accuracy: 68.35%\n",
      "Epoch [1141/2500], Train Loss: 0.6687, Train Accuracy: 72.40%, Test Loss: 0.9931, Test Accuracy: 68.35%\n",
      "Epoch [1142/2500], Train Loss: 0.6679, Train Accuracy: 71.83%, Test Loss: 0.9927, Test Accuracy: 70.89%\n",
      "Epoch [1143/2500], Train Loss: 0.6935, Train Accuracy: 70.98%, Test Loss: 0.9879, Test Accuracy: 69.62%\n",
      "Epoch [1144/2500], Train Loss: 0.6586, Train Accuracy: 70.27%, Test Loss: 1.0106, Test Accuracy: 67.09%\n",
      "Epoch [1145/2500], Train Loss: 0.6652, Train Accuracy: 70.27%, Test Loss: 1.0024, Test Accuracy: 68.35%\n",
      "Epoch [1146/2500], Train Loss: 0.6683, Train Accuracy: 69.56%, Test Loss: 1.0000, Test Accuracy: 69.62%\n",
      "Epoch [1147/2500], Train Loss: 0.6713, Train Accuracy: 69.84%, Test Loss: 0.9481, Test Accuracy: 69.62%\n",
      "Epoch [1148/2500], Train Loss: 0.6622, Train Accuracy: 71.41%, Test Loss: 0.9851, Test Accuracy: 70.89%\n",
      "Epoch [1149/2500], Train Loss: 0.6502, Train Accuracy: 73.68%, Test Loss: 1.0075, Test Accuracy: 68.35%\n",
      "Epoch [1150/2500], Train Loss: 0.6644, Train Accuracy: 71.83%, Test Loss: 0.9959, Test Accuracy: 70.89%\n",
      "Epoch [1151/2500], Train Loss: 0.6625, Train Accuracy: 71.55%, Test Loss: 1.0105, Test Accuracy: 67.09%\n",
      "Epoch [1152/2500], Train Loss: 0.6507, Train Accuracy: 71.12%, Test Loss: 0.9905, Test Accuracy: 68.35%\n",
      "Epoch [1153/2500], Train Loss: 0.6741, Train Accuracy: 72.26%, Test Loss: 1.0235, Test Accuracy: 67.09%\n",
      "Epoch [1154/2500], Train Loss: 0.6957, Train Accuracy: 69.56%, Test Loss: 0.9516, Test Accuracy: 67.09%\n",
      "Epoch [1155/2500], Train Loss: 0.6755, Train Accuracy: 70.41%, Test Loss: 1.0091, Test Accuracy: 65.82%\n",
      "Epoch [1156/2500], Train Loss: 0.6662, Train Accuracy: 69.99%, Test Loss: 0.9926, Test Accuracy: 67.09%\n",
      "Epoch [1157/2500], Train Loss: 0.6726, Train Accuracy: 71.69%, Test Loss: 0.9773, Test Accuracy: 68.35%\n",
      "Epoch [1158/2500], Train Loss: 0.6570, Train Accuracy: 69.99%, Test Loss: 0.9667, Test Accuracy: 68.35%\n",
      "Epoch [1159/2500], Train Loss: 0.6639, Train Accuracy: 72.69%, Test Loss: 0.9872, Test Accuracy: 67.09%\n",
      "Epoch [1160/2500], Train Loss: 0.6920, Train Accuracy: 69.42%, Test Loss: 0.9712, Test Accuracy: 65.82%\n",
      "Epoch [1161/2500], Train Loss: 0.6561, Train Accuracy: 74.11%, Test Loss: 0.9994, Test Accuracy: 65.82%\n",
      "Epoch [1162/2500], Train Loss: 0.6822, Train Accuracy: 68.71%, Test Loss: 0.9956, Test Accuracy: 65.82%\n",
      "Epoch [1163/2500], Train Loss: 0.6688, Train Accuracy: 70.41%, Test Loss: 0.9652, Test Accuracy: 65.82%\n",
      "Epoch [1164/2500], Train Loss: 0.6588, Train Accuracy: 73.12%, Test Loss: 1.0398, Test Accuracy: 67.09%\n",
      "Epoch [1165/2500], Train Loss: 0.6389, Train Accuracy: 71.98%, Test Loss: 1.0122, Test Accuracy: 67.09%\n",
      "Epoch [1166/2500], Train Loss: 0.6506, Train Accuracy: 70.27%, Test Loss: 1.0011, Test Accuracy: 67.09%\n",
      "Epoch [1167/2500], Train Loss: 0.6758, Train Accuracy: 71.83%, Test Loss: 0.9806, Test Accuracy: 67.09%\n",
      "Epoch [1168/2500], Train Loss: 0.6637, Train Accuracy: 69.99%, Test Loss: 1.0257, Test Accuracy: 67.09%\n",
      "Epoch [1169/2500], Train Loss: 0.6749, Train Accuracy: 70.13%, Test Loss: 1.0306, Test Accuracy: 65.82%\n",
      "Epoch [1170/2500], Train Loss: 0.6637, Train Accuracy: 70.41%, Test Loss: 1.0022, Test Accuracy: 68.35%\n",
      "Epoch [1171/2500], Train Loss: 0.6669, Train Accuracy: 70.70%, Test Loss: 1.0056, Test Accuracy: 69.62%\n",
      "Epoch [1172/2500], Train Loss: 0.6442, Train Accuracy: 74.25%, Test Loss: 1.0375, Test Accuracy: 67.09%\n",
      "Epoch [1173/2500], Train Loss: 0.6557, Train Accuracy: 72.55%, Test Loss: 1.0291, Test Accuracy: 70.89%\n",
      "Epoch [1174/2500], Train Loss: 0.6630, Train Accuracy: 71.27%, Test Loss: 1.0275, Test Accuracy: 68.35%\n",
      "Epoch [1175/2500], Train Loss: 0.6742, Train Accuracy: 71.41%, Test Loss: 0.9820, Test Accuracy: 69.62%\n",
      "Epoch [1176/2500], Train Loss: 0.6938, Train Accuracy: 70.13%, Test Loss: 0.9798, Test Accuracy: 69.62%\n",
      "Epoch [1177/2500], Train Loss: 0.6564, Train Accuracy: 70.98%, Test Loss: 1.0103, Test Accuracy: 67.09%\n",
      "Epoch [1178/2500], Train Loss: 0.6625, Train Accuracy: 70.70%, Test Loss: 0.9979, Test Accuracy: 67.09%\n",
      "Epoch [1179/2500], Train Loss: 0.6562, Train Accuracy: 73.12%, Test Loss: 0.9986, Test Accuracy: 68.35%\n",
      "Epoch [1180/2500], Train Loss: 0.6503, Train Accuracy: 72.26%, Test Loss: 1.0332, Test Accuracy: 68.35%\n",
      "Epoch [1181/2500], Train Loss: 0.6601, Train Accuracy: 71.41%, Test Loss: 1.0241, Test Accuracy: 67.09%\n",
      "Epoch [1182/2500], Train Loss: 0.6752, Train Accuracy: 71.98%, Test Loss: 0.9836, Test Accuracy: 67.09%\n",
      "Epoch [1183/2500], Train Loss: 0.6502, Train Accuracy: 71.12%, Test Loss: 0.9787, Test Accuracy: 69.62%\n",
      "Epoch [1184/2500], Train Loss: 0.6926, Train Accuracy: 70.41%, Test Loss: 0.9825, Test Accuracy: 69.62%\n",
      "Epoch [1185/2500], Train Loss: 0.6454, Train Accuracy: 70.84%, Test Loss: 1.0102, Test Accuracy: 68.35%\n",
      "Epoch [1186/2500], Train Loss: 0.6718, Train Accuracy: 70.13%, Test Loss: 1.0021, Test Accuracy: 68.35%\n",
      "Epoch [1187/2500], Train Loss: 0.6642, Train Accuracy: 69.42%, Test Loss: 0.9876, Test Accuracy: 68.35%\n",
      "Epoch [1188/2500], Train Loss: 0.6479, Train Accuracy: 71.55%, Test Loss: 1.0258, Test Accuracy: 68.35%\n",
      "Epoch [1189/2500], Train Loss: 0.6809, Train Accuracy: 71.41%, Test Loss: 0.9937, Test Accuracy: 67.09%\n",
      "Epoch [1190/2500], Train Loss: 0.6597, Train Accuracy: 70.84%, Test Loss: 0.9692, Test Accuracy: 67.09%\n",
      "Epoch [1191/2500], Train Loss: 0.6893, Train Accuracy: 71.69%, Test Loss: 0.9866, Test Accuracy: 68.35%\n",
      "Epoch [1192/2500], Train Loss: 0.6713, Train Accuracy: 68.42%, Test Loss: 0.9762, Test Accuracy: 65.82%\n",
      "Epoch [1193/2500], Train Loss: 0.6620, Train Accuracy: 71.98%, Test Loss: 1.0507, Test Accuracy: 65.82%\n",
      "Epoch [1194/2500], Train Loss: 0.6750, Train Accuracy: 71.83%, Test Loss: 1.0060, Test Accuracy: 67.09%\n",
      "Epoch [1195/2500], Train Loss: 0.6477, Train Accuracy: 69.84%, Test Loss: 0.9459, Test Accuracy: 69.62%\n",
      "Epoch [1196/2500], Train Loss: 0.6786, Train Accuracy: 69.99%, Test Loss: 0.9729, Test Accuracy: 68.35%\n",
      "Epoch [1197/2500], Train Loss: 0.6704, Train Accuracy: 71.69%, Test Loss: 0.9402, Test Accuracy: 68.35%\n",
      "Epoch [1198/2500], Train Loss: 0.6556, Train Accuracy: 70.13%, Test Loss: 0.9806, Test Accuracy: 65.82%\n",
      "Epoch [1199/2500], Train Loss: 0.6659, Train Accuracy: 70.55%, Test Loss: 1.0300, Test Accuracy: 67.09%\n",
      "Epoch [1200/2500], Train Loss: 0.6558, Train Accuracy: 71.69%, Test Loss: 0.9719, Test Accuracy: 68.35%\n",
      "Epoch [1201/2500], Train Loss: 0.6550, Train Accuracy: 74.25%, Test Loss: 0.9411, Test Accuracy: 68.35%\n",
      "Epoch [1202/2500], Train Loss: 0.6671, Train Accuracy: 69.84%, Test Loss: 1.0012, Test Accuracy: 67.09%\n",
      "Epoch [1203/2500], Train Loss: 0.6437, Train Accuracy: 71.41%, Test Loss: 0.9643, Test Accuracy: 69.62%\n",
      "Epoch [1204/2500], Train Loss: 0.6838, Train Accuracy: 69.84%, Test Loss: 0.9879, Test Accuracy: 67.09%\n",
      "Epoch [1205/2500], Train Loss: 0.6670, Train Accuracy: 70.84%, Test Loss: 0.9701, Test Accuracy: 67.09%\n",
      "Epoch [1206/2500], Train Loss: 0.6709, Train Accuracy: 71.55%, Test Loss: 0.9631, Test Accuracy: 67.09%\n",
      "Epoch [1207/2500], Train Loss: 0.6486, Train Accuracy: 71.83%, Test Loss: 0.9321, Test Accuracy: 68.35%\n",
      "Epoch [1208/2500], Train Loss: 0.6877, Train Accuracy: 69.42%, Test Loss: 0.9821, Test Accuracy: 68.35%\n",
      "Epoch [1209/2500], Train Loss: 0.6418, Train Accuracy: 71.41%, Test Loss: 0.9393, Test Accuracy: 72.15%\n",
      "Epoch [1210/2500], Train Loss: 0.6882, Train Accuracy: 69.13%, Test Loss: 1.0208, Test Accuracy: 68.35%\n",
      "Epoch [1211/2500], Train Loss: 0.6849, Train Accuracy: 69.70%, Test Loss: 0.9635, Test Accuracy: 70.89%\n",
      "Epoch [1212/2500], Train Loss: 0.6491, Train Accuracy: 71.27%, Test Loss: 0.9445, Test Accuracy: 70.89%\n",
      "Epoch [1213/2500], Train Loss: 0.6604, Train Accuracy: 71.27%, Test Loss: 1.0058, Test Accuracy: 65.82%\n",
      "Epoch [1214/2500], Train Loss: 0.6775, Train Accuracy: 68.42%, Test Loss: 0.9847, Test Accuracy: 67.09%\n",
      "Epoch [1215/2500], Train Loss: 0.6705, Train Accuracy: 70.27%, Test Loss: 0.9835, Test Accuracy: 67.09%\n",
      "Epoch [1216/2500], Train Loss: 0.6405, Train Accuracy: 72.12%, Test Loss: 1.0259, Test Accuracy: 67.09%\n",
      "Epoch [1217/2500], Train Loss: 0.6652, Train Accuracy: 70.84%, Test Loss: 0.9622, Test Accuracy: 68.35%\n",
      "Epoch [1218/2500], Train Loss: 0.6514, Train Accuracy: 70.13%, Test Loss: 1.0104, Test Accuracy: 68.35%\n",
      "Epoch [1219/2500], Train Loss: 0.6549, Train Accuracy: 71.41%, Test Loss: 1.0010, Test Accuracy: 67.09%\n",
      "Epoch [1220/2500], Train Loss: 0.6667, Train Accuracy: 69.70%, Test Loss: 0.9789, Test Accuracy: 68.35%\n",
      "Epoch [1221/2500], Train Loss: 0.6533, Train Accuracy: 71.41%, Test Loss: 0.9589, Test Accuracy: 69.62%\n",
      "Epoch [1222/2500], Train Loss: 0.6564, Train Accuracy: 71.12%, Test Loss: 0.9751, Test Accuracy: 67.09%\n",
      "Epoch [1223/2500], Train Loss: 0.6674, Train Accuracy: 69.56%, Test Loss: 1.0465, Test Accuracy: 68.35%\n",
      "Epoch [1224/2500], Train Loss: 0.6773, Train Accuracy: 70.84%, Test Loss: 0.9680, Test Accuracy: 67.09%\n",
      "Epoch [1225/2500], Train Loss: 0.7021, Train Accuracy: 70.84%, Test Loss: 0.9924, Test Accuracy: 65.82%\n",
      "Epoch [1226/2500], Train Loss: 0.6733, Train Accuracy: 71.41%, Test Loss: 0.9645, Test Accuracy: 68.35%\n",
      "Epoch [1227/2500], Train Loss: 0.6661, Train Accuracy: 70.55%, Test Loss: 0.9793, Test Accuracy: 68.35%\n",
      "Epoch [1228/2500], Train Loss: 0.6882, Train Accuracy: 71.41%, Test Loss: 0.9748, Test Accuracy: 68.35%\n",
      "Epoch [1229/2500], Train Loss: 0.6788, Train Accuracy: 69.56%, Test Loss: 0.9662, Test Accuracy: 70.89%\n",
      "Epoch [1230/2500], Train Loss: 0.6767, Train Accuracy: 69.56%, Test Loss: 0.9531, Test Accuracy: 67.09%\n",
      "Epoch [1231/2500], Train Loss: 0.6653, Train Accuracy: 70.98%, Test Loss: 1.0163, Test Accuracy: 67.09%\n",
      "Epoch [1232/2500], Train Loss: 0.6248, Train Accuracy: 72.83%, Test Loss: 1.0625, Test Accuracy: 67.09%\n",
      "Epoch [1233/2500], Train Loss: 0.6729, Train Accuracy: 71.27%, Test Loss: 0.9756, Test Accuracy: 67.09%\n",
      "Epoch [1234/2500], Train Loss: 0.6547, Train Accuracy: 72.12%, Test Loss: 0.9849, Test Accuracy: 67.09%\n",
      "Epoch [1235/2500], Train Loss: 0.6469, Train Accuracy: 72.83%, Test Loss: 0.9723, Test Accuracy: 67.09%\n",
      "Epoch [1236/2500], Train Loss: 0.6325, Train Accuracy: 71.27%, Test Loss: 0.9611, Test Accuracy: 68.35%\n",
      "Epoch [1237/2500], Train Loss: 0.6687, Train Accuracy: 71.55%, Test Loss: 0.9878, Test Accuracy: 65.82%\n",
      "Epoch [1238/2500], Train Loss: 0.6609, Train Accuracy: 71.98%, Test Loss: 0.9571, Test Accuracy: 70.89%\n",
      "Epoch [1239/2500], Train Loss: 0.6681, Train Accuracy: 70.70%, Test Loss: 0.9945, Test Accuracy: 65.82%\n",
      "Epoch [1240/2500], Train Loss: 0.6711, Train Accuracy: 71.98%, Test Loss: 0.9816, Test Accuracy: 69.62%\n",
      "Epoch [1241/2500], Train Loss: 0.6671, Train Accuracy: 71.27%, Test Loss: 0.9982, Test Accuracy: 68.35%\n",
      "Epoch [1242/2500], Train Loss: 0.6610, Train Accuracy: 71.41%, Test Loss: 0.9734, Test Accuracy: 64.56%\n",
      "Epoch [1243/2500], Train Loss: 0.6543, Train Accuracy: 71.69%, Test Loss: 0.9617, Test Accuracy: 67.09%\n",
      "Epoch [1244/2500], Train Loss: 0.6570, Train Accuracy: 71.27%, Test Loss: 1.0219, Test Accuracy: 65.82%\n",
      "Epoch [1245/2500], Train Loss: 0.6598, Train Accuracy: 72.69%, Test Loss: 1.0057, Test Accuracy: 65.82%\n",
      "Epoch [1246/2500], Train Loss: 0.6603, Train Accuracy: 72.26%, Test Loss: 1.0066, Test Accuracy: 67.09%\n",
      "Epoch [1247/2500], Train Loss: 0.6646, Train Accuracy: 71.12%, Test Loss: 0.9669, Test Accuracy: 68.35%\n",
      "Epoch [1248/2500], Train Loss: 0.6551, Train Accuracy: 71.98%, Test Loss: 0.9913, Test Accuracy: 67.09%\n",
      "Epoch [1249/2500], Train Loss: 0.6493, Train Accuracy: 71.98%, Test Loss: 0.9933, Test Accuracy: 69.62%\n",
      "Epoch [1250/2500], Train Loss: 0.6565, Train Accuracy: 70.70%, Test Loss: 0.9679, Test Accuracy: 69.62%\n",
      "Epoch [1251/2500], Train Loss: 0.6393, Train Accuracy: 72.40%, Test Loss: 0.9577, Test Accuracy: 67.09%\n",
      "Epoch [1252/2500], Train Loss: 0.6763, Train Accuracy: 71.83%, Test Loss: 0.9920, Test Accuracy: 67.09%\n",
      "Epoch [1253/2500], Train Loss: 0.6585, Train Accuracy: 71.41%, Test Loss: 1.0172, Test Accuracy: 67.09%\n",
      "Epoch [1254/2500], Train Loss: 0.6292, Train Accuracy: 73.12%, Test Loss: 0.9753, Test Accuracy: 70.89%\n",
      "Epoch [1255/2500], Train Loss: 0.6495, Train Accuracy: 71.69%, Test Loss: 0.9947, Test Accuracy: 68.35%\n",
      "Epoch [1256/2500], Train Loss: 0.6351, Train Accuracy: 71.69%, Test Loss: 1.0033, Test Accuracy: 67.09%\n",
      "Epoch [1257/2500], Train Loss: 0.6498, Train Accuracy: 71.55%, Test Loss: 1.0116, Test Accuracy: 65.82%\n",
      "Epoch [1258/2500], Train Loss: 0.6460, Train Accuracy: 72.40%, Test Loss: 0.9732, Test Accuracy: 67.09%\n",
      "Epoch [1259/2500], Train Loss: 0.6618, Train Accuracy: 70.41%, Test Loss: 0.9799, Test Accuracy: 65.82%\n",
      "Epoch [1260/2500], Train Loss: 0.6815, Train Accuracy: 72.69%, Test Loss: 1.0422, Test Accuracy: 67.09%\n",
      "Epoch [1261/2500], Train Loss: 0.6484, Train Accuracy: 71.98%, Test Loss: 1.0035, Test Accuracy: 68.35%\n",
      "Epoch [1262/2500], Train Loss: 0.6568, Train Accuracy: 69.84%, Test Loss: 0.9839, Test Accuracy: 69.62%\n",
      "Epoch [1263/2500], Train Loss: 0.6549, Train Accuracy: 70.41%, Test Loss: 0.9780, Test Accuracy: 69.62%\n",
      "Epoch [1264/2500], Train Loss: 0.6362, Train Accuracy: 73.83%, Test Loss: 1.0322, Test Accuracy: 68.35%\n",
      "Epoch [1265/2500], Train Loss: 0.6998, Train Accuracy: 69.27%, Test Loss: 0.9896, Test Accuracy: 68.35%\n",
      "Epoch [1266/2500], Train Loss: 0.6332, Train Accuracy: 72.26%, Test Loss: 1.0137, Test Accuracy: 67.09%\n",
      "Epoch [1267/2500], Train Loss: 0.6332, Train Accuracy: 70.55%, Test Loss: 0.9883, Test Accuracy: 70.89%\n",
      "Epoch [1268/2500], Train Loss: 0.6460, Train Accuracy: 71.41%, Test Loss: 1.0730, Test Accuracy: 67.09%\n",
      "Epoch [1269/2500], Train Loss: 0.6515, Train Accuracy: 70.41%, Test Loss: 0.9882, Test Accuracy: 68.35%\n",
      "Epoch [1270/2500], Train Loss: 0.6486, Train Accuracy: 72.40%, Test Loss: 0.9940, Test Accuracy: 70.89%\n",
      "Epoch [1271/2500], Train Loss: 0.6644, Train Accuracy: 70.13%, Test Loss: 1.0090, Test Accuracy: 69.62%\n",
      "Epoch [1272/2500], Train Loss: 0.6350, Train Accuracy: 72.40%, Test Loss: 0.9975, Test Accuracy: 67.09%\n",
      "Epoch [1273/2500], Train Loss: 0.6271, Train Accuracy: 72.97%, Test Loss: 1.0098, Test Accuracy: 69.62%\n",
      "Epoch [1274/2500], Train Loss: 0.6267, Train Accuracy: 73.12%, Test Loss: 1.0329, Test Accuracy: 68.35%\n",
      "Epoch [1275/2500], Train Loss: 0.6240, Train Accuracy: 73.12%, Test Loss: 1.0149, Test Accuracy: 70.89%\n",
      "Epoch [1276/2500], Train Loss: 0.6382, Train Accuracy: 70.98%, Test Loss: 1.0155, Test Accuracy: 68.35%\n",
      "Epoch [1277/2500], Train Loss: 0.6480, Train Accuracy: 74.25%, Test Loss: 0.9957, Test Accuracy: 70.89%\n",
      "Epoch [1278/2500], Train Loss: 0.6474, Train Accuracy: 72.55%, Test Loss: 0.9957, Test Accuracy: 67.09%\n",
      "Epoch [1279/2500], Train Loss: 0.6588, Train Accuracy: 72.40%, Test Loss: 0.9659, Test Accuracy: 69.62%\n",
      "Epoch [1280/2500], Train Loss: 0.6645, Train Accuracy: 71.27%, Test Loss: 0.9952, Test Accuracy: 68.35%\n",
      "Epoch [1281/2500], Train Loss: 0.6488, Train Accuracy: 71.12%, Test Loss: 1.0209, Test Accuracy: 68.35%\n",
      "Epoch [1282/2500], Train Loss: 0.6795, Train Accuracy: 70.98%, Test Loss: 0.9896, Test Accuracy: 69.62%\n",
      "Epoch [1283/2500], Train Loss: 0.6297, Train Accuracy: 72.40%, Test Loss: 1.0357, Test Accuracy: 67.09%\n",
      "Epoch [1284/2500], Train Loss: 0.6676, Train Accuracy: 69.99%, Test Loss: 1.0161, Test Accuracy: 65.82%\n",
      "Epoch [1285/2500], Train Loss: 0.6450, Train Accuracy: 71.41%, Test Loss: 1.0558, Test Accuracy: 67.09%\n",
      "Epoch [1286/2500], Train Loss: 0.6884, Train Accuracy: 69.56%, Test Loss: 0.9686, Test Accuracy: 70.89%\n",
      "Epoch [1287/2500], Train Loss: 0.6545, Train Accuracy: 70.70%, Test Loss: 1.0448, Test Accuracy: 65.82%\n",
      "Epoch [1288/2500], Train Loss: 0.6646, Train Accuracy: 71.83%, Test Loss: 1.0292, Test Accuracy: 69.62%\n",
      "Epoch [1289/2500], Train Loss: 0.6767, Train Accuracy: 70.55%, Test Loss: 0.9836, Test Accuracy: 65.82%\n",
      "Epoch [1290/2500], Train Loss: 0.6532, Train Accuracy: 71.98%, Test Loss: 1.0192, Test Accuracy: 68.35%\n",
      "Epoch [1291/2500], Train Loss: 0.6461, Train Accuracy: 71.98%, Test Loss: 1.0338, Test Accuracy: 68.35%\n",
      "Epoch [1292/2500], Train Loss: 0.6436, Train Accuracy: 70.55%, Test Loss: 1.0480, Test Accuracy: 67.09%\n",
      "Epoch [1293/2500], Train Loss: 0.6689, Train Accuracy: 72.26%, Test Loss: 1.0443, Test Accuracy: 65.82%\n",
      "Epoch [1294/2500], Train Loss: 0.6482, Train Accuracy: 72.97%, Test Loss: 1.0288, Test Accuracy: 69.62%\n",
      "Epoch [1295/2500], Train Loss: 0.6588, Train Accuracy: 70.98%, Test Loss: 1.0504, Test Accuracy: 67.09%\n",
      "Epoch [1296/2500], Train Loss: 0.6527, Train Accuracy: 69.70%, Test Loss: 1.0144, Test Accuracy: 68.35%\n",
      "Epoch [1297/2500], Train Loss: 0.6548, Train Accuracy: 71.98%, Test Loss: 0.9925, Test Accuracy: 69.62%\n",
      "Epoch [1298/2500], Train Loss: 0.6708, Train Accuracy: 70.55%, Test Loss: 0.9914, Test Accuracy: 69.62%\n",
      "Epoch [1299/2500], Train Loss: 0.6611, Train Accuracy: 71.41%, Test Loss: 1.0280, Test Accuracy: 67.09%\n",
      "Epoch [1300/2500], Train Loss: 0.6508, Train Accuracy: 71.98%, Test Loss: 1.0196, Test Accuracy: 69.62%\n",
      "Epoch [1301/2500], Train Loss: 0.6577, Train Accuracy: 69.70%, Test Loss: 1.0255, Test Accuracy: 67.09%\n",
      "Epoch [1302/2500], Train Loss: 0.6391, Train Accuracy: 71.69%, Test Loss: 0.9812, Test Accuracy: 69.62%\n",
      "Epoch [1303/2500], Train Loss: 0.6575, Train Accuracy: 70.27%, Test Loss: 1.0188, Test Accuracy: 67.09%\n",
      "Epoch [1304/2500], Train Loss: 0.6675, Train Accuracy: 69.84%, Test Loss: 1.0097, Test Accuracy: 67.09%\n",
      "Epoch [1305/2500], Train Loss: 0.6323, Train Accuracy: 70.70%, Test Loss: 1.0517, Test Accuracy: 64.56%\n",
      "Epoch [1306/2500], Train Loss: 0.6642, Train Accuracy: 70.41%, Test Loss: 1.0351, Test Accuracy: 65.82%\n",
      "Epoch [1307/2500], Train Loss: 0.6642, Train Accuracy: 71.41%, Test Loss: 1.0080, Test Accuracy: 67.09%\n",
      "Epoch [1308/2500], Train Loss: 0.6796, Train Accuracy: 70.84%, Test Loss: 1.0195, Test Accuracy: 65.82%\n",
      "Epoch [1309/2500], Train Loss: 0.6540, Train Accuracy: 70.98%, Test Loss: 1.0103, Test Accuracy: 64.56%\n",
      "Epoch [1310/2500], Train Loss: 0.6362, Train Accuracy: 72.12%, Test Loss: 1.0237, Test Accuracy: 67.09%\n",
      "Epoch [1311/2500], Train Loss: 0.6390, Train Accuracy: 72.97%, Test Loss: 1.0492, Test Accuracy: 67.09%\n",
      "Epoch [1312/2500], Train Loss: 0.6407, Train Accuracy: 70.84%, Test Loss: 1.0030, Test Accuracy: 68.35%\n",
      "Epoch [1313/2500], Train Loss: 0.6832, Train Accuracy: 70.41%, Test Loss: 0.9887, Test Accuracy: 67.09%\n",
      "Epoch [1314/2500], Train Loss: 0.6327, Train Accuracy: 72.40%, Test Loss: 1.0298, Test Accuracy: 65.82%\n",
      "Epoch [1315/2500], Train Loss: 0.6795, Train Accuracy: 72.69%, Test Loss: 0.9987, Test Accuracy: 65.82%\n",
      "Epoch [1316/2500], Train Loss: 0.6500, Train Accuracy: 71.27%, Test Loss: 1.0012, Test Accuracy: 68.35%\n",
      "Epoch [1317/2500], Train Loss: 0.6437, Train Accuracy: 72.55%, Test Loss: 1.0309, Test Accuracy: 69.62%\n",
      "Epoch [1318/2500], Train Loss: 0.6569, Train Accuracy: 72.83%, Test Loss: 1.0161, Test Accuracy: 68.35%\n",
      "Epoch [1319/2500], Train Loss: 0.6236, Train Accuracy: 70.84%, Test Loss: 1.0426, Test Accuracy: 65.82%\n",
      "Epoch [1320/2500], Train Loss: 0.6402, Train Accuracy: 72.97%, Test Loss: 1.0301, Test Accuracy: 65.82%\n",
      "Epoch [1321/2500], Train Loss: 0.6660, Train Accuracy: 71.41%, Test Loss: 1.0350, Test Accuracy: 67.09%\n",
      "Epoch [1322/2500], Train Loss: 0.6344, Train Accuracy: 71.83%, Test Loss: 1.0152, Test Accuracy: 65.82%\n",
      "Epoch [1323/2500], Train Loss: 0.6406, Train Accuracy: 73.40%, Test Loss: 1.0369, Test Accuracy: 67.09%\n",
      "Epoch [1324/2500], Train Loss: 0.6367, Train Accuracy: 72.97%, Test Loss: 1.0815, Test Accuracy: 65.82%\n",
      "Epoch [1325/2500], Train Loss: 0.6361, Train Accuracy: 73.40%, Test Loss: 1.0423, Test Accuracy: 67.09%\n",
      "Epoch [1326/2500], Train Loss: 0.6592, Train Accuracy: 69.70%, Test Loss: 1.0494, Test Accuracy: 68.35%\n",
      "Epoch [1327/2500], Train Loss: 0.6879, Train Accuracy: 69.56%, Test Loss: 1.0082, Test Accuracy: 65.82%\n",
      "Epoch [1328/2500], Train Loss: 0.6308, Train Accuracy: 71.27%, Test Loss: 0.9893, Test Accuracy: 69.62%\n",
      "Epoch [1329/2500], Train Loss: 0.6433, Train Accuracy: 73.54%, Test Loss: 0.9955, Test Accuracy: 69.62%\n",
      "Epoch [1330/2500], Train Loss: 0.6474, Train Accuracy: 72.55%, Test Loss: 1.0490, Test Accuracy: 67.09%\n",
      "Epoch [1331/2500], Train Loss: 0.6262, Train Accuracy: 70.84%, Test Loss: 1.0141, Test Accuracy: 67.09%\n",
      "Epoch [1332/2500], Train Loss: 0.6593, Train Accuracy: 70.27%, Test Loss: 1.1070, Test Accuracy: 68.35%\n",
      "Epoch [1333/2500], Train Loss: 0.6667, Train Accuracy: 69.56%, Test Loss: 1.0177, Test Accuracy: 68.35%\n",
      "Epoch [1334/2500], Train Loss: 0.6744, Train Accuracy: 71.12%, Test Loss: 0.9790, Test Accuracy: 69.62%\n",
      "Epoch [1335/2500], Train Loss: 0.6404, Train Accuracy: 71.98%, Test Loss: 1.0238, Test Accuracy: 68.35%\n",
      "Epoch [1336/2500], Train Loss: 0.6541, Train Accuracy: 71.83%, Test Loss: 0.9823, Test Accuracy: 68.35%\n",
      "Epoch [1337/2500], Train Loss: 0.6327, Train Accuracy: 72.97%, Test Loss: 1.0495, Test Accuracy: 65.82%\n",
      "Epoch [1338/2500], Train Loss: 0.6346, Train Accuracy: 72.97%, Test Loss: 1.0705, Test Accuracy: 65.82%\n",
      "Epoch [1339/2500], Train Loss: 0.6337, Train Accuracy: 72.12%, Test Loss: 1.1018, Test Accuracy: 64.56%\n",
      "Epoch [1340/2500], Train Loss: 0.6536, Train Accuracy: 71.98%, Test Loss: 1.0373, Test Accuracy: 67.09%\n",
      "Epoch [1341/2500], Train Loss: 0.6067, Train Accuracy: 73.40%, Test Loss: 1.0723, Test Accuracy: 67.09%\n",
      "Epoch [1342/2500], Train Loss: 0.6202, Train Accuracy: 72.40%, Test Loss: 1.0702, Test Accuracy: 68.35%\n",
      "Epoch [1343/2500], Train Loss: 0.6520, Train Accuracy: 71.55%, Test Loss: 1.0140, Test Accuracy: 67.09%\n",
      "Epoch [1344/2500], Train Loss: 0.6270, Train Accuracy: 71.83%, Test Loss: 1.0214, Test Accuracy: 67.09%\n",
      "Epoch [1345/2500], Train Loss: 0.6468, Train Accuracy: 69.56%, Test Loss: 1.0081, Test Accuracy: 65.82%\n",
      "Epoch [1346/2500], Train Loss: 0.6548, Train Accuracy: 70.41%, Test Loss: 1.0155, Test Accuracy: 65.82%\n",
      "Epoch [1347/2500], Train Loss: 0.6735, Train Accuracy: 70.27%, Test Loss: 1.0128, Test Accuracy: 68.35%\n",
      "Epoch [1348/2500], Train Loss: 0.6407, Train Accuracy: 71.12%, Test Loss: 1.0128, Test Accuracy: 65.82%\n",
      "Epoch [1349/2500], Train Loss: 0.6474, Train Accuracy: 71.41%, Test Loss: 1.0102, Test Accuracy: 65.82%\n",
      "Epoch [1350/2500], Train Loss: 0.6406, Train Accuracy: 71.83%, Test Loss: 1.0285, Test Accuracy: 67.09%\n",
      "Epoch [1351/2500], Train Loss: 0.6459, Train Accuracy: 72.55%, Test Loss: 1.0263, Test Accuracy: 65.82%\n",
      "Epoch [1352/2500], Train Loss: 0.6577, Train Accuracy: 72.83%, Test Loss: 1.0055, Test Accuracy: 67.09%\n",
      "Epoch [1353/2500], Train Loss: 0.6546, Train Accuracy: 70.41%, Test Loss: 0.9885, Test Accuracy: 68.35%\n",
      "Epoch [1354/2500], Train Loss: 0.6319, Train Accuracy: 71.12%, Test Loss: 0.9874, Test Accuracy: 68.35%\n",
      "Epoch [1355/2500], Train Loss: 0.6298, Train Accuracy: 73.26%, Test Loss: 1.0723, Test Accuracy: 65.82%\n",
      "Epoch [1356/2500], Train Loss: 0.6515, Train Accuracy: 71.55%, Test Loss: 1.0374, Test Accuracy: 64.56%\n",
      "Epoch [1357/2500], Train Loss: 0.6784, Train Accuracy: 70.55%, Test Loss: 1.0654, Test Accuracy: 64.56%\n",
      "Epoch [1358/2500], Train Loss: 0.6706, Train Accuracy: 71.83%, Test Loss: 1.0461, Test Accuracy: 67.09%\n",
      "Epoch [1359/2500], Train Loss: 0.6464, Train Accuracy: 71.12%, Test Loss: 1.0596, Test Accuracy: 67.09%\n",
      "Epoch [1360/2500], Train Loss: 0.6486, Train Accuracy: 73.97%, Test Loss: 1.0637, Test Accuracy: 67.09%\n",
      "Epoch [1361/2500], Train Loss: 0.6192, Train Accuracy: 72.12%, Test Loss: 1.0332, Test Accuracy: 67.09%\n",
      "Epoch [1362/2500], Train Loss: 0.6445, Train Accuracy: 69.42%, Test Loss: 1.0461, Test Accuracy: 69.62%\n",
      "Epoch [1363/2500], Train Loss: 0.6450, Train Accuracy: 71.98%, Test Loss: 0.9960, Test Accuracy: 68.35%\n",
      "Epoch [1364/2500], Train Loss: 0.6695, Train Accuracy: 69.70%, Test Loss: 1.0498, Test Accuracy: 67.09%\n",
      "Epoch [1365/2500], Train Loss: 0.6388, Train Accuracy: 72.40%, Test Loss: 1.0022, Test Accuracy: 68.35%\n",
      "Epoch [1366/2500], Train Loss: 0.6452, Train Accuracy: 73.83%, Test Loss: 1.0539, Test Accuracy: 67.09%\n",
      "Epoch [1367/2500], Train Loss: 0.6352, Train Accuracy: 73.68%, Test Loss: 1.0179, Test Accuracy: 67.09%\n",
      "Epoch [1368/2500], Train Loss: 0.6343, Train Accuracy: 73.26%, Test Loss: 0.9840, Test Accuracy: 67.09%\n",
      "Epoch [1369/2500], Train Loss: 0.6688, Train Accuracy: 71.69%, Test Loss: 1.0611, Test Accuracy: 65.82%\n",
      "Epoch [1370/2500], Train Loss: 0.6366, Train Accuracy: 71.69%, Test Loss: 0.9738, Test Accuracy: 70.89%\n",
      "Epoch [1371/2500], Train Loss: 0.6478, Train Accuracy: 71.12%, Test Loss: 1.0273, Test Accuracy: 65.82%\n",
      "Epoch [1372/2500], Train Loss: 0.6609, Train Accuracy: 71.41%, Test Loss: 0.9717, Test Accuracy: 70.89%\n",
      "Epoch [1373/2500], Train Loss: 0.6435, Train Accuracy: 71.98%, Test Loss: 1.0209, Test Accuracy: 65.82%\n",
      "Epoch [1374/2500], Train Loss: 0.6389, Train Accuracy: 72.55%, Test Loss: 1.0505, Test Accuracy: 70.89%\n",
      "Epoch [1375/2500], Train Loss: 0.6506, Train Accuracy: 71.83%, Test Loss: 1.0584, Test Accuracy: 64.56%\n",
      "Epoch [1376/2500], Train Loss: 0.6271, Train Accuracy: 70.84%, Test Loss: 1.0503, Test Accuracy: 67.09%\n",
      "Epoch [1377/2500], Train Loss: 0.6499, Train Accuracy: 71.55%, Test Loss: 1.0328, Test Accuracy: 70.89%\n",
      "Epoch [1378/2500], Train Loss: 0.6303, Train Accuracy: 72.26%, Test Loss: 1.0268, Test Accuracy: 67.09%\n",
      "Epoch [1379/2500], Train Loss: 0.6785, Train Accuracy: 69.13%, Test Loss: 1.0366, Test Accuracy: 68.35%\n",
      "Epoch [1380/2500], Train Loss: 0.6460, Train Accuracy: 70.84%, Test Loss: 1.0400, Test Accuracy: 68.35%\n",
      "Epoch [1381/2500], Train Loss: 0.6373, Train Accuracy: 71.55%, Test Loss: 1.0642, Test Accuracy: 68.35%\n",
      "Epoch [1382/2500], Train Loss: 0.6343, Train Accuracy: 71.41%, Test Loss: 1.0576, Test Accuracy: 65.82%\n",
      "Epoch [1383/2500], Train Loss: 0.6413, Train Accuracy: 73.26%, Test Loss: 1.0372, Test Accuracy: 65.82%\n",
      "Epoch [1384/2500], Train Loss: 0.6448, Train Accuracy: 72.55%, Test Loss: 1.0133, Test Accuracy: 67.09%\n",
      "Epoch [1385/2500], Train Loss: 0.6378, Train Accuracy: 71.55%, Test Loss: 1.0213, Test Accuracy: 67.09%\n",
      "Epoch [1386/2500], Train Loss: 0.6421, Train Accuracy: 71.83%, Test Loss: 1.0511, Test Accuracy: 65.82%\n",
      "Epoch [1387/2500], Train Loss: 0.6501, Train Accuracy: 71.27%, Test Loss: 1.0583, Test Accuracy: 64.56%\n",
      "Epoch [1388/2500], Train Loss: 0.6495, Train Accuracy: 71.55%, Test Loss: 1.0548, Test Accuracy: 65.82%\n",
      "Epoch [1389/2500], Train Loss: 0.6404, Train Accuracy: 72.69%, Test Loss: 1.0768, Test Accuracy: 65.82%\n",
      "Epoch [1390/2500], Train Loss: 0.6184, Train Accuracy: 72.97%, Test Loss: 1.0799, Test Accuracy: 67.09%\n",
      "Epoch [1391/2500], Train Loss: 0.6456, Train Accuracy: 72.97%, Test Loss: 1.0840, Test Accuracy: 67.09%\n",
      "Epoch [1392/2500], Train Loss: 0.6581, Train Accuracy: 70.55%, Test Loss: 1.0982, Test Accuracy: 65.82%\n",
      "Epoch [1393/2500], Train Loss: 0.6253, Train Accuracy: 73.12%, Test Loss: 1.0401, Test Accuracy: 68.35%\n",
      "Epoch [1394/2500], Train Loss: 0.6554, Train Accuracy: 70.55%, Test Loss: 1.1055, Test Accuracy: 65.82%\n",
      "Epoch [1395/2500], Train Loss: 0.6443, Train Accuracy: 71.69%, Test Loss: 1.0209, Test Accuracy: 64.56%\n",
      "Epoch [1396/2500], Train Loss: 0.6565, Train Accuracy: 71.55%, Test Loss: 1.0339, Test Accuracy: 68.35%\n",
      "Epoch [1397/2500], Train Loss: 0.6589, Train Accuracy: 71.55%, Test Loss: 1.0122, Test Accuracy: 64.56%\n",
      "Epoch [1398/2500], Train Loss: 0.6556, Train Accuracy: 70.55%, Test Loss: 1.0019, Test Accuracy: 68.35%\n",
      "Epoch [1399/2500], Train Loss: 0.6330, Train Accuracy: 72.97%, Test Loss: 1.0278, Test Accuracy: 68.35%\n",
      "Epoch [1400/2500], Train Loss: 0.6144, Train Accuracy: 70.84%, Test Loss: 1.0473, Test Accuracy: 68.35%\n",
      "Epoch [1401/2500], Train Loss: 0.6309, Train Accuracy: 71.55%, Test Loss: 1.0268, Test Accuracy: 64.56%\n",
      "Epoch [1402/2500], Train Loss: 0.6477, Train Accuracy: 71.27%, Test Loss: 1.0318, Test Accuracy: 65.82%\n",
      "Epoch [1403/2500], Train Loss: 0.6417, Train Accuracy: 72.97%, Test Loss: 1.0103, Test Accuracy: 65.82%\n",
      "Epoch [1404/2500], Train Loss: 0.6371, Train Accuracy: 72.26%, Test Loss: 1.0183, Test Accuracy: 68.35%\n",
      "Epoch [1405/2500], Train Loss: 0.6400, Train Accuracy: 72.40%, Test Loss: 1.0145, Test Accuracy: 64.56%\n",
      "Epoch [1406/2500], Train Loss: 0.6294, Train Accuracy: 74.96%, Test Loss: 1.0415, Test Accuracy: 67.09%\n",
      "Epoch [1407/2500], Train Loss: 0.6610, Train Accuracy: 70.98%, Test Loss: 0.9740, Test Accuracy: 67.09%\n",
      "Epoch [1408/2500], Train Loss: 0.6408, Train Accuracy: 72.40%, Test Loss: 1.0436, Test Accuracy: 67.09%\n",
      "Epoch [1409/2500], Train Loss: 0.6545, Train Accuracy: 71.83%, Test Loss: 1.0607, Test Accuracy: 65.82%\n",
      "Epoch [1410/2500], Train Loss: 0.6466, Train Accuracy: 72.83%, Test Loss: 1.0210, Test Accuracy: 67.09%\n",
      "Epoch [1411/2500], Train Loss: 0.6568, Train Accuracy: 71.55%, Test Loss: 1.0272, Test Accuracy: 68.35%\n",
      "Epoch [1412/2500], Train Loss: 0.6240, Train Accuracy: 72.26%, Test Loss: 1.0067, Test Accuracy: 69.62%\n",
      "Epoch [1413/2500], Train Loss: 0.6232, Train Accuracy: 72.55%, Test Loss: 1.0245, Test Accuracy: 68.35%\n",
      "Epoch [1414/2500], Train Loss: 0.6272, Train Accuracy: 73.97%, Test Loss: 1.0294, Test Accuracy: 67.09%\n",
      "Epoch [1415/2500], Train Loss: 0.6660, Train Accuracy: 72.83%, Test Loss: 1.0504, Test Accuracy: 67.09%\n",
      "Epoch [1416/2500], Train Loss: 0.6430, Train Accuracy: 73.12%, Test Loss: 1.0304, Test Accuracy: 65.82%\n",
      "Epoch [1417/2500], Train Loss: 0.6193, Train Accuracy: 71.98%, Test Loss: 1.0700, Test Accuracy: 65.82%\n",
      "Epoch [1418/2500], Train Loss: 0.6362, Train Accuracy: 70.84%, Test Loss: 1.0853, Test Accuracy: 65.82%\n",
      "Epoch [1419/2500], Train Loss: 0.6414, Train Accuracy: 72.83%, Test Loss: 1.0308, Test Accuracy: 65.82%\n",
      "Epoch [1420/2500], Train Loss: 0.6325, Train Accuracy: 72.83%, Test Loss: 1.0827, Test Accuracy: 65.82%\n",
      "Epoch [1421/2500], Train Loss: 0.6422, Train Accuracy: 71.98%, Test Loss: 1.0386, Test Accuracy: 65.82%\n",
      "Epoch [1422/2500], Train Loss: 0.6538, Train Accuracy: 71.27%, Test Loss: 1.0073, Test Accuracy: 65.82%\n",
      "Epoch [1423/2500], Train Loss: 0.6214, Train Accuracy: 72.97%, Test Loss: 1.0344, Test Accuracy: 63.29%\n",
      "Epoch [1424/2500], Train Loss: 0.6287, Train Accuracy: 70.98%, Test Loss: 1.0892, Test Accuracy: 64.56%\n",
      "Epoch [1425/2500], Train Loss: 0.6304, Train Accuracy: 70.27%, Test Loss: 1.0499, Test Accuracy: 64.56%\n",
      "Epoch [1426/2500], Train Loss: 0.6321, Train Accuracy: 72.26%, Test Loss: 0.9944, Test Accuracy: 65.82%\n",
      "Epoch [1427/2500], Train Loss: 0.6611, Train Accuracy: 72.69%, Test Loss: 1.0564, Test Accuracy: 70.89%\n",
      "Epoch [1428/2500], Train Loss: 0.6349, Train Accuracy: 73.54%, Test Loss: 1.0444, Test Accuracy: 67.09%\n",
      "Epoch [1429/2500], Train Loss: 0.6103, Train Accuracy: 73.54%, Test Loss: 1.0796, Test Accuracy: 67.09%\n",
      "Epoch [1430/2500], Train Loss: 0.6454, Train Accuracy: 70.84%, Test Loss: 1.0549, Test Accuracy: 65.82%\n",
      "Epoch [1431/2500], Train Loss: 0.6512, Train Accuracy: 72.26%, Test Loss: 1.0601, Test Accuracy: 65.82%\n",
      "Epoch [1432/2500], Train Loss: 0.6268, Train Accuracy: 72.97%, Test Loss: 1.0424, Test Accuracy: 65.82%\n",
      "Epoch [1433/2500], Train Loss: 0.6209, Train Accuracy: 71.83%, Test Loss: 1.0659, Test Accuracy: 67.09%\n",
      "Epoch [1434/2500], Train Loss: 0.6507, Train Accuracy: 72.26%, Test Loss: 1.0146, Test Accuracy: 69.62%\n",
      "Epoch [1435/2500], Train Loss: 0.6449, Train Accuracy: 70.41%, Test Loss: 1.0503, Test Accuracy: 64.56%\n",
      "Epoch [1436/2500], Train Loss: 0.6214, Train Accuracy: 74.82%, Test Loss: 1.0675, Test Accuracy: 67.09%\n",
      "Epoch [1437/2500], Train Loss: 0.6364, Train Accuracy: 72.55%, Test Loss: 1.0428, Test Accuracy: 67.09%\n",
      "Epoch [1438/2500], Train Loss: 0.6283, Train Accuracy: 73.54%, Test Loss: 1.0597, Test Accuracy: 62.03%\n",
      "Epoch [1439/2500], Train Loss: 0.6187, Train Accuracy: 73.26%, Test Loss: 1.0496, Test Accuracy: 68.35%\n",
      "Epoch [1440/2500], Train Loss: 0.6142, Train Accuracy: 74.11%, Test Loss: 1.0441, Test Accuracy: 68.35%\n",
      "Epoch [1441/2500], Train Loss: 0.6399, Train Accuracy: 71.98%, Test Loss: 1.0786, Test Accuracy: 67.09%\n",
      "Epoch [1442/2500], Train Loss: 0.6388, Train Accuracy: 72.40%, Test Loss: 1.0761, Test Accuracy: 68.35%\n",
      "Epoch [1443/2500], Train Loss: 0.5994, Train Accuracy: 73.54%, Test Loss: 1.0635, Test Accuracy: 67.09%\n",
      "Epoch [1444/2500], Train Loss: 0.6257, Train Accuracy: 72.26%, Test Loss: 1.1472, Test Accuracy: 62.03%\n",
      "Epoch [1445/2500], Train Loss: 0.6187, Train Accuracy: 74.25%, Test Loss: 1.0734, Test Accuracy: 68.35%\n",
      "Epoch [1446/2500], Train Loss: 0.6231, Train Accuracy: 70.98%, Test Loss: 1.0802, Test Accuracy: 67.09%\n",
      "Epoch [1447/2500], Train Loss: 0.6219, Train Accuracy: 73.83%, Test Loss: 1.1336, Test Accuracy: 65.82%\n",
      "Epoch [1448/2500], Train Loss: 0.6279, Train Accuracy: 71.27%, Test Loss: 1.0950, Test Accuracy: 65.82%\n",
      "Epoch [1449/2500], Train Loss: 0.6317, Train Accuracy: 72.12%, Test Loss: 1.0819, Test Accuracy: 68.35%\n",
      "Epoch [1450/2500], Train Loss: 0.6587, Train Accuracy: 71.27%, Test Loss: 1.0755, Test Accuracy: 65.82%\n",
      "Epoch [1451/2500], Train Loss: 0.6730, Train Accuracy: 69.42%, Test Loss: 1.0612, Test Accuracy: 65.82%\n",
      "Epoch [1452/2500], Train Loss: 0.6420, Train Accuracy: 71.55%, Test Loss: 0.9925, Test Accuracy: 65.82%\n",
      "Epoch [1453/2500], Train Loss: 0.6259, Train Accuracy: 72.97%, Test Loss: 1.0079, Test Accuracy: 68.35%\n",
      "Epoch [1454/2500], Train Loss: 0.6343, Train Accuracy: 72.69%, Test Loss: 1.0674, Test Accuracy: 63.29%\n",
      "Epoch [1455/2500], Train Loss: 0.6196, Train Accuracy: 74.25%, Test Loss: 1.0008, Test Accuracy: 73.42%\n",
      "Epoch [1456/2500], Train Loss: 0.6507, Train Accuracy: 73.54%, Test Loss: 1.0246, Test Accuracy: 69.62%\n",
      "Epoch [1457/2500], Train Loss: 0.6677, Train Accuracy: 70.55%, Test Loss: 0.9900, Test Accuracy: 67.09%\n",
      "Epoch [1458/2500], Train Loss: 0.6169, Train Accuracy: 73.68%, Test Loss: 1.0151, Test Accuracy: 70.89%\n",
      "Epoch [1459/2500], Train Loss: 0.6499, Train Accuracy: 72.55%, Test Loss: 1.0109, Test Accuracy: 68.35%\n",
      "Epoch [1460/2500], Train Loss: 0.6201, Train Accuracy: 72.26%, Test Loss: 1.0421, Test Accuracy: 70.89%\n",
      "Epoch [1461/2500], Train Loss: 0.6456, Train Accuracy: 71.12%, Test Loss: 1.0473, Test Accuracy: 67.09%\n",
      "Epoch [1462/2500], Train Loss: 0.6349, Train Accuracy: 72.97%, Test Loss: 1.0555, Test Accuracy: 67.09%\n",
      "Epoch [1463/2500], Train Loss: 0.6303, Train Accuracy: 72.83%, Test Loss: 1.0583, Test Accuracy: 65.82%\n",
      "Epoch [1464/2500], Train Loss: 0.6342, Train Accuracy: 72.26%, Test Loss: 1.0515, Test Accuracy: 64.56%\n",
      "Epoch [1465/2500], Train Loss: 0.6342, Train Accuracy: 73.12%, Test Loss: 1.0260, Test Accuracy: 67.09%\n",
      "Epoch [1466/2500], Train Loss: 0.6380, Train Accuracy: 72.12%, Test Loss: 1.0394, Test Accuracy: 68.35%\n",
      "Epoch [1467/2500], Train Loss: 0.6332, Train Accuracy: 72.69%, Test Loss: 1.0384, Test Accuracy: 65.82%\n",
      "Epoch [1468/2500], Train Loss: 0.6350, Train Accuracy: 71.41%, Test Loss: 1.0749, Test Accuracy: 67.09%\n",
      "Epoch [1469/2500], Train Loss: 0.6701, Train Accuracy: 69.84%, Test Loss: 1.0178, Test Accuracy: 64.56%\n",
      "Epoch [1470/2500], Train Loss: 0.6120, Train Accuracy: 72.83%, Test Loss: 1.0580, Test Accuracy: 67.09%\n",
      "Epoch [1471/2500], Train Loss: 0.6397, Train Accuracy: 71.83%, Test Loss: 1.0445, Test Accuracy: 68.35%\n",
      "Epoch [1472/2500], Train Loss: 0.6329, Train Accuracy: 72.12%, Test Loss: 1.0123, Test Accuracy: 72.15%\n",
      "Epoch [1473/2500], Train Loss: 0.6249, Train Accuracy: 71.27%, Test Loss: 1.0305, Test Accuracy: 68.35%\n",
      "Epoch [1474/2500], Train Loss: 0.6450, Train Accuracy: 71.83%, Test Loss: 1.0945, Test Accuracy: 64.56%\n",
      "Epoch [1475/2500], Train Loss: 0.6460, Train Accuracy: 72.55%, Test Loss: 1.0279, Test Accuracy: 68.35%\n",
      "Epoch [1476/2500], Train Loss: 0.6345, Train Accuracy: 72.26%, Test Loss: 1.0379, Test Accuracy: 65.82%\n",
      "Epoch [1477/2500], Train Loss: 0.6019, Train Accuracy: 73.68%, Test Loss: 1.0765, Test Accuracy: 68.35%\n",
      "Epoch [1478/2500], Train Loss: 0.6444, Train Accuracy: 71.98%, Test Loss: 1.0735, Test Accuracy: 63.29%\n",
      "Epoch [1479/2500], Train Loss: 0.6311, Train Accuracy: 72.55%, Test Loss: 1.0883, Test Accuracy: 67.09%\n",
      "Epoch [1480/2500], Train Loss: 0.6415, Train Accuracy: 72.69%, Test Loss: 1.0540, Test Accuracy: 67.09%\n",
      "Epoch [1481/2500], Train Loss: 0.6344, Train Accuracy: 72.55%, Test Loss: 1.0408, Test Accuracy: 67.09%\n",
      "Epoch [1482/2500], Train Loss: 0.6177, Train Accuracy: 73.54%, Test Loss: 1.0500, Test Accuracy: 68.35%\n",
      "Epoch [1483/2500], Train Loss: 0.6212, Train Accuracy: 72.12%, Test Loss: 1.0430, Test Accuracy: 65.82%\n",
      "Epoch [1484/2500], Train Loss: 0.6510, Train Accuracy: 71.27%, Test Loss: 1.0155, Test Accuracy: 67.09%\n",
      "Epoch [1485/2500], Train Loss: 0.6453, Train Accuracy: 73.12%, Test Loss: 1.0418, Test Accuracy: 69.62%\n",
      "Epoch [1486/2500], Train Loss: 0.6345, Train Accuracy: 72.26%, Test Loss: 0.9997, Test Accuracy: 68.35%\n",
      "Epoch [1487/2500], Train Loss: 0.6257, Train Accuracy: 73.54%, Test Loss: 1.0410, Test Accuracy: 69.62%\n",
      "Epoch [1488/2500], Train Loss: 0.6226, Train Accuracy: 72.26%, Test Loss: 1.0670, Test Accuracy: 68.35%\n",
      "Epoch [1489/2500], Train Loss: 0.6295, Train Accuracy: 72.26%, Test Loss: 1.0839, Test Accuracy: 65.82%\n",
      "Epoch [1490/2500], Train Loss: 0.6391, Train Accuracy: 73.26%, Test Loss: 1.0880, Test Accuracy: 64.56%\n",
      "Epoch [1491/2500], Train Loss: 0.6639, Train Accuracy: 70.98%, Test Loss: 1.1047, Test Accuracy: 65.82%\n",
      "Epoch [1492/2500], Train Loss: 0.6484, Train Accuracy: 72.12%, Test Loss: 1.0093, Test Accuracy: 65.82%\n",
      "Epoch [1493/2500], Train Loss: 0.6429, Train Accuracy: 70.98%, Test Loss: 1.0329, Test Accuracy: 65.82%\n",
      "Epoch [1494/2500], Train Loss: 0.6507, Train Accuracy: 72.97%, Test Loss: 1.0428, Test Accuracy: 67.09%\n",
      "Epoch [1495/2500], Train Loss: 0.6210, Train Accuracy: 73.40%, Test Loss: 1.0084, Test Accuracy: 65.82%\n",
      "Epoch [1496/2500], Train Loss: 0.6625, Train Accuracy: 71.69%, Test Loss: 1.0050, Test Accuracy: 67.09%\n",
      "Epoch [1497/2500], Train Loss: 0.6410, Train Accuracy: 71.98%, Test Loss: 1.0401, Test Accuracy: 65.82%\n",
      "Epoch [1498/2500], Train Loss: 0.6225, Train Accuracy: 73.40%, Test Loss: 1.0120, Test Accuracy: 67.09%\n",
      "Epoch [1499/2500], Train Loss: 0.6211, Train Accuracy: 72.83%, Test Loss: 1.0325, Test Accuracy: 67.09%\n",
      "Epoch [1500/2500], Train Loss: 0.6221, Train Accuracy: 72.40%, Test Loss: 1.0667, Test Accuracy: 65.82%\n",
      "Epoch [1501/2500], Train Loss: 0.6307, Train Accuracy: 73.12%, Test Loss: 1.0989, Test Accuracy: 67.09%\n",
      "Epoch [1502/2500], Train Loss: 0.6436, Train Accuracy: 71.27%, Test Loss: 1.0638, Test Accuracy: 67.09%\n",
      "Epoch [1503/2500], Train Loss: 0.6504, Train Accuracy: 72.40%, Test Loss: 1.0317, Test Accuracy: 65.82%\n",
      "Epoch [1504/2500], Train Loss: 0.6330, Train Accuracy: 73.83%, Test Loss: 1.0425, Test Accuracy: 65.82%\n",
      "Epoch [1505/2500], Train Loss: 0.6120, Train Accuracy: 73.83%, Test Loss: 1.0519, Test Accuracy: 65.82%\n",
      "Epoch [1506/2500], Train Loss: 0.6428, Train Accuracy: 73.26%, Test Loss: 1.0558, Test Accuracy: 65.82%\n",
      "Epoch [1507/2500], Train Loss: 0.6112, Train Accuracy: 72.83%, Test Loss: 1.0201, Test Accuracy: 67.09%\n",
      "Epoch [1508/2500], Train Loss: 0.6509, Train Accuracy: 73.97%, Test Loss: 1.0501, Test Accuracy: 67.09%\n",
      "Epoch [1509/2500], Train Loss: 0.6223, Train Accuracy: 72.26%, Test Loss: 1.0211, Test Accuracy: 67.09%\n",
      "Epoch [1510/2500], Train Loss: 0.6425, Train Accuracy: 72.69%, Test Loss: 1.0414, Test Accuracy: 68.35%\n",
      "Epoch [1511/2500], Train Loss: 0.6440, Train Accuracy: 72.69%, Test Loss: 1.0871, Test Accuracy: 65.82%\n",
      "Epoch [1512/2500], Train Loss: 0.6293, Train Accuracy: 73.83%, Test Loss: 1.0520, Test Accuracy: 63.29%\n",
      "Epoch [1513/2500], Train Loss: 0.6289, Train Accuracy: 72.83%, Test Loss: 1.0617, Test Accuracy: 67.09%\n",
      "Epoch [1514/2500], Train Loss: 0.6366, Train Accuracy: 71.69%, Test Loss: 1.0597, Test Accuracy: 67.09%\n",
      "Epoch [1515/2500], Train Loss: 0.6102, Train Accuracy: 74.25%, Test Loss: 1.0449, Test Accuracy: 67.09%\n",
      "Epoch [1516/2500], Train Loss: 0.6101, Train Accuracy: 76.10%, Test Loss: 1.0447, Test Accuracy: 68.35%\n",
      "Epoch [1517/2500], Train Loss: 0.6446, Train Accuracy: 72.26%, Test Loss: 1.1172, Test Accuracy: 65.82%\n",
      "Epoch [1518/2500], Train Loss: 0.6397, Train Accuracy: 72.12%, Test Loss: 1.0706, Test Accuracy: 67.09%\n",
      "Epoch [1519/2500], Train Loss: 0.6220, Train Accuracy: 73.68%, Test Loss: 1.1452, Test Accuracy: 67.09%\n",
      "Epoch [1520/2500], Train Loss: 0.6317, Train Accuracy: 72.83%, Test Loss: 1.0503, Test Accuracy: 68.35%\n",
      "Epoch [1521/2500], Train Loss: 0.6565, Train Accuracy: 70.13%, Test Loss: 1.0275, Test Accuracy: 70.89%\n",
      "Epoch [1522/2500], Train Loss: 0.6211, Train Accuracy: 70.84%, Test Loss: 1.0613, Test Accuracy: 68.35%\n",
      "Epoch [1523/2500], Train Loss: 0.6159, Train Accuracy: 73.26%, Test Loss: 1.0878, Test Accuracy: 67.09%\n",
      "Epoch [1524/2500], Train Loss: 0.6089, Train Accuracy: 74.25%, Test Loss: 1.1014, Test Accuracy: 64.56%\n",
      "Epoch [1525/2500], Train Loss: 0.6279, Train Accuracy: 72.55%, Test Loss: 1.0482, Test Accuracy: 65.82%\n",
      "Epoch [1526/2500], Train Loss: 0.6220, Train Accuracy: 73.54%, Test Loss: 1.0818, Test Accuracy: 64.56%\n",
      "Epoch [1527/2500], Train Loss: 0.6379, Train Accuracy: 71.98%, Test Loss: 1.0502, Test Accuracy: 65.82%\n",
      "Epoch [1528/2500], Train Loss: 0.6077, Train Accuracy: 74.25%, Test Loss: 1.0872, Test Accuracy: 64.56%\n",
      "Epoch [1529/2500], Train Loss: 0.6145, Train Accuracy: 72.83%, Test Loss: 1.0680, Test Accuracy: 68.35%\n",
      "Epoch [1530/2500], Train Loss: 0.6320, Train Accuracy: 72.83%, Test Loss: 1.0798, Test Accuracy: 65.82%\n",
      "Epoch [1531/2500], Train Loss: 0.6042, Train Accuracy: 73.97%, Test Loss: 1.0687, Test Accuracy: 63.29%\n",
      "Epoch [1532/2500], Train Loss: 0.6163, Train Accuracy: 72.83%, Test Loss: 1.0543, Test Accuracy: 68.35%\n",
      "Epoch [1533/2500], Train Loss: 0.6238, Train Accuracy: 74.68%, Test Loss: 1.0628, Test Accuracy: 68.35%\n",
      "Epoch [1534/2500], Train Loss: 0.6294, Train Accuracy: 72.40%, Test Loss: 1.0769, Test Accuracy: 68.35%\n",
      "Epoch [1535/2500], Train Loss: 0.5879, Train Accuracy: 72.69%, Test Loss: 1.0986, Test Accuracy: 68.35%\n",
      "Epoch [1536/2500], Train Loss: 0.6476, Train Accuracy: 72.55%, Test Loss: 1.1026, Test Accuracy: 68.35%\n",
      "Epoch [1537/2500], Train Loss: 0.6466, Train Accuracy: 71.27%, Test Loss: 1.0630, Test Accuracy: 68.35%\n",
      "Epoch [1538/2500], Train Loss: 0.6339, Train Accuracy: 72.83%, Test Loss: 1.0710, Test Accuracy: 67.09%\n",
      "Epoch [1539/2500], Train Loss: 0.6600, Train Accuracy: 70.84%, Test Loss: 1.0660, Test Accuracy: 69.62%\n",
      "Epoch [1540/2500], Train Loss: 0.6376, Train Accuracy: 72.40%, Test Loss: 1.1033, Test Accuracy: 64.56%\n",
      "Epoch [1541/2500], Train Loss: 0.6133, Train Accuracy: 73.12%, Test Loss: 1.0882, Test Accuracy: 69.62%\n",
      "Epoch [1542/2500], Train Loss: 0.6656, Train Accuracy: 71.69%, Test Loss: 1.0227, Test Accuracy: 70.89%\n",
      "Epoch [1543/2500], Train Loss: 0.6292, Train Accuracy: 72.97%, Test Loss: 1.0560, Test Accuracy: 68.35%\n",
      "Epoch [1544/2500], Train Loss: 0.6226, Train Accuracy: 73.12%, Test Loss: 1.0615, Test Accuracy: 67.09%\n",
      "Epoch [1545/2500], Train Loss: 0.6318, Train Accuracy: 70.98%, Test Loss: 1.0513, Test Accuracy: 68.35%\n",
      "Epoch [1546/2500], Train Loss: 0.6151, Train Accuracy: 72.69%, Test Loss: 1.0682, Test Accuracy: 67.09%\n",
      "Epoch [1547/2500], Train Loss: 0.6403, Train Accuracy: 71.69%, Test Loss: 1.0500, Test Accuracy: 64.56%\n",
      "Epoch [1548/2500], Train Loss: 0.5992, Train Accuracy: 75.53%, Test Loss: 1.0847, Test Accuracy: 69.62%\n",
      "Epoch [1549/2500], Train Loss: 0.6336, Train Accuracy: 73.40%, Test Loss: 1.0262, Test Accuracy: 69.62%\n",
      "Epoch [1550/2500], Train Loss: 0.6391, Train Accuracy: 72.55%, Test Loss: 1.0602, Test Accuracy: 68.35%\n",
      "Epoch [1551/2500], Train Loss: 0.6259, Train Accuracy: 72.40%, Test Loss: 1.0499, Test Accuracy: 69.62%\n",
      "Epoch [1552/2500], Train Loss: 0.6388, Train Accuracy: 72.83%, Test Loss: 1.0372, Test Accuracy: 67.09%\n",
      "Epoch [1553/2500], Train Loss: 0.6190, Train Accuracy: 74.11%, Test Loss: 1.0996, Test Accuracy: 68.35%\n",
      "Epoch [1554/2500], Train Loss: 0.6172, Train Accuracy: 74.25%, Test Loss: 1.0622, Test Accuracy: 67.09%\n",
      "Epoch [1555/2500], Train Loss: 0.6364, Train Accuracy: 73.40%, Test Loss: 1.0941, Test Accuracy: 69.62%\n",
      "Epoch [1556/2500], Train Loss: 0.6274, Train Accuracy: 72.26%, Test Loss: 1.0479, Test Accuracy: 67.09%\n",
      "Epoch [1557/2500], Train Loss: 0.6302, Train Accuracy: 71.27%, Test Loss: 1.0959, Test Accuracy: 67.09%\n",
      "Epoch [1558/2500], Train Loss: 0.6305, Train Accuracy: 72.69%, Test Loss: 1.1174, Test Accuracy: 65.82%\n",
      "Epoch [1559/2500], Train Loss: 0.6274, Train Accuracy: 74.82%, Test Loss: 1.0512, Test Accuracy: 68.35%\n",
      "Epoch [1560/2500], Train Loss: 0.6165, Train Accuracy: 73.83%, Test Loss: 1.0677, Test Accuracy: 69.62%\n",
      "Epoch [1561/2500], Train Loss: 0.6326, Train Accuracy: 72.40%, Test Loss: 1.0931, Test Accuracy: 68.35%\n",
      "Epoch [1562/2500], Train Loss: 0.6229, Train Accuracy: 72.55%, Test Loss: 1.0278, Test Accuracy: 69.62%\n",
      "Epoch [1563/2500], Train Loss: 0.6242, Train Accuracy: 72.69%, Test Loss: 1.0622, Test Accuracy: 68.35%\n",
      "Epoch [1564/2500], Train Loss: 0.6204, Train Accuracy: 73.68%, Test Loss: 1.0607, Test Accuracy: 68.35%\n",
      "Epoch [1565/2500], Train Loss: 0.6094, Train Accuracy: 75.25%, Test Loss: 1.0707, Test Accuracy: 67.09%\n",
      "Epoch [1566/2500], Train Loss: 0.6285, Train Accuracy: 73.12%, Test Loss: 1.0860, Test Accuracy: 68.35%\n",
      "Epoch [1567/2500], Train Loss: 0.6383, Train Accuracy: 72.40%, Test Loss: 1.1070, Test Accuracy: 68.35%\n",
      "Epoch [1568/2500], Train Loss: 0.6409, Train Accuracy: 72.26%, Test Loss: 1.0613, Test Accuracy: 69.62%\n",
      "Epoch [1569/2500], Train Loss: 0.6092, Train Accuracy: 74.40%, Test Loss: 1.0700, Test Accuracy: 67.09%\n",
      "Epoch [1570/2500], Train Loss: 0.6233, Train Accuracy: 72.40%, Test Loss: 1.0192, Test Accuracy: 72.15%\n",
      "Epoch [1571/2500], Train Loss: 0.6263, Train Accuracy: 71.27%, Test Loss: 1.0981, Test Accuracy: 65.82%\n",
      "Epoch [1572/2500], Train Loss: 0.6297, Train Accuracy: 72.69%, Test Loss: 1.0963, Test Accuracy: 68.35%\n",
      "Epoch [1573/2500], Train Loss: 0.6372, Train Accuracy: 71.55%, Test Loss: 1.0604, Test Accuracy: 67.09%\n",
      "Epoch [1574/2500], Train Loss: 0.6277, Train Accuracy: 72.55%, Test Loss: 1.0683, Test Accuracy: 67.09%\n",
      "Epoch [1575/2500], Train Loss: 0.6059, Train Accuracy: 74.40%, Test Loss: 1.1018, Test Accuracy: 67.09%\n",
      "Epoch [1576/2500], Train Loss: 0.6408, Train Accuracy: 70.55%, Test Loss: 1.0721, Test Accuracy: 67.09%\n",
      "Epoch [1577/2500], Train Loss: 0.6472, Train Accuracy: 70.98%, Test Loss: 1.0459, Test Accuracy: 67.09%\n",
      "Epoch [1578/2500], Train Loss: 0.6115, Train Accuracy: 73.83%, Test Loss: 1.1024, Test Accuracy: 68.35%\n",
      "Epoch [1579/2500], Train Loss: 0.6248, Train Accuracy: 71.41%, Test Loss: 1.0687, Test Accuracy: 67.09%\n",
      "Epoch [1580/2500], Train Loss: 0.6244, Train Accuracy: 72.69%, Test Loss: 1.0805, Test Accuracy: 69.62%\n",
      "Epoch [1581/2500], Train Loss: 0.6100, Train Accuracy: 73.54%, Test Loss: 1.0807, Test Accuracy: 70.89%\n",
      "Epoch [1582/2500], Train Loss: 0.6158, Train Accuracy: 73.26%, Test Loss: 1.0831, Test Accuracy: 67.09%\n",
      "Epoch [1583/2500], Train Loss: 0.6146, Train Accuracy: 73.54%, Test Loss: 1.0487, Test Accuracy: 68.35%\n",
      "Epoch [1584/2500], Train Loss: 0.6125, Train Accuracy: 72.12%, Test Loss: 1.0579, Test Accuracy: 69.62%\n",
      "Epoch [1585/2500], Train Loss: 0.6092, Train Accuracy: 73.97%, Test Loss: 1.0420, Test Accuracy: 67.09%\n",
      "Epoch [1586/2500], Train Loss: 0.6161, Train Accuracy: 73.83%, Test Loss: 1.0952, Test Accuracy: 67.09%\n",
      "Epoch [1587/2500], Train Loss: 0.6243, Train Accuracy: 75.39%, Test Loss: 1.0690, Test Accuracy: 65.82%\n",
      "Epoch [1588/2500], Train Loss: 0.6263, Train Accuracy: 72.55%, Test Loss: 1.0707, Test Accuracy: 65.82%\n",
      "Epoch [1589/2500], Train Loss: 0.6085, Train Accuracy: 74.25%, Test Loss: 1.0937, Test Accuracy: 65.82%\n",
      "Epoch [1590/2500], Train Loss: 0.6135, Train Accuracy: 73.54%, Test Loss: 1.0831, Test Accuracy: 65.82%\n",
      "Epoch [1591/2500], Train Loss: 0.6176, Train Accuracy: 73.83%, Test Loss: 1.0333, Test Accuracy: 67.09%\n",
      "Epoch [1592/2500], Train Loss: 0.6280, Train Accuracy: 74.82%, Test Loss: 1.1125, Test Accuracy: 67.09%\n",
      "Epoch [1593/2500], Train Loss: 0.6040, Train Accuracy: 74.40%, Test Loss: 1.1068, Test Accuracy: 68.35%\n",
      "Epoch [1594/2500], Train Loss: 0.6496, Train Accuracy: 72.83%, Test Loss: 1.0450, Test Accuracy: 69.62%\n",
      "Epoch [1595/2500], Train Loss: 0.6310, Train Accuracy: 72.55%, Test Loss: 1.0536, Test Accuracy: 67.09%\n",
      "Epoch [1596/2500], Train Loss: 0.6204, Train Accuracy: 72.83%, Test Loss: 1.0415, Test Accuracy: 67.09%\n",
      "Epoch [1597/2500], Train Loss: 0.6145, Train Accuracy: 71.98%, Test Loss: 1.0861, Test Accuracy: 67.09%\n",
      "Epoch [1598/2500], Train Loss: 0.6289, Train Accuracy: 74.11%, Test Loss: 1.0957, Test Accuracy: 67.09%\n",
      "Epoch [1599/2500], Train Loss: 0.6277, Train Accuracy: 70.84%, Test Loss: 1.0817, Test Accuracy: 68.35%\n",
      "Epoch [1600/2500], Train Loss: 0.6243, Train Accuracy: 72.26%, Test Loss: 1.1006, Test Accuracy: 67.09%\n",
      "Epoch [1601/2500], Train Loss: 0.6197, Train Accuracy: 73.83%, Test Loss: 1.0734, Test Accuracy: 65.82%\n",
      "Epoch [1602/2500], Train Loss: 0.6012, Train Accuracy: 71.98%, Test Loss: 1.0263, Test Accuracy: 65.82%\n",
      "Epoch [1603/2500], Train Loss: 0.6188, Train Accuracy: 72.55%, Test Loss: 1.0677, Test Accuracy: 65.82%\n",
      "Epoch [1604/2500], Train Loss: 0.6207, Train Accuracy: 71.41%, Test Loss: 1.0501, Test Accuracy: 68.35%\n",
      "Epoch [1605/2500], Train Loss: 0.6297, Train Accuracy: 74.68%, Test Loss: 1.0664, Test Accuracy: 65.82%\n",
      "Epoch [1606/2500], Train Loss: 0.6199, Train Accuracy: 73.54%, Test Loss: 1.0970, Test Accuracy: 68.35%\n",
      "Epoch [1607/2500], Train Loss: 0.6280, Train Accuracy: 73.12%, Test Loss: 1.0844, Test Accuracy: 67.09%\n",
      "Epoch [1608/2500], Train Loss: 0.5925, Train Accuracy: 76.24%, Test Loss: 1.0355, Test Accuracy: 67.09%\n",
      "Epoch [1609/2500], Train Loss: 0.6085, Train Accuracy: 73.26%, Test Loss: 1.0795, Test Accuracy: 65.82%\n",
      "Epoch [1610/2500], Train Loss: 0.6495, Train Accuracy: 72.69%, Test Loss: 1.0517, Test Accuracy: 68.35%\n",
      "Epoch [1611/2500], Train Loss: 0.6047, Train Accuracy: 74.68%, Test Loss: 1.0814, Test Accuracy: 65.82%\n",
      "Epoch [1612/2500], Train Loss: 0.6040, Train Accuracy: 73.68%, Test Loss: 1.1301, Test Accuracy: 65.82%\n",
      "Epoch [1613/2500], Train Loss: 0.6412, Train Accuracy: 72.83%, Test Loss: 1.0504, Test Accuracy: 65.82%\n",
      "Epoch [1614/2500], Train Loss: 0.6270, Train Accuracy: 73.54%, Test Loss: 1.0484, Test Accuracy: 65.82%\n",
      "Epoch [1615/2500], Train Loss: 0.6213, Train Accuracy: 74.54%, Test Loss: 1.0700, Test Accuracy: 65.82%\n",
      "Epoch [1616/2500], Train Loss: 0.6261, Train Accuracy: 73.12%, Test Loss: 1.0403, Test Accuracy: 68.35%\n",
      "Epoch [1617/2500], Train Loss: 0.6120, Train Accuracy: 73.83%, Test Loss: 1.0880, Test Accuracy: 69.62%\n",
      "Epoch [1618/2500], Train Loss: 0.6529, Train Accuracy: 71.27%, Test Loss: 1.0528, Test Accuracy: 68.35%\n",
      "Epoch [1619/2500], Train Loss: 0.5896, Train Accuracy: 74.54%, Test Loss: 1.1081, Test Accuracy: 67.09%\n",
      "Epoch [1620/2500], Train Loss: 0.5996, Train Accuracy: 74.11%, Test Loss: 1.0747, Test Accuracy: 69.62%\n",
      "Epoch [1621/2500], Train Loss: 0.6552, Train Accuracy: 71.69%, Test Loss: 1.0527, Test Accuracy: 69.62%\n",
      "Epoch [1622/2500], Train Loss: 0.6382, Train Accuracy: 73.26%, Test Loss: 1.0852, Test Accuracy: 68.35%\n",
      "Epoch [1623/2500], Train Loss: 0.6153, Train Accuracy: 74.68%, Test Loss: 1.1033, Test Accuracy: 65.82%\n",
      "Epoch [1624/2500], Train Loss: 0.6144, Train Accuracy: 74.68%, Test Loss: 1.0502, Test Accuracy: 69.62%\n",
      "Epoch [1625/2500], Train Loss: 0.6025, Train Accuracy: 73.83%, Test Loss: 1.0393, Test Accuracy: 69.62%\n",
      "Epoch [1626/2500], Train Loss: 0.6218, Train Accuracy: 73.83%, Test Loss: 1.0332, Test Accuracy: 69.62%\n",
      "Epoch [1627/2500], Train Loss: 0.6547, Train Accuracy: 70.70%, Test Loss: 1.0428, Test Accuracy: 67.09%\n",
      "Epoch [1628/2500], Train Loss: 0.5953, Train Accuracy: 74.40%, Test Loss: 1.0858, Test Accuracy: 69.62%\n",
      "Epoch [1629/2500], Train Loss: 0.6094, Train Accuracy: 74.54%, Test Loss: 1.0971, Test Accuracy: 70.89%\n",
      "Epoch [1630/2500], Train Loss: 0.6341, Train Accuracy: 73.54%, Test Loss: 1.0227, Test Accuracy: 68.35%\n",
      "Epoch [1631/2500], Train Loss: 0.6131, Train Accuracy: 74.54%, Test Loss: 1.1008, Test Accuracy: 67.09%\n",
      "Epoch [1632/2500], Train Loss: 0.6391, Train Accuracy: 71.98%, Test Loss: 1.0567, Test Accuracy: 67.09%\n",
      "Epoch [1633/2500], Train Loss: 0.6122, Train Accuracy: 76.67%, Test Loss: 1.0724, Test Accuracy: 65.82%\n",
      "Epoch [1634/2500], Train Loss: 0.6169, Train Accuracy: 73.40%, Test Loss: 1.0713, Test Accuracy: 68.35%\n",
      "Epoch [1635/2500], Train Loss: 0.6224, Train Accuracy: 73.97%, Test Loss: 1.0598, Test Accuracy: 68.35%\n",
      "Epoch [1636/2500], Train Loss: 0.6318, Train Accuracy: 72.40%, Test Loss: 1.0412, Test Accuracy: 67.09%\n",
      "Epoch [1637/2500], Train Loss: 0.5939, Train Accuracy: 72.83%, Test Loss: 1.0361, Test Accuracy: 65.82%\n",
      "Epoch [1638/2500], Train Loss: 0.5997, Train Accuracy: 74.82%, Test Loss: 1.0296, Test Accuracy: 68.35%\n",
      "Epoch [1639/2500], Train Loss: 0.6148, Train Accuracy: 73.97%, Test Loss: 1.0695, Test Accuracy: 65.82%\n",
      "Epoch [1640/2500], Train Loss: 0.6599, Train Accuracy: 70.27%, Test Loss: 1.0597, Test Accuracy: 67.09%\n",
      "Epoch [1641/2500], Train Loss: 0.5990, Train Accuracy: 73.68%, Test Loss: 1.0411, Test Accuracy: 67.09%\n",
      "Epoch [1642/2500], Train Loss: 0.6060, Train Accuracy: 74.11%, Test Loss: 1.0748, Test Accuracy: 65.82%\n",
      "Epoch [1643/2500], Train Loss: 0.6211, Train Accuracy: 71.83%, Test Loss: 1.1107, Test Accuracy: 65.82%\n",
      "Epoch [1644/2500], Train Loss: 0.6102, Train Accuracy: 73.54%, Test Loss: 1.0889, Test Accuracy: 64.56%\n",
      "Epoch [1645/2500], Train Loss: 0.5955, Train Accuracy: 72.40%, Test Loss: 1.0809, Test Accuracy: 63.29%\n",
      "Epoch [1646/2500], Train Loss: 0.5931, Train Accuracy: 75.68%, Test Loss: 1.1232, Test Accuracy: 64.56%\n",
      "Epoch [1647/2500], Train Loss: 0.6359, Train Accuracy: 72.69%, Test Loss: 1.0726, Test Accuracy: 64.56%\n",
      "Epoch [1648/2500], Train Loss: 0.6275, Train Accuracy: 72.40%, Test Loss: 1.0909, Test Accuracy: 65.82%\n",
      "Epoch [1649/2500], Train Loss: 0.6180, Train Accuracy: 73.97%, Test Loss: 1.1183, Test Accuracy: 65.82%\n",
      "Epoch [1650/2500], Train Loss: 0.5891, Train Accuracy: 73.97%, Test Loss: 1.0914, Test Accuracy: 68.35%\n",
      "Epoch [1651/2500], Train Loss: 0.6185, Train Accuracy: 73.54%, Test Loss: 1.0962, Test Accuracy: 67.09%\n",
      "Epoch [1652/2500], Train Loss: 0.6154, Train Accuracy: 72.83%, Test Loss: 1.1271, Test Accuracy: 67.09%\n",
      "Epoch [1653/2500], Train Loss: 0.6049, Train Accuracy: 73.54%, Test Loss: 1.0236, Test Accuracy: 68.35%\n",
      "Epoch [1654/2500], Train Loss: 0.6259, Train Accuracy: 72.69%, Test Loss: 1.0270, Test Accuracy: 64.56%\n",
      "Epoch [1655/2500], Train Loss: 0.6089, Train Accuracy: 73.83%, Test Loss: 1.0662, Test Accuracy: 65.82%\n",
      "Epoch [1656/2500], Train Loss: 0.6369, Train Accuracy: 71.12%, Test Loss: 1.0750, Test Accuracy: 65.82%\n",
      "Epoch [1657/2500], Train Loss: 0.6204, Train Accuracy: 72.69%, Test Loss: 1.0654, Test Accuracy: 64.56%\n",
      "Epoch [1658/2500], Train Loss: 0.6009, Train Accuracy: 72.69%, Test Loss: 1.0856, Test Accuracy: 67.09%\n",
      "Epoch [1659/2500], Train Loss: 0.6068, Train Accuracy: 72.83%, Test Loss: 1.1027, Test Accuracy: 64.56%\n",
      "Epoch [1660/2500], Train Loss: 0.6300, Train Accuracy: 72.83%, Test Loss: 1.1550, Test Accuracy: 67.09%\n",
      "Epoch [1661/2500], Train Loss: 0.6179, Train Accuracy: 72.69%, Test Loss: 1.0459, Test Accuracy: 70.89%\n",
      "Epoch [1662/2500], Train Loss: 0.6019, Train Accuracy: 73.26%, Test Loss: 1.0615, Test Accuracy: 67.09%\n",
      "Epoch [1663/2500], Train Loss: 0.6176, Train Accuracy: 72.97%, Test Loss: 1.0207, Test Accuracy: 67.09%\n",
      "Epoch [1664/2500], Train Loss: 0.6341, Train Accuracy: 71.41%, Test Loss: 1.0214, Test Accuracy: 67.09%\n",
      "Epoch [1665/2500], Train Loss: 0.6074, Train Accuracy: 74.25%, Test Loss: 1.0677, Test Accuracy: 67.09%\n",
      "Epoch [1666/2500], Train Loss: 0.6426, Train Accuracy: 71.98%, Test Loss: 1.0231, Test Accuracy: 68.35%\n",
      "Epoch [1667/2500], Train Loss: 0.6247, Train Accuracy: 72.97%, Test Loss: 1.0803, Test Accuracy: 64.56%\n",
      "Epoch [1668/2500], Train Loss: 0.5948, Train Accuracy: 74.11%, Test Loss: 1.0520, Test Accuracy: 69.62%\n",
      "Epoch [1669/2500], Train Loss: 0.6133, Train Accuracy: 72.40%, Test Loss: 1.0418, Test Accuracy: 69.62%\n",
      "Epoch [1670/2500], Train Loss: 0.6132, Train Accuracy: 73.68%, Test Loss: 1.0146, Test Accuracy: 69.62%\n",
      "Epoch [1671/2500], Train Loss: 0.6310, Train Accuracy: 73.40%, Test Loss: 1.0668, Test Accuracy: 67.09%\n",
      "Epoch [1672/2500], Train Loss: 0.6109, Train Accuracy: 74.40%, Test Loss: 1.0424, Test Accuracy: 69.62%\n",
      "Epoch [1673/2500], Train Loss: 0.6169, Train Accuracy: 71.27%, Test Loss: 1.0773, Test Accuracy: 68.35%\n",
      "Epoch [1674/2500], Train Loss: 0.6088, Train Accuracy: 72.26%, Test Loss: 1.0324, Test Accuracy: 65.82%\n",
      "Epoch [1675/2500], Train Loss: 0.6073, Train Accuracy: 74.25%, Test Loss: 1.0715, Test Accuracy: 64.56%\n",
      "Epoch [1676/2500], Train Loss: 0.6014, Train Accuracy: 73.83%, Test Loss: 1.0671, Test Accuracy: 65.82%\n",
      "Epoch [1677/2500], Train Loss: 0.6076, Train Accuracy: 75.39%, Test Loss: 1.0666, Test Accuracy: 67.09%\n",
      "Epoch [1678/2500], Train Loss: 0.6002, Train Accuracy: 74.11%, Test Loss: 1.1120, Test Accuracy: 64.56%\n",
      "Epoch [1679/2500], Train Loss: 0.6178, Train Accuracy: 73.83%, Test Loss: 1.1066, Test Accuracy: 68.35%\n",
      "Epoch [1680/2500], Train Loss: 0.6100, Train Accuracy: 72.83%, Test Loss: 1.0514, Test Accuracy: 64.56%\n",
      "Epoch [1681/2500], Train Loss: 0.6419, Train Accuracy: 71.98%, Test Loss: 1.0369, Test Accuracy: 65.82%\n",
      "Epoch [1682/2500], Train Loss: 0.6227, Train Accuracy: 73.97%, Test Loss: 1.1319, Test Accuracy: 63.29%\n",
      "Epoch [1683/2500], Train Loss: 0.5890, Train Accuracy: 74.25%, Test Loss: 1.0787, Test Accuracy: 63.29%\n",
      "Epoch [1684/2500], Train Loss: 0.5908, Train Accuracy: 73.40%, Test Loss: 1.1047, Test Accuracy: 65.82%\n",
      "Epoch [1685/2500], Train Loss: 0.5778, Train Accuracy: 76.81%, Test Loss: 1.0919, Test Accuracy: 65.82%\n",
      "Epoch [1686/2500], Train Loss: 0.5926, Train Accuracy: 74.68%, Test Loss: 1.0405, Test Accuracy: 68.35%\n",
      "Epoch [1687/2500], Train Loss: 0.6133, Train Accuracy: 70.84%, Test Loss: 1.0773, Test Accuracy: 67.09%\n",
      "Epoch [1688/2500], Train Loss: 0.6196, Train Accuracy: 76.10%, Test Loss: 1.0720, Test Accuracy: 65.82%\n",
      "Epoch [1689/2500], Train Loss: 0.6092, Train Accuracy: 73.97%, Test Loss: 1.0830, Test Accuracy: 65.82%\n",
      "Epoch [1690/2500], Train Loss: 0.6094, Train Accuracy: 72.83%, Test Loss: 1.0905, Test Accuracy: 64.56%\n",
      "Epoch [1691/2500], Train Loss: 0.5972, Train Accuracy: 73.83%, Test Loss: 1.1030, Test Accuracy: 65.82%\n",
      "Epoch [1692/2500], Train Loss: 0.6179, Train Accuracy: 73.54%, Test Loss: 1.0806, Test Accuracy: 65.82%\n",
      "Epoch [1693/2500], Train Loss: 0.6396, Train Accuracy: 73.12%, Test Loss: 1.0750, Test Accuracy: 65.82%\n",
      "Epoch [1694/2500], Train Loss: 0.5997, Train Accuracy: 71.69%, Test Loss: 1.0501, Test Accuracy: 67.09%\n",
      "Epoch [1695/2500], Train Loss: 0.5936, Train Accuracy: 74.11%, Test Loss: 1.0937, Test Accuracy: 68.35%\n",
      "Epoch [1696/2500], Train Loss: 0.6049, Train Accuracy: 73.40%, Test Loss: 1.0966, Test Accuracy: 65.82%\n",
      "Epoch [1697/2500], Train Loss: 0.6085, Train Accuracy: 74.68%, Test Loss: 1.1038, Test Accuracy: 67.09%\n",
      "Epoch [1698/2500], Train Loss: 0.5970, Train Accuracy: 75.11%, Test Loss: 1.1058, Test Accuracy: 67.09%\n",
      "Epoch [1699/2500], Train Loss: 0.6320, Train Accuracy: 72.26%, Test Loss: 1.0593, Test Accuracy: 65.82%\n",
      "Epoch [1700/2500], Train Loss: 0.6209, Train Accuracy: 73.12%, Test Loss: 1.0488, Test Accuracy: 68.35%\n",
      "Epoch [1701/2500], Train Loss: 0.6111, Train Accuracy: 74.40%, Test Loss: 1.0325, Test Accuracy: 69.62%\n",
      "Epoch [1702/2500], Train Loss: 0.6303, Train Accuracy: 72.83%, Test Loss: 1.0581, Test Accuracy: 62.03%\n",
      "Epoch [1703/2500], Train Loss: 0.5914, Train Accuracy: 73.12%, Test Loss: 1.0894, Test Accuracy: 64.56%\n",
      "Epoch [1704/2500], Train Loss: 0.6041, Train Accuracy: 75.25%, Test Loss: 1.1205, Test Accuracy: 68.35%\n",
      "Epoch [1705/2500], Train Loss: 0.6251, Train Accuracy: 72.69%, Test Loss: 1.1212, Test Accuracy: 65.82%\n",
      "Epoch [1706/2500], Train Loss: 0.6213, Train Accuracy: 73.40%, Test Loss: 1.0831, Test Accuracy: 64.56%\n",
      "Epoch [1707/2500], Train Loss: 0.6228, Train Accuracy: 72.83%, Test Loss: 1.0548, Test Accuracy: 67.09%\n",
      "Epoch [1708/2500], Train Loss: 0.5941, Train Accuracy: 73.12%, Test Loss: 1.0717, Test Accuracy: 67.09%\n",
      "Epoch [1709/2500], Train Loss: 0.6140, Train Accuracy: 72.55%, Test Loss: 1.0568, Test Accuracy: 64.56%\n",
      "Epoch [1710/2500], Train Loss: 0.6015, Train Accuracy: 72.55%, Test Loss: 1.1030, Test Accuracy: 65.82%\n",
      "Epoch [1711/2500], Train Loss: 0.5973, Train Accuracy: 72.97%, Test Loss: 1.1081, Test Accuracy: 64.56%\n",
      "Epoch [1712/2500], Train Loss: 0.6277, Train Accuracy: 73.40%, Test Loss: 1.1010, Test Accuracy: 65.82%\n",
      "Epoch [1713/2500], Train Loss: 0.6063, Train Accuracy: 73.40%, Test Loss: 1.1380, Test Accuracy: 67.09%\n",
      "Epoch [1714/2500], Train Loss: 0.6467, Train Accuracy: 73.12%, Test Loss: 1.0806, Test Accuracy: 65.82%\n",
      "Epoch [1715/2500], Train Loss: 0.6165, Train Accuracy: 73.54%, Test Loss: 1.0489, Test Accuracy: 68.35%\n",
      "Epoch [1716/2500], Train Loss: 0.5955, Train Accuracy: 75.11%, Test Loss: 1.1035, Test Accuracy: 67.09%\n",
      "Epoch [1717/2500], Train Loss: 0.6049, Train Accuracy: 74.82%, Test Loss: 1.0676, Test Accuracy: 65.82%\n",
      "Epoch [1718/2500], Train Loss: 0.6085, Train Accuracy: 71.55%, Test Loss: 1.1185, Test Accuracy: 65.82%\n",
      "Epoch [1719/2500], Train Loss: 0.6028, Train Accuracy: 74.11%, Test Loss: 1.0854, Test Accuracy: 67.09%\n",
      "Epoch [1720/2500], Train Loss: 0.6455, Train Accuracy: 72.97%, Test Loss: 1.1027, Test Accuracy: 62.03%\n",
      "Epoch [1721/2500], Train Loss: 0.6197, Train Accuracy: 73.54%, Test Loss: 1.1098, Test Accuracy: 63.29%\n",
      "Epoch [1722/2500], Train Loss: 0.6181, Train Accuracy: 72.83%, Test Loss: 1.1010, Test Accuracy: 63.29%\n",
      "Epoch [1723/2500], Train Loss: 0.5943, Train Accuracy: 75.39%, Test Loss: 1.1183, Test Accuracy: 64.56%\n",
      "Epoch [1724/2500], Train Loss: 0.6064, Train Accuracy: 74.11%, Test Loss: 1.1063, Test Accuracy: 63.29%\n",
      "Epoch [1725/2500], Train Loss: 0.5978, Train Accuracy: 75.68%, Test Loss: 1.0807, Test Accuracy: 64.56%\n",
      "Epoch [1726/2500], Train Loss: 0.5841, Train Accuracy: 76.81%, Test Loss: 1.0729, Test Accuracy: 67.09%\n",
      "Epoch [1727/2500], Train Loss: 0.6099, Train Accuracy: 74.54%, Test Loss: 1.0794, Test Accuracy: 67.09%\n",
      "Epoch [1728/2500], Train Loss: 0.5856, Train Accuracy: 74.68%, Test Loss: 1.0782, Test Accuracy: 67.09%\n",
      "Epoch [1729/2500], Train Loss: 0.6066, Train Accuracy: 74.11%, Test Loss: 1.0749, Test Accuracy: 64.56%\n",
      "Epoch [1730/2500], Train Loss: 0.5934, Train Accuracy: 74.25%, Test Loss: 1.0523, Test Accuracy: 68.35%\n",
      "Epoch [1731/2500], Train Loss: 0.6197, Train Accuracy: 74.96%, Test Loss: 1.0677, Test Accuracy: 68.35%\n",
      "Epoch [1732/2500], Train Loss: 0.5995, Train Accuracy: 76.10%, Test Loss: 1.0838, Test Accuracy: 64.56%\n",
      "Epoch [1733/2500], Train Loss: 0.6006, Train Accuracy: 73.54%, Test Loss: 1.1350, Test Accuracy: 64.56%\n",
      "Epoch [1734/2500], Train Loss: 0.6072, Train Accuracy: 73.68%, Test Loss: 1.0877, Test Accuracy: 64.56%\n",
      "Epoch [1735/2500], Train Loss: 0.5799, Train Accuracy: 74.25%, Test Loss: 1.1707, Test Accuracy: 65.82%\n",
      "Epoch [1736/2500], Train Loss: 0.6079, Train Accuracy: 74.68%, Test Loss: 1.0688, Test Accuracy: 65.82%\n",
      "Epoch [1737/2500], Train Loss: 0.6185, Train Accuracy: 73.40%, Test Loss: 1.0859, Test Accuracy: 64.56%\n",
      "Epoch [1738/2500], Train Loss: 0.6099, Train Accuracy: 73.12%, Test Loss: 1.1361, Test Accuracy: 64.56%\n",
      "Epoch [1739/2500], Train Loss: 0.6116, Train Accuracy: 72.40%, Test Loss: 1.0738, Test Accuracy: 67.09%\n",
      "Epoch [1740/2500], Train Loss: 0.5913, Train Accuracy: 74.11%, Test Loss: 1.0420, Test Accuracy: 68.35%\n",
      "Epoch [1741/2500], Train Loss: 0.6197, Train Accuracy: 72.83%, Test Loss: 1.0617, Test Accuracy: 67.09%\n",
      "Epoch [1742/2500], Train Loss: 0.6233, Train Accuracy: 73.97%, Test Loss: 1.0689, Test Accuracy: 68.35%\n",
      "Epoch [1743/2500], Train Loss: 0.5989, Train Accuracy: 75.53%, Test Loss: 1.0484, Test Accuracy: 68.35%\n",
      "Epoch [1744/2500], Train Loss: 0.5965, Train Accuracy: 73.97%, Test Loss: 1.0655, Test Accuracy: 65.82%\n",
      "Epoch [1745/2500], Train Loss: 0.6109, Train Accuracy: 74.40%, Test Loss: 1.0488, Test Accuracy: 67.09%\n",
      "Epoch [1746/2500], Train Loss: 0.6234, Train Accuracy: 73.54%, Test Loss: 1.0655, Test Accuracy: 64.56%\n",
      "Epoch [1747/2500], Train Loss: 0.6575, Train Accuracy: 71.27%, Test Loss: 1.0466, Test Accuracy: 64.56%\n",
      "Epoch [1748/2500], Train Loss: 0.6086, Train Accuracy: 72.55%, Test Loss: 1.0896, Test Accuracy: 65.82%\n",
      "Epoch [1749/2500], Train Loss: 0.6156, Train Accuracy: 72.97%, Test Loss: 1.1640, Test Accuracy: 67.09%\n",
      "Epoch [1750/2500], Train Loss: 0.6185, Train Accuracy: 72.12%, Test Loss: 1.0929, Test Accuracy: 63.29%\n",
      "Epoch [1751/2500], Train Loss: 0.5918, Train Accuracy: 74.54%, Test Loss: 1.0845, Test Accuracy: 65.82%\n",
      "Epoch [1752/2500], Train Loss: 0.6032, Train Accuracy: 73.54%, Test Loss: 1.1399, Test Accuracy: 65.82%\n",
      "Epoch [1753/2500], Train Loss: 0.5878, Train Accuracy: 74.40%, Test Loss: 1.1080, Test Accuracy: 65.82%\n",
      "Epoch [1754/2500], Train Loss: 0.5952, Train Accuracy: 74.40%, Test Loss: 1.0864, Test Accuracy: 65.82%\n",
      "Epoch [1755/2500], Train Loss: 0.6247, Train Accuracy: 73.12%, Test Loss: 1.0359, Test Accuracy: 65.82%\n",
      "Epoch [1756/2500], Train Loss: 0.6066, Train Accuracy: 73.54%, Test Loss: 1.1326, Test Accuracy: 63.29%\n",
      "Epoch [1757/2500], Train Loss: 0.6140, Train Accuracy: 74.25%, Test Loss: 1.0745, Test Accuracy: 69.62%\n",
      "Epoch [1758/2500], Train Loss: 0.6160, Train Accuracy: 72.40%, Test Loss: 1.1070, Test Accuracy: 67.09%\n",
      "Epoch [1759/2500], Train Loss: 0.6135, Train Accuracy: 73.40%, Test Loss: 1.0648, Test Accuracy: 69.62%\n",
      "Epoch [1760/2500], Train Loss: 0.6063, Train Accuracy: 73.40%, Test Loss: 1.0620, Test Accuracy: 63.29%\n",
      "Epoch [1761/2500], Train Loss: 0.5727, Train Accuracy: 75.68%, Test Loss: 1.1085, Test Accuracy: 67.09%\n",
      "Epoch [1762/2500], Train Loss: 0.6016, Train Accuracy: 74.25%, Test Loss: 1.1002, Test Accuracy: 63.29%\n",
      "Epoch [1763/2500], Train Loss: 0.5871, Train Accuracy: 75.25%, Test Loss: 1.1514, Test Accuracy: 65.82%\n",
      "Epoch [1764/2500], Train Loss: 0.6019, Train Accuracy: 73.97%, Test Loss: 1.0868, Test Accuracy: 67.09%\n",
      "Epoch [1765/2500], Train Loss: 0.6109, Train Accuracy: 72.40%, Test Loss: 1.1064, Test Accuracy: 65.82%\n",
      "Epoch [1766/2500], Train Loss: 0.5974, Train Accuracy: 75.82%, Test Loss: 1.0983, Test Accuracy: 67.09%\n",
      "Epoch [1767/2500], Train Loss: 0.6047, Train Accuracy: 72.55%, Test Loss: 1.0145, Test Accuracy: 70.89%\n",
      "Epoch [1768/2500], Train Loss: 0.6073, Train Accuracy: 73.54%, Test Loss: 1.0854, Test Accuracy: 68.35%\n",
      "Epoch [1769/2500], Train Loss: 0.6211, Train Accuracy: 72.26%, Test Loss: 1.0964, Test Accuracy: 65.82%\n",
      "Epoch [1770/2500], Train Loss: 0.6126, Train Accuracy: 72.55%, Test Loss: 1.0852, Test Accuracy: 68.35%\n",
      "Epoch [1771/2500], Train Loss: 0.5953, Train Accuracy: 72.40%, Test Loss: 1.1345, Test Accuracy: 65.82%\n",
      "Epoch [1772/2500], Train Loss: 0.6444, Train Accuracy: 70.41%, Test Loss: 1.0641, Test Accuracy: 67.09%\n",
      "Epoch [1773/2500], Train Loss: 0.6240, Train Accuracy: 73.54%, Test Loss: 1.0705, Test Accuracy: 67.09%\n",
      "Epoch [1774/2500], Train Loss: 0.5830, Train Accuracy: 75.96%, Test Loss: 1.0949, Test Accuracy: 63.29%\n",
      "Epoch [1775/2500], Train Loss: 0.5829, Train Accuracy: 73.97%, Test Loss: 1.0849, Test Accuracy: 64.56%\n",
      "Epoch [1776/2500], Train Loss: 0.5857, Train Accuracy: 72.12%, Test Loss: 1.0822, Test Accuracy: 68.35%\n",
      "Epoch [1777/2500], Train Loss: 0.5937, Train Accuracy: 73.12%, Test Loss: 1.1192, Test Accuracy: 64.56%\n",
      "Epoch [1778/2500], Train Loss: 0.6249, Train Accuracy: 74.11%, Test Loss: 1.0850, Test Accuracy: 65.82%\n",
      "Epoch [1779/2500], Train Loss: 0.5877, Train Accuracy: 74.11%, Test Loss: 1.1033, Test Accuracy: 65.82%\n",
      "Epoch [1780/2500], Train Loss: 0.6055, Train Accuracy: 75.25%, Test Loss: 1.0295, Test Accuracy: 67.09%\n",
      "Epoch [1781/2500], Train Loss: 0.6232, Train Accuracy: 73.40%, Test Loss: 1.0972, Test Accuracy: 67.09%\n",
      "Epoch [1782/2500], Train Loss: 0.5993, Train Accuracy: 75.96%, Test Loss: 1.0418, Test Accuracy: 68.35%\n",
      "Epoch [1783/2500], Train Loss: 0.5976, Train Accuracy: 74.40%, Test Loss: 1.1232, Test Accuracy: 67.09%\n",
      "Epoch [1784/2500], Train Loss: 0.6291, Train Accuracy: 71.12%, Test Loss: 1.0610, Test Accuracy: 64.56%\n",
      "Epoch [1785/2500], Train Loss: 0.6085, Train Accuracy: 74.54%, Test Loss: 1.0912, Test Accuracy: 64.56%\n",
      "Epoch [1786/2500], Train Loss: 0.6056, Train Accuracy: 74.96%, Test Loss: 1.1240, Test Accuracy: 65.82%\n",
      "Epoch [1787/2500], Train Loss: 0.5925, Train Accuracy: 75.39%, Test Loss: 1.0700, Test Accuracy: 67.09%\n",
      "Epoch [1788/2500], Train Loss: 0.5802, Train Accuracy: 75.25%, Test Loss: 1.0938, Test Accuracy: 69.62%\n",
      "Epoch [1789/2500], Train Loss: 0.5907, Train Accuracy: 73.26%, Test Loss: 1.0735, Test Accuracy: 65.82%\n",
      "Epoch [1790/2500], Train Loss: 0.6324, Train Accuracy: 72.12%, Test Loss: 1.0760, Test Accuracy: 67.09%\n",
      "Epoch [1791/2500], Train Loss: 0.6334, Train Accuracy: 73.97%, Test Loss: 1.0499, Test Accuracy: 69.62%\n",
      "Epoch [1792/2500], Train Loss: 0.6049, Train Accuracy: 75.53%, Test Loss: 1.0823, Test Accuracy: 65.82%\n",
      "Epoch [1793/2500], Train Loss: 0.6053, Train Accuracy: 73.68%, Test Loss: 1.0778, Test Accuracy: 68.35%\n",
      "Epoch [1794/2500], Train Loss: 0.5957, Train Accuracy: 74.40%, Test Loss: 1.1171, Test Accuracy: 65.82%\n",
      "Epoch [1795/2500], Train Loss: 0.5673, Train Accuracy: 76.81%, Test Loss: 1.0829, Test Accuracy: 65.82%\n",
      "Epoch [1796/2500], Train Loss: 0.5922, Train Accuracy: 73.83%, Test Loss: 1.0969, Test Accuracy: 64.56%\n",
      "Epoch [1797/2500], Train Loss: 0.6069, Train Accuracy: 73.83%, Test Loss: 1.0551, Test Accuracy: 65.82%\n",
      "Epoch [1798/2500], Train Loss: 0.6000, Train Accuracy: 75.11%, Test Loss: 1.1003, Test Accuracy: 65.82%\n",
      "Epoch [1799/2500], Train Loss: 0.6192, Train Accuracy: 74.11%, Test Loss: 1.0847, Test Accuracy: 67.09%\n",
      "Epoch [1800/2500], Train Loss: 0.5997, Train Accuracy: 71.69%, Test Loss: 1.0621, Test Accuracy: 67.09%\n",
      "Epoch [1801/2500], Train Loss: 0.5991, Train Accuracy: 73.97%, Test Loss: 1.0631, Test Accuracy: 68.35%\n",
      "Epoch [1802/2500], Train Loss: 0.5783, Train Accuracy: 74.54%, Test Loss: 1.0599, Test Accuracy: 67.09%\n",
      "Epoch [1803/2500], Train Loss: 0.5959, Train Accuracy: 75.11%, Test Loss: 1.0601, Test Accuracy: 68.35%\n",
      "Epoch [1804/2500], Train Loss: 0.5861, Train Accuracy: 74.82%, Test Loss: 1.0815, Test Accuracy: 67.09%\n",
      "Epoch [1805/2500], Train Loss: 0.6326, Train Accuracy: 74.68%, Test Loss: 1.0572, Test Accuracy: 67.09%\n",
      "Epoch [1806/2500], Train Loss: 0.5841, Train Accuracy: 73.68%, Test Loss: 1.0935, Test Accuracy: 67.09%\n",
      "Epoch [1807/2500], Train Loss: 0.6031, Train Accuracy: 75.25%, Test Loss: 1.1141, Test Accuracy: 67.09%\n",
      "Epoch [1808/2500], Train Loss: 0.5902, Train Accuracy: 74.11%, Test Loss: 1.0465, Test Accuracy: 68.35%\n",
      "Epoch [1809/2500], Train Loss: 0.5766, Train Accuracy: 75.53%, Test Loss: 1.0874, Test Accuracy: 67.09%\n",
      "Epoch [1810/2500], Train Loss: 0.6100, Train Accuracy: 73.97%, Test Loss: 1.0996, Test Accuracy: 69.62%\n",
      "Epoch [1811/2500], Train Loss: 0.6079, Train Accuracy: 74.40%, Test Loss: 1.0800, Test Accuracy: 68.35%\n",
      "Epoch [1812/2500], Train Loss: 0.6048, Train Accuracy: 73.40%, Test Loss: 1.0467, Test Accuracy: 70.89%\n",
      "Epoch [1813/2500], Train Loss: 0.5817, Train Accuracy: 76.53%, Test Loss: 1.0802, Test Accuracy: 68.35%\n",
      "Epoch [1814/2500], Train Loss: 0.5909, Train Accuracy: 74.68%, Test Loss: 1.0641, Test Accuracy: 68.35%\n",
      "Epoch [1815/2500], Train Loss: 0.6000, Train Accuracy: 75.82%, Test Loss: 1.1030, Test Accuracy: 70.89%\n",
      "Epoch [1816/2500], Train Loss: 0.5902, Train Accuracy: 72.55%, Test Loss: 1.1330, Test Accuracy: 64.56%\n",
      "Epoch [1817/2500], Train Loss: 0.5955, Train Accuracy: 73.68%, Test Loss: 1.1441, Test Accuracy: 67.09%\n",
      "Epoch [1818/2500], Train Loss: 0.5970, Train Accuracy: 75.25%, Test Loss: 1.0471, Test Accuracy: 64.56%\n",
      "Epoch [1819/2500], Train Loss: 0.6179, Train Accuracy: 74.54%, Test Loss: 1.0949, Test Accuracy: 67.09%\n",
      "Epoch [1820/2500], Train Loss: 0.5655, Train Accuracy: 75.96%, Test Loss: 1.1148, Test Accuracy: 67.09%\n",
      "Epoch [1821/2500], Train Loss: 0.5779, Train Accuracy: 74.96%, Test Loss: 1.0880, Test Accuracy: 68.35%\n",
      "Epoch [1822/2500], Train Loss: 0.5792, Train Accuracy: 74.11%, Test Loss: 1.0885, Test Accuracy: 65.82%\n",
      "Epoch [1823/2500], Train Loss: 0.5859, Train Accuracy: 75.11%, Test Loss: 1.1269, Test Accuracy: 67.09%\n",
      "Epoch [1824/2500], Train Loss: 0.6077, Train Accuracy: 72.55%, Test Loss: 1.0564, Test Accuracy: 65.82%\n",
      "Epoch [1825/2500], Train Loss: 0.5959, Train Accuracy: 74.25%, Test Loss: 1.0824, Test Accuracy: 64.56%\n",
      "Epoch [1826/2500], Train Loss: 0.6180, Train Accuracy: 73.97%, Test Loss: 1.1145, Test Accuracy: 67.09%\n",
      "Epoch [1827/2500], Train Loss: 0.6057, Train Accuracy: 73.12%, Test Loss: 1.0860, Test Accuracy: 64.56%\n",
      "Epoch [1828/2500], Train Loss: 0.6288, Train Accuracy: 72.97%, Test Loss: 1.0822, Test Accuracy: 67.09%\n",
      "Epoch [1829/2500], Train Loss: 0.6083, Train Accuracy: 74.40%, Test Loss: 1.0886, Test Accuracy: 67.09%\n",
      "Epoch [1830/2500], Train Loss: 0.5840, Train Accuracy: 73.68%, Test Loss: 1.0959, Test Accuracy: 65.82%\n",
      "Epoch [1831/2500], Train Loss: 0.6090, Train Accuracy: 73.68%, Test Loss: 1.1264, Test Accuracy: 68.35%\n",
      "Epoch [1832/2500], Train Loss: 0.5744, Train Accuracy: 76.39%, Test Loss: 1.0982, Test Accuracy: 65.82%\n",
      "Epoch [1833/2500], Train Loss: 0.6176, Train Accuracy: 72.26%, Test Loss: 1.1082, Test Accuracy: 67.09%\n",
      "Epoch [1834/2500], Train Loss: 0.6024, Train Accuracy: 75.39%, Test Loss: 1.1142, Test Accuracy: 69.62%\n",
      "Epoch [1835/2500], Train Loss: 0.5863, Train Accuracy: 73.68%, Test Loss: 1.1392, Test Accuracy: 68.35%\n",
      "Epoch [1836/2500], Train Loss: 0.5763, Train Accuracy: 73.83%, Test Loss: 1.1219, Test Accuracy: 69.62%\n",
      "Epoch [1837/2500], Train Loss: 0.5800, Train Accuracy: 75.25%, Test Loss: 1.0703, Test Accuracy: 67.09%\n",
      "Epoch [1838/2500], Train Loss: 0.5620, Train Accuracy: 76.81%, Test Loss: 1.0721, Test Accuracy: 68.35%\n",
      "Epoch [1839/2500], Train Loss: 0.6191, Train Accuracy: 73.26%, Test Loss: 1.0711, Test Accuracy: 69.62%\n",
      "Epoch [1840/2500], Train Loss: 0.6221, Train Accuracy: 73.97%, Test Loss: 1.0653, Test Accuracy: 69.62%\n",
      "Epoch [1841/2500], Train Loss: 0.5669, Train Accuracy: 75.39%, Test Loss: 1.0752, Test Accuracy: 68.35%\n",
      "Epoch [1842/2500], Train Loss: 0.5990, Train Accuracy: 74.96%, Test Loss: 1.1103, Test Accuracy: 68.35%\n",
      "Epoch [1843/2500], Train Loss: 0.5867, Train Accuracy: 75.96%, Test Loss: 1.0983, Test Accuracy: 67.09%\n",
      "Epoch [1844/2500], Train Loss: 0.5706, Train Accuracy: 74.25%, Test Loss: 1.1584, Test Accuracy: 65.82%\n",
      "Epoch [1845/2500], Train Loss: 0.6131, Train Accuracy: 74.25%, Test Loss: 1.0951, Test Accuracy: 69.62%\n",
      "Epoch [1846/2500], Train Loss: 0.6059, Train Accuracy: 74.11%, Test Loss: 1.0872, Test Accuracy: 65.82%\n",
      "Epoch [1847/2500], Train Loss: 0.5974, Train Accuracy: 71.83%, Test Loss: 1.0980, Test Accuracy: 65.82%\n",
      "Epoch [1848/2500], Train Loss: 0.5882, Train Accuracy: 72.69%, Test Loss: 1.1241, Test Accuracy: 65.82%\n",
      "Epoch [1849/2500], Train Loss: 0.5904, Train Accuracy: 75.39%, Test Loss: 1.1690, Test Accuracy: 65.82%\n",
      "Epoch [1850/2500], Train Loss: 0.6000, Train Accuracy: 74.54%, Test Loss: 1.1835, Test Accuracy: 65.82%\n",
      "Epoch [1851/2500], Train Loss: 0.5801, Train Accuracy: 76.24%, Test Loss: 1.1075, Test Accuracy: 67.09%\n",
      "Epoch [1852/2500], Train Loss: 0.6093, Train Accuracy: 73.26%, Test Loss: 1.1251, Test Accuracy: 64.56%\n",
      "Epoch [1853/2500], Train Loss: 0.6141, Train Accuracy: 72.69%, Test Loss: 1.1057, Test Accuracy: 67.09%\n",
      "Epoch [1854/2500], Train Loss: 0.5911, Train Accuracy: 75.68%, Test Loss: 1.0974, Test Accuracy: 65.82%\n",
      "Epoch [1855/2500], Train Loss: 0.5961, Train Accuracy: 73.68%, Test Loss: 1.1521, Test Accuracy: 65.82%\n",
      "Epoch [1856/2500], Train Loss: 0.6176, Train Accuracy: 72.69%, Test Loss: 1.0653, Test Accuracy: 65.82%\n",
      "Epoch [1857/2500], Train Loss: 0.5989, Train Accuracy: 74.25%, Test Loss: 1.1250, Test Accuracy: 68.35%\n",
      "Epoch [1858/2500], Train Loss: 0.5837, Train Accuracy: 74.25%, Test Loss: 1.1026, Test Accuracy: 63.29%\n",
      "Epoch [1859/2500], Train Loss: 0.5973, Train Accuracy: 77.24%, Test Loss: 1.1249, Test Accuracy: 65.82%\n",
      "Epoch [1860/2500], Train Loss: 0.6068, Train Accuracy: 73.54%, Test Loss: 1.1272, Test Accuracy: 65.82%\n",
      "Epoch [1861/2500], Train Loss: 0.6045, Train Accuracy: 73.26%, Test Loss: 1.1137, Test Accuracy: 65.82%\n",
      "Epoch [1862/2500], Train Loss: 0.5992, Train Accuracy: 73.54%, Test Loss: 1.1275, Test Accuracy: 68.35%\n",
      "Epoch [1863/2500], Train Loss: 0.6174, Train Accuracy: 72.55%, Test Loss: 1.0925, Test Accuracy: 65.82%\n",
      "Epoch [1864/2500], Train Loss: 0.5839, Train Accuracy: 74.25%, Test Loss: 1.0876, Test Accuracy: 67.09%\n",
      "Epoch [1865/2500], Train Loss: 0.5905, Train Accuracy: 74.25%, Test Loss: 1.1282, Test Accuracy: 65.82%\n",
      "Epoch [1866/2500], Train Loss: 0.5716, Train Accuracy: 75.39%, Test Loss: 1.0705, Test Accuracy: 68.35%\n",
      "Epoch [1867/2500], Train Loss: 0.5948, Train Accuracy: 72.69%, Test Loss: 1.1103, Test Accuracy: 67.09%\n",
      "Epoch [1868/2500], Train Loss: 0.5826, Train Accuracy: 73.26%, Test Loss: 1.1047, Test Accuracy: 67.09%\n",
      "Epoch [1869/2500], Train Loss: 0.6098, Train Accuracy: 72.83%, Test Loss: 1.0582, Test Accuracy: 67.09%\n",
      "Epoch [1870/2500], Train Loss: 0.5952, Train Accuracy: 73.40%, Test Loss: 1.1133, Test Accuracy: 65.82%\n",
      "Epoch [1871/2500], Train Loss: 0.5850, Train Accuracy: 75.96%, Test Loss: 1.1258, Test Accuracy: 64.56%\n",
      "Epoch [1872/2500], Train Loss: 0.5808, Train Accuracy: 75.68%, Test Loss: 1.1299, Test Accuracy: 65.82%\n",
      "Epoch [1873/2500], Train Loss: 0.5677, Train Accuracy: 76.67%, Test Loss: 1.1295, Test Accuracy: 67.09%\n",
      "Epoch [1874/2500], Train Loss: 0.6155, Train Accuracy: 74.96%, Test Loss: 1.1446, Test Accuracy: 68.35%\n",
      "Epoch [1875/2500], Train Loss: 0.5788, Train Accuracy: 76.96%, Test Loss: 1.1216, Test Accuracy: 67.09%\n",
      "Epoch [1876/2500], Train Loss: 0.5891, Train Accuracy: 75.11%, Test Loss: 1.1211, Test Accuracy: 67.09%\n",
      "Epoch [1877/2500], Train Loss: 0.6054, Train Accuracy: 73.12%, Test Loss: 1.1390, Test Accuracy: 68.35%\n",
      "Epoch [1878/2500], Train Loss: 0.6038, Train Accuracy: 73.54%, Test Loss: 1.0817, Test Accuracy: 68.35%\n",
      "Epoch [1879/2500], Train Loss: 0.6026, Train Accuracy: 73.68%, Test Loss: 1.1096, Test Accuracy: 67.09%\n",
      "Epoch [1880/2500], Train Loss: 0.6057, Train Accuracy: 73.83%, Test Loss: 1.0853, Test Accuracy: 63.29%\n",
      "Epoch [1881/2500], Train Loss: 0.5739, Train Accuracy: 75.39%, Test Loss: 1.1101, Test Accuracy: 69.62%\n",
      "Epoch [1882/2500], Train Loss: 0.6164, Train Accuracy: 72.55%, Test Loss: 1.1179, Test Accuracy: 65.82%\n",
      "Epoch [1883/2500], Train Loss: 0.5888, Train Accuracy: 75.25%, Test Loss: 1.1547, Test Accuracy: 64.56%\n",
      "Epoch [1884/2500], Train Loss: 0.6071, Train Accuracy: 75.11%, Test Loss: 1.1544, Test Accuracy: 65.82%\n",
      "Epoch [1885/2500], Train Loss: 0.5914, Train Accuracy: 75.96%, Test Loss: 1.0592, Test Accuracy: 64.56%\n",
      "Epoch [1886/2500], Train Loss: 0.5903, Train Accuracy: 73.54%, Test Loss: 1.1228, Test Accuracy: 65.82%\n",
      "Epoch [1887/2500], Train Loss: 0.5966, Train Accuracy: 73.40%, Test Loss: 1.1000, Test Accuracy: 65.82%\n",
      "Epoch [1888/2500], Train Loss: 0.5752, Train Accuracy: 76.10%, Test Loss: 1.0653, Test Accuracy: 63.29%\n",
      "Epoch [1889/2500], Train Loss: 0.5945, Train Accuracy: 74.96%, Test Loss: 1.1604, Test Accuracy: 65.82%\n",
      "Epoch [1890/2500], Train Loss: 0.5908, Train Accuracy: 74.82%, Test Loss: 1.1554, Test Accuracy: 65.82%\n",
      "Epoch [1891/2500], Train Loss: 0.5928, Train Accuracy: 74.82%, Test Loss: 1.1155, Test Accuracy: 64.56%\n",
      "Epoch [1892/2500], Train Loss: 0.5775, Train Accuracy: 74.25%, Test Loss: 1.1183, Test Accuracy: 65.82%\n",
      "Epoch [1893/2500], Train Loss: 0.5938, Train Accuracy: 74.11%, Test Loss: 1.0960, Test Accuracy: 67.09%\n",
      "Epoch [1894/2500], Train Loss: 0.5890, Train Accuracy: 74.54%, Test Loss: 1.0638, Test Accuracy: 67.09%\n",
      "Epoch [1895/2500], Train Loss: 0.5712, Train Accuracy: 73.97%, Test Loss: 1.1126, Test Accuracy: 65.82%\n",
      "Epoch [1896/2500], Train Loss: 0.5888, Train Accuracy: 75.25%, Test Loss: 1.1478, Test Accuracy: 65.82%\n",
      "Epoch [1897/2500], Train Loss: 0.5862, Train Accuracy: 74.40%, Test Loss: 1.1114, Test Accuracy: 67.09%\n",
      "Epoch [1898/2500], Train Loss: 0.6120, Train Accuracy: 73.97%, Test Loss: 1.0852, Test Accuracy: 67.09%\n",
      "Epoch [1899/2500], Train Loss: 0.5994, Train Accuracy: 73.68%, Test Loss: 1.0966, Test Accuracy: 64.56%\n",
      "Epoch [1900/2500], Train Loss: 0.5717, Train Accuracy: 74.96%, Test Loss: 1.1434, Test Accuracy: 64.56%\n",
      "Epoch [1901/2500], Train Loss: 0.6112, Train Accuracy: 72.12%, Test Loss: 1.1412, Test Accuracy: 65.82%\n",
      "Epoch [1902/2500], Train Loss: 0.5981, Train Accuracy: 76.39%, Test Loss: 1.1306, Test Accuracy: 67.09%\n",
      "Epoch [1903/2500], Train Loss: 0.5892, Train Accuracy: 73.68%, Test Loss: 1.1532, Test Accuracy: 67.09%\n",
      "Epoch [1904/2500], Train Loss: 0.5708, Train Accuracy: 75.25%, Test Loss: 1.1073, Test Accuracy: 67.09%\n",
      "Epoch [1905/2500], Train Loss: 0.6053, Train Accuracy: 72.97%, Test Loss: 1.1006, Test Accuracy: 65.82%\n",
      "Epoch [1906/2500], Train Loss: 0.5920, Train Accuracy: 74.11%, Test Loss: 1.0880, Test Accuracy: 65.82%\n",
      "Epoch [1907/2500], Train Loss: 0.5726, Train Accuracy: 73.97%, Test Loss: 1.1455, Test Accuracy: 65.82%\n",
      "Epoch [1908/2500], Train Loss: 0.5962, Train Accuracy: 73.68%, Test Loss: 1.1082, Test Accuracy: 67.09%\n",
      "Epoch [1909/2500], Train Loss: 0.5804, Train Accuracy: 75.11%, Test Loss: 1.1278, Test Accuracy: 67.09%\n",
      "Epoch [1910/2500], Train Loss: 0.6103, Train Accuracy: 72.97%, Test Loss: 1.1219, Test Accuracy: 68.35%\n",
      "Epoch [1911/2500], Train Loss: 0.5680, Train Accuracy: 76.39%, Test Loss: 1.0627, Test Accuracy: 64.56%\n",
      "Epoch [1912/2500], Train Loss: 0.5885, Train Accuracy: 75.53%, Test Loss: 1.1372, Test Accuracy: 67.09%\n",
      "Epoch [1913/2500], Train Loss: 0.5887, Train Accuracy: 75.96%, Test Loss: 1.1402, Test Accuracy: 65.82%\n",
      "Epoch [1914/2500], Train Loss: 0.6005, Train Accuracy: 74.54%, Test Loss: 1.0788, Test Accuracy: 67.09%\n",
      "Epoch [1915/2500], Train Loss: 0.5829, Train Accuracy: 75.82%, Test Loss: 1.1600, Test Accuracy: 64.56%\n",
      "Epoch [1916/2500], Train Loss: 0.6166, Train Accuracy: 74.11%, Test Loss: 1.1242, Test Accuracy: 67.09%\n",
      "Epoch [1917/2500], Train Loss: 0.5696, Train Accuracy: 74.68%, Test Loss: 1.1389, Test Accuracy: 67.09%\n",
      "Epoch [1918/2500], Train Loss: 0.5762, Train Accuracy: 72.97%, Test Loss: 1.1806, Test Accuracy: 64.56%\n",
      "Epoch [1919/2500], Train Loss: 0.5509, Train Accuracy: 76.10%, Test Loss: 1.1434, Test Accuracy: 64.56%\n",
      "Epoch [1920/2500], Train Loss: 0.5974, Train Accuracy: 73.26%, Test Loss: 1.1769, Test Accuracy: 63.29%\n",
      "Epoch [1921/2500], Train Loss: 0.5872, Train Accuracy: 74.54%, Test Loss: 1.1991, Test Accuracy: 63.29%\n",
      "Epoch [1922/2500], Train Loss: 0.5841, Train Accuracy: 74.11%, Test Loss: 1.1333, Test Accuracy: 63.29%\n",
      "Epoch [1923/2500], Train Loss: 0.5845, Train Accuracy: 74.40%, Test Loss: 1.1419, Test Accuracy: 67.09%\n",
      "Epoch [1924/2500], Train Loss: 0.5703, Train Accuracy: 75.11%, Test Loss: 1.1712, Test Accuracy: 64.56%\n",
      "Epoch [1925/2500], Train Loss: 0.5971, Train Accuracy: 73.40%, Test Loss: 1.1695, Test Accuracy: 65.82%\n",
      "Epoch [1926/2500], Train Loss: 0.5875, Train Accuracy: 74.54%, Test Loss: 1.1226, Test Accuracy: 64.56%\n",
      "Epoch [1927/2500], Train Loss: 0.5884, Train Accuracy: 74.11%, Test Loss: 1.1458, Test Accuracy: 68.35%\n",
      "Epoch [1928/2500], Train Loss: 0.5842, Train Accuracy: 74.25%, Test Loss: 1.1024, Test Accuracy: 67.09%\n",
      "Epoch [1929/2500], Train Loss: 0.6045, Train Accuracy: 74.54%, Test Loss: 1.0482, Test Accuracy: 69.62%\n",
      "Epoch [1930/2500], Train Loss: 0.5984, Train Accuracy: 74.96%, Test Loss: 1.0967, Test Accuracy: 67.09%\n",
      "Epoch [1931/2500], Train Loss: 0.5748, Train Accuracy: 74.82%, Test Loss: 1.0830, Test Accuracy: 69.62%\n",
      "Epoch [1932/2500], Train Loss: 0.5797, Train Accuracy: 72.83%, Test Loss: 1.1202, Test Accuracy: 67.09%\n",
      "Epoch [1933/2500], Train Loss: 0.5749, Train Accuracy: 75.25%, Test Loss: 1.1361, Test Accuracy: 67.09%\n",
      "Epoch [1934/2500], Train Loss: 0.5825, Train Accuracy: 76.24%, Test Loss: 1.1447, Test Accuracy: 67.09%\n",
      "Epoch [1935/2500], Train Loss: 0.5813, Train Accuracy: 76.10%, Test Loss: 1.0690, Test Accuracy: 67.09%\n",
      "Epoch [1936/2500], Train Loss: 0.5858, Train Accuracy: 74.25%, Test Loss: 1.1188, Test Accuracy: 67.09%\n",
      "Epoch [1937/2500], Train Loss: 0.5917, Train Accuracy: 73.26%, Test Loss: 1.1459, Test Accuracy: 69.62%\n",
      "Epoch [1938/2500], Train Loss: 0.5661, Train Accuracy: 75.11%, Test Loss: 1.1265, Test Accuracy: 69.62%\n",
      "Epoch [1939/2500], Train Loss: 0.5817, Train Accuracy: 73.97%, Test Loss: 1.1277, Test Accuracy: 69.62%\n",
      "Epoch [1940/2500], Train Loss: 0.5966, Train Accuracy: 74.40%, Test Loss: 1.0837, Test Accuracy: 69.62%\n",
      "Epoch [1941/2500], Train Loss: 0.5897, Train Accuracy: 74.40%, Test Loss: 1.1096, Test Accuracy: 68.35%\n",
      "Epoch [1942/2500], Train Loss: 0.5843, Train Accuracy: 73.97%, Test Loss: 1.1536, Test Accuracy: 65.82%\n",
      "Epoch [1943/2500], Train Loss: 0.5991, Train Accuracy: 76.10%, Test Loss: 1.0616, Test Accuracy: 67.09%\n",
      "Epoch [1944/2500], Train Loss: 0.5900, Train Accuracy: 73.26%, Test Loss: 1.1189, Test Accuracy: 68.35%\n",
      "Epoch [1945/2500], Train Loss: 0.5792, Train Accuracy: 74.82%, Test Loss: 1.0831, Test Accuracy: 67.09%\n",
      "Epoch [1946/2500], Train Loss: 0.5623, Train Accuracy: 76.10%, Test Loss: 1.1254, Test Accuracy: 70.89%\n",
      "Epoch [1947/2500], Train Loss: 0.5619, Train Accuracy: 74.96%, Test Loss: 1.1270, Test Accuracy: 68.35%\n",
      "Epoch [1948/2500], Train Loss: 0.6107, Train Accuracy: 73.26%, Test Loss: 1.0825, Test Accuracy: 68.35%\n",
      "Epoch [1949/2500], Train Loss: 0.5999, Train Accuracy: 75.11%, Test Loss: 1.0642, Test Accuracy: 68.35%\n",
      "Epoch [1950/2500], Train Loss: 0.5781, Train Accuracy: 76.53%, Test Loss: 1.1131, Test Accuracy: 65.82%\n",
      "Epoch [1951/2500], Train Loss: 0.5750, Train Accuracy: 74.25%, Test Loss: 1.1185, Test Accuracy: 67.09%\n",
      "Epoch [1952/2500], Train Loss: 0.5930, Train Accuracy: 74.11%, Test Loss: 1.1040, Test Accuracy: 65.82%\n",
      "Epoch [1953/2500], Train Loss: 0.5873, Train Accuracy: 75.25%, Test Loss: 1.1158, Test Accuracy: 68.35%\n",
      "Epoch [1954/2500], Train Loss: 0.5808, Train Accuracy: 73.83%, Test Loss: 1.1452, Test Accuracy: 65.82%\n",
      "Epoch [1955/2500], Train Loss: 0.5813, Train Accuracy: 75.68%, Test Loss: 1.1712, Test Accuracy: 65.82%\n",
      "Epoch [1956/2500], Train Loss: 0.5812, Train Accuracy: 74.96%, Test Loss: 1.1750, Test Accuracy: 67.09%\n",
      "Epoch [1957/2500], Train Loss: 0.5710, Train Accuracy: 74.68%, Test Loss: 1.1625, Test Accuracy: 65.82%\n",
      "Epoch [1958/2500], Train Loss: 0.6085, Train Accuracy: 72.55%, Test Loss: 1.0786, Test Accuracy: 65.82%\n",
      "Epoch [1959/2500], Train Loss: 0.5974, Train Accuracy: 74.25%, Test Loss: 1.1098, Test Accuracy: 68.35%\n",
      "Epoch [1960/2500], Train Loss: 0.5683, Train Accuracy: 74.11%, Test Loss: 1.1408, Test Accuracy: 67.09%\n",
      "Epoch [1961/2500], Train Loss: 0.5795, Train Accuracy: 74.54%, Test Loss: 1.1641, Test Accuracy: 65.82%\n",
      "Epoch [1962/2500], Train Loss: 0.6047, Train Accuracy: 71.69%, Test Loss: 1.1422, Test Accuracy: 65.82%\n",
      "Epoch [1963/2500], Train Loss: 0.5705, Train Accuracy: 76.96%, Test Loss: 1.1801, Test Accuracy: 67.09%\n",
      "Epoch [1964/2500], Train Loss: 0.6014, Train Accuracy: 74.68%, Test Loss: 1.1461, Test Accuracy: 67.09%\n",
      "Epoch [1965/2500], Train Loss: 0.5891, Train Accuracy: 73.68%, Test Loss: 1.1461, Test Accuracy: 68.35%\n",
      "Epoch [1966/2500], Train Loss: 0.6007, Train Accuracy: 73.26%, Test Loss: 1.1248, Test Accuracy: 65.82%\n",
      "Epoch [1967/2500], Train Loss: 0.5730, Train Accuracy: 75.82%, Test Loss: 1.0525, Test Accuracy: 68.35%\n",
      "Epoch [1968/2500], Train Loss: 0.5777, Train Accuracy: 74.68%, Test Loss: 1.1820, Test Accuracy: 67.09%\n",
      "Epoch [1969/2500], Train Loss: 0.6143, Train Accuracy: 73.54%, Test Loss: 1.1099, Test Accuracy: 67.09%\n",
      "Epoch [1970/2500], Train Loss: 0.6201, Train Accuracy: 74.40%, Test Loss: 1.1270, Test Accuracy: 68.35%\n",
      "Epoch [1971/2500], Train Loss: 0.5809, Train Accuracy: 75.96%, Test Loss: 1.1205, Test Accuracy: 67.09%\n",
      "Epoch [1972/2500], Train Loss: 0.5889, Train Accuracy: 75.82%, Test Loss: 1.1220, Test Accuracy: 67.09%\n",
      "Epoch [1973/2500], Train Loss: 0.6082, Train Accuracy: 72.97%, Test Loss: 1.1770, Test Accuracy: 65.82%\n",
      "Epoch [1974/2500], Train Loss: 0.5948, Train Accuracy: 75.11%, Test Loss: 1.1624, Test Accuracy: 67.09%\n",
      "Epoch [1975/2500], Train Loss: 0.5829, Train Accuracy: 72.83%, Test Loss: 1.1106, Test Accuracy: 65.82%\n",
      "Epoch [1976/2500], Train Loss: 0.5971, Train Accuracy: 74.54%, Test Loss: 1.1450, Test Accuracy: 67.09%\n",
      "Epoch [1977/2500], Train Loss: 0.5878, Train Accuracy: 74.40%, Test Loss: 1.1356, Test Accuracy: 65.82%\n",
      "Epoch [1978/2500], Train Loss: 0.5586, Train Accuracy: 75.25%, Test Loss: 1.1675, Test Accuracy: 68.35%\n",
      "Epoch [1979/2500], Train Loss: 0.5672, Train Accuracy: 76.53%, Test Loss: 1.2163, Test Accuracy: 65.82%\n",
      "Epoch [1980/2500], Train Loss: 0.5819, Train Accuracy: 75.25%, Test Loss: 1.1513, Test Accuracy: 67.09%\n",
      "Epoch [1981/2500], Train Loss: 0.5987, Train Accuracy: 73.26%, Test Loss: 1.1644, Test Accuracy: 65.82%\n",
      "Epoch [1982/2500], Train Loss: 0.5962, Train Accuracy: 76.39%, Test Loss: 1.0938, Test Accuracy: 65.82%\n",
      "Epoch [1983/2500], Train Loss: 0.6025, Train Accuracy: 73.83%, Test Loss: 1.1636, Test Accuracy: 64.56%\n",
      "Epoch [1984/2500], Train Loss: 0.5601, Train Accuracy: 74.25%, Test Loss: 1.1228, Test Accuracy: 65.82%\n",
      "Epoch [1985/2500], Train Loss: 0.5675, Train Accuracy: 76.67%, Test Loss: 1.1371, Test Accuracy: 64.56%\n",
      "Epoch [1986/2500], Train Loss: 0.5817, Train Accuracy: 73.68%, Test Loss: 1.1004, Test Accuracy: 65.82%\n",
      "Epoch [1987/2500], Train Loss: 0.5996, Train Accuracy: 74.40%, Test Loss: 1.0841, Test Accuracy: 65.82%\n",
      "Epoch [1988/2500], Train Loss: 0.5957, Train Accuracy: 76.10%, Test Loss: 1.1698, Test Accuracy: 64.56%\n",
      "Epoch [1989/2500], Train Loss: 0.6006, Train Accuracy: 74.40%, Test Loss: 1.1074, Test Accuracy: 65.82%\n",
      "Epoch [1990/2500], Train Loss: 0.5688, Train Accuracy: 75.82%, Test Loss: 1.1100, Test Accuracy: 67.09%\n",
      "Epoch [1991/2500], Train Loss: 0.5794, Train Accuracy: 74.68%, Test Loss: 1.1240, Test Accuracy: 68.35%\n",
      "Epoch [1992/2500], Train Loss: 0.5958, Train Accuracy: 75.53%, Test Loss: 1.1356, Test Accuracy: 69.62%\n",
      "Epoch [1993/2500], Train Loss: 0.5680, Train Accuracy: 76.81%, Test Loss: 1.0875, Test Accuracy: 68.35%\n",
      "Epoch [1994/2500], Train Loss: 0.5870, Train Accuracy: 75.39%, Test Loss: 1.1789, Test Accuracy: 69.62%\n",
      "Epoch [1995/2500], Train Loss: 0.5881, Train Accuracy: 75.11%, Test Loss: 1.1344, Test Accuracy: 67.09%\n",
      "Epoch [1996/2500], Train Loss: 0.5915, Train Accuracy: 74.25%, Test Loss: 1.0959, Test Accuracy: 68.35%\n",
      "Epoch [1997/2500], Train Loss: 0.5923, Train Accuracy: 74.25%, Test Loss: 1.1370, Test Accuracy: 68.35%\n",
      "Epoch [1998/2500], Train Loss: 0.5747, Train Accuracy: 75.25%, Test Loss: 1.1193, Test Accuracy: 67.09%\n",
      "Epoch [1999/2500], Train Loss: 0.5529, Train Accuracy: 75.68%, Test Loss: 1.1437, Test Accuracy: 65.82%\n",
      "Epoch [2000/2500], Train Loss: 0.5829, Train Accuracy: 73.26%, Test Loss: 1.0836, Test Accuracy: 68.35%\n",
      "Epoch [2001/2500], Train Loss: 0.5865, Train Accuracy: 75.25%, Test Loss: 1.1302, Test Accuracy: 67.09%\n",
      "Epoch [2002/2500], Train Loss: 0.5826, Train Accuracy: 74.54%, Test Loss: 1.1221, Test Accuracy: 68.35%\n",
      "Epoch [2003/2500], Train Loss: 0.5849, Train Accuracy: 74.82%, Test Loss: 1.1632, Test Accuracy: 65.82%\n",
      "Epoch [2004/2500], Train Loss: 0.6101, Train Accuracy: 74.11%, Test Loss: 1.1252, Test Accuracy: 67.09%\n",
      "Epoch [2005/2500], Train Loss: 0.5868, Train Accuracy: 73.83%, Test Loss: 1.1174, Test Accuracy: 64.56%\n",
      "Epoch [2006/2500], Train Loss: 0.5709, Train Accuracy: 74.82%, Test Loss: 1.0850, Test Accuracy: 67.09%\n",
      "Epoch [2007/2500], Train Loss: 0.5696, Train Accuracy: 76.53%, Test Loss: 1.1802, Test Accuracy: 65.82%\n",
      "Epoch [2008/2500], Train Loss: 0.5836, Train Accuracy: 73.26%, Test Loss: 1.1211, Test Accuracy: 65.82%\n",
      "Epoch [2009/2500], Train Loss: 0.5995, Train Accuracy: 73.68%, Test Loss: 1.0959, Test Accuracy: 65.82%\n",
      "Epoch [2010/2500], Train Loss: 0.5882, Train Accuracy: 73.26%, Test Loss: 1.0911, Test Accuracy: 65.82%\n",
      "Epoch [2011/2500], Train Loss: 0.5565, Train Accuracy: 75.82%, Test Loss: 1.2059, Test Accuracy: 63.29%\n",
      "Epoch [2012/2500], Train Loss: 0.5942, Train Accuracy: 74.40%, Test Loss: 1.1456, Test Accuracy: 65.82%\n",
      "Epoch [2013/2500], Train Loss: 0.5830, Train Accuracy: 75.53%, Test Loss: 1.1420, Test Accuracy: 67.09%\n",
      "Epoch [2014/2500], Train Loss: 0.6039, Train Accuracy: 72.83%, Test Loss: 1.1301, Test Accuracy: 67.09%\n",
      "Epoch [2015/2500], Train Loss: 0.5777, Train Accuracy: 76.67%, Test Loss: 1.1662, Test Accuracy: 64.56%\n",
      "Epoch [2016/2500], Train Loss: 0.5710, Train Accuracy: 76.10%, Test Loss: 1.1214, Test Accuracy: 64.56%\n",
      "Epoch [2017/2500], Train Loss: 0.5763, Train Accuracy: 74.68%, Test Loss: 1.1719, Test Accuracy: 63.29%\n",
      "Epoch [2018/2500], Train Loss: 0.5773, Train Accuracy: 76.10%, Test Loss: 1.2072, Test Accuracy: 64.56%\n",
      "Epoch [2019/2500], Train Loss: 0.5910, Train Accuracy: 73.54%, Test Loss: 1.1579, Test Accuracy: 64.56%\n",
      "Epoch [2020/2500], Train Loss: 0.5662, Train Accuracy: 77.24%, Test Loss: 1.1280, Test Accuracy: 64.56%\n",
      "Epoch [2021/2500], Train Loss: 0.5686, Train Accuracy: 73.54%, Test Loss: 1.1265, Test Accuracy: 67.09%\n",
      "Epoch [2022/2500], Train Loss: 0.5861, Train Accuracy: 72.55%, Test Loss: 1.2046, Test Accuracy: 65.82%\n",
      "Epoch [2023/2500], Train Loss: 0.5950, Train Accuracy: 75.25%, Test Loss: 1.1199, Test Accuracy: 65.82%\n",
      "Epoch [2024/2500], Train Loss: 0.5906, Train Accuracy: 74.25%, Test Loss: 1.1352, Test Accuracy: 68.35%\n",
      "Epoch [2025/2500], Train Loss: 0.6027, Train Accuracy: 73.40%, Test Loss: 1.1668, Test Accuracy: 65.82%\n",
      "Epoch [2026/2500], Train Loss: 0.5863, Train Accuracy: 76.39%, Test Loss: 1.1443, Test Accuracy: 68.35%\n",
      "Epoch [2027/2500], Train Loss: 0.5760, Train Accuracy: 75.96%, Test Loss: 1.1322, Test Accuracy: 64.56%\n",
      "Epoch [2028/2500], Train Loss: 0.5881, Train Accuracy: 74.11%, Test Loss: 1.1244, Test Accuracy: 64.56%\n",
      "Epoch [2029/2500], Train Loss: 0.5674, Train Accuracy: 75.53%, Test Loss: 1.1612, Test Accuracy: 64.56%\n",
      "Epoch [2030/2500], Train Loss: 0.5702, Train Accuracy: 74.11%, Test Loss: 1.1985, Test Accuracy: 67.09%\n",
      "Epoch [2031/2500], Train Loss: 0.5652, Train Accuracy: 75.82%, Test Loss: 1.1473, Test Accuracy: 65.82%\n",
      "Epoch [2032/2500], Train Loss: 0.5984, Train Accuracy: 73.97%, Test Loss: 1.1559, Test Accuracy: 63.29%\n",
      "Epoch [2033/2500], Train Loss: 0.5894, Train Accuracy: 73.12%, Test Loss: 1.1511, Test Accuracy: 63.29%\n",
      "Epoch [2034/2500], Train Loss: 0.5819, Train Accuracy: 74.82%, Test Loss: 1.1938, Test Accuracy: 65.82%\n",
      "Epoch [2035/2500], Train Loss: 0.5933, Train Accuracy: 73.12%, Test Loss: 1.1366, Test Accuracy: 67.09%\n",
      "Epoch [2036/2500], Train Loss: 0.5967, Train Accuracy: 75.39%, Test Loss: 1.1241, Test Accuracy: 64.56%\n",
      "Epoch [2037/2500], Train Loss: 0.5753, Train Accuracy: 75.68%, Test Loss: 1.1569, Test Accuracy: 63.29%\n",
      "Epoch [2038/2500], Train Loss: 0.5856, Train Accuracy: 75.96%, Test Loss: 1.0920, Test Accuracy: 67.09%\n",
      "Epoch [2039/2500], Train Loss: 0.5774, Train Accuracy: 75.68%, Test Loss: 1.0738, Test Accuracy: 68.35%\n",
      "Epoch [2040/2500], Train Loss: 0.5529, Train Accuracy: 75.53%, Test Loss: 1.1297, Test Accuracy: 65.82%\n",
      "Epoch [2041/2500], Train Loss: 0.5788, Train Accuracy: 76.10%, Test Loss: 1.1129, Test Accuracy: 63.29%\n",
      "Epoch [2042/2500], Train Loss: 0.5923, Train Accuracy: 73.97%, Test Loss: 1.0989, Test Accuracy: 67.09%\n",
      "Epoch [2043/2500], Train Loss: 0.5518, Train Accuracy: 76.10%, Test Loss: 1.1885, Test Accuracy: 67.09%\n",
      "Epoch [2044/2500], Train Loss: 0.5509, Train Accuracy: 77.10%, Test Loss: 1.1418, Test Accuracy: 65.82%\n",
      "Epoch [2045/2500], Train Loss: 0.5662, Train Accuracy: 76.39%, Test Loss: 1.1918, Test Accuracy: 64.56%\n",
      "Epoch [2046/2500], Train Loss: 0.5733, Train Accuracy: 76.24%, Test Loss: 1.1523, Test Accuracy: 65.82%\n",
      "Epoch [2047/2500], Train Loss: 0.5789, Train Accuracy: 75.82%, Test Loss: 1.1504, Test Accuracy: 67.09%\n",
      "Epoch [2048/2500], Train Loss: 0.5983, Train Accuracy: 73.97%, Test Loss: 1.0959, Test Accuracy: 67.09%\n",
      "Epoch [2049/2500], Train Loss: 0.5827, Train Accuracy: 75.53%, Test Loss: 1.1622, Test Accuracy: 68.35%\n",
      "Epoch [2050/2500], Train Loss: 0.5525, Train Accuracy: 75.82%, Test Loss: 1.1760, Test Accuracy: 64.56%\n",
      "Epoch [2051/2500], Train Loss: 0.5679, Train Accuracy: 75.96%, Test Loss: 1.1328, Test Accuracy: 68.35%\n",
      "Epoch [2052/2500], Train Loss: 0.5628, Train Accuracy: 76.10%, Test Loss: 1.1549, Test Accuracy: 68.35%\n",
      "Epoch [2053/2500], Train Loss: 0.5635, Train Accuracy: 75.25%, Test Loss: 1.1089, Test Accuracy: 63.29%\n",
      "Epoch [2054/2500], Train Loss: 0.5814, Train Accuracy: 75.25%, Test Loss: 1.1352, Test Accuracy: 65.82%\n",
      "Epoch [2055/2500], Train Loss: 0.5851, Train Accuracy: 75.96%, Test Loss: 1.1748, Test Accuracy: 65.82%\n",
      "Epoch [2056/2500], Train Loss: 0.5801, Train Accuracy: 74.68%, Test Loss: 1.1885, Test Accuracy: 67.09%\n",
      "Epoch [2057/2500], Train Loss: 0.5748, Train Accuracy: 76.67%, Test Loss: 1.1915, Test Accuracy: 64.56%\n",
      "Epoch [2058/2500], Train Loss: 0.5719, Train Accuracy: 74.96%, Test Loss: 1.1729, Test Accuracy: 64.56%\n",
      "Epoch [2059/2500], Train Loss: 0.5516, Train Accuracy: 76.53%, Test Loss: 1.1355, Test Accuracy: 67.09%\n",
      "Epoch [2060/2500], Train Loss: 0.5750, Train Accuracy: 75.53%, Test Loss: 1.1629, Test Accuracy: 63.29%\n",
      "Epoch [2061/2500], Train Loss: 0.5867, Train Accuracy: 72.40%, Test Loss: 1.1355, Test Accuracy: 65.82%\n",
      "Epoch [2062/2500], Train Loss: 0.5486, Train Accuracy: 76.24%, Test Loss: 1.2043, Test Accuracy: 67.09%\n",
      "Epoch [2063/2500], Train Loss: 0.5561, Train Accuracy: 77.52%, Test Loss: 1.1804, Test Accuracy: 64.56%\n",
      "Epoch [2064/2500], Train Loss: 0.5778, Train Accuracy: 73.97%, Test Loss: 1.1882, Test Accuracy: 65.82%\n",
      "Epoch [2065/2500], Train Loss: 0.5500, Train Accuracy: 76.96%, Test Loss: 1.1455, Test Accuracy: 68.35%\n",
      "Epoch [2066/2500], Train Loss: 0.5779, Train Accuracy: 75.82%, Test Loss: 1.2058, Test Accuracy: 67.09%\n",
      "Epoch [2067/2500], Train Loss: 0.5699, Train Accuracy: 75.53%, Test Loss: 1.1733, Test Accuracy: 67.09%\n",
      "Epoch [2068/2500], Train Loss: 0.5748, Train Accuracy: 76.67%, Test Loss: 1.1475, Test Accuracy: 67.09%\n",
      "Epoch [2069/2500], Train Loss: 0.5459, Train Accuracy: 77.24%, Test Loss: 1.2116, Test Accuracy: 65.82%\n",
      "Epoch [2070/2500], Train Loss: 0.5544, Train Accuracy: 76.39%, Test Loss: 1.1641, Test Accuracy: 62.03%\n",
      "Epoch [2071/2500], Train Loss: 0.5919, Train Accuracy: 73.26%, Test Loss: 1.1459, Test Accuracy: 68.35%\n",
      "Epoch [2072/2500], Train Loss: 0.5773, Train Accuracy: 75.11%, Test Loss: 1.1662, Test Accuracy: 63.29%\n",
      "Epoch [2073/2500], Train Loss: 0.5583, Train Accuracy: 74.11%, Test Loss: 1.1627, Test Accuracy: 68.35%\n",
      "Epoch [2074/2500], Train Loss: 0.5719, Train Accuracy: 74.82%, Test Loss: 1.1672, Test Accuracy: 64.56%\n",
      "Epoch [2075/2500], Train Loss: 0.5701, Train Accuracy: 75.25%, Test Loss: 1.1724, Test Accuracy: 67.09%\n",
      "Epoch [2076/2500], Train Loss: 0.5670, Train Accuracy: 76.10%, Test Loss: 1.1971, Test Accuracy: 64.56%\n",
      "Epoch [2077/2500], Train Loss: 0.5666, Train Accuracy: 75.39%, Test Loss: 1.2085, Test Accuracy: 65.82%\n",
      "Epoch [2078/2500], Train Loss: 0.5712, Train Accuracy: 76.24%, Test Loss: 1.1622, Test Accuracy: 65.82%\n",
      "Epoch [2079/2500], Train Loss: 0.5500, Train Accuracy: 75.82%, Test Loss: 1.2182, Test Accuracy: 64.56%\n",
      "Epoch [2080/2500], Train Loss: 0.5641, Train Accuracy: 76.96%, Test Loss: 1.2006, Test Accuracy: 64.56%\n",
      "Epoch [2081/2500], Train Loss: 0.5926, Train Accuracy: 74.68%, Test Loss: 1.1627, Test Accuracy: 65.82%\n",
      "Epoch [2082/2500], Train Loss: 0.5889, Train Accuracy: 73.40%, Test Loss: 1.1776, Test Accuracy: 64.56%\n",
      "Epoch [2083/2500], Train Loss: 0.5752, Train Accuracy: 76.67%, Test Loss: 1.2169, Test Accuracy: 64.56%\n",
      "Epoch [2084/2500], Train Loss: 0.5970, Train Accuracy: 74.96%, Test Loss: 1.1957, Test Accuracy: 63.29%\n",
      "Epoch [2085/2500], Train Loss: 0.5794, Train Accuracy: 75.39%, Test Loss: 1.1791, Test Accuracy: 65.82%\n",
      "Epoch [2086/2500], Train Loss: 0.5942, Train Accuracy: 73.83%, Test Loss: 1.1963, Test Accuracy: 64.56%\n",
      "Epoch [2087/2500], Train Loss: 0.5613, Train Accuracy: 77.38%, Test Loss: 1.2052, Test Accuracy: 67.09%\n",
      "Epoch [2088/2500], Train Loss: 0.5592, Train Accuracy: 78.24%, Test Loss: 1.2164, Test Accuracy: 64.56%\n",
      "Epoch [2089/2500], Train Loss: 0.5738, Train Accuracy: 75.96%, Test Loss: 1.1571, Test Accuracy: 67.09%\n",
      "Epoch [2090/2500], Train Loss: 0.5846, Train Accuracy: 74.82%, Test Loss: 1.2192, Test Accuracy: 64.56%\n",
      "Epoch [2091/2500], Train Loss: 0.5901, Train Accuracy: 74.68%, Test Loss: 1.1620, Test Accuracy: 67.09%\n",
      "Epoch [2092/2500], Train Loss: 0.5727, Train Accuracy: 76.81%, Test Loss: 1.1975, Test Accuracy: 65.82%\n",
      "Epoch [2093/2500], Train Loss: 0.5373, Train Accuracy: 77.95%, Test Loss: 1.2155, Test Accuracy: 67.09%\n",
      "Epoch [2094/2500], Train Loss: 0.5528, Train Accuracy: 76.67%, Test Loss: 1.1700, Test Accuracy: 69.62%\n",
      "Epoch [2095/2500], Train Loss: 0.5889, Train Accuracy: 75.68%, Test Loss: 1.1618, Test Accuracy: 65.82%\n",
      "Epoch [2096/2500], Train Loss: 0.5753, Train Accuracy: 74.82%, Test Loss: 1.1781, Test Accuracy: 65.82%\n",
      "Epoch [2097/2500], Train Loss: 0.5673, Train Accuracy: 74.25%, Test Loss: 1.1157, Test Accuracy: 64.56%\n",
      "Epoch [2098/2500], Train Loss: 0.5527, Train Accuracy: 75.82%, Test Loss: 1.1528, Test Accuracy: 65.82%\n",
      "Epoch [2099/2500], Train Loss: 0.5772, Train Accuracy: 72.97%, Test Loss: 1.2028, Test Accuracy: 67.09%\n",
      "Epoch [2100/2500], Train Loss: 0.5942, Train Accuracy: 77.10%, Test Loss: 1.2041, Test Accuracy: 63.29%\n",
      "Epoch [2101/2500], Train Loss: 0.6145, Train Accuracy: 73.54%, Test Loss: 1.1747, Test Accuracy: 65.82%\n",
      "Epoch [2102/2500], Train Loss: 0.5553, Train Accuracy: 76.39%, Test Loss: 1.1127, Test Accuracy: 65.82%\n",
      "Epoch [2103/2500], Train Loss: 0.5509, Train Accuracy: 74.40%, Test Loss: 1.1360, Test Accuracy: 64.56%\n",
      "Epoch [2104/2500], Train Loss: 0.5740, Train Accuracy: 76.81%, Test Loss: 1.2095, Test Accuracy: 63.29%\n",
      "Epoch [2105/2500], Train Loss: 0.5877, Train Accuracy: 73.83%, Test Loss: 1.2054, Test Accuracy: 67.09%\n",
      "Epoch [2106/2500], Train Loss: 0.5914, Train Accuracy: 75.53%, Test Loss: 1.1652, Test Accuracy: 67.09%\n",
      "Epoch [2107/2500], Train Loss: 0.5729, Train Accuracy: 74.96%, Test Loss: 1.1716, Test Accuracy: 65.82%\n",
      "Epoch [2108/2500], Train Loss: 0.5833, Train Accuracy: 75.11%, Test Loss: 1.2102, Test Accuracy: 62.03%\n",
      "Epoch [2109/2500], Train Loss: 0.5844, Train Accuracy: 75.82%, Test Loss: 1.1384, Test Accuracy: 67.09%\n",
      "Epoch [2110/2500], Train Loss: 0.5660, Train Accuracy: 75.82%, Test Loss: 1.1616, Test Accuracy: 64.56%\n",
      "Epoch [2111/2500], Train Loss: 0.5767, Train Accuracy: 75.39%, Test Loss: 1.1890, Test Accuracy: 65.82%\n",
      "Epoch [2112/2500], Train Loss: 0.5542, Train Accuracy: 75.53%, Test Loss: 1.1785, Test Accuracy: 65.82%\n",
      "Epoch [2113/2500], Train Loss: 0.5597, Train Accuracy: 75.25%, Test Loss: 1.1977, Test Accuracy: 64.56%\n",
      "Epoch [2114/2500], Train Loss: 0.5822, Train Accuracy: 74.82%, Test Loss: 1.2005, Test Accuracy: 65.82%\n",
      "Epoch [2115/2500], Train Loss: 0.5731, Train Accuracy: 73.97%, Test Loss: 1.1876, Test Accuracy: 67.09%\n",
      "Epoch [2116/2500], Train Loss: 0.5802, Train Accuracy: 74.11%, Test Loss: 1.2108, Test Accuracy: 67.09%\n",
      "Epoch [2117/2500], Train Loss: 0.5517, Train Accuracy: 75.68%, Test Loss: 1.1673, Test Accuracy: 67.09%\n",
      "Epoch [2118/2500], Train Loss: 0.5735, Train Accuracy: 75.25%, Test Loss: 1.1619, Test Accuracy: 65.82%\n",
      "Epoch [2119/2500], Train Loss: 0.5869, Train Accuracy: 75.39%, Test Loss: 1.1698, Test Accuracy: 65.82%\n",
      "Epoch [2120/2500], Train Loss: 0.5947, Train Accuracy: 75.53%, Test Loss: 1.1464, Test Accuracy: 67.09%\n",
      "Epoch [2121/2500], Train Loss: 0.6085, Train Accuracy: 76.53%, Test Loss: 1.1027, Test Accuracy: 67.09%\n",
      "Epoch [2122/2500], Train Loss: 0.5715, Train Accuracy: 75.11%, Test Loss: 1.1502, Test Accuracy: 64.56%\n",
      "Epoch [2123/2500], Train Loss: 0.5603, Train Accuracy: 75.96%, Test Loss: 1.1716, Test Accuracy: 65.82%\n",
      "Epoch [2124/2500], Train Loss: 0.5417, Train Accuracy: 76.81%, Test Loss: 1.2435, Test Accuracy: 68.35%\n",
      "Epoch [2125/2500], Train Loss: 0.5664, Train Accuracy: 75.68%, Test Loss: 1.2111, Test Accuracy: 67.09%\n",
      "Epoch [2126/2500], Train Loss: 0.5560, Train Accuracy: 76.81%, Test Loss: 1.2059, Test Accuracy: 68.35%\n",
      "Epoch [2127/2500], Train Loss: 0.5873, Train Accuracy: 74.68%, Test Loss: 1.1907, Test Accuracy: 67.09%\n",
      "Epoch [2128/2500], Train Loss: 0.5811, Train Accuracy: 73.83%, Test Loss: 1.1366, Test Accuracy: 68.35%\n",
      "Epoch [2129/2500], Train Loss: 0.5701, Train Accuracy: 74.11%, Test Loss: 1.2431, Test Accuracy: 65.82%\n",
      "Epoch [2130/2500], Train Loss: 0.5805, Train Accuracy: 75.11%, Test Loss: 1.1914, Test Accuracy: 68.35%\n",
      "Epoch [2131/2500], Train Loss: 0.5504, Train Accuracy: 74.96%, Test Loss: 1.1339, Test Accuracy: 64.56%\n",
      "Epoch [2132/2500], Train Loss: 0.5548, Train Accuracy: 76.53%, Test Loss: 1.2070, Test Accuracy: 68.35%\n",
      "Epoch [2133/2500], Train Loss: 0.5850, Train Accuracy: 76.10%, Test Loss: 1.2435, Test Accuracy: 63.29%\n",
      "Epoch [2134/2500], Train Loss: 0.5689, Train Accuracy: 75.68%, Test Loss: 1.2195, Test Accuracy: 63.29%\n",
      "Epoch [2135/2500], Train Loss: 0.5754, Train Accuracy: 75.11%, Test Loss: 1.2121, Test Accuracy: 65.82%\n",
      "Epoch [2136/2500], Train Loss: 0.5340, Train Accuracy: 77.95%, Test Loss: 1.1453, Test Accuracy: 65.82%\n",
      "Epoch [2137/2500], Train Loss: 0.5709, Train Accuracy: 77.10%, Test Loss: 1.2454, Test Accuracy: 63.29%\n",
      "Epoch [2138/2500], Train Loss: 0.5407, Train Accuracy: 77.10%, Test Loss: 1.2469, Test Accuracy: 63.29%\n",
      "Epoch [2139/2500], Train Loss: 0.5541, Train Accuracy: 76.24%, Test Loss: 1.1959, Test Accuracy: 64.56%\n",
      "Epoch [2140/2500], Train Loss: 0.5556, Train Accuracy: 75.96%, Test Loss: 1.2249, Test Accuracy: 63.29%\n",
      "Epoch [2141/2500], Train Loss: 0.5794, Train Accuracy: 77.10%, Test Loss: 1.2258, Test Accuracy: 67.09%\n",
      "Epoch [2142/2500], Train Loss: 0.5854, Train Accuracy: 73.97%, Test Loss: 1.2096, Test Accuracy: 64.56%\n",
      "Epoch [2143/2500], Train Loss: 0.5749, Train Accuracy: 73.97%, Test Loss: 1.2234, Test Accuracy: 63.29%\n",
      "Epoch [2144/2500], Train Loss: 0.5810, Train Accuracy: 71.83%, Test Loss: 1.1969, Test Accuracy: 65.82%\n",
      "Epoch [2145/2500], Train Loss: 0.5629, Train Accuracy: 75.39%, Test Loss: 1.2341, Test Accuracy: 63.29%\n",
      "Epoch [2146/2500], Train Loss: 0.5726, Train Accuracy: 76.67%, Test Loss: 1.2057, Test Accuracy: 65.82%\n",
      "Epoch [2147/2500], Train Loss: 0.5630, Train Accuracy: 76.39%, Test Loss: 1.1857, Test Accuracy: 65.82%\n",
      "Epoch [2148/2500], Train Loss: 0.5905, Train Accuracy: 75.39%, Test Loss: 1.2552, Test Accuracy: 63.29%\n",
      "Epoch [2149/2500], Train Loss: 0.5482, Train Accuracy: 75.53%, Test Loss: 1.2671, Test Accuracy: 64.56%\n",
      "Epoch [2150/2500], Train Loss: 0.5740, Train Accuracy: 75.53%, Test Loss: 1.2511, Test Accuracy: 64.56%\n",
      "Epoch [2151/2500], Train Loss: 0.5591, Train Accuracy: 76.10%, Test Loss: 1.2127, Test Accuracy: 68.35%\n",
      "Epoch [2152/2500], Train Loss: 0.5778, Train Accuracy: 74.82%, Test Loss: 1.1852, Test Accuracy: 68.35%\n",
      "Epoch [2153/2500], Train Loss: 0.5579, Train Accuracy: 75.68%, Test Loss: 1.1764, Test Accuracy: 67.09%\n",
      "Epoch [2154/2500], Train Loss: 0.5606, Train Accuracy: 75.53%, Test Loss: 1.1945, Test Accuracy: 65.82%\n",
      "Epoch [2155/2500], Train Loss: 0.5955, Train Accuracy: 73.83%, Test Loss: 1.1276, Test Accuracy: 69.62%\n",
      "Epoch [2156/2500], Train Loss: 0.5753, Train Accuracy: 74.25%, Test Loss: 1.1781, Test Accuracy: 63.29%\n",
      "Epoch [2157/2500], Train Loss: 0.5601, Train Accuracy: 76.67%, Test Loss: 1.1417, Test Accuracy: 65.82%\n",
      "Epoch [2158/2500], Train Loss: 0.5557, Train Accuracy: 76.53%, Test Loss: 1.2374, Test Accuracy: 65.82%\n",
      "Epoch [2159/2500], Train Loss: 0.5869, Train Accuracy: 75.68%, Test Loss: 1.1376, Test Accuracy: 67.09%\n",
      "Epoch [2160/2500], Train Loss: 0.5839, Train Accuracy: 77.52%, Test Loss: 1.1460, Test Accuracy: 67.09%\n",
      "Epoch [2161/2500], Train Loss: 0.5617, Train Accuracy: 75.82%, Test Loss: 1.1576, Test Accuracy: 65.82%\n",
      "Epoch [2162/2500], Train Loss: 0.5800, Train Accuracy: 74.25%, Test Loss: 1.1654, Test Accuracy: 68.35%\n",
      "Epoch [2163/2500], Train Loss: 0.5527, Train Accuracy: 75.11%, Test Loss: 1.1890, Test Accuracy: 65.82%\n",
      "Epoch [2164/2500], Train Loss: 0.5726, Train Accuracy: 73.68%, Test Loss: 1.2038, Test Accuracy: 65.82%\n",
      "Epoch [2165/2500], Train Loss: 0.5846, Train Accuracy: 75.25%, Test Loss: 1.1383, Test Accuracy: 65.82%\n",
      "Epoch [2166/2500], Train Loss: 0.5579, Train Accuracy: 76.24%, Test Loss: 1.1363, Test Accuracy: 67.09%\n",
      "Epoch [2167/2500], Train Loss: 0.5442, Train Accuracy: 75.68%, Test Loss: 1.1419, Test Accuracy: 68.35%\n",
      "Epoch [2168/2500], Train Loss: 0.5568, Train Accuracy: 75.96%, Test Loss: 1.2386, Test Accuracy: 67.09%\n",
      "Epoch [2169/2500], Train Loss: 0.6010, Train Accuracy: 74.96%, Test Loss: 1.1389, Test Accuracy: 67.09%\n",
      "Epoch [2170/2500], Train Loss: 0.5550, Train Accuracy: 77.10%, Test Loss: 1.2807, Test Accuracy: 63.29%\n",
      "Epoch [2171/2500], Train Loss: 0.5449, Train Accuracy: 75.68%, Test Loss: 1.2067, Test Accuracy: 65.82%\n",
      "Epoch [2172/2500], Train Loss: 0.5526, Train Accuracy: 76.39%, Test Loss: 1.1901, Test Accuracy: 65.82%\n",
      "Epoch [2173/2500], Train Loss: 0.5659, Train Accuracy: 76.81%, Test Loss: 1.1901, Test Accuracy: 65.82%\n",
      "Epoch [2174/2500], Train Loss: 0.5219, Train Accuracy: 76.39%, Test Loss: 1.1840, Test Accuracy: 68.35%\n",
      "Epoch [2175/2500], Train Loss: 0.6004, Train Accuracy: 74.11%, Test Loss: 1.1036, Test Accuracy: 69.62%\n",
      "Epoch [2176/2500], Train Loss: 0.5721, Train Accuracy: 74.25%, Test Loss: 1.1065, Test Accuracy: 68.35%\n",
      "Epoch [2177/2500], Train Loss: 0.5564, Train Accuracy: 77.10%, Test Loss: 1.1791, Test Accuracy: 67.09%\n",
      "Epoch [2178/2500], Train Loss: 0.5719, Train Accuracy: 75.39%, Test Loss: 1.1883, Test Accuracy: 65.82%\n",
      "Epoch [2179/2500], Train Loss: 0.5641, Train Accuracy: 75.53%, Test Loss: 1.1612, Test Accuracy: 67.09%\n",
      "Epoch [2180/2500], Train Loss: 0.5620, Train Accuracy: 77.38%, Test Loss: 1.1569, Test Accuracy: 69.62%\n",
      "Epoch [2181/2500], Train Loss: 0.5566, Train Accuracy: 77.38%, Test Loss: 1.1403, Test Accuracy: 67.09%\n",
      "Epoch [2182/2500], Train Loss: 0.5753, Train Accuracy: 75.68%, Test Loss: 1.2357, Test Accuracy: 64.56%\n",
      "Epoch [2183/2500], Train Loss: 0.5625, Train Accuracy: 76.24%, Test Loss: 1.1985, Test Accuracy: 65.82%\n",
      "Epoch [2184/2500], Train Loss: 0.5740, Train Accuracy: 74.82%, Test Loss: 1.1578, Test Accuracy: 68.35%\n",
      "Epoch [2185/2500], Train Loss: 0.5614, Train Accuracy: 75.82%, Test Loss: 1.1763, Test Accuracy: 67.09%\n",
      "Epoch [2186/2500], Train Loss: 0.5803, Train Accuracy: 73.83%, Test Loss: 1.1374, Test Accuracy: 64.56%\n",
      "Epoch [2187/2500], Train Loss: 0.5722, Train Accuracy: 74.11%, Test Loss: 1.1437, Test Accuracy: 67.09%\n",
      "Epoch [2188/2500], Train Loss: 0.5473, Train Accuracy: 77.24%, Test Loss: 1.1517, Test Accuracy: 67.09%\n",
      "Epoch [2189/2500], Train Loss: 0.5715, Train Accuracy: 75.82%, Test Loss: 1.1728, Test Accuracy: 65.82%\n",
      "Epoch [2190/2500], Train Loss: 0.5617, Train Accuracy: 77.10%, Test Loss: 1.1974, Test Accuracy: 67.09%\n",
      "Epoch [2191/2500], Train Loss: 0.5501, Train Accuracy: 76.53%, Test Loss: 1.1791, Test Accuracy: 67.09%\n",
      "Epoch [2192/2500], Train Loss: 0.5459, Train Accuracy: 76.39%, Test Loss: 1.1843, Test Accuracy: 65.82%\n",
      "Epoch [2193/2500], Train Loss: 0.5512, Train Accuracy: 75.96%, Test Loss: 1.2073, Test Accuracy: 68.35%\n",
      "Epoch [2194/2500], Train Loss: 0.6044, Train Accuracy: 73.26%, Test Loss: 1.1129, Test Accuracy: 67.09%\n",
      "Epoch [2195/2500], Train Loss: 0.5395, Train Accuracy: 76.39%, Test Loss: 1.2376, Test Accuracy: 64.56%\n",
      "Epoch [2196/2500], Train Loss: 0.5737, Train Accuracy: 76.67%, Test Loss: 1.1793, Test Accuracy: 65.82%\n",
      "Epoch [2197/2500], Train Loss: 0.5673, Train Accuracy: 75.96%, Test Loss: 1.1839, Test Accuracy: 65.82%\n",
      "Epoch [2198/2500], Train Loss: 0.5778, Train Accuracy: 73.54%, Test Loss: 1.1776, Test Accuracy: 67.09%\n",
      "Epoch [2199/2500], Train Loss: 0.5707, Train Accuracy: 75.68%, Test Loss: 1.1322, Test Accuracy: 65.82%\n",
      "Epoch [2200/2500], Train Loss: 0.5621, Train Accuracy: 75.53%, Test Loss: 1.1472, Test Accuracy: 64.56%\n",
      "Epoch [2201/2500], Train Loss: 0.5695, Train Accuracy: 75.11%, Test Loss: 1.2008, Test Accuracy: 67.09%\n",
      "Epoch [2202/2500], Train Loss: 0.5380, Train Accuracy: 76.81%, Test Loss: 1.1273, Test Accuracy: 67.09%\n",
      "Epoch [2203/2500], Train Loss: 0.5548, Train Accuracy: 75.82%, Test Loss: 1.2182, Test Accuracy: 64.56%\n",
      "Epoch [2204/2500], Train Loss: 0.5577, Train Accuracy: 75.68%, Test Loss: 1.1365, Test Accuracy: 64.56%\n",
      "Epoch [2205/2500], Train Loss: 0.5464, Train Accuracy: 74.82%, Test Loss: 1.2002, Test Accuracy: 65.82%\n",
      "Epoch [2206/2500], Train Loss: 0.5482, Train Accuracy: 75.68%, Test Loss: 1.2102, Test Accuracy: 64.56%\n",
      "Epoch [2207/2500], Train Loss: 0.5456, Train Accuracy: 74.68%, Test Loss: 1.1552, Test Accuracy: 65.82%\n",
      "Epoch [2208/2500], Train Loss: 0.5685, Train Accuracy: 76.53%, Test Loss: 1.2391, Test Accuracy: 65.82%\n",
      "Epoch [2209/2500], Train Loss: 0.5551, Train Accuracy: 75.96%, Test Loss: 1.1587, Test Accuracy: 65.82%\n",
      "Epoch [2210/2500], Train Loss: 0.5669, Train Accuracy: 75.96%, Test Loss: 1.1541, Test Accuracy: 67.09%\n",
      "Epoch [2211/2500], Train Loss: 0.5480, Train Accuracy: 74.82%, Test Loss: 1.1405, Test Accuracy: 65.82%\n",
      "Epoch [2212/2500], Train Loss: 0.5272, Train Accuracy: 76.96%, Test Loss: 1.2064, Test Accuracy: 65.82%\n",
      "Epoch [2213/2500], Train Loss: 0.5668, Train Accuracy: 75.53%, Test Loss: 1.1870, Test Accuracy: 65.82%\n",
      "Epoch [2214/2500], Train Loss: 0.5746, Train Accuracy: 75.39%, Test Loss: 1.2016, Test Accuracy: 63.29%\n",
      "Epoch [2215/2500], Train Loss: 0.5695, Train Accuracy: 74.96%, Test Loss: 1.2136, Test Accuracy: 67.09%\n",
      "Epoch [2216/2500], Train Loss: 0.5538, Train Accuracy: 75.82%, Test Loss: 1.1778, Test Accuracy: 65.82%\n",
      "Epoch [2217/2500], Train Loss: 0.5662, Train Accuracy: 76.67%, Test Loss: 1.1440, Test Accuracy: 65.82%\n",
      "Epoch [2218/2500], Train Loss: 0.5563, Train Accuracy: 75.82%, Test Loss: 1.1885, Test Accuracy: 60.76%\n",
      "Epoch [2219/2500], Train Loss: 0.5517, Train Accuracy: 75.68%, Test Loss: 1.1898, Test Accuracy: 65.82%\n",
      "Epoch [2220/2500], Train Loss: 0.5654, Train Accuracy: 75.82%, Test Loss: 1.2214, Test Accuracy: 64.56%\n",
      "Epoch [2221/2500], Train Loss: 0.5602, Train Accuracy: 75.82%, Test Loss: 1.1831, Test Accuracy: 64.56%\n",
      "Epoch [2222/2500], Train Loss: 0.5639, Train Accuracy: 76.24%, Test Loss: 1.2752, Test Accuracy: 65.82%\n",
      "Epoch [2223/2500], Train Loss: 0.5567, Train Accuracy: 75.39%, Test Loss: 1.1298, Test Accuracy: 67.09%\n",
      "Epoch [2224/2500], Train Loss: 0.5579, Train Accuracy: 75.39%, Test Loss: 1.1744, Test Accuracy: 67.09%\n",
      "Epoch [2225/2500], Train Loss: 0.5632, Train Accuracy: 76.10%, Test Loss: 1.2407, Test Accuracy: 65.82%\n",
      "Epoch [2226/2500], Train Loss: 0.5625, Train Accuracy: 77.81%, Test Loss: 1.1667, Test Accuracy: 67.09%\n",
      "Epoch [2227/2500], Train Loss: 0.5559, Train Accuracy: 74.82%, Test Loss: 1.2203, Test Accuracy: 65.82%\n",
      "Epoch [2228/2500], Train Loss: 0.5746, Train Accuracy: 77.67%, Test Loss: 1.1740, Test Accuracy: 68.35%\n",
      "Epoch [2229/2500], Train Loss: 0.5514, Train Accuracy: 76.81%, Test Loss: 1.2118, Test Accuracy: 68.35%\n",
      "Epoch [2230/2500], Train Loss: 0.5794, Train Accuracy: 73.97%, Test Loss: 1.1610, Test Accuracy: 67.09%\n",
      "Epoch [2231/2500], Train Loss: 0.5572, Train Accuracy: 76.53%, Test Loss: 1.2066, Test Accuracy: 64.56%\n",
      "Epoch [2232/2500], Train Loss: 0.5736, Train Accuracy: 75.11%, Test Loss: 1.1804, Test Accuracy: 65.82%\n",
      "Epoch [2233/2500], Train Loss: 0.5624, Train Accuracy: 75.96%, Test Loss: 1.1967, Test Accuracy: 63.29%\n",
      "Epoch [2234/2500], Train Loss: 0.5445, Train Accuracy: 77.24%, Test Loss: 1.1945, Test Accuracy: 67.09%\n",
      "Epoch [2235/2500], Train Loss: 0.5344, Train Accuracy: 77.95%, Test Loss: 1.1975, Test Accuracy: 67.09%\n",
      "Epoch [2236/2500], Train Loss: 0.5489, Train Accuracy: 76.81%, Test Loss: 1.1911, Test Accuracy: 65.82%\n",
      "Epoch [2237/2500], Train Loss: 0.5329, Train Accuracy: 77.38%, Test Loss: 1.2677, Test Accuracy: 64.56%\n",
      "Epoch [2238/2500], Train Loss: 0.5619, Train Accuracy: 76.67%, Test Loss: 1.2140, Test Accuracy: 67.09%\n",
      "Epoch [2239/2500], Train Loss: 0.5643, Train Accuracy: 76.10%, Test Loss: 1.2429, Test Accuracy: 63.29%\n",
      "Epoch [2240/2500], Train Loss: 0.5392, Train Accuracy: 75.25%, Test Loss: 1.2207, Test Accuracy: 65.82%\n",
      "Epoch [2241/2500], Train Loss: 0.5585, Train Accuracy: 77.52%, Test Loss: 1.1850, Test Accuracy: 68.35%\n",
      "Epoch [2242/2500], Train Loss: 0.5731, Train Accuracy: 75.68%, Test Loss: 1.1780, Test Accuracy: 68.35%\n",
      "Epoch [2243/2500], Train Loss: 0.5648, Train Accuracy: 74.96%, Test Loss: 1.2170, Test Accuracy: 65.82%\n",
      "Epoch [2244/2500], Train Loss: 0.5494, Train Accuracy: 75.53%, Test Loss: 1.2024, Test Accuracy: 68.35%\n",
      "Epoch [2245/2500], Train Loss: 0.5633, Train Accuracy: 76.67%, Test Loss: 1.2435, Test Accuracy: 64.56%\n",
      "Epoch [2246/2500], Train Loss: 0.5384, Train Accuracy: 77.81%, Test Loss: 1.2165, Test Accuracy: 65.82%\n",
      "Epoch [2247/2500], Train Loss: 0.5626, Train Accuracy: 75.68%, Test Loss: 1.2613, Test Accuracy: 65.82%\n",
      "Epoch [2248/2500], Train Loss: 0.5946, Train Accuracy: 74.68%, Test Loss: 1.1994, Test Accuracy: 65.82%\n",
      "Epoch [2249/2500], Train Loss: 0.5526, Train Accuracy: 76.81%, Test Loss: 1.2115, Test Accuracy: 65.82%\n",
      "Epoch [2250/2500], Train Loss: 0.5453, Train Accuracy: 76.96%, Test Loss: 1.2588, Test Accuracy: 65.82%\n",
      "Epoch [2251/2500], Train Loss: 0.5440, Train Accuracy: 76.24%, Test Loss: 1.2421, Test Accuracy: 65.82%\n",
      "Epoch [2252/2500], Train Loss: 0.5381, Train Accuracy: 77.10%, Test Loss: 1.2109, Test Accuracy: 65.82%\n",
      "Epoch [2253/2500], Train Loss: 0.5623, Train Accuracy: 75.68%, Test Loss: 1.1757, Test Accuracy: 65.82%\n",
      "Epoch [2254/2500], Train Loss: 0.5625, Train Accuracy: 75.11%, Test Loss: 1.1903, Test Accuracy: 67.09%\n",
      "Epoch [2255/2500], Train Loss: 0.5520, Train Accuracy: 75.11%, Test Loss: 1.1851, Test Accuracy: 65.82%\n",
      "Epoch [2256/2500], Train Loss: 0.5489, Train Accuracy: 77.24%, Test Loss: 1.1703, Test Accuracy: 67.09%\n",
      "Epoch [2257/2500], Train Loss: 0.5688, Train Accuracy: 74.82%, Test Loss: 1.1704, Test Accuracy: 65.82%\n",
      "Epoch [2258/2500], Train Loss: 0.5423, Train Accuracy: 74.82%, Test Loss: 1.2591, Test Accuracy: 65.82%\n",
      "Epoch [2259/2500], Train Loss: 0.5531, Train Accuracy: 75.96%, Test Loss: 1.2278, Test Accuracy: 63.29%\n",
      "Epoch [2260/2500], Train Loss: 0.5606, Train Accuracy: 75.68%, Test Loss: 1.2355, Test Accuracy: 63.29%\n",
      "Epoch [2261/2500], Train Loss: 0.5524, Train Accuracy: 75.25%, Test Loss: 1.2150, Test Accuracy: 64.56%\n",
      "Epoch [2262/2500], Train Loss: 0.5741, Train Accuracy: 75.68%, Test Loss: 1.1535, Test Accuracy: 65.82%\n",
      "Epoch [2263/2500], Train Loss: 0.5739, Train Accuracy: 76.96%, Test Loss: 1.2309, Test Accuracy: 62.03%\n",
      "Epoch [2264/2500], Train Loss: 0.5448, Train Accuracy: 76.39%, Test Loss: 1.1464, Test Accuracy: 65.82%\n",
      "Epoch [2265/2500], Train Loss: 0.5893, Train Accuracy: 74.25%, Test Loss: 1.1752, Test Accuracy: 62.03%\n",
      "Epoch [2266/2500], Train Loss: 0.5717, Train Accuracy: 75.39%, Test Loss: 1.1289, Test Accuracy: 68.35%\n",
      "Epoch [2267/2500], Train Loss: 0.5557, Train Accuracy: 76.39%, Test Loss: 1.2049, Test Accuracy: 65.82%\n",
      "Epoch [2268/2500], Train Loss: 0.5747, Train Accuracy: 75.82%, Test Loss: 1.2278, Test Accuracy: 64.56%\n",
      "Epoch [2269/2500], Train Loss: 0.5771, Train Accuracy: 74.82%, Test Loss: 1.2066, Test Accuracy: 64.56%\n",
      "Epoch [2270/2500], Train Loss: 0.5535, Train Accuracy: 76.67%, Test Loss: 1.2076, Test Accuracy: 64.56%\n",
      "Epoch [2271/2500], Train Loss: 0.5564, Train Accuracy: 75.82%, Test Loss: 1.2179, Test Accuracy: 65.82%\n",
      "Epoch [2272/2500], Train Loss: 0.5635, Train Accuracy: 77.38%, Test Loss: 1.2203, Test Accuracy: 65.82%\n",
      "Epoch [2273/2500], Train Loss: 0.5602, Train Accuracy: 74.96%, Test Loss: 1.1826, Test Accuracy: 64.56%\n",
      "Epoch [2274/2500], Train Loss: 0.5432, Train Accuracy: 77.38%, Test Loss: 1.2391, Test Accuracy: 64.56%\n",
      "Epoch [2275/2500], Train Loss: 0.5810, Train Accuracy: 74.82%, Test Loss: 1.2431, Test Accuracy: 63.29%\n",
      "Epoch [2276/2500], Train Loss: 0.5171, Train Accuracy: 79.66%, Test Loss: 1.2566, Test Accuracy: 65.82%\n",
      "Epoch [2277/2500], Train Loss: 0.5540, Train Accuracy: 76.24%, Test Loss: 1.2192, Test Accuracy: 67.09%\n",
      "Epoch [2278/2500], Train Loss: 0.5394, Train Accuracy: 76.39%, Test Loss: 1.2032, Test Accuracy: 65.82%\n",
      "Epoch [2279/2500], Train Loss: 0.5389, Train Accuracy: 78.24%, Test Loss: 1.1887, Test Accuracy: 67.09%\n",
      "Epoch [2280/2500], Train Loss: 0.5619, Train Accuracy: 76.39%, Test Loss: 1.1721, Test Accuracy: 65.82%\n",
      "Epoch [2281/2500], Train Loss: 0.5809, Train Accuracy: 74.82%, Test Loss: 1.0830, Test Accuracy: 67.09%\n",
      "Epoch [2282/2500], Train Loss: 0.5292, Train Accuracy: 76.81%, Test Loss: 1.1818, Test Accuracy: 65.82%\n",
      "Epoch [2283/2500], Train Loss: 0.5419, Train Accuracy: 76.67%, Test Loss: 1.1530, Test Accuracy: 68.35%\n",
      "Epoch [2284/2500], Train Loss: 0.5523, Train Accuracy: 76.10%, Test Loss: 1.1733, Test Accuracy: 68.35%\n",
      "Epoch [2285/2500], Train Loss: 0.5556, Train Accuracy: 75.25%, Test Loss: 1.1834, Test Accuracy: 67.09%\n",
      "Epoch [2286/2500], Train Loss: 0.5697, Train Accuracy: 75.25%, Test Loss: 1.1876, Test Accuracy: 67.09%\n",
      "Epoch [2287/2500], Train Loss: 0.5232, Train Accuracy: 77.24%, Test Loss: 1.2163, Test Accuracy: 64.56%\n",
      "Epoch [2288/2500], Train Loss: 0.5556, Train Accuracy: 76.53%, Test Loss: 1.2244, Test Accuracy: 67.09%\n",
      "Epoch [2289/2500], Train Loss: 0.5482, Train Accuracy: 76.67%, Test Loss: 1.1413, Test Accuracy: 65.82%\n",
      "Epoch [2290/2500], Train Loss: 0.5455, Train Accuracy: 75.82%, Test Loss: 1.1956, Test Accuracy: 65.82%\n",
      "Epoch [2291/2500], Train Loss: 0.5269, Train Accuracy: 78.24%, Test Loss: 1.2522, Test Accuracy: 65.82%\n",
      "Epoch [2292/2500], Train Loss: 0.5411, Train Accuracy: 78.52%, Test Loss: 1.1834, Test Accuracy: 67.09%\n",
      "Epoch [2293/2500], Train Loss: 0.5663, Train Accuracy: 75.39%, Test Loss: 1.1802, Test Accuracy: 65.82%\n",
      "Epoch [2294/2500], Train Loss: 0.5337, Train Accuracy: 76.53%, Test Loss: 1.2534, Test Accuracy: 64.56%\n",
      "Epoch [2295/2500], Train Loss: 0.5614, Train Accuracy: 76.67%, Test Loss: 1.1879, Test Accuracy: 64.56%\n",
      "Epoch [2296/2500], Train Loss: 0.5329, Train Accuracy: 77.38%, Test Loss: 1.2768, Test Accuracy: 64.56%\n",
      "Epoch [2297/2500], Train Loss: 0.5550, Train Accuracy: 74.40%, Test Loss: 1.2410, Test Accuracy: 64.56%\n",
      "Epoch [2298/2500], Train Loss: 0.5719, Train Accuracy: 76.67%, Test Loss: 1.2154, Test Accuracy: 63.29%\n",
      "Epoch [2299/2500], Train Loss: 0.5418, Train Accuracy: 76.81%, Test Loss: 1.2494, Test Accuracy: 63.29%\n",
      "Epoch [2300/2500], Train Loss: 0.5722, Train Accuracy: 74.82%, Test Loss: 1.2391, Test Accuracy: 64.56%\n",
      "Epoch [2301/2500], Train Loss: 0.5701, Train Accuracy: 75.39%, Test Loss: 1.2119, Test Accuracy: 64.56%\n",
      "Epoch [2302/2500], Train Loss: 0.5515, Train Accuracy: 74.96%, Test Loss: 1.2521, Test Accuracy: 65.82%\n",
      "Epoch [2303/2500], Train Loss: 0.5864, Train Accuracy: 73.26%, Test Loss: 1.1744, Test Accuracy: 65.82%\n",
      "Epoch [2304/2500], Train Loss: 0.5585, Train Accuracy: 76.67%, Test Loss: 1.1928, Test Accuracy: 65.82%\n",
      "Epoch [2305/2500], Train Loss: 0.5500, Train Accuracy: 75.68%, Test Loss: 1.2571, Test Accuracy: 65.82%\n",
      "Epoch [2306/2500], Train Loss: 0.5565, Train Accuracy: 74.54%, Test Loss: 1.2677, Test Accuracy: 64.56%\n",
      "Epoch [2307/2500], Train Loss: 0.5515, Train Accuracy: 76.10%, Test Loss: 1.1059, Test Accuracy: 67.09%\n",
      "Epoch [2308/2500], Train Loss: 0.5274, Train Accuracy: 78.52%, Test Loss: 1.2098, Test Accuracy: 69.62%\n",
      "Epoch [2309/2500], Train Loss: 0.5603, Train Accuracy: 75.68%, Test Loss: 1.1152, Test Accuracy: 67.09%\n",
      "Epoch [2310/2500], Train Loss: 0.5399, Train Accuracy: 77.81%, Test Loss: 1.2361, Test Accuracy: 67.09%\n",
      "Epoch [2311/2500], Train Loss: 0.5584, Train Accuracy: 75.68%, Test Loss: 1.1835, Test Accuracy: 67.09%\n",
      "Epoch [2312/2500], Train Loss: 0.5415, Train Accuracy: 75.68%, Test Loss: 1.2650, Test Accuracy: 67.09%\n",
      "Epoch [2313/2500], Train Loss: 0.5449, Train Accuracy: 75.53%, Test Loss: 1.1304, Test Accuracy: 67.09%\n",
      "Epoch [2314/2500], Train Loss: 0.5507, Train Accuracy: 75.82%, Test Loss: 1.1609, Test Accuracy: 67.09%\n",
      "Epoch [2315/2500], Train Loss: 0.5565, Train Accuracy: 76.39%, Test Loss: 1.2004, Test Accuracy: 64.56%\n",
      "Epoch [2316/2500], Train Loss: 0.5312, Train Accuracy: 76.53%, Test Loss: 1.1770, Test Accuracy: 67.09%\n",
      "Epoch [2317/2500], Train Loss: 0.5628, Train Accuracy: 75.25%, Test Loss: 1.2104, Test Accuracy: 68.35%\n",
      "Epoch [2318/2500], Train Loss: 0.5839, Train Accuracy: 75.39%, Test Loss: 1.1312, Test Accuracy: 67.09%\n",
      "Epoch [2319/2500], Train Loss: 0.5435, Train Accuracy: 74.40%, Test Loss: 1.2121, Test Accuracy: 67.09%\n",
      "Epoch [2320/2500], Train Loss: 0.5353, Train Accuracy: 76.39%, Test Loss: 1.2408, Test Accuracy: 68.35%\n",
      "Epoch [2321/2500], Train Loss: 0.5380, Train Accuracy: 75.96%, Test Loss: 1.2229, Test Accuracy: 67.09%\n",
      "Epoch [2322/2500], Train Loss: 0.5501, Train Accuracy: 76.39%, Test Loss: 1.1839, Test Accuracy: 63.29%\n",
      "Epoch [2323/2500], Train Loss: 0.5780, Train Accuracy: 74.40%, Test Loss: 1.2068, Test Accuracy: 63.29%\n",
      "Epoch [2324/2500], Train Loss: 0.5500, Train Accuracy: 74.82%, Test Loss: 1.1957, Test Accuracy: 65.82%\n",
      "Epoch [2325/2500], Train Loss: 0.5509, Train Accuracy: 75.68%, Test Loss: 1.1853, Test Accuracy: 68.35%\n",
      "Epoch [2326/2500], Train Loss: 0.5473, Train Accuracy: 75.82%, Test Loss: 1.2697, Test Accuracy: 65.82%\n",
      "Epoch [2327/2500], Train Loss: 0.5486, Train Accuracy: 77.38%, Test Loss: 1.1955, Test Accuracy: 65.82%\n",
      "Epoch [2328/2500], Train Loss: 0.5662, Train Accuracy: 75.82%, Test Loss: 1.2311, Test Accuracy: 65.82%\n",
      "Epoch [2329/2500], Train Loss: 0.5871, Train Accuracy: 74.40%, Test Loss: 1.2119, Test Accuracy: 67.09%\n",
      "Epoch [2330/2500], Train Loss: 0.5348, Train Accuracy: 78.24%, Test Loss: 1.2143, Test Accuracy: 67.09%\n",
      "Epoch [2331/2500], Train Loss: 0.5662, Train Accuracy: 77.38%, Test Loss: 1.1907, Test Accuracy: 67.09%\n",
      "Epoch [2332/2500], Train Loss: 0.5429, Train Accuracy: 75.25%, Test Loss: 1.2561, Test Accuracy: 67.09%\n",
      "Epoch [2333/2500], Train Loss: 0.5341, Train Accuracy: 76.96%, Test Loss: 1.2165, Test Accuracy: 67.09%\n",
      "Epoch [2334/2500], Train Loss: 0.5540, Train Accuracy: 75.11%, Test Loss: 1.2340, Test Accuracy: 68.35%\n",
      "Epoch [2335/2500], Train Loss: 0.5418, Train Accuracy: 77.24%, Test Loss: 1.2305, Test Accuracy: 65.82%\n",
      "Epoch [2336/2500], Train Loss: 0.5455, Train Accuracy: 77.10%, Test Loss: 1.1880, Test Accuracy: 67.09%\n",
      "Epoch [2337/2500], Train Loss: 0.5462, Train Accuracy: 76.24%, Test Loss: 1.2385, Test Accuracy: 67.09%\n",
      "Epoch [2338/2500], Train Loss: 0.5260, Train Accuracy: 75.68%, Test Loss: 1.2990, Test Accuracy: 65.82%\n",
      "Epoch [2339/2500], Train Loss: 0.5600, Train Accuracy: 76.96%, Test Loss: 1.1951, Test Accuracy: 68.35%\n",
      "Epoch [2340/2500], Train Loss: 0.5519, Train Accuracy: 76.24%, Test Loss: 1.1813, Test Accuracy: 67.09%\n",
      "Epoch [2341/2500], Train Loss: 0.5739, Train Accuracy: 77.10%, Test Loss: 1.2146, Test Accuracy: 68.35%\n",
      "Epoch [2342/2500], Train Loss: 0.5386, Train Accuracy: 76.24%, Test Loss: 1.2490, Test Accuracy: 67.09%\n",
      "Epoch [2343/2500], Train Loss: 0.5617, Train Accuracy: 75.68%, Test Loss: 1.1997, Test Accuracy: 67.09%\n",
      "Epoch [2344/2500], Train Loss: 0.5523, Train Accuracy: 77.24%, Test Loss: 1.2358, Test Accuracy: 67.09%\n",
      "Epoch [2345/2500], Train Loss: 0.5563, Train Accuracy: 78.09%, Test Loss: 1.2224, Test Accuracy: 68.35%\n",
      "Epoch [2346/2500], Train Loss: 0.5556, Train Accuracy: 75.39%, Test Loss: 1.2734, Test Accuracy: 65.82%\n",
      "Epoch [2347/2500], Train Loss: 0.5214, Train Accuracy: 76.53%, Test Loss: 1.2615, Test Accuracy: 65.82%\n",
      "Epoch [2348/2500], Train Loss: 0.5433, Train Accuracy: 76.53%, Test Loss: 1.2587, Test Accuracy: 67.09%\n",
      "Epoch [2349/2500], Train Loss: 0.5548, Train Accuracy: 75.25%, Test Loss: 1.2884, Test Accuracy: 65.82%\n",
      "Epoch [2350/2500], Train Loss: 0.5544, Train Accuracy: 74.96%, Test Loss: 1.2274, Test Accuracy: 68.35%\n",
      "Epoch [2351/2500], Train Loss: 0.5586, Train Accuracy: 75.39%, Test Loss: 1.2579, Test Accuracy: 68.35%\n",
      "Epoch [2352/2500], Train Loss: 0.5337, Train Accuracy: 78.38%, Test Loss: 1.1566, Test Accuracy: 67.09%\n",
      "Epoch [2353/2500], Train Loss: 0.5537, Train Accuracy: 76.39%, Test Loss: 1.1944, Test Accuracy: 67.09%\n",
      "Epoch [2354/2500], Train Loss: 0.5371, Train Accuracy: 76.67%, Test Loss: 1.2036, Test Accuracy: 65.82%\n",
      "Epoch [2355/2500], Train Loss: 0.5551, Train Accuracy: 75.68%, Test Loss: 1.2615, Test Accuracy: 67.09%\n",
      "Epoch [2356/2500], Train Loss: 0.5474, Train Accuracy: 78.24%, Test Loss: 1.2639, Test Accuracy: 65.82%\n",
      "Epoch [2357/2500], Train Loss: 0.5461, Train Accuracy: 77.24%, Test Loss: 1.2171, Test Accuracy: 64.56%\n",
      "Epoch [2358/2500], Train Loss: 0.5454, Train Accuracy: 74.68%, Test Loss: 1.2638, Test Accuracy: 64.56%\n",
      "Epoch [2359/2500], Train Loss: 0.5426, Train Accuracy: 77.38%, Test Loss: 1.1858, Test Accuracy: 64.56%\n",
      "Epoch [2360/2500], Train Loss: 0.5588, Train Accuracy: 74.82%, Test Loss: 1.2031, Test Accuracy: 67.09%\n",
      "Epoch [2361/2500], Train Loss: 0.5505, Train Accuracy: 76.96%, Test Loss: 1.1812, Test Accuracy: 67.09%\n",
      "Epoch [2362/2500], Train Loss: 0.5390, Train Accuracy: 76.81%, Test Loss: 1.2253, Test Accuracy: 64.56%\n",
      "Epoch [2363/2500], Train Loss: 0.5459, Train Accuracy: 77.67%, Test Loss: 1.2289, Test Accuracy: 65.82%\n",
      "Epoch [2364/2500], Train Loss: 0.5815, Train Accuracy: 75.82%, Test Loss: 1.1919, Test Accuracy: 64.56%\n",
      "Epoch [2365/2500], Train Loss: 0.5326, Train Accuracy: 77.24%, Test Loss: 1.2007, Test Accuracy: 65.82%\n",
      "Epoch [2366/2500], Train Loss: 0.5604, Train Accuracy: 77.38%, Test Loss: 1.2125, Test Accuracy: 63.29%\n",
      "Epoch [2367/2500], Train Loss: 0.5546, Train Accuracy: 76.39%, Test Loss: 1.2127, Test Accuracy: 65.82%\n",
      "Epoch [2368/2500], Train Loss: 0.5494, Train Accuracy: 75.25%, Test Loss: 1.2011, Test Accuracy: 67.09%\n",
      "Epoch [2369/2500], Train Loss: 0.5696, Train Accuracy: 75.82%, Test Loss: 1.2016, Test Accuracy: 68.35%\n",
      "Epoch [2370/2500], Train Loss: 0.5595, Train Accuracy: 76.67%, Test Loss: 1.2227, Test Accuracy: 64.56%\n",
      "Epoch [2371/2500], Train Loss: 0.5566, Train Accuracy: 77.38%, Test Loss: 1.2426, Test Accuracy: 65.82%\n",
      "Epoch [2372/2500], Train Loss: 0.5747, Train Accuracy: 75.25%, Test Loss: 1.1885, Test Accuracy: 67.09%\n",
      "Epoch [2373/2500], Train Loss: 0.5390, Train Accuracy: 76.10%, Test Loss: 1.2161, Test Accuracy: 65.82%\n",
      "Epoch [2374/2500], Train Loss: 0.5628, Train Accuracy: 74.68%, Test Loss: 1.1456, Test Accuracy: 67.09%\n",
      "Epoch [2375/2500], Train Loss: 0.5542, Train Accuracy: 74.11%, Test Loss: 1.1770, Test Accuracy: 64.56%\n",
      "Epoch [2376/2500], Train Loss: 0.5329, Train Accuracy: 76.96%, Test Loss: 1.2214, Test Accuracy: 67.09%\n",
      "Epoch [2377/2500], Train Loss: 0.5457, Train Accuracy: 76.39%, Test Loss: 1.1970, Test Accuracy: 67.09%\n",
      "Epoch [2378/2500], Train Loss: 0.5441, Train Accuracy: 75.82%, Test Loss: 1.2234, Test Accuracy: 65.82%\n",
      "Epoch [2379/2500], Train Loss: 0.5525, Train Accuracy: 75.68%, Test Loss: 1.2094, Test Accuracy: 65.82%\n",
      "Epoch [2380/2500], Train Loss: 0.5456, Train Accuracy: 77.95%, Test Loss: 1.2292, Test Accuracy: 67.09%\n",
      "Epoch [2381/2500], Train Loss: 0.5492, Train Accuracy: 76.10%, Test Loss: 1.2379, Test Accuracy: 64.56%\n",
      "Epoch [2382/2500], Train Loss: 0.5480, Train Accuracy: 76.53%, Test Loss: 1.2437, Test Accuracy: 65.82%\n",
      "Epoch [2383/2500], Train Loss: 0.5708, Train Accuracy: 74.68%, Test Loss: 1.2001, Test Accuracy: 63.29%\n",
      "Epoch [2384/2500], Train Loss: 0.5554, Train Accuracy: 76.10%, Test Loss: 1.2521, Test Accuracy: 65.82%\n",
      "Epoch [2385/2500], Train Loss: 0.5608, Train Accuracy: 75.11%, Test Loss: 1.1768, Test Accuracy: 67.09%\n",
      "Epoch [2386/2500], Train Loss: 0.5336, Train Accuracy: 76.24%, Test Loss: 1.2712, Test Accuracy: 62.03%\n",
      "Epoch [2387/2500], Train Loss: 0.5229, Train Accuracy: 76.81%, Test Loss: 1.2275, Test Accuracy: 68.35%\n",
      "Epoch [2388/2500], Train Loss: 0.5749, Train Accuracy: 74.11%, Test Loss: 1.0979, Test Accuracy: 64.56%\n",
      "Epoch [2389/2500], Train Loss: 0.5134, Train Accuracy: 77.81%, Test Loss: 1.1987, Test Accuracy: 62.03%\n",
      "Epoch [2390/2500], Train Loss: 0.5551, Train Accuracy: 76.53%, Test Loss: 1.2344, Test Accuracy: 65.82%\n",
      "Epoch [2391/2500], Train Loss: 0.5195, Train Accuracy: 78.66%, Test Loss: 1.2359, Test Accuracy: 63.29%\n",
      "Epoch [2392/2500], Train Loss: 0.5490, Train Accuracy: 75.82%, Test Loss: 1.2424, Test Accuracy: 65.82%\n",
      "Epoch [2393/2500], Train Loss: 0.5395, Train Accuracy: 76.67%, Test Loss: 1.2239, Test Accuracy: 65.82%\n",
      "Epoch [2394/2500], Train Loss: 0.5617, Train Accuracy: 74.82%, Test Loss: 1.1644, Test Accuracy: 65.82%\n",
      "Epoch [2395/2500], Train Loss: 0.5595, Train Accuracy: 76.10%, Test Loss: 1.1580, Test Accuracy: 63.29%\n",
      "Epoch [2396/2500], Train Loss: 0.5545, Train Accuracy: 75.39%, Test Loss: 1.1721, Test Accuracy: 67.09%\n",
      "Epoch [2397/2500], Train Loss: 0.5284, Train Accuracy: 78.52%, Test Loss: 1.2264, Test Accuracy: 63.29%\n",
      "Epoch [2398/2500], Train Loss: 0.5449, Train Accuracy: 77.95%, Test Loss: 1.2221, Test Accuracy: 64.56%\n",
      "Epoch [2399/2500], Train Loss: 0.5347, Train Accuracy: 77.95%, Test Loss: 1.2196, Test Accuracy: 65.82%\n",
      "Epoch [2400/2500], Train Loss: 0.5384, Train Accuracy: 78.66%, Test Loss: 1.1953, Test Accuracy: 67.09%\n",
      "Epoch [2401/2500], Train Loss: 0.5489, Train Accuracy: 75.96%, Test Loss: 1.1579, Test Accuracy: 64.56%\n",
      "Epoch [2402/2500], Train Loss: 0.5562, Train Accuracy: 74.96%, Test Loss: 1.2246, Test Accuracy: 64.56%\n",
      "Epoch [2403/2500], Train Loss: 0.5456, Train Accuracy: 77.52%, Test Loss: 1.2065, Test Accuracy: 64.56%\n",
      "Epoch [2404/2500], Train Loss: 0.5776, Train Accuracy: 75.53%, Test Loss: 1.2125, Test Accuracy: 65.82%\n",
      "Epoch [2405/2500], Train Loss: 0.5380, Train Accuracy: 75.96%, Test Loss: 1.1977, Test Accuracy: 64.56%\n",
      "Epoch [2406/2500], Train Loss: 0.5243, Train Accuracy: 77.67%, Test Loss: 1.1896, Test Accuracy: 67.09%\n",
      "Epoch [2407/2500], Train Loss: 0.5269, Train Accuracy: 76.96%, Test Loss: 1.2428, Test Accuracy: 68.35%\n",
      "Epoch [2408/2500], Train Loss: 0.5445, Train Accuracy: 76.96%, Test Loss: 1.2075, Test Accuracy: 65.82%\n",
      "Epoch [2409/2500], Train Loss: 0.5303, Train Accuracy: 76.24%, Test Loss: 1.2509, Test Accuracy: 64.56%\n",
      "Epoch [2410/2500], Train Loss: 0.5249, Train Accuracy: 76.96%, Test Loss: 1.2726, Test Accuracy: 63.29%\n",
      "Epoch [2411/2500], Train Loss: 0.5633, Train Accuracy: 77.10%, Test Loss: 1.2424, Test Accuracy: 64.56%\n",
      "Epoch [2412/2500], Train Loss: 0.5379, Train Accuracy: 76.24%, Test Loss: 1.2685, Test Accuracy: 64.56%\n",
      "Epoch [2413/2500], Train Loss: 0.5748, Train Accuracy: 75.96%, Test Loss: 1.2688, Test Accuracy: 65.82%\n",
      "Epoch [2414/2500], Train Loss: 0.5409, Train Accuracy: 77.95%, Test Loss: 1.2259, Test Accuracy: 64.56%\n",
      "Epoch [2415/2500], Train Loss: 0.5121, Train Accuracy: 77.52%, Test Loss: 1.2348, Test Accuracy: 64.56%\n",
      "Epoch [2416/2500], Train Loss: 0.5563, Train Accuracy: 74.96%, Test Loss: 1.2246, Test Accuracy: 65.82%\n",
      "Epoch [2417/2500], Train Loss: 0.5430, Train Accuracy: 78.38%, Test Loss: 1.2597, Test Accuracy: 65.82%\n",
      "Epoch [2418/2500], Train Loss: 0.5348, Train Accuracy: 77.81%, Test Loss: 1.2354, Test Accuracy: 65.82%\n",
      "Epoch [2419/2500], Train Loss: 0.5603, Train Accuracy: 74.82%, Test Loss: 1.2369, Test Accuracy: 64.56%\n",
      "Epoch [2420/2500], Train Loss: 0.5486, Train Accuracy: 76.24%, Test Loss: 1.2017, Test Accuracy: 68.35%\n",
      "Epoch [2421/2500], Train Loss: 0.5438, Train Accuracy: 77.10%, Test Loss: 1.1675, Test Accuracy: 68.35%\n",
      "Epoch [2422/2500], Train Loss: 0.5336, Train Accuracy: 78.24%, Test Loss: 1.1960, Test Accuracy: 65.82%\n",
      "Epoch [2423/2500], Train Loss: 0.5366, Train Accuracy: 77.10%, Test Loss: 1.2778, Test Accuracy: 64.56%\n",
      "Epoch [2424/2500], Train Loss: 0.5214, Train Accuracy: 75.96%, Test Loss: 1.2370, Test Accuracy: 67.09%\n",
      "Epoch [2425/2500], Train Loss: 0.5495, Train Accuracy: 75.39%, Test Loss: 1.2071, Test Accuracy: 68.35%\n",
      "Epoch [2426/2500], Train Loss: 0.5362, Train Accuracy: 76.10%, Test Loss: 1.2283, Test Accuracy: 64.56%\n",
      "Epoch [2427/2500], Train Loss: 0.5502, Train Accuracy: 75.53%, Test Loss: 1.2595, Test Accuracy: 60.76%\n",
      "Epoch [2428/2500], Train Loss: 0.5393, Train Accuracy: 75.82%, Test Loss: 1.2728, Test Accuracy: 64.56%\n",
      "Epoch [2429/2500], Train Loss: 0.5328, Train Accuracy: 77.38%, Test Loss: 1.2477, Test Accuracy: 63.29%\n",
      "Epoch [2430/2500], Train Loss: 0.5571, Train Accuracy: 76.53%, Test Loss: 1.2165, Test Accuracy: 63.29%\n",
      "Epoch [2431/2500], Train Loss: 0.5419, Train Accuracy: 75.68%, Test Loss: 1.1559, Test Accuracy: 65.82%\n",
      "Epoch [2432/2500], Train Loss: 0.5510, Train Accuracy: 75.11%, Test Loss: 1.2192, Test Accuracy: 64.56%\n",
      "Epoch [2433/2500], Train Loss: 0.5415, Train Accuracy: 76.24%, Test Loss: 1.2611, Test Accuracy: 64.56%\n",
      "Epoch [2434/2500], Train Loss: 0.5489, Train Accuracy: 76.10%, Test Loss: 1.2602, Test Accuracy: 64.56%\n",
      "Epoch [2435/2500], Train Loss: 0.5543, Train Accuracy: 76.39%, Test Loss: 1.2002, Test Accuracy: 64.56%\n",
      "Epoch [2436/2500], Train Loss: 0.5229, Train Accuracy: 77.81%, Test Loss: 1.2293, Test Accuracy: 65.82%\n",
      "Epoch [2437/2500], Train Loss: 0.5197, Train Accuracy: 77.81%, Test Loss: 1.2337, Test Accuracy: 68.35%\n",
      "Epoch [2438/2500], Train Loss: 0.5507, Train Accuracy: 75.82%, Test Loss: 1.2055, Test Accuracy: 67.09%\n",
      "Epoch [2439/2500], Train Loss: 0.5253, Train Accuracy: 77.81%, Test Loss: 1.1759, Test Accuracy: 68.35%\n",
      "Epoch [2440/2500], Train Loss: 0.5508, Train Accuracy: 76.53%, Test Loss: 1.2522, Test Accuracy: 63.29%\n",
      "Epoch [2441/2500], Train Loss: 0.5448, Train Accuracy: 76.67%, Test Loss: 1.2470, Test Accuracy: 63.29%\n",
      "Epoch [2442/2500], Train Loss: 0.5407, Train Accuracy: 76.10%, Test Loss: 1.2179, Test Accuracy: 64.56%\n",
      "Epoch [2443/2500], Train Loss: 0.5557, Train Accuracy: 76.53%, Test Loss: 1.2507, Test Accuracy: 63.29%\n",
      "Epoch [2444/2500], Train Loss: 0.5397, Train Accuracy: 78.66%, Test Loss: 1.2106, Test Accuracy: 65.82%\n",
      "Epoch [2445/2500], Train Loss: 0.5273, Train Accuracy: 76.67%, Test Loss: 1.2735, Test Accuracy: 65.82%\n",
      "Epoch [2446/2500], Train Loss: 0.5450, Train Accuracy: 76.24%, Test Loss: 1.2417, Test Accuracy: 64.56%\n",
      "Epoch [2447/2500], Train Loss: 0.5423, Train Accuracy: 77.67%, Test Loss: 1.2016, Test Accuracy: 68.35%\n",
      "Epoch [2448/2500], Train Loss: 0.5411, Train Accuracy: 75.82%, Test Loss: 1.2063, Test Accuracy: 67.09%\n",
      "Epoch [2449/2500], Train Loss: 0.4918, Train Accuracy: 79.37%, Test Loss: 1.2886, Test Accuracy: 67.09%\n",
      "Epoch [2450/2500], Train Loss: 0.5412, Train Accuracy: 76.96%, Test Loss: 1.1979, Test Accuracy: 64.56%\n",
      "Epoch [2451/2500], Train Loss: 0.5333, Train Accuracy: 76.67%, Test Loss: 1.2778, Test Accuracy: 62.03%\n",
      "Epoch [2452/2500], Train Loss: 0.5397, Train Accuracy: 76.24%, Test Loss: 1.2171, Test Accuracy: 65.82%\n",
      "Epoch [2453/2500], Train Loss: 0.5424, Train Accuracy: 76.24%, Test Loss: 1.1986, Test Accuracy: 67.09%\n",
      "Epoch [2454/2500], Train Loss: 0.5265, Train Accuracy: 78.66%, Test Loss: 1.2434, Test Accuracy: 67.09%\n",
      "Epoch [2455/2500], Train Loss: 0.5394, Train Accuracy: 75.68%, Test Loss: 1.2125, Test Accuracy: 63.29%\n",
      "Epoch [2456/2500], Train Loss: 0.5418, Train Accuracy: 77.10%, Test Loss: 1.2122, Test Accuracy: 64.56%\n",
      "Epoch [2457/2500], Train Loss: 0.5251, Train Accuracy: 78.09%, Test Loss: 1.1835, Test Accuracy: 64.56%\n",
      "Epoch [2458/2500], Train Loss: 0.5233, Train Accuracy: 78.52%, Test Loss: 1.2306, Test Accuracy: 65.82%\n",
      "Epoch [2459/2500], Train Loss: 0.5475, Train Accuracy: 77.67%, Test Loss: 1.1458, Test Accuracy: 67.09%\n",
      "Epoch [2460/2500], Train Loss: 0.5237, Train Accuracy: 75.25%, Test Loss: 1.2610, Test Accuracy: 65.82%\n",
      "Epoch [2461/2500], Train Loss: 0.5421, Train Accuracy: 77.10%, Test Loss: 1.3210, Test Accuracy: 63.29%\n",
      "Epoch [2462/2500], Train Loss: 0.5399, Train Accuracy: 78.09%, Test Loss: 1.2876, Test Accuracy: 65.82%\n",
      "Epoch [2463/2500], Train Loss: 0.5186, Train Accuracy: 76.81%, Test Loss: 1.2317, Test Accuracy: 68.35%\n",
      "Epoch [2464/2500], Train Loss: 0.5404, Train Accuracy: 75.96%, Test Loss: 1.2728, Test Accuracy: 67.09%\n",
      "Epoch [2465/2500], Train Loss: 0.5429, Train Accuracy: 76.96%, Test Loss: 1.2738, Test Accuracy: 64.56%\n",
      "Epoch [2466/2500], Train Loss: 0.5165, Train Accuracy: 79.23%, Test Loss: 1.2254, Test Accuracy: 64.56%\n",
      "Epoch [2467/2500], Train Loss: 0.5222, Train Accuracy: 77.52%, Test Loss: 1.3175, Test Accuracy: 67.09%\n",
      "Epoch [2468/2500], Train Loss: 0.5256, Train Accuracy: 77.95%, Test Loss: 1.2178, Test Accuracy: 68.35%\n",
      "Epoch [2469/2500], Train Loss: 0.5350, Train Accuracy: 77.10%, Test Loss: 1.2655, Test Accuracy: 67.09%\n",
      "Epoch [2470/2500], Train Loss: 0.5316, Train Accuracy: 77.24%, Test Loss: 1.2312, Test Accuracy: 64.56%\n",
      "Epoch [2471/2500], Train Loss: 0.5246, Train Accuracy: 78.09%, Test Loss: 1.2120, Test Accuracy: 68.35%\n",
      "Epoch [2472/2500], Train Loss: 0.5459, Train Accuracy: 77.81%, Test Loss: 1.2797, Test Accuracy: 65.82%\n",
      "Epoch [2473/2500], Train Loss: 0.5450, Train Accuracy: 78.66%, Test Loss: 1.2790, Test Accuracy: 62.03%\n",
      "Epoch [2474/2500], Train Loss: 0.5570, Train Accuracy: 74.68%, Test Loss: 1.2315, Test Accuracy: 67.09%\n",
      "Epoch [2475/2500], Train Loss: 0.5121, Train Accuracy: 77.95%, Test Loss: 1.3542, Test Accuracy: 64.56%\n",
      "Epoch [2476/2500], Train Loss: 0.5203, Train Accuracy: 75.82%, Test Loss: 1.3037, Test Accuracy: 67.09%\n",
      "Epoch [2477/2500], Train Loss: 0.5102, Train Accuracy: 77.95%, Test Loss: 1.2444, Test Accuracy: 64.56%\n",
      "Epoch [2478/2500], Train Loss: 0.5428, Train Accuracy: 77.24%, Test Loss: 1.2409, Test Accuracy: 64.56%\n",
      "Epoch [2479/2500], Train Loss: 0.5657, Train Accuracy: 76.39%, Test Loss: 1.2402, Test Accuracy: 63.29%\n",
      "Epoch [2480/2500], Train Loss: 0.5309, Train Accuracy: 79.23%, Test Loss: 1.2045, Test Accuracy: 65.82%\n",
      "Epoch [2481/2500], Train Loss: 0.5539, Train Accuracy: 75.68%, Test Loss: 1.1611, Test Accuracy: 64.56%\n",
      "Epoch [2482/2500], Train Loss: 0.5350, Train Accuracy: 76.39%, Test Loss: 1.1877, Test Accuracy: 65.82%\n",
      "Epoch [2483/2500], Train Loss: 0.5339, Train Accuracy: 78.66%, Test Loss: 1.2178, Test Accuracy: 64.56%\n",
      "Epoch [2484/2500], Train Loss: 0.5206, Train Accuracy: 76.39%, Test Loss: 1.2472, Test Accuracy: 63.29%\n",
      "Epoch [2485/2500], Train Loss: 0.5329, Train Accuracy: 76.24%, Test Loss: 1.2702, Test Accuracy: 64.56%\n",
      "Epoch [2486/2500], Train Loss: 0.5474, Train Accuracy: 76.81%, Test Loss: 1.2761, Test Accuracy: 64.56%\n",
      "Epoch [2487/2500], Train Loss: 0.5583, Train Accuracy: 76.10%, Test Loss: 1.2300, Test Accuracy: 65.82%\n",
      "Epoch [2488/2500], Train Loss: 0.5278, Train Accuracy: 77.24%, Test Loss: 1.2307, Test Accuracy: 64.56%\n",
      "Epoch [2489/2500], Train Loss: 0.5454, Train Accuracy: 76.81%, Test Loss: 1.2441, Test Accuracy: 63.29%\n",
      "Epoch [2490/2500], Train Loss: 0.5559, Train Accuracy: 75.96%, Test Loss: 1.2165, Test Accuracy: 63.29%\n",
      "Epoch [2491/2500], Train Loss: 0.5583, Train Accuracy: 77.67%, Test Loss: 1.2124, Test Accuracy: 65.82%\n",
      "Epoch [2492/2500], Train Loss: 0.5314, Train Accuracy: 78.09%, Test Loss: 1.2703, Test Accuracy: 65.82%\n",
      "Epoch [2493/2500], Train Loss: 0.5266, Train Accuracy: 77.38%, Test Loss: 1.2073, Test Accuracy: 64.56%\n",
      "Epoch [2494/2500], Train Loss: 0.5325, Train Accuracy: 77.38%, Test Loss: 1.2350, Test Accuracy: 68.35%\n",
      "Epoch [2495/2500], Train Loss: 0.5311, Train Accuracy: 76.39%, Test Loss: 1.2171, Test Accuracy: 68.35%\n",
      "Epoch [2496/2500], Train Loss: 0.5430, Train Accuracy: 75.11%, Test Loss: 1.3331, Test Accuracy: 65.82%\n",
      "Epoch [2497/2500], Train Loss: 0.5421, Train Accuracy: 76.39%, Test Loss: 1.1905, Test Accuracy: 67.09%\n",
      "Epoch [2498/2500], Train Loss: 0.5024, Train Accuracy: 77.95%, Test Loss: 1.2436, Test Accuracy: 64.56%\n",
      "Epoch [2499/2500], Train Loss: 0.5401, Train Accuracy: 77.24%, Test Loss: 1.1622, Test Accuracy: 65.82%\n",
      "Epoch [2500/2500], Train Loss: 0.5453, Train Accuracy: 76.24%, Test Loss: 1.2569, Test Accuracy: 67.09%\n",
      "model_cnn1d saved as model_cnn1d_4class_best.pth\n",
      "\n",
      "Metrics for model_cnn1d saved as model_cnn1d_4class_metrics.csv\n",
      "\n",
      "Training model_cnn1d_lstm\n",
      "Epoch [1/2500], Train Loss: 1.3765, Train Accuracy: 27.17%, Test Loss: 1.3391, Test Accuracy: 48.10%\n",
      "Epoch [2/2500], Train Loss: 1.3605, Train Accuracy: 32.29%, Test Loss: 1.3238, Test Accuracy: 39.24%\n",
      "Epoch [3/2500], Train Loss: 1.3493, Train Accuracy: 33.71%, Test Loss: 1.3123, Test Accuracy: 39.24%\n",
      "Epoch [4/2500], Train Loss: 1.3412, Train Accuracy: 34.99%, Test Loss: 1.3072, Test Accuracy: 39.24%\n",
      "Epoch [5/2500], Train Loss: 1.3458, Train Accuracy: 34.42%, Test Loss: 1.3005, Test Accuracy: 39.24%\n",
      "Epoch [6/2500], Train Loss: 1.3363, Train Accuracy: 36.70%, Test Loss: 1.2967, Test Accuracy: 39.24%\n",
      "Epoch [7/2500], Train Loss: 1.3398, Train Accuracy: 34.99%, Test Loss: 1.2945, Test Accuracy: 39.24%\n",
      "Epoch [8/2500], Train Loss: 1.3417, Train Accuracy: 35.42%, Test Loss: 1.2905, Test Accuracy: 39.24%\n",
      "Epoch [9/2500], Train Loss: 1.3315, Train Accuracy: 35.56%, Test Loss: 1.2887, Test Accuracy: 39.24%\n",
      "Epoch [10/2500], Train Loss: 1.3408, Train Accuracy: 35.99%, Test Loss: 1.2857, Test Accuracy: 39.24%\n",
      "Epoch [11/2500], Train Loss: 1.3290, Train Accuracy: 34.99%, Test Loss: 1.2831, Test Accuracy: 39.24%\n",
      "Epoch [12/2500], Train Loss: 1.3285, Train Accuracy: 35.70%, Test Loss: 1.2792, Test Accuracy: 39.24%\n",
      "Epoch [13/2500], Train Loss: 1.3269, Train Accuracy: 35.70%, Test Loss: 1.2777, Test Accuracy: 39.24%\n",
      "Epoch [14/2500], Train Loss: 1.3268, Train Accuracy: 36.98%, Test Loss: 1.2755, Test Accuracy: 39.24%\n",
      "Epoch [15/2500], Train Loss: 1.3340, Train Accuracy: 35.70%, Test Loss: 1.2734, Test Accuracy: 39.24%\n",
      "Epoch [16/2500], Train Loss: 1.3310, Train Accuracy: 36.42%, Test Loss: 1.2698, Test Accuracy: 39.24%\n",
      "Epoch [17/2500], Train Loss: 1.3300, Train Accuracy: 36.42%, Test Loss: 1.2697, Test Accuracy: 39.24%\n",
      "Epoch [18/2500], Train Loss: 1.3327, Train Accuracy: 36.56%, Test Loss: 1.2668, Test Accuracy: 39.24%\n",
      "Epoch [19/2500], Train Loss: 1.3249, Train Accuracy: 36.27%, Test Loss: 1.2612, Test Accuracy: 39.24%\n",
      "Epoch [20/2500], Train Loss: 1.3190, Train Accuracy: 36.98%, Test Loss: 1.2600, Test Accuracy: 39.24%\n",
      "Epoch [21/2500], Train Loss: 1.3161, Train Accuracy: 37.70%, Test Loss: 1.2573, Test Accuracy: 39.24%\n",
      "Epoch [22/2500], Train Loss: 1.3236, Train Accuracy: 36.27%, Test Loss: 1.2538, Test Accuracy: 39.24%\n",
      "Epoch [23/2500], Train Loss: 1.3220, Train Accuracy: 36.98%, Test Loss: 1.2519, Test Accuracy: 39.24%\n",
      "Epoch [24/2500], Train Loss: 1.3115, Train Accuracy: 37.55%, Test Loss: 1.2485, Test Accuracy: 39.24%\n",
      "Epoch [25/2500], Train Loss: 1.3186, Train Accuracy: 36.27%, Test Loss: 1.2440, Test Accuracy: 39.24%\n",
      "Epoch [26/2500], Train Loss: 1.3080, Train Accuracy: 38.41%, Test Loss: 1.2434, Test Accuracy: 39.24%\n",
      "Epoch [27/2500], Train Loss: 1.3196, Train Accuracy: 35.56%, Test Loss: 1.2364, Test Accuracy: 39.24%\n",
      "Epoch [28/2500], Train Loss: 1.3119, Train Accuracy: 37.70%, Test Loss: 1.2343, Test Accuracy: 39.24%\n",
      "Epoch [29/2500], Train Loss: 1.3225, Train Accuracy: 37.41%, Test Loss: 1.2329, Test Accuracy: 39.24%\n",
      "Epoch [30/2500], Train Loss: 1.3138, Train Accuracy: 39.54%, Test Loss: 1.2289, Test Accuracy: 39.24%\n",
      "Epoch [31/2500], Train Loss: 1.3172, Train Accuracy: 37.27%, Test Loss: 1.2255, Test Accuracy: 39.24%\n",
      "Epoch [32/2500], Train Loss: 1.3135, Train Accuracy: 36.84%, Test Loss: 1.2199, Test Accuracy: 39.24%\n",
      "Epoch [33/2500], Train Loss: 1.3054, Train Accuracy: 39.12%, Test Loss: 1.2181, Test Accuracy: 39.24%\n",
      "Epoch [34/2500], Train Loss: 1.3028, Train Accuracy: 40.54%, Test Loss: 1.2126, Test Accuracy: 39.24%\n",
      "Epoch [35/2500], Train Loss: 1.3090, Train Accuracy: 38.41%, Test Loss: 1.2118, Test Accuracy: 40.51%\n",
      "Epoch [36/2500], Train Loss: 1.2980, Train Accuracy: 39.97%, Test Loss: 1.2049, Test Accuracy: 40.51%\n",
      "Epoch [37/2500], Train Loss: 1.3018, Train Accuracy: 39.83%, Test Loss: 1.2003, Test Accuracy: 40.51%\n",
      "Epoch [38/2500], Train Loss: 1.3039, Train Accuracy: 40.68%, Test Loss: 1.1974, Test Accuracy: 40.51%\n",
      "Epoch [39/2500], Train Loss: 1.2857, Train Accuracy: 40.83%, Test Loss: 1.1932, Test Accuracy: 41.77%\n",
      "Epoch [40/2500], Train Loss: 1.2874, Train Accuracy: 42.82%, Test Loss: 1.1893, Test Accuracy: 43.04%\n",
      "Epoch [41/2500], Train Loss: 1.2946, Train Accuracy: 42.53%, Test Loss: 1.1824, Test Accuracy: 45.57%\n",
      "Epoch [42/2500], Train Loss: 1.2833, Train Accuracy: 42.53%, Test Loss: 1.1790, Test Accuracy: 46.84%\n",
      "Epoch [43/2500], Train Loss: 1.2795, Train Accuracy: 44.81%, Test Loss: 1.1744, Test Accuracy: 48.10%\n",
      "Epoch [44/2500], Train Loss: 1.2841, Train Accuracy: 42.39%, Test Loss: 1.1670, Test Accuracy: 49.37%\n",
      "Epoch [45/2500], Train Loss: 1.2798, Train Accuracy: 42.53%, Test Loss: 1.1670, Test Accuracy: 49.37%\n",
      "Epoch [46/2500], Train Loss: 1.2848, Train Accuracy: 43.39%, Test Loss: 1.1606, Test Accuracy: 49.37%\n",
      "Epoch [47/2500], Train Loss: 1.2697, Train Accuracy: 45.66%, Test Loss: 1.1535, Test Accuracy: 50.63%\n",
      "Epoch [48/2500], Train Loss: 1.2761, Train Accuracy: 43.24%, Test Loss: 1.1494, Test Accuracy: 50.63%\n",
      "Epoch [49/2500], Train Loss: 1.2735, Train Accuracy: 43.81%, Test Loss: 1.1468, Test Accuracy: 50.63%\n",
      "Epoch [50/2500], Train Loss: 1.2593, Train Accuracy: 45.09%, Test Loss: 1.1424, Test Accuracy: 51.90%\n",
      "Epoch [51/2500], Train Loss: 1.2603, Train Accuracy: 45.38%, Test Loss: 1.1341, Test Accuracy: 51.90%\n",
      "Epoch [52/2500], Train Loss: 1.2529, Train Accuracy: 47.80%, Test Loss: 1.1267, Test Accuracy: 51.90%\n",
      "Epoch [53/2500], Train Loss: 1.2365, Train Accuracy: 49.08%, Test Loss: 1.1223, Test Accuracy: 51.90%\n",
      "Epoch [54/2500], Train Loss: 1.2378, Train Accuracy: 47.80%, Test Loss: 1.1196, Test Accuracy: 51.90%\n",
      "Epoch [55/2500], Train Loss: 1.2372, Train Accuracy: 48.51%, Test Loss: 1.1108, Test Accuracy: 53.16%\n",
      "Epoch [56/2500], Train Loss: 1.2354, Train Accuracy: 46.94%, Test Loss: 1.1058, Test Accuracy: 53.16%\n",
      "Epoch [57/2500], Train Loss: 1.2269, Train Accuracy: 48.65%, Test Loss: 1.1000, Test Accuracy: 53.16%\n",
      "Epoch [58/2500], Train Loss: 1.2338, Train Accuracy: 46.51%, Test Loss: 1.0957, Test Accuracy: 53.16%\n",
      "Epoch [59/2500], Train Loss: 1.2283, Train Accuracy: 46.94%, Test Loss: 1.0969, Test Accuracy: 53.16%\n",
      "Epoch [60/2500], Train Loss: 1.2197, Train Accuracy: 47.65%, Test Loss: 1.0832, Test Accuracy: 53.16%\n",
      "Epoch [61/2500], Train Loss: 1.2109, Train Accuracy: 48.51%, Test Loss: 1.0861, Test Accuracy: 51.90%\n",
      "Epoch [62/2500], Train Loss: 1.2115, Train Accuracy: 48.65%, Test Loss: 1.0825, Test Accuracy: 54.43%\n",
      "Epoch [63/2500], Train Loss: 1.2047, Train Accuracy: 47.80%, Test Loss: 1.0758, Test Accuracy: 53.16%\n",
      "Epoch [64/2500], Train Loss: 1.2015, Train Accuracy: 49.50%, Test Loss: 1.0710, Test Accuracy: 53.16%\n",
      "Epoch [65/2500], Train Loss: 1.1968, Train Accuracy: 49.08%, Test Loss: 1.0718, Test Accuracy: 53.16%\n",
      "Epoch [66/2500], Train Loss: 1.1911, Train Accuracy: 49.50%, Test Loss: 1.0598, Test Accuracy: 54.43%\n",
      "Epoch [67/2500], Train Loss: 1.1905, Train Accuracy: 50.92%, Test Loss: 1.0651, Test Accuracy: 53.16%\n",
      "Epoch [68/2500], Train Loss: 1.1828, Train Accuracy: 50.64%, Test Loss: 1.0624, Test Accuracy: 54.43%\n",
      "Epoch [69/2500], Train Loss: 1.1756, Train Accuracy: 50.36%, Test Loss: 1.0553, Test Accuracy: 54.43%\n",
      "Epoch [70/2500], Train Loss: 1.1769, Train Accuracy: 50.07%, Test Loss: 1.0604, Test Accuracy: 55.70%\n",
      "Epoch [71/2500], Train Loss: 1.1904, Train Accuracy: 51.64%, Test Loss: 1.0445, Test Accuracy: 54.43%\n",
      "Epoch [72/2500], Train Loss: 1.1614, Train Accuracy: 50.07%, Test Loss: 1.0407, Test Accuracy: 55.70%\n",
      "Epoch [73/2500], Train Loss: 1.1718, Train Accuracy: 50.36%, Test Loss: 1.0546, Test Accuracy: 54.43%\n",
      "Epoch [74/2500], Train Loss: 1.1586, Train Accuracy: 50.21%, Test Loss: 1.0304, Test Accuracy: 54.43%\n",
      "Epoch [75/2500], Train Loss: 1.1741, Train Accuracy: 50.21%, Test Loss: 1.0352, Test Accuracy: 55.70%\n",
      "Epoch [76/2500], Train Loss: 1.1663, Train Accuracy: 50.21%, Test Loss: 1.0447, Test Accuracy: 55.70%\n",
      "Epoch [77/2500], Train Loss: 1.1578, Train Accuracy: 52.63%, Test Loss: 1.0301, Test Accuracy: 55.70%\n",
      "Epoch [78/2500], Train Loss: 1.1431, Train Accuracy: 52.92%, Test Loss: 1.0398, Test Accuracy: 55.70%\n",
      "Epoch [79/2500], Train Loss: 1.1333, Train Accuracy: 53.91%, Test Loss: 1.0459, Test Accuracy: 56.96%\n",
      "Epoch [80/2500], Train Loss: 1.1228, Train Accuracy: 53.06%, Test Loss: 1.0382, Test Accuracy: 55.70%\n",
      "Epoch [81/2500], Train Loss: 1.1300, Train Accuracy: 51.64%, Test Loss: 1.0267, Test Accuracy: 55.70%\n",
      "Epoch [82/2500], Train Loss: 1.1315, Train Accuracy: 53.06%, Test Loss: 1.0246, Test Accuracy: 55.70%\n",
      "Epoch [83/2500], Train Loss: 1.1300, Train Accuracy: 52.49%, Test Loss: 1.0323, Test Accuracy: 55.70%\n",
      "Epoch [84/2500], Train Loss: 1.1322, Train Accuracy: 52.92%, Test Loss: 1.0239, Test Accuracy: 55.70%\n",
      "Epoch [85/2500], Train Loss: 1.1333, Train Accuracy: 51.35%, Test Loss: 1.0077, Test Accuracy: 55.70%\n",
      "Epoch [86/2500], Train Loss: 1.1448, Train Accuracy: 52.63%, Test Loss: 1.0248, Test Accuracy: 55.70%\n",
      "Epoch [87/2500], Train Loss: 1.1396, Train Accuracy: 52.06%, Test Loss: 0.9918, Test Accuracy: 56.96%\n",
      "Epoch [88/2500], Train Loss: 1.1357, Train Accuracy: 50.64%, Test Loss: 1.0057, Test Accuracy: 55.70%\n",
      "Epoch [89/2500], Train Loss: 1.1125, Train Accuracy: 53.34%, Test Loss: 1.0040, Test Accuracy: 55.70%\n",
      "Epoch [90/2500], Train Loss: 1.1058, Train Accuracy: 53.34%, Test Loss: 1.0077, Test Accuracy: 55.70%\n",
      "Epoch [91/2500], Train Loss: 1.1039, Train Accuracy: 55.05%, Test Loss: 1.0042, Test Accuracy: 55.70%\n",
      "Epoch [92/2500], Train Loss: 1.1084, Train Accuracy: 54.20%, Test Loss: 0.9997, Test Accuracy: 56.96%\n",
      "Epoch [93/2500], Train Loss: 1.1108, Train Accuracy: 54.20%, Test Loss: 1.0042, Test Accuracy: 55.70%\n",
      "Epoch [94/2500], Train Loss: 1.1057, Train Accuracy: 54.62%, Test Loss: 1.0013, Test Accuracy: 55.70%\n",
      "Epoch [95/2500], Train Loss: 1.1086, Train Accuracy: 53.63%, Test Loss: 0.9997, Test Accuracy: 56.96%\n",
      "Epoch [96/2500], Train Loss: 1.1106, Train Accuracy: 50.78%, Test Loss: 0.9982, Test Accuracy: 56.96%\n",
      "Epoch [97/2500], Train Loss: 1.1139, Train Accuracy: 54.91%, Test Loss: 0.9831, Test Accuracy: 56.96%\n",
      "Epoch [98/2500], Train Loss: 1.1011, Train Accuracy: 53.91%, Test Loss: 1.0036, Test Accuracy: 58.23%\n",
      "Epoch [99/2500], Train Loss: 1.0885, Train Accuracy: 53.77%, Test Loss: 0.9937, Test Accuracy: 56.96%\n",
      "Epoch [100/2500], Train Loss: 1.0957, Train Accuracy: 53.20%, Test Loss: 0.9763, Test Accuracy: 58.23%\n",
      "Epoch [101/2500], Train Loss: 1.0978, Train Accuracy: 52.92%, Test Loss: 0.9899, Test Accuracy: 56.96%\n",
      "Epoch [102/2500], Train Loss: 1.0894, Train Accuracy: 53.63%, Test Loss: 0.9833, Test Accuracy: 58.23%\n",
      "Epoch [103/2500], Train Loss: 1.0805, Train Accuracy: 53.63%, Test Loss: 0.9929, Test Accuracy: 56.96%\n",
      "Epoch [104/2500], Train Loss: 1.0808, Train Accuracy: 56.05%, Test Loss: 0.9812, Test Accuracy: 58.23%\n",
      "Epoch [105/2500], Train Loss: 1.0808, Train Accuracy: 54.20%, Test Loss: 0.9754, Test Accuracy: 58.23%\n",
      "Epoch [106/2500], Train Loss: 1.0751, Train Accuracy: 55.33%, Test Loss: 0.9681, Test Accuracy: 59.49%\n",
      "Epoch [107/2500], Train Loss: 1.0905, Train Accuracy: 53.49%, Test Loss: 0.9724, Test Accuracy: 59.49%\n",
      "Epoch [108/2500], Train Loss: 1.0763, Train Accuracy: 56.47%, Test Loss: 1.0094, Test Accuracy: 58.23%\n",
      "Epoch [109/2500], Train Loss: 1.0658, Train Accuracy: 53.91%, Test Loss: 0.9813, Test Accuracy: 58.23%\n",
      "Epoch [110/2500], Train Loss: 1.0792, Train Accuracy: 54.05%, Test Loss: 0.9859, Test Accuracy: 59.49%\n",
      "Epoch [111/2500], Train Loss: 1.0901, Train Accuracy: 53.77%, Test Loss: 0.9661, Test Accuracy: 59.49%\n",
      "Epoch [112/2500], Train Loss: 1.0491, Train Accuracy: 55.19%, Test Loss: 0.9849, Test Accuracy: 59.49%\n",
      "Epoch [113/2500], Train Loss: 1.0742, Train Accuracy: 55.19%, Test Loss: 0.9703, Test Accuracy: 59.49%\n",
      "Epoch [114/2500], Train Loss: 1.0757, Train Accuracy: 54.05%, Test Loss: 0.9662, Test Accuracy: 59.49%\n",
      "Epoch [115/2500], Train Loss: 1.0730, Train Accuracy: 55.33%, Test Loss: 0.9708, Test Accuracy: 59.49%\n",
      "Epoch [116/2500], Train Loss: 1.0691, Train Accuracy: 54.91%, Test Loss: 0.9595, Test Accuracy: 59.49%\n",
      "Epoch [117/2500], Train Loss: 1.0778, Train Accuracy: 54.48%, Test Loss: 0.9804, Test Accuracy: 59.49%\n",
      "Epoch [118/2500], Train Loss: 1.0665, Train Accuracy: 54.91%, Test Loss: 0.9908, Test Accuracy: 59.49%\n",
      "Epoch [119/2500], Train Loss: 1.0684, Train Accuracy: 53.63%, Test Loss: 0.9611, Test Accuracy: 59.49%\n",
      "Epoch [120/2500], Train Loss: 1.0589, Train Accuracy: 54.91%, Test Loss: 0.9689, Test Accuracy: 59.49%\n",
      "Epoch [121/2500], Train Loss: 1.0717, Train Accuracy: 54.91%, Test Loss: 0.9695, Test Accuracy: 59.49%\n",
      "Epoch [122/2500], Train Loss: 1.0643, Train Accuracy: 55.76%, Test Loss: 0.9645, Test Accuracy: 58.23%\n",
      "Epoch [123/2500], Train Loss: 1.0543, Train Accuracy: 55.33%, Test Loss: 0.9804, Test Accuracy: 59.49%\n",
      "Epoch [124/2500], Train Loss: 1.0603, Train Accuracy: 55.19%, Test Loss: 0.9556, Test Accuracy: 58.23%\n",
      "Epoch [125/2500], Train Loss: 1.0587, Train Accuracy: 56.61%, Test Loss: 0.9756, Test Accuracy: 58.23%\n",
      "Epoch [126/2500], Train Loss: 1.0700, Train Accuracy: 54.62%, Test Loss: 0.9511, Test Accuracy: 59.49%\n",
      "Epoch [127/2500], Train Loss: 1.0724, Train Accuracy: 56.05%, Test Loss: 0.9438, Test Accuracy: 59.49%\n",
      "Epoch [128/2500], Train Loss: 1.0585, Train Accuracy: 56.19%, Test Loss: 0.9566, Test Accuracy: 56.96%\n",
      "Epoch [129/2500], Train Loss: 1.0566, Train Accuracy: 55.33%, Test Loss: 0.9555, Test Accuracy: 58.23%\n",
      "Epoch [130/2500], Train Loss: 1.0524, Train Accuracy: 55.05%, Test Loss: 0.9450, Test Accuracy: 59.49%\n",
      "Epoch [131/2500], Train Loss: 1.0244, Train Accuracy: 57.04%, Test Loss: 0.9689, Test Accuracy: 56.96%\n",
      "Epoch [132/2500], Train Loss: 1.0443, Train Accuracy: 55.33%, Test Loss: 0.9460, Test Accuracy: 59.49%\n",
      "Epoch [133/2500], Train Loss: 1.0606, Train Accuracy: 55.05%, Test Loss: 0.9603, Test Accuracy: 58.23%\n",
      "Epoch [134/2500], Train Loss: 1.0663, Train Accuracy: 56.33%, Test Loss: 0.9498, Test Accuracy: 58.23%\n",
      "Epoch [135/2500], Train Loss: 1.0717, Train Accuracy: 53.77%, Test Loss: 0.9729, Test Accuracy: 58.23%\n",
      "Epoch [136/2500], Train Loss: 1.0506, Train Accuracy: 56.61%, Test Loss: 0.9639, Test Accuracy: 56.96%\n",
      "Epoch [137/2500], Train Loss: 1.0933, Train Accuracy: 55.05%, Test Loss: 0.9523, Test Accuracy: 59.49%\n",
      "Epoch [138/2500], Train Loss: 1.0521, Train Accuracy: 55.76%, Test Loss: 0.9580, Test Accuracy: 56.96%\n",
      "Epoch [139/2500], Train Loss: 1.0455, Train Accuracy: 56.33%, Test Loss: 0.9474, Test Accuracy: 58.23%\n",
      "Epoch [140/2500], Train Loss: 1.0313, Train Accuracy: 55.76%, Test Loss: 0.9547, Test Accuracy: 59.49%\n",
      "Epoch [141/2500], Train Loss: 1.0342, Train Accuracy: 57.18%, Test Loss: 0.9517, Test Accuracy: 58.23%\n",
      "Epoch [142/2500], Train Loss: 1.0437, Train Accuracy: 55.90%, Test Loss: 0.9511, Test Accuracy: 58.23%\n",
      "Epoch [143/2500], Train Loss: 1.0345, Train Accuracy: 57.47%, Test Loss: 0.9510, Test Accuracy: 59.49%\n",
      "Epoch [144/2500], Train Loss: 1.0364, Train Accuracy: 56.05%, Test Loss: 0.9469, Test Accuracy: 58.23%\n",
      "Epoch [145/2500], Train Loss: 1.0479, Train Accuracy: 56.05%, Test Loss: 0.9466, Test Accuracy: 59.49%\n",
      "Epoch [146/2500], Train Loss: 1.0324, Train Accuracy: 57.89%, Test Loss: 0.9528, Test Accuracy: 59.49%\n",
      "Epoch [147/2500], Train Loss: 1.0439, Train Accuracy: 55.33%, Test Loss: 0.9507, Test Accuracy: 58.23%\n",
      "Epoch [148/2500], Train Loss: 1.0308, Train Accuracy: 57.33%, Test Loss: 0.9586, Test Accuracy: 58.23%\n",
      "Epoch [149/2500], Train Loss: 1.0239, Train Accuracy: 56.47%, Test Loss: 0.9601, Test Accuracy: 59.49%\n",
      "Epoch [150/2500], Train Loss: 1.0192, Train Accuracy: 57.18%, Test Loss: 0.9527, Test Accuracy: 58.23%\n",
      "Epoch [151/2500], Train Loss: 1.0452, Train Accuracy: 56.05%, Test Loss: 0.9557, Test Accuracy: 58.23%\n",
      "Epoch [152/2500], Train Loss: 1.0209, Train Accuracy: 57.18%, Test Loss: 0.9451, Test Accuracy: 59.49%\n",
      "Epoch [153/2500], Train Loss: 1.0589, Train Accuracy: 55.48%, Test Loss: 0.9452, Test Accuracy: 59.49%\n",
      "Epoch [154/2500], Train Loss: 1.0385, Train Accuracy: 55.48%, Test Loss: 0.9552, Test Accuracy: 58.23%\n",
      "Epoch [155/2500], Train Loss: 1.0445, Train Accuracy: 55.90%, Test Loss: 0.9498, Test Accuracy: 59.49%\n",
      "Epoch [156/2500], Train Loss: 1.0252, Train Accuracy: 56.33%, Test Loss: 0.9458, Test Accuracy: 59.49%\n",
      "Epoch [157/2500], Train Loss: 1.0485, Train Accuracy: 55.33%, Test Loss: 0.9512, Test Accuracy: 59.49%\n",
      "Epoch [158/2500], Train Loss: 1.0228, Train Accuracy: 55.48%, Test Loss: 0.9481, Test Accuracy: 59.49%\n",
      "Epoch [159/2500], Train Loss: 1.0191, Train Accuracy: 56.61%, Test Loss: 0.9546, Test Accuracy: 58.23%\n",
      "Epoch [160/2500], Train Loss: 1.0422, Train Accuracy: 57.18%, Test Loss: 0.9469, Test Accuracy: 59.49%\n",
      "Epoch [161/2500], Train Loss: 1.0107, Train Accuracy: 56.76%, Test Loss: 0.9456, Test Accuracy: 59.49%\n",
      "Epoch [162/2500], Train Loss: 1.0160, Train Accuracy: 56.90%, Test Loss: 0.9567, Test Accuracy: 58.23%\n",
      "Epoch [163/2500], Train Loss: 1.0259, Train Accuracy: 56.33%, Test Loss: 0.9482, Test Accuracy: 59.49%\n",
      "Epoch [164/2500], Train Loss: 1.0320, Train Accuracy: 56.61%, Test Loss: 0.9439, Test Accuracy: 59.49%\n",
      "Epoch [165/2500], Train Loss: 1.0013, Train Accuracy: 56.61%, Test Loss: 0.9426, Test Accuracy: 59.49%\n",
      "Epoch [166/2500], Train Loss: 1.0188, Train Accuracy: 56.76%, Test Loss: 0.9566, Test Accuracy: 59.49%\n",
      "Epoch [167/2500], Train Loss: 1.0164, Train Accuracy: 57.75%, Test Loss: 0.9533, Test Accuracy: 59.49%\n",
      "Epoch [168/2500], Train Loss: 1.0059, Train Accuracy: 57.61%, Test Loss: 0.9601, Test Accuracy: 59.49%\n",
      "Epoch [169/2500], Train Loss: 1.0204, Train Accuracy: 57.47%, Test Loss: 0.9666, Test Accuracy: 58.23%\n",
      "Epoch [170/2500], Train Loss: 1.0208, Train Accuracy: 58.32%, Test Loss: 0.9587, Test Accuracy: 59.49%\n",
      "Epoch [171/2500], Train Loss: 1.0177, Train Accuracy: 57.61%, Test Loss: 0.9617, Test Accuracy: 58.23%\n",
      "Epoch [172/2500], Train Loss: 1.0076, Train Accuracy: 57.04%, Test Loss: 0.9572, Test Accuracy: 59.49%\n",
      "Epoch [173/2500], Train Loss: 1.0121, Train Accuracy: 56.33%, Test Loss: 0.9430, Test Accuracy: 59.49%\n",
      "Epoch [174/2500], Train Loss: 1.0281, Train Accuracy: 58.04%, Test Loss: 0.9664, Test Accuracy: 58.23%\n",
      "Epoch [175/2500], Train Loss: 1.0333, Train Accuracy: 56.90%, Test Loss: 0.9565, Test Accuracy: 59.49%\n",
      "Epoch [176/2500], Train Loss: 1.0291, Train Accuracy: 55.76%, Test Loss: 0.9556, Test Accuracy: 59.49%\n",
      "Epoch [177/2500], Train Loss: 1.0009, Train Accuracy: 58.04%, Test Loss: 0.9498, Test Accuracy: 60.76%\n",
      "Epoch [178/2500], Train Loss: 1.0220, Train Accuracy: 55.76%, Test Loss: 0.9707, Test Accuracy: 58.23%\n",
      "Epoch [179/2500], Train Loss: 1.0045, Train Accuracy: 57.33%, Test Loss: 0.9616, Test Accuracy: 59.49%\n",
      "Epoch [180/2500], Train Loss: 1.0176, Train Accuracy: 56.61%, Test Loss: 0.9654, Test Accuracy: 59.49%\n",
      "Epoch [181/2500], Train Loss: 1.0211, Train Accuracy: 57.75%, Test Loss: 0.9567, Test Accuracy: 59.49%\n",
      "Epoch [182/2500], Train Loss: 1.0108, Train Accuracy: 57.47%, Test Loss: 0.9461, Test Accuracy: 60.76%\n",
      "Epoch [183/2500], Train Loss: 1.0130, Train Accuracy: 57.33%, Test Loss: 0.9471, Test Accuracy: 60.76%\n",
      "Epoch [184/2500], Train Loss: 1.0253, Train Accuracy: 55.48%, Test Loss: 0.9543, Test Accuracy: 59.49%\n",
      "Epoch [185/2500], Train Loss: 1.0088, Train Accuracy: 55.76%, Test Loss: 0.9532, Test Accuracy: 59.49%\n",
      "Epoch [186/2500], Train Loss: 1.0269, Train Accuracy: 55.90%, Test Loss: 0.9749, Test Accuracy: 58.23%\n",
      "Epoch [187/2500], Train Loss: 1.0039, Train Accuracy: 56.61%, Test Loss: 0.9600, Test Accuracy: 59.49%\n",
      "Epoch [188/2500], Train Loss: 1.0203, Train Accuracy: 54.91%, Test Loss: 0.9644, Test Accuracy: 59.49%\n",
      "Epoch [189/2500], Train Loss: 1.0154, Train Accuracy: 56.05%, Test Loss: 0.9575, Test Accuracy: 59.49%\n",
      "Epoch [190/2500], Train Loss: 1.0116, Train Accuracy: 57.33%, Test Loss: 0.9666, Test Accuracy: 59.49%\n",
      "Epoch [191/2500], Train Loss: 1.0027, Train Accuracy: 57.04%, Test Loss: 0.9619, Test Accuracy: 59.49%\n",
      "Epoch [192/2500], Train Loss: 1.0014, Train Accuracy: 56.90%, Test Loss: 0.9568, Test Accuracy: 59.49%\n",
      "Epoch [193/2500], Train Loss: 1.0143, Train Accuracy: 57.04%, Test Loss: 0.9546, Test Accuracy: 59.49%\n",
      "Epoch [194/2500], Train Loss: 1.0101, Train Accuracy: 57.89%, Test Loss: 0.9423, Test Accuracy: 60.76%\n",
      "Epoch [195/2500], Train Loss: 1.0125, Train Accuracy: 56.76%, Test Loss: 0.9689, Test Accuracy: 59.49%\n",
      "Epoch [196/2500], Train Loss: 1.0140, Train Accuracy: 57.33%, Test Loss: 0.9505, Test Accuracy: 59.49%\n",
      "Epoch [197/2500], Train Loss: 0.9773, Train Accuracy: 57.75%, Test Loss: 0.9623, Test Accuracy: 59.49%\n",
      "Epoch [198/2500], Train Loss: 1.0124, Train Accuracy: 56.47%, Test Loss: 0.9478, Test Accuracy: 60.76%\n",
      "Epoch [199/2500], Train Loss: 1.0042, Train Accuracy: 57.04%, Test Loss: 0.9659, Test Accuracy: 59.49%\n",
      "Epoch [200/2500], Train Loss: 0.9802, Train Accuracy: 57.04%, Test Loss: 0.9483, Test Accuracy: 60.76%\n",
      "Epoch [201/2500], Train Loss: 1.0084, Train Accuracy: 57.18%, Test Loss: 0.9602, Test Accuracy: 59.49%\n",
      "Epoch [202/2500], Train Loss: 1.0140, Train Accuracy: 56.90%, Test Loss: 0.9576, Test Accuracy: 59.49%\n",
      "Epoch [203/2500], Train Loss: 0.9881, Train Accuracy: 58.75%, Test Loss: 0.9656, Test Accuracy: 59.49%\n",
      "Epoch [204/2500], Train Loss: 1.0186, Train Accuracy: 56.19%, Test Loss: 0.9587, Test Accuracy: 59.49%\n",
      "Epoch [205/2500], Train Loss: 1.0002, Train Accuracy: 57.89%, Test Loss: 0.9582, Test Accuracy: 59.49%\n",
      "Epoch [206/2500], Train Loss: 0.9804, Train Accuracy: 57.18%, Test Loss: 0.9557, Test Accuracy: 59.49%\n",
      "Epoch [207/2500], Train Loss: 1.0164, Train Accuracy: 56.47%, Test Loss: 0.9495, Test Accuracy: 60.76%\n",
      "Epoch [208/2500], Train Loss: 1.0059, Train Accuracy: 56.61%, Test Loss: 0.9668, Test Accuracy: 59.49%\n",
      "Epoch [209/2500], Train Loss: 1.0161, Train Accuracy: 56.33%, Test Loss: 0.9525, Test Accuracy: 59.49%\n",
      "Epoch [210/2500], Train Loss: 1.0138, Train Accuracy: 55.76%, Test Loss: 0.9634, Test Accuracy: 59.49%\n",
      "Epoch [211/2500], Train Loss: 1.0141, Train Accuracy: 56.19%, Test Loss: 0.9429, Test Accuracy: 60.76%\n",
      "Epoch [212/2500], Train Loss: 0.9971, Train Accuracy: 56.90%, Test Loss: 0.9475, Test Accuracy: 59.49%\n",
      "Epoch [213/2500], Train Loss: 1.0044, Train Accuracy: 56.90%, Test Loss: 0.9423, Test Accuracy: 60.76%\n",
      "Epoch [214/2500], Train Loss: 1.0215, Train Accuracy: 57.33%, Test Loss: 0.9463, Test Accuracy: 59.49%\n",
      "Epoch [215/2500], Train Loss: 0.9901, Train Accuracy: 57.18%, Test Loss: 0.9570, Test Accuracy: 59.49%\n",
      "Epoch [216/2500], Train Loss: 1.0030, Train Accuracy: 57.75%, Test Loss: 0.9472, Test Accuracy: 60.76%\n",
      "Epoch [217/2500], Train Loss: 0.9952, Train Accuracy: 58.32%, Test Loss: 0.9428, Test Accuracy: 59.49%\n",
      "Epoch [218/2500], Train Loss: 0.9766, Train Accuracy: 56.61%, Test Loss: 0.9430, Test Accuracy: 59.49%\n",
      "Epoch [219/2500], Train Loss: 1.0095, Train Accuracy: 55.48%, Test Loss: 0.9474, Test Accuracy: 60.76%\n",
      "Epoch [220/2500], Train Loss: 1.0065, Train Accuracy: 55.48%, Test Loss: 0.9401, Test Accuracy: 59.49%\n",
      "Epoch [221/2500], Train Loss: 1.0064, Train Accuracy: 56.76%, Test Loss: 0.9464, Test Accuracy: 60.76%\n",
      "Epoch [222/2500], Train Loss: 1.0103, Train Accuracy: 57.75%, Test Loss: 0.9412, Test Accuracy: 59.49%\n",
      "Epoch [223/2500], Train Loss: 0.9872, Train Accuracy: 57.33%, Test Loss: 0.9619, Test Accuracy: 58.23%\n",
      "Epoch [224/2500], Train Loss: 1.0012, Train Accuracy: 56.90%, Test Loss: 0.9394, Test Accuracy: 59.49%\n",
      "Epoch [225/2500], Train Loss: 0.9914, Train Accuracy: 56.33%, Test Loss: 0.9428, Test Accuracy: 59.49%\n",
      "Epoch [226/2500], Train Loss: 0.9817, Train Accuracy: 57.33%, Test Loss: 0.9466, Test Accuracy: 59.49%\n",
      "Epoch [227/2500], Train Loss: 1.0146, Train Accuracy: 55.90%, Test Loss: 0.9377, Test Accuracy: 59.49%\n",
      "Epoch [228/2500], Train Loss: 0.9794, Train Accuracy: 57.75%, Test Loss: 0.9379, Test Accuracy: 59.49%\n",
      "Epoch [229/2500], Train Loss: 0.9869, Train Accuracy: 57.04%, Test Loss: 0.9448, Test Accuracy: 59.49%\n",
      "Epoch [230/2500], Train Loss: 1.0068, Train Accuracy: 56.90%, Test Loss: 0.9412, Test Accuracy: 59.49%\n",
      "Epoch [231/2500], Train Loss: 0.9871, Train Accuracy: 57.61%, Test Loss: 0.9403, Test Accuracy: 59.49%\n",
      "Epoch [232/2500], Train Loss: 0.9978, Train Accuracy: 58.18%, Test Loss: 0.9449, Test Accuracy: 59.49%\n",
      "Epoch [233/2500], Train Loss: 0.9723, Train Accuracy: 58.75%, Test Loss: 0.9405, Test Accuracy: 59.49%\n",
      "Epoch [234/2500], Train Loss: 0.9925, Train Accuracy: 57.61%, Test Loss: 0.9468, Test Accuracy: 59.49%\n",
      "Epoch [235/2500], Train Loss: 0.9644, Train Accuracy: 57.33%, Test Loss: 0.9538, Test Accuracy: 60.76%\n",
      "Epoch [236/2500], Train Loss: 1.0128, Train Accuracy: 56.90%, Test Loss: 0.9536, Test Accuracy: 60.76%\n",
      "Epoch [237/2500], Train Loss: 0.9719, Train Accuracy: 58.75%, Test Loss: 0.9577, Test Accuracy: 60.76%\n",
      "Epoch [238/2500], Train Loss: 0.9836, Train Accuracy: 57.33%, Test Loss: 0.9523, Test Accuracy: 60.76%\n",
      "Epoch [239/2500], Train Loss: 0.9967, Train Accuracy: 57.61%, Test Loss: 0.9602, Test Accuracy: 59.49%\n",
      "Epoch [240/2500], Train Loss: 0.9831, Train Accuracy: 57.33%, Test Loss: 0.9716, Test Accuracy: 58.23%\n",
      "Epoch [241/2500], Train Loss: 0.9835, Train Accuracy: 56.61%, Test Loss: 0.9528, Test Accuracy: 60.76%\n",
      "Epoch [242/2500], Train Loss: 0.9852, Train Accuracy: 57.18%, Test Loss: 0.9474, Test Accuracy: 59.49%\n",
      "Epoch [243/2500], Train Loss: 0.9791, Train Accuracy: 57.18%, Test Loss: 0.9515, Test Accuracy: 60.76%\n",
      "Epoch [244/2500], Train Loss: 0.9746, Train Accuracy: 57.61%, Test Loss: 0.9514, Test Accuracy: 59.49%\n",
      "Epoch [245/2500], Train Loss: 0.9880, Train Accuracy: 59.32%, Test Loss: 0.9557, Test Accuracy: 60.76%\n",
      "Epoch [246/2500], Train Loss: 0.9979, Train Accuracy: 57.61%, Test Loss: 0.9505, Test Accuracy: 59.49%\n",
      "Epoch [247/2500], Train Loss: 0.9910, Train Accuracy: 58.18%, Test Loss: 0.9499, Test Accuracy: 59.49%\n",
      "Epoch [248/2500], Train Loss: 0.9911, Train Accuracy: 57.47%, Test Loss: 0.9558, Test Accuracy: 60.76%\n",
      "Epoch [249/2500], Train Loss: 0.9775, Train Accuracy: 58.18%, Test Loss: 0.9512, Test Accuracy: 60.76%\n",
      "Epoch [250/2500], Train Loss: 0.9890, Train Accuracy: 57.89%, Test Loss: 0.9479, Test Accuracy: 60.76%\n",
      "Epoch [251/2500], Train Loss: 0.9928, Train Accuracy: 57.18%, Test Loss: 0.9573, Test Accuracy: 58.23%\n",
      "Epoch [252/2500], Train Loss: 0.9727, Train Accuracy: 57.89%, Test Loss: 0.9527, Test Accuracy: 60.76%\n",
      "Epoch [253/2500], Train Loss: 0.9746, Train Accuracy: 57.89%, Test Loss: 0.9519, Test Accuracy: 60.76%\n",
      "Epoch [254/2500], Train Loss: 0.9842, Train Accuracy: 57.18%, Test Loss: 0.9485, Test Accuracy: 59.49%\n",
      "Epoch [255/2500], Train Loss: 0.9758, Train Accuracy: 58.32%, Test Loss: 0.9500, Test Accuracy: 60.76%\n",
      "Epoch [256/2500], Train Loss: 0.9911, Train Accuracy: 57.04%, Test Loss: 0.9404, Test Accuracy: 59.49%\n",
      "Epoch [257/2500], Train Loss: 0.9858, Train Accuracy: 57.89%, Test Loss: 0.9553, Test Accuracy: 58.23%\n",
      "Epoch [258/2500], Train Loss: 0.9746, Train Accuracy: 58.04%, Test Loss: 0.9615, Test Accuracy: 58.23%\n",
      "Epoch [259/2500], Train Loss: 0.9797, Train Accuracy: 57.04%, Test Loss: 0.9439, Test Accuracy: 59.49%\n",
      "Epoch [260/2500], Train Loss: 1.0054, Train Accuracy: 57.89%, Test Loss: 0.9433, Test Accuracy: 60.76%\n",
      "Epoch [261/2500], Train Loss: 0.9687, Train Accuracy: 57.04%, Test Loss: 0.9472, Test Accuracy: 60.76%\n",
      "Epoch [262/2500], Train Loss: 0.9741, Train Accuracy: 57.75%, Test Loss: 0.9532, Test Accuracy: 59.49%\n",
      "Epoch [263/2500], Train Loss: 0.9802, Train Accuracy: 56.76%, Test Loss: 0.9409, Test Accuracy: 59.49%\n",
      "Epoch [264/2500], Train Loss: 0.9711, Train Accuracy: 58.32%, Test Loss: 0.9384, Test Accuracy: 59.49%\n",
      "Epoch [265/2500], Train Loss: 1.0003, Train Accuracy: 58.04%, Test Loss: 0.9481, Test Accuracy: 59.49%\n",
      "Epoch [266/2500], Train Loss: 0.9716, Train Accuracy: 57.33%, Test Loss: 0.9392, Test Accuracy: 59.49%\n",
      "Epoch [267/2500], Train Loss: 0.9845, Train Accuracy: 57.75%, Test Loss: 0.9405, Test Accuracy: 60.76%\n",
      "Epoch [268/2500], Train Loss: 0.9718, Train Accuracy: 56.47%, Test Loss: 0.9530, Test Accuracy: 58.23%\n",
      "Epoch [269/2500], Train Loss: 0.9723, Train Accuracy: 58.61%, Test Loss: 0.9408, Test Accuracy: 59.49%\n",
      "Epoch [270/2500], Train Loss: 0.9742, Train Accuracy: 57.89%, Test Loss: 0.9419, Test Accuracy: 60.76%\n",
      "Epoch [271/2500], Train Loss: 0.9708, Train Accuracy: 58.32%, Test Loss: 0.9486, Test Accuracy: 59.49%\n",
      "Epoch [272/2500], Train Loss: 0.9571, Train Accuracy: 58.32%, Test Loss: 0.9440, Test Accuracy: 59.49%\n",
      "Epoch [273/2500], Train Loss: 0.9653, Train Accuracy: 59.32%, Test Loss: 0.9443, Test Accuracy: 59.49%\n",
      "Epoch [274/2500], Train Loss: 0.9656, Train Accuracy: 58.18%, Test Loss: 0.9503, Test Accuracy: 60.76%\n",
      "Epoch [275/2500], Train Loss: 0.9798, Train Accuracy: 56.33%, Test Loss: 0.9516, Test Accuracy: 60.76%\n",
      "Epoch [276/2500], Train Loss: 0.9750, Train Accuracy: 57.75%, Test Loss: 0.9496, Test Accuracy: 60.76%\n",
      "Epoch [277/2500], Train Loss: 0.9631, Train Accuracy: 57.33%, Test Loss: 0.9429, Test Accuracy: 59.49%\n",
      "Epoch [278/2500], Train Loss: 0.9702, Train Accuracy: 56.47%, Test Loss: 0.9409, Test Accuracy: 59.49%\n",
      "Epoch [279/2500], Train Loss: 0.9706, Train Accuracy: 56.90%, Test Loss: 0.9376, Test Accuracy: 60.76%\n",
      "Epoch [280/2500], Train Loss: 0.9699, Train Accuracy: 57.89%, Test Loss: 0.9422, Test Accuracy: 59.49%\n",
      "Epoch [281/2500], Train Loss: 0.9718, Train Accuracy: 56.90%, Test Loss: 0.9430, Test Accuracy: 59.49%\n",
      "Epoch [282/2500], Train Loss: 0.9726, Train Accuracy: 57.89%, Test Loss: 0.9564, Test Accuracy: 58.23%\n",
      "Epoch [283/2500], Train Loss: 0.9720, Train Accuracy: 56.33%, Test Loss: 0.9351, Test Accuracy: 59.49%\n",
      "Epoch [284/2500], Train Loss: 0.9688, Train Accuracy: 57.18%, Test Loss: 0.9369, Test Accuracy: 59.49%\n",
      "Epoch [285/2500], Train Loss: 0.9621, Train Accuracy: 57.75%, Test Loss: 0.9448, Test Accuracy: 59.49%\n",
      "Epoch [286/2500], Train Loss: 0.9702, Train Accuracy: 58.18%, Test Loss: 0.9409, Test Accuracy: 60.76%\n",
      "Epoch [287/2500], Train Loss: 0.9553, Train Accuracy: 56.61%, Test Loss: 0.9522, Test Accuracy: 59.49%\n",
      "Epoch [288/2500], Train Loss: 0.9653, Train Accuracy: 57.61%, Test Loss: 0.9514, Test Accuracy: 59.49%\n",
      "Epoch [289/2500], Train Loss: 0.9528, Train Accuracy: 57.89%, Test Loss: 0.9575, Test Accuracy: 59.49%\n",
      "Epoch [290/2500], Train Loss: 0.9755, Train Accuracy: 57.04%, Test Loss: 0.9507, Test Accuracy: 59.49%\n",
      "Epoch [291/2500], Train Loss: 0.9777, Train Accuracy: 56.33%, Test Loss: 0.9560, Test Accuracy: 59.49%\n",
      "Epoch [292/2500], Train Loss: 0.9548, Train Accuracy: 58.75%, Test Loss: 0.9432, Test Accuracy: 59.49%\n",
      "Epoch [293/2500], Train Loss: 0.9504, Train Accuracy: 57.61%, Test Loss: 0.9552, Test Accuracy: 59.49%\n",
      "Epoch [294/2500], Train Loss: 0.9603, Train Accuracy: 58.04%, Test Loss: 0.9528, Test Accuracy: 59.49%\n",
      "Epoch [295/2500], Train Loss: 0.9838, Train Accuracy: 57.75%, Test Loss: 0.9439, Test Accuracy: 59.49%\n",
      "Epoch [296/2500], Train Loss: 0.9622, Train Accuracy: 57.47%, Test Loss: 0.9434, Test Accuracy: 58.23%\n",
      "Epoch [297/2500], Train Loss: 0.9437, Train Accuracy: 56.90%, Test Loss: 0.9484, Test Accuracy: 59.49%\n",
      "Epoch [298/2500], Train Loss: 0.9515, Train Accuracy: 58.04%, Test Loss: 0.9411, Test Accuracy: 58.23%\n",
      "Epoch [299/2500], Train Loss: 0.9848, Train Accuracy: 57.75%, Test Loss: 0.9442, Test Accuracy: 59.49%\n",
      "Epoch [300/2500], Train Loss: 0.9632, Train Accuracy: 56.19%, Test Loss: 0.9438, Test Accuracy: 59.49%\n",
      "Epoch [301/2500], Train Loss: 0.9621, Train Accuracy: 58.46%, Test Loss: 0.9413, Test Accuracy: 59.49%\n",
      "Epoch [302/2500], Train Loss: 0.9742, Train Accuracy: 56.47%, Test Loss: 0.9361, Test Accuracy: 59.49%\n",
      "Epoch [303/2500], Train Loss: 0.9770, Train Accuracy: 59.32%, Test Loss: 0.9398, Test Accuracy: 59.49%\n",
      "Epoch [304/2500], Train Loss: 0.9696, Train Accuracy: 58.18%, Test Loss: 0.9466, Test Accuracy: 59.49%\n",
      "Epoch [305/2500], Train Loss: 0.9649, Train Accuracy: 56.33%, Test Loss: 0.9388, Test Accuracy: 59.49%\n",
      "Epoch [306/2500], Train Loss: 0.9599, Train Accuracy: 58.32%, Test Loss: 0.9341, Test Accuracy: 58.23%\n",
      "Epoch [307/2500], Train Loss: 0.9716, Train Accuracy: 58.32%, Test Loss: 0.9353, Test Accuracy: 58.23%\n",
      "Epoch [308/2500], Train Loss: 0.9677, Train Accuracy: 58.75%, Test Loss: 0.9369, Test Accuracy: 59.49%\n",
      "Epoch [309/2500], Train Loss: 0.9610, Train Accuracy: 57.33%, Test Loss: 0.9410, Test Accuracy: 59.49%\n",
      "Epoch [310/2500], Train Loss: 0.9712, Train Accuracy: 59.46%, Test Loss: 0.9400, Test Accuracy: 59.49%\n",
      "Epoch [311/2500], Train Loss: 0.9552, Train Accuracy: 56.76%, Test Loss: 0.9350, Test Accuracy: 58.23%\n",
      "Epoch [312/2500], Train Loss: 0.9460, Train Accuracy: 58.75%, Test Loss: 0.9388, Test Accuracy: 59.49%\n",
      "Epoch [313/2500], Train Loss: 1.0004, Train Accuracy: 57.61%, Test Loss: 0.9343, Test Accuracy: 59.49%\n",
      "Epoch [314/2500], Train Loss: 0.9508, Train Accuracy: 58.04%, Test Loss: 0.9376, Test Accuracy: 59.49%\n",
      "Epoch [315/2500], Train Loss: 0.9589, Train Accuracy: 57.89%, Test Loss: 0.9438, Test Accuracy: 59.49%\n",
      "Epoch [316/2500], Train Loss: 0.9683, Train Accuracy: 58.04%, Test Loss: 0.9372, Test Accuracy: 59.49%\n",
      "Epoch [317/2500], Train Loss: 0.9322, Train Accuracy: 59.03%, Test Loss: 0.9390, Test Accuracy: 59.49%\n",
      "Epoch [318/2500], Train Loss: 0.9523, Train Accuracy: 59.60%, Test Loss: 0.9444, Test Accuracy: 59.49%\n",
      "Epoch [319/2500], Train Loss: 0.9634, Train Accuracy: 58.75%, Test Loss: 0.9403, Test Accuracy: 59.49%\n",
      "Epoch [320/2500], Train Loss: 0.9640, Train Accuracy: 58.04%, Test Loss: 0.9423, Test Accuracy: 59.49%\n",
      "Epoch [321/2500], Train Loss: 0.9637, Train Accuracy: 56.90%, Test Loss: 0.9416, Test Accuracy: 59.49%\n",
      "Epoch [322/2500], Train Loss: 0.9625, Train Accuracy: 57.47%, Test Loss: 0.9423, Test Accuracy: 59.49%\n",
      "Epoch [323/2500], Train Loss: 0.9634, Train Accuracy: 57.47%, Test Loss: 0.9438, Test Accuracy: 59.49%\n",
      "Epoch [324/2500], Train Loss: 0.9562, Train Accuracy: 57.33%, Test Loss: 0.9426, Test Accuracy: 59.49%\n",
      "Epoch [325/2500], Train Loss: 0.9532, Train Accuracy: 57.61%, Test Loss: 0.9462, Test Accuracy: 59.49%\n",
      "Epoch [326/2500], Train Loss: 0.9538, Train Accuracy: 57.75%, Test Loss: 0.9468, Test Accuracy: 59.49%\n",
      "Epoch [327/2500], Train Loss: 0.9566, Train Accuracy: 57.89%, Test Loss: 0.9427, Test Accuracy: 59.49%\n",
      "Epoch [328/2500], Train Loss: 0.9607, Train Accuracy: 58.46%, Test Loss: 0.9510, Test Accuracy: 59.49%\n",
      "Epoch [329/2500], Train Loss: 0.9545, Train Accuracy: 57.04%, Test Loss: 0.9439, Test Accuracy: 59.49%\n",
      "Epoch [330/2500], Train Loss: 0.9355, Train Accuracy: 59.03%, Test Loss: 0.9430, Test Accuracy: 59.49%\n",
      "Epoch [331/2500], Train Loss: 0.9408, Train Accuracy: 57.18%, Test Loss: 0.9382, Test Accuracy: 59.49%\n",
      "Epoch [332/2500], Train Loss: 0.9575, Train Accuracy: 58.04%, Test Loss: 0.9672, Test Accuracy: 58.23%\n",
      "Epoch [333/2500], Train Loss: 0.9779, Train Accuracy: 56.61%, Test Loss: 0.9469, Test Accuracy: 59.49%\n",
      "Epoch [334/2500], Train Loss: 0.9724, Train Accuracy: 56.33%, Test Loss: 0.9430, Test Accuracy: 59.49%\n",
      "Epoch [335/2500], Train Loss: 0.9618, Train Accuracy: 58.18%, Test Loss: 0.9421, Test Accuracy: 59.49%\n",
      "Epoch [336/2500], Train Loss: 0.9444, Train Accuracy: 59.74%, Test Loss: 0.9519, Test Accuracy: 59.49%\n",
      "Epoch [337/2500], Train Loss: 0.9487, Train Accuracy: 57.18%, Test Loss: 0.9413, Test Accuracy: 58.23%\n",
      "Epoch [338/2500], Train Loss: 0.9434, Train Accuracy: 58.32%, Test Loss: 0.9427, Test Accuracy: 59.49%\n",
      "Epoch [339/2500], Train Loss: 0.9706, Train Accuracy: 55.76%, Test Loss: 0.9430, Test Accuracy: 59.49%\n",
      "Epoch [340/2500], Train Loss: 0.9395, Train Accuracy: 58.75%, Test Loss: 0.9422, Test Accuracy: 60.76%\n",
      "Epoch [341/2500], Train Loss: 0.9549, Train Accuracy: 58.46%, Test Loss: 0.9375, Test Accuracy: 59.49%\n",
      "Epoch [342/2500], Train Loss: 0.9391, Train Accuracy: 57.33%, Test Loss: 0.9471, Test Accuracy: 60.76%\n",
      "Epoch [343/2500], Train Loss: 0.9498, Train Accuracy: 57.04%, Test Loss: 0.9360, Test Accuracy: 59.49%\n",
      "Epoch [344/2500], Train Loss: 0.9529, Train Accuracy: 57.18%, Test Loss: 0.9403, Test Accuracy: 59.49%\n",
      "Epoch [345/2500], Train Loss: 0.9657, Train Accuracy: 58.32%, Test Loss: 0.9420, Test Accuracy: 60.76%\n",
      "Epoch [346/2500], Train Loss: 0.9493, Train Accuracy: 58.61%, Test Loss: 0.9362, Test Accuracy: 59.49%\n",
      "Epoch [347/2500], Train Loss: 0.9479, Train Accuracy: 60.46%, Test Loss: 0.9342, Test Accuracy: 60.76%\n",
      "Epoch [348/2500], Train Loss: 0.9402, Train Accuracy: 57.61%, Test Loss: 0.9473, Test Accuracy: 59.49%\n",
      "Epoch [349/2500], Train Loss: 0.9580, Train Accuracy: 57.75%, Test Loss: 0.9368, Test Accuracy: 60.76%\n",
      "Epoch [350/2500], Train Loss: 0.9291, Train Accuracy: 59.60%, Test Loss: 0.9365, Test Accuracy: 60.76%\n",
      "Epoch [351/2500], Train Loss: 0.9333, Train Accuracy: 58.89%, Test Loss: 0.9437, Test Accuracy: 59.49%\n",
      "Epoch [352/2500], Train Loss: 0.9415, Train Accuracy: 57.47%, Test Loss: 0.9342, Test Accuracy: 59.49%\n",
      "Epoch [353/2500], Train Loss: 0.9376, Train Accuracy: 56.90%, Test Loss: 0.9431, Test Accuracy: 60.76%\n",
      "Epoch [354/2500], Train Loss: 0.9453, Train Accuracy: 58.18%, Test Loss: 0.9394, Test Accuracy: 60.76%\n",
      "Epoch [355/2500], Train Loss: 0.9569, Train Accuracy: 59.17%, Test Loss: 0.9297, Test Accuracy: 59.49%\n",
      "Epoch [356/2500], Train Loss: 0.9301, Train Accuracy: 59.03%, Test Loss: 0.9334, Test Accuracy: 59.49%\n",
      "Epoch [357/2500], Train Loss: 0.9353, Train Accuracy: 59.60%, Test Loss: 0.9500, Test Accuracy: 59.49%\n",
      "Epoch [358/2500], Train Loss: 0.9542, Train Accuracy: 58.46%, Test Loss: 0.9442, Test Accuracy: 60.76%\n",
      "Epoch [359/2500], Train Loss: 0.9317, Train Accuracy: 57.61%, Test Loss: 0.9393, Test Accuracy: 59.49%\n",
      "Epoch [360/2500], Train Loss: 0.9316, Train Accuracy: 57.75%, Test Loss: 0.9340, Test Accuracy: 59.49%\n",
      "Epoch [361/2500], Train Loss: 0.9544, Train Accuracy: 56.90%, Test Loss: 0.9296, Test Accuracy: 59.49%\n",
      "Epoch [362/2500], Train Loss: 0.9383, Train Accuracy: 58.04%, Test Loss: 0.9405, Test Accuracy: 60.76%\n",
      "Epoch [363/2500], Train Loss: 0.9653, Train Accuracy: 59.17%, Test Loss: 0.9291, Test Accuracy: 59.49%\n",
      "Epoch [364/2500], Train Loss: 0.9492, Train Accuracy: 57.04%, Test Loss: 0.9227, Test Accuracy: 59.49%\n",
      "Epoch [365/2500], Train Loss: 0.9412, Train Accuracy: 60.03%, Test Loss: 0.9368, Test Accuracy: 60.76%\n",
      "Epoch [366/2500], Train Loss: 0.9589, Train Accuracy: 58.75%, Test Loss: 0.9188, Test Accuracy: 60.76%\n",
      "Epoch [367/2500], Train Loss: 0.9357, Train Accuracy: 56.33%, Test Loss: 0.9296, Test Accuracy: 59.49%\n",
      "Epoch [368/2500], Train Loss: 0.9294, Train Accuracy: 58.46%, Test Loss: 0.9356, Test Accuracy: 59.49%\n",
      "Epoch [369/2500], Train Loss: 0.9550, Train Accuracy: 57.75%, Test Loss: 0.9259, Test Accuracy: 59.49%\n",
      "Epoch [370/2500], Train Loss: 0.9555, Train Accuracy: 57.04%, Test Loss: 0.9341, Test Accuracy: 60.76%\n",
      "Epoch [371/2500], Train Loss: 0.9418, Train Accuracy: 60.31%, Test Loss: 0.9382, Test Accuracy: 60.76%\n",
      "Epoch [372/2500], Train Loss: 0.9297, Train Accuracy: 58.32%, Test Loss: 0.9267, Test Accuracy: 60.76%\n",
      "Epoch [373/2500], Train Loss: 0.9296, Train Accuracy: 58.89%, Test Loss: 0.9306, Test Accuracy: 59.49%\n",
      "Epoch [374/2500], Train Loss: 0.9437, Train Accuracy: 58.61%, Test Loss: 0.9268, Test Accuracy: 60.76%\n",
      "Epoch [375/2500], Train Loss: 0.9519, Train Accuracy: 57.89%, Test Loss: 0.9313, Test Accuracy: 60.76%\n",
      "Epoch [376/2500], Train Loss: 0.9491, Train Accuracy: 57.61%, Test Loss: 0.9137, Test Accuracy: 59.49%\n",
      "Epoch [377/2500], Train Loss: 0.9549, Train Accuracy: 60.03%, Test Loss: 0.9132, Test Accuracy: 60.76%\n",
      "Epoch [378/2500], Train Loss: 0.9505, Train Accuracy: 56.90%, Test Loss: 0.9329, Test Accuracy: 60.76%\n",
      "Epoch [379/2500], Train Loss: 0.9400, Train Accuracy: 58.32%, Test Loss: 0.9336, Test Accuracy: 60.76%\n",
      "Epoch [380/2500], Train Loss: 0.9284, Train Accuracy: 57.89%, Test Loss: 0.9390, Test Accuracy: 60.76%\n",
      "Epoch [381/2500], Train Loss: 0.9444, Train Accuracy: 59.32%, Test Loss: 0.9278, Test Accuracy: 59.49%\n",
      "Epoch [382/2500], Train Loss: 0.9312, Train Accuracy: 57.18%, Test Loss: 0.9279, Test Accuracy: 59.49%\n",
      "Epoch [383/2500], Train Loss: 0.9464, Train Accuracy: 57.75%, Test Loss: 0.9268, Test Accuracy: 59.49%\n",
      "Epoch [384/2500], Train Loss: 0.9336, Train Accuracy: 59.74%, Test Loss: 0.9384, Test Accuracy: 60.76%\n",
      "Epoch [385/2500], Train Loss: 0.9320, Train Accuracy: 58.46%, Test Loss: 0.9241, Test Accuracy: 60.76%\n",
      "Epoch [386/2500], Train Loss: 0.9362, Train Accuracy: 58.04%, Test Loss: 0.9245, Test Accuracy: 59.49%\n",
      "Epoch [387/2500], Train Loss: 0.9212, Train Accuracy: 58.61%, Test Loss: 0.9344, Test Accuracy: 59.49%\n",
      "Epoch [388/2500], Train Loss: 0.9602, Train Accuracy: 59.03%, Test Loss: 0.9228, Test Accuracy: 59.49%\n",
      "Epoch [389/2500], Train Loss: 0.9208, Train Accuracy: 59.17%, Test Loss: 0.9232, Test Accuracy: 59.49%\n",
      "Epoch [390/2500], Train Loss: 0.9248, Train Accuracy: 60.31%, Test Loss: 0.9293, Test Accuracy: 60.76%\n",
      "Epoch [391/2500], Train Loss: 0.9241, Train Accuracy: 58.18%, Test Loss: 0.9300, Test Accuracy: 62.03%\n",
      "Epoch [392/2500], Train Loss: 0.9259, Train Accuracy: 57.89%, Test Loss: 0.9206, Test Accuracy: 60.76%\n",
      "Epoch [393/2500], Train Loss: 0.9284, Train Accuracy: 58.89%, Test Loss: 0.9226, Test Accuracy: 60.76%\n",
      "Epoch [394/2500], Train Loss: 0.9219, Train Accuracy: 59.46%, Test Loss: 0.9320, Test Accuracy: 62.03%\n",
      "Epoch [395/2500], Train Loss: 0.9340, Train Accuracy: 57.75%, Test Loss: 0.9129, Test Accuracy: 60.76%\n",
      "Epoch [396/2500], Train Loss: 0.9323, Train Accuracy: 60.60%, Test Loss: 0.9206, Test Accuracy: 60.76%\n",
      "Epoch [397/2500], Train Loss: 0.9471, Train Accuracy: 57.04%, Test Loss: 0.9236, Test Accuracy: 62.03%\n",
      "Epoch [398/2500], Train Loss: 0.9490, Train Accuracy: 57.47%, Test Loss: 0.9187, Test Accuracy: 62.03%\n",
      "Epoch [399/2500], Train Loss: 0.9366, Train Accuracy: 58.46%, Test Loss: 0.9224, Test Accuracy: 63.29%\n",
      "Epoch [400/2500], Train Loss: 0.9315, Train Accuracy: 59.32%, Test Loss: 0.9314, Test Accuracy: 62.03%\n",
      "Epoch [401/2500], Train Loss: 0.9161, Train Accuracy: 59.74%, Test Loss: 0.9207, Test Accuracy: 60.76%\n",
      "Epoch [402/2500], Train Loss: 0.9288, Train Accuracy: 59.74%, Test Loss: 0.9283, Test Accuracy: 62.03%\n",
      "Epoch [403/2500], Train Loss: 0.9314, Train Accuracy: 58.18%, Test Loss: 0.9256, Test Accuracy: 60.76%\n",
      "Epoch [404/2500], Train Loss: 0.9219, Train Accuracy: 59.32%, Test Loss: 0.9279, Test Accuracy: 60.76%\n",
      "Epoch [405/2500], Train Loss: 0.9260, Train Accuracy: 59.89%, Test Loss: 0.9248, Test Accuracy: 60.76%\n",
      "Epoch [406/2500], Train Loss: 0.9497, Train Accuracy: 58.89%, Test Loss: 0.9352, Test Accuracy: 60.76%\n",
      "Epoch [407/2500], Train Loss: 0.9288, Train Accuracy: 58.32%, Test Loss: 0.9417, Test Accuracy: 63.29%\n",
      "Epoch [408/2500], Train Loss: 0.9248, Train Accuracy: 58.46%, Test Loss: 0.9207, Test Accuracy: 62.03%\n",
      "Epoch [409/2500], Train Loss: 0.9529, Train Accuracy: 58.46%, Test Loss: 0.9296, Test Accuracy: 62.03%\n",
      "Epoch [410/2500], Train Loss: 0.9305, Train Accuracy: 59.89%, Test Loss: 0.9212, Test Accuracy: 60.76%\n",
      "Epoch [411/2500], Train Loss: 0.9328, Train Accuracy: 59.60%, Test Loss: 0.9183, Test Accuracy: 63.29%\n",
      "Epoch [412/2500], Train Loss: 0.9254, Train Accuracy: 59.32%, Test Loss: 0.9393, Test Accuracy: 62.03%\n",
      "Epoch [413/2500], Train Loss: 0.9122, Train Accuracy: 58.89%, Test Loss: 0.9329, Test Accuracy: 60.76%\n",
      "Epoch [414/2500], Train Loss: 0.9399, Train Accuracy: 58.04%, Test Loss: 0.9263, Test Accuracy: 60.76%\n",
      "Epoch [415/2500], Train Loss: 0.9382, Train Accuracy: 60.17%, Test Loss: 0.9189, Test Accuracy: 62.03%\n",
      "Epoch [416/2500], Train Loss: 0.9254, Train Accuracy: 57.75%, Test Loss: 0.9250, Test Accuracy: 63.29%\n",
      "Epoch [417/2500], Train Loss: 0.9305, Train Accuracy: 59.60%, Test Loss: 0.9285, Test Accuracy: 63.29%\n",
      "Epoch [418/2500], Train Loss: 0.9147, Train Accuracy: 60.46%, Test Loss: 0.9413, Test Accuracy: 63.29%\n",
      "Epoch [419/2500], Train Loss: 0.9456, Train Accuracy: 58.61%, Test Loss: 0.9361, Test Accuracy: 62.03%\n",
      "Epoch [420/2500], Train Loss: 0.9247, Train Accuracy: 58.18%, Test Loss: 0.9271, Test Accuracy: 64.56%\n",
      "Epoch [421/2500], Train Loss: 0.9148, Train Accuracy: 60.17%, Test Loss: 0.9261, Test Accuracy: 63.29%\n",
      "Epoch [422/2500], Train Loss: 0.9137, Train Accuracy: 58.75%, Test Loss: 0.9221, Test Accuracy: 62.03%\n",
      "Epoch [423/2500], Train Loss: 0.9276, Train Accuracy: 59.46%, Test Loss: 0.9156, Test Accuracy: 64.56%\n",
      "Epoch [424/2500], Train Loss: 0.9227, Train Accuracy: 59.03%, Test Loss: 0.9283, Test Accuracy: 63.29%\n",
      "Epoch [425/2500], Train Loss: 0.9340, Train Accuracy: 58.46%, Test Loss: 0.9206, Test Accuracy: 63.29%\n",
      "Epoch [426/2500], Train Loss: 0.9029, Train Accuracy: 60.46%, Test Loss: 0.9165, Test Accuracy: 63.29%\n",
      "Epoch [427/2500], Train Loss: 0.9105, Train Accuracy: 58.89%, Test Loss: 0.9181, Test Accuracy: 63.29%\n",
      "Epoch [428/2500], Train Loss: 0.9035, Train Accuracy: 61.45%, Test Loss: 0.9312, Test Accuracy: 60.76%\n",
      "Epoch [429/2500], Train Loss: 0.9441, Train Accuracy: 58.89%, Test Loss: 0.9171, Test Accuracy: 63.29%\n",
      "Epoch [430/2500], Train Loss: 0.9185, Train Accuracy: 59.17%, Test Loss: 0.9146, Test Accuracy: 64.56%\n",
      "Epoch [431/2500], Train Loss: 0.9162, Train Accuracy: 58.46%, Test Loss: 0.9298, Test Accuracy: 62.03%\n",
      "Epoch [432/2500], Train Loss: 0.9392, Train Accuracy: 58.46%, Test Loss: 0.9235, Test Accuracy: 63.29%\n",
      "Epoch [433/2500], Train Loss: 0.9110, Train Accuracy: 61.17%, Test Loss: 0.9183, Test Accuracy: 67.09%\n",
      "Epoch [434/2500], Train Loss: 0.9302, Train Accuracy: 60.74%, Test Loss: 0.9335, Test Accuracy: 63.29%\n",
      "Epoch [435/2500], Train Loss: 0.9205, Train Accuracy: 59.17%, Test Loss: 0.9235, Test Accuracy: 64.56%\n",
      "Epoch [436/2500], Train Loss: 0.8979, Train Accuracy: 61.74%, Test Loss: 0.9427, Test Accuracy: 62.03%\n",
      "Epoch [437/2500], Train Loss: 0.9229, Train Accuracy: 59.89%, Test Loss: 0.9259, Test Accuracy: 64.56%\n",
      "Epoch [438/2500], Train Loss: 0.9143, Train Accuracy: 59.32%, Test Loss: 0.9340, Test Accuracy: 63.29%\n",
      "Epoch [439/2500], Train Loss: 0.9058, Train Accuracy: 60.46%, Test Loss: 0.9215, Test Accuracy: 63.29%\n",
      "Epoch [440/2500], Train Loss: 0.9140, Train Accuracy: 59.89%, Test Loss: 0.9373, Test Accuracy: 63.29%\n",
      "Epoch [441/2500], Train Loss: 0.9191, Train Accuracy: 58.89%, Test Loss: 0.9257, Test Accuracy: 63.29%\n",
      "Epoch [442/2500], Train Loss: 0.9091, Train Accuracy: 58.75%, Test Loss: 0.9256, Test Accuracy: 63.29%\n",
      "Epoch [443/2500], Train Loss: 0.9360, Train Accuracy: 58.04%, Test Loss: 0.9417, Test Accuracy: 62.03%\n",
      "Epoch [444/2500], Train Loss: 0.9310, Train Accuracy: 59.17%, Test Loss: 0.9242, Test Accuracy: 64.56%\n",
      "Epoch [445/2500], Train Loss: 0.9324, Train Accuracy: 58.75%, Test Loss: 0.9343, Test Accuracy: 63.29%\n",
      "Epoch [446/2500], Train Loss: 0.9147, Train Accuracy: 60.46%, Test Loss: 0.9302, Test Accuracy: 64.56%\n",
      "Epoch [447/2500], Train Loss: 0.9350, Train Accuracy: 58.18%, Test Loss: 0.9175, Test Accuracy: 64.56%\n",
      "Epoch [448/2500], Train Loss: 0.9376, Train Accuracy: 58.61%, Test Loss: 0.9166, Test Accuracy: 65.82%\n",
      "Epoch [449/2500], Train Loss: 0.9252, Train Accuracy: 58.61%, Test Loss: 0.9349, Test Accuracy: 62.03%\n",
      "Epoch [450/2500], Train Loss: 0.9307, Train Accuracy: 59.03%, Test Loss: 0.9120, Test Accuracy: 65.82%\n",
      "Epoch [451/2500], Train Loss: 0.9328, Train Accuracy: 58.46%, Test Loss: 0.9191, Test Accuracy: 64.56%\n",
      "Epoch [452/2500], Train Loss: 0.9191, Train Accuracy: 59.60%, Test Loss: 0.9181, Test Accuracy: 64.56%\n",
      "Epoch [453/2500], Train Loss: 0.9264, Train Accuracy: 59.46%, Test Loss: 0.9236, Test Accuracy: 64.56%\n",
      "Epoch [454/2500], Train Loss: 0.9276, Train Accuracy: 61.02%, Test Loss: 0.9497, Test Accuracy: 56.96%\n",
      "Epoch [455/2500], Train Loss: 0.9174, Train Accuracy: 59.74%, Test Loss: 0.9143, Test Accuracy: 64.56%\n",
      "Epoch [456/2500], Train Loss: 0.9138, Train Accuracy: 60.31%, Test Loss: 0.9182, Test Accuracy: 64.56%\n",
      "Epoch [457/2500], Train Loss: 0.9120, Train Accuracy: 58.32%, Test Loss: 0.9125, Test Accuracy: 64.56%\n",
      "Epoch [458/2500], Train Loss: 0.9191, Train Accuracy: 60.31%, Test Loss: 0.9209, Test Accuracy: 62.03%\n",
      "Epoch [459/2500], Train Loss: 0.9246, Train Accuracy: 58.89%, Test Loss: 0.9293, Test Accuracy: 64.56%\n",
      "Epoch [460/2500], Train Loss: 0.9039, Train Accuracy: 61.31%, Test Loss: 0.9129, Test Accuracy: 63.29%\n",
      "Epoch [461/2500], Train Loss: 0.9158, Train Accuracy: 58.04%, Test Loss: 0.9154, Test Accuracy: 63.29%\n",
      "Epoch [462/2500], Train Loss: 0.9020, Train Accuracy: 60.03%, Test Loss: 0.9260, Test Accuracy: 64.56%\n",
      "Epoch [463/2500], Train Loss: 0.9388, Train Accuracy: 59.60%, Test Loss: 0.9178, Test Accuracy: 65.82%\n",
      "Epoch [464/2500], Train Loss: 0.9169, Train Accuracy: 59.46%, Test Loss: 0.9083, Test Accuracy: 65.82%\n",
      "Epoch [465/2500], Train Loss: 0.9129, Train Accuracy: 60.03%, Test Loss: 0.9181, Test Accuracy: 65.82%\n",
      "Epoch [466/2500], Train Loss: 0.8999, Train Accuracy: 59.32%, Test Loss: 0.9203, Test Accuracy: 65.82%\n",
      "Epoch [467/2500], Train Loss: 0.9216, Train Accuracy: 59.89%, Test Loss: 0.9065, Test Accuracy: 64.56%\n",
      "Epoch [468/2500], Train Loss: 0.9148, Train Accuracy: 57.89%, Test Loss: 0.9064, Test Accuracy: 67.09%\n",
      "Epoch [469/2500], Train Loss: 0.9133, Train Accuracy: 60.74%, Test Loss: 0.9069, Test Accuracy: 67.09%\n",
      "Epoch [470/2500], Train Loss: 0.9133, Train Accuracy: 61.17%, Test Loss: 0.9203, Test Accuracy: 64.56%\n",
      "Epoch [471/2500], Train Loss: 0.9179, Train Accuracy: 58.32%, Test Loss: 0.9078, Test Accuracy: 65.82%\n",
      "Epoch [472/2500], Train Loss: 0.8969, Train Accuracy: 63.16%, Test Loss: 0.8962, Test Accuracy: 63.29%\n",
      "Epoch [473/2500], Train Loss: 0.8900, Train Accuracy: 60.60%, Test Loss: 0.9178, Test Accuracy: 64.56%\n",
      "Epoch [474/2500], Train Loss: 0.9395, Train Accuracy: 58.46%, Test Loss: 0.9045, Test Accuracy: 65.82%\n",
      "Epoch [475/2500], Train Loss: 0.9048, Train Accuracy: 61.31%, Test Loss: 0.9065, Test Accuracy: 65.82%\n",
      "Epoch [476/2500], Train Loss: 0.9079, Train Accuracy: 59.60%, Test Loss: 0.9128, Test Accuracy: 65.82%\n",
      "Epoch [477/2500], Train Loss: 0.8955, Train Accuracy: 60.74%, Test Loss: 0.9133, Test Accuracy: 65.82%\n",
      "Epoch [478/2500], Train Loss: 0.9113, Train Accuracy: 59.17%, Test Loss: 0.9281, Test Accuracy: 63.29%\n",
      "Epoch [479/2500], Train Loss: 0.9142, Train Accuracy: 60.31%, Test Loss: 0.9093, Test Accuracy: 67.09%\n",
      "Epoch [480/2500], Train Loss: 0.9305, Train Accuracy: 59.17%, Test Loss: 0.9092, Test Accuracy: 64.56%\n",
      "Epoch [481/2500], Train Loss: 0.9022, Train Accuracy: 60.03%, Test Loss: 0.9083, Test Accuracy: 67.09%\n",
      "Epoch [482/2500], Train Loss: 0.8988, Train Accuracy: 57.89%, Test Loss: 0.9561, Test Accuracy: 56.96%\n",
      "Epoch [483/2500], Train Loss: 0.8967, Train Accuracy: 61.17%, Test Loss: 0.9258, Test Accuracy: 63.29%\n",
      "Epoch [484/2500], Train Loss: 0.9130, Train Accuracy: 60.03%, Test Loss: 0.9276, Test Accuracy: 63.29%\n",
      "Epoch [485/2500], Train Loss: 0.9144, Train Accuracy: 60.17%, Test Loss: 0.9149, Test Accuracy: 64.56%\n",
      "Epoch [486/2500], Train Loss: 0.9115, Train Accuracy: 59.89%, Test Loss: 0.9157, Test Accuracy: 64.56%\n",
      "Epoch [487/2500], Train Loss: 0.8876, Train Accuracy: 59.89%, Test Loss: 0.9203, Test Accuracy: 65.82%\n",
      "Epoch [488/2500], Train Loss: 0.9075, Train Accuracy: 59.17%, Test Loss: 0.9121, Test Accuracy: 64.56%\n",
      "Epoch [489/2500], Train Loss: 0.9003, Train Accuracy: 60.03%, Test Loss: 0.9174, Test Accuracy: 64.56%\n",
      "Epoch [490/2500], Train Loss: 0.9090, Train Accuracy: 60.31%, Test Loss: 0.9102, Test Accuracy: 64.56%\n",
      "Epoch [491/2500], Train Loss: 0.9070, Train Accuracy: 62.02%, Test Loss: 0.9419, Test Accuracy: 59.49%\n",
      "Epoch [492/2500], Train Loss: 0.8918, Train Accuracy: 59.89%, Test Loss: 0.9128, Test Accuracy: 63.29%\n",
      "Epoch [493/2500], Train Loss: 0.9252, Train Accuracy: 58.89%, Test Loss: 0.9194, Test Accuracy: 64.56%\n",
      "Epoch [494/2500], Train Loss: 0.8769, Train Accuracy: 60.17%, Test Loss: 0.9378, Test Accuracy: 60.76%\n",
      "Epoch [495/2500], Train Loss: 0.8973, Train Accuracy: 61.59%, Test Loss: 0.9308, Test Accuracy: 64.56%\n",
      "Epoch [496/2500], Train Loss: 0.9086, Train Accuracy: 60.60%, Test Loss: 0.9095, Test Accuracy: 67.09%\n",
      "Epoch [497/2500], Train Loss: 0.9214, Train Accuracy: 60.60%, Test Loss: 0.9124, Test Accuracy: 64.56%\n",
      "Epoch [498/2500], Train Loss: 0.9075, Train Accuracy: 59.89%, Test Loss: 0.9325, Test Accuracy: 64.56%\n",
      "Epoch [499/2500], Train Loss: 0.9122, Train Accuracy: 60.03%, Test Loss: 0.9109, Test Accuracy: 64.56%\n",
      "Epoch [500/2500], Train Loss: 0.8750, Train Accuracy: 63.30%, Test Loss: 0.9260, Test Accuracy: 63.29%\n",
      "Epoch [501/2500], Train Loss: 0.9024, Train Accuracy: 59.74%, Test Loss: 0.9079, Test Accuracy: 64.56%\n",
      "Epoch [502/2500], Train Loss: 0.9062, Train Accuracy: 58.61%, Test Loss: 0.9199, Test Accuracy: 63.29%\n",
      "Epoch [503/2500], Train Loss: 0.8963, Train Accuracy: 60.74%, Test Loss: 0.9102, Test Accuracy: 64.56%\n",
      "Epoch [504/2500], Train Loss: 0.9212, Train Accuracy: 58.89%, Test Loss: 0.8994, Test Accuracy: 64.56%\n",
      "Epoch [505/2500], Train Loss: 0.9084, Train Accuracy: 59.17%, Test Loss: 0.9029, Test Accuracy: 64.56%\n",
      "Epoch [506/2500], Train Loss: 0.9088, Train Accuracy: 58.75%, Test Loss: 0.9185, Test Accuracy: 63.29%\n",
      "Epoch [507/2500], Train Loss: 0.8954, Train Accuracy: 59.89%, Test Loss: 0.9123, Test Accuracy: 64.56%\n",
      "Epoch [508/2500], Train Loss: 0.8867, Train Accuracy: 63.02%, Test Loss: 0.9142, Test Accuracy: 64.56%\n",
      "Epoch [509/2500], Train Loss: 0.9009, Train Accuracy: 57.75%, Test Loss: 0.9076, Test Accuracy: 65.82%\n",
      "Epoch [510/2500], Train Loss: 0.8777, Train Accuracy: 61.31%, Test Loss: 0.9239, Test Accuracy: 63.29%\n",
      "Epoch [511/2500], Train Loss: 0.9043, Train Accuracy: 59.32%, Test Loss: 0.9135, Test Accuracy: 63.29%\n",
      "Epoch [512/2500], Train Loss: 0.9246, Train Accuracy: 59.89%, Test Loss: 0.9095, Test Accuracy: 63.29%\n",
      "Epoch [513/2500], Train Loss: 0.9061, Train Accuracy: 59.74%, Test Loss: 0.9154, Test Accuracy: 63.29%\n",
      "Epoch [514/2500], Train Loss: 0.9074, Train Accuracy: 59.74%, Test Loss: 0.9216, Test Accuracy: 63.29%\n",
      "Epoch [515/2500], Train Loss: 0.8957, Train Accuracy: 62.02%, Test Loss: 0.9224, Test Accuracy: 62.03%\n",
      "Epoch [516/2500], Train Loss: 0.9112, Train Accuracy: 58.61%, Test Loss: 0.9352, Test Accuracy: 59.49%\n",
      "Epoch [517/2500], Train Loss: 0.9085, Train Accuracy: 59.74%, Test Loss: 0.9324, Test Accuracy: 62.03%\n",
      "Epoch [518/2500], Train Loss: 0.8965, Train Accuracy: 59.32%, Test Loss: 0.9202, Test Accuracy: 63.29%\n",
      "Epoch [519/2500], Train Loss: 0.8949, Train Accuracy: 61.45%, Test Loss: 0.9185, Test Accuracy: 60.76%\n",
      "Epoch [520/2500], Train Loss: 0.8901, Train Accuracy: 60.31%, Test Loss: 0.9295, Test Accuracy: 60.76%\n",
      "Epoch [521/2500], Train Loss: 0.9156, Train Accuracy: 57.89%, Test Loss: 0.9134, Test Accuracy: 63.29%\n",
      "Epoch [522/2500], Train Loss: 0.8969, Train Accuracy: 60.17%, Test Loss: 0.9103, Test Accuracy: 63.29%\n",
      "Epoch [523/2500], Train Loss: 0.8905, Train Accuracy: 60.60%, Test Loss: 0.9264, Test Accuracy: 62.03%\n",
      "Epoch [524/2500], Train Loss: 0.8977, Train Accuracy: 59.17%, Test Loss: 0.9205, Test Accuracy: 62.03%\n",
      "Epoch [525/2500], Train Loss: 0.8795, Train Accuracy: 61.45%, Test Loss: 0.9155, Test Accuracy: 64.56%\n",
      "Epoch [526/2500], Train Loss: 0.8928, Train Accuracy: 61.45%, Test Loss: 0.9308, Test Accuracy: 62.03%\n",
      "Epoch [527/2500], Train Loss: 0.8871, Train Accuracy: 61.31%, Test Loss: 0.9174, Test Accuracy: 64.56%\n",
      "Epoch [528/2500], Train Loss: 0.8906, Train Accuracy: 60.31%, Test Loss: 0.9110, Test Accuracy: 63.29%\n",
      "Epoch [529/2500], Train Loss: 0.9079, Train Accuracy: 59.74%, Test Loss: 0.9081, Test Accuracy: 62.03%\n",
      "Epoch [530/2500], Train Loss: 0.8888, Train Accuracy: 59.74%, Test Loss: 0.9099, Test Accuracy: 62.03%\n",
      "Epoch [531/2500], Train Loss: 0.9029, Train Accuracy: 60.17%, Test Loss: 0.9128, Test Accuracy: 63.29%\n",
      "Epoch [532/2500], Train Loss: 0.8940, Train Accuracy: 61.17%, Test Loss: 0.9247, Test Accuracy: 59.49%\n",
      "Epoch [533/2500], Train Loss: 0.8883, Train Accuracy: 59.60%, Test Loss: 0.9228, Test Accuracy: 62.03%\n",
      "Epoch [534/2500], Train Loss: 0.8808, Train Accuracy: 59.60%, Test Loss: 0.9158, Test Accuracy: 63.29%\n",
      "Epoch [535/2500], Train Loss: 0.8827, Train Accuracy: 60.17%, Test Loss: 0.8940, Test Accuracy: 65.82%\n",
      "Epoch [536/2500], Train Loss: 0.8875, Train Accuracy: 62.59%, Test Loss: 0.9121, Test Accuracy: 62.03%\n",
      "Epoch [537/2500], Train Loss: 0.8867, Train Accuracy: 59.17%, Test Loss: 0.9266, Test Accuracy: 59.49%\n",
      "Epoch [538/2500], Train Loss: 0.8900, Train Accuracy: 61.02%, Test Loss: 0.8963, Test Accuracy: 63.29%\n",
      "Epoch [539/2500], Train Loss: 0.8958, Train Accuracy: 59.74%, Test Loss: 0.8918, Test Accuracy: 63.29%\n",
      "Epoch [540/2500], Train Loss: 0.8914, Train Accuracy: 60.88%, Test Loss: 0.9230, Test Accuracy: 62.03%\n",
      "Epoch [541/2500], Train Loss: 0.9048, Train Accuracy: 60.17%, Test Loss: 0.8994, Test Accuracy: 65.82%\n",
      "Epoch [542/2500], Train Loss: 0.8877, Train Accuracy: 61.74%, Test Loss: 0.9055, Test Accuracy: 64.56%\n",
      "Epoch [543/2500], Train Loss: 0.8950, Train Accuracy: 61.88%, Test Loss: 0.9129, Test Accuracy: 64.56%\n",
      "Epoch [544/2500], Train Loss: 0.8818, Train Accuracy: 61.59%, Test Loss: 0.9107, Test Accuracy: 62.03%\n",
      "Epoch [545/2500], Train Loss: 0.8875, Train Accuracy: 60.31%, Test Loss: 0.9167, Test Accuracy: 64.56%\n",
      "Epoch [546/2500], Train Loss: 0.8827, Train Accuracy: 60.03%, Test Loss: 0.9254, Test Accuracy: 62.03%\n",
      "Epoch [547/2500], Train Loss: 0.8942, Train Accuracy: 61.02%, Test Loss: 0.9190, Test Accuracy: 63.29%\n",
      "Epoch [548/2500], Train Loss: 0.8840, Train Accuracy: 61.74%, Test Loss: 0.9133, Test Accuracy: 64.56%\n",
      "Epoch [549/2500], Train Loss: 0.8776, Train Accuracy: 62.30%, Test Loss: 0.9081, Test Accuracy: 62.03%\n",
      "Epoch [550/2500], Train Loss: 0.9067, Train Accuracy: 59.32%, Test Loss: 0.9134, Test Accuracy: 63.29%\n",
      "Epoch [551/2500], Train Loss: 0.8878, Train Accuracy: 61.45%, Test Loss: 0.9148, Test Accuracy: 63.29%\n",
      "Epoch [552/2500], Train Loss: 0.9040, Train Accuracy: 59.74%, Test Loss: 0.9306, Test Accuracy: 63.29%\n",
      "Epoch [553/2500], Train Loss: 0.8964, Train Accuracy: 59.46%, Test Loss: 0.9359, Test Accuracy: 62.03%\n",
      "Epoch [554/2500], Train Loss: 0.8879, Train Accuracy: 61.31%, Test Loss: 0.9360, Test Accuracy: 62.03%\n",
      "Epoch [555/2500], Train Loss: 0.8938, Train Accuracy: 59.89%, Test Loss: 0.9041, Test Accuracy: 63.29%\n",
      "Epoch [556/2500], Train Loss: 0.8997, Train Accuracy: 60.31%, Test Loss: 0.9078, Test Accuracy: 64.56%\n",
      "Epoch [557/2500], Train Loss: 0.8919, Train Accuracy: 60.31%, Test Loss: 0.9062, Test Accuracy: 63.29%\n",
      "Epoch [558/2500], Train Loss: 0.8770, Train Accuracy: 61.45%, Test Loss: 0.9103, Test Accuracy: 62.03%\n",
      "Epoch [559/2500], Train Loss: 0.8644, Train Accuracy: 61.31%, Test Loss: 0.9367, Test Accuracy: 62.03%\n",
      "Epoch [560/2500], Train Loss: 0.8802, Train Accuracy: 60.17%, Test Loss: 0.9017, Test Accuracy: 65.82%\n",
      "Epoch [561/2500], Train Loss: 0.8826, Train Accuracy: 60.31%, Test Loss: 0.9215, Test Accuracy: 65.82%\n",
      "Epoch [562/2500], Train Loss: 0.8662, Train Accuracy: 62.87%, Test Loss: 0.9352, Test Accuracy: 63.29%\n",
      "Epoch [563/2500], Train Loss: 0.8774, Train Accuracy: 61.17%, Test Loss: 0.9276, Test Accuracy: 62.03%\n",
      "Epoch [564/2500], Train Loss: 0.9033, Train Accuracy: 61.31%, Test Loss: 0.9165, Test Accuracy: 64.56%\n",
      "Epoch [565/2500], Train Loss: 0.9024, Train Accuracy: 61.17%, Test Loss: 0.9086, Test Accuracy: 64.56%\n",
      "Epoch [566/2500], Train Loss: 0.8801, Train Accuracy: 62.45%, Test Loss: 0.9095, Test Accuracy: 63.29%\n",
      "Epoch [567/2500], Train Loss: 0.8819, Train Accuracy: 61.59%, Test Loss: 0.8977, Test Accuracy: 65.82%\n",
      "Epoch [568/2500], Train Loss: 0.8911, Train Accuracy: 61.17%, Test Loss: 0.9262, Test Accuracy: 63.29%\n",
      "Epoch [569/2500], Train Loss: 0.8684, Train Accuracy: 62.59%, Test Loss: 0.9071, Test Accuracy: 65.82%\n",
      "Epoch [570/2500], Train Loss: 0.8662, Train Accuracy: 61.88%, Test Loss: 0.9185, Test Accuracy: 64.56%\n",
      "Epoch [571/2500], Train Loss: 0.8583, Train Accuracy: 59.74%, Test Loss: 0.9207, Test Accuracy: 62.03%\n",
      "Epoch [572/2500], Train Loss: 0.8655, Train Accuracy: 64.44%, Test Loss: 0.8976, Test Accuracy: 64.56%\n",
      "Epoch [573/2500], Train Loss: 0.8851, Train Accuracy: 62.16%, Test Loss: 0.9208, Test Accuracy: 62.03%\n",
      "Epoch [574/2500], Train Loss: 0.8780, Train Accuracy: 61.45%, Test Loss: 0.9129, Test Accuracy: 63.29%\n",
      "Epoch [575/2500], Train Loss: 0.8809, Train Accuracy: 59.32%, Test Loss: 0.9312, Test Accuracy: 62.03%\n",
      "Epoch [576/2500], Train Loss: 0.8789, Train Accuracy: 62.02%, Test Loss: 0.9075, Test Accuracy: 63.29%\n",
      "Epoch [577/2500], Train Loss: 0.8745, Train Accuracy: 60.74%, Test Loss: 0.9334, Test Accuracy: 63.29%\n",
      "Epoch [578/2500], Train Loss: 0.8817, Train Accuracy: 61.31%, Test Loss: 0.9018, Test Accuracy: 63.29%\n",
      "Epoch [579/2500], Train Loss: 0.8832, Train Accuracy: 61.17%, Test Loss: 0.9063, Test Accuracy: 64.56%\n",
      "Epoch [580/2500], Train Loss: 0.8804, Train Accuracy: 60.31%, Test Loss: 0.9038, Test Accuracy: 64.56%\n",
      "Epoch [581/2500], Train Loss: 0.8915, Train Accuracy: 60.74%, Test Loss: 0.9132, Test Accuracy: 62.03%\n",
      "Epoch [582/2500], Train Loss: 0.8877, Train Accuracy: 62.45%, Test Loss: 0.9246, Test Accuracy: 63.29%\n",
      "Epoch [583/2500], Train Loss: 0.8733, Train Accuracy: 62.87%, Test Loss: 0.9144, Test Accuracy: 63.29%\n",
      "Epoch [584/2500], Train Loss: 0.8796, Train Accuracy: 60.88%, Test Loss: 0.9162, Test Accuracy: 63.29%\n",
      "Epoch [585/2500], Train Loss: 0.8864, Train Accuracy: 59.46%, Test Loss: 0.9016, Test Accuracy: 63.29%\n",
      "Epoch [586/2500], Train Loss: 0.8879, Train Accuracy: 61.31%, Test Loss: 0.9034, Test Accuracy: 62.03%\n",
      "Epoch [587/2500], Train Loss: 0.8808, Train Accuracy: 60.46%, Test Loss: 0.9281, Test Accuracy: 63.29%\n",
      "Epoch [588/2500], Train Loss: 0.8947, Train Accuracy: 61.02%, Test Loss: 0.8969, Test Accuracy: 64.56%\n",
      "Epoch [589/2500], Train Loss: 0.8702, Train Accuracy: 60.88%, Test Loss: 0.9017, Test Accuracy: 64.56%\n",
      "Epoch [590/2500], Train Loss: 0.8688, Train Accuracy: 61.02%, Test Loss: 0.9058, Test Accuracy: 62.03%\n",
      "Epoch [591/2500], Train Loss: 0.8562, Train Accuracy: 61.88%, Test Loss: 0.9080, Test Accuracy: 65.82%\n",
      "Epoch [592/2500], Train Loss: 0.8813, Train Accuracy: 61.02%, Test Loss: 0.9092, Test Accuracy: 63.29%\n",
      "Epoch [593/2500], Train Loss: 0.8823, Train Accuracy: 61.59%, Test Loss: 0.9103, Test Accuracy: 62.03%\n",
      "Epoch [594/2500], Train Loss: 0.8765, Train Accuracy: 61.31%, Test Loss: 0.9151, Test Accuracy: 63.29%\n",
      "Epoch [595/2500], Train Loss: 0.8766, Train Accuracy: 62.02%, Test Loss: 0.9033, Test Accuracy: 65.82%\n",
      "Epoch [596/2500], Train Loss: 0.8791, Train Accuracy: 62.02%, Test Loss: 0.9102, Test Accuracy: 63.29%\n",
      "Epoch [597/2500], Train Loss: 0.8553, Train Accuracy: 62.45%, Test Loss: 0.9176, Test Accuracy: 63.29%\n",
      "Epoch [598/2500], Train Loss: 0.8648, Train Accuracy: 62.02%, Test Loss: 0.9275, Test Accuracy: 60.76%\n",
      "Epoch [599/2500], Train Loss: 0.8913, Train Accuracy: 60.60%, Test Loss: 0.9067, Test Accuracy: 65.82%\n",
      "Epoch [600/2500], Train Loss: 0.8746, Train Accuracy: 62.30%, Test Loss: 0.9007, Test Accuracy: 65.82%\n",
      "Epoch [601/2500], Train Loss: 0.8721, Train Accuracy: 62.87%, Test Loss: 0.9312, Test Accuracy: 60.76%\n",
      "Epoch [602/2500], Train Loss: 0.9003, Train Accuracy: 60.60%, Test Loss: 0.9037, Test Accuracy: 64.56%\n",
      "Epoch [603/2500], Train Loss: 0.8884, Train Accuracy: 61.45%, Test Loss: 0.9074, Test Accuracy: 64.56%\n",
      "Epoch [604/2500], Train Loss: 0.8516, Train Accuracy: 61.59%, Test Loss: 0.9174, Test Accuracy: 64.56%\n",
      "Epoch [605/2500], Train Loss: 0.8749, Train Accuracy: 61.88%, Test Loss: 0.9086, Test Accuracy: 64.56%\n",
      "Epoch [606/2500], Train Loss: 0.8661, Train Accuracy: 61.88%, Test Loss: 0.9042, Test Accuracy: 64.56%\n",
      "Epoch [607/2500], Train Loss: 0.8801, Train Accuracy: 62.16%, Test Loss: 0.8993, Test Accuracy: 65.82%\n",
      "Epoch [608/2500], Train Loss: 0.8565, Train Accuracy: 63.73%, Test Loss: 0.8829, Test Accuracy: 67.09%\n",
      "Epoch [609/2500], Train Loss: 0.8660, Train Accuracy: 63.02%, Test Loss: 0.9083, Test Accuracy: 64.56%\n",
      "Epoch [610/2500], Train Loss: 0.8608, Train Accuracy: 63.16%, Test Loss: 0.9004, Test Accuracy: 62.03%\n",
      "Epoch [611/2500], Train Loss: 0.8610, Train Accuracy: 62.02%, Test Loss: 0.8899, Test Accuracy: 67.09%\n",
      "Epoch [612/2500], Train Loss: 0.8768, Train Accuracy: 61.02%, Test Loss: 0.8968, Test Accuracy: 64.56%\n",
      "Epoch [613/2500], Train Loss: 0.8687, Train Accuracy: 63.16%, Test Loss: 0.9071, Test Accuracy: 64.56%\n",
      "Epoch [614/2500], Train Loss: 0.8613, Train Accuracy: 62.16%, Test Loss: 0.9032, Test Accuracy: 64.56%\n",
      "Epoch [615/2500], Train Loss: 0.8288, Train Accuracy: 63.30%, Test Loss: 0.9061, Test Accuracy: 63.29%\n",
      "Epoch [616/2500], Train Loss: 0.8719, Train Accuracy: 62.16%, Test Loss: 0.9039, Test Accuracy: 62.03%\n",
      "Epoch [617/2500], Train Loss: 0.8634, Train Accuracy: 61.02%, Test Loss: 0.9204, Test Accuracy: 62.03%\n",
      "Epoch [618/2500], Train Loss: 0.8775, Train Accuracy: 62.73%, Test Loss: 0.9227, Test Accuracy: 62.03%\n",
      "Epoch [619/2500], Train Loss: 0.8560, Train Accuracy: 61.59%, Test Loss: 0.8978, Test Accuracy: 65.82%\n",
      "Epoch [620/2500], Train Loss: 0.8811, Train Accuracy: 61.59%, Test Loss: 0.9070, Test Accuracy: 62.03%\n",
      "Epoch [621/2500], Train Loss: 0.8706, Train Accuracy: 60.74%, Test Loss: 0.8948, Test Accuracy: 64.56%\n",
      "Epoch [622/2500], Train Loss: 0.8656, Train Accuracy: 62.16%, Test Loss: 0.9202, Test Accuracy: 62.03%\n",
      "Epoch [623/2500], Train Loss: 0.8676, Train Accuracy: 62.45%, Test Loss: 0.9109, Test Accuracy: 63.29%\n",
      "Epoch [624/2500], Train Loss: 0.8419, Train Accuracy: 65.86%, Test Loss: 0.9009, Test Accuracy: 62.03%\n",
      "Epoch [625/2500], Train Loss: 0.8601, Train Accuracy: 62.02%, Test Loss: 0.9066, Test Accuracy: 64.56%\n",
      "Epoch [626/2500], Train Loss: 0.8548, Train Accuracy: 63.44%, Test Loss: 0.9100, Test Accuracy: 60.76%\n",
      "Epoch [627/2500], Train Loss: 0.8776, Train Accuracy: 61.02%, Test Loss: 0.9357, Test Accuracy: 60.76%\n",
      "Epoch [628/2500], Train Loss: 0.8530, Train Accuracy: 64.44%, Test Loss: 0.9083, Test Accuracy: 63.29%\n",
      "Epoch [629/2500], Train Loss: 0.8711, Train Accuracy: 61.59%, Test Loss: 0.9136, Test Accuracy: 63.29%\n",
      "Epoch [630/2500], Train Loss: 0.8657, Train Accuracy: 61.45%, Test Loss: 0.9028, Test Accuracy: 63.29%\n",
      "Epoch [631/2500], Train Loss: 0.8467, Train Accuracy: 63.44%, Test Loss: 0.9051, Test Accuracy: 63.29%\n",
      "Epoch [632/2500], Train Loss: 0.8720, Train Accuracy: 60.46%, Test Loss: 0.8966, Test Accuracy: 65.82%\n",
      "Epoch [633/2500], Train Loss: 0.8459, Train Accuracy: 63.16%, Test Loss: 0.9195, Test Accuracy: 60.76%\n",
      "Epoch [634/2500], Train Loss: 0.8488, Train Accuracy: 64.58%, Test Loss: 0.8944, Test Accuracy: 64.56%\n",
      "Epoch [635/2500], Train Loss: 0.8803, Train Accuracy: 61.02%, Test Loss: 0.8922, Test Accuracy: 67.09%\n",
      "Epoch [636/2500], Train Loss: 0.8821, Train Accuracy: 63.30%, Test Loss: 0.9040, Test Accuracy: 63.29%\n",
      "Epoch [637/2500], Train Loss: 0.8700, Train Accuracy: 63.16%, Test Loss: 0.8865, Test Accuracy: 64.56%\n",
      "Epoch [638/2500], Train Loss: 0.8803, Train Accuracy: 61.17%, Test Loss: 0.9092, Test Accuracy: 63.29%\n",
      "Epoch [639/2500], Train Loss: 0.8770, Train Accuracy: 60.60%, Test Loss: 0.9071, Test Accuracy: 64.56%\n",
      "Epoch [640/2500], Train Loss: 0.8909, Train Accuracy: 63.73%, Test Loss: 0.9157, Test Accuracy: 59.49%\n",
      "Epoch [641/2500], Train Loss: 0.8534, Train Accuracy: 62.30%, Test Loss: 0.8933, Test Accuracy: 65.82%\n",
      "Epoch [642/2500], Train Loss: 0.8724, Train Accuracy: 63.58%, Test Loss: 0.8843, Test Accuracy: 67.09%\n",
      "Epoch [643/2500], Train Loss: 0.8351, Train Accuracy: 64.44%, Test Loss: 0.8932, Test Accuracy: 63.29%\n",
      "Epoch [644/2500], Train Loss: 0.8642, Train Accuracy: 61.88%, Test Loss: 0.9083, Test Accuracy: 63.29%\n",
      "Epoch [645/2500], Train Loss: 0.8552, Train Accuracy: 61.02%, Test Loss: 0.8928, Test Accuracy: 65.82%\n",
      "Epoch [646/2500], Train Loss: 0.8713, Train Accuracy: 61.31%, Test Loss: 0.9046, Test Accuracy: 64.56%\n",
      "Epoch [647/2500], Train Loss: 0.8610, Train Accuracy: 63.16%, Test Loss: 0.9211, Test Accuracy: 62.03%\n",
      "Epoch [648/2500], Train Loss: 0.8630, Train Accuracy: 61.88%, Test Loss: 0.9356, Test Accuracy: 62.03%\n",
      "Epoch [649/2500], Train Loss: 0.8403, Train Accuracy: 62.02%, Test Loss: 0.9011, Test Accuracy: 64.56%\n",
      "Epoch [650/2500], Train Loss: 0.8657, Train Accuracy: 60.74%, Test Loss: 0.9022, Test Accuracy: 67.09%\n",
      "Epoch [651/2500], Train Loss: 0.8725, Train Accuracy: 63.44%, Test Loss: 0.8995, Test Accuracy: 63.29%\n",
      "Epoch [652/2500], Train Loss: 0.8671, Train Accuracy: 62.30%, Test Loss: 0.9308, Test Accuracy: 62.03%\n",
      "Epoch [653/2500], Train Loss: 0.8660, Train Accuracy: 61.74%, Test Loss: 0.9108, Test Accuracy: 60.76%\n",
      "Epoch [654/2500], Train Loss: 0.8557, Train Accuracy: 63.58%, Test Loss: 0.8854, Test Accuracy: 65.82%\n",
      "Epoch [655/2500], Train Loss: 0.8769, Train Accuracy: 61.74%, Test Loss: 0.8979, Test Accuracy: 64.56%\n",
      "Epoch [656/2500], Train Loss: 0.8576, Train Accuracy: 64.44%, Test Loss: 0.9059, Test Accuracy: 64.56%\n",
      "Epoch [657/2500], Train Loss: 0.8609, Train Accuracy: 62.45%, Test Loss: 0.9058, Test Accuracy: 64.56%\n",
      "Epoch [658/2500], Train Loss: 0.8592, Train Accuracy: 63.30%, Test Loss: 0.8975, Test Accuracy: 67.09%\n",
      "Epoch [659/2500], Train Loss: 0.8560, Train Accuracy: 60.88%, Test Loss: 0.9074, Test Accuracy: 64.56%\n",
      "Epoch [660/2500], Train Loss: 0.8672, Train Accuracy: 61.45%, Test Loss: 0.9043, Test Accuracy: 65.82%\n",
      "Epoch [661/2500], Train Loss: 0.8777, Train Accuracy: 62.59%, Test Loss: 0.9003, Test Accuracy: 65.82%\n",
      "Epoch [662/2500], Train Loss: 0.8570, Train Accuracy: 63.16%, Test Loss: 0.9453, Test Accuracy: 60.76%\n",
      "Epoch [663/2500], Train Loss: 0.8528, Train Accuracy: 62.16%, Test Loss: 0.8894, Test Accuracy: 67.09%\n",
      "Epoch [664/2500], Train Loss: 0.8650, Train Accuracy: 61.02%, Test Loss: 0.9131, Test Accuracy: 63.29%\n",
      "Epoch [665/2500], Train Loss: 0.8713, Train Accuracy: 61.59%, Test Loss: 0.8995, Test Accuracy: 65.82%\n",
      "Epoch [666/2500], Train Loss: 0.8375, Train Accuracy: 67.43%, Test Loss: 0.8939, Test Accuracy: 65.82%\n",
      "Epoch [667/2500], Train Loss: 0.8610, Train Accuracy: 62.87%, Test Loss: 0.9444, Test Accuracy: 62.03%\n",
      "Epoch [668/2500], Train Loss: 0.8706, Train Accuracy: 61.88%, Test Loss: 0.9095, Test Accuracy: 63.29%\n",
      "Epoch [669/2500], Train Loss: 0.8711, Train Accuracy: 61.31%, Test Loss: 0.8973, Test Accuracy: 65.82%\n",
      "Epoch [670/2500], Train Loss: 0.8543, Train Accuracy: 61.02%, Test Loss: 0.8872, Test Accuracy: 65.82%\n",
      "Epoch [671/2500], Train Loss: 0.8534, Train Accuracy: 62.45%, Test Loss: 0.8934, Test Accuracy: 63.29%\n",
      "Epoch [672/2500], Train Loss: 0.8315, Train Accuracy: 62.30%, Test Loss: 0.8979, Test Accuracy: 64.56%\n",
      "Epoch [673/2500], Train Loss: 0.8394, Train Accuracy: 65.01%, Test Loss: 0.9039, Test Accuracy: 64.56%\n",
      "Epoch [674/2500], Train Loss: 0.8268, Train Accuracy: 64.15%, Test Loss: 0.8897, Test Accuracy: 67.09%\n",
      "Epoch [675/2500], Train Loss: 0.8482, Train Accuracy: 62.59%, Test Loss: 0.8888, Test Accuracy: 65.82%\n",
      "Epoch [676/2500], Train Loss: 0.8485, Train Accuracy: 64.01%, Test Loss: 0.8949, Test Accuracy: 64.56%\n",
      "Epoch [677/2500], Train Loss: 0.8513, Train Accuracy: 63.58%, Test Loss: 0.8980, Test Accuracy: 64.56%\n",
      "Epoch [678/2500], Train Loss: 0.8467, Train Accuracy: 63.16%, Test Loss: 0.9102, Test Accuracy: 63.29%\n",
      "Epoch [679/2500], Train Loss: 0.8329, Train Accuracy: 63.30%, Test Loss: 0.8868, Test Accuracy: 65.82%\n",
      "Epoch [680/2500], Train Loss: 0.8522, Train Accuracy: 62.16%, Test Loss: 0.9062, Test Accuracy: 63.29%\n",
      "Epoch [681/2500], Train Loss: 0.8344, Train Accuracy: 65.15%, Test Loss: 0.9096, Test Accuracy: 63.29%\n",
      "Epoch [682/2500], Train Loss: 0.8481, Train Accuracy: 64.01%, Test Loss: 0.9118, Test Accuracy: 64.56%\n",
      "Epoch [683/2500], Train Loss: 0.8503, Train Accuracy: 61.45%, Test Loss: 0.9038, Test Accuracy: 64.56%\n",
      "Epoch [684/2500], Train Loss: 0.8424, Train Accuracy: 63.44%, Test Loss: 0.8911, Test Accuracy: 64.56%\n",
      "Epoch [685/2500], Train Loss: 0.8338, Train Accuracy: 63.58%, Test Loss: 0.9162, Test Accuracy: 63.29%\n",
      "Epoch [686/2500], Train Loss: 0.8191, Train Accuracy: 64.01%, Test Loss: 0.9386, Test Accuracy: 58.23%\n",
      "Epoch [687/2500], Train Loss: 0.8587, Train Accuracy: 63.44%, Test Loss: 0.8888, Test Accuracy: 65.82%\n",
      "Epoch [688/2500], Train Loss: 0.8626, Train Accuracy: 62.87%, Test Loss: 0.8992, Test Accuracy: 63.29%\n",
      "Epoch [689/2500], Train Loss: 0.8706, Train Accuracy: 61.31%, Test Loss: 0.9019, Test Accuracy: 62.03%\n",
      "Epoch [690/2500], Train Loss: 0.8361, Train Accuracy: 62.59%, Test Loss: 0.9125, Test Accuracy: 65.82%\n",
      "Epoch [691/2500], Train Loss: 0.8642, Train Accuracy: 61.45%, Test Loss: 0.9120, Test Accuracy: 64.56%\n",
      "Epoch [692/2500], Train Loss: 0.8346, Train Accuracy: 64.01%, Test Loss: 0.9132, Test Accuracy: 63.29%\n",
      "Epoch [693/2500], Train Loss: 0.8658, Train Accuracy: 61.17%, Test Loss: 0.8848, Test Accuracy: 67.09%\n",
      "Epoch [694/2500], Train Loss: 0.8486, Train Accuracy: 63.58%, Test Loss: 0.9094, Test Accuracy: 63.29%\n",
      "Epoch [695/2500], Train Loss: 0.8498, Train Accuracy: 62.30%, Test Loss: 0.9099, Test Accuracy: 62.03%\n",
      "Epoch [696/2500], Train Loss: 0.8565, Train Accuracy: 61.74%, Test Loss: 0.9171, Test Accuracy: 65.82%\n",
      "Epoch [697/2500], Train Loss: 0.8576, Train Accuracy: 61.88%, Test Loss: 0.8833, Test Accuracy: 67.09%\n",
      "Epoch [698/2500], Train Loss: 0.8561, Train Accuracy: 62.73%, Test Loss: 0.8925, Test Accuracy: 68.35%\n",
      "Epoch [699/2500], Train Loss: 0.8588, Train Accuracy: 62.87%, Test Loss: 0.8961, Test Accuracy: 65.82%\n",
      "Epoch [700/2500], Train Loss: 0.8453, Train Accuracy: 63.02%, Test Loss: 0.9024, Test Accuracy: 63.29%\n",
      "Epoch [701/2500], Train Loss: 0.8385, Train Accuracy: 62.45%, Test Loss: 0.9070, Test Accuracy: 63.29%\n",
      "Epoch [702/2500], Train Loss: 0.8633, Train Accuracy: 63.02%, Test Loss: 0.8959, Test Accuracy: 62.03%\n",
      "Epoch [703/2500], Train Loss: 0.8505, Train Accuracy: 61.31%, Test Loss: 0.8862, Test Accuracy: 67.09%\n",
      "Epoch [704/2500], Train Loss: 0.8397, Train Accuracy: 62.59%, Test Loss: 0.8947, Test Accuracy: 65.82%\n",
      "Epoch [705/2500], Train Loss: 0.8439, Train Accuracy: 62.87%, Test Loss: 0.8840, Test Accuracy: 64.56%\n",
      "Epoch [706/2500], Train Loss: 0.8528, Train Accuracy: 63.58%, Test Loss: 0.8988, Test Accuracy: 63.29%\n",
      "Epoch [707/2500], Train Loss: 0.8636, Train Accuracy: 63.02%, Test Loss: 0.9085, Test Accuracy: 64.56%\n",
      "Epoch [708/2500], Train Loss: 0.8745, Train Accuracy: 61.88%, Test Loss: 0.8935, Test Accuracy: 65.82%\n",
      "Epoch [709/2500], Train Loss: 0.8613, Train Accuracy: 61.17%, Test Loss: 0.9044, Test Accuracy: 63.29%\n",
      "Epoch [710/2500], Train Loss: 0.8401, Train Accuracy: 62.16%, Test Loss: 0.9178, Test Accuracy: 64.56%\n",
      "Epoch [711/2500], Train Loss: 0.8476, Train Accuracy: 63.73%, Test Loss: 0.9021, Test Accuracy: 64.56%\n",
      "Epoch [712/2500], Train Loss: 0.8450, Train Accuracy: 63.02%, Test Loss: 0.8919, Test Accuracy: 65.82%\n",
      "Epoch [713/2500], Train Loss: 0.8311, Train Accuracy: 64.15%, Test Loss: 0.9011, Test Accuracy: 64.56%\n",
      "Epoch [714/2500], Train Loss: 0.8532, Train Accuracy: 63.58%, Test Loss: 0.8901, Test Accuracy: 68.35%\n",
      "Epoch [715/2500], Train Loss: 0.8605, Train Accuracy: 61.59%, Test Loss: 0.9172, Test Accuracy: 64.56%\n",
      "Epoch [716/2500], Train Loss: 0.8410, Train Accuracy: 63.02%, Test Loss: 0.9016, Test Accuracy: 63.29%\n",
      "Epoch [717/2500], Train Loss: 0.8488, Train Accuracy: 62.45%, Test Loss: 0.8977, Test Accuracy: 68.35%\n",
      "Epoch [718/2500], Train Loss: 0.8634, Train Accuracy: 62.87%, Test Loss: 0.8958, Test Accuracy: 67.09%\n",
      "Epoch [719/2500], Train Loss: 0.8515, Train Accuracy: 62.87%, Test Loss: 0.9211, Test Accuracy: 62.03%\n",
      "Epoch [720/2500], Train Loss: 0.8501, Train Accuracy: 62.73%, Test Loss: 0.8813, Test Accuracy: 67.09%\n",
      "Epoch [721/2500], Train Loss: 0.8216, Train Accuracy: 63.87%, Test Loss: 0.8905, Test Accuracy: 65.82%\n",
      "Epoch [722/2500], Train Loss: 0.8311, Train Accuracy: 63.73%, Test Loss: 0.9072, Test Accuracy: 64.56%\n",
      "Epoch [723/2500], Train Loss: 0.8579, Train Accuracy: 62.87%, Test Loss: 0.8948, Test Accuracy: 63.29%\n",
      "Epoch [724/2500], Train Loss: 0.8146, Train Accuracy: 65.01%, Test Loss: 0.9096, Test Accuracy: 67.09%\n",
      "Epoch [725/2500], Train Loss: 0.8596, Train Accuracy: 63.30%, Test Loss: 0.8856, Test Accuracy: 63.29%\n",
      "Epoch [726/2500], Train Loss: 0.8802, Train Accuracy: 59.46%, Test Loss: 0.8815, Test Accuracy: 64.56%\n",
      "Epoch [727/2500], Train Loss: 0.8351, Train Accuracy: 61.31%, Test Loss: 0.8892, Test Accuracy: 64.56%\n",
      "Epoch [728/2500], Train Loss: 0.8458, Train Accuracy: 63.30%, Test Loss: 0.8727, Test Accuracy: 67.09%\n",
      "Epoch [729/2500], Train Loss: 0.8562, Train Accuracy: 61.74%, Test Loss: 0.8933, Test Accuracy: 63.29%\n",
      "Epoch [730/2500], Train Loss: 0.8288, Train Accuracy: 66.15%, Test Loss: 0.8802, Test Accuracy: 63.29%\n",
      "Epoch [731/2500], Train Loss: 0.8393, Train Accuracy: 63.87%, Test Loss: 0.8909, Test Accuracy: 67.09%\n",
      "Epoch [732/2500], Train Loss: 0.8442, Train Accuracy: 61.74%, Test Loss: 0.9005, Test Accuracy: 64.56%\n",
      "Epoch [733/2500], Train Loss: 0.8140, Train Accuracy: 64.86%, Test Loss: 0.8924, Test Accuracy: 64.56%\n",
      "Epoch [734/2500], Train Loss: 0.8350, Train Accuracy: 60.74%, Test Loss: 0.8902, Test Accuracy: 65.82%\n",
      "Epoch [735/2500], Train Loss: 0.8441, Train Accuracy: 62.87%, Test Loss: 0.8999, Test Accuracy: 64.56%\n",
      "Epoch [736/2500], Train Loss: 0.8597, Train Accuracy: 62.16%, Test Loss: 0.8896, Test Accuracy: 63.29%\n",
      "Epoch [737/2500], Train Loss: 0.8418, Train Accuracy: 64.30%, Test Loss: 0.8880, Test Accuracy: 67.09%\n",
      "Epoch [738/2500], Train Loss: 0.8375, Train Accuracy: 63.87%, Test Loss: 0.9077, Test Accuracy: 64.56%\n",
      "Epoch [739/2500], Train Loss: 0.8302, Train Accuracy: 63.44%, Test Loss: 0.8953, Test Accuracy: 64.56%\n",
      "Epoch [740/2500], Train Loss: 0.8594, Train Accuracy: 61.59%, Test Loss: 0.9231, Test Accuracy: 65.82%\n",
      "Epoch [741/2500], Train Loss: 0.8208, Train Accuracy: 65.86%, Test Loss: 0.9060, Test Accuracy: 67.09%\n",
      "Epoch [742/2500], Train Loss: 0.8473, Train Accuracy: 62.87%, Test Loss: 0.8935, Test Accuracy: 65.82%\n",
      "Epoch [743/2500], Train Loss: 0.8524, Train Accuracy: 61.88%, Test Loss: 0.8968, Test Accuracy: 65.82%\n",
      "Epoch [744/2500], Train Loss: 0.8329, Train Accuracy: 62.73%, Test Loss: 0.9181, Test Accuracy: 63.29%\n",
      "Epoch [745/2500], Train Loss: 0.8504, Train Accuracy: 63.30%, Test Loss: 0.9174, Test Accuracy: 62.03%\n",
      "Epoch [746/2500], Train Loss: 0.8566, Train Accuracy: 62.45%, Test Loss: 0.8860, Test Accuracy: 65.82%\n",
      "Epoch [747/2500], Train Loss: 0.8322, Train Accuracy: 62.02%, Test Loss: 0.8993, Test Accuracy: 62.03%\n",
      "Epoch [748/2500], Train Loss: 0.8186, Train Accuracy: 64.30%, Test Loss: 0.8988, Test Accuracy: 65.82%\n",
      "Epoch [749/2500], Train Loss: 0.8502, Train Accuracy: 62.59%, Test Loss: 0.8968, Test Accuracy: 67.09%\n",
      "Epoch [750/2500], Train Loss: 0.8492, Train Accuracy: 62.73%, Test Loss: 0.8954, Test Accuracy: 64.56%\n",
      "Epoch [751/2500], Train Loss: 0.8337, Train Accuracy: 62.30%, Test Loss: 0.9024, Test Accuracy: 65.82%\n",
      "Epoch [752/2500], Train Loss: 0.8325, Train Accuracy: 63.30%, Test Loss: 0.8886, Test Accuracy: 67.09%\n",
      "Epoch [753/2500], Train Loss: 0.8456, Train Accuracy: 61.31%, Test Loss: 0.9165, Test Accuracy: 65.82%\n",
      "Epoch [754/2500], Train Loss: 0.8764, Train Accuracy: 60.74%, Test Loss: 0.9001, Test Accuracy: 65.82%\n",
      "Epoch [755/2500], Train Loss: 0.8419, Train Accuracy: 65.72%, Test Loss: 0.9104, Test Accuracy: 64.56%\n",
      "Epoch [756/2500], Train Loss: 0.8314, Train Accuracy: 64.01%, Test Loss: 0.8925, Test Accuracy: 67.09%\n",
      "Epoch [757/2500], Train Loss: 0.8323, Train Accuracy: 63.30%, Test Loss: 0.8988, Test Accuracy: 63.29%\n",
      "Epoch [758/2500], Train Loss: 0.8620, Train Accuracy: 61.02%, Test Loss: 0.9073, Test Accuracy: 65.82%\n",
      "Epoch [759/2500], Train Loss: 0.8326, Train Accuracy: 63.73%, Test Loss: 0.8790, Test Accuracy: 67.09%\n",
      "Epoch [760/2500], Train Loss: 0.8377, Train Accuracy: 61.59%, Test Loss: 0.8839, Test Accuracy: 67.09%\n",
      "Epoch [761/2500], Train Loss: 0.8439, Train Accuracy: 63.58%, Test Loss: 0.8769, Test Accuracy: 67.09%\n",
      "Epoch [762/2500], Train Loss: 0.8154, Train Accuracy: 64.72%, Test Loss: 0.8997, Test Accuracy: 64.56%\n",
      "Epoch [763/2500], Train Loss: 0.8388, Train Accuracy: 61.74%, Test Loss: 0.8882, Test Accuracy: 67.09%\n",
      "Epoch [764/2500], Train Loss: 0.8298, Train Accuracy: 65.86%, Test Loss: 0.9101, Test Accuracy: 67.09%\n",
      "Epoch [765/2500], Train Loss: 0.8169, Train Accuracy: 64.01%, Test Loss: 0.9244, Test Accuracy: 63.29%\n",
      "Epoch [766/2500], Train Loss: 0.8708, Train Accuracy: 61.02%, Test Loss: 0.9019, Test Accuracy: 64.56%\n",
      "Epoch [767/2500], Train Loss: 0.8409, Train Accuracy: 62.87%, Test Loss: 0.8923, Test Accuracy: 67.09%\n",
      "Epoch [768/2500], Train Loss: 0.8217, Train Accuracy: 64.58%, Test Loss: 0.9221, Test Accuracy: 65.82%\n",
      "Epoch [769/2500], Train Loss: 0.8354, Train Accuracy: 63.30%, Test Loss: 0.8987, Test Accuracy: 64.56%\n",
      "Epoch [770/2500], Train Loss: 0.8199, Train Accuracy: 63.44%, Test Loss: 0.9087, Test Accuracy: 65.82%\n",
      "Epoch [771/2500], Train Loss: 0.8381, Train Accuracy: 62.59%, Test Loss: 0.9051, Test Accuracy: 64.56%\n",
      "Epoch [772/2500], Train Loss: 0.8548, Train Accuracy: 63.16%, Test Loss: 0.8900, Test Accuracy: 67.09%\n",
      "Epoch [773/2500], Train Loss: 0.8343, Train Accuracy: 62.87%, Test Loss: 0.9112, Test Accuracy: 64.56%\n",
      "Epoch [774/2500], Train Loss: 0.8126, Train Accuracy: 63.58%, Test Loss: 0.8795, Test Accuracy: 68.35%\n",
      "Epoch [775/2500], Train Loss: 0.8403, Train Accuracy: 62.02%, Test Loss: 0.8954, Test Accuracy: 63.29%\n",
      "Epoch [776/2500], Train Loss: 0.8457, Train Accuracy: 62.73%, Test Loss: 0.9267, Test Accuracy: 65.82%\n",
      "Epoch [777/2500], Train Loss: 0.8419, Train Accuracy: 62.45%, Test Loss: 0.8868, Test Accuracy: 67.09%\n",
      "Epoch [778/2500], Train Loss: 0.8315, Train Accuracy: 62.59%, Test Loss: 0.8871, Test Accuracy: 68.35%\n",
      "Epoch [779/2500], Train Loss: 0.8288, Train Accuracy: 63.44%, Test Loss: 0.8843, Test Accuracy: 67.09%\n",
      "Epoch [780/2500], Train Loss: 0.8389, Train Accuracy: 62.59%, Test Loss: 0.9146, Test Accuracy: 65.82%\n",
      "Epoch [781/2500], Train Loss: 0.8245, Train Accuracy: 62.87%, Test Loss: 0.8899, Test Accuracy: 64.56%\n",
      "Epoch [782/2500], Train Loss: 0.8171, Train Accuracy: 64.58%, Test Loss: 0.9036, Test Accuracy: 64.56%\n",
      "Epoch [783/2500], Train Loss: 0.8122, Train Accuracy: 64.72%, Test Loss: 0.8856, Test Accuracy: 68.35%\n",
      "Epoch [784/2500], Train Loss: 0.8265, Train Accuracy: 64.72%, Test Loss: 0.8933, Test Accuracy: 65.82%\n",
      "Epoch [785/2500], Train Loss: 0.8116, Train Accuracy: 63.87%, Test Loss: 0.8907, Test Accuracy: 68.35%\n",
      "Epoch [786/2500], Train Loss: 0.8273, Train Accuracy: 63.44%, Test Loss: 0.9013, Test Accuracy: 63.29%\n",
      "Epoch [787/2500], Train Loss: 0.8212, Train Accuracy: 63.16%, Test Loss: 0.8812, Test Accuracy: 65.82%\n",
      "Epoch [788/2500], Train Loss: 0.8266, Train Accuracy: 64.30%, Test Loss: 0.8874, Test Accuracy: 67.09%\n",
      "Epoch [789/2500], Train Loss: 0.8113, Train Accuracy: 63.44%, Test Loss: 0.8836, Test Accuracy: 64.56%\n",
      "Epoch [790/2500], Train Loss: 0.8234, Train Accuracy: 63.02%, Test Loss: 0.8952, Test Accuracy: 65.82%\n",
      "Epoch [791/2500], Train Loss: 0.8207, Train Accuracy: 65.29%, Test Loss: 0.8785, Test Accuracy: 68.35%\n",
      "Epoch [792/2500], Train Loss: 0.8131, Train Accuracy: 63.58%, Test Loss: 0.8975, Test Accuracy: 64.56%\n",
      "Epoch [793/2500], Train Loss: 0.8219, Train Accuracy: 63.73%, Test Loss: 0.9407, Test Accuracy: 65.82%\n",
      "Epoch [794/2500], Train Loss: 0.8287, Train Accuracy: 62.87%, Test Loss: 0.9053, Test Accuracy: 65.82%\n",
      "Epoch [795/2500], Train Loss: 0.8556, Train Accuracy: 63.87%, Test Loss: 0.9067, Test Accuracy: 64.56%\n",
      "Epoch [796/2500], Train Loss: 0.8308, Train Accuracy: 64.58%, Test Loss: 0.9144, Test Accuracy: 65.82%\n",
      "Epoch [797/2500], Train Loss: 0.8236, Train Accuracy: 64.15%, Test Loss: 0.8922, Test Accuracy: 64.56%\n",
      "Epoch [798/2500], Train Loss: 0.8139, Train Accuracy: 65.58%, Test Loss: 0.8929, Test Accuracy: 67.09%\n",
      "Epoch [799/2500], Train Loss: 0.8255, Train Accuracy: 65.15%, Test Loss: 0.9096, Test Accuracy: 67.09%\n",
      "Epoch [800/2500], Train Loss: 0.8099, Train Accuracy: 64.72%, Test Loss: 0.8856, Test Accuracy: 65.82%\n",
      "Epoch [801/2500], Train Loss: 0.8525, Train Accuracy: 63.73%, Test Loss: 0.8810, Test Accuracy: 67.09%\n",
      "Epoch [802/2500], Train Loss: 0.8229, Train Accuracy: 63.16%, Test Loss: 0.8842, Test Accuracy: 67.09%\n",
      "Epoch [803/2500], Train Loss: 0.8148, Train Accuracy: 64.86%, Test Loss: 0.8859, Test Accuracy: 67.09%\n",
      "Epoch [804/2500], Train Loss: 0.8171, Train Accuracy: 66.15%, Test Loss: 0.8868, Test Accuracy: 67.09%\n",
      "Epoch [805/2500], Train Loss: 0.8044, Train Accuracy: 63.44%, Test Loss: 0.8918, Test Accuracy: 68.35%\n",
      "Epoch [806/2500], Train Loss: 0.8223, Train Accuracy: 64.15%, Test Loss: 0.8850, Test Accuracy: 68.35%\n",
      "Epoch [807/2500], Train Loss: 0.8272, Train Accuracy: 63.30%, Test Loss: 0.9023, Test Accuracy: 67.09%\n",
      "Epoch [808/2500], Train Loss: 0.8187, Train Accuracy: 61.88%, Test Loss: 0.8978, Test Accuracy: 64.56%\n",
      "Epoch [809/2500], Train Loss: 0.8114, Train Accuracy: 64.72%, Test Loss: 0.8957, Test Accuracy: 63.29%\n",
      "Epoch [810/2500], Train Loss: 0.8300, Train Accuracy: 65.72%, Test Loss: 0.8813, Test Accuracy: 65.82%\n",
      "Epoch [811/2500], Train Loss: 0.8303, Train Accuracy: 63.58%, Test Loss: 0.8739, Test Accuracy: 69.62%\n",
      "Epoch [812/2500], Train Loss: 0.8309, Train Accuracy: 63.02%, Test Loss: 0.8739, Test Accuracy: 69.62%\n",
      "Epoch [813/2500], Train Loss: 0.8291, Train Accuracy: 62.73%, Test Loss: 0.8845, Test Accuracy: 65.82%\n",
      "Epoch [814/2500], Train Loss: 0.8205, Train Accuracy: 63.87%, Test Loss: 0.9215, Test Accuracy: 65.82%\n",
      "Epoch [815/2500], Train Loss: 0.8453, Train Accuracy: 63.58%, Test Loss: 0.8815, Test Accuracy: 67.09%\n",
      "Epoch [816/2500], Train Loss: 0.8135, Train Accuracy: 65.43%, Test Loss: 0.8851, Test Accuracy: 67.09%\n",
      "Epoch [817/2500], Train Loss: 0.8196, Train Accuracy: 65.43%, Test Loss: 0.8882, Test Accuracy: 68.35%\n",
      "Epoch [818/2500], Train Loss: 0.8305, Train Accuracy: 63.44%, Test Loss: 0.8877, Test Accuracy: 68.35%\n",
      "Epoch [819/2500], Train Loss: 0.8120, Train Accuracy: 66.29%, Test Loss: 0.8960, Test Accuracy: 67.09%\n",
      "Epoch [820/2500], Train Loss: 0.8305, Train Accuracy: 66.43%, Test Loss: 0.8839, Test Accuracy: 64.56%\n",
      "Epoch [821/2500], Train Loss: 0.8362, Train Accuracy: 63.30%, Test Loss: 0.8789, Test Accuracy: 68.35%\n",
      "Epoch [822/2500], Train Loss: 0.8321, Train Accuracy: 63.87%, Test Loss: 0.8890, Test Accuracy: 65.82%\n",
      "Epoch [823/2500], Train Loss: 0.8202, Train Accuracy: 64.58%, Test Loss: 0.8760, Test Accuracy: 67.09%\n",
      "Epoch [824/2500], Train Loss: 0.8334, Train Accuracy: 63.87%, Test Loss: 0.8946, Test Accuracy: 65.82%\n",
      "Epoch [825/2500], Train Loss: 0.8376, Train Accuracy: 64.44%, Test Loss: 0.8973, Test Accuracy: 63.29%\n",
      "Epoch [826/2500], Train Loss: 0.8224, Train Accuracy: 64.86%, Test Loss: 0.9106, Test Accuracy: 65.82%\n",
      "Epoch [827/2500], Train Loss: 0.8222, Train Accuracy: 63.16%, Test Loss: 0.8783, Test Accuracy: 65.82%\n",
      "Epoch [828/2500], Train Loss: 0.8119, Train Accuracy: 65.29%, Test Loss: 0.8876, Test Accuracy: 68.35%\n",
      "Epoch [829/2500], Train Loss: 0.8131, Train Accuracy: 64.30%, Test Loss: 0.9005, Test Accuracy: 67.09%\n",
      "Epoch [830/2500], Train Loss: 0.8269, Train Accuracy: 65.15%, Test Loss: 0.8993, Test Accuracy: 67.09%\n",
      "Epoch [831/2500], Train Loss: 0.8175, Train Accuracy: 64.86%, Test Loss: 0.8833, Test Accuracy: 65.82%\n",
      "Epoch [832/2500], Train Loss: 0.8164, Train Accuracy: 64.72%, Test Loss: 0.8775, Test Accuracy: 67.09%\n",
      "Epoch [833/2500], Train Loss: 0.8133, Train Accuracy: 64.15%, Test Loss: 0.9108, Test Accuracy: 67.09%\n",
      "Epoch [834/2500], Train Loss: 0.8270, Train Accuracy: 63.58%, Test Loss: 0.8866, Test Accuracy: 65.82%\n",
      "Epoch [835/2500], Train Loss: 0.8274, Train Accuracy: 63.30%, Test Loss: 0.9000, Test Accuracy: 67.09%\n",
      "Epoch [836/2500], Train Loss: 0.8179, Train Accuracy: 65.58%, Test Loss: 0.8925, Test Accuracy: 65.82%\n",
      "Epoch [837/2500], Train Loss: 0.8336, Train Accuracy: 63.87%, Test Loss: 0.8767, Test Accuracy: 65.82%\n",
      "Epoch [838/2500], Train Loss: 0.8132, Train Accuracy: 63.87%, Test Loss: 0.8975, Test Accuracy: 67.09%\n",
      "Epoch [839/2500], Train Loss: 0.8213, Train Accuracy: 62.02%, Test Loss: 0.9022, Test Accuracy: 63.29%\n",
      "Epoch [840/2500], Train Loss: 0.8221, Train Accuracy: 64.86%, Test Loss: 0.8869, Test Accuracy: 67.09%\n",
      "Epoch [841/2500], Train Loss: 0.8155, Train Accuracy: 65.29%, Test Loss: 0.8832, Test Accuracy: 67.09%\n",
      "Epoch [842/2500], Train Loss: 0.8284, Train Accuracy: 62.73%, Test Loss: 0.8819, Test Accuracy: 68.35%\n",
      "Epoch [843/2500], Train Loss: 0.8077, Train Accuracy: 64.58%, Test Loss: 0.8856, Test Accuracy: 68.35%\n",
      "Epoch [844/2500], Train Loss: 0.8132, Train Accuracy: 65.72%, Test Loss: 0.8902, Test Accuracy: 68.35%\n",
      "Epoch [845/2500], Train Loss: 0.8328, Train Accuracy: 61.59%, Test Loss: 0.8698, Test Accuracy: 68.35%\n",
      "Epoch [846/2500], Train Loss: 0.8117, Train Accuracy: 63.02%, Test Loss: 0.8977, Test Accuracy: 67.09%\n",
      "Epoch [847/2500], Train Loss: 0.8211, Train Accuracy: 63.58%, Test Loss: 0.8945, Test Accuracy: 67.09%\n",
      "Epoch [848/2500], Train Loss: 0.8211, Train Accuracy: 63.02%, Test Loss: 0.8838, Test Accuracy: 68.35%\n",
      "Epoch [849/2500], Train Loss: 0.8252, Train Accuracy: 64.86%, Test Loss: 0.8624, Test Accuracy: 68.35%\n",
      "Epoch [850/2500], Train Loss: 0.8076, Train Accuracy: 65.15%, Test Loss: 0.8907, Test Accuracy: 67.09%\n",
      "Epoch [851/2500], Train Loss: 0.8278, Train Accuracy: 62.59%, Test Loss: 0.8757, Test Accuracy: 68.35%\n",
      "Epoch [852/2500], Train Loss: 0.8151, Train Accuracy: 64.30%, Test Loss: 0.8698, Test Accuracy: 69.62%\n",
      "Epoch [853/2500], Train Loss: 0.8189, Train Accuracy: 63.02%, Test Loss: 0.8721, Test Accuracy: 65.82%\n",
      "Epoch [854/2500], Train Loss: 0.8264, Train Accuracy: 64.15%, Test Loss: 0.8837, Test Accuracy: 68.35%\n",
      "Epoch [855/2500], Train Loss: 0.8204, Train Accuracy: 65.58%, Test Loss: 0.8718, Test Accuracy: 67.09%\n",
      "Epoch [856/2500], Train Loss: 0.7953, Train Accuracy: 66.00%, Test Loss: 0.8959, Test Accuracy: 67.09%\n",
      "Epoch [857/2500], Train Loss: 0.7959, Train Accuracy: 65.86%, Test Loss: 0.8871, Test Accuracy: 67.09%\n",
      "Epoch [858/2500], Train Loss: 0.8285, Train Accuracy: 63.73%, Test Loss: 0.8733, Test Accuracy: 67.09%\n",
      "Epoch [859/2500], Train Loss: 0.8257, Train Accuracy: 61.88%, Test Loss: 0.8720, Test Accuracy: 69.62%\n",
      "Epoch [860/2500], Train Loss: 0.8185, Train Accuracy: 65.01%, Test Loss: 0.8912, Test Accuracy: 65.82%\n",
      "Epoch [861/2500], Train Loss: 0.7785, Train Accuracy: 66.00%, Test Loss: 0.8745, Test Accuracy: 68.35%\n",
      "Epoch [862/2500], Train Loss: 0.8149, Train Accuracy: 63.58%, Test Loss: 0.8895, Test Accuracy: 67.09%\n",
      "Epoch [863/2500], Train Loss: 0.8121, Train Accuracy: 64.30%, Test Loss: 0.8881, Test Accuracy: 67.09%\n",
      "Epoch [864/2500], Train Loss: 0.8078, Train Accuracy: 65.72%, Test Loss: 0.8780, Test Accuracy: 68.35%\n",
      "Epoch [865/2500], Train Loss: 0.8223, Train Accuracy: 63.87%, Test Loss: 0.8836, Test Accuracy: 68.35%\n",
      "Epoch [866/2500], Train Loss: 0.8329, Train Accuracy: 62.30%, Test Loss: 0.8678, Test Accuracy: 67.09%\n",
      "Epoch [867/2500], Train Loss: 0.7957, Train Accuracy: 65.29%, Test Loss: 0.8704, Test Accuracy: 68.35%\n",
      "Epoch [868/2500], Train Loss: 0.8179, Train Accuracy: 64.44%, Test Loss: 0.8807, Test Accuracy: 64.56%\n",
      "Epoch [869/2500], Train Loss: 0.8012, Train Accuracy: 64.15%, Test Loss: 0.8741, Test Accuracy: 69.62%\n",
      "Epoch [870/2500], Train Loss: 0.8004, Train Accuracy: 65.01%, Test Loss: 0.8887, Test Accuracy: 65.82%\n",
      "Epoch [871/2500], Train Loss: 0.8143, Train Accuracy: 65.29%, Test Loss: 0.8957, Test Accuracy: 65.82%\n",
      "Epoch [872/2500], Train Loss: 0.8338, Train Accuracy: 64.58%, Test Loss: 0.9054, Test Accuracy: 67.09%\n",
      "Epoch [873/2500], Train Loss: 0.8155, Train Accuracy: 61.02%, Test Loss: 0.9028, Test Accuracy: 65.82%\n",
      "Epoch [874/2500], Train Loss: 0.8235, Train Accuracy: 63.30%, Test Loss: 0.8914, Test Accuracy: 67.09%\n",
      "Epoch [875/2500], Train Loss: 0.8268, Train Accuracy: 64.72%, Test Loss: 0.8800, Test Accuracy: 67.09%\n",
      "Epoch [876/2500], Train Loss: 0.7975, Train Accuracy: 65.58%, Test Loss: 0.9018, Test Accuracy: 67.09%\n",
      "Epoch [877/2500], Train Loss: 0.7976, Train Accuracy: 64.15%, Test Loss: 0.8839, Test Accuracy: 67.09%\n",
      "Epoch [878/2500], Train Loss: 0.8368, Train Accuracy: 64.01%, Test Loss: 0.8794, Test Accuracy: 65.82%\n",
      "Epoch [879/2500], Train Loss: 0.8134, Train Accuracy: 65.15%, Test Loss: 0.8865, Test Accuracy: 65.82%\n",
      "Epoch [880/2500], Train Loss: 0.8196, Train Accuracy: 63.58%, Test Loss: 0.8797, Test Accuracy: 64.56%\n",
      "Epoch [881/2500], Train Loss: 0.8335, Train Accuracy: 63.87%, Test Loss: 0.8761, Test Accuracy: 65.82%\n",
      "Epoch [882/2500], Train Loss: 0.7912, Train Accuracy: 65.15%, Test Loss: 0.8774, Test Accuracy: 67.09%\n",
      "Epoch [883/2500], Train Loss: 0.8236, Train Accuracy: 63.44%, Test Loss: 0.8928, Test Accuracy: 65.82%\n",
      "Epoch [884/2500], Train Loss: 0.8022, Train Accuracy: 63.73%, Test Loss: 0.8706, Test Accuracy: 65.82%\n",
      "Epoch [885/2500], Train Loss: 0.8201, Train Accuracy: 63.73%, Test Loss: 0.8856, Test Accuracy: 67.09%\n",
      "Epoch [886/2500], Train Loss: 0.8002, Train Accuracy: 66.15%, Test Loss: 0.8939, Test Accuracy: 67.09%\n",
      "Epoch [887/2500], Train Loss: 0.8016, Train Accuracy: 66.00%, Test Loss: 0.9070, Test Accuracy: 65.82%\n",
      "Epoch [888/2500], Train Loss: 0.7926, Train Accuracy: 65.43%, Test Loss: 0.9130, Test Accuracy: 67.09%\n",
      "Epoch [889/2500], Train Loss: 0.8046, Train Accuracy: 65.15%, Test Loss: 0.9027, Test Accuracy: 67.09%\n",
      "Epoch [890/2500], Train Loss: 0.8187, Train Accuracy: 63.30%, Test Loss: 0.8727, Test Accuracy: 68.35%\n",
      "Epoch [891/2500], Train Loss: 0.7889, Train Accuracy: 64.72%, Test Loss: 0.8750, Test Accuracy: 65.82%\n",
      "Epoch [892/2500], Train Loss: 0.8041, Train Accuracy: 64.44%, Test Loss: 0.8897, Test Accuracy: 67.09%\n",
      "Epoch [893/2500], Train Loss: 0.8064, Train Accuracy: 65.01%, Test Loss: 0.8971, Test Accuracy: 67.09%\n",
      "Epoch [894/2500], Train Loss: 0.8394, Train Accuracy: 63.16%, Test Loss: 0.8705, Test Accuracy: 67.09%\n",
      "Epoch [895/2500], Train Loss: 0.7898, Train Accuracy: 64.44%, Test Loss: 0.9114, Test Accuracy: 64.56%\n",
      "Epoch [896/2500], Train Loss: 0.8166, Train Accuracy: 65.43%, Test Loss: 0.8697, Test Accuracy: 68.35%\n",
      "Epoch [897/2500], Train Loss: 0.7938, Train Accuracy: 65.15%, Test Loss: 0.8751, Test Accuracy: 65.82%\n",
      "Epoch [898/2500], Train Loss: 0.8015, Train Accuracy: 64.58%, Test Loss: 0.8925, Test Accuracy: 67.09%\n",
      "Epoch [899/2500], Train Loss: 0.7757, Train Accuracy: 67.14%, Test Loss: 0.8694, Test Accuracy: 68.35%\n",
      "Epoch [900/2500], Train Loss: 0.7951, Train Accuracy: 67.99%, Test Loss: 0.8719, Test Accuracy: 68.35%\n",
      "Epoch [901/2500], Train Loss: 0.8029, Train Accuracy: 66.29%, Test Loss: 0.8675, Test Accuracy: 67.09%\n",
      "Epoch [902/2500], Train Loss: 0.8014, Train Accuracy: 65.43%, Test Loss: 0.8714, Test Accuracy: 67.09%\n",
      "Epoch [903/2500], Train Loss: 0.8152, Train Accuracy: 63.02%, Test Loss: 0.8954, Test Accuracy: 67.09%\n",
      "Epoch [904/2500], Train Loss: 0.8028, Train Accuracy: 63.87%, Test Loss: 0.8794, Test Accuracy: 67.09%\n",
      "Epoch [905/2500], Train Loss: 0.8150, Train Accuracy: 64.72%, Test Loss: 0.8750, Test Accuracy: 68.35%\n",
      "Epoch [906/2500], Train Loss: 0.7936, Train Accuracy: 63.30%, Test Loss: 0.8741, Test Accuracy: 68.35%\n",
      "Epoch [907/2500], Train Loss: 0.7952, Train Accuracy: 66.43%, Test Loss: 0.8800, Test Accuracy: 67.09%\n",
      "Epoch [908/2500], Train Loss: 0.8116, Train Accuracy: 64.44%, Test Loss: 0.8719, Test Accuracy: 68.35%\n",
      "Epoch [909/2500], Train Loss: 0.8055, Train Accuracy: 65.29%, Test Loss: 0.8719, Test Accuracy: 67.09%\n",
      "Epoch [910/2500], Train Loss: 0.8079, Train Accuracy: 64.44%, Test Loss: 0.8627, Test Accuracy: 67.09%\n",
      "Epoch [911/2500], Train Loss: 0.7950, Train Accuracy: 64.01%, Test Loss: 0.8760, Test Accuracy: 67.09%\n",
      "Epoch [912/2500], Train Loss: 0.8105, Train Accuracy: 63.73%, Test Loss: 0.9006, Test Accuracy: 67.09%\n",
      "Epoch [913/2500], Train Loss: 0.7851, Train Accuracy: 65.58%, Test Loss: 0.8874, Test Accuracy: 67.09%\n",
      "Epoch [914/2500], Train Loss: 0.8222, Train Accuracy: 64.72%, Test Loss: 0.8821, Test Accuracy: 65.82%\n",
      "Epoch [915/2500], Train Loss: 0.8181, Train Accuracy: 63.58%, Test Loss: 0.8804, Test Accuracy: 67.09%\n",
      "Epoch [916/2500], Train Loss: 0.8041, Train Accuracy: 65.43%, Test Loss: 0.8875, Test Accuracy: 67.09%\n",
      "Epoch [917/2500], Train Loss: 0.7943, Train Accuracy: 65.01%, Test Loss: 0.8851, Test Accuracy: 65.82%\n",
      "Epoch [918/2500], Train Loss: 0.7923, Train Accuracy: 63.16%, Test Loss: 0.8988, Test Accuracy: 67.09%\n",
      "Epoch [919/2500], Train Loss: 0.8129, Train Accuracy: 63.16%, Test Loss: 0.9194, Test Accuracy: 64.56%\n",
      "Epoch [920/2500], Train Loss: 0.8072, Train Accuracy: 65.01%, Test Loss: 0.8915, Test Accuracy: 67.09%\n",
      "Epoch [921/2500], Train Loss: 0.7884, Train Accuracy: 64.44%, Test Loss: 0.8831, Test Accuracy: 67.09%\n",
      "Epoch [922/2500], Train Loss: 0.8039, Train Accuracy: 65.01%, Test Loss: 0.8916, Test Accuracy: 67.09%\n",
      "Epoch [923/2500], Train Loss: 0.8046, Train Accuracy: 63.58%, Test Loss: 0.8739, Test Accuracy: 67.09%\n",
      "Epoch [924/2500], Train Loss: 0.8368, Train Accuracy: 63.30%, Test Loss: 0.8927, Test Accuracy: 67.09%\n",
      "Epoch [925/2500], Train Loss: 0.8067, Train Accuracy: 65.15%, Test Loss: 0.8993, Test Accuracy: 64.56%\n",
      "Epoch [926/2500], Train Loss: 0.7999, Train Accuracy: 65.86%, Test Loss: 0.8819, Test Accuracy: 68.35%\n",
      "Epoch [927/2500], Train Loss: 0.8038, Train Accuracy: 64.44%, Test Loss: 0.9041, Test Accuracy: 67.09%\n",
      "Epoch [928/2500], Train Loss: 0.8034, Train Accuracy: 66.57%, Test Loss: 0.9011, Test Accuracy: 65.82%\n",
      "Epoch [929/2500], Train Loss: 0.8075, Train Accuracy: 64.58%, Test Loss: 0.8836, Test Accuracy: 67.09%\n",
      "Epoch [930/2500], Train Loss: 0.8009, Train Accuracy: 63.87%, Test Loss: 0.8929, Test Accuracy: 65.82%\n",
      "Epoch [931/2500], Train Loss: 0.8062, Train Accuracy: 64.30%, Test Loss: 0.8837, Test Accuracy: 67.09%\n",
      "Epoch [932/2500], Train Loss: 0.7979, Train Accuracy: 64.58%, Test Loss: 0.8797, Test Accuracy: 67.09%\n",
      "Epoch [933/2500], Train Loss: 0.8114, Train Accuracy: 64.44%, Test Loss: 0.9016, Test Accuracy: 65.82%\n",
      "Epoch [934/2500], Train Loss: 0.8131, Train Accuracy: 61.59%, Test Loss: 0.9121, Test Accuracy: 64.56%\n",
      "Epoch [935/2500], Train Loss: 0.7871, Train Accuracy: 66.00%, Test Loss: 0.8838, Test Accuracy: 68.35%\n",
      "Epoch [936/2500], Train Loss: 0.7872, Train Accuracy: 66.29%, Test Loss: 0.8831, Test Accuracy: 67.09%\n",
      "Epoch [937/2500], Train Loss: 0.8031, Train Accuracy: 61.59%, Test Loss: 0.8851, Test Accuracy: 68.35%\n",
      "Epoch [938/2500], Train Loss: 0.8238, Train Accuracy: 61.88%, Test Loss: 0.8963, Test Accuracy: 65.82%\n",
      "Epoch [939/2500], Train Loss: 0.8226, Train Accuracy: 64.01%, Test Loss: 0.8760, Test Accuracy: 68.35%\n",
      "Epoch [940/2500], Train Loss: 0.7680, Train Accuracy: 67.43%, Test Loss: 0.9072, Test Accuracy: 65.82%\n",
      "Epoch [941/2500], Train Loss: 0.7990, Train Accuracy: 66.57%, Test Loss: 0.9130, Test Accuracy: 65.82%\n",
      "Epoch [942/2500], Train Loss: 0.7806, Train Accuracy: 67.99%, Test Loss: 0.9072, Test Accuracy: 65.82%\n",
      "Epoch [943/2500], Train Loss: 0.7956, Train Accuracy: 65.72%, Test Loss: 0.8725, Test Accuracy: 68.35%\n",
      "Epoch [944/2500], Train Loss: 0.8000, Train Accuracy: 63.58%, Test Loss: 0.8885, Test Accuracy: 68.35%\n",
      "Epoch [945/2500], Train Loss: 0.8095, Train Accuracy: 64.58%, Test Loss: 0.9062, Test Accuracy: 67.09%\n",
      "Epoch [946/2500], Train Loss: 0.7876, Train Accuracy: 64.15%, Test Loss: 0.8821, Test Accuracy: 68.35%\n",
      "Epoch [947/2500], Train Loss: 0.8043, Train Accuracy: 63.73%, Test Loss: 0.9269, Test Accuracy: 64.56%\n",
      "Epoch [948/2500], Train Loss: 0.7965, Train Accuracy: 65.29%, Test Loss: 0.8871, Test Accuracy: 65.82%\n",
      "Epoch [949/2500], Train Loss: 0.8028, Train Accuracy: 64.30%, Test Loss: 0.9040, Test Accuracy: 67.09%\n",
      "Epoch [950/2500], Train Loss: 0.7759, Train Accuracy: 66.57%, Test Loss: 0.8970, Test Accuracy: 67.09%\n",
      "Epoch [951/2500], Train Loss: 0.8229, Train Accuracy: 65.72%, Test Loss: 0.8922, Test Accuracy: 67.09%\n",
      "Epoch [952/2500], Train Loss: 0.7963, Train Accuracy: 64.44%, Test Loss: 0.8984, Test Accuracy: 65.82%\n",
      "Epoch [953/2500], Train Loss: 0.8072, Train Accuracy: 63.58%, Test Loss: 0.8724, Test Accuracy: 67.09%\n",
      "Epoch [954/2500], Train Loss: 0.7938, Train Accuracy: 64.72%, Test Loss: 0.8745, Test Accuracy: 67.09%\n",
      "Epoch [955/2500], Train Loss: 0.7848, Train Accuracy: 67.28%, Test Loss: 0.8951, Test Accuracy: 67.09%\n",
      "Epoch [956/2500], Train Loss: 0.7931, Train Accuracy: 65.86%, Test Loss: 0.8712, Test Accuracy: 67.09%\n",
      "Epoch [957/2500], Train Loss: 0.7987, Train Accuracy: 64.86%, Test Loss: 0.8951, Test Accuracy: 67.09%\n",
      "Epoch [958/2500], Train Loss: 0.7759, Train Accuracy: 66.29%, Test Loss: 0.8735, Test Accuracy: 67.09%\n",
      "Epoch [959/2500], Train Loss: 0.8078, Train Accuracy: 64.58%, Test Loss: 0.8934, Test Accuracy: 67.09%\n",
      "Epoch [960/2500], Train Loss: 0.7726, Train Accuracy: 64.58%, Test Loss: 0.8997, Test Accuracy: 67.09%\n",
      "Epoch [961/2500], Train Loss: 0.7856, Train Accuracy: 63.16%, Test Loss: 0.9162, Test Accuracy: 65.82%\n",
      "Epoch [962/2500], Train Loss: 0.7940, Train Accuracy: 64.86%, Test Loss: 0.9134, Test Accuracy: 65.82%\n",
      "Epoch [963/2500], Train Loss: 0.8212, Train Accuracy: 62.59%, Test Loss: 0.8715, Test Accuracy: 68.35%\n",
      "Epoch [964/2500], Train Loss: 0.8114, Train Accuracy: 65.29%, Test Loss: 0.8805, Test Accuracy: 65.82%\n",
      "Epoch [965/2500], Train Loss: 0.7937, Train Accuracy: 66.00%, Test Loss: 0.8927, Test Accuracy: 67.09%\n",
      "Epoch [966/2500], Train Loss: 0.7870, Train Accuracy: 67.00%, Test Loss: 0.8843, Test Accuracy: 67.09%\n",
      "Epoch [967/2500], Train Loss: 0.7722, Train Accuracy: 64.72%, Test Loss: 0.8849, Test Accuracy: 67.09%\n",
      "Epoch [968/2500], Train Loss: 0.8122, Train Accuracy: 63.73%, Test Loss: 0.8924, Test Accuracy: 67.09%\n",
      "Epoch [969/2500], Train Loss: 0.7838, Train Accuracy: 67.14%, Test Loss: 0.9344, Test Accuracy: 65.82%\n",
      "Epoch [970/2500], Train Loss: 0.7875, Train Accuracy: 65.15%, Test Loss: 0.8981, Test Accuracy: 67.09%\n",
      "Epoch [971/2500], Train Loss: 0.8094, Train Accuracy: 63.87%, Test Loss: 0.8710, Test Accuracy: 67.09%\n",
      "Epoch [972/2500], Train Loss: 0.7998, Train Accuracy: 64.30%, Test Loss: 0.8900, Test Accuracy: 67.09%\n",
      "Epoch [973/2500], Train Loss: 0.7690, Train Accuracy: 67.00%, Test Loss: 0.8745, Test Accuracy: 69.62%\n",
      "Epoch [974/2500], Train Loss: 0.8260, Train Accuracy: 63.16%, Test Loss: 0.8778, Test Accuracy: 67.09%\n",
      "Epoch [975/2500], Train Loss: 0.7889, Train Accuracy: 63.16%, Test Loss: 0.8688, Test Accuracy: 67.09%\n",
      "Epoch [976/2500], Train Loss: 0.7870, Train Accuracy: 66.86%, Test Loss: 0.8752, Test Accuracy: 67.09%\n",
      "Epoch [977/2500], Train Loss: 0.8000, Train Accuracy: 63.44%, Test Loss: 0.9136, Test Accuracy: 64.56%\n",
      "Epoch [978/2500], Train Loss: 0.8122, Train Accuracy: 63.44%, Test Loss: 0.9044, Test Accuracy: 65.82%\n",
      "Epoch [979/2500], Train Loss: 0.7850, Train Accuracy: 65.29%, Test Loss: 0.8845, Test Accuracy: 67.09%\n",
      "Epoch [980/2500], Train Loss: 0.8170, Train Accuracy: 63.73%, Test Loss: 0.9257, Test Accuracy: 65.82%\n",
      "Epoch [981/2500], Train Loss: 0.7981, Train Accuracy: 65.01%, Test Loss: 0.8865, Test Accuracy: 67.09%\n",
      "Epoch [982/2500], Train Loss: 0.8019, Train Accuracy: 66.00%, Test Loss: 0.8927, Test Accuracy: 67.09%\n",
      "Epoch [983/2500], Train Loss: 0.7739, Train Accuracy: 64.86%, Test Loss: 0.9300, Test Accuracy: 65.82%\n",
      "Epoch [984/2500], Train Loss: 0.8102, Train Accuracy: 65.29%, Test Loss: 0.8945, Test Accuracy: 67.09%\n",
      "Epoch [985/2500], Train Loss: 0.7944, Train Accuracy: 65.58%, Test Loss: 0.9105, Test Accuracy: 65.82%\n",
      "Epoch [986/2500], Train Loss: 0.7996, Train Accuracy: 65.29%, Test Loss: 0.8755, Test Accuracy: 68.35%\n",
      "Epoch [987/2500], Train Loss: 0.7816, Train Accuracy: 65.43%, Test Loss: 0.8821, Test Accuracy: 68.35%\n",
      "Epoch [988/2500], Train Loss: 0.7975, Train Accuracy: 64.86%, Test Loss: 0.9119, Test Accuracy: 65.82%\n",
      "Epoch [989/2500], Train Loss: 0.7918, Train Accuracy: 65.15%, Test Loss: 0.9073, Test Accuracy: 67.09%\n",
      "Epoch [990/2500], Train Loss: 0.7870, Train Accuracy: 64.15%, Test Loss: 0.8753, Test Accuracy: 67.09%\n",
      "Epoch [991/2500], Train Loss: 0.7830, Train Accuracy: 65.01%, Test Loss: 0.9008, Test Accuracy: 65.82%\n",
      "Epoch [992/2500], Train Loss: 0.7784, Train Accuracy: 66.43%, Test Loss: 0.8697, Test Accuracy: 69.62%\n",
      "Epoch [993/2500], Train Loss: 0.7695, Train Accuracy: 66.57%, Test Loss: 0.8808, Test Accuracy: 69.62%\n",
      "Epoch [994/2500], Train Loss: 0.7974, Train Accuracy: 66.15%, Test Loss: 0.8792, Test Accuracy: 69.62%\n",
      "Epoch [995/2500], Train Loss: 0.7949, Train Accuracy: 64.86%, Test Loss: 0.8854, Test Accuracy: 67.09%\n",
      "Epoch [996/2500], Train Loss: 0.7924, Train Accuracy: 66.00%, Test Loss: 0.8758, Test Accuracy: 68.35%\n",
      "Epoch [997/2500], Train Loss: 0.7944, Train Accuracy: 66.00%, Test Loss: 0.8837, Test Accuracy: 68.35%\n",
      "Epoch [998/2500], Train Loss: 0.7837, Train Accuracy: 66.43%, Test Loss: 0.8767, Test Accuracy: 65.82%\n",
      "Epoch [999/2500], Train Loss: 0.7551, Train Accuracy: 67.57%, Test Loss: 0.8932, Test Accuracy: 67.09%\n",
      "Epoch [1000/2500], Train Loss: 0.7956, Train Accuracy: 63.02%, Test Loss: 0.8610, Test Accuracy: 68.35%\n",
      "Epoch [1001/2500], Train Loss: 0.7858, Train Accuracy: 67.14%, Test Loss: 0.8720, Test Accuracy: 68.35%\n",
      "Epoch [1002/2500], Train Loss: 0.7576, Train Accuracy: 66.86%, Test Loss: 0.8891, Test Accuracy: 67.09%\n",
      "Epoch [1003/2500], Train Loss: 0.7953, Train Accuracy: 63.73%, Test Loss: 0.8937, Test Accuracy: 68.35%\n",
      "Epoch [1004/2500], Train Loss: 0.7631, Train Accuracy: 67.43%, Test Loss: 0.9009, Test Accuracy: 67.09%\n",
      "Epoch [1005/2500], Train Loss: 0.7677, Train Accuracy: 66.43%, Test Loss: 0.9012, Test Accuracy: 67.09%\n",
      "Epoch [1006/2500], Train Loss: 0.7668, Train Accuracy: 66.15%, Test Loss: 0.9202, Test Accuracy: 65.82%\n",
      "Epoch [1007/2500], Train Loss: 0.8168, Train Accuracy: 65.29%, Test Loss: 0.8769, Test Accuracy: 68.35%\n",
      "Epoch [1008/2500], Train Loss: 0.7760, Train Accuracy: 65.86%, Test Loss: 0.9271, Test Accuracy: 65.82%\n",
      "Epoch [1009/2500], Train Loss: 0.8098, Train Accuracy: 65.01%, Test Loss: 0.8941, Test Accuracy: 67.09%\n",
      "Epoch [1010/2500], Train Loss: 0.7915, Train Accuracy: 64.44%, Test Loss: 0.8930, Test Accuracy: 67.09%\n",
      "Epoch [1011/2500], Train Loss: 0.7920, Train Accuracy: 64.44%, Test Loss: 0.8770, Test Accuracy: 67.09%\n",
      "Epoch [1012/2500], Train Loss: 0.8050, Train Accuracy: 65.15%, Test Loss: 0.9193, Test Accuracy: 65.82%\n",
      "Epoch [1013/2500], Train Loss: 0.7786, Train Accuracy: 65.72%, Test Loss: 0.9029, Test Accuracy: 67.09%\n",
      "Epoch [1014/2500], Train Loss: 0.7720, Train Accuracy: 66.29%, Test Loss: 0.8831, Test Accuracy: 67.09%\n",
      "Epoch [1015/2500], Train Loss: 0.7712, Train Accuracy: 66.57%, Test Loss: 0.9141, Test Accuracy: 67.09%\n",
      "Epoch [1016/2500], Train Loss: 0.7859, Train Accuracy: 65.72%, Test Loss: 0.9379, Test Accuracy: 64.56%\n",
      "Epoch [1017/2500], Train Loss: 0.7752, Train Accuracy: 64.44%, Test Loss: 0.9105, Test Accuracy: 65.82%\n",
      "Epoch [1018/2500], Train Loss: 0.7656, Train Accuracy: 67.57%, Test Loss: 0.8953, Test Accuracy: 67.09%\n",
      "Epoch [1019/2500], Train Loss: 0.8076, Train Accuracy: 63.44%, Test Loss: 0.9111, Test Accuracy: 65.82%\n",
      "Epoch [1020/2500], Train Loss: 0.8082, Train Accuracy: 63.87%, Test Loss: 0.8774, Test Accuracy: 67.09%\n",
      "Epoch [1021/2500], Train Loss: 0.7796, Train Accuracy: 65.43%, Test Loss: 0.8852, Test Accuracy: 67.09%\n",
      "Epoch [1022/2500], Train Loss: 0.7720, Train Accuracy: 65.15%, Test Loss: 0.8901, Test Accuracy: 67.09%\n",
      "Epoch [1023/2500], Train Loss: 0.7762, Train Accuracy: 65.58%, Test Loss: 0.8750, Test Accuracy: 67.09%\n",
      "Epoch [1024/2500], Train Loss: 0.7684, Train Accuracy: 65.58%, Test Loss: 0.8958, Test Accuracy: 67.09%\n",
      "Epoch [1025/2500], Train Loss: 0.8151, Train Accuracy: 63.87%, Test Loss: 0.8907, Test Accuracy: 65.82%\n",
      "Epoch [1026/2500], Train Loss: 0.8049, Train Accuracy: 64.30%, Test Loss: 0.8790, Test Accuracy: 68.35%\n",
      "Epoch [1027/2500], Train Loss: 0.7847, Train Accuracy: 66.29%, Test Loss: 0.9367, Test Accuracy: 65.82%\n",
      "Epoch [1028/2500], Train Loss: 0.7695, Train Accuracy: 64.58%, Test Loss: 0.8928, Test Accuracy: 67.09%\n",
      "Epoch [1029/2500], Train Loss: 0.7798, Train Accuracy: 66.86%, Test Loss: 0.9073, Test Accuracy: 67.09%\n",
      "Epoch [1030/2500], Train Loss: 0.8018, Train Accuracy: 65.15%, Test Loss: 0.8757, Test Accuracy: 69.62%\n",
      "Epoch [1031/2500], Train Loss: 0.7951, Train Accuracy: 67.14%, Test Loss: 0.8761, Test Accuracy: 69.62%\n",
      "Epoch [1032/2500], Train Loss: 0.7728, Train Accuracy: 66.29%, Test Loss: 0.8829, Test Accuracy: 67.09%\n",
      "Epoch [1033/2500], Train Loss: 0.7976, Train Accuracy: 65.86%, Test Loss: 0.9123, Test Accuracy: 68.35%\n",
      "Epoch [1034/2500], Train Loss: 0.7857, Train Accuracy: 65.43%, Test Loss: 0.8966, Test Accuracy: 68.35%\n",
      "Epoch [1035/2500], Train Loss: 0.7631, Train Accuracy: 66.43%, Test Loss: 0.8715, Test Accuracy: 69.62%\n",
      "Epoch [1036/2500], Train Loss: 0.8100, Train Accuracy: 64.15%, Test Loss: 0.8825, Test Accuracy: 68.35%\n",
      "Epoch [1037/2500], Train Loss: 0.7851, Train Accuracy: 64.72%, Test Loss: 0.9050, Test Accuracy: 68.35%\n",
      "Epoch [1038/2500], Train Loss: 0.7715, Train Accuracy: 66.57%, Test Loss: 0.9335, Test Accuracy: 67.09%\n",
      "Epoch [1039/2500], Train Loss: 0.7457, Train Accuracy: 68.71%, Test Loss: 0.9092, Test Accuracy: 67.09%\n",
      "Epoch [1040/2500], Train Loss: 0.7955, Train Accuracy: 65.29%, Test Loss: 0.9111, Test Accuracy: 67.09%\n",
      "Epoch [1041/2500], Train Loss: 0.7749, Train Accuracy: 65.86%, Test Loss: 0.9428, Test Accuracy: 65.82%\n",
      "Epoch [1042/2500], Train Loss: 0.7453, Train Accuracy: 66.43%, Test Loss: 0.9222, Test Accuracy: 65.82%\n",
      "Epoch [1043/2500], Train Loss: 0.7855, Train Accuracy: 66.57%, Test Loss: 0.9086, Test Accuracy: 67.09%\n",
      "Epoch [1044/2500], Train Loss: 0.7563, Train Accuracy: 66.57%, Test Loss: 0.9271, Test Accuracy: 68.35%\n",
      "Epoch [1045/2500], Train Loss: 0.7693, Train Accuracy: 67.00%, Test Loss: 0.8812, Test Accuracy: 69.62%\n",
      "Epoch [1046/2500], Train Loss: 0.7663, Train Accuracy: 68.42%, Test Loss: 0.9159, Test Accuracy: 67.09%\n",
      "Epoch [1047/2500], Train Loss: 0.7558, Train Accuracy: 66.57%, Test Loss: 0.9303, Test Accuracy: 67.09%\n",
      "Epoch [1048/2500], Train Loss: 0.7945, Train Accuracy: 67.43%, Test Loss: 0.8816, Test Accuracy: 70.89%\n",
      "Epoch [1049/2500], Train Loss: 0.7788, Train Accuracy: 66.57%, Test Loss: 0.9248, Test Accuracy: 67.09%\n",
      "Epoch [1050/2500], Train Loss: 0.7859, Train Accuracy: 65.58%, Test Loss: 0.9207, Test Accuracy: 67.09%\n",
      "Epoch [1051/2500], Train Loss: 0.7766, Train Accuracy: 65.58%, Test Loss: 0.9057, Test Accuracy: 67.09%\n",
      "Epoch [1052/2500], Train Loss: 0.7824, Train Accuracy: 66.43%, Test Loss: 0.8833, Test Accuracy: 67.09%\n",
      "Epoch [1053/2500], Train Loss: 0.7920, Train Accuracy: 64.15%, Test Loss: 0.9122, Test Accuracy: 64.56%\n",
      "Epoch [1054/2500], Train Loss: 0.7836, Train Accuracy: 65.72%, Test Loss: 0.8929, Test Accuracy: 65.82%\n",
      "Epoch [1055/2500], Train Loss: 0.7666, Train Accuracy: 67.71%, Test Loss: 0.9351, Test Accuracy: 64.56%\n",
      "Epoch [1056/2500], Train Loss: 0.7725, Train Accuracy: 66.00%, Test Loss: 0.9007, Test Accuracy: 67.09%\n",
      "Epoch [1057/2500], Train Loss: 0.7941, Train Accuracy: 65.29%, Test Loss: 0.8986, Test Accuracy: 67.09%\n",
      "Epoch [1058/2500], Train Loss: 0.7926, Train Accuracy: 65.86%, Test Loss: 0.9173, Test Accuracy: 67.09%\n",
      "Epoch [1059/2500], Train Loss: 0.7802, Train Accuracy: 65.43%, Test Loss: 0.8999, Test Accuracy: 67.09%\n",
      "Epoch [1060/2500], Train Loss: 0.7654, Train Accuracy: 66.29%, Test Loss: 0.8893, Test Accuracy: 67.09%\n",
      "Epoch [1061/2500], Train Loss: 0.7834, Train Accuracy: 64.44%, Test Loss: 0.9324, Test Accuracy: 65.82%\n",
      "Epoch [1062/2500], Train Loss: 0.7703, Train Accuracy: 66.15%, Test Loss: 0.8651, Test Accuracy: 68.35%\n",
      "Epoch [1063/2500], Train Loss: 0.7997, Train Accuracy: 66.00%, Test Loss: 0.9361, Test Accuracy: 65.82%\n",
      "Epoch [1064/2500], Train Loss: 0.7741, Train Accuracy: 67.00%, Test Loss: 0.9102, Test Accuracy: 67.09%\n",
      "Epoch [1065/2500], Train Loss: 0.7690, Train Accuracy: 67.85%, Test Loss: 0.8932, Test Accuracy: 67.09%\n",
      "Epoch [1066/2500], Train Loss: 0.7689, Train Accuracy: 67.14%, Test Loss: 0.9021, Test Accuracy: 68.35%\n",
      "Epoch [1067/2500], Train Loss: 0.7795, Train Accuracy: 65.43%, Test Loss: 0.8935, Test Accuracy: 68.35%\n",
      "Epoch [1068/2500], Train Loss: 0.7839, Train Accuracy: 68.85%, Test Loss: 0.9018, Test Accuracy: 67.09%\n",
      "Epoch [1069/2500], Train Loss: 0.7741, Train Accuracy: 65.15%, Test Loss: 0.9041, Test Accuracy: 67.09%\n",
      "Epoch [1070/2500], Train Loss: 0.7617, Train Accuracy: 66.43%, Test Loss: 0.8912, Test Accuracy: 67.09%\n",
      "Epoch [1071/2500], Train Loss: 0.7810, Train Accuracy: 64.58%, Test Loss: 0.9161, Test Accuracy: 65.82%\n",
      "Epoch [1072/2500], Train Loss: 0.8091, Train Accuracy: 64.86%, Test Loss: 0.9103, Test Accuracy: 65.82%\n",
      "Epoch [1073/2500], Train Loss: 0.7687, Train Accuracy: 66.71%, Test Loss: 0.8855, Test Accuracy: 67.09%\n",
      "Epoch [1074/2500], Train Loss: 0.7700, Train Accuracy: 65.86%, Test Loss: 0.8770, Test Accuracy: 65.82%\n",
      "Epoch [1075/2500], Train Loss: 0.7803, Train Accuracy: 66.57%, Test Loss: 0.9071, Test Accuracy: 67.09%\n",
      "Epoch [1076/2500], Train Loss: 0.8009, Train Accuracy: 66.00%, Test Loss: 0.8869, Test Accuracy: 68.35%\n",
      "Epoch [1077/2500], Train Loss: 0.7819, Train Accuracy: 67.57%, Test Loss: 0.9023, Test Accuracy: 68.35%\n",
      "Epoch [1078/2500], Train Loss: 0.8078, Train Accuracy: 64.44%, Test Loss: 0.9106, Test Accuracy: 67.09%\n",
      "Epoch [1079/2500], Train Loss: 0.7850, Train Accuracy: 64.44%, Test Loss: 0.8723, Test Accuracy: 68.35%\n",
      "Epoch [1080/2500], Train Loss: 0.7729, Train Accuracy: 64.15%, Test Loss: 0.9072, Test Accuracy: 68.35%\n",
      "Epoch [1081/2500], Train Loss: 0.7675, Train Accuracy: 66.29%, Test Loss: 0.9193, Test Accuracy: 68.35%\n",
      "Epoch [1082/2500], Train Loss: 0.7787, Train Accuracy: 67.28%, Test Loss: 0.8933, Test Accuracy: 67.09%\n",
      "Epoch [1083/2500], Train Loss: 0.7726, Train Accuracy: 66.00%, Test Loss: 0.9105, Test Accuracy: 68.35%\n",
      "Epoch [1084/2500], Train Loss: 0.7735, Train Accuracy: 65.15%, Test Loss: 0.8824, Test Accuracy: 68.35%\n",
      "Epoch [1085/2500], Train Loss: 0.7703, Train Accuracy: 66.43%, Test Loss: 0.8642, Test Accuracy: 69.62%\n",
      "Epoch [1086/2500], Train Loss: 0.7769, Train Accuracy: 65.15%, Test Loss: 0.8889, Test Accuracy: 67.09%\n",
      "Epoch [1087/2500], Train Loss: 0.7780, Train Accuracy: 65.86%, Test Loss: 0.9195, Test Accuracy: 67.09%\n",
      "Epoch [1088/2500], Train Loss: 0.7564, Train Accuracy: 67.00%, Test Loss: 0.8839, Test Accuracy: 68.35%\n",
      "Epoch [1089/2500], Train Loss: 0.7688, Train Accuracy: 67.14%, Test Loss: 0.8752, Test Accuracy: 67.09%\n",
      "Epoch [1090/2500], Train Loss: 0.7805, Train Accuracy: 65.72%, Test Loss: 0.8625, Test Accuracy: 68.35%\n",
      "Epoch [1091/2500], Train Loss: 0.7677, Train Accuracy: 65.29%, Test Loss: 0.8813, Test Accuracy: 68.35%\n",
      "Epoch [1092/2500], Train Loss: 0.7893, Train Accuracy: 65.43%, Test Loss: 0.9136, Test Accuracy: 67.09%\n",
      "Epoch [1093/2500], Train Loss: 0.7769, Train Accuracy: 66.43%, Test Loss: 0.9092, Test Accuracy: 68.35%\n",
      "Epoch [1094/2500], Train Loss: 0.7725, Train Accuracy: 65.29%, Test Loss: 0.8924, Test Accuracy: 67.09%\n",
      "Epoch [1095/2500], Train Loss: 0.8025, Train Accuracy: 63.87%, Test Loss: 0.8910, Test Accuracy: 68.35%\n",
      "Epoch [1096/2500], Train Loss: 0.7642, Train Accuracy: 66.43%, Test Loss: 0.8614, Test Accuracy: 68.35%\n",
      "Epoch [1097/2500], Train Loss: 0.7618, Train Accuracy: 66.43%, Test Loss: 0.9289, Test Accuracy: 67.09%\n",
      "Epoch [1098/2500], Train Loss: 0.7491, Train Accuracy: 66.29%, Test Loss: 0.9141, Test Accuracy: 65.82%\n",
      "Epoch [1099/2500], Train Loss: 0.7499, Train Accuracy: 65.29%, Test Loss: 0.8895, Test Accuracy: 67.09%\n",
      "Epoch [1100/2500], Train Loss: 0.7580, Train Accuracy: 68.42%, Test Loss: 0.8890, Test Accuracy: 67.09%\n",
      "Epoch [1101/2500], Train Loss: 0.7464, Train Accuracy: 67.28%, Test Loss: 0.8923, Test Accuracy: 67.09%\n",
      "Epoch [1102/2500], Train Loss: 0.7698, Train Accuracy: 65.72%, Test Loss: 0.8730, Test Accuracy: 67.09%\n",
      "Epoch [1103/2500], Train Loss: 0.7694, Train Accuracy: 64.72%, Test Loss: 0.9094, Test Accuracy: 67.09%\n",
      "Epoch [1104/2500], Train Loss: 0.7502, Train Accuracy: 68.42%, Test Loss: 0.8640, Test Accuracy: 68.35%\n",
      "Epoch [1105/2500], Train Loss: 0.7725, Train Accuracy: 66.00%, Test Loss: 0.8873, Test Accuracy: 68.35%\n",
      "Epoch [1106/2500], Train Loss: 0.7407, Train Accuracy: 67.28%, Test Loss: 0.9004, Test Accuracy: 68.35%\n",
      "Epoch [1107/2500], Train Loss: 0.7618, Train Accuracy: 66.43%, Test Loss: 0.8830, Test Accuracy: 67.09%\n",
      "Epoch [1108/2500], Train Loss: 0.7688, Train Accuracy: 67.71%, Test Loss: 0.8992, Test Accuracy: 68.35%\n",
      "Epoch [1109/2500], Train Loss: 0.7485, Train Accuracy: 66.71%, Test Loss: 0.9371, Test Accuracy: 64.56%\n",
      "Epoch [1110/2500], Train Loss: 0.7769, Train Accuracy: 66.57%, Test Loss: 0.8914, Test Accuracy: 67.09%\n",
      "Epoch [1111/2500], Train Loss: 0.7659, Train Accuracy: 65.01%, Test Loss: 0.8975, Test Accuracy: 65.82%\n",
      "Epoch [1112/2500], Train Loss: 0.7555, Train Accuracy: 66.29%, Test Loss: 0.9178, Test Accuracy: 67.09%\n",
      "Epoch [1113/2500], Train Loss: 0.7495, Train Accuracy: 66.71%, Test Loss: 0.9149, Test Accuracy: 65.82%\n",
      "Epoch [1114/2500], Train Loss: 0.7488, Train Accuracy: 66.29%, Test Loss: 0.8948, Test Accuracy: 67.09%\n",
      "Epoch [1115/2500], Train Loss: 0.7509, Train Accuracy: 66.43%, Test Loss: 0.9460, Test Accuracy: 64.56%\n",
      "Epoch [1116/2500], Train Loss: 0.7742, Train Accuracy: 66.29%, Test Loss: 0.8856, Test Accuracy: 65.82%\n",
      "Epoch [1117/2500], Train Loss: 0.7684, Train Accuracy: 67.00%, Test Loss: 0.9087, Test Accuracy: 67.09%\n",
      "Epoch [1118/2500], Train Loss: 0.7873, Train Accuracy: 65.01%, Test Loss: 0.9068, Test Accuracy: 65.82%\n",
      "Epoch [1119/2500], Train Loss: 0.7766, Train Accuracy: 67.99%, Test Loss: 0.8624, Test Accuracy: 68.35%\n",
      "Epoch [1120/2500], Train Loss: 0.7570, Train Accuracy: 67.00%, Test Loss: 0.8827, Test Accuracy: 67.09%\n",
      "Epoch [1121/2500], Train Loss: 0.7571, Train Accuracy: 67.43%, Test Loss: 0.8812, Test Accuracy: 67.09%\n",
      "Epoch [1122/2500], Train Loss: 0.7682, Train Accuracy: 66.43%, Test Loss: 0.8988, Test Accuracy: 65.82%\n",
      "Epoch [1123/2500], Train Loss: 0.7705, Train Accuracy: 65.86%, Test Loss: 0.8883, Test Accuracy: 68.35%\n",
      "Epoch [1124/2500], Train Loss: 0.7602, Train Accuracy: 65.58%, Test Loss: 0.8787, Test Accuracy: 68.35%\n",
      "Epoch [1125/2500], Train Loss: 0.7462, Train Accuracy: 68.56%, Test Loss: 0.8968, Test Accuracy: 68.35%\n",
      "Epoch [1126/2500], Train Loss: 0.7416, Train Accuracy: 68.28%, Test Loss: 0.8984, Test Accuracy: 64.56%\n",
      "Epoch [1127/2500], Train Loss: 0.7808, Train Accuracy: 66.86%, Test Loss: 0.9291, Test Accuracy: 64.56%\n",
      "Epoch [1128/2500], Train Loss: 0.7716, Train Accuracy: 64.30%, Test Loss: 0.8990, Test Accuracy: 68.35%\n",
      "Epoch [1129/2500], Train Loss: 0.7552, Train Accuracy: 65.86%, Test Loss: 0.8848, Test Accuracy: 69.62%\n",
      "Epoch [1130/2500], Train Loss: 0.7534, Train Accuracy: 67.85%, Test Loss: 0.9051, Test Accuracy: 65.82%\n",
      "Epoch [1131/2500], Train Loss: 0.7668, Train Accuracy: 66.57%, Test Loss: 0.8876, Test Accuracy: 69.62%\n",
      "Epoch [1132/2500], Train Loss: 0.7774, Train Accuracy: 65.43%, Test Loss: 0.8853, Test Accuracy: 67.09%\n",
      "Epoch [1133/2500], Train Loss: 0.7495, Train Accuracy: 67.57%, Test Loss: 0.8706, Test Accuracy: 69.62%\n",
      "Epoch [1134/2500], Train Loss: 0.7706, Train Accuracy: 66.43%, Test Loss: 0.8863, Test Accuracy: 68.35%\n",
      "Epoch [1135/2500], Train Loss: 0.7768, Train Accuracy: 63.87%, Test Loss: 0.8779, Test Accuracy: 65.82%\n",
      "Epoch [1136/2500], Train Loss: 0.7765, Train Accuracy: 66.43%, Test Loss: 0.8989, Test Accuracy: 68.35%\n",
      "Epoch [1137/2500], Train Loss: 0.7840, Train Accuracy: 65.43%, Test Loss: 0.9115, Test Accuracy: 65.82%\n",
      "Epoch [1138/2500], Train Loss: 0.7702, Train Accuracy: 65.43%, Test Loss: 0.8959, Test Accuracy: 68.35%\n",
      "Epoch [1139/2500], Train Loss: 0.7706, Train Accuracy: 65.01%, Test Loss: 0.9186, Test Accuracy: 65.82%\n",
      "Epoch [1140/2500], Train Loss: 0.7757, Train Accuracy: 64.44%, Test Loss: 0.9287, Test Accuracy: 64.56%\n",
      "Epoch [1141/2500], Train Loss: 0.7501, Train Accuracy: 68.42%, Test Loss: 0.8957, Test Accuracy: 64.56%\n",
      "Epoch [1142/2500], Train Loss: 0.7815, Train Accuracy: 65.15%, Test Loss: 0.8907, Test Accuracy: 67.09%\n",
      "Epoch [1143/2500], Train Loss: 0.7619, Train Accuracy: 67.57%, Test Loss: 0.9215, Test Accuracy: 64.56%\n",
      "Epoch [1144/2500], Train Loss: 0.7485, Train Accuracy: 67.85%, Test Loss: 0.8814, Test Accuracy: 69.62%\n",
      "Epoch [1145/2500], Train Loss: 0.7626, Train Accuracy: 67.14%, Test Loss: 0.9034, Test Accuracy: 65.82%\n",
      "Epoch [1146/2500], Train Loss: 0.7412, Train Accuracy: 67.85%, Test Loss: 0.8883, Test Accuracy: 68.35%\n",
      "Epoch [1147/2500], Train Loss: 0.7531, Train Accuracy: 66.29%, Test Loss: 0.9131, Test Accuracy: 67.09%\n",
      "Epoch [1148/2500], Train Loss: 0.7813, Train Accuracy: 64.15%, Test Loss: 0.8820, Test Accuracy: 68.35%\n",
      "Epoch [1149/2500], Train Loss: 0.7609, Train Accuracy: 65.01%, Test Loss: 0.8724, Test Accuracy: 68.35%\n",
      "Epoch [1150/2500], Train Loss: 0.7418, Train Accuracy: 66.71%, Test Loss: 0.9257, Test Accuracy: 64.56%\n",
      "Epoch [1151/2500], Train Loss: 0.7510, Train Accuracy: 64.72%, Test Loss: 0.8997, Test Accuracy: 69.62%\n",
      "Epoch [1152/2500], Train Loss: 0.7519, Train Accuracy: 65.86%, Test Loss: 0.9252, Test Accuracy: 63.29%\n",
      "Epoch [1153/2500], Train Loss: 0.7738, Train Accuracy: 65.15%, Test Loss: 0.8827, Test Accuracy: 68.35%\n",
      "Epoch [1154/2500], Train Loss: 0.7713, Train Accuracy: 66.71%, Test Loss: 0.9034, Test Accuracy: 67.09%\n",
      "Epoch [1155/2500], Train Loss: 0.7582, Train Accuracy: 66.71%, Test Loss: 0.8978, Test Accuracy: 65.82%\n",
      "Epoch [1156/2500], Train Loss: 0.7379, Train Accuracy: 68.14%, Test Loss: 0.8799, Test Accuracy: 68.35%\n",
      "Epoch [1157/2500], Train Loss: 0.7575, Train Accuracy: 67.43%, Test Loss: 0.9080, Test Accuracy: 65.82%\n",
      "Epoch [1158/2500], Train Loss: 0.7439, Train Accuracy: 69.84%, Test Loss: 0.8705, Test Accuracy: 65.82%\n",
      "Epoch [1159/2500], Train Loss: 0.7438, Train Accuracy: 67.14%, Test Loss: 0.9074, Test Accuracy: 67.09%\n",
      "Epoch [1160/2500], Train Loss: 0.7633, Train Accuracy: 66.71%, Test Loss: 0.9057, Test Accuracy: 68.35%\n",
      "Epoch [1161/2500], Train Loss: 0.7384, Train Accuracy: 68.42%, Test Loss: 0.9141, Test Accuracy: 67.09%\n",
      "Epoch [1162/2500], Train Loss: 0.7875, Train Accuracy: 65.01%, Test Loss: 0.9041, Test Accuracy: 67.09%\n",
      "Epoch [1163/2500], Train Loss: 0.7586, Train Accuracy: 67.99%, Test Loss: 0.8805, Test Accuracy: 67.09%\n",
      "Epoch [1164/2500], Train Loss: 0.7553, Train Accuracy: 66.15%, Test Loss: 0.8836, Test Accuracy: 68.35%\n",
      "Epoch [1165/2500], Train Loss: 0.7672, Train Accuracy: 66.15%, Test Loss: 0.9020, Test Accuracy: 67.09%\n",
      "Epoch [1166/2500], Train Loss: 0.7720, Train Accuracy: 67.00%, Test Loss: 0.8807, Test Accuracy: 69.62%\n",
      "Epoch [1167/2500], Train Loss: 0.7781, Train Accuracy: 66.00%, Test Loss: 0.9040, Test Accuracy: 68.35%\n",
      "Epoch [1168/2500], Train Loss: 0.7450, Train Accuracy: 66.86%, Test Loss: 0.8969, Test Accuracy: 68.35%\n",
      "Epoch [1169/2500], Train Loss: 0.7698, Train Accuracy: 66.15%, Test Loss: 0.9009, Test Accuracy: 68.35%\n",
      "Epoch [1170/2500], Train Loss: 0.7523, Train Accuracy: 66.86%, Test Loss: 0.9127, Test Accuracy: 68.35%\n",
      "Epoch [1171/2500], Train Loss: 0.7687, Train Accuracy: 66.29%, Test Loss: 0.8973, Test Accuracy: 68.35%\n",
      "Epoch [1172/2500], Train Loss: 0.7392, Train Accuracy: 67.99%, Test Loss: 0.9417, Test Accuracy: 65.82%\n",
      "Epoch [1173/2500], Train Loss: 0.7737, Train Accuracy: 67.28%, Test Loss: 0.8936, Test Accuracy: 68.35%\n",
      "Epoch [1174/2500], Train Loss: 0.7517, Train Accuracy: 68.28%, Test Loss: 0.8896, Test Accuracy: 68.35%\n",
      "Epoch [1175/2500], Train Loss: 0.7645, Train Accuracy: 67.14%, Test Loss: 0.9096, Test Accuracy: 68.35%\n",
      "Epoch [1176/2500], Train Loss: 0.7504, Train Accuracy: 67.57%, Test Loss: 0.8668, Test Accuracy: 69.62%\n",
      "Epoch [1177/2500], Train Loss: 0.7627, Train Accuracy: 67.43%, Test Loss: 0.9201, Test Accuracy: 68.35%\n",
      "Epoch [1178/2500], Train Loss: 0.7745, Train Accuracy: 66.86%, Test Loss: 0.9203, Test Accuracy: 68.35%\n",
      "Epoch [1179/2500], Train Loss: 0.7343, Train Accuracy: 70.13%, Test Loss: 0.8728, Test Accuracy: 69.62%\n",
      "Epoch [1180/2500], Train Loss: 0.7446, Train Accuracy: 66.15%, Test Loss: 0.8887, Test Accuracy: 68.35%\n",
      "Epoch [1181/2500], Train Loss: 0.7643, Train Accuracy: 66.57%, Test Loss: 0.8797, Test Accuracy: 69.62%\n",
      "Epoch [1182/2500], Train Loss: 0.7670, Train Accuracy: 64.86%, Test Loss: 0.9221, Test Accuracy: 65.82%\n",
      "Epoch [1183/2500], Train Loss: 0.7451, Train Accuracy: 68.85%, Test Loss: 0.8810, Test Accuracy: 69.62%\n",
      "Epoch [1184/2500], Train Loss: 0.7905, Train Accuracy: 66.29%, Test Loss: 0.8823, Test Accuracy: 67.09%\n",
      "Epoch [1185/2500], Train Loss: 0.7314, Train Accuracy: 67.85%, Test Loss: 0.8535, Test Accuracy: 69.62%\n",
      "Epoch [1186/2500], Train Loss: 0.7632, Train Accuracy: 66.71%, Test Loss: 0.9021, Test Accuracy: 67.09%\n",
      "Epoch [1187/2500], Train Loss: 0.7601, Train Accuracy: 67.57%, Test Loss: 0.8896, Test Accuracy: 68.35%\n",
      "Epoch [1188/2500], Train Loss: 0.7447, Train Accuracy: 67.00%, Test Loss: 0.8763, Test Accuracy: 69.62%\n",
      "Epoch [1189/2500], Train Loss: 0.7591, Train Accuracy: 69.27%, Test Loss: 0.9036, Test Accuracy: 68.35%\n",
      "Epoch [1190/2500], Train Loss: 0.7791, Train Accuracy: 65.58%, Test Loss: 0.9328, Test Accuracy: 63.29%\n",
      "Epoch [1191/2500], Train Loss: 0.7610, Train Accuracy: 67.57%, Test Loss: 0.9322, Test Accuracy: 63.29%\n",
      "Epoch [1192/2500], Train Loss: 0.7689, Train Accuracy: 66.43%, Test Loss: 0.8922, Test Accuracy: 67.09%\n",
      "Epoch [1193/2500], Train Loss: 0.7569, Train Accuracy: 67.14%, Test Loss: 0.9065, Test Accuracy: 65.82%\n",
      "Epoch [1194/2500], Train Loss: 0.7635, Train Accuracy: 66.29%, Test Loss: 0.8859, Test Accuracy: 67.09%\n",
      "Epoch [1195/2500], Train Loss: 0.7611, Train Accuracy: 65.86%, Test Loss: 0.9212, Test Accuracy: 64.56%\n",
      "Epoch [1196/2500], Train Loss: 0.7506, Train Accuracy: 67.00%, Test Loss: 0.8694, Test Accuracy: 68.35%\n",
      "Epoch [1197/2500], Train Loss: 0.7500, Train Accuracy: 67.14%, Test Loss: 0.8657, Test Accuracy: 68.35%\n",
      "Epoch [1198/2500], Train Loss: 0.7323, Train Accuracy: 67.99%, Test Loss: 0.8830, Test Accuracy: 67.09%\n",
      "Epoch [1199/2500], Train Loss: 0.7559, Train Accuracy: 66.29%, Test Loss: 0.8636, Test Accuracy: 69.62%\n",
      "Epoch [1200/2500], Train Loss: 0.7477, Train Accuracy: 67.28%, Test Loss: 0.8998, Test Accuracy: 65.82%\n",
      "Epoch [1201/2500], Train Loss: 0.7421, Train Accuracy: 67.43%, Test Loss: 0.8972, Test Accuracy: 68.35%\n",
      "Epoch [1202/2500], Train Loss: 0.7403, Train Accuracy: 67.28%, Test Loss: 0.9645, Test Accuracy: 62.03%\n",
      "Epoch [1203/2500], Train Loss: 0.7518, Train Accuracy: 67.14%, Test Loss: 0.9378, Test Accuracy: 63.29%\n",
      "Epoch [1204/2500], Train Loss: 0.7681, Train Accuracy: 65.01%, Test Loss: 0.9113, Test Accuracy: 65.82%\n",
      "Epoch [1205/2500], Train Loss: 0.7731, Train Accuracy: 65.86%, Test Loss: 0.8739, Test Accuracy: 65.82%\n",
      "Epoch [1206/2500], Train Loss: 0.7760, Train Accuracy: 64.72%, Test Loss: 0.8779, Test Accuracy: 68.35%\n",
      "Epoch [1207/2500], Train Loss: 0.7671, Train Accuracy: 65.86%, Test Loss: 0.8666, Test Accuracy: 68.35%\n",
      "Epoch [1208/2500], Train Loss: 0.7696, Train Accuracy: 66.43%, Test Loss: 0.9076, Test Accuracy: 64.56%\n",
      "Epoch [1209/2500], Train Loss: 0.7340, Train Accuracy: 67.28%, Test Loss: 0.9060, Test Accuracy: 64.56%\n",
      "Epoch [1210/2500], Train Loss: 0.7501, Train Accuracy: 65.72%, Test Loss: 0.9318, Test Accuracy: 64.56%\n",
      "Epoch [1211/2500], Train Loss: 0.7519, Train Accuracy: 68.14%, Test Loss: 0.9006, Test Accuracy: 67.09%\n",
      "Epoch [1212/2500], Train Loss: 0.7532, Train Accuracy: 66.15%, Test Loss: 0.8898, Test Accuracy: 68.35%\n",
      "Epoch [1213/2500], Train Loss: 0.7652, Train Accuracy: 65.43%, Test Loss: 0.8744, Test Accuracy: 69.62%\n",
      "Epoch [1214/2500], Train Loss: 0.7661, Train Accuracy: 66.57%, Test Loss: 0.8798, Test Accuracy: 68.35%\n",
      "Epoch [1215/2500], Train Loss: 0.7522, Train Accuracy: 67.43%, Test Loss: 0.8673, Test Accuracy: 69.62%\n",
      "Epoch [1216/2500], Train Loss: 0.7603, Train Accuracy: 66.00%, Test Loss: 0.8811, Test Accuracy: 68.35%\n",
      "Epoch [1217/2500], Train Loss: 0.7752, Train Accuracy: 65.86%, Test Loss: 0.8874, Test Accuracy: 68.35%\n",
      "Epoch [1218/2500], Train Loss: 0.7713, Train Accuracy: 65.58%, Test Loss: 0.8660, Test Accuracy: 69.62%\n",
      "Epoch [1219/2500], Train Loss: 0.7553, Train Accuracy: 66.15%, Test Loss: 0.8979, Test Accuracy: 65.82%\n",
      "Epoch [1220/2500], Train Loss: 0.7512, Train Accuracy: 66.86%, Test Loss: 0.8826, Test Accuracy: 69.62%\n",
      "Epoch [1221/2500], Train Loss: 0.7441, Train Accuracy: 66.15%, Test Loss: 0.9062, Test Accuracy: 65.82%\n",
      "Epoch [1222/2500], Train Loss: 0.7472, Train Accuracy: 66.00%, Test Loss: 0.9504, Test Accuracy: 63.29%\n",
      "Epoch [1223/2500], Train Loss: 0.7714, Train Accuracy: 66.00%, Test Loss: 0.9074, Test Accuracy: 64.56%\n",
      "Epoch [1224/2500], Train Loss: 0.7523, Train Accuracy: 65.01%, Test Loss: 0.8869, Test Accuracy: 69.62%\n",
      "Epoch [1225/2500], Train Loss: 0.7618, Train Accuracy: 66.86%, Test Loss: 0.8716, Test Accuracy: 69.62%\n",
      "Epoch [1226/2500], Train Loss: 0.7437, Train Accuracy: 67.43%, Test Loss: 0.9299, Test Accuracy: 64.56%\n",
      "Epoch [1227/2500], Train Loss: 0.7405, Train Accuracy: 67.28%, Test Loss: 0.8754, Test Accuracy: 67.09%\n",
      "Epoch [1228/2500], Train Loss: 0.7556, Train Accuracy: 66.86%, Test Loss: 0.9181, Test Accuracy: 63.29%\n",
      "Epoch [1229/2500], Train Loss: 0.7377, Train Accuracy: 67.28%, Test Loss: 0.9168, Test Accuracy: 64.56%\n",
      "Epoch [1230/2500], Train Loss: 0.7194, Train Accuracy: 69.70%, Test Loss: 0.8915, Test Accuracy: 67.09%\n",
      "Epoch [1231/2500], Train Loss: 0.7477, Train Accuracy: 67.99%, Test Loss: 0.8619, Test Accuracy: 68.35%\n",
      "Epoch [1232/2500], Train Loss: 0.7504, Train Accuracy: 65.58%, Test Loss: 0.9082, Test Accuracy: 64.56%\n",
      "Epoch [1233/2500], Train Loss: 0.7436, Train Accuracy: 66.57%, Test Loss: 0.8938, Test Accuracy: 65.82%\n",
      "Epoch [1234/2500], Train Loss: 0.7349, Train Accuracy: 69.42%, Test Loss: 0.9240, Test Accuracy: 64.56%\n",
      "Epoch [1235/2500], Train Loss: 0.7443, Train Accuracy: 65.86%, Test Loss: 0.9193, Test Accuracy: 63.29%\n",
      "Epoch [1236/2500], Train Loss: 0.7275, Train Accuracy: 68.42%, Test Loss: 0.9159, Test Accuracy: 63.29%\n",
      "Epoch [1237/2500], Train Loss: 0.7430, Train Accuracy: 67.99%, Test Loss: 0.8872, Test Accuracy: 65.82%\n",
      "Epoch [1238/2500], Train Loss: 0.7422, Train Accuracy: 66.71%, Test Loss: 0.9429, Test Accuracy: 63.29%\n",
      "Epoch [1239/2500], Train Loss: 0.7531, Train Accuracy: 67.85%, Test Loss: 0.9082, Test Accuracy: 63.29%\n",
      "Epoch [1240/2500], Train Loss: 0.7634, Train Accuracy: 68.28%, Test Loss: 0.9035, Test Accuracy: 64.56%\n",
      "Epoch [1241/2500], Train Loss: 0.7573, Train Accuracy: 66.57%, Test Loss: 0.9571, Test Accuracy: 64.56%\n",
      "Epoch [1242/2500], Train Loss: 0.7665, Train Accuracy: 67.57%, Test Loss: 0.9223, Test Accuracy: 63.29%\n",
      "Epoch [1243/2500], Train Loss: 0.7710, Train Accuracy: 67.57%, Test Loss: 0.8922, Test Accuracy: 65.82%\n",
      "Epoch [1244/2500], Train Loss: 0.7392, Train Accuracy: 68.14%, Test Loss: 0.9052, Test Accuracy: 65.82%\n",
      "Epoch [1245/2500], Train Loss: 0.7584, Train Accuracy: 68.85%, Test Loss: 0.8815, Test Accuracy: 68.35%\n",
      "Epoch [1246/2500], Train Loss: 0.7564, Train Accuracy: 67.28%, Test Loss: 0.9072, Test Accuracy: 67.09%\n",
      "Epoch [1247/2500], Train Loss: 0.7608, Train Accuracy: 66.86%, Test Loss: 0.8975, Test Accuracy: 67.09%\n",
      "Epoch [1248/2500], Train Loss: 0.7347, Train Accuracy: 67.28%, Test Loss: 0.9141, Test Accuracy: 63.29%\n",
      "Epoch [1249/2500], Train Loss: 0.7360, Train Accuracy: 67.14%, Test Loss: 0.9059, Test Accuracy: 64.56%\n",
      "Epoch [1250/2500], Train Loss: 0.7376, Train Accuracy: 67.43%, Test Loss: 0.8896, Test Accuracy: 65.82%\n",
      "Epoch [1251/2500], Train Loss: 0.7692, Train Accuracy: 65.43%, Test Loss: 0.9678, Test Accuracy: 62.03%\n",
      "Epoch [1252/2500], Train Loss: 0.7472, Train Accuracy: 68.14%, Test Loss: 0.8945, Test Accuracy: 65.82%\n",
      "Epoch [1253/2500], Train Loss: 0.7277, Train Accuracy: 66.57%, Test Loss: 0.9696, Test Accuracy: 63.29%\n",
      "Epoch [1254/2500], Train Loss: 0.7522, Train Accuracy: 65.43%, Test Loss: 0.9179, Test Accuracy: 64.56%\n",
      "Epoch [1255/2500], Train Loss: 0.7334, Train Accuracy: 67.71%, Test Loss: 0.8883, Test Accuracy: 64.56%\n",
      "Epoch [1256/2500], Train Loss: 0.7351, Train Accuracy: 68.99%, Test Loss: 0.8828, Test Accuracy: 67.09%\n",
      "Epoch [1257/2500], Train Loss: 0.7284, Train Accuracy: 68.85%, Test Loss: 0.9270, Test Accuracy: 64.56%\n",
      "Epoch [1258/2500], Train Loss: 0.7338, Train Accuracy: 69.13%, Test Loss: 0.8969, Test Accuracy: 65.82%\n",
      "Epoch [1259/2500], Train Loss: 0.7426, Train Accuracy: 68.42%, Test Loss: 0.8832, Test Accuracy: 67.09%\n",
      "Epoch [1260/2500], Train Loss: 0.7564, Train Accuracy: 66.43%, Test Loss: 0.8972, Test Accuracy: 64.56%\n",
      "Epoch [1261/2500], Train Loss: 0.7151, Train Accuracy: 68.42%, Test Loss: 0.8829, Test Accuracy: 68.35%\n",
      "Epoch [1262/2500], Train Loss: 0.7451, Train Accuracy: 66.43%, Test Loss: 0.8939, Test Accuracy: 65.82%\n",
      "Epoch [1263/2500], Train Loss: 0.7244, Train Accuracy: 69.27%, Test Loss: 0.9003, Test Accuracy: 64.56%\n",
      "Epoch [1264/2500], Train Loss: 0.7346, Train Accuracy: 69.70%, Test Loss: 0.9060, Test Accuracy: 65.82%\n",
      "Epoch [1265/2500], Train Loss: 0.7253, Train Accuracy: 67.71%, Test Loss: 0.9146, Test Accuracy: 64.56%\n",
      "Epoch [1266/2500], Train Loss: 0.7513, Train Accuracy: 67.57%, Test Loss: 0.8871, Test Accuracy: 67.09%\n",
      "Epoch [1267/2500], Train Loss: 0.7127, Train Accuracy: 68.85%, Test Loss: 0.9170, Test Accuracy: 64.56%\n",
      "Epoch [1268/2500], Train Loss: 0.7422, Train Accuracy: 66.43%, Test Loss: 0.9044, Test Accuracy: 65.82%\n",
      "Epoch [1269/2500], Train Loss: 0.7502, Train Accuracy: 67.43%, Test Loss: 0.8812, Test Accuracy: 68.35%\n",
      "Epoch [1270/2500], Train Loss: 0.7558, Train Accuracy: 66.15%, Test Loss: 0.8850, Test Accuracy: 64.56%\n",
      "Epoch [1271/2500], Train Loss: 0.7288, Train Accuracy: 69.56%, Test Loss: 0.9327, Test Accuracy: 63.29%\n",
      "Epoch [1272/2500], Train Loss: 0.7385, Train Accuracy: 67.99%, Test Loss: 0.8644, Test Accuracy: 69.62%\n",
      "Epoch [1273/2500], Train Loss: 0.7500, Train Accuracy: 67.28%, Test Loss: 0.9410, Test Accuracy: 62.03%\n",
      "Epoch [1274/2500], Train Loss: 0.7591, Train Accuracy: 67.00%, Test Loss: 0.8921, Test Accuracy: 68.35%\n",
      "Epoch [1275/2500], Train Loss: 0.7530, Train Accuracy: 68.14%, Test Loss: 0.9387, Test Accuracy: 63.29%\n",
      "Epoch [1276/2500], Train Loss: 0.7321, Train Accuracy: 67.99%, Test Loss: 0.9291, Test Accuracy: 63.29%\n",
      "Epoch [1277/2500], Train Loss: 0.7296, Train Accuracy: 67.99%, Test Loss: 0.9265, Test Accuracy: 63.29%\n",
      "Epoch [1278/2500], Train Loss: 0.7337, Train Accuracy: 68.42%, Test Loss: 0.9199, Test Accuracy: 64.56%\n",
      "Epoch [1279/2500], Train Loss: 0.7370, Train Accuracy: 66.57%, Test Loss: 0.8911, Test Accuracy: 65.82%\n",
      "Epoch [1280/2500], Train Loss: 0.7489, Train Accuracy: 65.72%, Test Loss: 0.9041, Test Accuracy: 63.29%\n",
      "Epoch [1281/2500], Train Loss: 0.7476, Train Accuracy: 66.43%, Test Loss: 0.9035, Test Accuracy: 65.82%\n",
      "Epoch [1282/2500], Train Loss: 0.7456, Train Accuracy: 66.00%, Test Loss: 0.9586, Test Accuracy: 63.29%\n",
      "Epoch [1283/2500], Train Loss: 0.7510, Train Accuracy: 67.85%, Test Loss: 0.9027, Test Accuracy: 65.82%\n",
      "Epoch [1284/2500], Train Loss: 0.7104, Train Accuracy: 71.12%, Test Loss: 0.9088, Test Accuracy: 63.29%\n",
      "Epoch [1285/2500], Train Loss: 0.7352, Train Accuracy: 67.85%, Test Loss: 0.9125, Test Accuracy: 63.29%\n",
      "Epoch [1286/2500], Train Loss: 0.7416, Train Accuracy: 67.85%, Test Loss: 0.9050, Test Accuracy: 65.82%\n",
      "Epoch [1287/2500], Train Loss: 0.7327, Train Accuracy: 68.56%, Test Loss: 0.9008, Test Accuracy: 64.56%\n",
      "Epoch [1288/2500], Train Loss: 0.7206, Train Accuracy: 67.85%, Test Loss: 0.9186, Test Accuracy: 64.56%\n",
      "Epoch [1289/2500], Train Loss: 0.7306, Train Accuracy: 67.71%, Test Loss: 0.9439, Test Accuracy: 64.56%\n",
      "Epoch [1290/2500], Train Loss: 0.7160, Train Accuracy: 69.13%, Test Loss: 0.9243, Test Accuracy: 64.56%\n",
      "Epoch [1291/2500], Train Loss: 0.7390, Train Accuracy: 68.42%, Test Loss: 0.9072, Test Accuracy: 64.56%\n",
      "Epoch [1292/2500], Train Loss: 0.7521, Train Accuracy: 67.28%, Test Loss: 0.8983, Test Accuracy: 64.56%\n",
      "Epoch [1293/2500], Train Loss: 0.7353, Train Accuracy: 68.28%, Test Loss: 0.8978, Test Accuracy: 64.56%\n",
      "Epoch [1294/2500], Train Loss: 0.7467, Train Accuracy: 65.72%, Test Loss: 0.9333, Test Accuracy: 64.56%\n",
      "Epoch [1295/2500], Train Loss: 0.7473, Train Accuracy: 67.71%, Test Loss: 0.9265, Test Accuracy: 63.29%\n",
      "Epoch [1296/2500], Train Loss: 0.7443, Train Accuracy: 67.57%, Test Loss: 0.8853, Test Accuracy: 67.09%\n",
      "Epoch [1297/2500], Train Loss: 0.7432, Train Accuracy: 66.43%, Test Loss: 0.8876, Test Accuracy: 67.09%\n",
      "Epoch [1298/2500], Train Loss: 0.7392, Train Accuracy: 66.57%, Test Loss: 0.8919, Test Accuracy: 65.82%\n",
      "Epoch [1299/2500], Train Loss: 0.7311, Train Accuracy: 67.43%, Test Loss: 0.9856, Test Accuracy: 62.03%\n",
      "Epoch [1300/2500], Train Loss: 0.7521, Train Accuracy: 67.00%, Test Loss: 0.9093, Test Accuracy: 63.29%\n",
      "Epoch [1301/2500], Train Loss: 0.7557, Train Accuracy: 66.86%, Test Loss: 0.9042, Test Accuracy: 63.29%\n",
      "Epoch [1302/2500], Train Loss: 0.7309, Train Accuracy: 66.71%, Test Loss: 0.9047, Test Accuracy: 63.29%\n",
      "Epoch [1303/2500], Train Loss: 0.7313, Train Accuracy: 68.56%, Test Loss: 0.8931, Test Accuracy: 64.56%\n",
      "Epoch [1304/2500], Train Loss: 0.7528, Train Accuracy: 66.71%, Test Loss: 0.9225, Test Accuracy: 63.29%\n",
      "Epoch [1305/2500], Train Loss: 0.7347, Train Accuracy: 69.42%, Test Loss: 0.9019, Test Accuracy: 64.56%\n",
      "Epoch [1306/2500], Train Loss: 0.7330, Train Accuracy: 67.14%, Test Loss: 0.9413, Test Accuracy: 63.29%\n",
      "Epoch [1307/2500], Train Loss: 0.7272, Train Accuracy: 70.41%, Test Loss: 0.9246, Test Accuracy: 62.03%\n",
      "Epoch [1308/2500], Train Loss: 0.7533, Train Accuracy: 67.43%, Test Loss: 0.9208, Test Accuracy: 63.29%\n",
      "Epoch [1309/2500], Train Loss: 0.7363, Train Accuracy: 67.14%, Test Loss: 0.8966, Test Accuracy: 64.56%\n",
      "Epoch [1310/2500], Train Loss: 0.7407, Train Accuracy: 67.57%, Test Loss: 0.8810, Test Accuracy: 65.82%\n",
      "Epoch [1311/2500], Train Loss: 0.7341, Train Accuracy: 70.98%, Test Loss: 0.8985, Test Accuracy: 64.56%\n",
      "Epoch [1312/2500], Train Loss: 0.7029, Train Accuracy: 69.42%, Test Loss: 0.9064, Test Accuracy: 64.56%\n",
      "Epoch [1313/2500], Train Loss: 0.7131, Train Accuracy: 69.84%, Test Loss: 0.9328, Test Accuracy: 63.29%\n",
      "Epoch [1314/2500], Train Loss: 0.7118, Train Accuracy: 70.70%, Test Loss: 0.8717, Test Accuracy: 68.35%\n",
      "Epoch [1315/2500], Train Loss: 0.7316, Train Accuracy: 67.71%, Test Loss: 0.9064, Test Accuracy: 64.56%\n",
      "Epoch [1316/2500], Train Loss: 0.7487, Train Accuracy: 66.71%, Test Loss: 0.9208, Test Accuracy: 64.56%\n",
      "Epoch [1317/2500], Train Loss: 0.7197, Train Accuracy: 67.71%, Test Loss: 0.9559, Test Accuracy: 62.03%\n",
      "Epoch [1318/2500], Train Loss: 0.7296, Train Accuracy: 68.99%, Test Loss: 0.9184, Test Accuracy: 63.29%\n",
      "Epoch [1319/2500], Train Loss: 0.7359, Train Accuracy: 68.99%, Test Loss: 0.8896, Test Accuracy: 64.56%\n",
      "Epoch [1320/2500], Train Loss: 0.7458, Train Accuracy: 67.85%, Test Loss: 0.9365, Test Accuracy: 63.29%\n",
      "Epoch [1321/2500], Train Loss: 0.7272, Train Accuracy: 68.14%, Test Loss: 0.9123, Test Accuracy: 63.29%\n",
      "Epoch [1322/2500], Train Loss: 0.6930, Train Accuracy: 70.13%, Test Loss: 0.9583, Test Accuracy: 63.29%\n",
      "Epoch [1323/2500], Train Loss: 0.7399, Train Accuracy: 67.57%, Test Loss: 0.9234, Test Accuracy: 64.56%\n",
      "Epoch [1324/2500], Train Loss: 0.7346, Train Accuracy: 68.71%, Test Loss: 0.8984, Test Accuracy: 65.82%\n",
      "Epoch [1325/2500], Train Loss: 0.7157, Train Accuracy: 67.28%, Test Loss: 0.9118, Test Accuracy: 64.56%\n",
      "Epoch [1326/2500], Train Loss: 0.7115, Train Accuracy: 69.42%, Test Loss: 0.9007, Test Accuracy: 64.56%\n",
      "Epoch [1327/2500], Train Loss: 0.7392, Train Accuracy: 67.00%, Test Loss: 0.9409, Test Accuracy: 63.29%\n",
      "Epoch [1328/2500], Train Loss: 0.7415, Train Accuracy: 68.71%, Test Loss: 0.8927, Test Accuracy: 64.56%\n",
      "Epoch [1329/2500], Train Loss: 0.7276, Train Accuracy: 69.13%, Test Loss: 0.8853, Test Accuracy: 65.82%\n",
      "Epoch [1330/2500], Train Loss: 0.7169, Train Accuracy: 70.41%, Test Loss: 0.8889, Test Accuracy: 64.56%\n",
      "Epoch [1331/2500], Train Loss: 0.7494, Train Accuracy: 68.71%, Test Loss: 0.9162, Test Accuracy: 64.56%\n",
      "Epoch [1332/2500], Train Loss: 0.7167, Train Accuracy: 67.71%, Test Loss: 0.9642, Test Accuracy: 62.03%\n",
      "Epoch [1333/2500], Train Loss: 0.7230, Train Accuracy: 69.56%, Test Loss: 0.9059, Test Accuracy: 65.82%\n",
      "Epoch [1334/2500], Train Loss: 0.7233, Train Accuracy: 68.42%, Test Loss: 0.9217, Test Accuracy: 64.56%\n",
      "Epoch [1335/2500], Train Loss: 0.7384, Train Accuracy: 69.42%, Test Loss: 0.9457, Test Accuracy: 63.29%\n",
      "Epoch [1336/2500], Train Loss: 0.7217, Train Accuracy: 67.57%, Test Loss: 0.8944, Test Accuracy: 64.56%\n",
      "Epoch [1337/2500], Train Loss: 0.7044, Train Accuracy: 68.71%, Test Loss: 0.9284, Test Accuracy: 63.29%\n",
      "Epoch [1338/2500], Train Loss: 0.7405, Train Accuracy: 67.00%, Test Loss: 0.9186, Test Accuracy: 63.29%\n",
      "Epoch [1339/2500], Train Loss: 0.7319, Train Accuracy: 67.71%, Test Loss: 0.9154, Test Accuracy: 64.56%\n",
      "Epoch [1340/2500], Train Loss: 0.7232, Train Accuracy: 67.43%, Test Loss: 0.9017, Test Accuracy: 64.56%\n",
      "Epoch [1341/2500], Train Loss: 0.7326, Train Accuracy: 66.15%, Test Loss: 0.8963, Test Accuracy: 64.56%\n",
      "Epoch [1342/2500], Train Loss: 0.7021, Train Accuracy: 70.41%, Test Loss: 0.9183, Test Accuracy: 62.03%\n",
      "Epoch [1343/2500], Train Loss: 0.7296, Train Accuracy: 67.71%, Test Loss: 0.9529, Test Accuracy: 62.03%\n",
      "Epoch [1344/2500], Train Loss: 0.7144, Train Accuracy: 68.14%, Test Loss: 0.9681, Test Accuracy: 62.03%\n",
      "Epoch [1345/2500], Train Loss: 0.7197, Train Accuracy: 67.57%, Test Loss: 0.9224, Test Accuracy: 64.56%\n",
      "Epoch [1346/2500], Train Loss: 0.7541, Train Accuracy: 67.43%, Test Loss: 0.9046, Test Accuracy: 62.03%\n",
      "Epoch [1347/2500], Train Loss: 0.7400, Train Accuracy: 67.43%, Test Loss: 0.9057, Test Accuracy: 64.56%\n",
      "Epoch [1348/2500], Train Loss: 0.7370, Train Accuracy: 68.85%, Test Loss: 0.9400, Test Accuracy: 64.56%\n",
      "Epoch [1349/2500], Train Loss: 0.7327, Train Accuracy: 67.00%, Test Loss: 0.8806, Test Accuracy: 65.82%\n",
      "Epoch [1350/2500], Train Loss: 0.7521, Train Accuracy: 67.14%, Test Loss: 0.9089, Test Accuracy: 64.56%\n",
      "Epoch [1351/2500], Train Loss: 0.7451, Train Accuracy: 67.57%, Test Loss: 0.9180, Test Accuracy: 63.29%\n",
      "Epoch [1352/2500], Train Loss: 0.7360, Train Accuracy: 67.99%, Test Loss: 0.9045, Test Accuracy: 62.03%\n",
      "Epoch [1353/2500], Train Loss: 0.7321, Train Accuracy: 67.71%, Test Loss: 0.8787, Test Accuracy: 67.09%\n",
      "Epoch [1354/2500], Train Loss: 0.7214, Train Accuracy: 67.14%, Test Loss: 0.9051, Test Accuracy: 63.29%\n",
      "Epoch [1355/2500], Train Loss: 0.7234, Train Accuracy: 68.28%, Test Loss: 0.8963, Test Accuracy: 64.56%\n",
      "Epoch [1356/2500], Train Loss: 0.7329, Train Accuracy: 68.42%, Test Loss: 0.8934, Test Accuracy: 64.56%\n",
      "Epoch [1357/2500], Train Loss: 0.7371, Train Accuracy: 65.72%, Test Loss: 0.9231, Test Accuracy: 64.56%\n",
      "Epoch [1358/2500], Train Loss: 0.7508, Train Accuracy: 66.71%, Test Loss: 0.9764, Test Accuracy: 62.03%\n",
      "Epoch [1359/2500], Train Loss: 0.7340, Train Accuracy: 68.85%, Test Loss: 0.9250, Test Accuracy: 63.29%\n",
      "Epoch [1360/2500], Train Loss: 0.7430, Train Accuracy: 68.14%, Test Loss: 0.9052, Test Accuracy: 62.03%\n",
      "Epoch [1361/2500], Train Loss: 0.7349, Train Accuracy: 66.71%, Test Loss: 0.9256, Test Accuracy: 63.29%\n",
      "Epoch [1362/2500], Train Loss: 0.7238, Train Accuracy: 68.99%, Test Loss: 0.9037, Test Accuracy: 62.03%\n",
      "Epoch [1363/2500], Train Loss: 0.7219, Train Accuracy: 67.99%, Test Loss: 0.8810, Test Accuracy: 65.82%\n",
      "Epoch [1364/2500], Train Loss: 0.7365, Train Accuracy: 68.56%, Test Loss: 0.8959, Test Accuracy: 63.29%\n",
      "Epoch [1365/2500], Train Loss: 0.7399, Train Accuracy: 68.71%, Test Loss: 0.9226, Test Accuracy: 63.29%\n",
      "Epoch [1366/2500], Train Loss: 0.6993, Train Accuracy: 70.55%, Test Loss: 0.8873, Test Accuracy: 67.09%\n",
      "Epoch [1367/2500], Train Loss: 0.7513, Train Accuracy: 65.86%, Test Loss: 0.9437, Test Accuracy: 62.03%\n",
      "Epoch [1368/2500], Train Loss: 0.7293, Train Accuracy: 67.00%, Test Loss: 0.9453, Test Accuracy: 63.29%\n",
      "Epoch [1369/2500], Train Loss: 0.7434, Train Accuracy: 69.42%, Test Loss: 0.9135, Test Accuracy: 62.03%\n",
      "Epoch [1370/2500], Train Loss: 0.7447, Train Accuracy: 66.71%, Test Loss: 0.9237, Test Accuracy: 63.29%\n",
      "Epoch [1371/2500], Train Loss: 0.7093, Train Accuracy: 68.14%, Test Loss: 0.9154, Test Accuracy: 62.03%\n",
      "Epoch [1372/2500], Train Loss: 0.7240, Train Accuracy: 68.85%, Test Loss: 0.9696, Test Accuracy: 63.29%\n",
      "Epoch [1373/2500], Train Loss: 0.7094, Train Accuracy: 70.27%, Test Loss: 0.9258, Test Accuracy: 63.29%\n",
      "Epoch [1374/2500], Train Loss: 0.7520, Train Accuracy: 68.85%, Test Loss: 0.9004, Test Accuracy: 64.56%\n",
      "Epoch [1375/2500], Train Loss: 0.7316, Train Accuracy: 67.43%, Test Loss: 0.9202, Test Accuracy: 63.29%\n",
      "Epoch [1376/2500], Train Loss: 0.7366, Train Accuracy: 66.86%, Test Loss: 0.9038, Test Accuracy: 63.29%\n",
      "Epoch [1377/2500], Train Loss: 0.7364, Train Accuracy: 68.14%, Test Loss: 0.8918, Test Accuracy: 64.56%\n",
      "Epoch [1378/2500], Train Loss: 0.7424, Train Accuracy: 68.28%, Test Loss: 0.9566, Test Accuracy: 62.03%\n",
      "Epoch [1379/2500], Train Loss: 0.7420, Train Accuracy: 67.00%, Test Loss: 0.9426, Test Accuracy: 62.03%\n",
      "Epoch [1380/2500], Train Loss: 0.7307, Train Accuracy: 68.85%, Test Loss: 0.8616, Test Accuracy: 67.09%\n",
      "Epoch [1381/2500], Train Loss: 0.7306, Train Accuracy: 68.28%, Test Loss: 0.8806, Test Accuracy: 64.56%\n",
      "Epoch [1382/2500], Train Loss: 0.7600, Train Accuracy: 67.71%, Test Loss: 0.8952, Test Accuracy: 64.56%\n",
      "Epoch [1383/2500], Train Loss: 0.7171, Train Accuracy: 69.13%, Test Loss: 0.8924, Test Accuracy: 63.29%\n",
      "Epoch [1384/2500], Train Loss: 0.7174, Train Accuracy: 68.56%, Test Loss: 0.9018, Test Accuracy: 63.29%\n",
      "Epoch [1385/2500], Train Loss: 0.7173, Train Accuracy: 67.57%, Test Loss: 0.8999, Test Accuracy: 64.56%\n",
      "Epoch [1386/2500], Train Loss: 0.7039, Train Accuracy: 68.85%, Test Loss: 0.9103, Test Accuracy: 62.03%\n",
      "Epoch [1387/2500], Train Loss: 0.7080, Train Accuracy: 69.99%, Test Loss: 0.9006, Test Accuracy: 63.29%\n",
      "Epoch [1388/2500], Train Loss: 0.7137, Train Accuracy: 69.84%, Test Loss: 0.8941, Test Accuracy: 64.56%\n",
      "Epoch [1389/2500], Train Loss: 0.7454, Train Accuracy: 68.28%, Test Loss: 0.8916, Test Accuracy: 65.82%\n",
      "Epoch [1390/2500], Train Loss: 0.7116, Train Accuracy: 68.71%, Test Loss: 0.9282, Test Accuracy: 62.03%\n",
      "Epoch [1391/2500], Train Loss: 0.7280, Train Accuracy: 69.42%, Test Loss: 0.9063, Test Accuracy: 62.03%\n",
      "Epoch [1392/2500], Train Loss: 0.7325, Train Accuracy: 66.43%, Test Loss: 0.9117, Test Accuracy: 63.29%\n",
      "Epoch [1393/2500], Train Loss: 0.7213, Train Accuracy: 67.00%, Test Loss: 0.8908, Test Accuracy: 63.29%\n",
      "Epoch [1394/2500], Train Loss: 0.7290, Train Accuracy: 67.85%, Test Loss: 0.9125, Test Accuracy: 63.29%\n",
      "Epoch [1395/2500], Train Loss: 0.7339, Train Accuracy: 67.43%, Test Loss: 0.8972, Test Accuracy: 63.29%\n",
      "Epoch [1396/2500], Train Loss: 0.7293, Train Accuracy: 67.71%, Test Loss: 0.9040, Test Accuracy: 63.29%\n",
      "Epoch [1397/2500], Train Loss: 0.7248, Train Accuracy: 67.14%, Test Loss: 0.9046, Test Accuracy: 64.56%\n",
      "Epoch [1398/2500], Train Loss: 0.7061, Train Accuracy: 68.42%, Test Loss: 0.9246, Test Accuracy: 62.03%\n",
      "Epoch [1399/2500], Train Loss: 0.7099, Train Accuracy: 68.28%, Test Loss: 0.9156, Test Accuracy: 63.29%\n",
      "Epoch [1400/2500], Train Loss: 0.7260, Train Accuracy: 69.27%, Test Loss: 0.8787, Test Accuracy: 65.82%\n",
      "Epoch [1401/2500], Train Loss: 0.7218, Train Accuracy: 68.85%, Test Loss: 0.9341, Test Accuracy: 62.03%\n",
      "Epoch [1402/2500], Train Loss: 0.7342, Train Accuracy: 68.85%, Test Loss: 0.9319, Test Accuracy: 63.29%\n",
      "Epoch [1403/2500], Train Loss: 0.7288, Train Accuracy: 69.13%, Test Loss: 0.8875, Test Accuracy: 68.35%\n",
      "Epoch [1404/2500], Train Loss: 0.7203, Train Accuracy: 67.99%, Test Loss: 0.9044, Test Accuracy: 63.29%\n",
      "Epoch [1405/2500], Train Loss: 0.7217, Train Accuracy: 68.28%, Test Loss: 0.8721, Test Accuracy: 67.09%\n",
      "Epoch [1406/2500], Train Loss: 0.7244, Train Accuracy: 68.42%, Test Loss: 0.9096, Test Accuracy: 62.03%\n",
      "Epoch [1407/2500], Train Loss: 0.6987, Train Accuracy: 69.70%, Test Loss: 0.9039, Test Accuracy: 63.29%\n",
      "Epoch [1408/2500], Train Loss: 0.7173, Train Accuracy: 68.42%, Test Loss: 0.9032, Test Accuracy: 65.82%\n",
      "Epoch [1409/2500], Train Loss: 0.7223, Train Accuracy: 68.42%, Test Loss: 0.8921, Test Accuracy: 64.56%\n",
      "Epoch [1410/2500], Train Loss: 0.7101, Train Accuracy: 68.28%, Test Loss: 0.9365, Test Accuracy: 63.29%\n",
      "Epoch [1411/2500], Train Loss: 0.7214, Train Accuracy: 69.27%, Test Loss: 0.8947, Test Accuracy: 64.56%\n",
      "Epoch [1412/2500], Train Loss: 0.7183, Train Accuracy: 67.00%, Test Loss: 0.9030, Test Accuracy: 64.56%\n",
      "Epoch [1413/2500], Train Loss: 0.7222, Train Accuracy: 68.99%, Test Loss: 0.8830, Test Accuracy: 64.56%\n",
      "Epoch [1414/2500], Train Loss: 0.7400, Train Accuracy: 67.43%, Test Loss: 0.9009, Test Accuracy: 63.29%\n",
      "Epoch [1415/2500], Train Loss: 0.7167, Train Accuracy: 68.71%, Test Loss: 0.9333, Test Accuracy: 63.29%\n",
      "Epoch [1416/2500], Train Loss: 0.6845, Train Accuracy: 72.26%, Test Loss: 0.8967, Test Accuracy: 64.56%\n",
      "Epoch [1417/2500], Train Loss: 0.7211, Train Accuracy: 68.56%, Test Loss: 0.9096, Test Accuracy: 65.82%\n",
      "Epoch [1418/2500], Train Loss: 0.7124, Train Accuracy: 68.71%, Test Loss: 0.9088, Test Accuracy: 63.29%\n",
      "Epoch [1419/2500], Train Loss: 0.7207, Train Accuracy: 68.42%, Test Loss: 0.8899, Test Accuracy: 65.82%\n",
      "Epoch [1420/2500], Train Loss: 0.7457, Train Accuracy: 68.56%, Test Loss: 0.9050, Test Accuracy: 63.29%\n",
      "Epoch [1421/2500], Train Loss: 0.7284, Train Accuracy: 68.28%, Test Loss: 0.8976, Test Accuracy: 64.56%\n",
      "Epoch [1422/2500], Train Loss: 0.7265, Train Accuracy: 69.27%, Test Loss: 0.9235, Test Accuracy: 63.29%\n",
      "Epoch [1423/2500], Train Loss: 0.7219, Train Accuracy: 67.00%, Test Loss: 0.8933, Test Accuracy: 63.29%\n",
      "Epoch [1424/2500], Train Loss: 0.7322, Train Accuracy: 66.29%, Test Loss: 0.9399, Test Accuracy: 64.56%\n",
      "Epoch [1425/2500], Train Loss: 0.6988, Train Accuracy: 68.85%, Test Loss: 0.9552, Test Accuracy: 62.03%\n",
      "Epoch [1426/2500], Train Loss: 0.6972, Train Accuracy: 67.99%, Test Loss: 0.8817, Test Accuracy: 65.82%\n",
      "Epoch [1427/2500], Train Loss: 0.7067, Train Accuracy: 70.70%, Test Loss: 0.9483, Test Accuracy: 63.29%\n",
      "Epoch [1428/2500], Train Loss: 0.7199, Train Accuracy: 67.43%, Test Loss: 0.9014, Test Accuracy: 63.29%\n",
      "Epoch [1429/2500], Train Loss: 0.7088, Train Accuracy: 69.27%, Test Loss: 0.9197, Test Accuracy: 63.29%\n",
      "Epoch [1430/2500], Train Loss: 0.6715, Train Accuracy: 71.12%, Test Loss: 0.9121, Test Accuracy: 62.03%\n",
      "Epoch [1431/2500], Train Loss: 0.7131, Train Accuracy: 68.14%, Test Loss: 0.9574, Test Accuracy: 62.03%\n",
      "Epoch [1432/2500], Train Loss: 0.7245, Train Accuracy: 67.71%, Test Loss: 0.9283, Test Accuracy: 63.29%\n",
      "Epoch [1433/2500], Train Loss: 0.7133, Train Accuracy: 67.99%, Test Loss: 0.9014, Test Accuracy: 64.56%\n",
      "Epoch [1434/2500], Train Loss: 0.7218, Train Accuracy: 67.99%, Test Loss: 0.9262, Test Accuracy: 63.29%\n",
      "Epoch [1435/2500], Train Loss: 0.7278, Train Accuracy: 69.13%, Test Loss: 0.8909, Test Accuracy: 65.82%\n",
      "Epoch [1436/2500], Train Loss: 0.7358, Train Accuracy: 67.57%, Test Loss: 0.9576, Test Accuracy: 63.29%\n",
      "Epoch [1437/2500], Train Loss: 0.7133, Train Accuracy: 67.14%, Test Loss: 0.9675, Test Accuracy: 63.29%\n",
      "Epoch [1438/2500], Train Loss: 0.7298, Train Accuracy: 67.99%, Test Loss: 0.9367, Test Accuracy: 62.03%\n",
      "Epoch [1439/2500], Train Loss: 0.7192, Train Accuracy: 68.14%, Test Loss: 0.9088, Test Accuracy: 63.29%\n",
      "Epoch [1440/2500], Train Loss: 0.7147, Train Accuracy: 68.71%, Test Loss: 0.9523, Test Accuracy: 63.29%\n",
      "Epoch [1441/2500], Train Loss: 0.7047, Train Accuracy: 69.13%, Test Loss: 0.9595, Test Accuracy: 64.56%\n",
      "Epoch [1442/2500], Train Loss: 0.6958, Train Accuracy: 70.13%, Test Loss: 0.9399, Test Accuracy: 63.29%\n",
      "Epoch [1443/2500], Train Loss: 0.7301, Train Accuracy: 69.56%, Test Loss: 0.9380, Test Accuracy: 62.03%\n",
      "Epoch [1444/2500], Train Loss: 0.7022, Train Accuracy: 69.42%, Test Loss: 0.9226, Test Accuracy: 63.29%\n",
      "Epoch [1445/2500], Train Loss: 0.7213, Train Accuracy: 67.43%, Test Loss: 0.9314, Test Accuracy: 63.29%\n",
      "Epoch [1446/2500], Train Loss: 0.7287, Train Accuracy: 68.28%, Test Loss: 0.9205, Test Accuracy: 62.03%\n",
      "Epoch [1447/2500], Train Loss: 0.6962, Train Accuracy: 69.42%, Test Loss: 0.9280, Test Accuracy: 64.56%\n",
      "Epoch [1448/2500], Train Loss: 0.7082, Train Accuracy: 69.27%, Test Loss: 0.8745, Test Accuracy: 67.09%\n",
      "Epoch [1449/2500], Train Loss: 0.7150, Train Accuracy: 68.56%, Test Loss: 0.9095, Test Accuracy: 64.56%\n",
      "Epoch [1450/2500], Train Loss: 0.7216, Train Accuracy: 68.99%, Test Loss: 0.9383, Test Accuracy: 63.29%\n",
      "Epoch [1451/2500], Train Loss: 0.7026, Train Accuracy: 69.13%, Test Loss: 0.9021, Test Accuracy: 64.56%\n",
      "Epoch [1452/2500], Train Loss: 0.6946, Train Accuracy: 69.56%, Test Loss: 0.9253, Test Accuracy: 62.03%\n",
      "Epoch [1453/2500], Train Loss: 0.7143, Train Accuracy: 70.27%, Test Loss: 0.9093, Test Accuracy: 64.56%\n",
      "Epoch [1454/2500], Train Loss: 0.7153, Train Accuracy: 70.41%, Test Loss: 0.9464, Test Accuracy: 63.29%\n",
      "Epoch [1455/2500], Train Loss: 0.7079, Train Accuracy: 69.70%, Test Loss: 0.9445, Test Accuracy: 63.29%\n",
      "Epoch [1456/2500], Train Loss: 0.6994, Train Accuracy: 67.85%, Test Loss: 0.9356, Test Accuracy: 63.29%\n",
      "Epoch [1457/2500], Train Loss: 0.7191, Train Accuracy: 67.00%, Test Loss: 0.9220, Test Accuracy: 63.29%\n",
      "Epoch [1458/2500], Train Loss: 0.6993, Train Accuracy: 69.13%, Test Loss: 0.9589, Test Accuracy: 62.03%\n",
      "Epoch [1459/2500], Train Loss: 0.7191, Train Accuracy: 68.71%, Test Loss: 0.9628, Test Accuracy: 63.29%\n",
      "Epoch [1460/2500], Train Loss: 0.7354, Train Accuracy: 67.85%, Test Loss: 0.9225, Test Accuracy: 62.03%\n",
      "Epoch [1461/2500], Train Loss: 0.7095, Train Accuracy: 68.14%, Test Loss: 0.9440, Test Accuracy: 62.03%\n",
      "Epoch [1462/2500], Train Loss: 0.7094, Train Accuracy: 69.13%, Test Loss: 0.9131, Test Accuracy: 62.03%\n",
      "Epoch [1463/2500], Train Loss: 0.7076, Train Accuracy: 68.85%, Test Loss: 0.9032, Test Accuracy: 64.56%\n",
      "Epoch [1464/2500], Train Loss: 0.7480, Train Accuracy: 67.00%, Test Loss: 0.9107, Test Accuracy: 63.29%\n",
      "Epoch [1465/2500], Train Loss: 0.7412, Train Accuracy: 68.42%, Test Loss: 0.9020, Test Accuracy: 63.29%\n",
      "Epoch [1466/2500], Train Loss: 0.6951, Train Accuracy: 67.57%, Test Loss: 0.9604, Test Accuracy: 62.03%\n",
      "Epoch [1467/2500], Train Loss: 0.7255, Train Accuracy: 68.99%, Test Loss: 0.8627, Test Accuracy: 65.82%\n",
      "Epoch [1468/2500], Train Loss: 0.7183, Train Accuracy: 68.14%, Test Loss: 0.9179, Test Accuracy: 63.29%\n",
      "Epoch [1469/2500], Train Loss: 0.7049, Train Accuracy: 68.99%, Test Loss: 0.9175, Test Accuracy: 63.29%\n",
      "Epoch [1470/2500], Train Loss: 0.6996, Train Accuracy: 68.85%, Test Loss: 0.9596, Test Accuracy: 63.29%\n",
      "Epoch [1471/2500], Train Loss: 0.7038, Train Accuracy: 69.42%, Test Loss: 0.9004, Test Accuracy: 64.56%\n",
      "Epoch [1472/2500], Train Loss: 0.7298, Train Accuracy: 67.43%, Test Loss: 0.9139, Test Accuracy: 63.29%\n",
      "Epoch [1473/2500], Train Loss: 0.6937, Train Accuracy: 69.27%, Test Loss: 0.8827, Test Accuracy: 65.82%\n",
      "Epoch [1474/2500], Train Loss: 0.7141, Train Accuracy: 69.56%, Test Loss: 0.9111, Test Accuracy: 64.56%\n",
      "Epoch [1475/2500], Train Loss: 0.7038, Train Accuracy: 68.85%, Test Loss: 0.8875, Test Accuracy: 65.82%\n",
      "Epoch [1476/2500], Train Loss: 0.7451, Train Accuracy: 69.13%, Test Loss: 0.8821, Test Accuracy: 67.09%\n",
      "Epoch [1477/2500], Train Loss: 0.7167, Train Accuracy: 69.27%, Test Loss: 0.8887, Test Accuracy: 65.82%\n",
      "Epoch [1478/2500], Train Loss: 0.7119, Train Accuracy: 68.42%, Test Loss: 0.8972, Test Accuracy: 63.29%\n",
      "Epoch [1479/2500], Train Loss: 0.7166, Train Accuracy: 69.13%, Test Loss: 0.9051, Test Accuracy: 63.29%\n",
      "Epoch [1480/2500], Train Loss: 0.7324, Train Accuracy: 69.13%, Test Loss: 0.9344, Test Accuracy: 63.29%\n",
      "Epoch [1481/2500], Train Loss: 0.7050, Train Accuracy: 69.56%, Test Loss: 0.9010, Test Accuracy: 65.82%\n",
      "Epoch [1482/2500], Train Loss: 0.7401, Train Accuracy: 67.28%, Test Loss: 0.9288, Test Accuracy: 63.29%\n",
      "Epoch [1483/2500], Train Loss: 0.7038, Train Accuracy: 69.56%, Test Loss: 0.9325, Test Accuracy: 63.29%\n",
      "Epoch [1484/2500], Train Loss: 0.6769, Train Accuracy: 71.12%, Test Loss: 0.9304, Test Accuracy: 63.29%\n",
      "Epoch [1485/2500], Train Loss: 0.7207, Train Accuracy: 66.71%, Test Loss: 0.9315, Test Accuracy: 62.03%\n",
      "Epoch [1486/2500], Train Loss: 0.7046, Train Accuracy: 68.28%, Test Loss: 0.9013, Test Accuracy: 63.29%\n",
      "Epoch [1487/2500], Train Loss: 0.6877, Train Accuracy: 70.27%, Test Loss: 0.8981, Test Accuracy: 64.56%\n",
      "Epoch [1488/2500], Train Loss: 0.6947, Train Accuracy: 70.55%, Test Loss: 0.9306, Test Accuracy: 63.29%\n",
      "Epoch [1489/2500], Train Loss: 0.7205, Train Accuracy: 69.27%, Test Loss: 0.9037, Test Accuracy: 64.56%\n",
      "Epoch [1490/2500], Train Loss: 0.7078, Train Accuracy: 69.42%, Test Loss: 0.9037, Test Accuracy: 64.56%\n",
      "Epoch [1491/2500], Train Loss: 0.7113, Train Accuracy: 69.13%, Test Loss: 0.9295, Test Accuracy: 63.29%\n",
      "Epoch [1492/2500], Train Loss: 0.7155, Train Accuracy: 68.42%, Test Loss: 0.8985, Test Accuracy: 64.56%\n",
      "Epoch [1493/2500], Train Loss: 0.7137, Train Accuracy: 70.70%, Test Loss: 0.8688, Test Accuracy: 65.82%\n",
      "Epoch [1494/2500], Train Loss: 0.7388, Train Accuracy: 66.86%, Test Loss: 0.9454, Test Accuracy: 62.03%\n",
      "Epoch [1495/2500], Train Loss: 0.6905, Train Accuracy: 68.28%, Test Loss: 0.9406, Test Accuracy: 63.29%\n",
      "Epoch [1496/2500], Train Loss: 0.7113, Train Accuracy: 69.70%, Test Loss: 0.9306, Test Accuracy: 63.29%\n",
      "Epoch [1497/2500], Train Loss: 0.7189, Train Accuracy: 68.71%, Test Loss: 0.9253, Test Accuracy: 64.56%\n",
      "Epoch [1498/2500], Train Loss: 0.7003, Train Accuracy: 67.28%, Test Loss: 0.9215, Test Accuracy: 64.56%\n",
      "Epoch [1499/2500], Train Loss: 0.7188, Train Accuracy: 67.14%, Test Loss: 0.9277, Test Accuracy: 63.29%\n",
      "Epoch [1500/2500], Train Loss: 0.7099, Train Accuracy: 68.99%, Test Loss: 0.9564, Test Accuracy: 63.29%\n",
      "Epoch [1501/2500], Train Loss: 0.7041, Train Accuracy: 69.99%, Test Loss: 0.9507, Test Accuracy: 62.03%\n",
      "Epoch [1502/2500], Train Loss: 0.7196, Train Accuracy: 66.71%, Test Loss: 0.9478, Test Accuracy: 62.03%\n",
      "Epoch [1503/2500], Train Loss: 0.7147, Train Accuracy: 67.99%, Test Loss: 0.9352, Test Accuracy: 62.03%\n",
      "Epoch [1504/2500], Train Loss: 0.7036, Train Accuracy: 69.42%, Test Loss: 0.8849, Test Accuracy: 64.56%\n",
      "Epoch [1505/2500], Train Loss: 0.7085, Train Accuracy: 69.42%, Test Loss: 0.9685, Test Accuracy: 62.03%\n",
      "Epoch [1506/2500], Train Loss: 0.6874, Train Accuracy: 69.27%, Test Loss: 0.9530, Test Accuracy: 63.29%\n",
      "Epoch [1507/2500], Train Loss: 0.6973, Train Accuracy: 70.98%, Test Loss: 0.8882, Test Accuracy: 64.56%\n",
      "Epoch [1508/2500], Train Loss: 0.7063, Train Accuracy: 68.42%, Test Loss: 0.8878, Test Accuracy: 64.56%\n",
      "Epoch [1509/2500], Train Loss: 0.7202, Train Accuracy: 69.84%, Test Loss: 0.9214, Test Accuracy: 62.03%\n",
      "Epoch [1510/2500], Train Loss: 0.7232, Train Accuracy: 68.14%, Test Loss: 0.9108, Test Accuracy: 64.56%\n",
      "Epoch [1511/2500], Train Loss: 0.7148, Train Accuracy: 68.28%, Test Loss: 0.9186, Test Accuracy: 63.29%\n",
      "Epoch [1512/2500], Train Loss: 0.6921, Train Accuracy: 70.55%, Test Loss: 0.8810, Test Accuracy: 64.56%\n",
      "Epoch [1513/2500], Train Loss: 0.7111, Train Accuracy: 68.14%, Test Loss: 0.8824, Test Accuracy: 64.56%\n",
      "Epoch [1514/2500], Train Loss: 0.7100, Train Accuracy: 69.42%, Test Loss: 0.9138, Test Accuracy: 63.29%\n",
      "Epoch [1515/2500], Train Loss: 0.7059, Train Accuracy: 68.56%, Test Loss: 0.8956, Test Accuracy: 64.56%\n",
      "Epoch [1516/2500], Train Loss: 0.6848, Train Accuracy: 71.27%, Test Loss: 0.8966, Test Accuracy: 63.29%\n",
      "Epoch [1517/2500], Train Loss: 0.7094, Train Accuracy: 67.99%, Test Loss: 0.8958, Test Accuracy: 65.82%\n",
      "Epoch [1518/2500], Train Loss: 0.7155, Train Accuracy: 68.85%, Test Loss: 0.9137, Test Accuracy: 63.29%\n",
      "Epoch [1519/2500], Train Loss: 0.6952, Train Accuracy: 71.12%, Test Loss: 0.9004, Test Accuracy: 64.56%\n",
      "Epoch [1520/2500], Train Loss: 0.7054, Train Accuracy: 69.99%, Test Loss: 0.9252, Test Accuracy: 65.82%\n",
      "Epoch [1521/2500], Train Loss: 0.7323, Train Accuracy: 67.85%, Test Loss: 0.9234, Test Accuracy: 63.29%\n",
      "Epoch [1522/2500], Train Loss: 0.6987, Train Accuracy: 70.13%, Test Loss: 0.9373, Test Accuracy: 63.29%\n",
      "Epoch [1523/2500], Train Loss: 0.7285, Train Accuracy: 66.86%, Test Loss: 0.9407, Test Accuracy: 63.29%\n",
      "Epoch [1524/2500], Train Loss: 0.7096, Train Accuracy: 69.84%, Test Loss: 0.9508, Test Accuracy: 64.56%\n",
      "Epoch [1525/2500], Train Loss: 0.6990, Train Accuracy: 69.13%, Test Loss: 0.9225, Test Accuracy: 64.56%\n",
      "Epoch [1526/2500], Train Loss: 0.7145, Train Accuracy: 68.99%, Test Loss: 0.9323, Test Accuracy: 63.29%\n",
      "Epoch [1527/2500], Train Loss: 0.7214, Train Accuracy: 68.14%, Test Loss: 0.9194, Test Accuracy: 63.29%\n",
      "Epoch [1528/2500], Train Loss: 0.6939, Train Accuracy: 69.13%, Test Loss: 0.9003, Test Accuracy: 63.29%\n",
      "Epoch [1529/2500], Train Loss: 0.7118, Train Accuracy: 69.27%, Test Loss: 0.9372, Test Accuracy: 63.29%\n",
      "Epoch [1530/2500], Train Loss: 0.6961, Train Accuracy: 69.42%, Test Loss: 0.9631, Test Accuracy: 62.03%\n",
      "Epoch [1531/2500], Train Loss: 0.7113, Train Accuracy: 69.70%, Test Loss: 0.9624, Test Accuracy: 64.56%\n",
      "Epoch [1532/2500], Train Loss: 0.6978, Train Accuracy: 68.99%, Test Loss: 0.8693, Test Accuracy: 67.09%\n",
      "Epoch [1533/2500], Train Loss: 0.7234, Train Accuracy: 67.57%, Test Loss: 0.9392, Test Accuracy: 63.29%\n",
      "Epoch [1534/2500], Train Loss: 0.7118, Train Accuracy: 68.56%, Test Loss: 0.8826, Test Accuracy: 67.09%\n",
      "Epoch [1535/2500], Train Loss: 0.7146, Train Accuracy: 67.28%, Test Loss: 0.8844, Test Accuracy: 67.09%\n",
      "Epoch [1536/2500], Train Loss: 0.7130, Train Accuracy: 69.56%, Test Loss: 0.9200, Test Accuracy: 62.03%\n",
      "Epoch [1537/2500], Train Loss: 0.7046, Train Accuracy: 68.85%, Test Loss: 0.9083, Test Accuracy: 64.56%\n",
      "Epoch [1538/2500], Train Loss: 0.7388, Train Accuracy: 67.28%, Test Loss: 0.9067, Test Accuracy: 63.29%\n",
      "Epoch [1539/2500], Train Loss: 0.6862, Train Accuracy: 71.55%, Test Loss: 0.9038, Test Accuracy: 65.82%\n",
      "Epoch [1540/2500], Train Loss: 0.7152, Train Accuracy: 68.42%, Test Loss: 0.8998, Test Accuracy: 64.56%\n",
      "Epoch [1541/2500], Train Loss: 0.7168, Train Accuracy: 68.14%, Test Loss: 0.8923, Test Accuracy: 65.82%\n",
      "Epoch [1542/2500], Train Loss: 0.6997, Train Accuracy: 67.85%, Test Loss: 0.9349, Test Accuracy: 64.56%\n",
      "Epoch [1543/2500], Train Loss: 0.7168, Train Accuracy: 67.99%, Test Loss: 0.9645, Test Accuracy: 63.29%\n",
      "Epoch [1544/2500], Train Loss: 0.7197, Train Accuracy: 67.71%, Test Loss: 0.9101, Test Accuracy: 63.29%\n",
      "Epoch [1545/2500], Train Loss: 0.7058, Train Accuracy: 69.13%, Test Loss: 0.9246, Test Accuracy: 63.29%\n",
      "Epoch [1546/2500], Train Loss: 0.6754, Train Accuracy: 69.70%, Test Loss: 0.9033, Test Accuracy: 65.82%\n",
      "Epoch [1547/2500], Train Loss: 0.7058, Train Accuracy: 67.99%, Test Loss: 0.9078, Test Accuracy: 64.56%\n",
      "Epoch [1548/2500], Train Loss: 0.7199, Train Accuracy: 66.71%, Test Loss: 0.9215, Test Accuracy: 63.29%\n",
      "Epoch [1549/2500], Train Loss: 0.7163, Train Accuracy: 67.14%, Test Loss: 0.9280, Test Accuracy: 63.29%\n",
      "Epoch [1550/2500], Train Loss: 0.7063, Train Accuracy: 70.84%, Test Loss: 0.9570, Test Accuracy: 63.29%\n",
      "Epoch [1551/2500], Train Loss: 0.7140, Train Accuracy: 69.42%, Test Loss: 0.9002, Test Accuracy: 64.56%\n",
      "Epoch [1552/2500], Train Loss: 0.6770, Train Accuracy: 71.41%, Test Loss: 0.9302, Test Accuracy: 63.29%\n",
      "Epoch [1553/2500], Train Loss: 0.6956, Train Accuracy: 68.14%, Test Loss: 0.9001, Test Accuracy: 63.29%\n",
      "Epoch [1554/2500], Train Loss: 0.6997, Train Accuracy: 68.28%, Test Loss: 0.9343, Test Accuracy: 64.56%\n",
      "Epoch [1555/2500], Train Loss: 0.7088, Train Accuracy: 68.71%, Test Loss: 0.9334, Test Accuracy: 64.56%\n",
      "Epoch [1556/2500], Train Loss: 0.6817, Train Accuracy: 69.99%, Test Loss: 0.9577, Test Accuracy: 62.03%\n",
      "Epoch [1557/2500], Train Loss: 0.6969, Train Accuracy: 70.13%, Test Loss: 0.9157, Test Accuracy: 64.56%\n",
      "Epoch [1558/2500], Train Loss: 0.6975, Train Accuracy: 68.71%, Test Loss: 0.9169, Test Accuracy: 64.56%\n",
      "Epoch [1559/2500], Train Loss: 0.6963, Train Accuracy: 70.98%, Test Loss: 0.9632, Test Accuracy: 63.29%\n",
      "Epoch [1560/2500], Train Loss: 0.7188, Train Accuracy: 68.14%, Test Loss: 0.9725, Test Accuracy: 63.29%\n",
      "Epoch [1561/2500], Train Loss: 0.7031, Train Accuracy: 68.99%, Test Loss: 0.9575, Test Accuracy: 62.03%\n",
      "Epoch [1562/2500], Train Loss: 0.7351, Train Accuracy: 67.71%, Test Loss: 0.9004, Test Accuracy: 63.29%\n",
      "Epoch [1563/2500], Train Loss: 0.7036, Train Accuracy: 70.27%, Test Loss: 0.8796, Test Accuracy: 67.09%\n",
      "Epoch [1564/2500], Train Loss: 0.6876, Train Accuracy: 70.55%, Test Loss: 0.9841, Test Accuracy: 63.29%\n",
      "Epoch [1565/2500], Train Loss: 0.6927, Train Accuracy: 72.55%, Test Loss: 0.8619, Test Accuracy: 65.82%\n",
      "Epoch [1566/2500], Train Loss: 0.6814, Train Accuracy: 70.41%, Test Loss: 0.8921, Test Accuracy: 64.56%\n",
      "Epoch [1567/2500], Train Loss: 0.7292, Train Accuracy: 68.42%, Test Loss: 0.8873, Test Accuracy: 65.82%\n",
      "Epoch [1568/2500], Train Loss: 0.7010, Train Accuracy: 69.56%, Test Loss: 0.9220, Test Accuracy: 64.56%\n",
      "Epoch [1569/2500], Train Loss: 0.7007, Train Accuracy: 69.84%, Test Loss: 0.9148, Test Accuracy: 63.29%\n",
      "Epoch [1570/2500], Train Loss: 0.6882, Train Accuracy: 69.84%, Test Loss: 0.9604, Test Accuracy: 63.29%\n",
      "Epoch [1571/2500], Train Loss: 0.6908, Train Accuracy: 70.55%, Test Loss: 0.8911, Test Accuracy: 64.56%\n",
      "Epoch [1572/2500], Train Loss: 0.7037, Train Accuracy: 69.84%, Test Loss: 0.9386, Test Accuracy: 63.29%\n",
      "Epoch [1573/2500], Train Loss: 0.6851, Train Accuracy: 69.42%, Test Loss: 0.9353, Test Accuracy: 64.56%\n",
      "Epoch [1574/2500], Train Loss: 0.6943, Train Accuracy: 69.27%, Test Loss: 0.9344, Test Accuracy: 64.56%\n",
      "Epoch [1575/2500], Train Loss: 0.7064, Train Accuracy: 67.28%, Test Loss: 0.9757, Test Accuracy: 62.03%\n",
      "Epoch [1576/2500], Train Loss: 0.7102, Train Accuracy: 69.56%, Test Loss: 0.9466, Test Accuracy: 62.03%\n",
      "Epoch [1577/2500], Train Loss: 0.7036, Train Accuracy: 68.99%, Test Loss: 0.9005, Test Accuracy: 65.82%\n",
      "Epoch [1578/2500], Train Loss: 0.6977, Train Accuracy: 69.56%, Test Loss: 0.9037, Test Accuracy: 65.82%\n",
      "Epoch [1579/2500], Train Loss: 0.7198, Train Accuracy: 69.70%, Test Loss: 0.9523, Test Accuracy: 63.29%\n",
      "Epoch [1580/2500], Train Loss: 0.6873, Train Accuracy: 68.56%, Test Loss: 0.8989, Test Accuracy: 65.82%\n",
      "Epoch [1581/2500], Train Loss: 0.6888, Train Accuracy: 70.13%, Test Loss: 0.9340, Test Accuracy: 63.29%\n",
      "Epoch [1582/2500], Train Loss: 0.6900, Train Accuracy: 70.70%, Test Loss: 0.9185, Test Accuracy: 64.56%\n",
      "Epoch [1583/2500], Train Loss: 0.7176, Train Accuracy: 68.14%, Test Loss: 0.9595, Test Accuracy: 62.03%\n",
      "Epoch [1584/2500], Train Loss: 0.6818, Train Accuracy: 70.84%, Test Loss: 0.9109, Test Accuracy: 64.56%\n",
      "Epoch [1585/2500], Train Loss: 0.6844, Train Accuracy: 69.13%, Test Loss: 0.9416, Test Accuracy: 64.56%\n",
      "Epoch [1586/2500], Train Loss: 0.7179, Train Accuracy: 68.56%, Test Loss: 1.0378, Test Accuracy: 60.76%\n",
      "Epoch [1587/2500], Train Loss: 0.7008, Train Accuracy: 69.70%, Test Loss: 0.8840, Test Accuracy: 65.82%\n",
      "Epoch [1588/2500], Train Loss: 0.7074, Train Accuracy: 67.85%, Test Loss: 0.9500, Test Accuracy: 62.03%\n",
      "Epoch [1589/2500], Train Loss: 0.7081, Train Accuracy: 68.85%, Test Loss: 0.9448, Test Accuracy: 63.29%\n",
      "Epoch [1590/2500], Train Loss: 0.7080, Train Accuracy: 69.56%, Test Loss: 0.9222, Test Accuracy: 64.56%\n",
      "Epoch [1591/2500], Train Loss: 0.6782, Train Accuracy: 71.55%, Test Loss: 0.9327, Test Accuracy: 62.03%\n",
      "Epoch [1592/2500], Train Loss: 0.6992, Train Accuracy: 70.84%, Test Loss: 0.9399, Test Accuracy: 62.03%\n",
      "Epoch [1593/2500], Train Loss: 0.7124, Train Accuracy: 68.71%, Test Loss: 0.9301, Test Accuracy: 63.29%\n",
      "Epoch [1594/2500], Train Loss: 0.6951, Train Accuracy: 68.56%, Test Loss: 0.9607, Test Accuracy: 64.56%\n",
      "Epoch [1595/2500], Train Loss: 0.7117, Train Accuracy: 69.84%, Test Loss: 0.9290, Test Accuracy: 64.56%\n",
      "Epoch [1596/2500], Train Loss: 0.7426, Train Accuracy: 66.00%, Test Loss: 0.9600, Test Accuracy: 62.03%\n",
      "Epoch [1597/2500], Train Loss: 0.6823, Train Accuracy: 70.13%, Test Loss: 0.9450, Test Accuracy: 63.29%\n",
      "Epoch [1598/2500], Train Loss: 0.7131, Train Accuracy: 68.56%, Test Loss: 0.9493, Test Accuracy: 63.29%\n",
      "Epoch [1599/2500], Train Loss: 0.6818, Train Accuracy: 71.69%, Test Loss: 0.8929, Test Accuracy: 64.56%\n",
      "Epoch [1600/2500], Train Loss: 0.7081, Train Accuracy: 69.42%, Test Loss: 0.9209, Test Accuracy: 65.82%\n",
      "Epoch [1601/2500], Train Loss: 0.6943, Train Accuracy: 70.13%, Test Loss: 0.9352, Test Accuracy: 62.03%\n",
      "Epoch [1602/2500], Train Loss: 0.6930, Train Accuracy: 69.70%, Test Loss: 0.9555, Test Accuracy: 62.03%\n",
      "Epoch [1603/2500], Train Loss: 0.7019, Train Accuracy: 70.55%, Test Loss: 0.9452, Test Accuracy: 63.29%\n",
      "Epoch [1604/2500], Train Loss: 0.6836, Train Accuracy: 70.13%, Test Loss: 1.0015, Test Accuracy: 60.76%\n",
      "Epoch [1605/2500], Train Loss: 0.7098, Train Accuracy: 68.28%, Test Loss: 0.9522, Test Accuracy: 62.03%\n",
      "Epoch [1606/2500], Train Loss: 0.6683, Train Accuracy: 71.27%, Test Loss: 0.9854, Test Accuracy: 63.29%\n",
      "Epoch [1607/2500], Train Loss: 0.7042, Train Accuracy: 69.27%, Test Loss: 0.9330, Test Accuracy: 64.56%\n",
      "Epoch [1608/2500], Train Loss: 0.6800, Train Accuracy: 70.41%, Test Loss: 0.9366, Test Accuracy: 64.56%\n",
      "Epoch [1609/2500], Train Loss: 0.7166, Train Accuracy: 68.28%, Test Loss: 0.9184, Test Accuracy: 64.56%\n",
      "Epoch [1610/2500], Train Loss: 0.6916, Train Accuracy: 69.84%, Test Loss: 0.9395, Test Accuracy: 64.56%\n",
      "Epoch [1611/2500], Train Loss: 0.6885, Train Accuracy: 70.13%, Test Loss: 0.9854, Test Accuracy: 64.56%\n",
      "Epoch [1612/2500], Train Loss: 0.7135, Train Accuracy: 68.56%, Test Loss: 0.9070, Test Accuracy: 64.56%\n",
      "Epoch [1613/2500], Train Loss: 0.6906, Train Accuracy: 70.41%, Test Loss: 0.9216, Test Accuracy: 62.03%\n",
      "Epoch [1614/2500], Train Loss: 0.6894, Train Accuracy: 68.99%, Test Loss: 0.9649, Test Accuracy: 63.29%\n",
      "Epoch [1615/2500], Train Loss: 0.7118, Train Accuracy: 71.27%, Test Loss: 0.9579, Test Accuracy: 63.29%\n",
      "Epoch [1616/2500], Train Loss: 0.6941, Train Accuracy: 72.55%, Test Loss: 0.9560, Test Accuracy: 63.29%\n",
      "Epoch [1617/2500], Train Loss: 0.6923, Train Accuracy: 69.42%, Test Loss: 0.8933, Test Accuracy: 64.56%\n",
      "Epoch [1618/2500], Train Loss: 0.6651, Train Accuracy: 71.98%, Test Loss: 0.9735, Test Accuracy: 63.29%\n",
      "Epoch [1619/2500], Train Loss: 0.6643, Train Accuracy: 72.69%, Test Loss: 0.9235, Test Accuracy: 63.29%\n",
      "Epoch [1620/2500], Train Loss: 0.7199, Train Accuracy: 70.70%, Test Loss: 0.9365, Test Accuracy: 63.29%\n",
      "Epoch [1621/2500], Train Loss: 0.6841, Train Accuracy: 69.99%, Test Loss: 0.9554, Test Accuracy: 63.29%\n",
      "Epoch [1622/2500], Train Loss: 0.6919, Train Accuracy: 68.71%, Test Loss: 0.8947, Test Accuracy: 64.56%\n",
      "Epoch [1623/2500], Train Loss: 0.7059, Train Accuracy: 70.13%, Test Loss: 0.9301, Test Accuracy: 64.56%\n",
      "Epoch [1624/2500], Train Loss: 0.7004, Train Accuracy: 70.41%, Test Loss: 0.9506, Test Accuracy: 63.29%\n",
      "Epoch [1625/2500], Train Loss: 0.6795, Train Accuracy: 70.70%, Test Loss: 0.9234, Test Accuracy: 64.56%\n",
      "Epoch [1626/2500], Train Loss: 0.6845, Train Accuracy: 71.55%, Test Loss: 0.9530, Test Accuracy: 64.56%\n",
      "Epoch [1627/2500], Train Loss: 0.6891, Train Accuracy: 70.55%, Test Loss: 0.9364, Test Accuracy: 64.56%\n",
      "Epoch [1628/2500], Train Loss: 0.6903, Train Accuracy: 69.13%, Test Loss: 0.9508, Test Accuracy: 64.56%\n",
      "Epoch [1629/2500], Train Loss: 0.6815, Train Accuracy: 70.13%, Test Loss: 0.9458, Test Accuracy: 63.29%\n",
      "Epoch [1630/2500], Train Loss: 0.6962, Train Accuracy: 69.99%, Test Loss: 0.9329, Test Accuracy: 64.56%\n",
      "Epoch [1631/2500], Train Loss: 0.6959, Train Accuracy: 67.85%, Test Loss: 0.9318, Test Accuracy: 63.29%\n",
      "Epoch [1632/2500], Train Loss: 0.6934, Train Accuracy: 70.27%, Test Loss: 0.9493, Test Accuracy: 64.56%\n",
      "Epoch [1633/2500], Train Loss: 0.7039, Train Accuracy: 70.13%, Test Loss: 0.9425, Test Accuracy: 64.56%\n",
      "Epoch [1634/2500], Train Loss: 0.6881, Train Accuracy: 70.13%, Test Loss: 0.9189, Test Accuracy: 63.29%\n",
      "Epoch [1635/2500], Train Loss: 0.7018, Train Accuracy: 69.56%, Test Loss: 0.9334, Test Accuracy: 64.56%\n",
      "Epoch [1636/2500], Train Loss: 0.7176, Train Accuracy: 68.28%, Test Loss: 0.8968, Test Accuracy: 63.29%\n",
      "Epoch [1637/2500], Train Loss: 0.7084, Train Accuracy: 69.84%, Test Loss: 0.9222, Test Accuracy: 63.29%\n",
      "Epoch [1638/2500], Train Loss: 0.7060, Train Accuracy: 70.98%, Test Loss: 0.9023, Test Accuracy: 64.56%\n",
      "Epoch [1639/2500], Train Loss: 0.6824, Train Accuracy: 71.12%, Test Loss: 1.0078, Test Accuracy: 62.03%\n",
      "Epoch [1640/2500], Train Loss: 0.7088, Train Accuracy: 69.27%, Test Loss: 0.9807, Test Accuracy: 63.29%\n",
      "Epoch [1641/2500], Train Loss: 0.6818, Train Accuracy: 69.99%, Test Loss: 0.9749, Test Accuracy: 63.29%\n",
      "Epoch [1642/2500], Train Loss: 0.7113, Train Accuracy: 69.99%, Test Loss: 0.9174, Test Accuracy: 64.56%\n",
      "Epoch [1643/2500], Train Loss: 0.7212, Train Accuracy: 68.14%, Test Loss: 0.9678, Test Accuracy: 63.29%\n",
      "Epoch [1644/2500], Train Loss: 0.7055, Train Accuracy: 70.55%, Test Loss: 0.9040, Test Accuracy: 65.82%\n",
      "Epoch [1645/2500], Train Loss: 0.6804, Train Accuracy: 69.84%, Test Loss: 0.9536, Test Accuracy: 64.56%\n",
      "Epoch [1646/2500], Train Loss: 0.6662, Train Accuracy: 71.69%, Test Loss: 0.9336, Test Accuracy: 62.03%\n",
      "Epoch [1647/2500], Train Loss: 0.6756, Train Accuracy: 69.99%, Test Loss: 0.9109, Test Accuracy: 63.29%\n",
      "Epoch [1648/2500], Train Loss: 0.6780, Train Accuracy: 68.85%, Test Loss: 0.9074, Test Accuracy: 64.56%\n",
      "Epoch [1649/2500], Train Loss: 0.6919, Train Accuracy: 70.27%, Test Loss: 0.9204, Test Accuracy: 64.56%\n",
      "Epoch [1650/2500], Train Loss: 0.7075, Train Accuracy: 68.42%, Test Loss: 0.9124, Test Accuracy: 65.82%\n",
      "Epoch [1651/2500], Train Loss: 0.6737, Train Accuracy: 70.55%, Test Loss: 0.9502, Test Accuracy: 64.56%\n",
      "Epoch [1652/2500], Train Loss: 0.6884, Train Accuracy: 69.99%, Test Loss: 0.9174, Test Accuracy: 63.29%\n",
      "Epoch [1653/2500], Train Loss: 0.6951, Train Accuracy: 71.41%, Test Loss: 0.9427, Test Accuracy: 65.82%\n",
      "Epoch [1654/2500], Train Loss: 0.6999, Train Accuracy: 70.55%, Test Loss: 0.9611, Test Accuracy: 63.29%\n",
      "Epoch [1655/2500], Train Loss: 0.6834, Train Accuracy: 69.99%, Test Loss: 0.8771, Test Accuracy: 67.09%\n",
      "Epoch [1656/2500], Train Loss: 0.6756, Train Accuracy: 71.83%, Test Loss: 0.9241, Test Accuracy: 64.56%\n",
      "Epoch [1657/2500], Train Loss: 0.6849, Train Accuracy: 70.84%, Test Loss: 0.9204, Test Accuracy: 64.56%\n",
      "Epoch [1658/2500], Train Loss: 0.6954, Train Accuracy: 68.42%, Test Loss: 0.9376, Test Accuracy: 64.56%\n",
      "Epoch [1659/2500], Train Loss: 0.7283, Train Accuracy: 71.12%, Test Loss: 0.9271, Test Accuracy: 64.56%\n",
      "Epoch [1660/2500], Train Loss: 0.6910, Train Accuracy: 70.27%, Test Loss: 0.8983, Test Accuracy: 64.56%\n",
      "Epoch [1661/2500], Train Loss: 0.6878, Train Accuracy: 70.27%, Test Loss: 0.8855, Test Accuracy: 65.82%\n",
      "Epoch [1662/2500], Train Loss: 0.6965, Train Accuracy: 68.14%, Test Loss: 0.9284, Test Accuracy: 65.82%\n",
      "Epoch [1663/2500], Train Loss: 0.7120, Train Accuracy: 68.42%, Test Loss: 0.9123, Test Accuracy: 64.56%\n",
      "Epoch [1664/2500], Train Loss: 0.7046, Train Accuracy: 68.56%, Test Loss: 0.9403, Test Accuracy: 64.56%\n",
      "Epoch [1665/2500], Train Loss: 0.6890, Train Accuracy: 70.84%, Test Loss: 0.9450, Test Accuracy: 63.29%\n",
      "Epoch [1666/2500], Train Loss: 0.6826, Train Accuracy: 71.12%, Test Loss: 0.9049, Test Accuracy: 65.82%\n",
      "Epoch [1667/2500], Train Loss: 0.7064, Train Accuracy: 69.84%, Test Loss: 0.9277, Test Accuracy: 63.29%\n",
      "Epoch [1668/2500], Train Loss: 0.7199, Train Accuracy: 67.57%, Test Loss: 0.9583, Test Accuracy: 63.29%\n",
      "Epoch [1669/2500], Train Loss: 0.6774, Train Accuracy: 71.27%, Test Loss: 0.9345, Test Accuracy: 64.56%\n",
      "Epoch [1670/2500], Train Loss: 0.6753, Train Accuracy: 71.98%, Test Loss: 0.9424, Test Accuracy: 64.56%\n",
      "Epoch [1671/2500], Train Loss: 0.6888, Train Accuracy: 70.98%, Test Loss: 0.9435, Test Accuracy: 64.56%\n",
      "Epoch [1672/2500], Train Loss: 0.6903, Train Accuracy: 70.27%, Test Loss: 0.9880, Test Accuracy: 62.03%\n",
      "Epoch [1673/2500], Train Loss: 0.6883, Train Accuracy: 69.56%, Test Loss: 0.9180, Test Accuracy: 64.56%\n",
      "Epoch [1674/2500], Train Loss: 0.6812, Train Accuracy: 70.84%, Test Loss: 0.9146, Test Accuracy: 64.56%\n",
      "Epoch [1675/2500], Train Loss: 0.6998, Train Accuracy: 68.42%, Test Loss: 0.9393, Test Accuracy: 64.56%\n",
      "Epoch [1676/2500], Train Loss: 0.7047, Train Accuracy: 70.13%, Test Loss: 0.9383, Test Accuracy: 64.56%\n",
      "Epoch [1677/2500], Train Loss: 0.6959, Train Accuracy: 69.70%, Test Loss: 0.9282, Test Accuracy: 63.29%\n",
      "Epoch [1678/2500], Train Loss: 0.6948, Train Accuracy: 68.99%, Test Loss: 0.9348, Test Accuracy: 64.56%\n",
      "Epoch [1679/2500], Train Loss: 0.6863, Train Accuracy: 68.85%, Test Loss: 0.9043, Test Accuracy: 63.29%\n",
      "Epoch [1680/2500], Train Loss: 0.6750, Train Accuracy: 68.42%, Test Loss: 0.8826, Test Accuracy: 64.56%\n",
      "Epoch [1681/2500], Train Loss: 0.6803, Train Accuracy: 69.99%, Test Loss: 0.9156, Test Accuracy: 64.56%\n",
      "Epoch [1682/2500], Train Loss: 0.6778, Train Accuracy: 70.27%, Test Loss: 0.8805, Test Accuracy: 64.56%\n",
      "Epoch [1683/2500], Train Loss: 0.7129, Train Accuracy: 68.42%, Test Loss: 0.9088, Test Accuracy: 63.29%\n",
      "Epoch [1684/2500], Train Loss: 0.6894, Train Accuracy: 70.27%, Test Loss: 0.9162, Test Accuracy: 64.56%\n",
      "Epoch [1685/2500], Train Loss: 0.6841, Train Accuracy: 69.42%, Test Loss: 0.9313, Test Accuracy: 65.82%\n",
      "Epoch [1686/2500], Train Loss: 0.7069, Train Accuracy: 69.70%, Test Loss: 0.9217, Test Accuracy: 64.56%\n",
      "Epoch [1687/2500], Train Loss: 0.6745, Train Accuracy: 70.41%, Test Loss: 0.9449, Test Accuracy: 64.56%\n",
      "Epoch [1688/2500], Train Loss: 0.7162, Train Accuracy: 69.27%, Test Loss: 0.9179, Test Accuracy: 65.82%\n",
      "Epoch [1689/2500], Train Loss: 0.6753, Train Accuracy: 68.14%, Test Loss: 0.9328, Test Accuracy: 63.29%\n",
      "Epoch [1690/2500], Train Loss: 0.6781, Train Accuracy: 70.41%, Test Loss: 0.9463, Test Accuracy: 64.56%\n",
      "Epoch [1691/2500], Train Loss: 0.6829, Train Accuracy: 71.41%, Test Loss: 0.9221, Test Accuracy: 64.56%\n",
      "Epoch [1692/2500], Train Loss: 0.6784, Train Accuracy: 70.98%, Test Loss: 0.9388, Test Accuracy: 64.56%\n",
      "Epoch [1693/2500], Train Loss: 0.6812, Train Accuracy: 71.12%, Test Loss: 0.9707, Test Accuracy: 63.29%\n",
      "Epoch [1694/2500], Train Loss: 0.6863, Train Accuracy: 70.84%, Test Loss: 0.9385, Test Accuracy: 63.29%\n",
      "Epoch [1695/2500], Train Loss: 0.6929, Train Accuracy: 69.99%, Test Loss: 0.9405, Test Accuracy: 64.56%\n",
      "Epoch [1696/2500], Train Loss: 0.6830, Train Accuracy: 70.70%, Test Loss: 0.9549, Test Accuracy: 63.29%\n",
      "Epoch [1697/2500], Train Loss: 0.6759, Train Accuracy: 70.55%, Test Loss: 0.9007, Test Accuracy: 67.09%\n",
      "Epoch [1698/2500], Train Loss: 0.6900, Train Accuracy: 69.27%, Test Loss: 0.9735, Test Accuracy: 63.29%\n",
      "Epoch [1699/2500], Train Loss: 0.6927, Train Accuracy: 71.83%, Test Loss: 0.9303, Test Accuracy: 64.56%\n",
      "Epoch [1700/2500], Train Loss: 0.6830, Train Accuracy: 72.12%, Test Loss: 0.8810, Test Accuracy: 67.09%\n",
      "Epoch [1701/2500], Train Loss: 0.6944, Train Accuracy: 69.42%, Test Loss: 0.9204, Test Accuracy: 65.82%\n",
      "Epoch [1702/2500], Train Loss: 0.6679, Train Accuracy: 69.84%, Test Loss: 0.9877, Test Accuracy: 64.56%\n",
      "Epoch [1703/2500], Train Loss: 0.6937, Train Accuracy: 70.41%, Test Loss: 0.9535, Test Accuracy: 64.56%\n",
      "Epoch [1704/2500], Train Loss: 0.6917, Train Accuracy: 70.55%, Test Loss: 0.9352, Test Accuracy: 63.29%\n",
      "Epoch [1705/2500], Train Loss: 0.6952, Train Accuracy: 68.99%, Test Loss: 0.9363, Test Accuracy: 63.29%\n",
      "Epoch [1706/2500], Train Loss: 0.6831, Train Accuracy: 69.84%, Test Loss: 0.9500, Test Accuracy: 65.82%\n",
      "Epoch [1707/2500], Train Loss: 0.6819, Train Accuracy: 70.70%, Test Loss: 0.9295, Test Accuracy: 65.82%\n",
      "Epoch [1708/2500], Train Loss: 0.6778, Train Accuracy: 72.26%, Test Loss: 0.9146, Test Accuracy: 64.56%\n",
      "Epoch [1709/2500], Train Loss: 0.6793, Train Accuracy: 69.27%, Test Loss: 0.9154, Test Accuracy: 63.29%\n",
      "Epoch [1710/2500], Train Loss: 0.6625, Train Accuracy: 72.55%, Test Loss: 0.9387, Test Accuracy: 65.82%\n",
      "Epoch [1711/2500], Train Loss: 0.6623, Train Accuracy: 69.13%, Test Loss: 0.9120, Test Accuracy: 64.56%\n",
      "Epoch [1712/2500], Train Loss: 0.6678, Train Accuracy: 68.85%, Test Loss: 0.9504, Test Accuracy: 65.82%\n",
      "Epoch [1713/2500], Train Loss: 0.6939, Train Accuracy: 72.55%, Test Loss: 0.9199, Test Accuracy: 65.82%\n",
      "Epoch [1714/2500], Train Loss: 0.6713, Train Accuracy: 71.55%, Test Loss: 0.9646, Test Accuracy: 64.56%\n",
      "Epoch [1715/2500], Train Loss: 0.7008, Train Accuracy: 68.71%, Test Loss: 0.9091, Test Accuracy: 64.56%\n",
      "Epoch [1716/2500], Train Loss: 0.6860, Train Accuracy: 71.69%, Test Loss: 0.9231, Test Accuracy: 64.56%\n",
      "Epoch [1717/2500], Train Loss: 0.6997, Train Accuracy: 70.41%, Test Loss: 0.8947, Test Accuracy: 67.09%\n",
      "Epoch [1718/2500], Train Loss: 0.6854, Train Accuracy: 69.84%, Test Loss: 0.9687, Test Accuracy: 64.56%\n",
      "Epoch [1719/2500], Train Loss: 0.7149, Train Accuracy: 68.28%, Test Loss: 0.9414, Test Accuracy: 64.56%\n",
      "Epoch [1720/2500], Train Loss: 0.6760, Train Accuracy: 70.98%, Test Loss: 0.9046, Test Accuracy: 65.82%\n",
      "Epoch [1721/2500], Train Loss: 0.7048, Train Accuracy: 68.99%, Test Loss: 0.9484, Test Accuracy: 64.56%\n",
      "Epoch [1722/2500], Train Loss: 0.7063, Train Accuracy: 69.99%, Test Loss: 0.9006, Test Accuracy: 64.56%\n",
      "Epoch [1723/2500], Train Loss: 0.6825, Train Accuracy: 69.99%, Test Loss: 0.9265, Test Accuracy: 64.56%\n",
      "Epoch [1724/2500], Train Loss: 0.6819, Train Accuracy: 69.70%, Test Loss: 0.9388, Test Accuracy: 64.56%\n",
      "Epoch [1725/2500], Train Loss: 0.6902, Train Accuracy: 72.12%, Test Loss: 0.8960, Test Accuracy: 64.56%\n",
      "Epoch [1726/2500], Train Loss: 0.7069, Train Accuracy: 69.70%, Test Loss: 0.9110, Test Accuracy: 64.56%\n",
      "Epoch [1727/2500], Train Loss: 0.6769, Train Accuracy: 71.55%, Test Loss: 0.8659, Test Accuracy: 65.82%\n",
      "Epoch [1728/2500], Train Loss: 0.6726, Train Accuracy: 70.70%, Test Loss: 0.8944, Test Accuracy: 65.82%\n",
      "Epoch [1729/2500], Train Loss: 0.6836, Train Accuracy: 69.27%, Test Loss: 0.9235, Test Accuracy: 64.56%\n",
      "Epoch [1730/2500], Train Loss: 0.6844, Train Accuracy: 69.84%, Test Loss: 0.9175, Test Accuracy: 64.56%\n",
      "Epoch [1731/2500], Train Loss: 0.7050, Train Accuracy: 68.85%, Test Loss: 0.9411, Test Accuracy: 64.56%\n",
      "Epoch [1732/2500], Train Loss: 0.6941, Train Accuracy: 69.56%, Test Loss: 0.9364, Test Accuracy: 65.82%\n",
      "Epoch [1733/2500], Train Loss: 0.6864, Train Accuracy: 72.55%, Test Loss: 0.9201, Test Accuracy: 64.56%\n",
      "Epoch [1734/2500], Train Loss: 0.7018, Train Accuracy: 69.42%, Test Loss: 0.8926, Test Accuracy: 64.56%\n",
      "Epoch [1735/2500], Train Loss: 0.6823, Train Accuracy: 70.13%, Test Loss: 0.9270, Test Accuracy: 64.56%\n",
      "Epoch [1736/2500], Train Loss: 0.6753, Train Accuracy: 70.70%, Test Loss: 0.9782, Test Accuracy: 64.56%\n",
      "Epoch [1737/2500], Train Loss: 0.7047, Train Accuracy: 69.13%, Test Loss: 0.8917, Test Accuracy: 65.82%\n",
      "Epoch [1738/2500], Train Loss: 0.6854, Train Accuracy: 69.27%, Test Loss: 0.9089, Test Accuracy: 65.82%\n",
      "Epoch [1739/2500], Train Loss: 0.6698, Train Accuracy: 71.55%, Test Loss: 0.9067, Test Accuracy: 64.56%\n",
      "Epoch [1740/2500], Train Loss: 0.6795, Train Accuracy: 70.70%, Test Loss: 0.9111, Test Accuracy: 64.56%\n",
      "Epoch [1741/2500], Train Loss: 0.7168, Train Accuracy: 67.43%, Test Loss: 0.9281, Test Accuracy: 65.82%\n",
      "Epoch [1742/2500], Train Loss: 0.6614, Train Accuracy: 71.27%, Test Loss: 0.8978, Test Accuracy: 64.56%\n",
      "Epoch [1743/2500], Train Loss: 0.6924, Train Accuracy: 68.42%, Test Loss: 0.9500, Test Accuracy: 64.56%\n",
      "Epoch [1744/2500], Train Loss: 0.6705, Train Accuracy: 71.55%, Test Loss: 0.8588, Test Accuracy: 67.09%\n",
      "Epoch [1745/2500], Train Loss: 0.6873, Train Accuracy: 70.27%, Test Loss: 0.8811, Test Accuracy: 65.82%\n",
      "Epoch [1746/2500], Train Loss: 0.6712, Train Accuracy: 71.41%, Test Loss: 0.9026, Test Accuracy: 65.82%\n",
      "Epoch [1747/2500], Train Loss: 0.6914, Train Accuracy: 69.99%, Test Loss: 0.9434, Test Accuracy: 64.56%\n",
      "Epoch [1748/2500], Train Loss: 0.6732, Train Accuracy: 70.84%, Test Loss: 0.9736, Test Accuracy: 65.82%\n",
      "Epoch [1749/2500], Train Loss: 0.6531, Train Accuracy: 69.70%, Test Loss: 0.8946, Test Accuracy: 65.82%\n",
      "Epoch [1750/2500], Train Loss: 0.6837, Train Accuracy: 71.55%, Test Loss: 0.8617, Test Accuracy: 65.82%\n",
      "Epoch [1751/2500], Train Loss: 0.6967, Train Accuracy: 68.85%, Test Loss: 0.9445, Test Accuracy: 64.56%\n",
      "Epoch [1752/2500], Train Loss: 0.6949, Train Accuracy: 70.55%, Test Loss: 0.9121, Test Accuracy: 64.56%\n",
      "Epoch [1753/2500], Train Loss: 0.6610, Train Accuracy: 71.55%, Test Loss: 0.9166, Test Accuracy: 64.56%\n",
      "Epoch [1754/2500], Train Loss: 0.6736, Train Accuracy: 68.99%, Test Loss: 0.8712, Test Accuracy: 65.82%\n",
      "Epoch [1755/2500], Train Loss: 0.6545, Train Accuracy: 71.27%, Test Loss: 0.9487, Test Accuracy: 64.56%\n",
      "Epoch [1756/2500], Train Loss: 0.6937, Train Accuracy: 68.85%, Test Loss: 0.9240, Test Accuracy: 65.82%\n",
      "Epoch [1757/2500], Train Loss: 0.6892, Train Accuracy: 69.42%, Test Loss: 0.9235, Test Accuracy: 64.56%\n",
      "Epoch [1758/2500], Train Loss: 0.6840, Train Accuracy: 70.55%, Test Loss: 0.9473, Test Accuracy: 64.56%\n",
      "Epoch [1759/2500], Train Loss: 0.6704, Train Accuracy: 68.99%, Test Loss: 0.9548, Test Accuracy: 63.29%\n",
      "Epoch [1760/2500], Train Loss: 0.6995, Train Accuracy: 69.99%, Test Loss: 0.9465, Test Accuracy: 64.56%\n",
      "Epoch [1761/2500], Train Loss: 0.7130, Train Accuracy: 68.71%, Test Loss: 0.9409, Test Accuracy: 64.56%\n",
      "Epoch [1762/2500], Train Loss: 0.6933, Train Accuracy: 72.12%, Test Loss: 0.9216, Test Accuracy: 65.82%\n",
      "Epoch [1763/2500], Train Loss: 0.6721, Train Accuracy: 71.55%, Test Loss: 0.8792, Test Accuracy: 67.09%\n",
      "Epoch [1764/2500], Train Loss: 0.6806, Train Accuracy: 71.55%, Test Loss: 0.8981, Test Accuracy: 64.56%\n",
      "Epoch [1765/2500], Train Loss: 0.6776, Train Accuracy: 69.56%, Test Loss: 0.9442, Test Accuracy: 65.82%\n",
      "Epoch [1766/2500], Train Loss: 0.6770, Train Accuracy: 70.98%, Test Loss: 0.9696, Test Accuracy: 63.29%\n",
      "Epoch [1767/2500], Train Loss: 0.6699, Train Accuracy: 69.42%, Test Loss: 0.8781, Test Accuracy: 67.09%\n",
      "Epoch [1768/2500], Train Loss: 0.6835, Train Accuracy: 70.55%, Test Loss: 0.9626, Test Accuracy: 64.56%\n",
      "Epoch [1769/2500], Train Loss: 0.6820, Train Accuracy: 71.69%, Test Loss: 0.9902, Test Accuracy: 64.56%\n",
      "Epoch [1770/2500], Train Loss: 0.6772, Train Accuracy: 70.27%, Test Loss: 0.9136, Test Accuracy: 67.09%\n",
      "Epoch [1771/2500], Train Loss: 0.6728, Train Accuracy: 71.55%, Test Loss: 0.8950, Test Accuracy: 65.82%\n",
      "Epoch [1772/2500], Train Loss: 0.7120, Train Accuracy: 69.56%, Test Loss: 0.9731, Test Accuracy: 64.56%\n",
      "Epoch [1773/2500], Train Loss: 0.6917, Train Accuracy: 69.42%, Test Loss: 0.9588, Test Accuracy: 65.82%\n",
      "Epoch [1774/2500], Train Loss: 0.6500, Train Accuracy: 70.55%, Test Loss: 0.9460, Test Accuracy: 65.82%\n",
      "Epoch [1775/2500], Train Loss: 0.6885, Train Accuracy: 70.13%, Test Loss: 0.9054, Test Accuracy: 64.56%\n",
      "Epoch [1776/2500], Train Loss: 0.6785, Train Accuracy: 71.69%, Test Loss: 0.9375, Test Accuracy: 63.29%\n",
      "Epoch [1777/2500], Train Loss: 0.6840, Train Accuracy: 69.70%, Test Loss: 0.8940, Test Accuracy: 64.56%\n",
      "Epoch [1778/2500], Train Loss: 0.6471, Train Accuracy: 72.40%, Test Loss: 0.9499, Test Accuracy: 64.56%\n",
      "Epoch [1779/2500], Train Loss: 0.6742, Train Accuracy: 69.99%, Test Loss: 0.9392, Test Accuracy: 65.82%\n",
      "Epoch [1780/2500], Train Loss: 0.6906, Train Accuracy: 69.99%, Test Loss: 0.9258, Test Accuracy: 64.56%\n",
      "Epoch [1781/2500], Train Loss: 0.6680, Train Accuracy: 70.70%, Test Loss: 0.9533, Test Accuracy: 64.56%\n",
      "Epoch [1782/2500], Train Loss: 0.6998, Train Accuracy: 70.27%, Test Loss: 0.9268, Test Accuracy: 64.56%\n",
      "Epoch [1783/2500], Train Loss: 0.6751, Train Accuracy: 71.41%, Test Loss: 0.9369, Test Accuracy: 65.82%\n",
      "Epoch [1784/2500], Train Loss: 0.6803, Train Accuracy: 69.27%, Test Loss: 0.9266, Test Accuracy: 64.56%\n",
      "Epoch [1785/2500], Train Loss: 0.6773, Train Accuracy: 70.55%, Test Loss: 0.9954, Test Accuracy: 64.56%\n",
      "Epoch [1786/2500], Train Loss: 0.6970, Train Accuracy: 69.27%, Test Loss: 1.0181, Test Accuracy: 64.56%\n",
      "Epoch [1787/2500], Train Loss: 0.6878, Train Accuracy: 69.56%, Test Loss: 0.9459, Test Accuracy: 64.56%\n",
      "Epoch [1788/2500], Train Loss: 0.6756, Train Accuracy: 70.98%, Test Loss: 1.0128, Test Accuracy: 62.03%\n",
      "Epoch [1789/2500], Train Loss: 0.6926, Train Accuracy: 69.99%, Test Loss: 0.9462, Test Accuracy: 64.56%\n",
      "Epoch [1790/2500], Train Loss: 0.6687, Train Accuracy: 71.98%, Test Loss: 0.9303, Test Accuracy: 65.82%\n",
      "Epoch [1791/2500], Train Loss: 0.6512, Train Accuracy: 71.55%, Test Loss: 0.9904, Test Accuracy: 64.56%\n",
      "Epoch [1792/2500], Train Loss: 0.6605, Train Accuracy: 71.55%, Test Loss: 0.9849, Test Accuracy: 64.56%\n",
      "Epoch [1793/2500], Train Loss: 0.6788, Train Accuracy: 71.41%, Test Loss: 0.9183, Test Accuracy: 64.56%\n",
      "Epoch [1794/2500], Train Loss: 0.7032, Train Accuracy: 69.70%, Test Loss: 0.9213, Test Accuracy: 64.56%\n",
      "Epoch [1795/2500], Train Loss: 0.6773, Train Accuracy: 70.13%, Test Loss: 0.9357, Test Accuracy: 65.82%\n",
      "Epoch [1796/2500], Train Loss: 0.7006, Train Accuracy: 69.13%, Test Loss: 0.9053, Test Accuracy: 63.29%\n",
      "Epoch [1797/2500], Train Loss: 0.6697, Train Accuracy: 71.27%, Test Loss: 0.9371, Test Accuracy: 64.56%\n",
      "Epoch [1798/2500], Train Loss: 0.6526, Train Accuracy: 70.84%, Test Loss: 0.9956, Test Accuracy: 63.29%\n",
      "Epoch [1799/2500], Train Loss: 0.6931, Train Accuracy: 70.98%, Test Loss: 0.9511, Test Accuracy: 64.56%\n",
      "Epoch [1800/2500], Train Loss: 0.6775, Train Accuracy: 68.71%, Test Loss: 0.9749, Test Accuracy: 64.56%\n",
      "Epoch [1801/2500], Train Loss: 0.6733, Train Accuracy: 70.98%, Test Loss: 0.9094, Test Accuracy: 64.56%\n",
      "Epoch [1802/2500], Train Loss: 0.6866, Train Accuracy: 71.55%, Test Loss: 0.9313, Test Accuracy: 64.56%\n",
      "Epoch [1803/2500], Train Loss: 0.6724, Train Accuracy: 70.13%, Test Loss: 0.9622, Test Accuracy: 64.56%\n",
      "Epoch [1804/2500], Train Loss: 0.6767, Train Accuracy: 70.13%, Test Loss: 0.9439, Test Accuracy: 64.56%\n",
      "Epoch [1805/2500], Train Loss: 0.6988, Train Accuracy: 70.27%, Test Loss: 0.9281, Test Accuracy: 64.56%\n",
      "Epoch [1806/2500], Train Loss: 0.6810, Train Accuracy: 70.27%, Test Loss: 0.9744, Test Accuracy: 64.56%\n",
      "Epoch [1807/2500], Train Loss: 0.6788, Train Accuracy: 70.27%, Test Loss: 0.9082, Test Accuracy: 64.56%\n",
      "Epoch [1808/2500], Train Loss: 0.6653, Train Accuracy: 69.84%, Test Loss: 1.0122, Test Accuracy: 63.29%\n",
      "Epoch [1809/2500], Train Loss: 0.6926, Train Accuracy: 69.56%, Test Loss: 0.9511, Test Accuracy: 63.29%\n",
      "Epoch [1810/2500], Train Loss: 0.6945, Train Accuracy: 69.27%, Test Loss: 0.9534, Test Accuracy: 63.29%\n",
      "Epoch [1811/2500], Train Loss: 0.6616, Train Accuracy: 71.83%, Test Loss: 0.9725, Test Accuracy: 63.29%\n",
      "Epoch [1812/2500], Train Loss: 0.6843, Train Accuracy: 69.27%, Test Loss: 0.9405, Test Accuracy: 64.56%\n",
      "Epoch [1813/2500], Train Loss: 0.6949, Train Accuracy: 70.70%, Test Loss: 0.9457, Test Accuracy: 63.29%\n",
      "Epoch [1814/2500], Train Loss: 0.6866, Train Accuracy: 70.41%, Test Loss: 0.9697, Test Accuracy: 64.56%\n",
      "Epoch [1815/2500], Train Loss: 0.6814, Train Accuracy: 70.13%, Test Loss: 0.9367, Test Accuracy: 63.29%\n",
      "Epoch [1816/2500], Train Loss: 0.6649, Train Accuracy: 70.70%, Test Loss: 1.0033, Test Accuracy: 62.03%\n",
      "Epoch [1817/2500], Train Loss: 0.6821, Train Accuracy: 71.27%, Test Loss: 0.9501, Test Accuracy: 64.56%\n",
      "Epoch [1818/2500], Train Loss: 0.6979, Train Accuracy: 70.70%, Test Loss: 0.9179, Test Accuracy: 64.56%\n",
      "Epoch [1819/2500], Train Loss: 0.6829, Train Accuracy: 69.99%, Test Loss: 0.9661, Test Accuracy: 64.56%\n",
      "Epoch [1820/2500], Train Loss: 0.7018, Train Accuracy: 68.99%, Test Loss: 0.9698, Test Accuracy: 64.56%\n",
      "Epoch [1821/2500], Train Loss: 0.6844, Train Accuracy: 69.70%, Test Loss: 0.9429, Test Accuracy: 64.56%\n",
      "Epoch [1822/2500], Train Loss: 0.6499, Train Accuracy: 71.55%, Test Loss: 0.8997, Test Accuracy: 67.09%\n",
      "Epoch [1823/2500], Train Loss: 0.6837, Train Accuracy: 70.98%, Test Loss: 0.9318, Test Accuracy: 65.82%\n",
      "Epoch [1824/2500], Train Loss: 0.6737, Train Accuracy: 70.41%, Test Loss: 0.8936, Test Accuracy: 67.09%\n",
      "Epoch [1825/2500], Train Loss: 0.6559, Train Accuracy: 69.70%, Test Loss: 0.9651, Test Accuracy: 65.82%\n",
      "Epoch [1826/2500], Train Loss: 0.6637, Train Accuracy: 71.98%, Test Loss: 0.9416, Test Accuracy: 64.56%\n",
      "Epoch [1827/2500], Train Loss: 0.6589, Train Accuracy: 72.26%, Test Loss: 0.9229, Test Accuracy: 64.56%\n",
      "Epoch [1828/2500], Train Loss: 0.6778, Train Accuracy: 69.99%, Test Loss: 0.9893, Test Accuracy: 64.56%\n",
      "Epoch [1829/2500], Train Loss: 0.6758, Train Accuracy: 70.84%, Test Loss: 0.9099, Test Accuracy: 64.56%\n",
      "Epoch [1830/2500], Train Loss: 0.6680, Train Accuracy: 71.27%, Test Loss: 0.9363, Test Accuracy: 64.56%\n",
      "Epoch [1831/2500], Train Loss: 0.6762, Train Accuracy: 71.98%, Test Loss: 0.9520, Test Accuracy: 64.56%\n",
      "Epoch [1832/2500], Train Loss: 0.6711, Train Accuracy: 71.55%, Test Loss: 0.9509, Test Accuracy: 63.29%\n",
      "Epoch [1833/2500], Train Loss: 0.6804, Train Accuracy: 71.41%, Test Loss: 0.9171, Test Accuracy: 64.56%\n",
      "Epoch [1834/2500], Train Loss: 0.6652, Train Accuracy: 71.55%, Test Loss: 1.0171, Test Accuracy: 64.56%\n",
      "Epoch [1835/2500], Train Loss: 0.6722, Train Accuracy: 69.13%, Test Loss: 0.9291, Test Accuracy: 65.82%\n",
      "Epoch [1836/2500], Train Loss: 0.6610, Train Accuracy: 72.26%, Test Loss: 0.9295, Test Accuracy: 64.56%\n",
      "Epoch [1837/2500], Train Loss: 0.6610, Train Accuracy: 70.84%, Test Loss: 0.9799, Test Accuracy: 63.29%\n",
      "Epoch [1838/2500], Train Loss: 0.6466, Train Accuracy: 72.69%, Test Loss: 0.9057, Test Accuracy: 67.09%\n",
      "Epoch [1839/2500], Train Loss: 0.6757, Train Accuracy: 70.27%, Test Loss: 0.9444, Test Accuracy: 63.29%\n",
      "Epoch [1840/2500], Train Loss: 0.6478, Train Accuracy: 71.98%, Test Loss: 0.9296, Test Accuracy: 65.82%\n",
      "Epoch [1841/2500], Train Loss: 0.6814, Train Accuracy: 69.70%, Test Loss: 0.9877, Test Accuracy: 63.29%\n",
      "Epoch [1842/2500], Train Loss: 0.6653, Train Accuracy: 70.98%, Test Loss: 0.9736, Test Accuracy: 64.56%\n",
      "Epoch [1843/2500], Train Loss: 0.6854, Train Accuracy: 69.70%, Test Loss: 0.9436, Test Accuracy: 64.56%\n",
      "Epoch [1844/2500], Train Loss: 0.6589, Train Accuracy: 71.12%, Test Loss: 0.9081, Test Accuracy: 67.09%\n",
      "Epoch [1845/2500], Train Loss: 0.6791, Train Accuracy: 69.42%, Test Loss: 0.9392, Test Accuracy: 64.56%\n",
      "Epoch [1846/2500], Train Loss: 0.6382, Train Accuracy: 71.12%, Test Loss: 1.0243, Test Accuracy: 63.29%\n",
      "Epoch [1847/2500], Train Loss: 0.6534, Train Accuracy: 71.83%, Test Loss: 0.9239, Test Accuracy: 64.56%\n",
      "Epoch [1848/2500], Train Loss: 0.6793, Train Accuracy: 69.27%, Test Loss: 0.9179, Test Accuracy: 65.82%\n",
      "Epoch [1849/2500], Train Loss: 0.6621, Train Accuracy: 71.55%, Test Loss: 0.9353, Test Accuracy: 65.82%\n",
      "Epoch [1850/2500], Train Loss: 0.6573, Train Accuracy: 72.69%, Test Loss: 0.9591, Test Accuracy: 64.56%\n",
      "Epoch [1851/2500], Train Loss: 0.6675, Train Accuracy: 70.70%, Test Loss: 1.0001, Test Accuracy: 63.29%\n",
      "Epoch [1852/2500], Train Loss: 0.6667, Train Accuracy: 69.84%, Test Loss: 0.9712, Test Accuracy: 63.29%\n",
      "Epoch [1853/2500], Train Loss: 0.6585, Train Accuracy: 71.41%, Test Loss: 0.9469, Test Accuracy: 64.56%\n",
      "Epoch [1854/2500], Train Loss: 0.6647, Train Accuracy: 71.27%, Test Loss: 0.8777, Test Accuracy: 67.09%\n",
      "Epoch [1855/2500], Train Loss: 0.6578, Train Accuracy: 73.68%, Test Loss: 0.9359, Test Accuracy: 65.82%\n",
      "Epoch [1856/2500], Train Loss: 0.6937, Train Accuracy: 70.98%, Test Loss: 0.9282, Test Accuracy: 64.56%\n",
      "Epoch [1857/2500], Train Loss: 0.6560, Train Accuracy: 71.55%, Test Loss: 0.9616, Test Accuracy: 64.56%\n",
      "Epoch [1858/2500], Train Loss: 0.6489, Train Accuracy: 70.84%, Test Loss: 0.9246, Test Accuracy: 64.56%\n",
      "Epoch [1859/2500], Train Loss: 0.6810, Train Accuracy: 68.99%, Test Loss: 0.9248, Test Accuracy: 64.56%\n",
      "Epoch [1860/2500], Train Loss: 0.6668, Train Accuracy: 70.84%, Test Loss: 0.9699, Test Accuracy: 63.29%\n",
      "Epoch [1861/2500], Train Loss: 0.6552, Train Accuracy: 71.55%, Test Loss: 0.9020, Test Accuracy: 64.56%\n",
      "Epoch [1862/2500], Train Loss: 0.6649, Train Accuracy: 71.69%, Test Loss: 0.9971, Test Accuracy: 64.56%\n",
      "Epoch [1863/2500], Train Loss: 0.6746, Train Accuracy: 71.41%, Test Loss: 0.9263, Test Accuracy: 64.56%\n",
      "Epoch [1864/2500], Train Loss: 0.6542, Train Accuracy: 73.26%, Test Loss: 1.0137, Test Accuracy: 63.29%\n",
      "Epoch [1865/2500], Train Loss: 0.6542, Train Accuracy: 71.12%, Test Loss: 0.9400, Test Accuracy: 64.56%\n",
      "Epoch [1866/2500], Train Loss: 0.6535, Train Accuracy: 73.26%, Test Loss: 0.9278, Test Accuracy: 65.82%\n",
      "Epoch [1867/2500], Train Loss: 0.6870, Train Accuracy: 69.99%, Test Loss: 0.9423, Test Accuracy: 64.56%\n",
      "Epoch [1868/2500], Train Loss: 0.6481, Train Accuracy: 70.70%, Test Loss: 0.9471, Test Accuracy: 65.82%\n",
      "Epoch [1869/2500], Train Loss: 0.6627, Train Accuracy: 71.69%, Test Loss: 0.9251, Test Accuracy: 65.82%\n",
      "Epoch [1870/2500], Train Loss: 0.6415, Train Accuracy: 71.83%, Test Loss: 0.9062, Test Accuracy: 65.82%\n",
      "Epoch [1871/2500], Train Loss: 0.6556, Train Accuracy: 73.12%, Test Loss: 0.9946, Test Accuracy: 64.56%\n",
      "Epoch [1872/2500], Train Loss: 0.6853, Train Accuracy: 70.84%, Test Loss: 0.9093, Test Accuracy: 64.56%\n",
      "Epoch [1873/2500], Train Loss: 0.6617, Train Accuracy: 72.40%, Test Loss: 0.9262, Test Accuracy: 65.82%\n",
      "Epoch [1874/2500], Train Loss: 0.6530, Train Accuracy: 71.55%, Test Loss: 0.9442, Test Accuracy: 64.56%\n",
      "Epoch [1875/2500], Train Loss: 0.6609, Train Accuracy: 71.98%, Test Loss: 0.9754, Test Accuracy: 64.56%\n",
      "Epoch [1876/2500], Train Loss: 0.6642, Train Accuracy: 71.98%, Test Loss: 0.9998, Test Accuracy: 63.29%\n",
      "Epoch [1877/2500], Train Loss: 0.6786, Train Accuracy: 69.84%, Test Loss: 0.9546, Test Accuracy: 65.82%\n",
      "Epoch [1878/2500], Train Loss: 0.6944, Train Accuracy: 69.84%, Test Loss: 0.9731, Test Accuracy: 65.82%\n",
      "Epoch [1879/2500], Train Loss: 0.6604, Train Accuracy: 72.83%, Test Loss: 0.8968, Test Accuracy: 67.09%\n",
      "Epoch [1880/2500], Train Loss: 0.6446, Train Accuracy: 70.98%, Test Loss: 0.8989, Test Accuracy: 67.09%\n",
      "Epoch [1881/2500], Train Loss: 0.6539, Train Accuracy: 71.83%, Test Loss: 0.9555, Test Accuracy: 65.82%\n",
      "Epoch [1882/2500], Train Loss: 0.6605, Train Accuracy: 69.27%, Test Loss: 0.9689, Test Accuracy: 65.82%\n",
      "Epoch [1883/2500], Train Loss: 0.6785, Train Accuracy: 71.12%, Test Loss: 0.9610, Test Accuracy: 65.82%\n",
      "Epoch [1884/2500], Train Loss: 0.6620, Train Accuracy: 71.27%, Test Loss: 0.9336, Test Accuracy: 65.82%\n",
      "Epoch [1885/2500], Train Loss: 0.6761, Train Accuracy: 71.27%, Test Loss: 0.9446, Test Accuracy: 65.82%\n",
      "Epoch [1886/2500], Train Loss: 0.6748, Train Accuracy: 70.41%, Test Loss: 0.9435, Test Accuracy: 64.56%\n",
      "Epoch [1887/2500], Train Loss: 0.6961, Train Accuracy: 70.41%, Test Loss: 0.9507, Test Accuracy: 65.82%\n",
      "Epoch [1888/2500], Train Loss: 0.6568, Train Accuracy: 72.83%, Test Loss: 0.9413, Test Accuracy: 65.82%\n",
      "Epoch [1889/2500], Train Loss: 0.6535, Train Accuracy: 70.41%, Test Loss: 0.9698, Test Accuracy: 64.56%\n",
      "Epoch [1890/2500], Train Loss: 0.6605, Train Accuracy: 69.84%, Test Loss: 0.8921, Test Accuracy: 65.82%\n",
      "Epoch [1891/2500], Train Loss: 0.6361, Train Accuracy: 72.12%, Test Loss: 0.9486, Test Accuracy: 65.82%\n",
      "Epoch [1892/2500], Train Loss: 0.6411, Train Accuracy: 73.54%, Test Loss: 1.0011, Test Accuracy: 64.56%\n",
      "Epoch [1893/2500], Train Loss: 0.6675, Train Accuracy: 70.13%, Test Loss: 0.9804, Test Accuracy: 65.82%\n",
      "Epoch [1894/2500], Train Loss: 0.6622, Train Accuracy: 70.13%, Test Loss: 0.9513, Test Accuracy: 63.29%\n",
      "Epoch [1895/2500], Train Loss: 0.6457, Train Accuracy: 71.55%, Test Loss: 0.9551, Test Accuracy: 64.56%\n",
      "Epoch [1896/2500], Train Loss: 0.6534, Train Accuracy: 72.26%, Test Loss: 0.9206, Test Accuracy: 64.56%\n",
      "Epoch [1897/2500], Train Loss: 0.6834, Train Accuracy: 70.27%, Test Loss: 0.9899, Test Accuracy: 64.56%\n",
      "Epoch [1898/2500], Train Loss: 0.6928, Train Accuracy: 70.41%, Test Loss: 0.9302, Test Accuracy: 65.82%\n",
      "Epoch [1899/2500], Train Loss: 0.6783, Train Accuracy: 69.27%, Test Loss: 0.9429, Test Accuracy: 65.82%\n",
      "Epoch [1900/2500], Train Loss: 0.6482, Train Accuracy: 72.26%, Test Loss: 0.8978, Test Accuracy: 65.82%\n",
      "Epoch [1901/2500], Train Loss: 0.6632, Train Accuracy: 72.83%, Test Loss: 0.9556, Test Accuracy: 64.56%\n",
      "Epoch [1902/2500], Train Loss: 0.6698, Train Accuracy: 69.99%, Test Loss: 0.9445, Test Accuracy: 64.56%\n",
      "Epoch [1903/2500], Train Loss: 0.6636, Train Accuracy: 70.70%, Test Loss: 0.9568, Test Accuracy: 63.29%\n",
      "Epoch [1904/2500], Train Loss: 0.6611, Train Accuracy: 71.27%, Test Loss: 0.9770, Test Accuracy: 64.56%\n",
      "Epoch [1905/2500], Train Loss: 0.6788, Train Accuracy: 70.70%, Test Loss: 0.9224, Test Accuracy: 64.56%\n",
      "Epoch [1906/2500], Train Loss: 0.6884, Train Accuracy: 70.84%, Test Loss: 0.9421, Test Accuracy: 64.56%\n",
      "Epoch [1907/2500], Train Loss: 0.6705, Train Accuracy: 69.56%, Test Loss: 0.9595, Test Accuracy: 64.56%\n",
      "Epoch [1908/2500], Train Loss: 0.6853, Train Accuracy: 69.27%, Test Loss: 0.9421, Test Accuracy: 64.56%\n",
      "Epoch [1909/2500], Train Loss: 0.6796, Train Accuracy: 71.98%, Test Loss: 0.9542, Test Accuracy: 63.29%\n",
      "Epoch [1910/2500], Train Loss: 0.6569, Train Accuracy: 70.84%, Test Loss: 0.9550, Test Accuracy: 64.56%\n",
      "Epoch [1911/2500], Train Loss: 0.6532, Train Accuracy: 73.12%, Test Loss: 0.9697, Test Accuracy: 64.56%\n",
      "Epoch [1912/2500], Train Loss: 0.6464, Train Accuracy: 70.98%, Test Loss: 0.8666, Test Accuracy: 68.35%\n",
      "Epoch [1913/2500], Train Loss: 0.6631, Train Accuracy: 70.70%, Test Loss: 0.9781, Test Accuracy: 64.56%\n",
      "Epoch [1914/2500], Train Loss: 0.6865, Train Accuracy: 68.28%, Test Loss: 0.9496, Test Accuracy: 65.82%\n",
      "Epoch [1915/2500], Train Loss: 0.6692, Train Accuracy: 69.42%, Test Loss: 0.9532, Test Accuracy: 64.56%\n",
      "Epoch [1916/2500], Train Loss: 0.6556, Train Accuracy: 72.12%, Test Loss: 0.9666, Test Accuracy: 65.82%\n",
      "Epoch [1917/2500], Train Loss: 0.6675, Train Accuracy: 73.26%, Test Loss: 0.9231, Test Accuracy: 65.82%\n",
      "Epoch [1918/2500], Train Loss: 0.6818, Train Accuracy: 71.12%, Test Loss: 0.9897, Test Accuracy: 65.82%\n",
      "Epoch [1919/2500], Train Loss: 0.6480, Train Accuracy: 73.26%, Test Loss: 0.9830, Test Accuracy: 64.56%\n",
      "Epoch [1920/2500], Train Loss: 0.6848, Train Accuracy: 70.41%, Test Loss: 0.9345, Test Accuracy: 65.82%\n",
      "Epoch [1921/2500], Train Loss: 0.6535, Train Accuracy: 71.12%, Test Loss: 1.0305, Test Accuracy: 64.56%\n",
      "Epoch [1922/2500], Train Loss: 0.6539, Train Accuracy: 70.84%, Test Loss: 0.9457, Test Accuracy: 64.56%\n",
      "Epoch [1923/2500], Train Loss: 0.6748, Train Accuracy: 70.55%, Test Loss: 0.9528, Test Accuracy: 64.56%\n",
      "Epoch [1924/2500], Train Loss: 0.6480, Train Accuracy: 71.83%, Test Loss: 0.9370, Test Accuracy: 64.56%\n",
      "Epoch [1925/2500], Train Loss: 0.6477, Train Accuracy: 72.97%, Test Loss: 0.8885, Test Accuracy: 67.09%\n",
      "Epoch [1926/2500], Train Loss: 0.6824, Train Accuracy: 70.13%, Test Loss: 0.9489, Test Accuracy: 64.56%\n",
      "Epoch [1927/2500], Train Loss: 0.6661, Train Accuracy: 71.83%, Test Loss: 1.0024, Test Accuracy: 64.56%\n",
      "Epoch [1928/2500], Train Loss: 0.6719, Train Accuracy: 70.70%, Test Loss: 0.9874, Test Accuracy: 64.56%\n",
      "Epoch [1929/2500], Train Loss: 0.6824, Train Accuracy: 70.70%, Test Loss: 0.8959, Test Accuracy: 67.09%\n",
      "Epoch [1930/2500], Train Loss: 0.6419, Train Accuracy: 72.83%, Test Loss: 0.9471, Test Accuracy: 64.56%\n",
      "Epoch [1931/2500], Train Loss: 0.6644, Train Accuracy: 71.27%, Test Loss: 0.9329, Test Accuracy: 64.56%\n",
      "Epoch [1932/2500], Train Loss: 0.6623, Train Accuracy: 71.55%, Test Loss: 0.9468, Test Accuracy: 64.56%\n",
      "Epoch [1933/2500], Train Loss: 0.6351, Train Accuracy: 71.27%, Test Loss: 0.9330, Test Accuracy: 64.56%\n",
      "Epoch [1934/2500], Train Loss: 0.6689, Train Accuracy: 69.84%, Test Loss: 0.9910, Test Accuracy: 63.29%\n",
      "Epoch [1935/2500], Train Loss: 0.6806, Train Accuracy: 71.55%, Test Loss: 0.9726, Test Accuracy: 65.82%\n",
      "Epoch [1936/2500], Train Loss: 0.6608, Train Accuracy: 69.42%, Test Loss: 0.9558, Test Accuracy: 64.56%\n",
      "Epoch [1937/2500], Train Loss: 0.6437, Train Accuracy: 73.26%, Test Loss: 0.9564, Test Accuracy: 64.56%\n",
      "Epoch [1938/2500], Train Loss: 0.6589, Train Accuracy: 71.55%, Test Loss: 0.9456, Test Accuracy: 64.56%\n",
      "Epoch [1939/2500], Train Loss: 0.6803, Train Accuracy: 69.42%, Test Loss: 0.9466, Test Accuracy: 64.56%\n",
      "Epoch [1940/2500], Train Loss: 0.6739, Train Accuracy: 72.40%, Test Loss: 0.9596, Test Accuracy: 64.56%\n",
      "Epoch [1941/2500], Train Loss: 0.6770, Train Accuracy: 69.84%, Test Loss: 0.9105, Test Accuracy: 64.56%\n",
      "Epoch [1942/2500], Train Loss: 0.6678, Train Accuracy: 70.98%, Test Loss: 0.9445, Test Accuracy: 64.56%\n",
      "Epoch [1943/2500], Train Loss: 0.6621, Train Accuracy: 70.41%, Test Loss: 0.9271, Test Accuracy: 64.56%\n",
      "Epoch [1944/2500], Train Loss: 0.6593, Train Accuracy: 72.97%, Test Loss: 0.9520, Test Accuracy: 64.56%\n",
      "Epoch [1945/2500], Train Loss: 0.6589, Train Accuracy: 70.84%, Test Loss: 0.9746, Test Accuracy: 64.56%\n",
      "Epoch [1946/2500], Train Loss: 0.6595, Train Accuracy: 73.40%, Test Loss: 0.9378, Test Accuracy: 65.82%\n",
      "Epoch [1947/2500], Train Loss: 0.6492, Train Accuracy: 72.26%, Test Loss: 0.9601, Test Accuracy: 64.56%\n",
      "Epoch [1948/2500], Train Loss: 0.6903, Train Accuracy: 70.70%, Test Loss: 0.9471, Test Accuracy: 64.56%\n",
      "Epoch [1949/2500], Train Loss: 0.6674, Train Accuracy: 69.56%, Test Loss: 0.9384, Test Accuracy: 64.56%\n",
      "Epoch [1950/2500], Train Loss: 0.6731, Train Accuracy: 70.70%, Test Loss: 0.9930, Test Accuracy: 64.56%\n",
      "Epoch [1951/2500], Train Loss: 0.6822, Train Accuracy: 68.42%, Test Loss: 0.9171, Test Accuracy: 65.82%\n",
      "Epoch [1952/2500], Train Loss: 0.6647, Train Accuracy: 72.26%, Test Loss: 0.9202, Test Accuracy: 65.82%\n",
      "Epoch [1953/2500], Train Loss: 0.6539, Train Accuracy: 71.69%, Test Loss: 0.9599, Test Accuracy: 64.56%\n",
      "Epoch [1954/2500], Train Loss: 0.6740, Train Accuracy: 71.69%, Test Loss: 0.9460, Test Accuracy: 64.56%\n",
      "Epoch [1955/2500], Train Loss: 0.6587, Train Accuracy: 70.70%, Test Loss: 0.9495, Test Accuracy: 65.82%\n",
      "Epoch [1956/2500], Train Loss: 0.6457, Train Accuracy: 70.55%, Test Loss: 0.9673, Test Accuracy: 64.56%\n",
      "Epoch [1957/2500], Train Loss: 0.6668, Train Accuracy: 71.98%, Test Loss: 0.9529, Test Accuracy: 64.56%\n",
      "Epoch [1958/2500], Train Loss: 0.6745, Train Accuracy: 70.27%, Test Loss: 0.9741, Test Accuracy: 64.56%\n",
      "Epoch [1959/2500], Train Loss: 0.6557, Train Accuracy: 73.12%, Test Loss: 0.9547, Test Accuracy: 64.56%\n",
      "Epoch [1960/2500], Train Loss: 0.6398, Train Accuracy: 70.27%, Test Loss: 0.9682, Test Accuracy: 64.56%\n",
      "Epoch [1961/2500], Train Loss: 0.6492, Train Accuracy: 73.83%, Test Loss: 0.9456, Test Accuracy: 64.56%\n",
      "Epoch [1962/2500], Train Loss: 0.6732, Train Accuracy: 70.84%, Test Loss: 0.9596, Test Accuracy: 65.82%\n",
      "Epoch [1963/2500], Train Loss: 0.6612, Train Accuracy: 70.70%, Test Loss: 0.9572, Test Accuracy: 65.82%\n",
      "Epoch [1964/2500], Train Loss: 0.6561, Train Accuracy: 71.98%, Test Loss: 0.9572, Test Accuracy: 65.82%\n",
      "Epoch [1965/2500], Train Loss: 0.6674, Train Accuracy: 71.98%, Test Loss: 0.9876, Test Accuracy: 63.29%\n",
      "Epoch [1966/2500], Train Loss: 0.6397, Train Accuracy: 72.55%, Test Loss: 0.9577, Test Accuracy: 64.56%\n",
      "Epoch [1967/2500], Train Loss: 0.6707, Train Accuracy: 70.98%, Test Loss: 1.0302, Test Accuracy: 64.56%\n",
      "Epoch [1968/2500], Train Loss: 0.6582, Train Accuracy: 71.83%, Test Loss: 0.9719, Test Accuracy: 64.56%\n",
      "Epoch [1969/2500], Train Loss: 0.6703, Train Accuracy: 70.13%, Test Loss: 0.9723, Test Accuracy: 64.56%\n",
      "Epoch [1970/2500], Train Loss: 0.6506, Train Accuracy: 72.97%, Test Loss: 0.9531, Test Accuracy: 64.56%\n",
      "Epoch [1971/2500], Train Loss: 0.6697, Train Accuracy: 70.70%, Test Loss: 0.9119, Test Accuracy: 65.82%\n",
      "Epoch [1972/2500], Train Loss: 0.6691, Train Accuracy: 71.98%, Test Loss: 0.9595, Test Accuracy: 65.82%\n",
      "Epoch [1973/2500], Train Loss: 0.6690, Train Accuracy: 71.12%, Test Loss: 0.9421, Test Accuracy: 64.56%\n",
      "Epoch [1974/2500], Train Loss: 0.6628, Train Accuracy: 70.98%, Test Loss: 0.9630, Test Accuracy: 64.56%\n",
      "Epoch [1975/2500], Train Loss: 0.6539, Train Accuracy: 71.27%, Test Loss: 0.9541, Test Accuracy: 64.56%\n",
      "Epoch [1976/2500], Train Loss: 0.6421, Train Accuracy: 71.98%, Test Loss: 0.9789, Test Accuracy: 64.56%\n",
      "Epoch [1977/2500], Train Loss: 0.6530, Train Accuracy: 70.98%, Test Loss: 0.9432, Test Accuracy: 64.56%\n",
      "Epoch [1978/2500], Train Loss: 0.6692, Train Accuracy: 68.99%, Test Loss: 0.9650, Test Accuracy: 65.82%\n",
      "Epoch [1979/2500], Train Loss: 0.6666, Train Accuracy: 71.98%, Test Loss: 0.9880, Test Accuracy: 65.82%\n",
      "Epoch [1980/2500], Train Loss: 0.6676, Train Accuracy: 71.27%, Test Loss: 0.9903, Test Accuracy: 65.82%\n",
      "Epoch [1981/2500], Train Loss: 0.6464, Train Accuracy: 73.12%, Test Loss: 0.9601, Test Accuracy: 64.56%\n",
      "Epoch [1982/2500], Train Loss: 0.6475, Train Accuracy: 71.98%, Test Loss: 0.9507, Test Accuracy: 64.56%\n",
      "Epoch [1983/2500], Train Loss: 0.6641, Train Accuracy: 72.40%, Test Loss: 0.9310, Test Accuracy: 64.56%\n",
      "Epoch [1984/2500], Train Loss: 0.6608, Train Accuracy: 70.55%, Test Loss: 0.9693, Test Accuracy: 64.56%\n",
      "Epoch [1985/2500], Train Loss: 0.6542, Train Accuracy: 69.84%, Test Loss: 0.9476, Test Accuracy: 64.56%\n",
      "Epoch [1986/2500], Train Loss: 0.6391, Train Accuracy: 72.83%, Test Loss: 0.9361, Test Accuracy: 64.56%\n",
      "Epoch [1987/2500], Train Loss: 0.6839, Train Accuracy: 69.99%, Test Loss: 0.9227, Test Accuracy: 64.56%\n",
      "Epoch [1988/2500], Train Loss: 0.6678, Train Accuracy: 71.41%, Test Loss: 0.9469, Test Accuracy: 64.56%\n",
      "Epoch [1989/2500], Train Loss: 0.6879, Train Accuracy: 70.13%, Test Loss: 1.0440, Test Accuracy: 63.29%\n",
      "Epoch [1990/2500], Train Loss: 0.6511, Train Accuracy: 71.55%, Test Loss: 0.9346, Test Accuracy: 64.56%\n",
      "Epoch [1991/2500], Train Loss: 0.6484, Train Accuracy: 72.69%, Test Loss: 0.9079, Test Accuracy: 65.82%\n",
      "Epoch [1992/2500], Train Loss: 0.6590, Train Accuracy: 70.98%, Test Loss: 0.9795, Test Accuracy: 64.56%\n",
      "Epoch [1993/2500], Train Loss: 0.6666, Train Accuracy: 69.84%, Test Loss: 0.9291, Test Accuracy: 65.82%\n",
      "Epoch [1994/2500], Train Loss: 0.6539, Train Accuracy: 72.26%, Test Loss: 0.9504, Test Accuracy: 64.56%\n",
      "Epoch [1995/2500], Train Loss: 0.6615, Train Accuracy: 68.99%, Test Loss: 1.0049, Test Accuracy: 63.29%\n",
      "Epoch [1996/2500], Train Loss: 0.6529, Train Accuracy: 71.98%, Test Loss: 0.9790, Test Accuracy: 64.56%\n",
      "Epoch [1997/2500], Train Loss: 0.6580, Train Accuracy: 70.98%, Test Loss: 0.9921, Test Accuracy: 64.56%\n",
      "Epoch [1998/2500], Train Loss: 0.6670, Train Accuracy: 69.84%, Test Loss: 0.9661, Test Accuracy: 64.56%\n",
      "Epoch [1999/2500], Train Loss: 0.6920, Train Accuracy: 70.41%, Test Loss: 1.0172, Test Accuracy: 63.29%\n",
      "Epoch [2000/2500], Train Loss: 0.6450, Train Accuracy: 72.26%, Test Loss: 0.9279, Test Accuracy: 64.56%\n",
      "Epoch [2001/2500], Train Loss: 0.6348, Train Accuracy: 71.55%, Test Loss: 0.9245, Test Accuracy: 64.56%\n",
      "Epoch [2002/2500], Train Loss: 0.6570, Train Accuracy: 72.97%, Test Loss: 0.9639, Test Accuracy: 64.56%\n",
      "Epoch [2003/2500], Train Loss: 0.6471, Train Accuracy: 70.98%, Test Loss: 0.9295, Test Accuracy: 65.82%\n",
      "Epoch [2004/2500], Train Loss: 0.6584, Train Accuracy: 69.13%, Test Loss: 0.9656, Test Accuracy: 64.56%\n",
      "Epoch [2005/2500], Train Loss: 0.6307, Train Accuracy: 71.83%, Test Loss: 1.0176, Test Accuracy: 65.82%\n",
      "Epoch [2006/2500], Train Loss: 0.6653, Train Accuracy: 70.41%, Test Loss: 0.9291, Test Accuracy: 65.82%\n",
      "Epoch [2007/2500], Train Loss: 0.6442, Train Accuracy: 71.27%, Test Loss: 0.9473, Test Accuracy: 64.56%\n",
      "Epoch [2008/2500], Train Loss: 0.6548, Train Accuracy: 69.70%, Test Loss: 0.9612, Test Accuracy: 64.56%\n",
      "Epoch [2009/2500], Train Loss: 0.6578, Train Accuracy: 73.12%, Test Loss: 0.9418, Test Accuracy: 64.56%\n",
      "Epoch [2010/2500], Train Loss: 0.6392, Train Accuracy: 73.12%, Test Loss: 0.9514, Test Accuracy: 65.82%\n",
      "Epoch [2011/2500], Train Loss: 0.6944, Train Accuracy: 69.70%, Test Loss: 1.0065, Test Accuracy: 65.82%\n",
      "Epoch [2012/2500], Train Loss: 0.6320, Train Accuracy: 71.83%, Test Loss: 0.9330, Test Accuracy: 65.82%\n",
      "Epoch [2013/2500], Train Loss: 0.6569, Train Accuracy: 70.13%, Test Loss: 0.9358, Test Accuracy: 65.82%\n",
      "Epoch [2014/2500], Train Loss: 0.6515, Train Accuracy: 72.40%, Test Loss: 0.9260, Test Accuracy: 65.82%\n",
      "Epoch [2015/2500], Train Loss: 0.6299, Train Accuracy: 72.12%, Test Loss: 1.0207, Test Accuracy: 64.56%\n",
      "Epoch [2016/2500], Train Loss: 0.6388, Train Accuracy: 73.26%, Test Loss: 0.9325, Test Accuracy: 64.56%\n",
      "Epoch [2017/2500], Train Loss: 0.6712, Train Accuracy: 70.55%, Test Loss: 0.9469, Test Accuracy: 64.56%\n",
      "Epoch [2018/2500], Train Loss: 0.6627, Train Accuracy: 70.41%, Test Loss: 0.9432, Test Accuracy: 65.82%\n",
      "Epoch [2019/2500], Train Loss: 0.6436, Train Accuracy: 72.12%, Test Loss: 0.9578, Test Accuracy: 65.82%\n",
      "Epoch [2020/2500], Train Loss: 0.6546, Train Accuracy: 71.83%, Test Loss: 0.9407, Test Accuracy: 65.82%\n",
      "Epoch [2021/2500], Train Loss: 0.6365, Train Accuracy: 71.41%, Test Loss: 1.0055, Test Accuracy: 63.29%\n",
      "Epoch [2022/2500], Train Loss: 0.6463, Train Accuracy: 72.69%, Test Loss: 0.9875, Test Accuracy: 63.29%\n",
      "Epoch [2023/2500], Train Loss: 0.6604, Train Accuracy: 72.12%, Test Loss: 0.9438, Test Accuracy: 65.82%\n",
      "Epoch [2024/2500], Train Loss: 0.6439, Train Accuracy: 71.69%, Test Loss: 0.9710, Test Accuracy: 64.56%\n",
      "Epoch [2025/2500], Train Loss: 0.6443, Train Accuracy: 71.41%, Test Loss: 0.9651, Test Accuracy: 65.82%\n",
      "Epoch [2026/2500], Train Loss: 0.6472, Train Accuracy: 71.83%, Test Loss: 0.9844, Test Accuracy: 64.56%\n",
      "Epoch [2027/2500], Train Loss: 0.6598, Train Accuracy: 70.55%, Test Loss: 0.9323, Test Accuracy: 64.56%\n",
      "Epoch [2028/2500], Train Loss: 0.6833, Train Accuracy: 71.98%, Test Loss: 0.9388, Test Accuracy: 64.56%\n",
      "Epoch [2029/2500], Train Loss: 0.6412, Train Accuracy: 72.55%, Test Loss: 0.9367, Test Accuracy: 64.56%\n",
      "Epoch [2030/2500], Train Loss: 0.6267, Train Accuracy: 74.11%, Test Loss: 0.9392, Test Accuracy: 64.56%\n",
      "Epoch [2031/2500], Train Loss: 0.6711, Train Accuracy: 72.26%, Test Loss: 0.9387, Test Accuracy: 64.56%\n",
      "Epoch [2032/2500], Train Loss: 0.6554, Train Accuracy: 70.98%, Test Loss: 0.9664, Test Accuracy: 65.82%\n",
      "Epoch [2033/2500], Train Loss: 0.6700, Train Accuracy: 71.55%, Test Loss: 0.9665, Test Accuracy: 64.56%\n",
      "Epoch [2034/2500], Train Loss: 0.6710, Train Accuracy: 69.70%, Test Loss: 0.9416, Test Accuracy: 64.56%\n",
      "Epoch [2035/2500], Train Loss: 0.6607, Train Accuracy: 71.27%, Test Loss: 0.9573, Test Accuracy: 64.56%\n",
      "Epoch [2036/2500], Train Loss: 0.6263, Train Accuracy: 71.41%, Test Loss: 0.9306, Test Accuracy: 64.56%\n",
      "Epoch [2037/2500], Train Loss: 0.6378, Train Accuracy: 71.69%, Test Loss: 0.9120, Test Accuracy: 65.82%\n",
      "Epoch [2038/2500], Train Loss: 0.6642, Train Accuracy: 70.84%, Test Loss: 0.9398, Test Accuracy: 65.82%\n",
      "Epoch [2039/2500], Train Loss: 0.6625, Train Accuracy: 70.55%, Test Loss: 0.9896, Test Accuracy: 65.82%\n",
      "Epoch [2040/2500], Train Loss: 0.6544, Train Accuracy: 72.97%, Test Loss: 0.9259, Test Accuracy: 65.82%\n",
      "Epoch [2041/2500], Train Loss: 0.6570, Train Accuracy: 71.69%, Test Loss: 0.9084, Test Accuracy: 67.09%\n",
      "Epoch [2042/2500], Train Loss: 0.6458, Train Accuracy: 72.69%, Test Loss: 0.9548, Test Accuracy: 64.56%\n",
      "Epoch [2043/2500], Train Loss: 0.6522, Train Accuracy: 72.83%, Test Loss: 0.9401, Test Accuracy: 65.82%\n",
      "Epoch [2044/2500], Train Loss: 0.6335, Train Accuracy: 73.40%, Test Loss: 0.9293, Test Accuracy: 65.82%\n",
      "Epoch [2045/2500], Train Loss: 0.6597, Train Accuracy: 71.98%, Test Loss: 0.9238, Test Accuracy: 65.82%\n",
      "Epoch [2046/2500], Train Loss: 0.6415, Train Accuracy: 71.83%, Test Loss: 0.9672, Test Accuracy: 64.56%\n",
      "Epoch [2047/2500], Train Loss: 0.6412, Train Accuracy: 70.55%, Test Loss: 0.9397, Test Accuracy: 64.56%\n",
      "Epoch [2048/2500], Train Loss: 0.6349, Train Accuracy: 73.83%, Test Loss: 0.9748, Test Accuracy: 64.56%\n",
      "Epoch [2049/2500], Train Loss: 0.6723, Train Accuracy: 73.26%, Test Loss: 0.9596, Test Accuracy: 63.29%\n",
      "Epoch [2050/2500], Train Loss: 0.6401, Train Accuracy: 73.97%, Test Loss: 0.9942, Test Accuracy: 64.56%\n",
      "Epoch [2051/2500], Train Loss: 0.6649, Train Accuracy: 71.12%, Test Loss: 0.9911, Test Accuracy: 63.29%\n",
      "Epoch [2052/2500], Train Loss: 0.6144, Train Accuracy: 73.40%, Test Loss: 0.9873, Test Accuracy: 60.76%\n",
      "Epoch [2053/2500], Train Loss: 0.6545, Train Accuracy: 72.12%, Test Loss: 0.9357, Test Accuracy: 64.56%\n",
      "Epoch [2054/2500], Train Loss: 0.6551, Train Accuracy: 72.26%, Test Loss: 0.9557, Test Accuracy: 64.56%\n",
      "Epoch [2055/2500], Train Loss: 0.6188, Train Accuracy: 71.27%, Test Loss: 0.9186, Test Accuracy: 65.82%\n",
      "Epoch [2056/2500], Train Loss: 0.6488, Train Accuracy: 70.70%, Test Loss: 0.9383, Test Accuracy: 64.56%\n",
      "Epoch [2057/2500], Train Loss: 0.6498, Train Accuracy: 73.26%, Test Loss: 0.9921, Test Accuracy: 63.29%\n",
      "Epoch [2058/2500], Train Loss: 0.6241, Train Accuracy: 73.12%, Test Loss: 0.9382, Test Accuracy: 64.56%\n",
      "Epoch [2059/2500], Train Loss: 0.6471, Train Accuracy: 72.97%, Test Loss: 0.9254, Test Accuracy: 64.56%\n",
      "Epoch [2060/2500], Train Loss: 0.6564, Train Accuracy: 71.98%, Test Loss: 0.9460, Test Accuracy: 65.82%\n",
      "Epoch [2061/2500], Train Loss: 0.6508, Train Accuracy: 73.40%, Test Loss: 0.9711, Test Accuracy: 65.82%\n",
      "Epoch [2062/2500], Train Loss: 0.6300, Train Accuracy: 72.69%, Test Loss: 0.9448, Test Accuracy: 65.82%\n",
      "Epoch [2063/2500], Train Loss: 0.6602, Train Accuracy: 69.56%, Test Loss: 0.9611, Test Accuracy: 65.82%\n",
      "Epoch [2064/2500], Train Loss: 0.6516, Train Accuracy: 71.27%, Test Loss: 0.9993, Test Accuracy: 65.82%\n",
      "Epoch [2065/2500], Train Loss: 0.6490, Train Accuracy: 69.84%, Test Loss: 0.9595, Test Accuracy: 64.56%\n",
      "Epoch [2066/2500], Train Loss: 0.6656, Train Accuracy: 73.40%, Test Loss: 0.9451, Test Accuracy: 64.56%\n",
      "Epoch [2067/2500], Train Loss: 0.6456, Train Accuracy: 73.26%, Test Loss: 0.9316, Test Accuracy: 64.56%\n",
      "Epoch [2068/2500], Train Loss: 0.6485, Train Accuracy: 73.12%, Test Loss: 0.9607, Test Accuracy: 65.82%\n",
      "Epoch [2069/2500], Train Loss: 0.6402, Train Accuracy: 71.12%, Test Loss: 0.9899, Test Accuracy: 63.29%\n",
      "Epoch [2070/2500], Train Loss: 0.6732, Train Accuracy: 70.13%, Test Loss: 0.9165, Test Accuracy: 64.56%\n",
      "Epoch [2071/2500], Train Loss: 0.6599, Train Accuracy: 71.27%, Test Loss: 0.9533, Test Accuracy: 65.82%\n",
      "Epoch [2072/2500], Train Loss: 0.6668, Train Accuracy: 71.69%, Test Loss: 0.9776, Test Accuracy: 65.82%\n",
      "Epoch [2073/2500], Train Loss: 0.6590, Train Accuracy: 71.55%, Test Loss: 0.9400, Test Accuracy: 65.82%\n",
      "Epoch [2074/2500], Train Loss: 0.6411, Train Accuracy: 71.12%, Test Loss: 0.9255, Test Accuracy: 65.82%\n",
      "Epoch [2075/2500], Train Loss: 0.6667, Train Accuracy: 71.12%, Test Loss: 0.9422, Test Accuracy: 65.82%\n",
      "Epoch [2076/2500], Train Loss: 0.6448, Train Accuracy: 71.41%, Test Loss: 0.9162, Test Accuracy: 67.09%\n",
      "Epoch [2077/2500], Train Loss: 0.6546, Train Accuracy: 71.55%, Test Loss: 0.9857, Test Accuracy: 64.56%\n",
      "Epoch [2078/2500], Train Loss: 0.6452, Train Accuracy: 71.98%, Test Loss: 0.9868, Test Accuracy: 64.56%\n",
      "Epoch [2079/2500], Train Loss: 0.6353, Train Accuracy: 71.55%, Test Loss: 0.9496, Test Accuracy: 65.82%\n",
      "Epoch [2080/2500], Train Loss: 0.6409, Train Accuracy: 71.12%, Test Loss: 0.9919, Test Accuracy: 64.56%\n",
      "Epoch [2081/2500], Train Loss: 0.6717, Train Accuracy: 69.99%, Test Loss: 0.9162, Test Accuracy: 65.82%\n",
      "Epoch [2082/2500], Train Loss: 0.6493, Train Accuracy: 71.41%, Test Loss: 0.9509, Test Accuracy: 64.56%\n",
      "Epoch [2083/2500], Train Loss: 0.6724, Train Accuracy: 71.27%, Test Loss: 0.9665, Test Accuracy: 63.29%\n",
      "Epoch [2084/2500], Train Loss: 0.6459, Train Accuracy: 72.40%, Test Loss: 0.9483, Test Accuracy: 64.56%\n",
      "Epoch [2085/2500], Train Loss: 0.6533, Train Accuracy: 70.70%, Test Loss: 0.9670, Test Accuracy: 64.56%\n",
      "Epoch [2086/2500], Train Loss: 0.6343, Train Accuracy: 72.26%, Test Loss: 0.9386, Test Accuracy: 64.56%\n",
      "Epoch [2087/2500], Train Loss: 0.6411, Train Accuracy: 71.83%, Test Loss: 0.9345, Test Accuracy: 64.56%\n",
      "Epoch [2088/2500], Train Loss: 0.6432, Train Accuracy: 71.55%, Test Loss: 0.9670, Test Accuracy: 65.82%\n",
      "Epoch [2089/2500], Train Loss: 0.6539, Train Accuracy: 70.55%, Test Loss: 0.9256, Test Accuracy: 64.56%\n",
      "Epoch [2090/2500], Train Loss: 0.6585, Train Accuracy: 71.55%, Test Loss: 0.9184, Test Accuracy: 65.82%\n",
      "Epoch [2091/2500], Train Loss: 0.6417, Train Accuracy: 72.26%, Test Loss: 0.9882, Test Accuracy: 65.82%\n",
      "Epoch [2092/2500], Train Loss: 0.6584, Train Accuracy: 72.40%, Test Loss: 0.9434, Test Accuracy: 64.56%\n",
      "Epoch [2093/2500], Train Loss: 0.6227, Train Accuracy: 72.40%, Test Loss: 0.9419, Test Accuracy: 65.82%\n",
      "Epoch [2094/2500], Train Loss: 0.6366, Train Accuracy: 72.12%, Test Loss: 0.9402, Test Accuracy: 65.82%\n",
      "Epoch [2095/2500], Train Loss: 0.6541, Train Accuracy: 70.13%, Test Loss: 0.9218, Test Accuracy: 64.56%\n",
      "Epoch [2096/2500], Train Loss: 0.6472, Train Accuracy: 69.84%, Test Loss: 0.9625, Test Accuracy: 64.56%\n",
      "Epoch [2097/2500], Train Loss: 0.6409, Train Accuracy: 70.55%, Test Loss: 0.9883, Test Accuracy: 65.82%\n",
      "Epoch [2098/2500], Train Loss: 0.6211, Train Accuracy: 73.97%, Test Loss: 0.9443, Test Accuracy: 64.56%\n",
      "Epoch [2099/2500], Train Loss: 0.6557, Train Accuracy: 70.13%, Test Loss: 1.0016, Test Accuracy: 65.82%\n",
      "Epoch [2100/2500], Train Loss: 0.6396, Train Accuracy: 72.83%, Test Loss: 0.9434, Test Accuracy: 65.82%\n",
      "Epoch [2101/2500], Train Loss: 0.6459, Train Accuracy: 71.69%, Test Loss: 0.9665, Test Accuracy: 64.56%\n",
      "Epoch [2102/2500], Train Loss: 0.6121, Train Accuracy: 72.97%, Test Loss: 0.9698, Test Accuracy: 64.56%\n",
      "Epoch [2103/2500], Train Loss: 0.6310, Train Accuracy: 73.54%, Test Loss: 0.9479, Test Accuracy: 64.56%\n",
      "Epoch [2104/2500], Train Loss: 0.6153, Train Accuracy: 71.27%, Test Loss: 0.9641, Test Accuracy: 64.56%\n",
      "Epoch [2105/2500], Train Loss: 0.6812, Train Accuracy: 70.27%, Test Loss: 0.9684, Test Accuracy: 64.56%\n",
      "Epoch [2106/2500], Train Loss: 0.6459, Train Accuracy: 69.42%, Test Loss: 1.0063, Test Accuracy: 63.29%\n",
      "Epoch [2107/2500], Train Loss: 0.6563, Train Accuracy: 71.83%, Test Loss: 0.9775, Test Accuracy: 64.56%\n",
      "Epoch [2108/2500], Train Loss: 0.6222, Train Accuracy: 73.68%, Test Loss: 0.9214, Test Accuracy: 64.56%\n",
      "Epoch [2109/2500], Train Loss: 0.6317, Train Accuracy: 73.26%, Test Loss: 0.9471, Test Accuracy: 64.56%\n",
      "Epoch [2110/2500], Train Loss: 0.6465, Train Accuracy: 71.27%, Test Loss: 0.9588, Test Accuracy: 64.56%\n",
      "Epoch [2111/2500], Train Loss: 0.6264, Train Accuracy: 73.40%, Test Loss: 0.9839, Test Accuracy: 65.82%\n",
      "Epoch [2112/2500], Train Loss: 0.6369, Train Accuracy: 72.83%, Test Loss: 0.9359, Test Accuracy: 64.56%\n",
      "Epoch [2113/2500], Train Loss: 0.6469, Train Accuracy: 70.84%, Test Loss: 0.9214, Test Accuracy: 65.82%\n",
      "Epoch [2114/2500], Train Loss: 0.6647, Train Accuracy: 71.83%, Test Loss: 0.9616, Test Accuracy: 64.56%\n",
      "Epoch [2115/2500], Train Loss: 0.6467, Train Accuracy: 71.27%, Test Loss: 0.9716, Test Accuracy: 64.56%\n",
      "Epoch [2116/2500], Train Loss: 0.6573, Train Accuracy: 71.12%, Test Loss: 0.9614, Test Accuracy: 64.56%\n",
      "Epoch [2117/2500], Train Loss: 0.6536, Train Accuracy: 70.27%, Test Loss: 0.9360, Test Accuracy: 64.56%\n",
      "Epoch [2118/2500], Train Loss: 0.6756, Train Accuracy: 71.12%, Test Loss: 0.9371, Test Accuracy: 65.82%\n",
      "Epoch [2119/2500], Train Loss: 0.6302, Train Accuracy: 72.55%, Test Loss: 0.9763, Test Accuracy: 64.56%\n",
      "Epoch [2120/2500], Train Loss: 0.6547, Train Accuracy: 72.40%, Test Loss: 1.0102, Test Accuracy: 63.29%\n",
      "Epoch [2121/2500], Train Loss: 0.6400, Train Accuracy: 72.12%, Test Loss: 0.9610, Test Accuracy: 64.56%\n",
      "Epoch [2122/2500], Train Loss: 0.6533, Train Accuracy: 71.12%, Test Loss: 0.9366, Test Accuracy: 64.56%\n",
      "Epoch [2123/2500], Train Loss: 0.6503, Train Accuracy: 69.84%, Test Loss: 0.9996, Test Accuracy: 63.29%\n",
      "Epoch [2124/2500], Train Loss: 0.6347, Train Accuracy: 71.69%, Test Loss: 0.9723, Test Accuracy: 64.56%\n",
      "Epoch [2125/2500], Train Loss: 0.6608, Train Accuracy: 70.84%, Test Loss: 0.9704, Test Accuracy: 64.56%\n",
      "Epoch [2126/2500], Train Loss: 0.6381, Train Accuracy: 70.98%, Test Loss: 1.0012, Test Accuracy: 63.29%\n",
      "Epoch [2127/2500], Train Loss: 0.6587, Train Accuracy: 71.69%, Test Loss: 0.9726, Test Accuracy: 63.29%\n",
      "Epoch [2128/2500], Train Loss: 0.6443, Train Accuracy: 72.55%, Test Loss: 1.0013, Test Accuracy: 62.03%\n",
      "Epoch [2129/2500], Train Loss: 0.6198, Train Accuracy: 74.11%, Test Loss: 0.9646, Test Accuracy: 64.56%\n",
      "Epoch [2130/2500], Train Loss: 0.6557, Train Accuracy: 71.55%, Test Loss: 0.9985, Test Accuracy: 63.29%\n",
      "Epoch [2131/2500], Train Loss: 0.6483, Train Accuracy: 72.55%, Test Loss: 0.9650, Test Accuracy: 64.56%\n",
      "Epoch [2132/2500], Train Loss: 0.6440, Train Accuracy: 71.83%, Test Loss: 0.9675, Test Accuracy: 65.82%\n",
      "Epoch [2133/2500], Train Loss: 0.6520, Train Accuracy: 73.26%, Test Loss: 0.8995, Test Accuracy: 67.09%\n",
      "Epoch [2134/2500], Train Loss: 0.6345, Train Accuracy: 72.40%, Test Loss: 0.9198, Test Accuracy: 64.56%\n",
      "Epoch [2135/2500], Train Loss: 0.6469, Train Accuracy: 71.83%, Test Loss: 0.9576, Test Accuracy: 64.56%\n",
      "Epoch [2136/2500], Train Loss: 0.6829, Train Accuracy: 70.27%, Test Loss: 0.9370, Test Accuracy: 64.56%\n",
      "Epoch [2137/2500], Train Loss: 0.6396, Train Accuracy: 72.69%, Test Loss: 0.9982, Test Accuracy: 64.56%\n",
      "Epoch [2138/2500], Train Loss: 0.6365, Train Accuracy: 73.12%, Test Loss: 0.9646, Test Accuracy: 64.56%\n",
      "Epoch [2139/2500], Train Loss: 0.6288, Train Accuracy: 74.82%, Test Loss: 0.9298, Test Accuracy: 67.09%\n",
      "Epoch [2140/2500], Train Loss: 0.6689, Train Accuracy: 71.98%, Test Loss: 0.9667, Test Accuracy: 63.29%\n",
      "Epoch [2141/2500], Train Loss: 0.6399, Train Accuracy: 71.98%, Test Loss: 1.0182, Test Accuracy: 63.29%\n",
      "Epoch [2142/2500], Train Loss: 0.6179, Train Accuracy: 73.40%, Test Loss: 0.9128, Test Accuracy: 65.82%\n",
      "Epoch [2143/2500], Train Loss: 0.6393, Train Accuracy: 72.12%, Test Loss: 0.9793, Test Accuracy: 64.56%\n",
      "Epoch [2144/2500], Train Loss: 0.6275, Train Accuracy: 73.68%, Test Loss: 0.9517, Test Accuracy: 65.82%\n",
      "Epoch [2145/2500], Train Loss: 0.6220, Train Accuracy: 72.26%, Test Loss: 0.9740, Test Accuracy: 65.82%\n",
      "Epoch [2146/2500], Train Loss: 0.6396, Train Accuracy: 71.98%, Test Loss: 0.9732, Test Accuracy: 64.56%\n",
      "Epoch [2147/2500], Train Loss: 0.6389, Train Accuracy: 73.26%, Test Loss: 0.9644, Test Accuracy: 64.56%\n",
      "Epoch [2148/2500], Train Loss: 0.6581, Train Accuracy: 70.55%, Test Loss: 0.8921, Test Accuracy: 67.09%\n",
      "Epoch [2149/2500], Train Loss: 0.6377, Train Accuracy: 70.27%, Test Loss: 0.9378, Test Accuracy: 64.56%\n",
      "Epoch [2150/2500], Train Loss: 0.6387, Train Accuracy: 72.26%, Test Loss: 0.9680, Test Accuracy: 65.82%\n",
      "Epoch [2151/2500], Train Loss: 0.6383, Train Accuracy: 71.83%, Test Loss: 0.9578, Test Accuracy: 65.82%\n",
      "Epoch [2152/2500], Train Loss: 0.6488, Train Accuracy: 71.55%, Test Loss: 0.9392, Test Accuracy: 64.56%\n",
      "Epoch [2153/2500], Train Loss: 0.6843, Train Accuracy: 69.13%, Test Loss: 0.9298, Test Accuracy: 65.82%\n",
      "Epoch [2154/2500], Train Loss: 0.6358, Train Accuracy: 72.12%, Test Loss: 0.9519, Test Accuracy: 64.56%\n",
      "Epoch [2155/2500], Train Loss: 0.6365, Train Accuracy: 74.40%, Test Loss: 0.9362, Test Accuracy: 65.82%\n",
      "Epoch [2156/2500], Train Loss: 0.6377, Train Accuracy: 70.98%, Test Loss: 0.9141, Test Accuracy: 67.09%\n",
      "Epoch [2157/2500], Train Loss: 0.6362, Train Accuracy: 72.55%, Test Loss: 0.9899, Test Accuracy: 64.56%\n",
      "Epoch [2158/2500], Train Loss: 0.6423, Train Accuracy: 72.40%, Test Loss: 0.9722, Test Accuracy: 65.82%\n",
      "Epoch [2159/2500], Train Loss: 0.6410, Train Accuracy: 70.98%, Test Loss: 0.9393, Test Accuracy: 65.82%\n",
      "Epoch [2160/2500], Train Loss: 0.6516, Train Accuracy: 73.12%, Test Loss: 0.9628, Test Accuracy: 64.56%\n",
      "Epoch [2161/2500], Train Loss: 0.6379, Train Accuracy: 72.12%, Test Loss: 0.9927, Test Accuracy: 65.82%\n",
      "Epoch [2162/2500], Train Loss: 0.6456, Train Accuracy: 71.55%, Test Loss: 0.9873, Test Accuracy: 63.29%\n",
      "Epoch [2163/2500], Train Loss: 0.6200, Train Accuracy: 74.68%, Test Loss: 0.9576, Test Accuracy: 65.82%\n",
      "Epoch [2164/2500], Train Loss: 0.6290, Train Accuracy: 73.26%, Test Loss: 0.9470, Test Accuracy: 65.82%\n",
      "Epoch [2165/2500], Train Loss: 0.6515, Train Accuracy: 70.84%, Test Loss: 0.9458, Test Accuracy: 64.56%\n",
      "Epoch [2166/2500], Train Loss: 0.6341, Train Accuracy: 73.68%, Test Loss: 0.9579, Test Accuracy: 64.56%\n",
      "Epoch [2167/2500], Train Loss: 0.6336, Train Accuracy: 71.69%, Test Loss: 0.9502, Test Accuracy: 65.82%\n",
      "Epoch [2168/2500], Train Loss: 0.6433, Train Accuracy: 73.40%, Test Loss: 0.9769, Test Accuracy: 64.56%\n",
      "Epoch [2169/2500], Train Loss: 0.6666, Train Accuracy: 69.70%, Test Loss: 0.9339, Test Accuracy: 65.82%\n",
      "Epoch [2170/2500], Train Loss: 0.6324, Train Accuracy: 74.25%, Test Loss: 0.9734, Test Accuracy: 64.56%\n",
      "Epoch [2171/2500], Train Loss: 0.6367, Train Accuracy: 73.68%, Test Loss: 0.9487, Test Accuracy: 64.56%\n",
      "Epoch [2172/2500], Train Loss: 0.6332, Train Accuracy: 72.40%, Test Loss: 0.9798, Test Accuracy: 64.56%\n",
      "Epoch [2173/2500], Train Loss: 0.6435, Train Accuracy: 72.26%, Test Loss: 0.9807, Test Accuracy: 64.56%\n",
      "Epoch [2174/2500], Train Loss: 0.6145, Train Accuracy: 73.54%, Test Loss: 0.9463, Test Accuracy: 64.56%\n",
      "Epoch [2175/2500], Train Loss: 0.6510, Train Accuracy: 71.83%, Test Loss: 0.9414, Test Accuracy: 64.56%\n",
      "Epoch [2176/2500], Train Loss: 0.6282, Train Accuracy: 73.68%, Test Loss: 0.9582, Test Accuracy: 64.56%\n",
      "Epoch [2177/2500], Train Loss: 0.6418, Train Accuracy: 72.83%, Test Loss: 0.9631, Test Accuracy: 65.82%\n",
      "Epoch [2178/2500], Train Loss: 0.6360, Train Accuracy: 71.27%, Test Loss: 0.9563, Test Accuracy: 64.56%\n",
      "Epoch [2179/2500], Train Loss: 0.6458, Train Accuracy: 71.27%, Test Loss: 0.9207, Test Accuracy: 64.56%\n",
      "Epoch [2180/2500], Train Loss: 0.6389, Train Accuracy: 70.55%, Test Loss: 0.9185, Test Accuracy: 67.09%\n",
      "Epoch [2181/2500], Train Loss: 0.6192, Train Accuracy: 74.68%, Test Loss: 0.9687, Test Accuracy: 65.82%\n",
      "Epoch [2182/2500], Train Loss: 0.6600, Train Accuracy: 71.41%, Test Loss: 0.9208, Test Accuracy: 65.82%\n",
      "Epoch [2183/2500], Train Loss: 0.6224, Train Accuracy: 73.40%, Test Loss: 0.9024, Test Accuracy: 67.09%\n",
      "Epoch [2184/2500], Train Loss: 0.6424, Train Accuracy: 72.83%, Test Loss: 0.9174, Test Accuracy: 65.82%\n",
      "Epoch [2185/2500], Train Loss: 0.6367, Train Accuracy: 72.40%, Test Loss: 0.8970, Test Accuracy: 67.09%\n",
      "Epoch [2186/2500], Train Loss: 0.6544, Train Accuracy: 72.97%, Test Loss: 0.9584, Test Accuracy: 65.82%\n",
      "Epoch [2187/2500], Train Loss: 0.6206, Train Accuracy: 73.40%, Test Loss: 0.9592, Test Accuracy: 64.56%\n",
      "Epoch [2188/2500], Train Loss: 0.6506, Train Accuracy: 70.84%, Test Loss: 0.9279, Test Accuracy: 65.82%\n",
      "Epoch [2189/2500], Train Loss: 0.6503, Train Accuracy: 71.98%, Test Loss: 0.9344, Test Accuracy: 67.09%\n",
      "Epoch [2190/2500], Train Loss: 0.6467, Train Accuracy: 71.69%, Test Loss: 0.9364, Test Accuracy: 67.09%\n",
      "Epoch [2191/2500], Train Loss: 0.6248, Train Accuracy: 72.69%, Test Loss: 0.9529, Test Accuracy: 67.09%\n",
      "Epoch [2192/2500], Train Loss: 0.6318, Train Accuracy: 72.69%, Test Loss: 0.9695, Test Accuracy: 65.82%\n",
      "Epoch [2193/2500], Train Loss: 0.6400, Train Accuracy: 72.55%, Test Loss: 0.9369, Test Accuracy: 65.82%\n",
      "Epoch [2194/2500], Train Loss: 0.6412, Train Accuracy: 72.97%, Test Loss: 0.9563, Test Accuracy: 65.82%\n",
      "Epoch [2195/2500], Train Loss: 0.6470, Train Accuracy: 71.83%, Test Loss: 0.9567, Test Accuracy: 65.82%\n",
      "Epoch [2196/2500], Train Loss: 0.6556, Train Accuracy: 72.40%, Test Loss: 0.9331, Test Accuracy: 65.82%\n",
      "Epoch [2197/2500], Train Loss: 0.6408, Train Accuracy: 72.55%, Test Loss: 0.9678, Test Accuracy: 64.56%\n",
      "Epoch [2198/2500], Train Loss: 0.6321, Train Accuracy: 73.12%, Test Loss: 0.9730, Test Accuracy: 64.56%\n",
      "Epoch [2199/2500], Train Loss: 0.6342, Train Accuracy: 71.55%, Test Loss: 0.9386, Test Accuracy: 64.56%\n",
      "Epoch [2200/2500], Train Loss: 0.6610, Train Accuracy: 70.70%, Test Loss: 0.9722, Test Accuracy: 65.82%\n",
      "Epoch [2201/2500], Train Loss: 0.6274, Train Accuracy: 74.11%, Test Loss: 0.9639, Test Accuracy: 64.56%\n",
      "Epoch [2202/2500], Train Loss: 0.6471, Train Accuracy: 71.41%, Test Loss: 0.9332, Test Accuracy: 67.09%\n",
      "Epoch [2203/2500], Train Loss: 0.6543, Train Accuracy: 70.98%, Test Loss: 0.9808, Test Accuracy: 64.56%\n",
      "Epoch [2204/2500], Train Loss: 0.6488, Train Accuracy: 72.40%, Test Loss: 0.9211, Test Accuracy: 67.09%\n",
      "Epoch [2205/2500], Train Loss: 0.6029, Train Accuracy: 72.83%, Test Loss: 0.9365, Test Accuracy: 67.09%\n",
      "Epoch [2206/2500], Train Loss: 0.6437, Train Accuracy: 72.83%, Test Loss: 0.9763, Test Accuracy: 65.82%\n",
      "Epoch [2207/2500], Train Loss: 0.6268, Train Accuracy: 72.69%, Test Loss: 0.9649, Test Accuracy: 65.82%\n",
      "Epoch [2208/2500], Train Loss: 0.6364, Train Accuracy: 73.26%, Test Loss: 0.9159, Test Accuracy: 65.82%\n",
      "Epoch [2209/2500], Train Loss: 0.6426, Train Accuracy: 72.26%, Test Loss: 0.9376, Test Accuracy: 64.56%\n",
      "Epoch [2210/2500], Train Loss: 0.6421, Train Accuracy: 71.83%, Test Loss: 0.9484, Test Accuracy: 65.82%\n",
      "Epoch [2211/2500], Train Loss: 0.6328, Train Accuracy: 73.54%, Test Loss: 0.9542, Test Accuracy: 65.82%\n",
      "Epoch [2212/2500], Train Loss: 0.6354, Train Accuracy: 72.97%, Test Loss: 0.9879, Test Accuracy: 64.56%\n",
      "Epoch [2213/2500], Train Loss: 0.6169, Train Accuracy: 74.25%, Test Loss: 0.9674, Test Accuracy: 64.56%\n",
      "Epoch [2214/2500], Train Loss: 0.6364, Train Accuracy: 71.83%, Test Loss: 1.0136, Test Accuracy: 63.29%\n",
      "Epoch [2215/2500], Train Loss: 0.6283, Train Accuracy: 72.83%, Test Loss: 0.9106, Test Accuracy: 65.82%\n",
      "Epoch [2216/2500], Train Loss: 0.6357, Train Accuracy: 73.12%, Test Loss: 0.9110, Test Accuracy: 65.82%\n",
      "Epoch [2217/2500], Train Loss: 0.6492, Train Accuracy: 72.26%, Test Loss: 0.9724, Test Accuracy: 64.56%\n",
      "Epoch [2218/2500], Train Loss: 0.6386, Train Accuracy: 72.97%, Test Loss: 1.0071, Test Accuracy: 64.56%\n",
      "Epoch [2219/2500], Train Loss: 0.6454, Train Accuracy: 72.97%, Test Loss: 0.9937, Test Accuracy: 63.29%\n",
      "Epoch [2220/2500], Train Loss: 0.6522, Train Accuracy: 73.40%, Test Loss: 0.9484, Test Accuracy: 65.82%\n",
      "Epoch [2221/2500], Train Loss: 0.6297, Train Accuracy: 75.11%, Test Loss: 0.9098, Test Accuracy: 65.82%\n",
      "Epoch [2222/2500], Train Loss: 0.6151, Train Accuracy: 72.55%, Test Loss: 0.9630, Test Accuracy: 64.56%\n",
      "Epoch [2223/2500], Train Loss: 0.6113, Train Accuracy: 74.96%, Test Loss: 0.9951, Test Accuracy: 64.56%\n",
      "Epoch [2224/2500], Train Loss: 0.6395, Train Accuracy: 72.40%, Test Loss: 1.0039, Test Accuracy: 64.56%\n",
      "Epoch [2225/2500], Train Loss: 0.6171, Train Accuracy: 74.96%, Test Loss: 1.0019, Test Accuracy: 64.56%\n",
      "Epoch [2226/2500], Train Loss: 0.6577, Train Accuracy: 71.98%, Test Loss: 0.9645, Test Accuracy: 64.56%\n",
      "Epoch [2227/2500], Train Loss: 0.6306, Train Accuracy: 72.55%, Test Loss: 0.9566, Test Accuracy: 64.56%\n",
      "Epoch [2228/2500], Train Loss: 0.6362, Train Accuracy: 73.40%, Test Loss: 0.9682, Test Accuracy: 63.29%\n",
      "Epoch [2229/2500], Train Loss: 0.6316, Train Accuracy: 73.26%, Test Loss: 0.9742, Test Accuracy: 65.82%\n",
      "Epoch [2230/2500], Train Loss: 0.6467, Train Accuracy: 70.98%, Test Loss: 0.9867, Test Accuracy: 64.56%\n",
      "Epoch [2231/2500], Train Loss: 0.6417, Train Accuracy: 72.83%, Test Loss: 1.0003, Test Accuracy: 64.56%\n",
      "Epoch [2232/2500], Train Loss: 0.6439, Train Accuracy: 73.68%, Test Loss: 0.9818, Test Accuracy: 64.56%\n",
      "Epoch [2233/2500], Train Loss: 0.6176, Train Accuracy: 73.40%, Test Loss: 0.9431, Test Accuracy: 65.82%\n",
      "Epoch [2234/2500], Train Loss: 0.6268, Train Accuracy: 73.68%, Test Loss: 0.9614, Test Accuracy: 64.56%\n",
      "Epoch [2235/2500], Train Loss: 0.6265, Train Accuracy: 72.97%, Test Loss: 0.9441, Test Accuracy: 65.82%\n",
      "Epoch [2236/2500], Train Loss: 0.6369, Train Accuracy: 71.83%, Test Loss: 0.9581, Test Accuracy: 63.29%\n",
      "Epoch [2237/2500], Train Loss: 0.6749, Train Accuracy: 70.84%, Test Loss: 0.9430, Test Accuracy: 64.56%\n",
      "Epoch [2238/2500], Train Loss: 0.6245, Train Accuracy: 74.11%, Test Loss: 0.9878, Test Accuracy: 65.82%\n",
      "Epoch [2239/2500], Train Loss: 0.6294, Train Accuracy: 72.55%, Test Loss: 0.9438, Test Accuracy: 64.56%\n",
      "Epoch [2240/2500], Train Loss: 0.6186, Train Accuracy: 72.97%, Test Loss: 0.9192, Test Accuracy: 65.82%\n",
      "Epoch [2241/2500], Train Loss: 0.6301, Train Accuracy: 73.68%, Test Loss: 0.9798, Test Accuracy: 64.56%\n",
      "Epoch [2242/2500], Train Loss: 0.6515, Train Accuracy: 72.26%, Test Loss: 0.9367, Test Accuracy: 65.82%\n",
      "Epoch [2243/2500], Train Loss: 0.6387, Train Accuracy: 72.40%, Test Loss: 0.9567, Test Accuracy: 65.82%\n",
      "Epoch [2244/2500], Train Loss: 0.6412, Train Accuracy: 72.26%, Test Loss: 0.9752, Test Accuracy: 64.56%\n",
      "Epoch [2245/2500], Train Loss: 0.6369, Train Accuracy: 71.98%, Test Loss: 0.9723, Test Accuracy: 64.56%\n",
      "Epoch [2246/2500], Train Loss: 0.6093, Train Accuracy: 73.40%, Test Loss: 0.9342, Test Accuracy: 65.82%\n",
      "Epoch [2247/2500], Train Loss: 0.6436, Train Accuracy: 72.69%, Test Loss: 0.9832, Test Accuracy: 64.56%\n",
      "Epoch [2248/2500], Train Loss: 0.6312, Train Accuracy: 72.83%, Test Loss: 0.9150, Test Accuracy: 64.56%\n",
      "Epoch [2249/2500], Train Loss: 0.6282, Train Accuracy: 73.54%, Test Loss: 0.9802, Test Accuracy: 64.56%\n",
      "Epoch [2250/2500], Train Loss: 0.6114, Train Accuracy: 73.40%, Test Loss: 0.9517, Test Accuracy: 65.82%\n",
      "Epoch [2251/2500], Train Loss: 0.6445, Train Accuracy: 70.98%, Test Loss: 0.9480, Test Accuracy: 64.56%\n",
      "Epoch [2252/2500], Train Loss: 0.6268, Train Accuracy: 72.69%, Test Loss: 1.0404, Test Accuracy: 62.03%\n",
      "Epoch [2253/2500], Train Loss: 0.6660, Train Accuracy: 71.41%, Test Loss: 1.0080, Test Accuracy: 63.29%\n",
      "Epoch [2254/2500], Train Loss: 0.6312, Train Accuracy: 73.83%, Test Loss: 0.9590, Test Accuracy: 64.56%\n",
      "Epoch [2255/2500], Train Loss: 0.6335, Train Accuracy: 73.54%, Test Loss: 0.9588, Test Accuracy: 64.56%\n",
      "Epoch [2256/2500], Train Loss: 0.6420, Train Accuracy: 72.83%, Test Loss: 0.9786, Test Accuracy: 63.29%\n",
      "Epoch [2257/2500], Train Loss: 0.6379, Train Accuracy: 71.98%, Test Loss: 0.9840, Test Accuracy: 64.56%\n",
      "Epoch [2258/2500], Train Loss: 0.6087, Train Accuracy: 71.98%, Test Loss: 0.9443, Test Accuracy: 64.56%\n",
      "Epoch [2259/2500], Train Loss: 0.6500, Train Accuracy: 72.12%, Test Loss: 0.9035, Test Accuracy: 65.82%\n",
      "Epoch [2260/2500], Train Loss: 0.6280, Train Accuracy: 74.11%, Test Loss: 0.9448, Test Accuracy: 65.82%\n",
      "Epoch [2261/2500], Train Loss: 0.6007, Train Accuracy: 73.68%, Test Loss: 0.9376, Test Accuracy: 65.82%\n",
      "Epoch [2262/2500], Train Loss: 0.6188, Train Accuracy: 74.25%, Test Loss: 0.9297, Test Accuracy: 65.82%\n",
      "Epoch [2263/2500], Train Loss: 0.6601, Train Accuracy: 70.84%, Test Loss: 0.9266, Test Accuracy: 64.56%\n",
      "Epoch [2264/2500], Train Loss: 0.6253, Train Accuracy: 73.26%, Test Loss: 0.9879, Test Accuracy: 64.56%\n",
      "Epoch [2265/2500], Train Loss: 0.6617, Train Accuracy: 70.27%, Test Loss: 0.9582, Test Accuracy: 64.56%\n",
      "Epoch [2266/2500], Train Loss: 0.6204, Train Accuracy: 73.40%, Test Loss: 1.0184, Test Accuracy: 64.56%\n",
      "Epoch [2267/2500], Train Loss: 0.6264, Train Accuracy: 73.83%, Test Loss: 0.9594, Test Accuracy: 64.56%\n",
      "Epoch [2268/2500], Train Loss: 0.6202, Train Accuracy: 72.12%, Test Loss: 0.9810, Test Accuracy: 64.56%\n",
      "Epoch [2269/2500], Train Loss: 0.6509, Train Accuracy: 71.69%, Test Loss: 0.9783, Test Accuracy: 65.82%\n",
      "Epoch [2270/2500], Train Loss: 0.6324, Train Accuracy: 71.55%, Test Loss: 0.9848, Test Accuracy: 64.56%\n",
      "Epoch [2271/2500], Train Loss: 0.6115, Train Accuracy: 75.39%, Test Loss: 1.0138, Test Accuracy: 64.56%\n",
      "Epoch [2272/2500], Train Loss: 0.6285, Train Accuracy: 72.97%, Test Loss: 0.9654, Test Accuracy: 64.56%\n",
      "Epoch [2273/2500], Train Loss: 0.6392, Train Accuracy: 73.12%, Test Loss: 1.0298, Test Accuracy: 64.56%\n",
      "Epoch [2274/2500], Train Loss: 0.6261, Train Accuracy: 73.12%, Test Loss: 0.9464, Test Accuracy: 65.82%\n",
      "Epoch [2275/2500], Train Loss: 0.6360, Train Accuracy: 73.26%, Test Loss: 0.9906, Test Accuracy: 63.29%\n",
      "Epoch [2276/2500], Train Loss: 0.6189, Train Accuracy: 74.25%, Test Loss: 0.9964, Test Accuracy: 64.56%\n",
      "Epoch [2277/2500], Train Loss: 0.6462, Train Accuracy: 71.98%, Test Loss: 0.9367, Test Accuracy: 65.82%\n",
      "Epoch [2278/2500], Train Loss: 0.6343, Train Accuracy: 72.26%, Test Loss: 0.9518, Test Accuracy: 65.82%\n",
      "Epoch [2279/2500], Train Loss: 0.6115, Train Accuracy: 73.68%, Test Loss: 0.9392, Test Accuracy: 64.56%\n",
      "Epoch [2280/2500], Train Loss: 0.6384, Train Accuracy: 73.12%, Test Loss: 0.9547, Test Accuracy: 64.56%\n",
      "Epoch [2281/2500], Train Loss: 0.6320, Train Accuracy: 72.83%, Test Loss: 0.9377, Test Accuracy: 64.56%\n",
      "Epoch [2282/2500], Train Loss: 0.6390, Train Accuracy: 72.55%, Test Loss: 0.9767, Test Accuracy: 67.09%\n",
      "Epoch [2283/2500], Train Loss: 0.6250, Train Accuracy: 73.26%, Test Loss: 0.9993, Test Accuracy: 64.56%\n",
      "Epoch [2284/2500], Train Loss: 0.6250, Train Accuracy: 72.83%, Test Loss: 0.9527, Test Accuracy: 65.82%\n",
      "Epoch [2285/2500], Train Loss: 0.6295, Train Accuracy: 72.69%, Test Loss: 1.0195, Test Accuracy: 64.56%\n",
      "Epoch [2286/2500], Train Loss: 0.6543, Train Accuracy: 70.84%, Test Loss: 0.9195, Test Accuracy: 65.82%\n",
      "Epoch [2287/2500], Train Loss: 0.6255, Train Accuracy: 74.11%, Test Loss: 0.9525, Test Accuracy: 65.82%\n",
      "Epoch [2288/2500], Train Loss: 0.6154, Train Accuracy: 74.11%, Test Loss: 0.9791, Test Accuracy: 64.56%\n",
      "Epoch [2289/2500], Train Loss: 0.6154, Train Accuracy: 73.68%, Test Loss: 0.9809, Test Accuracy: 64.56%\n",
      "Epoch [2290/2500], Train Loss: 0.6109, Train Accuracy: 73.40%, Test Loss: 0.9804, Test Accuracy: 64.56%\n",
      "Epoch [2291/2500], Train Loss: 0.6411, Train Accuracy: 73.26%, Test Loss: 0.9281, Test Accuracy: 64.56%\n",
      "Epoch [2292/2500], Train Loss: 0.6662, Train Accuracy: 69.70%, Test Loss: 0.9241, Test Accuracy: 65.82%\n",
      "Epoch [2293/2500], Train Loss: 0.6316, Train Accuracy: 71.69%, Test Loss: 0.9325, Test Accuracy: 65.82%\n",
      "Epoch [2294/2500], Train Loss: 0.6575, Train Accuracy: 71.27%, Test Loss: 0.9358, Test Accuracy: 65.82%\n",
      "Epoch [2295/2500], Train Loss: 0.6408, Train Accuracy: 70.13%, Test Loss: 0.9822, Test Accuracy: 65.82%\n",
      "Epoch [2296/2500], Train Loss: 0.6394, Train Accuracy: 71.98%, Test Loss: 0.9441, Test Accuracy: 65.82%\n",
      "Epoch [2297/2500], Train Loss: 0.6217, Train Accuracy: 73.40%, Test Loss: 0.9564, Test Accuracy: 64.56%\n",
      "Epoch [2298/2500], Train Loss: 0.6310, Train Accuracy: 71.27%, Test Loss: 0.9428, Test Accuracy: 64.56%\n",
      "Epoch [2299/2500], Train Loss: 0.6369, Train Accuracy: 73.12%, Test Loss: 1.0001, Test Accuracy: 64.56%\n",
      "Epoch [2300/2500], Train Loss: 0.6002, Train Accuracy: 72.69%, Test Loss: 0.9873, Test Accuracy: 64.56%\n",
      "Epoch [2301/2500], Train Loss: 0.6300, Train Accuracy: 73.97%, Test Loss: 0.9862, Test Accuracy: 63.29%\n",
      "Epoch [2302/2500], Train Loss: 0.6325, Train Accuracy: 73.54%, Test Loss: 1.0012, Test Accuracy: 65.82%\n",
      "Epoch [2303/2500], Train Loss: 0.6117, Train Accuracy: 73.68%, Test Loss: 0.9453, Test Accuracy: 64.56%\n",
      "Epoch [2304/2500], Train Loss: 0.6181, Train Accuracy: 72.40%, Test Loss: 0.9703, Test Accuracy: 64.56%\n",
      "Epoch [2305/2500], Train Loss: 0.6037, Train Accuracy: 74.54%, Test Loss: 1.0038, Test Accuracy: 64.56%\n",
      "Epoch [2306/2500], Train Loss: 0.6260, Train Accuracy: 73.40%, Test Loss: 0.9461, Test Accuracy: 64.56%\n",
      "Epoch [2307/2500], Train Loss: 0.6335, Train Accuracy: 72.97%, Test Loss: 0.9814, Test Accuracy: 64.56%\n",
      "Epoch [2308/2500], Train Loss: 0.6234, Train Accuracy: 71.69%, Test Loss: 0.9603, Test Accuracy: 64.56%\n",
      "Epoch [2309/2500], Train Loss: 0.6230, Train Accuracy: 73.68%, Test Loss: 0.9851, Test Accuracy: 64.56%\n",
      "Epoch [2310/2500], Train Loss: 0.6179, Train Accuracy: 74.40%, Test Loss: 0.9892, Test Accuracy: 64.56%\n",
      "Epoch [2311/2500], Train Loss: 0.6358, Train Accuracy: 72.55%, Test Loss: 0.9544, Test Accuracy: 64.56%\n",
      "Epoch [2312/2500], Train Loss: 0.6189, Train Accuracy: 73.97%, Test Loss: 0.9358, Test Accuracy: 65.82%\n",
      "Epoch [2313/2500], Train Loss: 0.6365, Train Accuracy: 73.12%, Test Loss: 0.9615, Test Accuracy: 64.56%\n",
      "Epoch [2314/2500], Train Loss: 0.6156, Train Accuracy: 72.83%, Test Loss: 0.9662, Test Accuracy: 64.56%\n",
      "Epoch [2315/2500], Train Loss: 0.6270, Train Accuracy: 71.69%, Test Loss: 0.9503, Test Accuracy: 67.09%\n",
      "Epoch [2316/2500], Train Loss: 0.6363, Train Accuracy: 73.83%, Test Loss: 0.9802, Test Accuracy: 64.56%\n",
      "Epoch [2317/2500], Train Loss: 0.6422, Train Accuracy: 71.27%, Test Loss: 0.9673, Test Accuracy: 64.56%\n",
      "Epoch [2318/2500], Train Loss: 0.6290, Train Accuracy: 69.99%, Test Loss: 0.9550, Test Accuracy: 64.56%\n",
      "Epoch [2319/2500], Train Loss: 0.6333, Train Accuracy: 73.12%, Test Loss: 0.9797, Test Accuracy: 65.82%\n",
      "Epoch [2320/2500], Train Loss: 0.6512, Train Accuracy: 74.25%, Test Loss: 0.9680, Test Accuracy: 64.56%\n",
      "Epoch [2321/2500], Train Loss: 0.6171, Train Accuracy: 73.97%, Test Loss: 0.9564, Test Accuracy: 63.29%\n",
      "Epoch [2322/2500], Train Loss: 0.6167, Train Accuracy: 74.11%, Test Loss: 0.9611, Test Accuracy: 65.82%\n",
      "Epoch [2323/2500], Train Loss: 0.6312, Train Accuracy: 72.26%, Test Loss: 0.9972, Test Accuracy: 64.56%\n",
      "Epoch [2324/2500], Train Loss: 0.6214, Train Accuracy: 74.40%, Test Loss: 1.0009, Test Accuracy: 64.56%\n",
      "Epoch [2325/2500], Train Loss: 0.6001, Train Accuracy: 74.54%, Test Loss: 0.9780, Test Accuracy: 64.56%\n",
      "Epoch [2326/2500], Train Loss: 0.6365, Train Accuracy: 73.12%, Test Loss: 0.9852, Test Accuracy: 64.56%\n",
      "Epoch [2327/2500], Train Loss: 0.6025, Train Accuracy: 74.96%, Test Loss: 0.9620, Test Accuracy: 65.82%\n",
      "Epoch [2328/2500], Train Loss: 0.6113, Train Accuracy: 75.11%, Test Loss: 0.9870, Test Accuracy: 67.09%\n",
      "Epoch [2329/2500], Train Loss: 0.6314, Train Accuracy: 72.26%, Test Loss: 0.9218, Test Accuracy: 67.09%\n",
      "Epoch [2330/2500], Train Loss: 0.6482, Train Accuracy: 72.69%, Test Loss: 1.0085, Test Accuracy: 65.82%\n",
      "Epoch [2331/2500], Train Loss: 0.6145, Train Accuracy: 72.97%, Test Loss: 0.9615, Test Accuracy: 65.82%\n",
      "Epoch [2332/2500], Train Loss: 0.6310, Train Accuracy: 71.98%, Test Loss: 0.9701, Test Accuracy: 65.82%\n",
      "Epoch [2333/2500], Train Loss: 0.6203, Train Accuracy: 72.40%, Test Loss: 0.9695, Test Accuracy: 64.56%\n",
      "Epoch [2334/2500], Train Loss: 0.6178, Train Accuracy: 74.25%, Test Loss: 0.9806, Test Accuracy: 65.82%\n",
      "Epoch [2335/2500], Train Loss: 0.6196, Train Accuracy: 73.40%, Test Loss: 0.9423, Test Accuracy: 65.82%\n",
      "Epoch [2336/2500], Train Loss: 0.5963, Train Accuracy: 73.68%, Test Loss: 0.9436, Test Accuracy: 65.82%\n",
      "Epoch [2337/2500], Train Loss: 0.6239, Train Accuracy: 73.54%, Test Loss: 0.9535, Test Accuracy: 64.56%\n",
      "Epoch [2338/2500], Train Loss: 0.6050, Train Accuracy: 73.40%, Test Loss: 0.9427, Test Accuracy: 65.82%\n",
      "Epoch [2339/2500], Train Loss: 0.6534, Train Accuracy: 73.12%, Test Loss: 0.9366, Test Accuracy: 65.82%\n",
      "Epoch [2340/2500], Train Loss: 0.6245, Train Accuracy: 73.12%, Test Loss: 0.9577, Test Accuracy: 65.82%\n",
      "Epoch [2341/2500], Train Loss: 0.6219, Train Accuracy: 72.26%, Test Loss: 0.9475, Test Accuracy: 65.82%\n",
      "Epoch [2342/2500], Train Loss: 0.6021, Train Accuracy: 72.97%, Test Loss: 0.9547, Test Accuracy: 64.56%\n",
      "Epoch [2343/2500], Train Loss: 0.6122, Train Accuracy: 74.25%, Test Loss: 0.9672, Test Accuracy: 65.82%\n",
      "Epoch [2344/2500], Train Loss: 0.6175, Train Accuracy: 72.26%, Test Loss: 0.9558, Test Accuracy: 65.82%\n",
      "Epoch [2345/2500], Train Loss: 0.6294, Train Accuracy: 72.97%, Test Loss: 0.9819, Test Accuracy: 64.56%\n",
      "Epoch [2346/2500], Train Loss: 0.6191, Train Accuracy: 74.40%, Test Loss: 0.9533, Test Accuracy: 65.82%\n",
      "Epoch [2347/2500], Train Loss: 0.6259, Train Accuracy: 73.83%, Test Loss: 0.9723, Test Accuracy: 65.82%\n",
      "Epoch [2348/2500], Train Loss: 0.6047, Train Accuracy: 73.54%, Test Loss: 0.9592, Test Accuracy: 65.82%\n",
      "Epoch [2349/2500], Train Loss: 0.6284, Train Accuracy: 71.69%, Test Loss: 0.9684, Test Accuracy: 65.82%\n",
      "Epoch [2350/2500], Train Loss: 0.6182, Train Accuracy: 74.40%, Test Loss: 0.9772, Test Accuracy: 65.82%\n",
      "Epoch [2351/2500], Train Loss: 0.6136, Train Accuracy: 73.83%, Test Loss: 0.9521, Test Accuracy: 65.82%\n",
      "Epoch [2352/2500], Train Loss: 0.6282, Train Accuracy: 72.83%, Test Loss: 0.9351, Test Accuracy: 63.29%\n",
      "Epoch [2353/2500], Train Loss: 0.6352, Train Accuracy: 71.55%, Test Loss: 0.9684, Test Accuracy: 64.56%\n",
      "Epoch [2354/2500], Train Loss: 0.6211, Train Accuracy: 74.82%, Test Loss: 0.9562, Test Accuracy: 63.29%\n",
      "Epoch [2355/2500], Train Loss: 0.6245, Train Accuracy: 74.11%, Test Loss: 0.9713, Test Accuracy: 65.82%\n",
      "Epoch [2356/2500], Train Loss: 0.6300, Train Accuracy: 74.40%, Test Loss: 0.9935, Test Accuracy: 65.82%\n",
      "Epoch [2357/2500], Train Loss: 0.6012, Train Accuracy: 74.25%, Test Loss: 1.0339, Test Accuracy: 63.29%\n",
      "Epoch [2358/2500], Train Loss: 0.6366, Train Accuracy: 73.26%, Test Loss: 0.9046, Test Accuracy: 67.09%\n",
      "Epoch [2359/2500], Train Loss: 0.6128, Train Accuracy: 73.83%, Test Loss: 0.9666, Test Accuracy: 64.56%\n",
      "Epoch [2360/2500], Train Loss: 0.6387, Train Accuracy: 72.83%, Test Loss: 1.0116, Test Accuracy: 63.29%\n",
      "Epoch [2361/2500], Train Loss: 0.6134, Train Accuracy: 74.11%, Test Loss: 0.9411, Test Accuracy: 64.56%\n",
      "Epoch [2362/2500], Train Loss: 0.6437, Train Accuracy: 73.12%, Test Loss: 0.9713, Test Accuracy: 63.29%\n",
      "Epoch [2363/2500], Train Loss: 0.6129, Train Accuracy: 73.83%, Test Loss: 0.9900, Test Accuracy: 64.56%\n",
      "Epoch [2364/2500], Train Loss: 0.6196, Train Accuracy: 74.54%, Test Loss: 0.9566, Test Accuracy: 64.56%\n",
      "Epoch [2365/2500], Train Loss: 0.6257, Train Accuracy: 73.54%, Test Loss: 0.9477, Test Accuracy: 63.29%\n",
      "Epoch [2366/2500], Train Loss: 0.6427, Train Accuracy: 71.69%, Test Loss: 0.9921, Test Accuracy: 64.56%\n",
      "Epoch [2367/2500], Train Loss: 0.6041, Train Accuracy: 72.55%, Test Loss: 0.9455, Test Accuracy: 63.29%\n",
      "Epoch [2368/2500], Train Loss: 0.6038, Train Accuracy: 75.25%, Test Loss: 0.9299, Test Accuracy: 65.82%\n",
      "Epoch [2369/2500], Train Loss: 0.6147, Train Accuracy: 73.26%, Test Loss: 0.9600, Test Accuracy: 63.29%\n",
      "Epoch [2370/2500], Train Loss: 0.6306, Train Accuracy: 72.40%, Test Loss: 0.9856, Test Accuracy: 64.56%\n",
      "Epoch [2371/2500], Train Loss: 0.6211, Train Accuracy: 73.68%, Test Loss: 0.9467, Test Accuracy: 65.82%\n",
      "Epoch [2372/2500], Train Loss: 0.6241, Train Accuracy: 72.55%, Test Loss: 0.9480, Test Accuracy: 63.29%\n",
      "Epoch [2373/2500], Train Loss: 0.6304, Train Accuracy: 74.25%, Test Loss: 0.9825, Test Accuracy: 64.56%\n",
      "Epoch [2374/2500], Train Loss: 0.6045, Train Accuracy: 74.40%, Test Loss: 1.0001, Test Accuracy: 63.29%\n",
      "Epoch [2375/2500], Train Loss: 0.6462, Train Accuracy: 73.26%, Test Loss: 0.9474, Test Accuracy: 67.09%\n",
      "Epoch [2376/2500], Train Loss: 0.6293, Train Accuracy: 72.83%, Test Loss: 0.9567, Test Accuracy: 64.56%\n",
      "Epoch [2377/2500], Train Loss: 0.6207, Train Accuracy: 72.40%, Test Loss: 0.9733, Test Accuracy: 65.82%\n",
      "Epoch [2378/2500], Train Loss: 0.6294, Train Accuracy: 73.68%, Test Loss: 0.9268, Test Accuracy: 67.09%\n",
      "Epoch [2379/2500], Train Loss: 0.6212, Train Accuracy: 72.55%, Test Loss: 0.9545, Test Accuracy: 64.56%\n",
      "Epoch [2380/2500], Train Loss: 0.6405, Train Accuracy: 72.40%, Test Loss: 1.0207, Test Accuracy: 62.03%\n",
      "Epoch [2381/2500], Train Loss: 0.6102, Train Accuracy: 74.82%, Test Loss: 1.0195, Test Accuracy: 64.56%\n",
      "Epoch [2382/2500], Train Loss: 0.6191, Train Accuracy: 71.12%, Test Loss: 0.9791, Test Accuracy: 64.56%\n",
      "Epoch [2383/2500], Train Loss: 0.6195, Train Accuracy: 73.12%, Test Loss: 0.9845, Test Accuracy: 63.29%\n",
      "Epoch [2384/2500], Train Loss: 0.6164, Train Accuracy: 73.97%, Test Loss: 1.0134, Test Accuracy: 63.29%\n",
      "Epoch [2385/2500], Train Loss: 0.6308, Train Accuracy: 72.55%, Test Loss: 0.9596, Test Accuracy: 64.56%\n",
      "Epoch [2386/2500], Train Loss: 0.6328, Train Accuracy: 71.27%, Test Loss: 0.9816, Test Accuracy: 64.56%\n",
      "Epoch [2387/2500], Train Loss: 0.6283, Train Accuracy: 71.83%, Test Loss: 0.9985, Test Accuracy: 65.82%\n",
      "Epoch [2388/2500], Train Loss: 0.6319, Train Accuracy: 72.83%, Test Loss: 0.9410, Test Accuracy: 65.82%\n",
      "Epoch [2389/2500], Train Loss: 0.6450, Train Accuracy: 72.55%, Test Loss: 0.9943, Test Accuracy: 64.56%\n",
      "Epoch [2390/2500], Train Loss: 0.6307, Train Accuracy: 71.83%, Test Loss: 0.9071, Test Accuracy: 67.09%\n",
      "Epoch [2391/2500], Train Loss: 0.6515, Train Accuracy: 71.12%, Test Loss: 0.9674, Test Accuracy: 64.56%\n",
      "Epoch [2392/2500], Train Loss: 0.6229, Train Accuracy: 74.82%, Test Loss: 0.9691, Test Accuracy: 64.56%\n",
      "Epoch [2393/2500], Train Loss: 0.6263, Train Accuracy: 73.54%, Test Loss: 0.9483, Test Accuracy: 67.09%\n",
      "Epoch [2394/2500], Train Loss: 0.6190, Train Accuracy: 72.55%, Test Loss: 0.9640, Test Accuracy: 67.09%\n",
      "Epoch [2395/2500], Train Loss: 0.6271, Train Accuracy: 74.25%, Test Loss: 0.9472, Test Accuracy: 65.82%\n",
      "Epoch [2396/2500], Train Loss: 0.6353, Train Accuracy: 72.69%, Test Loss: 0.9345, Test Accuracy: 67.09%\n",
      "Epoch [2397/2500], Train Loss: 0.6329, Train Accuracy: 71.69%, Test Loss: 0.9281, Test Accuracy: 67.09%\n",
      "Epoch [2398/2500], Train Loss: 0.6331, Train Accuracy: 72.40%, Test Loss: 1.0025, Test Accuracy: 63.29%\n",
      "Epoch [2399/2500], Train Loss: 0.6183, Train Accuracy: 72.83%, Test Loss: 0.9537, Test Accuracy: 65.82%\n",
      "Epoch [2400/2500], Train Loss: 0.6249, Train Accuracy: 72.69%, Test Loss: 0.9458, Test Accuracy: 67.09%\n",
      "Epoch [2401/2500], Train Loss: 0.6247, Train Accuracy: 72.97%, Test Loss: 0.9701, Test Accuracy: 64.56%\n",
      "Epoch [2402/2500], Train Loss: 0.6154, Train Accuracy: 73.12%, Test Loss: 0.9447, Test Accuracy: 65.82%\n",
      "Epoch [2403/2500], Train Loss: 0.6036, Train Accuracy: 74.96%, Test Loss: 1.0113, Test Accuracy: 63.29%\n",
      "Epoch [2404/2500], Train Loss: 0.6060, Train Accuracy: 74.25%, Test Loss: 0.9343, Test Accuracy: 65.82%\n",
      "Epoch [2405/2500], Train Loss: 0.6494, Train Accuracy: 72.55%, Test Loss: 0.9506, Test Accuracy: 64.56%\n",
      "Epoch [2406/2500], Train Loss: 0.6374, Train Accuracy: 72.12%, Test Loss: 0.9484, Test Accuracy: 67.09%\n",
      "Epoch [2407/2500], Train Loss: 0.6206, Train Accuracy: 72.83%, Test Loss: 0.9669, Test Accuracy: 67.09%\n",
      "Epoch [2408/2500], Train Loss: 0.6079, Train Accuracy: 73.54%, Test Loss: 0.9201, Test Accuracy: 65.82%\n",
      "Epoch [2409/2500], Train Loss: 0.6094, Train Accuracy: 73.83%, Test Loss: 0.9731, Test Accuracy: 64.56%\n",
      "Epoch [2410/2500], Train Loss: 0.6300, Train Accuracy: 73.40%, Test Loss: 0.9523, Test Accuracy: 67.09%\n",
      "Epoch [2411/2500], Train Loss: 0.6413, Train Accuracy: 73.97%, Test Loss: 0.9706, Test Accuracy: 65.82%\n",
      "Epoch [2412/2500], Train Loss: 0.6152, Train Accuracy: 75.39%, Test Loss: 0.9629, Test Accuracy: 65.82%\n",
      "Epoch [2413/2500], Train Loss: 0.6268, Train Accuracy: 73.12%, Test Loss: 1.0093, Test Accuracy: 62.03%\n",
      "Epoch [2414/2500], Train Loss: 0.6129, Train Accuracy: 73.83%, Test Loss: 0.9714, Test Accuracy: 65.82%\n",
      "Epoch [2415/2500], Train Loss: 0.6410, Train Accuracy: 73.26%, Test Loss: 0.9862, Test Accuracy: 64.56%\n",
      "Epoch [2416/2500], Train Loss: 0.6242, Train Accuracy: 72.97%, Test Loss: 0.9610, Test Accuracy: 64.56%\n",
      "Epoch [2417/2500], Train Loss: 0.6312, Train Accuracy: 73.54%, Test Loss: 0.9506, Test Accuracy: 65.82%\n",
      "Epoch [2418/2500], Train Loss: 0.6340, Train Accuracy: 72.26%, Test Loss: 0.9022, Test Accuracy: 68.35%\n",
      "Epoch [2419/2500], Train Loss: 0.6075, Train Accuracy: 72.26%, Test Loss: 0.9508, Test Accuracy: 63.29%\n",
      "Epoch [2420/2500], Train Loss: 0.6255, Train Accuracy: 74.68%, Test Loss: 0.9427, Test Accuracy: 67.09%\n",
      "Epoch [2421/2500], Train Loss: 0.6119, Train Accuracy: 71.69%, Test Loss: 0.9428, Test Accuracy: 67.09%\n",
      "Epoch [2422/2500], Train Loss: 0.6246, Train Accuracy: 73.83%, Test Loss: 0.9673, Test Accuracy: 64.56%\n",
      "Epoch [2423/2500], Train Loss: 0.6172, Train Accuracy: 73.83%, Test Loss: 0.9794, Test Accuracy: 64.56%\n",
      "Epoch [2424/2500], Train Loss: 0.6142, Train Accuracy: 72.26%, Test Loss: 0.9691, Test Accuracy: 64.56%\n",
      "Epoch [2425/2500], Train Loss: 0.6230, Train Accuracy: 72.97%, Test Loss: 0.9512, Test Accuracy: 64.56%\n",
      "Epoch [2426/2500], Train Loss: 0.6297, Train Accuracy: 71.98%, Test Loss: 0.9736, Test Accuracy: 65.82%\n",
      "Epoch [2427/2500], Train Loss: 0.6225, Train Accuracy: 72.40%, Test Loss: 0.9513, Test Accuracy: 64.56%\n",
      "Epoch [2428/2500], Train Loss: 0.6313, Train Accuracy: 73.54%, Test Loss: 0.9309, Test Accuracy: 67.09%\n",
      "Epoch [2429/2500], Train Loss: 0.6143, Train Accuracy: 73.83%, Test Loss: 0.9480, Test Accuracy: 64.56%\n",
      "Epoch [2430/2500], Train Loss: 0.6140, Train Accuracy: 73.54%, Test Loss: 0.9599, Test Accuracy: 63.29%\n",
      "Epoch [2431/2500], Train Loss: 0.5844, Train Accuracy: 75.11%, Test Loss: 0.9290, Test Accuracy: 67.09%\n",
      "Epoch [2432/2500], Train Loss: 0.6185, Train Accuracy: 73.54%, Test Loss: 0.9713, Test Accuracy: 65.82%\n",
      "Epoch [2433/2500], Train Loss: 0.6119, Train Accuracy: 73.68%, Test Loss: 0.9596, Test Accuracy: 64.56%\n",
      "Epoch [2434/2500], Train Loss: 0.6173, Train Accuracy: 72.83%, Test Loss: 0.9285, Test Accuracy: 67.09%\n",
      "Epoch [2435/2500], Train Loss: 0.5997, Train Accuracy: 74.82%, Test Loss: 0.9283, Test Accuracy: 67.09%\n",
      "Epoch [2436/2500], Train Loss: 0.6135, Train Accuracy: 75.82%, Test Loss: 0.9468, Test Accuracy: 64.56%\n",
      "Epoch [2437/2500], Train Loss: 0.6082, Train Accuracy: 74.82%, Test Loss: 0.9346, Test Accuracy: 65.82%\n",
      "Epoch [2438/2500], Train Loss: 0.6049, Train Accuracy: 73.97%, Test Loss: 0.9280, Test Accuracy: 65.82%\n",
      "Epoch [2439/2500], Train Loss: 0.6145, Train Accuracy: 73.26%, Test Loss: 0.9327, Test Accuracy: 65.82%\n",
      "Epoch [2440/2500], Train Loss: 0.6335, Train Accuracy: 73.54%, Test Loss: 0.9726, Test Accuracy: 64.56%\n",
      "Epoch [2441/2500], Train Loss: 0.6136, Train Accuracy: 73.68%, Test Loss: 0.9389, Test Accuracy: 64.56%\n",
      "Epoch [2442/2500], Train Loss: 0.6189, Train Accuracy: 73.68%, Test Loss: 0.9565, Test Accuracy: 65.82%\n",
      "Epoch [2443/2500], Train Loss: 0.6246, Train Accuracy: 73.97%, Test Loss: 0.9842, Test Accuracy: 63.29%\n",
      "Epoch [2444/2500], Train Loss: 0.6153, Train Accuracy: 73.40%, Test Loss: 0.9866, Test Accuracy: 64.56%\n",
      "Epoch [2445/2500], Train Loss: 0.6257, Train Accuracy: 73.97%, Test Loss: 0.9615, Test Accuracy: 64.56%\n",
      "Epoch [2446/2500], Train Loss: 0.6191, Train Accuracy: 72.97%, Test Loss: 0.9919, Test Accuracy: 63.29%\n",
      "Epoch [2447/2500], Train Loss: 0.6171, Train Accuracy: 73.26%, Test Loss: 1.0282, Test Accuracy: 63.29%\n",
      "Epoch [2448/2500], Train Loss: 0.6051, Train Accuracy: 73.97%, Test Loss: 0.9551, Test Accuracy: 63.29%\n",
      "Epoch [2449/2500], Train Loss: 0.6116, Train Accuracy: 73.26%, Test Loss: 0.9138, Test Accuracy: 64.56%\n",
      "Epoch [2450/2500], Train Loss: 0.6203, Train Accuracy: 72.12%, Test Loss: 0.9585, Test Accuracy: 64.56%\n",
      "Epoch [2451/2500], Train Loss: 0.6332, Train Accuracy: 71.41%, Test Loss: 0.9124, Test Accuracy: 65.82%\n",
      "Epoch [2452/2500], Train Loss: 0.6272, Train Accuracy: 73.40%, Test Loss: 0.9711, Test Accuracy: 64.56%\n",
      "Epoch [2453/2500], Train Loss: 0.6170, Train Accuracy: 73.68%, Test Loss: 0.9380, Test Accuracy: 64.56%\n",
      "Epoch [2454/2500], Train Loss: 0.6174, Train Accuracy: 72.55%, Test Loss: 0.9503, Test Accuracy: 65.82%\n",
      "Epoch [2455/2500], Train Loss: 0.6297, Train Accuracy: 72.97%, Test Loss: 0.9071, Test Accuracy: 68.35%\n",
      "Epoch [2456/2500], Train Loss: 0.6468, Train Accuracy: 72.26%, Test Loss: 0.9533, Test Accuracy: 65.82%\n",
      "Epoch [2457/2500], Train Loss: 0.5995, Train Accuracy: 74.82%, Test Loss: 1.0063, Test Accuracy: 64.56%\n",
      "Epoch [2458/2500], Train Loss: 0.6270, Train Accuracy: 71.98%, Test Loss: 0.9626, Test Accuracy: 65.82%\n",
      "Epoch [2459/2500], Train Loss: 0.6052, Train Accuracy: 73.83%, Test Loss: 0.9793, Test Accuracy: 65.82%\n",
      "Epoch [2460/2500], Train Loss: 0.6084, Train Accuracy: 72.55%, Test Loss: 0.9675, Test Accuracy: 64.56%\n",
      "Epoch [2461/2500], Train Loss: 0.6198, Train Accuracy: 72.26%, Test Loss: 0.9758, Test Accuracy: 64.56%\n",
      "Epoch [2462/2500], Train Loss: 0.6005, Train Accuracy: 75.53%, Test Loss: 0.9695, Test Accuracy: 65.82%\n",
      "Epoch [2463/2500], Train Loss: 0.6076, Train Accuracy: 73.97%, Test Loss: 0.9297, Test Accuracy: 68.35%\n",
      "Epoch [2464/2500], Train Loss: 0.5993, Train Accuracy: 75.53%, Test Loss: 0.9397, Test Accuracy: 67.09%\n",
      "Epoch [2465/2500], Train Loss: 0.6100, Train Accuracy: 72.40%, Test Loss: 0.9254, Test Accuracy: 65.82%\n",
      "Epoch [2466/2500], Train Loss: 0.6184, Train Accuracy: 72.40%, Test Loss: 0.9440, Test Accuracy: 64.56%\n",
      "Epoch [2467/2500], Train Loss: 0.5960, Train Accuracy: 74.25%, Test Loss: 0.9998, Test Accuracy: 64.56%\n",
      "Epoch [2468/2500], Train Loss: 0.6076, Train Accuracy: 72.97%, Test Loss: 0.9838, Test Accuracy: 67.09%\n",
      "Epoch [2469/2500], Train Loss: 0.5993, Train Accuracy: 74.40%, Test Loss: 0.9555, Test Accuracy: 67.09%\n",
      "Epoch [2470/2500], Train Loss: 0.6198, Train Accuracy: 72.83%, Test Loss: 0.9768, Test Accuracy: 65.82%\n",
      "Epoch [2471/2500], Train Loss: 0.6078, Train Accuracy: 73.26%, Test Loss: 0.9650, Test Accuracy: 65.82%\n",
      "Epoch [2472/2500], Train Loss: 0.5985, Train Accuracy: 74.40%, Test Loss: 1.0029, Test Accuracy: 65.82%\n",
      "Epoch [2473/2500], Train Loss: 0.6193, Train Accuracy: 73.68%, Test Loss: 0.9777, Test Accuracy: 64.56%\n",
      "Epoch [2474/2500], Train Loss: 0.6154, Train Accuracy: 72.69%, Test Loss: 0.9475, Test Accuracy: 64.56%\n",
      "Epoch [2475/2500], Train Loss: 0.5954, Train Accuracy: 75.39%, Test Loss: 0.9880, Test Accuracy: 64.56%\n",
      "Epoch [2476/2500], Train Loss: 0.6123, Train Accuracy: 74.54%, Test Loss: 0.9417, Test Accuracy: 65.82%\n",
      "Epoch [2477/2500], Train Loss: 0.5944, Train Accuracy: 74.11%, Test Loss: 0.9597, Test Accuracy: 65.82%\n",
      "Epoch [2478/2500], Train Loss: 0.6104, Train Accuracy: 72.69%, Test Loss: 0.9795, Test Accuracy: 65.82%\n",
      "Epoch [2479/2500], Train Loss: 0.6156, Train Accuracy: 74.82%, Test Loss: 0.9789, Test Accuracy: 64.56%\n",
      "Epoch [2480/2500], Train Loss: 0.6083, Train Accuracy: 75.11%, Test Loss: 0.9917, Test Accuracy: 65.82%\n",
      "Epoch [2481/2500], Train Loss: 0.5807, Train Accuracy: 74.68%, Test Loss: 0.9414, Test Accuracy: 67.09%\n",
      "Epoch [2482/2500], Train Loss: 0.6110, Train Accuracy: 73.97%, Test Loss: 0.9770, Test Accuracy: 64.56%\n",
      "Epoch [2483/2500], Train Loss: 0.6244, Train Accuracy: 72.40%, Test Loss: 0.9493, Test Accuracy: 64.56%\n",
      "Epoch [2484/2500], Train Loss: 0.6278, Train Accuracy: 72.83%, Test Loss: 0.9252, Test Accuracy: 65.82%\n",
      "Epoch [2485/2500], Train Loss: 0.6042, Train Accuracy: 74.96%, Test Loss: 0.9788, Test Accuracy: 63.29%\n",
      "Epoch [2486/2500], Train Loss: 0.6190, Train Accuracy: 73.68%, Test Loss: 0.9754, Test Accuracy: 63.29%\n",
      "Epoch [2487/2500], Train Loss: 0.5996, Train Accuracy: 73.54%, Test Loss: 0.9661, Test Accuracy: 64.56%\n",
      "Epoch [2488/2500], Train Loss: 0.6096, Train Accuracy: 71.69%, Test Loss: 0.9548, Test Accuracy: 63.29%\n",
      "Epoch [2489/2500], Train Loss: 0.5986, Train Accuracy: 73.26%, Test Loss: 0.9597, Test Accuracy: 64.56%\n",
      "Epoch [2490/2500], Train Loss: 0.6090, Train Accuracy: 72.83%, Test Loss: 0.9027, Test Accuracy: 68.35%\n",
      "Epoch [2491/2500], Train Loss: 0.5969, Train Accuracy: 74.40%, Test Loss: 1.0015, Test Accuracy: 65.82%\n",
      "Epoch [2492/2500], Train Loss: 0.6271, Train Accuracy: 74.68%, Test Loss: 0.9310, Test Accuracy: 64.56%\n",
      "Epoch [2493/2500], Train Loss: 0.6349, Train Accuracy: 73.26%, Test Loss: 0.9478, Test Accuracy: 65.82%\n",
      "Epoch [2494/2500], Train Loss: 0.5944, Train Accuracy: 76.10%, Test Loss: 0.9366, Test Accuracy: 65.82%\n",
      "Epoch [2495/2500], Train Loss: 0.6177, Train Accuracy: 74.68%, Test Loss: 0.9713, Test Accuracy: 65.82%\n",
      "Epoch [2496/2500], Train Loss: 0.6154, Train Accuracy: 74.68%, Test Loss: 0.9909, Test Accuracy: 64.56%\n",
      "Epoch [2497/2500], Train Loss: 0.6049, Train Accuracy: 74.11%, Test Loss: 1.0074, Test Accuracy: 64.56%\n",
      "Epoch [2498/2500], Train Loss: 0.5970, Train Accuracy: 74.11%, Test Loss: 0.9836, Test Accuracy: 65.82%\n",
      "Epoch [2499/2500], Train Loss: 0.6235, Train Accuracy: 73.54%, Test Loss: 0.9435, Test Accuracy: 67.09%\n",
      "Epoch [2500/2500], Train Loss: 0.5990, Train Accuracy: 73.26%, Test Loss: 1.0110, Test Accuracy: 65.82%\n",
      "model_cnn1d_lstm saved as model_cnn1d_lstm_4class_best.pth\n",
      "\n",
      "Metrics for model_cnn1d_lstm saved as model_cnn1d_lstm_4class_metrics.csv\n",
      "\n",
      "Training model_cnn1d_att\n",
      "Epoch [1/2500], Train Loss: 1.3832, Train Accuracy: 24.61%, Test Loss: 1.3747, Test Accuracy: 30.38%\n",
      "Epoch [2/2500], Train Loss: 1.3778, Train Accuracy: 31.86%, Test Loss: 1.3692, Test Accuracy: 39.24%\n",
      "Epoch [3/2500], Train Loss: 1.3733, Train Accuracy: 34.85%, Test Loss: 1.3637, Test Accuracy: 39.24%\n",
      "Epoch [4/2500], Train Loss: 1.3668, Train Accuracy: 35.28%, Test Loss: 1.3568, Test Accuracy: 39.24%\n",
      "Epoch [5/2500], Train Loss: 1.3605, Train Accuracy: 35.28%, Test Loss: 1.3489, Test Accuracy: 39.24%\n",
      "Epoch [6/2500], Train Loss: 1.3536, Train Accuracy: 35.28%, Test Loss: 1.3386, Test Accuracy: 39.24%\n",
      "Epoch [7/2500], Train Loss: 1.3452, Train Accuracy: 35.28%, Test Loss: 1.3269, Test Accuracy: 39.24%\n",
      "Epoch [8/2500], Train Loss: 1.3359, Train Accuracy: 35.28%, Test Loss: 1.3138, Test Accuracy: 39.24%\n",
      "Epoch [9/2500], Train Loss: 1.3343, Train Accuracy: 35.28%, Test Loss: 1.3017, Test Accuracy: 39.24%\n",
      "Epoch [10/2500], Train Loss: 1.3307, Train Accuracy: 35.28%, Test Loss: 1.2924, Test Accuracy: 39.24%\n",
      "Epoch [11/2500], Train Loss: 1.3310, Train Accuracy: 35.28%, Test Loss: 1.2866, Test Accuracy: 39.24%\n",
      "Epoch [12/2500], Train Loss: 1.3318, Train Accuracy: 35.28%, Test Loss: 1.2806, Test Accuracy: 39.24%\n",
      "Epoch [13/2500], Train Loss: 1.3190, Train Accuracy: 35.42%, Test Loss: 1.2695, Test Accuracy: 39.24%\n",
      "Epoch [14/2500], Train Loss: 1.3219, Train Accuracy: 35.14%, Test Loss: 1.2619, Test Accuracy: 39.24%\n",
      "Epoch [15/2500], Train Loss: 1.3088, Train Accuracy: 35.99%, Test Loss: 1.2433, Test Accuracy: 39.24%\n",
      "Epoch [16/2500], Train Loss: 1.3163, Train Accuracy: 36.27%, Test Loss: 1.2242, Test Accuracy: 41.77%\n",
      "Epoch [17/2500], Train Loss: 1.2979, Train Accuracy: 38.12%, Test Loss: 1.2018, Test Accuracy: 45.57%\n",
      "Epoch [18/2500], Train Loss: 1.2986, Train Accuracy: 38.12%, Test Loss: 1.1866, Test Accuracy: 45.57%\n",
      "Epoch [19/2500], Train Loss: 1.2820, Train Accuracy: 38.98%, Test Loss: 1.1573, Test Accuracy: 48.10%\n",
      "Epoch [20/2500], Train Loss: 1.2812, Train Accuracy: 40.68%, Test Loss: 1.1422, Test Accuracy: 48.10%\n",
      "Epoch [21/2500], Train Loss: 1.2453, Train Accuracy: 42.25%, Test Loss: 1.0987, Test Accuracy: 49.37%\n",
      "Epoch [22/2500], Train Loss: 1.2336, Train Accuracy: 42.25%, Test Loss: 1.0685, Test Accuracy: 50.63%\n",
      "Epoch [23/2500], Train Loss: 1.2268, Train Accuracy: 43.53%, Test Loss: 1.0552, Test Accuracy: 50.63%\n",
      "Epoch [24/2500], Train Loss: 1.2130, Train Accuracy: 44.24%, Test Loss: 1.0269, Test Accuracy: 56.96%\n",
      "Epoch [25/2500], Train Loss: 1.2054, Train Accuracy: 43.81%, Test Loss: 1.0159, Test Accuracy: 55.70%\n",
      "Epoch [26/2500], Train Loss: 1.2030, Train Accuracy: 44.81%, Test Loss: 1.0052, Test Accuracy: 54.43%\n",
      "Epoch [27/2500], Train Loss: 1.1980, Train Accuracy: 46.37%, Test Loss: 0.9908, Test Accuracy: 58.23%\n",
      "Epoch [28/2500], Train Loss: 1.1580, Train Accuracy: 48.79%, Test Loss: 0.9695, Test Accuracy: 58.23%\n",
      "Epoch [29/2500], Train Loss: 1.1455, Train Accuracy: 49.36%, Test Loss: 0.9701, Test Accuracy: 59.49%\n",
      "Epoch [30/2500], Train Loss: 1.1417, Train Accuracy: 49.22%, Test Loss: 0.9660, Test Accuracy: 56.96%\n",
      "Epoch [31/2500], Train Loss: 1.1438, Train Accuracy: 49.36%, Test Loss: 0.9642, Test Accuracy: 56.96%\n",
      "Epoch [32/2500], Train Loss: 1.1190, Train Accuracy: 49.50%, Test Loss: 0.9732, Test Accuracy: 55.70%\n",
      "Epoch [33/2500], Train Loss: 1.1205, Train Accuracy: 50.07%, Test Loss: 0.9651, Test Accuracy: 55.70%\n",
      "Epoch [34/2500], Train Loss: 1.1291, Train Accuracy: 52.63%, Test Loss: 0.9613, Test Accuracy: 55.70%\n",
      "Epoch [35/2500], Train Loss: 1.1136, Train Accuracy: 53.34%, Test Loss: 0.9670, Test Accuracy: 55.70%\n",
      "Epoch [36/2500], Train Loss: 1.0865, Train Accuracy: 53.77%, Test Loss: 0.9774, Test Accuracy: 56.96%\n",
      "Epoch [37/2500], Train Loss: 1.1139, Train Accuracy: 51.49%, Test Loss: 0.9677, Test Accuracy: 54.43%\n",
      "Epoch [38/2500], Train Loss: 1.1026, Train Accuracy: 51.49%, Test Loss: 0.9623, Test Accuracy: 55.70%\n",
      "Epoch [39/2500], Train Loss: 1.0924, Train Accuracy: 54.48%, Test Loss: 0.9802, Test Accuracy: 56.96%\n",
      "Epoch [40/2500], Train Loss: 1.1053, Train Accuracy: 54.62%, Test Loss: 0.9606, Test Accuracy: 55.70%\n",
      "Epoch [41/2500], Train Loss: 1.0856, Train Accuracy: 53.91%, Test Loss: 0.9628, Test Accuracy: 55.70%\n",
      "Epoch [42/2500], Train Loss: 1.0793, Train Accuracy: 54.34%, Test Loss: 0.9728, Test Accuracy: 55.70%\n",
      "Epoch [43/2500], Train Loss: 1.0718, Train Accuracy: 53.06%, Test Loss: 0.9583, Test Accuracy: 58.23%\n",
      "Epoch [44/2500], Train Loss: 1.0766, Train Accuracy: 54.62%, Test Loss: 0.9579, Test Accuracy: 56.96%\n",
      "Epoch [45/2500], Train Loss: 1.0843, Train Accuracy: 54.77%, Test Loss: 0.9714, Test Accuracy: 55.70%\n",
      "Epoch [46/2500], Train Loss: 1.0579, Train Accuracy: 56.61%, Test Loss: 0.9607, Test Accuracy: 56.96%\n",
      "Epoch [47/2500], Train Loss: 1.0813, Train Accuracy: 54.48%, Test Loss: 0.9665, Test Accuracy: 55.70%\n",
      "Epoch [48/2500], Train Loss: 1.0781, Train Accuracy: 56.61%, Test Loss: 0.9588, Test Accuracy: 58.23%\n",
      "Epoch [49/2500], Train Loss: 1.0679, Train Accuracy: 53.91%, Test Loss: 0.9635, Test Accuracy: 58.23%\n",
      "Epoch [50/2500], Train Loss: 1.0574, Train Accuracy: 54.34%, Test Loss: 0.9643, Test Accuracy: 58.23%\n",
      "Epoch [51/2500], Train Loss: 1.0509, Train Accuracy: 55.76%, Test Loss: 0.9625, Test Accuracy: 56.96%\n",
      "Epoch [52/2500], Train Loss: 1.0570, Train Accuracy: 57.61%, Test Loss: 0.9650, Test Accuracy: 56.96%\n",
      "Epoch [53/2500], Train Loss: 1.0413, Train Accuracy: 56.76%, Test Loss: 0.9628, Test Accuracy: 56.96%\n",
      "Epoch [54/2500], Train Loss: 1.0544, Train Accuracy: 56.05%, Test Loss: 0.9642, Test Accuracy: 56.96%\n",
      "Epoch [55/2500], Train Loss: 1.0359, Train Accuracy: 56.05%, Test Loss: 0.9677, Test Accuracy: 56.96%\n",
      "Epoch [56/2500], Train Loss: 1.0511, Train Accuracy: 56.33%, Test Loss: 0.9715, Test Accuracy: 56.96%\n",
      "Epoch [57/2500], Train Loss: 1.0379, Train Accuracy: 56.33%, Test Loss: 0.9756, Test Accuracy: 56.96%\n",
      "Epoch [58/2500], Train Loss: 1.0339, Train Accuracy: 54.34%, Test Loss: 0.9634, Test Accuracy: 56.96%\n",
      "Epoch [59/2500], Train Loss: 1.0400, Train Accuracy: 56.19%, Test Loss: 0.9639, Test Accuracy: 56.96%\n",
      "Epoch [60/2500], Train Loss: 1.0670, Train Accuracy: 55.33%, Test Loss: 0.9625, Test Accuracy: 56.96%\n",
      "Epoch [61/2500], Train Loss: 1.0429, Train Accuracy: 56.05%, Test Loss: 0.9597, Test Accuracy: 56.96%\n",
      "Epoch [62/2500], Train Loss: 1.0514, Train Accuracy: 55.90%, Test Loss: 0.9688, Test Accuracy: 56.96%\n",
      "Epoch [63/2500], Train Loss: 1.0182, Train Accuracy: 56.90%, Test Loss: 0.9585, Test Accuracy: 58.23%\n",
      "Epoch [64/2500], Train Loss: 1.0182, Train Accuracy: 57.61%, Test Loss: 0.9561, Test Accuracy: 58.23%\n",
      "Epoch [65/2500], Train Loss: 1.0346, Train Accuracy: 56.90%, Test Loss: 0.9590, Test Accuracy: 58.23%\n",
      "Epoch [66/2500], Train Loss: 1.0516, Train Accuracy: 56.76%, Test Loss: 0.9718, Test Accuracy: 56.96%\n",
      "Epoch [67/2500], Train Loss: 1.0342, Train Accuracy: 57.89%, Test Loss: 0.9787, Test Accuracy: 56.96%\n",
      "Epoch [68/2500], Train Loss: 1.0448, Train Accuracy: 55.05%, Test Loss: 0.9773, Test Accuracy: 56.96%\n",
      "Epoch [69/2500], Train Loss: 1.0482, Train Accuracy: 55.33%, Test Loss: 0.9676, Test Accuracy: 58.23%\n",
      "Epoch [70/2500], Train Loss: 1.0423, Train Accuracy: 55.19%, Test Loss: 0.9678, Test Accuracy: 58.23%\n",
      "Epoch [71/2500], Train Loss: 1.0447, Train Accuracy: 56.90%, Test Loss: 0.9766, Test Accuracy: 56.96%\n",
      "Epoch [72/2500], Train Loss: 1.0367, Train Accuracy: 56.90%, Test Loss: 0.9722, Test Accuracy: 56.96%\n",
      "Epoch [73/2500], Train Loss: 1.0163, Train Accuracy: 55.62%, Test Loss: 0.9700, Test Accuracy: 56.96%\n",
      "Epoch [74/2500], Train Loss: 1.0438, Train Accuracy: 57.04%, Test Loss: 0.9707, Test Accuracy: 56.96%\n",
      "Epoch [75/2500], Train Loss: 1.0317, Train Accuracy: 55.62%, Test Loss: 0.9651, Test Accuracy: 58.23%\n",
      "Epoch [76/2500], Train Loss: 1.0328, Train Accuracy: 56.33%, Test Loss: 0.9676, Test Accuracy: 58.23%\n",
      "Epoch [77/2500], Train Loss: 1.0261, Train Accuracy: 56.90%, Test Loss: 0.9803, Test Accuracy: 56.96%\n",
      "Epoch [78/2500], Train Loss: 1.0203, Train Accuracy: 56.47%, Test Loss: 0.9629, Test Accuracy: 58.23%\n",
      "Epoch [79/2500], Train Loss: 1.0158, Train Accuracy: 57.04%, Test Loss: 0.9624, Test Accuracy: 58.23%\n",
      "Epoch [80/2500], Train Loss: 1.0144, Train Accuracy: 56.61%, Test Loss: 0.9625, Test Accuracy: 58.23%\n",
      "Epoch [81/2500], Train Loss: 1.0252, Train Accuracy: 57.33%, Test Loss: 0.9638, Test Accuracy: 58.23%\n",
      "Epoch [82/2500], Train Loss: 1.0244, Train Accuracy: 57.18%, Test Loss: 0.9582, Test Accuracy: 58.23%\n",
      "Epoch [83/2500], Train Loss: 1.0215, Train Accuracy: 56.19%, Test Loss: 0.9582, Test Accuracy: 58.23%\n",
      "Epoch [84/2500], Train Loss: 1.0296, Train Accuracy: 56.33%, Test Loss: 0.9534, Test Accuracy: 58.23%\n",
      "Epoch [85/2500], Train Loss: 1.0062, Train Accuracy: 56.90%, Test Loss: 0.9506, Test Accuracy: 58.23%\n",
      "Epoch [86/2500], Train Loss: 1.0196, Train Accuracy: 57.18%, Test Loss: 0.9610, Test Accuracy: 56.96%\n",
      "Epoch [87/2500], Train Loss: 1.0077, Train Accuracy: 56.90%, Test Loss: 0.9710, Test Accuracy: 56.96%\n",
      "Epoch [88/2500], Train Loss: 1.0102, Train Accuracy: 58.04%, Test Loss: 0.9595, Test Accuracy: 56.96%\n",
      "Epoch [89/2500], Train Loss: 1.0190, Train Accuracy: 56.76%, Test Loss: 0.9643, Test Accuracy: 55.70%\n",
      "Epoch [90/2500], Train Loss: 1.0173, Train Accuracy: 57.04%, Test Loss: 0.9621, Test Accuracy: 55.70%\n",
      "Epoch [91/2500], Train Loss: 1.0002, Train Accuracy: 55.90%, Test Loss: 0.9527, Test Accuracy: 58.23%\n",
      "Epoch [92/2500], Train Loss: 1.0211, Train Accuracy: 57.04%, Test Loss: 0.9563, Test Accuracy: 58.23%\n",
      "Epoch [93/2500], Train Loss: 1.0187, Train Accuracy: 56.90%, Test Loss: 0.9585, Test Accuracy: 58.23%\n",
      "Epoch [94/2500], Train Loss: 1.0093, Train Accuracy: 58.46%, Test Loss: 0.9574, Test Accuracy: 58.23%\n",
      "Epoch [95/2500], Train Loss: 1.0073, Train Accuracy: 56.90%, Test Loss: 0.9550, Test Accuracy: 56.96%\n",
      "Epoch [96/2500], Train Loss: 1.0105, Train Accuracy: 56.33%, Test Loss: 0.9561, Test Accuracy: 56.96%\n",
      "Epoch [97/2500], Train Loss: 1.0235, Train Accuracy: 55.90%, Test Loss: 0.9600, Test Accuracy: 56.96%\n",
      "Epoch [98/2500], Train Loss: 1.0046, Train Accuracy: 57.75%, Test Loss: 0.9596, Test Accuracy: 56.96%\n",
      "Epoch [99/2500], Train Loss: 0.9995, Train Accuracy: 57.33%, Test Loss: 0.9664, Test Accuracy: 56.96%\n",
      "Epoch [100/2500], Train Loss: 1.0176, Train Accuracy: 58.75%, Test Loss: 0.9569, Test Accuracy: 58.23%\n",
      "Epoch [101/2500], Train Loss: 1.0148, Train Accuracy: 56.05%, Test Loss: 0.9526, Test Accuracy: 56.96%\n",
      "Epoch [102/2500], Train Loss: 1.0098, Train Accuracy: 58.04%, Test Loss: 0.9638, Test Accuracy: 56.96%\n",
      "Epoch [103/2500], Train Loss: 0.9976, Train Accuracy: 57.75%, Test Loss: 0.9561, Test Accuracy: 58.23%\n",
      "Epoch [104/2500], Train Loss: 0.9988, Train Accuracy: 57.61%, Test Loss: 0.9602, Test Accuracy: 56.96%\n",
      "Epoch [105/2500], Train Loss: 1.0109, Train Accuracy: 57.04%, Test Loss: 0.9520, Test Accuracy: 56.96%\n",
      "Epoch [106/2500], Train Loss: 1.0101, Train Accuracy: 57.18%, Test Loss: 0.9575, Test Accuracy: 58.23%\n",
      "Epoch [107/2500], Train Loss: 0.9972, Train Accuracy: 57.18%, Test Loss: 0.9710, Test Accuracy: 56.96%\n",
      "Epoch [108/2500], Train Loss: 1.0146, Train Accuracy: 56.47%, Test Loss: 0.9582, Test Accuracy: 58.23%\n",
      "Epoch [109/2500], Train Loss: 1.0003, Train Accuracy: 55.90%, Test Loss: 0.9647, Test Accuracy: 56.96%\n",
      "Epoch [110/2500], Train Loss: 1.0073, Train Accuracy: 56.33%, Test Loss: 0.9643, Test Accuracy: 56.96%\n",
      "Epoch [111/2500], Train Loss: 1.0062, Train Accuracy: 56.47%, Test Loss: 0.9600, Test Accuracy: 56.96%\n",
      "Epoch [112/2500], Train Loss: 0.9927, Train Accuracy: 57.18%, Test Loss: 0.9576, Test Accuracy: 58.23%\n",
      "Epoch [113/2500], Train Loss: 0.9952, Train Accuracy: 56.90%, Test Loss: 0.9547, Test Accuracy: 58.23%\n",
      "Epoch [114/2500], Train Loss: 1.0022, Train Accuracy: 56.33%, Test Loss: 0.9676, Test Accuracy: 56.96%\n",
      "Epoch [115/2500], Train Loss: 0.9961, Train Accuracy: 58.18%, Test Loss: 0.9742, Test Accuracy: 56.96%\n",
      "Epoch [116/2500], Train Loss: 0.9852, Train Accuracy: 58.04%, Test Loss: 0.9636, Test Accuracy: 58.23%\n",
      "Epoch [117/2500], Train Loss: 0.9896, Train Accuracy: 58.46%, Test Loss: 0.9633, Test Accuracy: 56.96%\n",
      "Epoch [118/2500], Train Loss: 1.0035, Train Accuracy: 57.04%, Test Loss: 0.9549, Test Accuracy: 58.23%\n",
      "Epoch [119/2500], Train Loss: 0.9954, Train Accuracy: 57.61%, Test Loss: 0.9556, Test Accuracy: 58.23%\n",
      "Epoch [120/2500], Train Loss: 1.0112, Train Accuracy: 56.47%, Test Loss: 0.9611, Test Accuracy: 56.96%\n",
      "Epoch [121/2500], Train Loss: 0.9854, Train Accuracy: 57.18%, Test Loss: 0.9641, Test Accuracy: 56.96%\n",
      "Epoch [122/2500], Train Loss: 0.9905, Train Accuracy: 57.04%, Test Loss: 0.9588, Test Accuracy: 56.96%\n",
      "Epoch [123/2500], Train Loss: 0.9698, Train Accuracy: 57.47%, Test Loss: 0.9651, Test Accuracy: 56.96%\n",
      "Epoch [124/2500], Train Loss: 0.9872, Train Accuracy: 57.47%, Test Loss: 0.9569, Test Accuracy: 58.23%\n",
      "Epoch [125/2500], Train Loss: 0.9937, Train Accuracy: 56.19%, Test Loss: 0.9620, Test Accuracy: 56.96%\n",
      "Epoch [126/2500], Train Loss: 0.9894, Train Accuracy: 56.90%, Test Loss: 0.9645, Test Accuracy: 56.96%\n",
      "Epoch [127/2500], Train Loss: 0.9920, Train Accuracy: 56.33%, Test Loss: 0.9585, Test Accuracy: 56.96%\n",
      "Epoch [128/2500], Train Loss: 0.9945, Train Accuracy: 57.04%, Test Loss: 0.9581, Test Accuracy: 58.23%\n",
      "Epoch [129/2500], Train Loss: 1.0000, Train Accuracy: 58.18%, Test Loss: 0.9562, Test Accuracy: 58.23%\n",
      "Epoch [130/2500], Train Loss: 0.9960, Train Accuracy: 56.90%, Test Loss: 0.9544, Test Accuracy: 56.96%\n",
      "Epoch [131/2500], Train Loss: 0.9906, Train Accuracy: 56.47%, Test Loss: 0.9543, Test Accuracy: 58.23%\n",
      "Epoch [132/2500], Train Loss: 0.9755, Train Accuracy: 57.04%, Test Loss: 0.9577, Test Accuracy: 58.23%\n",
      "Epoch [133/2500], Train Loss: 0.9921, Train Accuracy: 57.33%, Test Loss: 0.9641, Test Accuracy: 58.23%\n",
      "Epoch [134/2500], Train Loss: 0.9842, Train Accuracy: 57.61%, Test Loss: 0.9618, Test Accuracy: 58.23%\n",
      "Epoch [135/2500], Train Loss: 0.9838, Train Accuracy: 58.32%, Test Loss: 0.9531, Test Accuracy: 59.49%\n",
      "Epoch [136/2500], Train Loss: 0.9825, Train Accuracy: 57.89%, Test Loss: 0.9559, Test Accuracy: 59.49%\n",
      "Epoch [137/2500], Train Loss: 0.9836, Train Accuracy: 56.33%, Test Loss: 0.9513, Test Accuracy: 59.49%\n",
      "Epoch [138/2500], Train Loss: 0.9832, Train Accuracy: 57.04%, Test Loss: 0.9652, Test Accuracy: 56.96%\n",
      "Epoch [139/2500], Train Loss: 0.9868, Train Accuracy: 57.75%, Test Loss: 0.9705, Test Accuracy: 56.96%\n",
      "Epoch [140/2500], Train Loss: 0.9869, Train Accuracy: 57.61%, Test Loss: 0.9534, Test Accuracy: 58.23%\n",
      "Epoch [141/2500], Train Loss: 0.9845, Train Accuracy: 57.04%, Test Loss: 0.9471, Test Accuracy: 59.49%\n",
      "Epoch [142/2500], Train Loss: 0.9724, Train Accuracy: 57.61%, Test Loss: 0.9662, Test Accuracy: 56.96%\n",
      "Epoch [143/2500], Train Loss: 0.9903, Train Accuracy: 57.61%, Test Loss: 0.9513, Test Accuracy: 59.49%\n",
      "Epoch [144/2500], Train Loss: 0.9673, Train Accuracy: 57.61%, Test Loss: 0.9468, Test Accuracy: 59.49%\n",
      "Epoch [145/2500], Train Loss: 0.9838, Train Accuracy: 57.61%, Test Loss: 0.9556, Test Accuracy: 58.23%\n",
      "Epoch [146/2500], Train Loss: 0.9724, Train Accuracy: 59.17%, Test Loss: 0.9517, Test Accuracy: 58.23%\n",
      "Epoch [147/2500], Train Loss: 0.9826, Train Accuracy: 57.47%, Test Loss: 0.9513, Test Accuracy: 58.23%\n",
      "Epoch [148/2500], Train Loss: 0.9958, Train Accuracy: 56.76%, Test Loss: 0.9524, Test Accuracy: 58.23%\n",
      "Epoch [149/2500], Train Loss: 0.9717, Train Accuracy: 57.75%, Test Loss: 0.9503, Test Accuracy: 58.23%\n",
      "Epoch [150/2500], Train Loss: 0.9772, Train Accuracy: 57.33%, Test Loss: 0.9476, Test Accuracy: 59.49%\n",
      "Epoch [151/2500], Train Loss: 0.9924, Train Accuracy: 58.18%, Test Loss: 0.9550, Test Accuracy: 58.23%\n",
      "Epoch [152/2500], Train Loss: 0.9760, Train Accuracy: 57.75%, Test Loss: 0.9458, Test Accuracy: 58.23%\n",
      "Epoch [153/2500], Train Loss: 0.9783, Train Accuracy: 57.75%, Test Loss: 0.9620, Test Accuracy: 58.23%\n",
      "Epoch [154/2500], Train Loss: 0.9798, Train Accuracy: 56.90%, Test Loss: 0.9523, Test Accuracy: 58.23%\n",
      "Epoch [155/2500], Train Loss: 0.9713, Train Accuracy: 57.75%, Test Loss: 0.9498, Test Accuracy: 59.49%\n",
      "Epoch [156/2500], Train Loss: 0.9709, Train Accuracy: 57.33%, Test Loss: 0.9547, Test Accuracy: 58.23%\n",
      "Epoch [157/2500], Train Loss: 0.9968, Train Accuracy: 57.89%, Test Loss: 0.9531, Test Accuracy: 58.23%\n",
      "Epoch [158/2500], Train Loss: 0.9748, Train Accuracy: 57.61%, Test Loss: 0.9534, Test Accuracy: 58.23%\n",
      "Epoch [159/2500], Train Loss: 0.9681, Train Accuracy: 57.47%, Test Loss: 0.9672, Test Accuracy: 58.23%\n",
      "Epoch [160/2500], Train Loss: 0.9554, Train Accuracy: 58.18%, Test Loss: 0.9610, Test Accuracy: 58.23%\n",
      "Epoch [161/2500], Train Loss: 0.9718, Train Accuracy: 57.89%, Test Loss: 0.9493, Test Accuracy: 58.23%\n",
      "Epoch [162/2500], Train Loss: 0.9850, Train Accuracy: 58.04%, Test Loss: 0.9468, Test Accuracy: 59.49%\n",
      "Epoch [163/2500], Train Loss: 0.9671, Train Accuracy: 58.18%, Test Loss: 0.9626, Test Accuracy: 56.96%\n",
      "Epoch [164/2500], Train Loss: 0.9434, Train Accuracy: 58.61%, Test Loss: 0.9774, Test Accuracy: 58.23%\n",
      "Epoch [165/2500], Train Loss: 0.9656, Train Accuracy: 58.32%, Test Loss: 0.9513, Test Accuracy: 58.23%\n",
      "Epoch [166/2500], Train Loss: 0.9674, Train Accuracy: 58.32%, Test Loss: 0.9591, Test Accuracy: 56.96%\n",
      "Epoch [167/2500], Train Loss: 0.9790, Train Accuracy: 58.75%, Test Loss: 0.9710, Test Accuracy: 58.23%\n",
      "Epoch [168/2500], Train Loss: 0.9605, Train Accuracy: 57.89%, Test Loss: 0.9695, Test Accuracy: 58.23%\n",
      "Epoch [169/2500], Train Loss: 0.9697, Train Accuracy: 59.03%, Test Loss: 0.9603, Test Accuracy: 58.23%\n",
      "Epoch [170/2500], Train Loss: 0.9474, Train Accuracy: 58.46%, Test Loss: 0.9627, Test Accuracy: 58.23%\n",
      "Epoch [171/2500], Train Loss: 0.9604, Train Accuracy: 57.33%, Test Loss: 0.9621, Test Accuracy: 59.49%\n",
      "Epoch [172/2500], Train Loss: 0.9591, Train Accuracy: 59.60%, Test Loss: 0.9452, Test Accuracy: 58.23%\n",
      "Epoch [173/2500], Train Loss: 0.9623, Train Accuracy: 58.61%, Test Loss: 0.9586, Test Accuracy: 58.23%\n",
      "Epoch [174/2500], Train Loss: 0.9624, Train Accuracy: 57.04%, Test Loss: 0.9616, Test Accuracy: 58.23%\n",
      "Epoch [175/2500], Train Loss: 0.9684, Train Accuracy: 57.89%, Test Loss: 0.9595, Test Accuracy: 59.49%\n",
      "Epoch [176/2500], Train Loss: 0.9729, Train Accuracy: 59.17%, Test Loss: 0.9590, Test Accuracy: 59.49%\n",
      "Epoch [177/2500], Train Loss: 0.9739, Train Accuracy: 59.03%, Test Loss: 0.9634, Test Accuracy: 58.23%\n",
      "Epoch [178/2500], Train Loss: 0.9582, Train Accuracy: 58.89%, Test Loss: 0.9660, Test Accuracy: 58.23%\n",
      "Epoch [179/2500], Train Loss: 0.9563, Train Accuracy: 59.46%, Test Loss: 0.9800, Test Accuracy: 58.23%\n",
      "Epoch [180/2500], Train Loss: 0.9633, Train Accuracy: 58.61%, Test Loss: 0.9740, Test Accuracy: 58.23%\n",
      "Epoch [181/2500], Train Loss: 0.9622, Train Accuracy: 58.75%, Test Loss: 0.9560, Test Accuracy: 59.49%\n",
      "Epoch [182/2500], Train Loss: 0.9629, Train Accuracy: 58.18%, Test Loss: 0.9558, Test Accuracy: 59.49%\n",
      "Epoch [183/2500], Train Loss: 0.9720, Train Accuracy: 57.04%, Test Loss: 0.9413, Test Accuracy: 59.49%\n",
      "Epoch [184/2500], Train Loss: 0.9497, Train Accuracy: 59.03%, Test Loss: 0.9745, Test Accuracy: 58.23%\n",
      "Epoch [185/2500], Train Loss: 0.9540, Train Accuracy: 58.46%, Test Loss: 0.9625, Test Accuracy: 59.49%\n",
      "Epoch [186/2500], Train Loss: 0.9525, Train Accuracy: 59.46%, Test Loss: 0.9521, Test Accuracy: 59.49%\n",
      "Epoch [187/2500], Train Loss: 0.9450, Train Accuracy: 59.17%, Test Loss: 0.9605, Test Accuracy: 59.49%\n",
      "Epoch [188/2500], Train Loss: 0.9738, Train Accuracy: 57.75%, Test Loss: 0.9628, Test Accuracy: 59.49%\n",
      "Epoch [189/2500], Train Loss: 0.9746, Train Accuracy: 57.89%, Test Loss: 0.9587, Test Accuracy: 59.49%\n",
      "Epoch [190/2500], Train Loss: 0.9393, Train Accuracy: 57.47%, Test Loss: 0.9523, Test Accuracy: 59.49%\n",
      "Epoch [191/2500], Train Loss: 0.9618, Train Accuracy: 59.03%, Test Loss: 0.9557, Test Accuracy: 59.49%\n",
      "Epoch [192/2500], Train Loss: 0.9546, Train Accuracy: 58.89%, Test Loss: 0.9677, Test Accuracy: 59.49%\n",
      "Epoch [193/2500], Train Loss: 0.9555, Train Accuracy: 59.17%, Test Loss: 0.9532, Test Accuracy: 59.49%\n",
      "Epoch [194/2500], Train Loss: 0.9423, Train Accuracy: 59.74%, Test Loss: 0.9589, Test Accuracy: 59.49%\n",
      "Epoch [195/2500], Train Loss: 0.9581, Train Accuracy: 57.18%, Test Loss: 0.9536, Test Accuracy: 59.49%\n",
      "Epoch [196/2500], Train Loss: 0.9285, Train Accuracy: 58.46%, Test Loss: 0.9638, Test Accuracy: 59.49%\n",
      "Epoch [197/2500], Train Loss: 0.9537, Train Accuracy: 58.46%, Test Loss: 0.9537, Test Accuracy: 59.49%\n",
      "Epoch [198/2500], Train Loss: 0.9561, Train Accuracy: 57.75%, Test Loss: 0.9546, Test Accuracy: 59.49%\n",
      "Epoch [199/2500], Train Loss: 0.9624, Train Accuracy: 58.18%, Test Loss: 0.9555, Test Accuracy: 59.49%\n",
      "Epoch [200/2500], Train Loss: 0.9395, Train Accuracy: 59.89%, Test Loss: 0.9598, Test Accuracy: 59.49%\n",
      "Epoch [201/2500], Train Loss: 0.9506, Train Accuracy: 57.33%, Test Loss: 0.9620, Test Accuracy: 59.49%\n",
      "Epoch [202/2500], Train Loss: 0.9704, Train Accuracy: 56.61%, Test Loss: 0.9574, Test Accuracy: 60.76%\n",
      "Epoch [203/2500], Train Loss: 0.9466, Train Accuracy: 58.18%, Test Loss: 0.9737, Test Accuracy: 60.76%\n",
      "Epoch [204/2500], Train Loss: 0.9510, Train Accuracy: 58.32%, Test Loss: 0.9552, Test Accuracy: 59.49%\n",
      "Epoch [205/2500], Train Loss: 0.9613, Train Accuracy: 58.61%, Test Loss: 0.9391, Test Accuracy: 59.49%\n",
      "Epoch [206/2500], Train Loss: 0.9423, Train Accuracy: 57.75%, Test Loss: 0.9335, Test Accuracy: 59.49%\n",
      "Epoch [207/2500], Train Loss: 0.9422, Train Accuracy: 57.89%, Test Loss: 0.9637, Test Accuracy: 59.49%\n",
      "Epoch [208/2500], Train Loss: 0.9502, Train Accuracy: 58.46%, Test Loss: 0.9444, Test Accuracy: 59.49%\n",
      "Epoch [209/2500], Train Loss: 0.9593, Train Accuracy: 58.18%, Test Loss: 0.9609, Test Accuracy: 59.49%\n",
      "Epoch [210/2500], Train Loss: 0.9468, Train Accuracy: 58.18%, Test Loss: 0.9343, Test Accuracy: 59.49%\n",
      "Epoch [211/2500], Train Loss: 0.9423, Train Accuracy: 60.31%, Test Loss: 0.9420, Test Accuracy: 59.49%\n",
      "Epoch [212/2500], Train Loss: 0.9452, Train Accuracy: 58.89%, Test Loss: 0.9446, Test Accuracy: 59.49%\n",
      "Epoch [213/2500], Train Loss: 0.9550, Train Accuracy: 60.17%, Test Loss: 0.9528, Test Accuracy: 59.49%\n",
      "Epoch [214/2500], Train Loss: 0.9230, Train Accuracy: 58.61%, Test Loss: 0.9366, Test Accuracy: 59.49%\n",
      "Epoch [215/2500], Train Loss: 0.9256, Train Accuracy: 58.18%, Test Loss: 0.9480, Test Accuracy: 59.49%\n",
      "Epoch [216/2500], Train Loss: 0.9336, Train Accuracy: 58.32%, Test Loss: 0.9572, Test Accuracy: 59.49%\n",
      "Epoch [217/2500], Train Loss: 0.9358, Train Accuracy: 58.04%, Test Loss: 0.9474, Test Accuracy: 59.49%\n",
      "Epoch [218/2500], Train Loss: 0.9559, Train Accuracy: 58.32%, Test Loss: 0.9354, Test Accuracy: 59.49%\n",
      "Epoch [219/2500], Train Loss: 0.9333, Train Accuracy: 57.89%, Test Loss: 0.9563, Test Accuracy: 59.49%\n",
      "Epoch [220/2500], Train Loss: 0.9312, Train Accuracy: 58.75%, Test Loss: 0.9560, Test Accuracy: 59.49%\n",
      "Epoch [221/2500], Train Loss: 0.9507, Train Accuracy: 58.61%, Test Loss: 0.9465, Test Accuracy: 59.49%\n",
      "Epoch [222/2500], Train Loss: 0.9519, Train Accuracy: 58.75%, Test Loss: 0.9459, Test Accuracy: 59.49%\n",
      "Epoch [223/2500], Train Loss: 0.9450, Train Accuracy: 59.03%, Test Loss: 0.9406, Test Accuracy: 59.49%\n",
      "Epoch [224/2500], Train Loss: 0.9284, Train Accuracy: 59.60%, Test Loss: 0.9474, Test Accuracy: 60.76%\n",
      "Epoch [225/2500], Train Loss: 0.9250, Train Accuracy: 59.03%, Test Loss: 0.9537, Test Accuracy: 59.49%\n",
      "Epoch [226/2500], Train Loss: 0.9457, Train Accuracy: 59.46%, Test Loss: 0.9417, Test Accuracy: 60.76%\n",
      "Epoch [227/2500], Train Loss: 0.9347, Train Accuracy: 60.03%, Test Loss: 0.9469, Test Accuracy: 59.49%\n",
      "Epoch [228/2500], Train Loss: 0.9336, Train Accuracy: 59.89%, Test Loss: 0.9573, Test Accuracy: 59.49%\n",
      "Epoch [229/2500], Train Loss: 0.9253, Train Accuracy: 58.04%, Test Loss: 0.9373, Test Accuracy: 59.49%\n",
      "Epoch [230/2500], Train Loss: 0.9274, Train Accuracy: 60.17%, Test Loss: 0.9459, Test Accuracy: 60.76%\n",
      "Epoch [231/2500], Train Loss: 0.9223, Train Accuracy: 58.18%, Test Loss: 0.9475, Test Accuracy: 59.49%\n",
      "Epoch [232/2500], Train Loss: 0.9287, Train Accuracy: 58.46%, Test Loss: 0.9634, Test Accuracy: 56.96%\n",
      "Epoch [233/2500], Train Loss: 0.9450, Train Accuracy: 59.46%, Test Loss: 0.9244, Test Accuracy: 59.49%\n",
      "Epoch [234/2500], Train Loss: 0.9390, Train Accuracy: 58.32%, Test Loss: 0.9628, Test Accuracy: 59.49%\n",
      "Epoch [235/2500], Train Loss: 0.9273, Train Accuracy: 58.89%, Test Loss: 0.9478, Test Accuracy: 59.49%\n",
      "Epoch [236/2500], Train Loss: 0.9276, Train Accuracy: 59.03%, Test Loss: 0.9431, Test Accuracy: 60.76%\n",
      "Epoch [237/2500], Train Loss: 0.9275, Train Accuracy: 59.03%, Test Loss: 0.9343, Test Accuracy: 59.49%\n",
      "Epoch [238/2500], Train Loss: 0.9097, Train Accuracy: 59.89%, Test Loss: 0.9353, Test Accuracy: 60.76%\n",
      "Epoch [239/2500], Train Loss: 0.9245, Train Accuracy: 58.32%, Test Loss: 0.9395, Test Accuracy: 59.49%\n",
      "Epoch [240/2500], Train Loss: 0.9379, Train Accuracy: 59.89%, Test Loss: 0.9408, Test Accuracy: 59.49%\n",
      "Epoch [241/2500], Train Loss: 0.9371, Train Accuracy: 59.89%, Test Loss: 0.9387, Test Accuracy: 59.49%\n",
      "Epoch [242/2500], Train Loss: 0.9412, Train Accuracy: 57.89%, Test Loss: 0.9300, Test Accuracy: 59.49%\n",
      "Epoch [243/2500], Train Loss: 0.9189, Train Accuracy: 59.32%, Test Loss: 0.9299, Test Accuracy: 59.49%\n",
      "Epoch [244/2500], Train Loss: 0.9469, Train Accuracy: 58.32%, Test Loss: 0.9335, Test Accuracy: 60.76%\n",
      "Epoch [245/2500], Train Loss: 0.9199, Train Accuracy: 60.17%, Test Loss: 0.9374, Test Accuracy: 59.49%\n",
      "Epoch [246/2500], Train Loss: 0.9393, Train Accuracy: 58.18%, Test Loss: 0.9325, Test Accuracy: 59.49%\n",
      "Epoch [247/2500], Train Loss: 0.9223, Train Accuracy: 59.32%, Test Loss: 0.9363, Test Accuracy: 59.49%\n",
      "Epoch [248/2500], Train Loss: 0.9372, Train Accuracy: 59.60%, Test Loss: 0.9432, Test Accuracy: 58.23%\n",
      "Epoch [249/2500], Train Loss: 0.9301, Train Accuracy: 59.03%, Test Loss: 0.9365, Test Accuracy: 59.49%\n",
      "Epoch [250/2500], Train Loss: 0.9203, Train Accuracy: 58.18%, Test Loss: 0.9458, Test Accuracy: 58.23%\n",
      "Epoch [251/2500], Train Loss: 0.9288, Train Accuracy: 57.75%, Test Loss: 0.9389, Test Accuracy: 60.76%\n",
      "Epoch [252/2500], Train Loss: 0.9101, Train Accuracy: 59.32%, Test Loss: 0.9553, Test Accuracy: 59.49%\n",
      "Epoch [253/2500], Train Loss: 0.9202, Train Accuracy: 60.17%, Test Loss: 0.9538, Test Accuracy: 60.76%\n",
      "Epoch [254/2500], Train Loss: 0.9239, Train Accuracy: 59.17%, Test Loss: 0.9395, Test Accuracy: 60.76%\n",
      "Epoch [255/2500], Train Loss: 0.9157, Train Accuracy: 59.46%, Test Loss: 0.9355, Test Accuracy: 58.23%\n",
      "Epoch [256/2500], Train Loss: 0.9070, Train Accuracy: 59.89%, Test Loss: 0.9408, Test Accuracy: 59.49%\n",
      "Epoch [257/2500], Train Loss: 0.9068, Train Accuracy: 59.32%, Test Loss: 0.9430, Test Accuracy: 59.49%\n",
      "Epoch [258/2500], Train Loss: 0.9084, Train Accuracy: 58.89%, Test Loss: 0.9386, Test Accuracy: 59.49%\n",
      "Epoch [259/2500], Train Loss: 0.9217, Train Accuracy: 60.31%, Test Loss: 0.9304, Test Accuracy: 59.49%\n",
      "Epoch [260/2500], Train Loss: 0.9273, Train Accuracy: 60.03%, Test Loss: 0.9507, Test Accuracy: 59.49%\n",
      "Epoch [261/2500], Train Loss: 0.9141, Train Accuracy: 60.74%, Test Loss: 0.9502, Test Accuracy: 59.49%\n",
      "Epoch [262/2500], Train Loss: 0.9294, Train Accuracy: 59.60%, Test Loss: 0.9404, Test Accuracy: 59.49%\n",
      "Epoch [263/2500], Train Loss: 0.9104, Train Accuracy: 60.46%, Test Loss: 0.9423, Test Accuracy: 59.49%\n",
      "Epoch [264/2500], Train Loss: 0.9367, Train Accuracy: 58.46%, Test Loss: 0.9329, Test Accuracy: 59.49%\n",
      "Epoch [265/2500], Train Loss: 0.9022, Train Accuracy: 59.46%, Test Loss: 0.9493, Test Accuracy: 59.49%\n",
      "Epoch [266/2500], Train Loss: 0.9176, Train Accuracy: 60.31%, Test Loss: 0.9614, Test Accuracy: 59.49%\n",
      "Epoch [267/2500], Train Loss: 0.9148, Train Accuracy: 58.04%, Test Loss: 0.9485, Test Accuracy: 59.49%\n",
      "Epoch [268/2500], Train Loss: 0.9159, Train Accuracy: 57.47%, Test Loss: 0.9473, Test Accuracy: 59.49%\n",
      "Epoch [269/2500], Train Loss: 0.9355, Train Accuracy: 59.60%, Test Loss: 0.9670, Test Accuracy: 56.96%\n",
      "Epoch [270/2500], Train Loss: 0.9013, Train Accuracy: 60.31%, Test Loss: 0.9635, Test Accuracy: 59.49%\n",
      "Epoch [271/2500], Train Loss: 0.9100, Train Accuracy: 58.89%, Test Loss: 0.9398, Test Accuracy: 60.76%\n",
      "Epoch [272/2500], Train Loss: 0.8936, Train Accuracy: 60.46%, Test Loss: 0.9494, Test Accuracy: 60.76%\n",
      "Epoch [273/2500], Train Loss: 0.9029, Train Accuracy: 60.88%, Test Loss: 0.9377, Test Accuracy: 59.49%\n",
      "Epoch [274/2500], Train Loss: 0.9097, Train Accuracy: 60.03%, Test Loss: 0.9381, Test Accuracy: 59.49%\n",
      "Epoch [275/2500], Train Loss: 0.9066, Train Accuracy: 59.17%, Test Loss: 0.9366, Test Accuracy: 59.49%\n",
      "Epoch [276/2500], Train Loss: 0.9112, Train Accuracy: 59.60%, Test Loss: 0.9284, Test Accuracy: 59.49%\n",
      "Epoch [277/2500], Train Loss: 0.9000, Train Accuracy: 59.46%, Test Loss: 0.9349, Test Accuracy: 60.76%\n",
      "Epoch [278/2500], Train Loss: 0.9014, Train Accuracy: 60.31%, Test Loss: 0.9219, Test Accuracy: 62.03%\n",
      "Epoch [279/2500], Train Loss: 0.9151, Train Accuracy: 61.59%, Test Loss: 0.9297, Test Accuracy: 59.49%\n",
      "Epoch [280/2500], Train Loss: 0.9163, Train Accuracy: 59.74%, Test Loss: 0.9357, Test Accuracy: 59.49%\n",
      "Epoch [281/2500], Train Loss: 0.9176, Train Accuracy: 61.02%, Test Loss: 0.9434, Test Accuracy: 56.96%\n",
      "Epoch [282/2500], Train Loss: 0.9154, Train Accuracy: 59.74%, Test Loss: 0.9401, Test Accuracy: 58.23%\n",
      "Epoch [283/2500], Train Loss: 0.9292, Train Accuracy: 60.17%, Test Loss: 0.9374, Test Accuracy: 60.76%\n",
      "Epoch [284/2500], Train Loss: 0.9154, Train Accuracy: 59.17%, Test Loss: 0.9302, Test Accuracy: 59.49%\n",
      "Epoch [285/2500], Train Loss: 0.9329, Train Accuracy: 59.46%, Test Loss: 0.9346, Test Accuracy: 60.76%\n",
      "Epoch [286/2500], Train Loss: 0.9194, Train Accuracy: 61.02%, Test Loss: 0.9253, Test Accuracy: 60.76%\n",
      "Epoch [287/2500], Train Loss: 0.9060, Train Accuracy: 60.60%, Test Loss: 0.9321, Test Accuracy: 59.49%\n",
      "Epoch [288/2500], Train Loss: 0.9095, Train Accuracy: 60.31%, Test Loss: 0.9241, Test Accuracy: 60.76%\n",
      "Epoch [289/2500], Train Loss: 0.9106, Train Accuracy: 59.89%, Test Loss: 0.9441, Test Accuracy: 60.76%\n",
      "Epoch [290/2500], Train Loss: 0.9052, Train Accuracy: 58.04%, Test Loss: 0.9540, Test Accuracy: 60.76%\n",
      "Epoch [291/2500], Train Loss: 0.9020, Train Accuracy: 60.46%, Test Loss: 0.9319, Test Accuracy: 63.29%\n",
      "Epoch [292/2500], Train Loss: 0.9282, Train Accuracy: 60.31%, Test Loss: 0.9351, Test Accuracy: 62.03%\n",
      "Epoch [293/2500], Train Loss: 0.8991, Train Accuracy: 60.31%, Test Loss: 0.9308, Test Accuracy: 62.03%\n",
      "Epoch [294/2500], Train Loss: 0.9123, Train Accuracy: 61.02%, Test Loss: 0.9259, Test Accuracy: 60.76%\n",
      "Epoch [295/2500], Train Loss: 0.9258, Train Accuracy: 60.03%, Test Loss: 0.9185, Test Accuracy: 60.76%\n",
      "Epoch [296/2500], Train Loss: 0.9127, Train Accuracy: 59.32%, Test Loss: 0.9306, Test Accuracy: 63.29%\n",
      "Epoch [297/2500], Train Loss: 0.8906, Train Accuracy: 58.89%, Test Loss: 0.9442, Test Accuracy: 59.49%\n",
      "Epoch [298/2500], Train Loss: 0.8959, Train Accuracy: 59.60%, Test Loss: 0.9555, Test Accuracy: 59.49%\n",
      "Epoch [299/2500], Train Loss: 0.8819, Train Accuracy: 61.59%, Test Loss: 0.9472, Test Accuracy: 60.76%\n",
      "Epoch [300/2500], Train Loss: 0.9149, Train Accuracy: 59.60%, Test Loss: 0.9184, Test Accuracy: 62.03%\n",
      "Epoch [301/2500], Train Loss: 0.9106, Train Accuracy: 60.31%, Test Loss: 0.9541, Test Accuracy: 60.76%\n",
      "Epoch [302/2500], Train Loss: 0.9106, Train Accuracy: 60.88%, Test Loss: 0.9556, Test Accuracy: 59.49%\n",
      "Epoch [303/2500], Train Loss: 0.8906, Train Accuracy: 61.45%, Test Loss: 0.9513, Test Accuracy: 60.76%\n",
      "Epoch [304/2500], Train Loss: 0.9274, Train Accuracy: 58.46%, Test Loss: 0.9292, Test Accuracy: 62.03%\n",
      "Epoch [305/2500], Train Loss: 0.9221, Train Accuracy: 60.03%, Test Loss: 0.9255, Test Accuracy: 60.76%\n",
      "Epoch [306/2500], Train Loss: 0.9009, Train Accuracy: 61.02%, Test Loss: 0.9418, Test Accuracy: 60.76%\n",
      "Epoch [307/2500], Train Loss: 0.8947, Train Accuracy: 60.03%, Test Loss: 0.9436, Test Accuracy: 63.29%\n",
      "Epoch [308/2500], Train Loss: 0.9023, Train Accuracy: 61.02%, Test Loss: 0.9466, Test Accuracy: 63.29%\n",
      "Epoch [309/2500], Train Loss: 0.8982, Train Accuracy: 61.17%, Test Loss: 0.9497, Test Accuracy: 62.03%\n",
      "Epoch [310/2500], Train Loss: 0.9309, Train Accuracy: 59.03%, Test Loss: 0.9297, Test Accuracy: 62.03%\n",
      "Epoch [311/2500], Train Loss: 0.9047, Train Accuracy: 60.74%, Test Loss: 0.9386, Test Accuracy: 62.03%\n",
      "Epoch [312/2500], Train Loss: 0.9117, Train Accuracy: 60.88%, Test Loss: 0.9352, Test Accuracy: 63.29%\n",
      "Epoch [313/2500], Train Loss: 0.9202, Train Accuracy: 60.17%, Test Loss: 0.9278, Test Accuracy: 63.29%\n",
      "Epoch [314/2500], Train Loss: 0.8994, Train Accuracy: 60.03%, Test Loss: 0.9387, Test Accuracy: 63.29%\n",
      "Epoch [315/2500], Train Loss: 0.9059, Train Accuracy: 59.32%, Test Loss: 0.9346, Test Accuracy: 63.29%\n",
      "Epoch [316/2500], Train Loss: 0.9054, Train Accuracy: 61.88%, Test Loss: 0.9328, Test Accuracy: 63.29%\n",
      "Epoch [317/2500], Train Loss: 0.9208, Train Accuracy: 60.60%, Test Loss: 0.9304, Test Accuracy: 62.03%\n",
      "Epoch [318/2500], Train Loss: 0.9064, Train Accuracy: 60.31%, Test Loss: 0.9372, Test Accuracy: 62.03%\n",
      "Epoch [319/2500], Train Loss: 0.8953, Train Accuracy: 61.31%, Test Loss: 0.9487, Test Accuracy: 62.03%\n",
      "Epoch [320/2500], Train Loss: 0.8977, Train Accuracy: 59.74%, Test Loss: 0.9340, Test Accuracy: 62.03%\n",
      "Epoch [321/2500], Train Loss: 0.9022, Train Accuracy: 60.60%, Test Loss: 0.9370, Test Accuracy: 62.03%\n",
      "Epoch [322/2500], Train Loss: 0.8947, Train Accuracy: 60.03%, Test Loss: 0.9347, Test Accuracy: 62.03%\n",
      "Epoch [323/2500], Train Loss: 0.8953, Train Accuracy: 59.89%, Test Loss: 0.9464, Test Accuracy: 60.76%\n",
      "Epoch [324/2500], Train Loss: 0.8854, Train Accuracy: 59.74%, Test Loss: 0.9287, Test Accuracy: 63.29%\n",
      "Epoch [325/2500], Train Loss: 0.8967, Train Accuracy: 59.74%, Test Loss: 0.9380, Test Accuracy: 60.76%\n",
      "Epoch [326/2500], Train Loss: 0.8882, Train Accuracy: 60.74%, Test Loss: 0.9398, Test Accuracy: 62.03%\n",
      "Epoch [327/2500], Train Loss: 0.9142, Train Accuracy: 59.89%, Test Loss: 0.9286, Test Accuracy: 60.76%\n",
      "Epoch [328/2500], Train Loss: 0.8917, Train Accuracy: 61.17%, Test Loss: 0.9391, Test Accuracy: 62.03%\n",
      "Epoch [329/2500], Train Loss: 0.9067, Train Accuracy: 59.03%, Test Loss: 0.9284, Test Accuracy: 62.03%\n",
      "Epoch [330/2500], Train Loss: 0.8866, Train Accuracy: 59.74%, Test Loss: 0.9188, Test Accuracy: 63.29%\n",
      "Epoch [331/2500], Train Loss: 0.8923, Train Accuracy: 61.59%, Test Loss: 0.9356, Test Accuracy: 63.29%\n",
      "Epoch [332/2500], Train Loss: 0.9231, Train Accuracy: 59.03%, Test Loss: 0.9352, Test Accuracy: 63.29%\n",
      "Epoch [333/2500], Train Loss: 0.8883, Train Accuracy: 59.32%, Test Loss: 0.9454, Test Accuracy: 63.29%\n",
      "Epoch [334/2500], Train Loss: 0.8639, Train Accuracy: 62.59%, Test Loss: 0.9409, Test Accuracy: 63.29%\n",
      "Epoch [335/2500], Train Loss: 0.8924, Train Accuracy: 60.17%, Test Loss: 0.9385, Test Accuracy: 63.29%\n",
      "Epoch [336/2500], Train Loss: 0.8854, Train Accuracy: 61.59%, Test Loss: 0.9417, Test Accuracy: 63.29%\n",
      "Epoch [337/2500], Train Loss: 0.9028, Train Accuracy: 60.46%, Test Loss: 0.9540, Test Accuracy: 63.29%\n",
      "Epoch [338/2500], Train Loss: 0.8783, Train Accuracy: 60.17%, Test Loss: 0.9507, Test Accuracy: 63.29%\n",
      "Epoch [339/2500], Train Loss: 0.8970, Train Accuracy: 61.31%, Test Loss: 0.9432, Test Accuracy: 63.29%\n",
      "Epoch [340/2500], Train Loss: 0.8928, Train Accuracy: 60.46%, Test Loss: 0.9236, Test Accuracy: 63.29%\n",
      "Epoch [341/2500], Train Loss: 0.8985, Train Accuracy: 59.74%, Test Loss: 0.9479, Test Accuracy: 63.29%\n",
      "Epoch [342/2500], Train Loss: 0.8838, Train Accuracy: 60.17%, Test Loss: 0.9357, Test Accuracy: 63.29%\n",
      "Epoch [343/2500], Train Loss: 0.8840, Train Accuracy: 60.88%, Test Loss: 0.9401, Test Accuracy: 63.29%\n",
      "Epoch [344/2500], Train Loss: 0.8821, Train Accuracy: 61.88%, Test Loss: 0.9287, Test Accuracy: 63.29%\n",
      "Epoch [345/2500], Train Loss: 0.8963, Train Accuracy: 59.60%, Test Loss: 0.9540, Test Accuracy: 63.29%\n",
      "Epoch [346/2500], Train Loss: 0.9141, Train Accuracy: 60.88%, Test Loss: 0.9417, Test Accuracy: 63.29%\n",
      "Epoch [347/2500], Train Loss: 0.8948, Train Accuracy: 61.02%, Test Loss: 0.9147, Test Accuracy: 62.03%\n",
      "Epoch [348/2500], Train Loss: 0.8796, Train Accuracy: 61.02%, Test Loss: 0.9535, Test Accuracy: 62.03%\n",
      "Epoch [349/2500], Train Loss: 0.8865, Train Accuracy: 59.60%, Test Loss: 0.9497, Test Accuracy: 62.03%\n",
      "Epoch [350/2500], Train Loss: 0.8816, Train Accuracy: 61.02%, Test Loss: 0.9368, Test Accuracy: 62.03%\n",
      "Epoch [351/2500], Train Loss: 0.8752, Train Accuracy: 61.88%, Test Loss: 0.9326, Test Accuracy: 62.03%\n",
      "Epoch [352/2500], Train Loss: 0.9054, Train Accuracy: 60.74%, Test Loss: 0.9435, Test Accuracy: 62.03%\n",
      "Epoch [353/2500], Train Loss: 0.8671, Train Accuracy: 62.73%, Test Loss: 0.9469, Test Accuracy: 62.03%\n",
      "Epoch [354/2500], Train Loss: 0.9078, Train Accuracy: 59.17%, Test Loss: 0.9186, Test Accuracy: 62.03%\n",
      "Epoch [355/2500], Train Loss: 0.8858, Train Accuracy: 60.31%, Test Loss: 0.9244, Test Accuracy: 62.03%\n",
      "Epoch [356/2500], Train Loss: 0.8883, Train Accuracy: 61.88%, Test Loss: 0.9229, Test Accuracy: 62.03%\n",
      "Epoch [357/2500], Train Loss: 0.8982, Train Accuracy: 61.02%, Test Loss: 0.9418, Test Accuracy: 62.03%\n",
      "Epoch [358/2500], Train Loss: 0.8835, Train Accuracy: 61.74%, Test Loss: 0.9492, Test Accuracy: 62.03%\n",
      "Epoch [359/2500], Train Loss: 0.8846, Train Accuracy: 62.59%, Test Loss: 0.9498, Test Accuracy: 62.03%\n",
      "Epoch [360/2500], Train Loss: 0.8922, Train Accuracy: 60.03%, Test Loss: 0.9597, Test Accuracy: 62.03%\n",
      "Epoch [361/2500], Train Loss: 0.8658, Train Accuracy: 61.45%, Test Loss: 0.9370, Test Accuracy: 62.03%\n",
      "Epoch [362/2500], Train Loss: 0.8958, Train Accuracy: 61.02%, Test Loss: 0.9218, Test Accuracy: 62.03%\n",
      "Epoch [363/2500], Train Loss: 0.9044, Train Accuracy: 58.61%, Test Loss: 0.9551, Test Accuracy: 60.76%\n",
      "Epoch [364/2500], Train Loss: 0.8700, Train Accuracy: 63.16%, Test Loss: 0.9488, Test Accuracy: 62.03%\n",
      "Epoch [365/2500], Train Loss: 0.8970, Train Accuracy: 60.60%, Test Loss: 0.9357, Test Accuracy: 62.03%\n",
      "Epoch [366/2500], Train Loss: 0.8666, Train Accuracy: 61.02%, Test Loss: 0.9309, Test Accuracy: 62.03%\n",
      "Epoch [367/2500], Train Loss: 0.8998, Train Accuracy: 59.74%, Test Loss: 0.9350, Test Accuracy: 62.03%\n",
      "Epoch [368/2500], Train Loss: 0.8851, Train Accuracy: 59.89%, Test Loss: 0.9290, Test Accuracy: 62.03%\n",
      "Epoch [369/2500], Train Loss: 0.8771, Train Accuracy: 61.59%, Test Loss: 0.9225, Test Accuracy: 62.03%\n",
      "Epoch [370/2500], Train Loss: 0.8750, Train Accuracy: 60.17%, Test Loss: 0.9474, Test Accuracy: 60.76%\n",
      "Epoch [371/2500], Train Loss: 0.8789, Train Accuracy: 61.74%, Test Loss: 0.9389, Test Accuracy: 62.03%\n",
      "Epoch [372/2500], Train Loss: 0.8669, Train Accuracy: 61.88%, Test Loss: 0.9312, Test Accuracy: 62.03%\n",
      "Epoch [373/2500], Train Loss: 0.8923, Train Accuracy: 60.17%, Test Loss: 0.9399, Test Accuracy: 62.03%\n",
      "Epoch [374/2500], Train Loss: 0.8858, Train Accuracy: 63.02%, Test Loss: 0.9334, Test Accuracy: 62.03%\n",
      "Epoch [375/2500], Train Loss: 0.8795, Train Accuracy: 59.32%, Test Loss: 0.9285, Test Accuracy: 62.03%\n",
      "Epoch [376/2500], Train Loss: 0.8574, Train Accuracy: 62.73%, Test Loss: 0.9177, Test Accuracy: 63.29%\n",
      "Epoch [377/2500], Train Loss: 0.8723, Train Accuracy: 62.30%, Test Loss: 0.9509, Test Accuracy: 60.76%\n",
      "Epoch [378/2500], Train Loss: 0.8785, Train Accuracy: 60.60%, Test Loss: 0.9284, Test Accuracy: 63.29%\n",
      "Epoch [379/2500], Train Loss: 0.8594, Train Accuracy: 60.60%, Test Loss: 0.9391, Test Accuracy: 62.03%\n",
      "Epoch [380/2500], Train Loss: 0.8644, Train Accuracy: 61.31%, Test Loss: 0.9325, Test Accuracy: 63.29%\n",
      "Epoch [381/2500], Train Loss: 0.8980, Train Accuracy: 61.31%, Test Loss: 0.9240, Test Accuracy: 62.03%\n",
      "Epoch [382/2500], Train Loss: 0.8714, Train Accuracy: 62.87%, Test Loss: 0.9326, Test Accuracy: 63.29%\n",
      "Epoch [383/2500], Train Loss: 0.8834, Train Accuracy: 61.02%, Test Loss: 0.9238, Test Accuracy: 62.03%\n",
      "Epoch [384/2500], Train Loss: 0.8725, Train Accuracy: 61.45%, Test Loss: 0.9179, Test Accuracy: 62.03%\n",
      "Epoch [385/2500], Train Loss: 0.8889, Train Accuracy: 62.45%, Test Loss: 0.9353, Test Accuracy: 62.03%\n",
      "Epoch [386/2500], Train Loss: 0.8737, Train Accuracy: 62.02%, Test Loss: 0.9290, Test Accuracy: 60.76%\n",
      "Epoch [387/2500], Train Loss: 0.8753, Train Accuracy: 62.45%, Test Loss: 0.9196, Test Accuracy: 63.29%\n",
      "Epoch [388/2500], Train Loss: 0.8585, Train Accuracy: 60.46%, Test Loss: 0.9301, Test Accuracy: 62.03%\n",
      "Epoch [389/2500], Train Loss: 0.9028, Train Accuracy: 61.45%, Test Loss: 0.9251, Test Accuracy: 63.29%\n",
      "Epoch [390/2500], Train Loss: 0.8788, Train Accuracy: 62.59%, Test Loss: 0.9295, Test Accuracy: 63.29%\n",
      "Epoch [391/2500], Train Loss: 0.8542, Train Accuracy: 61.31%, Test Loss: 0.9354, Test Accuracy: 60.76%\n",
      "Epoch [392/2500], Train Loss: 0.8741, Train Accuracy: 60.88%, Test Loss: 0.9444, Test Accuracy: 62.03%\n",
      "Epoch [393/2500], Train Loss: 0.8946, Train Accuracy: 60.46%, Test Loss: 0.9377, Test Accuracy: 60.76%\n",
      "Epoch [394/2500], Train Loss: 0.8913, Train Accuracy: 58.89%, Test Loss: 0.9345, Test Accuracy: 60.76%\n",
      "Epoch [395/2500], Train Loss: 0.8885, Train Accuracy: 59.60%, Test Loss: 0.9272, Test Accuracy: 63.29%\n",
      "Epoch [396/2500], Train Loss: 0.8605, Train Accuracy: 62.73%, Test Loss: 0.9384, Test Accuracy: 63.29%\n",
      "Epoch [397/2500], Train Loss: 0.8550, Train Accuracy: 61.59%, Test Loss: 0.9281, Test Accuracy: 63.29%\n",
      "Epoch [398/2500], Train Loss: 0.8691, Train Accuracy: 62.02%, Test Loss: 0.9336, Test Accuracy: 60.76%\n",
      "Epoch [399/2500], Train Loss: 0.8831, Train Accuracy: 60.60%, Test Loss: 0.9183, Test Accuracy: 60.76%\n",
      "Epoch [400/2500], Train Loss: 0.8628, Train Accuracy: 61.88%, Test Loss: 0.9269, Test Accuracy: 62.03%\n",
      "Epoch [401/2500], Train Loss: 0.8796, Train Accuracy: 60.74%, Test Loss: 0.9299, Test Accuracy: 63.29%\n",
      "Epoch [402/2500], Train Loss: 0.8819, Train Accuracy: 60.46%, Test Loss: 0.9267, Test Accuracy: 60.76%\n",
      "Epoch [403/2500], Train Loss: 0.8795, Train Accuracy: 62.30%, Test Loss: 0.9466, Test Accuracy: 62.03%\n",
      "Epoch [404/2500], Train Loss: 0.8617, Train Accuracy: 61.02%, Test Loss: 0.9218, Test Accuracy: 62.03%\n",
      "Epoch [405/2500], Train Loss: 0.8658, Train Accuracy: 62.16%, Test Loss: 0.9294, Test Accuracy: 62.03%\n",
      "Epoch [406/2500], Train Loss: 0.8678, Train Accuracy: 60.88%, Test Loss: 0.9157, Test Accuracy: 62.03%\n",
      "Epoch [407/2500], Train Loss: 0.8760, Train Accuracy: 61.02%, Test Loss: 0.9326, Test Accuracy: 62.03%\n",
      "Epoch [408/2500], Train Loss: 0.8425, Train Accuracy: 62.59%, Test Loss: 0.9241, Test Accuracy: 63.29%\n",
      "Epoch [409/2500], Train Loss: 0.8623, Train Accuracy: 61.17%, Test Loss: 0.9443, Test Accuracy: 60.76%\n",
      "Epoch [410/2500], Train Loss: 0.8777, Train Accuracy: 61.17%, Test Loss: 0.9248, Test Accuracy: 60.76%\n",
      "Epoch [411/2500], Train Loss: 0.8748, Train Accuracy: 61.45%, Test Loss: 0.9443, Test Accuracy: 60.76%\n",
      "Epoch [412/2500], Train Loss: 0.8812, Train Accuracy: 60.74%, Test Loss: 0.9286, Test Accuracy: 62.03%\n",
      "Epoch [413/2500], Train Loss: 0.8776, Train Accuracy: 62.16%, Test Loss: 0.9511, Test Accuracy: 60.76%\n",
      "Epoch [414/2500], Train Loss: 0.8678, Train Accuracy: 61.02%, Test Loss: 0.9103, Test Accuracy: 60.76%\n",
      "Epoch [415/2500], Train Loss: 0.8801, Train Accuracy: 61.74%, Test Loss: 0.9137, Test Accuracy: 60.76%\n",
      "Epoch [416/2500], Train Loss: 0.8816, Train Accuracy: 62.59%, Test Loss: 0.9204, Test Accuracy: 62.03%\n",
      "Epoch [417/2500], Train Loss: 0.8495, Train Accuracy: 60.88%, Test Loss: 0.9564, Test Accuracy: 60.76%\n",
      "Epoch [418/2500], Train Loss: 0.8485, Train Accuracy: 62.16%, Test Loss: 0.9294, Test Accuracy: 60.76%\n",
      "Epoch [419/2500], Train Loss: 0.8558, Train Accuracy: 62.02%, Test Loss: 0.9355, Test Accuracy: 62.03%\n",
      "Epoch [420/2500], Train Loss: 0.8556, Train Accuracy: 61.45%, Test Loss: 0.9262, Test Accuracy: 62.03%\n",
      "Epoch [421/2500], Train Loss: 0.8469, Train Accuracy: 61.88%, Test Loss: 0.9358, Test Accuracy: 60.76%\n",
      "Epoch [422/2500], Train Loss: 0.8483, Train Accuracy: 62.87%, Test Loss: 0.9226, Test Accuracy: 62.03%\n",
      "Epoch [423/2500], Train Loss: 0.8689, Train Accuracy: 60.60%, Test Loss: 0.9369, Test Accuracy: 60.76%\n",
      "Epoch [424/2500], Train Loss: 0.8455, Train Accuracy: 62.45%, Test Loss: 0.9213, Test Accuracy: 62.03%\n",
      "Epoch [425/2500], Train Loss: 0.8720, Train Accuracy: 62.30%, Test Loss: 0.9257, Test Accuracy: 62.03%\n",
      "Epoch [426/2500], Train Loss: 0.8529, Train Accuracy: 60.88%, Test Loss: 0.9193, Test Accuracy: 62.03%\n",
      "Epoch [427/2500], Train Loss: 0.8727, Train Accuracy: 61.02%, Test Loss: 0.9126, Test Accuracy: 62.03%\n",
      "Epoch [428/2500], Train Loss: 0.8582, Train Accuracy: 60.74%, Test Loss: 0.9217, Test Accuracy: 62.03%\n",
      "Epoch [429/2500], Train Loss: 0.8627, Train Accuracy: 60.17%, Test Loss: 0.9153, Test Accuracy: 62.03%\n",
      "Epoch [430/2500], Train Loss: 0.8501, Train Accuracy: 61.17%, Test Loss: 0.9252, Test Accuracy: 62.03%\n",
      "Epoch [431/2500], Train Loss: 0.8534, Train Accuracy: 62.45%, Test Loss: 0.9339, Test Accuracy: 62.03%\n",
      "Epoch [432/2500], Train Loss: 0.8558, Train Accuracy: 62.16%, Test Loss: 0.9375, Test Accuracy: 63.29%\n",
      "Epoch [433/2500], Train Loss: 0.8598, Train Accuracy: 62.02%, Test Loss: 0.9073, Test Accuracy: 62.03%\n",
      "Epoch [434/2500], Train Loss: 0.8515, Train Accuracy: 62.02%, Test Loss: 0.9402, Test Accuracy: 62.03%\n",
      "Epoch [435/2500], Train Loss: 0.8490, Train Accuracy: 62.16%, Test Loss: 0.9293, Test Accuracy: 62.03%\n",
      "Epoch [436/2500], Train Loss: 0.8564, Train Accuracy: 63.02%, Test Loss: 0.9171, Test Accuracy: 62.03%\n",
      "Epoch [437/2500], Train Loss: 0.8639, Train Accuracy: 61.17%, Test Loss: 0.9112, Test Accuracy: 62.03%\n",
      "Epoch [438/2500], Train Loss: 0.8517, Train Accuracy: 61.02%, Test Loss: 0.9344, Test Accuracy: 62.03%\n",
      "Epoch [439/2500], Train Loss: 0.8537, Train Accuracy: 61.59%, Test Loss: 0.9339, Test Accuracy: 63.29%\n",
      "Epoch [440/2500], Train Loss: 0.8586, Train Accuracy: 61.45%, Test Loss: 0.9221, Test Accuracy: 62.03%\n",
      "Epoch [441/2500], Train Loss: 0.8581, Train Accuracy: 62.45%, Test Loss: 0.9161, Test Accuracy: 62.03%\n",
      "Epoch [442/2500], Train Loss: 0.8563, Train Accuracy: 62.16%, Test Loss: 0.9376, Test Accuracy: 63.29%\n",
      "Epoch [443/2500], Train Loss: 0.8965, Train Accuracy: 59.60%, Test Loss: 0.9222, Test Accuracy: 62.03%\n",
      "Epoch [444/2500], Train Loss: 0.8631, Train Accuracy: 63.30%, Test Loss: 0.9319, Test Accuracy: 62.03%\n",
      "Epoch [445/2500], Train Loss: 0.8633, Train Accuracy: 61.31%, Test Loss: 0.9094, Test Accuracy: 62.03%\n",
      "Epoch [446/2500], Train Loss: 0.8293, Train Accuracy: 61.59%, Test Loss: 0.9307, Test Accuracy: 63.29%\n",
      "Epoch [447/2500], Train Loss: 0.8807, Train Accuracy: 61.59%, Test Loss: 0.9321, Test Accuracy: 62.03%\n",
      "Epoch [448/2500], Train Loss: 0.8542, Train Accuracy: 61.45%, Test Loss: 0.9314, Test Accuracy: 62.03%\n",
      "Epoch [449/2500], Train Loss: 0.8771, Train Accuracy: 61.59%, Test Loss: 0.9272, Test Accuracy: 60.76%\n",
      "Epoch [450/2500], Train Loss: 0.8496, Train Accuracy: 60.74%, Test Loss: 0.9124, Test Accuracy: 63.29%\n",
      "Epoch [451/2500], Train Loss: 0.8364, Train Accuracy: 62.45%, Test Loss: 0.9299, Test Accuracy: 62.03%\n",
      "Epoch [452/2500], Train Loss: 0.8410, Train Accuracy: 62.59%, Test Loss: 0.9362, Test Accuracy: 63.29%\n",
      "Epoch [453/2500], Train Loss: 0.8599, Train Accuracy: 59.89%, Test Loss: 0.9410, Test Accuracy: 62.03%\n",
      "Epoch [454/2500], Train Loss: 0.8505, Train Accuracy: 61.02%, Test Loss: 0.9466, Test Accuracy: 62.03%\n",
      "Epoch [455/2500], Train Loss: 0.8510, Train Accuracy: 63.87%, Test Loss: 0.9416, Test Accuracy: 62.03%\n",
      "Epoch [456/2500], Train Loss: 0.8447, Train Accuracy: 63.58%, Test Loss: 0.9340, Test Accuracy: 63.29%\n",
      "Epoch [457/2500], Train Loss: 0.8752, Train Accuracy: 60.17%, Test Loss: 0.9106, Test Accuracy: 62.03%\n",
      "Epoch [458/2500], Train Loss: 0.8377, Train Accuracy: 62.59%, Test Loss: 0.9294, Test Accuracy: 62.03%\n",
      "Epoch [459/2500], Train Loss: 0.8516, Train Accuracy: 62.30%, Test Loss: 0.9335, Test Accuracy: 63.29%\n",
      "Epoch [460/2500], Train Loss: 0.8474, Train Accuracy: 62.59%, Test Loss: 0.9311, Test Accuracy: 63.29%\n",
      "Epoch [461/2500], Train Loss: 0.8547, Train Accuracy: 62.87%, Test Loss: 0.9345, Test Accuracy: 62.03%\n",
      "Epoch [462/2500], Train Loss: 0.8600, Train Accuracy: 62.30%, Test Loss: 0.9432, Test Accuracy: 62.03%\n",
      "Epoch [463/2500], Train Loss: 0.8338, Train Accuracy: 63.30%, Test Loss: 0.9332, Test Accuracy: 62.03%\n",
      "Epoch [464/2500], Train Loss: 0.8409, Train Accuracy: 62.45%, Test Loss: 0.9372, Test Accuracy: 64.56%\n",
      "Epoch [465/2500], Train Loss: 0.8272, Train Accuracy: 62.16%, Test Loss: 0.9116, Test Accuracy: 63.29%\n",
      "Epoch [466/2500], Train Loss: 0.8499, Train Accuracy: 62.73%, Test Loss: 0.9365, Test Accuracy: 62.03%\n",
      "Epoch [467/2500], Train Loss: 0.8481, Train Accuracy: 62.02%, Test Loss: 0.9080, Test Accuracy: 62.03%\n",
      "Epoch [468/2500], Train Loss: 0.8619, Train Accuracy: 62.73%, Test Loss: 0.9176, Test Accuracy: 63.29%\n",
      "Epoch [469/2500], Train Loss: 0.8557, Train Accuracy: 61.88%, Test Loss: 0.9226, Test Accuracy: 63.29%\n",
      "Epoch [470/2500], Train Loss: 0.8495, Train Accuracy: 62.30%, Test Loss: 0.9241, Test Accuracy: 62.03%\n",
      "Epoch [471/2500], Train Loss: 0.8434, Train Accuracy: 62.02%, Test Loss: 0.9216, Test Accuracy: 63.29%\n",
      "Epoch [472/2500], Train Loss: 0.8668, Train Accuracy: 62.45%, Test Loss: 0.9188, Test Accuracy: 62.03%\n",
      "Epoch [473/2500], Train Loss: 0.8506, Train Accuracy: 61.31%, Test Loss: 0.9277, Test Accuracy: 62.03%\n",
      "Epoch [474/2500], Train Loss: 0.8405, Train Accuracy: 63.73%, Test Loss: 0.9228, Test Accuracy: 60.76%\n",
      "Epoch [475/2500], Train Loss: 0.8581, Train Accuracy: 61.45%, Test Loss: 0.9218, Test Accuracy: 63.29%\n",
      "Epoch [476/2500], Train Loss: 0.8251, Train Accuracy: 62.02%, Test Loss: 0.9184, Test Accuracy: 62.03%\n",
      "Epoch [477/2500], Train Loss: 0.8304, Train Accuracy: 62.45%, Test Loss: 0.9138, Test Accuracy: 63.29%\n",
      "Epoch [478/2500], Train Loss: 0.8499, Train Accuracy: 62.45%, Test Loss: 0.9022, Test Accuracy: 63.29%\n",
      "Epoch [479/2500], Train Loss: 0.8280, Train Accuracy: 63.02%, Test Loss: 0.9346, Test Accuracy: 63.29%\n",
      "Epoch [480/2500], Train Loss: 0.8442, Train Accuracy: 63.73%, Test Loss: 0.9456, Test Accuracy: 62.03%\n",
      "Epoch [481/2500], Train Loss: 0.8360, Train Accuracy: 62.02%, Test Loss: 0.9155, Test Accuracy: 63.29%\n",
      "Epoch [482/2500], Train Loss: 0.8507, Train Accuracy: 60.88%, Test Loss: 0.9221, Test Accuracy: 60.76%\n",
      "Epoch [483/2500], Train Loss: 0.8304, Train Accuracy: 64.15%, Test Loss: 0.9195, Test Accuracy: 62.03%\n",
      "Epoch [484/2500], Train Loss: 0.8446, Train Accuracy: 64.01%, Test Loss: 0.9015, Test Accuracy: 62.03%\n",
      "Epoch [485/2500], Train Loss: 0.8609, Train Accuracy: 61.88%, Test Loss: 0.9057, Test Accuracy: 60.76%\n",
      "Epoch [486/2500], Train Loss: 0.8379, Train Accuracy: 62.73%, Test Loss: 0.9104, Test Accuracy: 62.03%\n",
      "Epoch [487/2500], Train Loss: 0.8294, Train Accuracy: 64.58%, Test Loss: 0.8996, Test Accuracy: 62.03%\n",
      "Epoch [488/2500], Train Loss: 0.8472, Train Accuracy: 61.17%, Test Loss: 0.9086, Test Accuracy: 62.03%\n",
      "Epoch [489/2500], Train Loss: 0.8398, Train Accuracy: 61.88%, Test Loss: 0.9058, Test Accuracy: 62.03%\n",
      "Epoch [490/2500], Train Loss: 0.8446, Train Accuracy: 61.45%, Test Loss: 0.9179, Test Accuracy: 62.03%\n",
      "Epoch [491/2500], Train Loss: 0.8626, Train Accuracy: 60.17%, Test Loss: 0.9149, Test Accuracy: 62.03%\n",
      "Epoch [492/2500], Train Loss: 0.8272, Train Accuracy: 62.45%, Test Loss: 0.9312, Test Accuracy: 60.76%\n",
      "Epoch [493/2500], Train Loss: 0.8578, Train Accuracy: 62.87%, Test Loss: 0.8944, Test Accuracy: 62.03%\n",
      "Epoch [494/2500], Train Loss: 0.8285, Train Accuracy: 63.16%, Test Loss: 0.9066, Test Accuracy: 60.76%\n",
      "Epoch [495/2500], Train Loss: 0.8345, Train Accuracy: 62.73%, Test Loss: 0.9167, Test Accuracy: 62.03%\n",
      "Epoch [496/2500], Train Loss: 0.8365, Train Accuracy: 64.58%, Test Loss: 0.8953, Test Accuracy: 62.03%\n",
      "Epoch [497/2500], Train Loss: 0.8233, Train Accuracy: 61.88%, Test Loss: 0.9195, Test Accuracy: 62.03%\n",
      "Epoch [498/2500], Train Loss: 0.8138, Train Accuracy: 63.02%, Test Loss: 0.9177, Test Accuracy: 63.29%\n",
      "Epoch [499/2500], Train Loss: 0.8273, Train Accuracy: 63.44%, Test Loss: 0.8963, Test Accuracy: 62.03%\n",
      "Epoch [500/2500], Train Loss: 0.8359, Train Accuracy: 61.74%, Test Loss: 0.9011, Test Accuracy: 62.03%\n",
      "Epoch [501/2500], Train Loss: 0.8340, Train Accuracy: 60.46%, Test Loss: 0.8941, Test Accuracy: 62.03%\n",
      "Epoch [502/2500], Train Loss: 0.8452, Train Accuracy: 63.44%, Test Loss: 0.8969, Test Accuracy: 62.03%\n",
      "Epoch [503/2500], Train Loss: 0.8655, Train Accuracy: 63.73%, Test Loss: 0.9142, Test Accuracy: 62.03%\n",
      "Epoch [504/2500], Train Loss: 0.8460, Train Accuracy: 64.30%, Test Loss: 0.9047, Test Accuracy: 60.76%\n",
      "Epoch [505/2500], Train Loss: 0.8291, Train Accuracy: 61.31%, Test Loss: 0.9061, Test Accuracy: 62.03%\n",
      "Epoch [506/2500], Train Loss: 0.8296, Train Accuracy: 63.73%, Test Loss: 0.9120, Test Accuracy: 60.76%\n",
      "Epoch [507/2500], Train Loss: 0.8384, Train Accuracy: 62.02%, Test Loss: 0.9153, Test Accuracy: 60.76%\n",
      "Epoch [508/2500], Train Loss: 0.8625, Train Accuracy: 61.88%, Test Loss: 0.9054, Test Accuracy: 62.03%\n",
      "Epoch [509/2500], Train Loss: 0.8511, Train Accuracy: 60.46%, Test Loss: 0.8966, Test Accuracy: 62.03%\n",
      "Epoch [510/2500], Train Loss: 0.8220, Train Accuracy: 63.16%, Test Loss: 0.9206, Test Accuracy: 62.03%\n",
      "Epoch [511/2500], Train Loss: 0.8415, Train Accuracy: 61.88%, Test Loss: 0.9236, Test Accuracy: 63.29%\n",
      "Epoch [512/2500], Train Loss: 0.8600, Train Accuracy: 62.59%, Test Loss: 0.8953, Test Accuracy: 62.03%\n",
      "Epoch [513/2500], Train Loss: 0.8329, Train Accuracy: 63.73%, Test Loss: 0.9169, Test Accuracy: 62.03%\n",
      "Epoch [514/2500], Train Loss: 0.8495, Train Accuracy: 62.45%, Test Loss: 0.8949, Test Accuracy: 62.03%\n",
      "Epoch [515/2500], Train Loss: 0.8327, Train Accuracy: 64.01%, Test Loss: 0.9032, Test Accuracy: 62.03%\n",
      "Epoch [516/2500], Train Loss: 0.8402, Train Accuracy: 62.87%, Test Loss: 0.9199, Test Accuracy: 63.29%\n",
      "Epoch [517/2500], Train Loss: 0.8577, Train Accuracy: 62.87%, Test Loss: 0.8938, Test Accuracy: 62.03%\n",
      "Epoch [518/2500], Train Loss: 0.8114, Train Accuracy: 63.30%, Test Loss: 0.9077, Test Accuracy: 60.76%\n",
      "Epoch [519/2500], Train Loss: 0.8365, Train Accuracy: 65.43%, Test Loss: 0.9110, Test Accuracy: 62.03%\n",
      "Epoch [520/2500], Train Loss: 0.8192, Train Accuracy: 63.02%, Test Loss: 0.9250, Test Accuracy: 63.29%\n",
      "Epoch [521/2500], Train Loss: 0.8252, Train Accuracy: 64.86%, Test Loss: 0.9037, Test Accuracy: 62.03%\n",
      "Epoch [522/2500], Train Loss: 0.8162, Train Accuracy: 63.16%, Test Loss: 0.9272, Test Accuracy: 63.29%\n",
      "Epoch [523/2500], Train Loss: 0.8269, Train Accuracy: 62.87%, Test Loss: 0.9107, Test Accuracy: 63.29%\n",
      "Epoch [524/2500], Train Loss: 0.8540, Train Accuracy: 64.01%, Test Loss: 0.9044, Test Accuracy: 62.03%\n",
      "Epoch [525/2500], Train Loss: 0.8417, Train Accuracy: 62.59%, Test Loss: 0.9117, Test Accuracy: 63.29%\n",
      "Epoch [526/2500], Train Loss: 0.8377, Train Accuracy: 62.02%, Test Loss: 0.9266, Test Accuracy: 63.29%\n",
      "Epoch [527/2500], Train Loss: 0.8237, Train Accuracy: 61.17%, Test Loss: 0.9152, Test Accuracy: 60.76%\n",
      "Epoch [528/2500], Train Loss: 0.8018, Train Accuracy: 63.87%, Test Loss: 0.9390, Test Accuracy: 63.29%\n",
      "Epoch [529/2500], Train Loss: 0.8248, Train Accuracy: 62.73%, Test Loss: 0.9131, Test Accuracy: 62.03%\n",
      "Epoch [530/2500], Train Loss: 0.8433, Train Accuracy: 60.60%, Test Loss: 0.9035, Test Accuracy: 63.29%\n",
      "Epoch [531/2500], Train Loss: 0.8359, Train Accuracy: 62.16%, Test Loss: 0.8917, Test Accuracy: 62.03%\n",
      "Epoch [532/2500], Train Loss: 0.8276, Train Accuracy: 63.87%, Test Loss: 0.9141, Test Accuracy: 63.29%\n",
      "Epoch [533/2500], Train Loss: 0.8474, Train Accuracy: 63.30%, Test Loss: 0.9065, Test Accuracy: 62.03%\n",
      "Epoch [534/2500], Train Loss: 0.8263, Train Accuracy: 62.59%, Test Loss: 0.8994, Test Accuracy: 62.03%\n",
      "Epoch [535/2500], Train Loss: 0.8292, Train Accuracy: 63.16%, Test Loss: 0.9098, Test Accuracy: 63.29%\n",
      "Epoch [536/2500], Train Loss: 0.8137, Train Accuracy: 62.45%, Test Loss: 0.9027, Test Accuracy: 63.29%\n",
      "Epoch [537/2500], Train Loss: 0.8464, Train Accuracy: 64.01%, Test Loss: 0.9003, Test Accuracy: 63.29%\n",
      "Epoch [538/2500], Train Loss: 0.8238, Train Accuracy: 62.73%, Test Loss: 0.9287, Test Accuracy: 62.03%\n",
      "Epoch [539/2500], Train Loss: 0.8306, Train Accuracy: 63.02%, Test Loss: 0.9046, Test Accuracy: 63.29%\n",
      "Epoch [540/2500], Train Loss: 0.8309, Train Accuracy: 64.15%, Test Loss: 0.8958, Test Accuracy: 63.29%\n",
      "Epoch [541/2500], Train Loss: 0.8419, Train Accuracy: 63.58%, Test Loss: 0.9020, Test Accuracy: 64.56%\n",
      "Epoch [542/2500], Train Loss: 0.8239, Train Accuracy: 63.30%, Test Loss: 0.9006, Test Accuracy: 63.29%\n",
      "Epoch [543/2500], Train Loss: 0.8377, Train Accuracy: 64.30%, Test Loss: 0.8934, Test Accuracy: 64.56%\n",
      "Epoch [544/2500], Train Loss: 0.8252, Train Accuracy: 63.30%, Test Loss: 0.8978, Test Accuracy: 64.56%\n",
      "Epoch [545/2500], Train Loss: 0.8366, Train Accuracy: 64.30%, Test Loss: 0.8969, Test Accuracy: 63.29%\n",
      "Epoch [546/2500], Train Loss: 0.8408, Train Accuracy: 64.58%, Test Loss: 0.8875, Test Accuracy: 64.56%\n",
      "Epoch [547/2500], Train Loss: 0.8289, Train Accuracy: 62.30%, Test Loss: 0.9123, Test Accuracy: 64.56%\n",
      "Epoch [548/2500], Train Loss: 0.8348, Train Accuracy: 62.73%, Test Loss: 0.8949, Test Accuracy: 63.29%\n",
      "Epoch [549/2500], Train Loss: 0.8216, Train Accuracy: 62.87%, Test Loss: 0.8956, Test Accuracy: 62.03%\n",
      "Epoch [550/2500], Train Loss: 0.8229, Train Accuracy: 63.02%, Test Loss: 0.9064, Test Accuracy: 63.29%\n",
      "Epoch [551/2500], Train Loss: 0.8129, Train Accuracy: 64.72%, Test Loss: 0.8966, Test Accuracy: 63.29%\n",
      "Epoch [552/2500], Train Loss: 0.8402, Train Accuracy: 63.87%, Test Loss: 0.9035, Test Accuracy: 63.29%\n",
      "Epoch [553/2500], Train Loss: 0.8309, Train Accuracy: 63.73%, Test Loss: 0.8968, Test Accuracy: 63.29%\n",
      "Epoch [554/2500], Train Loss: 0.8406, Train Accuracy: 63.16%, Test Loss: 0.8892, Test Accuracy: 63.29%\n",
      "Epoch [555/2500], Train Loss: 0.8068, Train Accuracy: 63.02%, Test Loss: 0.8990, Test Accuracy: 64.56%\n",
      "Epoch [556/2500], Train Loss: 0.8303, Train Accuracy: 63.30%, Test Loss: 0.8926, Test Accuracy: 63.29%\n",
      "Epoch [557/2500], Train Loss: 0.8292, Train Accuracy: 63.44%, Test Loss: 0.9076, Test Accuracy: 64.56%\n",
      "Epoch [558/2500], Train Loss: 0.8285, Train Accuracy: 64.01%, Test Loss: 0.9096, Test Accuracy: 63.29%\n",
      "Epoch [559/2500], Train Loss: 0.8071, Train Accuracy: 64.86%, Test Loss: 0.9051, Test Accuracy: 64.56%\n",
      "Epoch [560/2500], Train Loss: 0.8220, Train Accuracy: 63.87%, Test Loss: 0.8977, Test Accuracy: 64.56%\n",
      "Epoch [561/2500], Train Loss: 0.8115, Train Accuracy: 64.01%, Test Loss: 0.9174, Test Accuracy: 62.03%\n",
      "Epoch [562/2500], Train Loss: 0.7927, Train Accuracy: 65.43%, Test Loss: 0.9089, Test Accuracy: 64.56%\n",
      "Epoch [563/2500], Train Loss: 0.8185, Train Accuracy: 62.16%, Test Loss: 0.9010, Test Accuracy: 63.29%\n",
      "Epoch [564/2500], Train Loss: 0.8170, Train Accuracy: 62.87%, Test Loss: 0.9021, Test Accuracy: 64.56%\n",
      "Epoch [565/2500], Train Loss: 0.8199, Train Accuracy: 62.45%, Test Loss: 0.9041, Test Accuracy: 64.56%\n",
      "Epoch [566/2500], Train Loss: 0.8106, Train Accuracy: 63.02%, Test Loss: 0.9078, Test Accuracy: 64.56%\n",
      "Epoch [567/2500], Train Loss: 0.8197, Train Accuracy: 62.02%, Test Loss: 0.9083, Test Accuracy: 64.56%\n",
      "Epoch [568/2500], Train Loss: 0.8124, Train Accuracy: 63.73%, Test Loss: 0.9017, Test Accuracy: 64.56%\n",
      "Epoch [569/2500], Train Loss: 0.8024, Train Accuracy: 66.29%, Test Loss: 0.9024, Test Accuracy: 64.56%\n",
      "Epoch [570/2500], Train Loss: 0.8148, Train Accuracy: 65.01%, Test Loss: 0.9103, Test Accuracy: 64.56%\n",
      "Epoch [571/2500], Train Loss: 0.8051, Train Accuracy: 65.72%, Test Loss: 0.8976, Test Accuracy: 65.82%\n",
      "Epoch [572/2500], Train Loss: 0.8334, Train Accuracy: 63.30%, Test Loss: 0.8850, Test Accuracy: 64.56%\n",
      "Epoch [573/2500], Train Loss: 0.8049, Train Accuracy: 63.58%, Test Loss: 0.9045, Test Accuracy: 64.56%\n",
      "Epoch [574/2500], Train Loss: 0.8396, Train Accuracy: 61.88%, Test Loss: 0.8918, Test Accuracy: 64.56%\n",
      "Epoch [575/2500], Train Loss: 0.8100, Train Accuracy: 65.15%, Test Loss: 0.8916, Test Accuracy: 63.29%\n",
      "Epoch [576/2500], Train Loss: 0.8167, Train Accuracy: 64.58%, Test Loss: 0.8896, Test Accuracy: 64.56%\n",
      "Epoch [577/2500], Train Loss: 0.8337, Train Accuracy: 62.87%, Test Loss: 0.9114, Test Accuracy: 62.03%\n",
      "Epoch [578/2500], Train Loss: 0.8257, Train Accuracy: 63.16%, Test Loss: 0.8960, Test Accuracy: 64.56%\n",
      "Epoch [579/2500], Train Loss: 0.8138, Train Accuracy: 62.87%, Test Loss: 0.8923, Test Accuracy: 63.29%\n",
      "Epoch [580/2500], Train Loss: 0.8037, Train Accuracy: 64.15%, Test Loss: 0.8867, Test Accuracy: 63.29%\n",
      "Epoch [581/2500], Train Loss: 0.8266, Train Accuracy: 62.16%, Test Loss: 0.8813, Test Accuracy: 63.29%\n",
      "Epoch [582/2500], Train Loss: 0.8121, Train Accuracy: 61.59%, Test Loss: 0.8832, Test Accuracy: 63.29%\n",
      "Epoch [583/2500], Train Loss: 0.8140, Train Accuracy: 62.73%, Test Loss: 0.8806, Test Accuracy: 63.29%\n",
      "Epoch [584/2500], Train Loss: 0.8028, Train Accuracy: 64.01%, Test Loss: 0.8903, Test Accuracy: 64.56%\n",
      "Epoch [585/2500], Train Loss: 0.8345, Train Accuracy: 63.16%, Test Loss: 0.8965, Test Accuracy: 64.56%\n",
      "Epoch [586/2500], Train Loss: 0.8477, Train Accuracy: 63.44%, Test Loss: 0.9024, Test Accuracy: 63.29%\n",
      "Epoch [587/2500], Train Loss: 0.8052, Train Accuracy: 62.30%, Test Loss: 0.8927, Test Accuracy: 63.29%\n",
      "Epoch [588/2500], Train Loss: 0.8147, Train Accuracy: 64.01%, Test Loss: 0.8989, Test Accuracy: 64.56%\n",
      "Epoch [589/2500], Train Loss: 0.8268, Train Accuracy: 63.30%, Test Loss: 0.8772, Test Accuracy: 63.29%\n",
      "Epoch [590/2500], Train Loss: 0.8206, Train Accuracy: 63.02%, Test Loss: 0.8831, Test Accuracy: 63.29%\n",
      "Epoch [591/2500], Train Loss: 0.8316, Train Accuracy: 63.02%, Test Loss: 0.8896, Test Accuracy: 63.29%\n",
      "Epoch [592/2500], Train Loss: 0.8097, Train Accuracy: 63.73%, Test Loss: 0.8728, Test Accuracy: 64.56%\n",
      "Epoch [593/2500], Train Loss: 0.8134, Train Accuracy: 64.15%, Test Loss: 0.8791, Test Accuracy: 65.82%\n",
      "Epoch [594/2500], Train Loss: 0.8332, Train Accuracy: 63.44%, Test Loss: 0.9044, Test Accuracy: 62.03%\n",
      "Epoch [595/2500], Train Loss: 0.8319, Train Accuracy: 64.15%, Test Loss: 0.8752, Test Accuracy: 64.56%\n",
      "Epoch [596/2500], Train Loss: 0.8150, Train Accuracy: 63.87%, Test Loss: 0.8959, Test Accuracy: 62.03%\n",
      "Epoch [597/2500], Train Loss: 0.8138, Train Accuracy: 63.02%, Test Loss: 0.8833, Test Accuracy: 64.56%\n",
      "Epoch [598/2500], Train Loss: 0.8235, Train Accuracy: 62.02%, Test Loss: 0.8869, Test Accuracy: 67.09%\n",
      "Epoch [599/2500], Train Loss: 0.8024, Train Accuracy: 64.44%, Test Loss: 0.8898, Test Accuracy: 68.35%\n",
      "Epoch [600/2500], Train Loss: 0.8134, Train Accuracy: 63.87%, Test Loss: 0.8867, Test Accuracy: 65.82%\n",
      "Epoch [601/2500], Train Loss: 0.8200, Train Accuracy: 64.72%, Test Loss: 0.8863, Test Accuracy: 63.29%\n",
      "Epoch [602/2500], Train Loss: 0.8183, Train Accuracy: 63.58%, Test Loss: 0.8886, Test Accuracy: 63.29%\n",
      "Epoch [603/2500], Train Loss: 0.8008, Train Accuracy: 63.73%, Test Loss: 0.8850, Test Accuracy: 67.09%\n",
      "Epoch [604/2500], Train Loss: 0.7942, Train Accuracy: 63.30%, Test Loss: 0.8949, Test Accuracy: 63.29%\n",
      "Epoch [605/2500], Train Loss: 0.8302, Train Accuracy: 62.87%, Test Loss: 0.8847, Test Accuracy: 65.82%\n",
      "Epoch [606/2500], Train Loss: 0.8140, Train Accuracy: 63.30%, Test Loss: 0.8840, Test Accuracy: 64.56%\n",
      "Epoch [607/2500], Train Loss: 0.7976, Train Accuracy: 64.01%, Test Loss: 0.9022, Test Accuracy: 63.29%\n",
      "Epoch [608/2500], Train Loss: 0.8184, Train Accuracy: 62.02%, Test Loss: 0.8923, Test Accuracy: 64.56%\n",
      "Epoch [609/2500], Train Loss: 0.7957, Train Accuracy: 63.73%, Test Loss: 0.8945, Test Accuracy: 63.29%\n",
      "Epoch [610/2500], Train Loss: 0.8045, Train Accuracy: 64.15%, Test Loss: 0.9038, Test Accuracy: 63.29%\n",
      "Epoch [611/2500], Train Loss: 0.8180, Train Accuracy: 65.86%, Test Loss: 0.9003, Test Accuracy: 64.56%\n",
      "Epoch [612/2500], Train Loss: 0.8124, Train Accuracy: 62.16%, Test Loss: 0.8835, Test Accuracy: 63.29%\n",
      "Epoch [613/2500], Train Loss: 0.8195, Train Accuracy: 64.86%, Test Loss: 0.8917, Test Accuracy: 64.56%\n",
      "Epoch [614/2500], Train Loss: 0.7978, Train Accuracy: 64.15%, Test Loss: 0.9002, Test Accuracy: 64.56%\n",
      "Epoch [615/2500], Train Loss: 0.8037, Train Accuracy: 64.15%, Test Loss: 0.8912, Test Accuracy: 62.03%\n",
      "Epoch [616/2500], Train Loss: 0.7988, Train Accuracy: 65.15%, Test Loss: 0.9036, Test Accuracy: 64.56%\n",
      "Epoch [617/2500], Train Loss: 0.8033, Train Accuracy: 64.72%, Test Loss: 0.8918, Test Accuracy: 63.29%\n",
      "Epoch [618/2500], Train Loss: 0.8080, Train Accuracy: 62.73%, Test Loss: 0.8884, Test Accuracy: 63.29%\n",
      "Epoch [619/2500], Train Loss: 0.8114, Train Accuracy: 64.01%, Test Loss: 0.8740, Test Accuracy: 64.56%\n",
      "Epoch [620/2500], Train Loss: 0.8262, Train Accuracy: 64.44%, Test Loss: 0.8677, Test Accuracy: 63.29%\n",
      "Epoch [621/2500], Train Loss: 0.8162, Train Accuracy: 63.02%, Test Loss: 0.8812, Test Accuracy: 63.29%\n",
      "Epoch [622/2500], Train Loss: 0.8087, Train Accuracy: 64.15%, Test Loss: 0.8695, Test Accuracy: 65.82%\n",
      "Epoch [623/2500], Train Loss: 0.8039, Train Accuracy: 65.01%, Test Loss: 0.8797, Test Accuracy: 63.29%\n",
      "Epoch [624/2500], Train Loss: 0.7946, Train Accuracy: 65.15%, Test Loss: 0.8812, Test Accuracy: 63.29%\n",
      "Epoch [625/2500], Train Loss: 0.8105, Train Accuracy: 63.16%, Test Loss: 0.8962, Test Accuracy: 63.29%\n",
      "Epoch [626/2500], Train Loss: 0.8044, Train Accuracy: 65.29%, Test Loss: 0.8950, Test Accuracy: 62.03%\n",
      "Epoch [627/2500], Train Loss: 0.8073, Train Accuracy: 64.30%, Test Loss: 0.8942, Test Accuracy: 62.03%\n",
      "Epoch [628/2500], Train Loss: 0.8055, Train Accuracy: 64.58%, Test Loss: 0.9011, Test Accuracy: 63.29%\n",
      "Epoch [629/2500], Train Loss: 0.8185, Train Accuracy: 65.29%, Test Loss: 0.8869, Test Accuracy: 63.29%\n",
      "Epoch [630/2500], Train Loss: 0.8146, Train Accuracy: 64.44%, Test Loss: 0.8752, Test Accuracy: 63.29%\n",
      "Epoch [631/2500], Train Loss: 0.8072, Train Accuracy: 63.58%, Test Loss: 0.8775, Test Accuracy: 64.56%\n",
      "Epoch [632/2500], Train Loss: 0.8130, Train Accuracy: 62.30%, Test Loss: 0.8767, Test Accuracy: 64.56%\n",
      "Epoch [633/2500], Train Loss: 0.8220, Train Accuracy: 62.16%, Test Loss: 0.8762, Test Accuracy: 63.29%\n",
      "Epoch [634/2500], Train Loss: 0.8168, Train Accuracy: 64.72%, Test Loss: 0.8767, Test Accuracy: 60.76%\n",
      "Epoch [635/2500], Train Loss: 0.7892, Train Accuracy: 64.72%, Test Loss: 0.8941, Test Accuracy: 65.82%\n",
      "Epoch [636/2500], Train Loss: 0.7832, Train Accuracy: 64.58%, Test Loss: 0.8948, Test Accuracy: 63.29%\n",
      "Epoch [637/2500], Train Loss: 0.7985, Train Accuracy: 63.58%, Test Loss: 0.8760, Test Accuracy: 65.82%\n",
      "Epoch [638/2500], Train Loss: 0.7845, Train Accuracy: 63.44%, Test Loss: 0.9006, Test Accuracy: 64.56%\n",
      "Epoch [639/2500], Train Loss: 0.8246, Train Accuracy: 61.74%, Test Loss: 0.8820, Test Accuracy: 64.56%\n",
      "Epoch [640/2500], Train Loss: 0.7964, Train Accuracy: 64.86%, Test Loss: 0.8648, Test Accuracy: 62.03%\n",
      "Epoch [641/2500], Train Loss: 0.8086, Train Accuracy: 62.87%, Test Loss: 0.8682, Test Accuracy: 67.09%\n",
      "Epoch [642/2500], Train Loss: 0.8148, Train Accuracy: 62.87%, Test Loss: 0.8744, Test Accuracy: 64.56%\n",
      "Epoch [643/2500], Train Loss: 0.8102, Train Accuracy: 64.30%, Test Loss: 0.8801, Test Accuracy: 65.82%\n",
      "Epoch [644/2500], Train Loss: 0.8031, Train Accuracy: 66.29%, Test Loss: 0.8784, Test Accuracy: 67.09%\n",
      "Epoch [645/2500], Train Loss: 0.7911, Train Accuracy: 66.00%, Test Loss: 0.8661, Test Accuracy: 67.09%\n",
      "Epoch [646/2500], Train Loss: 0.7962, Train Accuracy: 64.30%, Test Loss: 0.8704, Test Accuracy: 63.29%\n",
      "Epoch [647/2500], Train Loss: 0.8002, Train Accuracy: 65.29%, Test Loss: 0.8597, Test Accuracy: 64.56%\n",
      "Epoch [648/2500], Train Loss: 0.7741, Train Accuracy: 65.86%, Test Loss: 0.8689, Test Accuracy: 67.09%\n",
      "Epoch [649/2500], Train Loss: 0.8067, Train Accuracy: 64.72%, Test Loss: 0.8772, Test Accuracy: 64.56%\n",
      "Epoch [650/2500], Train Loss: 0.8013, Train Accuracy: 62.45%, Test Loss: 0.8778, Test Accuracy: 63.29%\n",
      "Epoch [651/2500], Train Loss: 0.8060, Train Accuracy: 63.73%, Test Loss: 0.8697, Test Accuracy: 65.82%\n",
      "Epoch [652/2500], Train Loss: 0.7966, Train Accuracy: 65.29%, Test Loss: 0.8692, Test Accuracy: 64.56%\n",
      "Epoch [653/2500], Train Loss: 0.7914, Train Accuracy: 64.58%, Test Loss: 0.8659, Test Accuracy: 64.56%\n",
      "Epoch [654/2500], Train Loss: 0.7939, Train Accuracy: 64.01%, Test Loss: 0.8657, Test Accuracy: 64.56%\n",
      "Epoch [655/2500], Train Loss: 0.8124, Train Accuracy: 62.87%, Test Loss: 0.8662, Test Accuracy: 64.56%\n",
      "Epoch [656/2500], Train Loss: 0.7995, Train Accuracy: 62.87%, Test Loss: 0.8667, Test Accuracy: 64.56%\n",
      "Epoch [657/2500], Train Loss: 0.8010, Train Accuracy: 64.72%, Test Loss: 0.8644, Test Accuracy: 63.29%\n",
      "Epoch [658/2500], Train Loss: 0.8017, Train Accuracy: 63.58%, Test Loss: 0.8631, Test Accuracy: 62.03%\n",
      "Epoch [659/2500], Train Loss: 0.7966, Train Accuracy: 64.30%, Test Loss: 0.8880, Test Accuracy: 64.56%\n",
      "Epoch [660/2500], Train Loss: 0.8002, Train Accuracy: 64.72%, Test Loss: 0.8687, Test Accuracy: 65.82%\n",
      "Epoch [661/2500], Train Loss: 0.7949, Train Accuracy: 64.15%, Test Loss: 0.8682, Test Accuracy: 63.29%\n",
      "Epoch [662/2500], Train Loss: 0.8008, Train Accuracy: 62.73%, Test Loss: 0.8567, Test Accuracy: 63.29%\n",
      "Epoch [663/2500], Train Loss: 0.8099, Train Accuracy: 65.15%, Test Loss: 0.8700, Test Accuracy: 62.03%\n",
      "Epoch [664/2500], Train Loss: 0.8122, Train Accuracy: 64.86%, Test Loss: 0.8608, Test Accuracy: 63.29%\n",
      "Epoch [665/2500], Train Loss: 0.7795, Train Accuracy: 66.43%, Test Loss: 0.8653, Test Accuracy: 65.82%\n",
      "Epoch [666/2500], Train Loss: 0.8031, Train Accuracy: 62.30%, Test Loss: 0.8761, Test Accuracy: 64.56%\n",
      "Epoch [667/2500], Train Loss: 0.7978, Train Accuracy: 63.73%, Test Loss: 0.8707, Test Accuracy: 62.03%\n",
      "Epoch [668/2500], Train Loss: 0.7752, Train Accuracy: 65.29%, Test Loss: 0.8602, Test Accuracy: 67.09%\n",
      "Epoch [669/2500], Train Loss: 0.8211, Train Accuracy: 65.01%, Test Loss: 0.8626, Test Accuracy: 64.56%\n",
      "Epoch [670/2500], Train Loss: 0.7999, Train Accuracy: 65.29%, Test Loss: 0.8796, Test Accuracy: 63.29%\n",
      "Epoch [671/2500], Train Loss: 0.7997, Train Accuracy: 63.16%, Test Loss: 0.8512, Test Accuracy: 63.29%\n",
      "Epoch [672/2500], Train Loss: 0.7998, Train Accuracy: 65.58%, Test Loss: 0.8621, Test Accuracy: 63.29%\n",
      "Epoch [673/2500], Train Loss: 0.7978, Train Accuracy: 65.43%, Test Loss: 0.8590, Test Accuracy: 62.03%\n",
      "Epoch [674/2500], Train Loss: 0.8075, Train Accuracy: 63.58%, Test Loss: 0.8847, Test Accuracy: 64.56%\n",
      "Epoch [675/2500], Train Loss: 0.7901, Train Accuracy: 64.15%, Test Loss: 0.8649, Test Accuracy: 62.03%\n",
      "Epoch [676/2500], Train Loss: 0.8186, Train Accuracy: 63.44%, Test Loss: 0.8836, Test Accuracy: 64.56%\n",
      "Epoch [677/2500], Train Loss: 0.7991, Train Accuracy: 63.87%, Test Loss: 0.8698, Test Accuracy: 64.56%\n",
      "Epoch [678/2500], Train Loss: 0.8005, Train Accuracy: 65.01%, Test Loss: 0.8525, Test Accuracy: 63.29%\n",
      "Epoch [679/2500], Train Loss: 0.7909, Train Accuracy: 64.30%, Test Loss: 0.8653, Test Accuracy: 62.03%\n",
      "Epoch [680/2500], Train Loss: 0.8078, Train Accuracy: 63.44%, Test Loss: 0.8531, Test Accuracy: 62.03%\n",
      "Epoch [681/2500], Train Loss: 0.7745, Train Accuracy: 67.00%, Test Loss: 0.8699, Test Accuracy: 63.29%\n",
      "Epoch [682/2500], Train Loss: 0.7861, Train Accuracy: 64.15%, Test Loss: 0.8696, Test Accuracy: 68.35%\n",
      "Epoch [683/2500], Train Loss: 0.8149, Train Accuracy: 63.44%, Test Loss: 0.8567, Test Accuracy: 65.82%\n",
      "Epoch [684/2500], Train Loss: 0.7997, Train Accuracy: 64.30%, Test Loss: 0.8761, Test Accuracy: 64.56%\n",
      "Epoch [685/2500], Train Loss: 0.7849, Train Accuracy: 65.86%, Test Loss: 0.8661, Test Accuracy: 64.56%\n",
      "Epoch [686/2500], Train Loss: 0.7917, Train Accuracy: 64.58%, Test Loss: 0.8816, Test Accuracy: 64.56%\n",
      "Epoch [687/2500], Train Loss: 0.7773, Train Accuracy: 64.72%, Test Loss: 0.8765, Test Accuracy: 63.29%\n",
      "Epoch [688/2500], Train Loss: 0.7930, Train Accuracy: 65.72%, Test Loss: 0.8732, Test Accuracy: 65.82%\n",
      "Epoch [689/2500], Train Loss: 0.7750, Train Accuracy: 65.58%, Test Loss: 0.8609, Test Accuracy: 62.03%\n",
      "Epoch [690/2500], Train Loss: 0.7966, Train Accuracy: 62.30%, Test Loss: 0.8609, Test Accuracy: 64.56%\n",
      "Epoch [691/2500], Train Loss: 0.7826, Train Accuracy: 66.15%, Test Loss: 0.8675, Test Accuracy: 65.82%\n",
      "Epoch [692/2500], Train Loss: 0.7953, Train Accuracy: 65.15%, Test Loss: 0.8703, Test Accuracy: 64.56%\n",
      "Epoch [693/2500], Train Loss: 0.7960, Train Accuracy: 63.44%, Test Loss: 0.8626, Test Accuracy: 62.03%\n",
      "Epoch [694/2500], Train Loss: 0.7925, Train Accuracy: 64.01%, Test Loss: 0.8768, Test Accuracy: 67.09%\n",
      "Epoch [695/2500], Train Loss: 0.7900, Train Accuracy: 64.01%, Test Loss: 0.8693, Test Accuracy: 64.56%\n",
      "Epoch [696/2500], Train Loss: 0.7941, Train Accuracy: 64.30%, Test Loss: 0.8694, Test Accuracy: 63.29%\n",
      "Epoch [697/2500], Train Loss: 0.7956, Train Accuracy: 65.01%, Test Loss: 0.8885, Test Accuracy: 62.03%\n",
      "Epoch [698/2500], Train Loss: 0.7878, Train Accuracy: 66.00%, Test Loss: 0.8835, Test Accuracy: 62.03%\n",
      "Epoch [699/2500], Train Loss: 0.7798, Train Accuracy: 66.29%, Test Loss: 0.8810, Test Accuracy: 64.56%\n",
      "Epoch [700/2500], Train Loss: 0.8008, Train Accuracy: 63.73%, Test Loss: 0.8759, Test Accuracy: 62.03%\n",
      "Epoch [701/2500], Train Loss: 0.7852, Train Accuracy: 63.58%, Test Loss: 0.8736, Test Accuracy: 63.29%\n",
      "Epoch [702/2500], Train Loss: 0.7853, Train Accuracy: 66.29%, Test Loss: 0.8575, Test Accuracy: 67.09%\n",
      "Epoch [703/2500], Train Loss: 0.7936, Train Accuracy: 64.30%, Test Loss: 0.8815, Test Accuracy: 64.56%\n",
      "Epoch [704/2500], Train Loss: 0.8014, Train Accuracy: 64.01%, Test Loss: 0.8719, Test Accuracy: 64.56%\n",
      "Epoch [705/2500], Train Loss: 0.7791, Train Accuracy: 63.58%, Test Loss: 0.8834, Test Accuracy: 65.82%\n",
      "Epoch [706/2500], Train Loss: 0.7818, Train Accuracy: 65.58%, Test Loss: 0.8838, Test Accuracy: 65.82%\n",
      "Epoch [707/2500], Train Loss: 0.8165, Train Accuracy: 62.02%, Test Loss: 0.8882, Test Accuracy: 65.82%\n",
      "Epoch [708/2500], Train Loss: 0.7839, Train Accuracy: 66.00%, Test Loss: 0.8716, Test Accuracy: 64.56%\n",
      "Epoch [709/2500], Train Loss: 0.7740, Train Accuracy: 66.29%, Test Loss: 0.8877, Test Accuracy: 64.56%\n",
      "Epoch [710/2500], Train Loss: 0.8002, Train Accuracy: 65.01%, Test Loss: 0.8750, Test Accuracy: 65.82%\n",
      "Epoch [711/2500], Train Loss: 0.7710, Train Accuracy: 65.43%, Test Loss: 0.8666, Test Accuracy: 64.56%\n",
      "Epoch [712/2500], Train Loss: 0.7721, Train Accuracy: 65.01%, Test Loss: 0.8686, Test Accuracy: 63.29%\n",
      "Epoch [713/2500], Train Loss: 0.7829, Train Accuracy: 66.57%, Test Loss: 0.8704, Test Accuracy: 67.09%\n",
      "Epoch [714/2500], Train Loss: 0.7890, Train Accuracy: 65.15%, Test Loss: 0.8701, Test Accuracy: 67.09%\n",
      "Epoch [715/2500], Train Loss: 0.7814, Train Accuracy: 65.01%, Test Loss: 0.8625, Test Accuracy: 65.82%\n",
      "Epoch [716/2500], Train Loss: 0.7758, Train Accuracy: 64.72%, Test Loss: 0.8867, Test Accuracy: 64.56%\n",
      "Epoch [717/2500], Train Loss: 0.8056, Train Accuracy: 65.15%, Test Loss: 0.8630, Test Accuracy: 65.82%\n",
      "Epoch [718/2500], Train Loss: 0.7902, Train Accuracy: 64.01%, Test Loss: 0.8659, Test Accuracy: 64.56%\n",
      "Epoch [719/2500], Train Loss: 0.7881, Train Accuracy: 65.15%, Test Loss: 0.8657, Test Accuracy: 65.82%\n",
      "Epoch [720/2500], Train Loss: 0.7820, Train Accuracy: 64.58%, Test Loss: 0.8626, Test Accuracy: 65.82%\n",
      "Epoch [721/2500], Train Loss: 0.7937, Train Accuracy: 65.58%, Test Loss: 0.8666, Test Accuracy: 64.56%\n",
      "Epoch [722/2500], Train Loss: 0.7869, Train Accuracy: 65.01%, Test Loss: 0.8675, Test Accuracy: 65.82%\n",
      "Epoch [723/2500], Train Loss: 0.7896, Train Accuracy: 63.02%, Test Loss: 0.8571, Test Accuracy: 64.56%\n",
      "Epoch [724/2500], Train Loss: 0.7929, Train Accuracy: 64.30%, Test Loss: 0.8520, Test Accuracy: 65.82%\n",
      "Epoch [725/2500], Train Loss: 0.7866, Train Accuracy: 64.01%, Test Loss: 0.8522, Test Accuracy: 65.82%\n",
      "Epoch [726/2500], Train Loss: 0.7861, Train Accuracy: 65.15%, Test Loss: 0.8503, Test Accuracy: 65.82%\n",
      "Epoch [727/2500], Train Loss: 0.7834, Train Accuracy: 65.29%, Test Loss: 0.8613, Test Accuracy: 63.29%\n",
      "Epoch [728/2500], Train Loss: 0.7863, Train Accuracy: 62.73%, Test Loss: 0.8793, Test Accuracy: 68.35%\n",
      "Epoch [729/2500], Train Loss: 0.7798, Train Accuracy: 63.44%, Test Loss: 0.8685, Test Accuracy: 67.09%\n",
      "Epoch [730/2500], Train Loss: 0.7754, Train Accuracy: 65.01%, Test Loss: 0.8636, Test Accuracy: 65.82%\n",
      "Epoch [731/2500], Train Loss: 0.7950, Train Accuracy: 62.59%, Test Loss: 0.8759, Test Accuracy: 65.82%\n",
      "Epoch [732/2500], Train Loss: 0.7797, Train Accuracy: 64.58%, Test Loss: 0.8603, Test Accuracy: 64.56%\n",
      "Epoch [733/2500], Train Loss: 0.7996, Train Accuracy: 63.16%, Test Loss: 0.8640, Test Accuracy: 65.82%\n",
      "Epoch [734/2500], Train Loss: 0.7783, Train Accuracy: 65.29%, Test Loss: 0.8558, Test Accuracy: 65.82%\n",
      "Epoch [735/2500], Train Loss: 0.7859, Train Accuracy: 64.15%, Test Loss: 0.8525, Test Accuracy: 67.09%\n",
      "Epoch [736/2500], Train Loss: 0.7698, Train Accuracy: 66.29%, Test Loss: 0.8665, Test Accuracy: 65.82%\n",
      "Epoch [737/2500], Train Loss: 0.7972, Train Accuracy: 64.86%, Test Loss: 0.8647, Test Accuracy: 65.82%\n",
      "Epoch [738/2500], Train Loss: 0.8066, Train Accuracy: 64.30%, Test Loss: 0.8718, Test Accuracy: 64.56%\n",
      "Epoch [739/2500], Train Loss: 0.7701, Train Accuracy: 65.15%, Test Loss: 0.8697, Test Accuracy: 65.82%\n",
      "Epoch [740/2500], Train Loss: 0.8019, Train Accuracy: 64.01%, Test Loss: 0.8813, Test Accuracy: 64.56%\n",
      "Epoch [741/2500], Train Loss: 0.7771, Train Accuracy: 65.29%, Test Loss: 0.8676, Test Accuracy: 63.29%\n",
      "Epoch [742/2500], Train Loss: 0.7856, Train Accuracy: 66.57%, Test Loss: 0.8663, Test Accuracy: 65.82%\n",
      "Epoch [743/2500], Train Loss: 0.7810, Train Accuracy: 65.86%, Test Loss: 0.8832, Test Accuracy: 68.35%\n",
      "Epoch [744/2500], Train Loss: 0.7674, Train Accuracy: 65.43%, Test Loss: 0.8576, Test Accuracy: 65.82%\n",
      "Epoch [745/2500], Train Loss: 0.7744, Train Accuracy: 64.44%, Test Loss: 0.8716, Test Accuracy: 67.09%\n",
      "Epoch [746/2500], Train Loss: 0.7747, Train Accuracy: 66.29%, Test Loss: 0.8818, Test Accuracy: 65.82%\n",
      "Epoch [747/2500], Train Loss: 0.7702, Train Accuracy: 65.29%, Test Loss: 0.8634, Test Accuracy: 65.82%\n",
      "Epoch [748/2500], Train Loss: 0.7954, Train Accuracy: 64.72%, Test Loss: 0.8799, Test Accuracy: 64.56%\n",
      "Epoch [749/2500], Train Loss: 0.7880, Train Accuracy: 64.58%, Test Loss: 0.8677, Test Accuracy: 64.56%\n",
      "Epoch [750/2500], Train Loss: 0.7733, Train Accuracy: 64.86%, Test Loss: 0.8801, Test Accuracy: 64.56%\n",
      "Epoch [751/2500], Train Loss: 0.7987, Train Accuracy: 64.58%, Test Loss: 0.8710, Test Accuracy: 63.29%\n",
      "Epoch [752/2500], Train Loss: 0.7815, Train Accuracy: 65.29%, Test Loss: 0.8772, Test Accuracy: 63.29%\n",
      "Epoch [753/2500], Train Loss: 0.7790, Train Accuracy: 65.29%, Test Loss: 0.9000, Test Accuracy: 63.29%\n",
      "Epoch [754/2500], Train Loss: 0.7886, Train Accuracy: 65.15%, Test Loss: 0.8637, Test Accuracy: 65.82%\n",
      "Epoch [755/2500], Train Loss: 0.7791, Train Accuracy: 64.58%, Test Loss: 0.8774, Test Accuracy: 67.09%\n",
      "Epoch [756/2500], Train Loss: 0.7786, Train Accuracy: 66.86%, Test Loss: 0.8721, Test Accuracy: 65.82%\n",
      "Epoch [757/2500], Train Loss: 0.7796, Train Accuracy: 64.86%, Test Loss: 0.8503, Test Accuracy: 64.56%\n",
      "Epoch [758/2500], Train Loss: 0.7847, Train Accuracy: 64.58%, Test Loss: 0.8754, Test Accuracy: 68.35%\n",
      "Epoch [759/2500], Train Loss: 0.7771, Train Accuracy: 66.86%, Test Loss: 0.8580, Test Accuracy: 65.82%\n",
      "Epoch [760/2500], Train Loss: 0.7701, Train Accuracy: 66.00%, Test Loss: 0.8693, Test Accuracy: 65.82%\n",
      "Epoch [761/2500], Train Loss: 0.7825, Train Accuracy: 64.01%, Test Loss: 0.8539, Test Accuracy: 67.09%\n",
      "Epoch [762/2500], Train Loss: 0.7833, Train Accuracy: 66.57%, Test Loss: 0.8664, Test Accuracy: 68.35%\n",
      "Epoch [763/2500], Train Loss: 0.7826, Train Accuracy: 66.57%, Test Loss: 0.8652, Test Accuracy: 67.09%\n",
      "Epoch [764/2500], Train Loss: 0.7788, Train Accuracy: 65.58%, Test Loss: 0.8892, Test Accuracy: 68.35%\n",
      "Epoch [765/2500], Train Loss: 0.7602, Train Accuracy: 65.43%, Test Loss: 0.8607, Test Accuracy: 67.09%\n",
      "Epoch [766/2500], Train Loss: 0.7522, Train Accuracy: 67.43%, Test Loss: 0.8657, Test Accuracy: 67.09%\n",
      "Epoch [767/2500], Train Loss: 0.7803, Train Accuracy: 64.86%, Test Loss: 0.8772, Test Accuracy: 67.09%\n",
      "Epoch [768/2500], Train Loss: 0.7974, Train Accuracy: 64.44%, Test Loss: 0.8538, Test Accuracy: 65.82%\n",
      "Epoch [769/2500], Train Loss: 0.7600, Train Accuracy: 64.15%, Test Loss: 0.8560, Test Accuracy: 65.82%\n",
      "Epoch [770/2500], Train Loss: 0.7652, Train Accuracy: 63.58%, Test Loss: 0.8766, Test Accuracy: 64.56%\n",
      "Epoch [771/2500], Train Loss: 0.7951, Train Accuracy: 65.15%, Test Loss: 0.8715, Test Accuracy: 64.56%\n",
      "Epoch [772/2500], Train Loss: 0.7702, Train Accuracy: 64.86%, Test Loss: 0.8745, Test Accuracy: 64.56%\n",
      "Epoch [773/2500], Train Loss: 0.7551, Train Accuracy: 66.71%, Test Loss: 0.8649, Test Accuracy: 67.09%\n",
      "Epoch [774/2500], Train Loss: 0.7642, Train Accuracy: 67.14%, Test Loss: 0.8665, Test Accuracy: 64.56%\n",
      "Epoch [775/2500], Train Loss: 0.7879, Train Accuracy: 65.15%, Test Loss: 0.8655, Test Accuracy: 64.56%\n",
      "Epoch [776/2500], Train Loss: 0.7626, Train Accuracy: 67.57%, Test Loss: 0.8582, Test Accuracy: 67.09%\n",
      "Epoch [777/2500], Train Loss: 0.7839, Train Accuracy: 65.86%, Test Loss: 0.8471, Test Accuracy: 64.56%\n",
      "Epoch [778/2500], Train Loss: 0.7852, Train Accuracy: 64.86%, Test Loss: 0.8637, Test Accuracy: 65.82%\n",
      "Epoch [779/2500], Train Loss: 0.7777, Train Accuracy: 65.29%, Test Loss: 0.8752, Test Accuracy: 67.09%\n",
      "Epoch [780/2500], Train Loss: 0.7460, Train Accuracy: 66.15%, Test Loss: 0.8656, Test Accuracy: 64.56%\n",
      "Epoch [781/2500], Train Loss: 0.7730, Train Accuracy: 65.29%, Test Loss: 0.8532, Test Accuracy: 65.82%\n",
      "Epoch [782/2500], Train Loss: 0.7789, Train Accuracy: 66.43%, Test Loss: 0.8766, Test Accuracy: 67.09%\n",
      "Epoch [783/2500], Train Loss: 0.7641, Train Accuracy: 67.14%, Test Loss: 0.8753, Test Accuracy: 67.09%\n",
      "Epoch [784/2500], Train Loss: 0.7925, Train Accuracy: 64.72%, Test Loss: 0.8752, Test Accuracy: 67.09%\n",
      "Epoch [785/2500], Train Loss: 0.8058, Train Accuracy: 64.44%, Test Loss: 0.8636, Test Accuracy: 67.09%\n",
      "Epoch [786/2500], Train Loss: 0.7961, Train Accuracy: 65.01%, Test Loss: 0.8720, Test Accuracy: 67.09%\n",
      "Epoch [787/2500], Train Loss: 0.7784, Train Accuracy: 66.43%, Test Loss: 0.8736, Test Accuracy: 65.82%\n",
      "Epoch [788/2500], Train Loss: 0.7963, Train Accuracy: 63.73%, Test Loss: 0.8577, Test Accuracy: 67.09%\n",
      "Epoch [789/2500], Train Loss: 0.7732, Train Accuracy: 66.57%, Test Loss: 0.8600, Test Accuracy: 65.82%\n",
      "Epoch [790/2500], Train Loss: 0.7930, Train Accuracy: 63.73%, Test Loss: 0.8600, Test Accuracy: 68.35%\n",
      "Epoch [791/2500], Train Loss: 0.7926, Train Accuracy: 64.72%, Test Loss: 0.8651, Test Accuracy: 67.09%\n",
      "Epoch [792/2500], Train Loss: 0.7596, Train Accuracy: 67.14%, Test Loss: 0.8866, Test Accuracy: 68.35%\n",
      "Epoch [793/2500], Train Loss: 0.7772, Train Accuracy: 64.58%, Test Loss: 0.8810, Test Accuracy: 68.35%\n",
      "Epoch [794/2500], Train Loss: 0.7762, Train Accuracy: 65.58%, Test Loss: 0.8685, Test Accuracy: 65.82%\n",
      "Epoch [795/2500], Train Loss: 0.7704, Train Accuracy: 65.58%, Test Loss: 0.8678, Test Accuracy: 67.09%\n",
      "Epoch [796/2500], Train Loss: 0.7821, Train Accuracy: 65.15%, Test Loss: 0.8711, Test Accuracy: 68.35%\n",
      "Epoch [797/2500], Train Loss: 0.7643, Train Accuracy: 65.15%, Test Loss: 0.8661, Test Accuracy: 65.82%\n",
      "Epoch [798/2500], Train Loss: 0.7687, Train Accuracy: 65.29%, Test Loss: 0.8924, Test Accuracy: 68.35%\n",
      "Epoch [799/2500], Train Loss: 0.7521, Train Accuracy: 64.72%, Test Loss: 0.8740, Test Accuracy: 67.09%\n",
      "Epoch [800/2500], Train Loss: 0.7890, Train Accuracy: 65.29%, Test Loss: 0.8587, Test Accuracy: 64.56%\n",
      "Epoch [801/2500], Train Loss: 0.8003, Train Accuracy: 66.43%, Test Loss: 0.8797, Test Accuracy: 64.56%\n",
      "Epoch [802/2500], Train Loss: 0.7951, Train Accuracy: 64.15%, Test Loss: 0.8573, Test Accuracy: 65.82%\n",
      "Epoch [803/2500], Train Loss: 0.7754, Train Accuracy: 64.01%, Test Loss: 0.8815, Test Accuracy: 68.35%\n",
      "Epoch [804/2500], Train Loss: 0.7822, Train Accuracy: 63.30%, Test Loss: 0.8778, Test Accuracy: 68.35%\n",
      "Epoch [805/2500], Train Loss: 0.7538, Train Accuracy: 67.43%, Test Loss: 0.8731, Test Accuracy: 67.09%\n",
      "Epoch [806/2500], Train Loss: 0.7467, Train Accuracy: 66.29%, Test Loss: 0.8876, Test Accuracy: 67.09%\n",
      "Epoch [807/2500], Train Loss: 0.7623, Train Accuracy: 65.43%, Test Loss: 0.9040, Test Accuracy: 67.09%\n",
      "Epoch [808/2500], Train Loss: 0.7589, Train Accuracy: 66.15%, Test Loss: 0.8912, Test Accuracy: 67.09%\n",
      "Epoch [809/2500], Train Loss: 0.7679, Train Accuracy: 66.86%, Test Loss: 0.8772, Test Accuracy: 65.82%\n",
      "Epoch [810/2500], Train Loss: 0.7892, Train Accuracy: 65.15%, Test Loss: 0.8872, Test Accuracy: 68.35%\n",
      "Epoch [811/2500], Train Loss: 0.7945, Train Accuracy: 64.44%, Test Loss: 0.8776, Test Accuracy: 67.09%\n",
      "Epoch [812/2500], Train Loss: 0.7699, Train Accuracy: 64.30%, Test Loss: 0.8893, Test Accuracy: 67.09%\n",
      "Epoch [813/2500], Train Loss: 0.7722, Train Accuracy: 64.30%, Test Loss: 0.8754, Test Accuracy: 67.09%\n",
      "Epoch [814/2500], Train Loss: 0.7690, Train Accuracy: 66.15%, Test Loss: 0.8718, Test Accuracy: 65.82%\n",
      "Epoch [815/2500], Train Loss: 0.7741, Train Accuracy: 62.16%, Test Loss: 0.8651, Test Accuracy: 67.09%\n",
      "Epoch [816/2500], Train Loss: 0.7882, Train Accuracy: 63.87%, Test Loss: 0.8585, Test Accuracy: 65.82%\n",
      "Epoch [817/2500], Train Loss: 0.7588, Train Accuracy: 65.15%, Test Loss: 0.8681, Test Accuracy: 67.09%\n",
      "Epoch [818/2500], Train Loss: 0.7681, Train Accuracy: 64.86%, Test Loss: 0.8730, Test Accuracy: 68.35%\n",
      "Epoch [819/2500], Train Loss: 0.7749, Train Accuracy: 67.00%, Test Loss: 0.8780, Test Accuracy: 67.09%\n",
      "Epoch [820/2500], Train Loss: 0.7770, Train Accuracy: 65.58%, Test Loss: 0.8757, Test Accuracy: 68.35%\n",
      "Epoch [821/2500], Train Loss: 0.7805, Train Accuracy: 66.00%, Test Loss: 0.8646, Test Accuracy: 68.35%\n",
      "Epoch [822/2500], Train Loss: 0.7585, Train Accuracy: 66.00%, Test Loss: 0.8944, Test Accuracy: 68.35%\n",
      "Epoch [823/2500], Train Loss: 0.7503, Train Accuracy: 65.72%, Test Loss: 0.8758, Test Accuracy: 68.35%\n",
      "Epoch [824/2500], Train Loss: 0.7842, Train Accuracy: 64.72%, Test Loss: 0.8595, Test Accuracy: 67.09%\n",
      "Epoch [825/2500], Train Loss: 0.7580, Train Accuracy: 65.86%, Test Loss: 0.8576, Test Accuracy: 67.09%\n",
      "Epoch [826/2500], Train Loss: 0.7721, Train Accuracy: 65.01%, Test Loss: 0.8791, Test Accuracy: 67.09%\n",
      "Epoch [827/2500], Train Loss: 0.7435, Train Accuracy: 66.71%, Test Loss: 0.8774, Test Accuracy: 65.82%\n",
      "Epoch [828/2500], Train Loss: 0.7704, Train Accuracy: 66.15%, Test Loss: 0.8666, Test Accuracy: 68.35%\n",
      "Epoch [829/2500], Train Loss: 0.7524, Train Accuracy: 66.00%, Test Loss: 0.8626, Test Accuracy: 65.82%\n",
      "Epoch [830/2500], Train Loss: 0.7820, Train Accuracy: 65.29%, Test Loss: 0.8922, Test Accuracy: 68.35%\n",
      "Epoch [831/2500], Train Loss: 0.7745, Train Accuracy: 64.86%, Test Loss: 0.8582, Test Accuracy: 65.82%\n",
      "Epoch [832/2500], Train Loss: 0.7500, Train Accuracy: 66.71%, Test Loss: 0.8824, Test Accuracy: 67.09%\n",
      "Epoch [833/2500], Train Loss: 0.7437, Train Accuracy: 66.57%, Test Loss: 0.8761, Test Accuracy: 69.62%\n",
      "Epoch [834/2500], Train Loss: 0.7462, Train Accuracy: 66.86%, Test Loss: 0.8681, Test Accuracy: 67.09%\n",
      "Epoch [835/2500], Train Loss: 0.7763, Train Accuracy: 65.72%, Test Loss: 0.8543, Test Accuracy: 65.82%\n",
      "Epoch [836/2500], Train Loss: 0.7494, Train Accuracy: 67.14%, Test Loss: 0.8670, Test Accuracy: 68.35%\n",
      "Epoch [837/2500], Train Loss: 0.7291, Train Accuracy: 67.99%, Test Loss: 0.8762, Test Accuracy: 67.09%\n",
      "Epoch [838/2500], Train Loss: 0.7551, Train Accuracy: 65.86%, Test Loss: 0.8982, Test Accuracy: 68.35%\n",
      "Epoch [839/2500], Train Loss: 0.7490, Train Accuracy: 67.57%, Test Loss: 0.8838, Test Accuracy: 67.09%\n",
      "Epoch [840/2500], Train Loss: 0.7705, Train Accuracy: 67.28%, Test Loss: 0.8567, Test Accuracy: 67.09%\n",
      "Epoch [841/2500], Train Loss: 0.7533, Train Accuracy: 67.14%, Test Loss: 0.8752, Test Accuracy: 67.09%\n",
      "Epoch [842/2500], Train Loss: 0.7586, Train Accuracy: 67.43%, Test Loss: 0.8682, Test Accuracy: 65.82%\n",
      "Epoch [843/2500], Train Loss: 0.7590, Train Accuracy: 64.30%, Test Loss: 0.8511, Test Accuracy: 67.09%\n",
      "Epoch [844/2500], Train Loss: 0.7496, Train Accuracy: 66.71%, Test Loss: 0.8665, Test Accuracy: 68.35%\n",
      "Epoch [845/2500], Train Loss: 0.7784, Train Accuracy: 66.00%, Test Loss: 0.8812, Test Accuracy: 65.82%\n",
      "Epoch [846/2500], Train Loss: 0.7455, Train Accuracy: 67.28%, Test Loss: 0.8839, Test Accuracy: 65.82%\n",
      "Epoch [847/2500], Train Loss: 0.7647, Train Accuracy: 65.86%, Test Loss: 0.8784, Test Accuracy: 65.82%\n",
      "Epoch [848/2500], Train Loss: 0.7563, Train Accuracy: 67.28%, Test Loss: 0.8600, Test Accuracy: 65.82%\n",
      "Epoch [849/2500], Train Loss: 0.7759, Train Accuracy: 65.43%, Test Loss: 0.8694, Test Accuracy: 64.56%\n",
      "Epoch [850/2500], Train Loss: 0.7778, Train Accuracy: 67.71%, Test Loss: 0.8620, Test Accuracy: 67.09%\n",
      "Epoch [851/2500], Train Loss: 0.7760, Train Accuracy: 65.15%, Test Loss: 0.8525, Test Accuracy: 65.82%\n",
      "Epoch [852/2500], Train Loss: 0.7559, Train Accuracy: 65.29%, Test Loss: 0.8470, Test Accuracy: 65.82%\n",
      "Epoch [853/2500], Train Loss: 0.7623, Train Accuracy: 66.57%, Test Loss: 0.8504, Test Accuracy: 65.82%\n",
      "Epoch [854/2500], Train Loss: 0.7532, Train Accuracy: 67.71%, Test Loss: 0.8603, Test Accuracy: 65.82%\n",
      "Epoch [855/2500], Train Loss: 0.7530, Train Accuracy: 65.72%, Test Loss: 0.8582, Test Accuracy: 67.09%\n",
      "Epoch [856/2500], Train Loss: 0.7603, Train Accuracy: 64.58%, Test Loss: 0.8570, Test Accuracy: 67.09%\n",
      "Epoch [857/2500], Train Loss: 0.7748, Train Accuracy: 65.86%, Test Loss: 0.8650, Test Accuracy: 68.35%\n",
      "Epoch [858/2500], Train Loss: 0.7617, Train Accuracy: 65.86%, Test Loss: 0.8678, Test Accuracy: 65.82%\n",
      "Epoch [859/2500], Train Loss: 0.7634, Train Accuracy: 66.57%, Test Loss: 0.8697, Test Accuracy: 67.09%\n",
      "Epoch [860/2500], Train Loss: 0.7661, Train Accuracy: 67.57%, Test Loss: 0.8802, Test Accuracy: 65.82%\n",
      "Epoch [861/2500], Train Loss: 0.7605, Train Accuracy: 66.43%, Test Loss: 0.8638, Test Accuracy: 68.35%\n",
      "Epoch [862/2500], Train Loss: 0.7762, Train Accuracy: 64.01%, Test Loss: 0.8676, Test Accuracy: 68.35%\n",
      "Epoch [863/2500], Train Loss: 0.7614, Train Accuracy: 67.00%, Test Loss: 0.8744, Test Accuracy: 68.35%\n",
      "Epoch [864/2500], Train Loss: 0.7364, Train Accuracy: 65.58%, Test Loss: 0.8789, Test Accuracy: 67.09%\n",
      "Epoch [865/2500], Train Loss: 0.7634, Train Accuracy: 66.86%, Test Loss: 0.8884, Test Accuracy: 64.56%\n",
      "Epoch [866/2500], Train Loss: 0.7636, Train Accuracy: 67.57%, Test Loss: 0.8702, Test Accuracy: 67.09%\n",
      "Epoch [867/2500], Train Loss: 0.7818, Train Accuracy: 66.00%, Test Loss: 0.8721, Test Accuracy: 65.82%\n",
      "Epoch [868/2500], Train Loss: 0.7334, Train Accuracy: 67.43%, Test Loss: 0.8698, Test Accuracy: 65.82%\n",
      "Epoch [869/2500], Train Loss: 0.7684, Train Accuracy: 67.71%, Test Loss: 0.8679, Test Accuracy: 67.09%\n",
      "Epoch [870/2500], Train Loss: 0.7768, Train Accuracy: 65.43%, Test Loss: 0.8702, Test Accuracy: 65.82%\n",
      "Epoch [871/2500], Train Loss: 0.7700, Train Accuracy: 64.86%, Test Loss: 0.8714, Test Accuracy: 65.82%\n",
      "Epoch [872/2500], Train Loss: 0.7608, Train Accuracy: 66.86%, Test Loss: 0.8624, Test Accuracy: 67.09%\n",
      "Epoch [873/2500], Train Loss: 0.7397, Train Accuracy: 66.86%, Test Loss: 0.8731, Test Accuracy: 67.09%\n",
      "Epoch [874/2500], Train Loss: 0.7765, Train Accuracy: 64.15%, Test Loss: 0.8865, Test Accuracy: 67.09%\n",
      "Epoch [875/2500], Train Loss: 0.7531, Train Accuracy: 67.57%, Test Loss: 0.9017, Test Accuracy: 67.09%\n",
      "Epoch [876/2500], Train Loss: 0.7712, Train Accuracy: 65.58%, Test Loss: 0.8709, Test Accuracy: 65.82%\n",
      "Epoch [877/2500], Train Loss: 0.7545, Train Accuracy: 66.00%, Test Loss: 0.8991, Test Accuracy: 67.09%\n",
      "Epoch [878/2500], Train Loss: 0.7514, Train Accuracy: 66.15%, Test Loss: 0.8850, Test Accuracy: 64.56%\n",
      "Epoch [879/2500], Train Loss: 0.7432, Train Accuracy: 66.57%, Test Loss: 0.8947, Test Accuracy: 64.56%\n",
      "Epoch [880/2500], Train Loss: 0.7402, Train Accuracy: 66.00%, Test Loss: 0.8826, Test Accuracy: 64.56%\n",
      "Epoch [881/2500], Train Loss: 0.7591, Train Accuracy: 66.86%, Test Loss: 0.8804, Test Accuracy: 62.03%\n",
      "Epoch [882/2500], Train Loss: 0.7772, Train Accuracy: 65.01%, Test Loss: 0.8853, Test Accuracy: 65.82%\n",
      "Epoch [883/2500], Train Loss: 0.7558, Train Accuracy: 66.29%, Test Loss: 0.8796, Test Accuracy: 65.82%\n",
      "Epoch [884/2500], Train Loss: 0.7835, Train Accuracy: 64.15%, Test Loss: 0.8773, Test Accuracy: 65.82%\n",
      "Epoch [885/2500], Train Loss: 0.7553, Train Accuracy: 66.71%, Test Loss: 0.8988, Test Accuracy: 67.09%\n",
      "Epoch [886/2500], Train Loss: 0.7525, Train Accuracy: 68.42%, Test Loss: 0.8896, Test Accuracy: 64.56%\n",
      "Epoch [887/2500], Train Loss: 0.7809, Train Accuracy: 64.01%, Test Loss: 0.8802, Test Accuracy: 65.82%\n",
      "Epoch [888/2500], Train Loss: 0.7549, Train Accuracy: 66.57%, Test Loss: 0.8691, Test Accuracy: 65.82%\n",
      "Epoch [889/2500], Train Loss: 0.7769, Train Accuracy: 65.58%, Test Loss: 0.8951, Test Accuracy: 65.82%\n",
      "Epoch [890/2500], Train Loss: 0.7705, Train Accuracy: 66.00%, Test Loss: 0.8827, Test Accuracy: 67.09%\n",
      "Epoch [891/2500], Train Loss: 0.7574, Train Accuracy: 65.86%, Test Loss: 0.8791, Test Accuracy: 67.09%\n",
      "Epoch [892/2500], Train Loss: 0.7477, Train Accuracy: 65.58%, Test Loss: 0.8610, Test Accuracy: 65.82%\n",
      "Epoch [893/2500], Train Loss: 0.7590, Train Accuracy: 65.01%, Test Loss: 0.8843, Test Accuracy: 64.56%\n",
      "Epoch [894/2500], Train Loss: 0.7660, Train Accuracy: 65.43%, Test Loss: 0.8728, Test Accuracy: 64.56%\n",
      "Epoch [895/2500], Train Loss: 0.7494, Train Accuracy: 66.71%, Test Loss: 0.8666, Test Accuracy: 65.82%\n",
      "Epoch [896/2500], Train Loss: 0.7517, Train Accuracy: 67.28%, Test Loss: 0.8670, Test Accuracy: 65.82%\n",
      "Epoch [897/2500], Train Loss: 0.7613, Train Accuracy: 66.00%, Test Loss: 0.8848, Test Accuracy: 67.09%\n",
      "Epoch [898/2500], Train Loss: 0.7694, Train Accuracy: 65.01%, Test Loss: 0.8981, Test Accuracy: 67.09%\n",
      "Epoch [899/2500], Train Loss: 0.7712, Train Accuracy: 66.57%, Test Loss: 0.8822, Test Accuracy: 64.56%\n",
      "Epoch [900/2500], Train Loss: 0.7541, Train Accuracy: 65.86%, Test Loss: 0.8838, Test Accuracy: 67.09%\n",
      "Epoch [901/2500], Train Loss: 0.7758, Train Accuracy: 65.58%, Test Loss: 0.8815, Test Accuracy: 65.82%\n",
      "Epoch [902/2500], Train Loss: 0.7550, Train Accuracy: 65.29%, Test Loss: 0.8741, Test Accuracy: 64.56%\n",
      "Epoch [903/2500], Train Loss: 0.7578, Train Accuracy: 65.43%, Test Loss: 0.8726, Test Accuracy: 65.82%\n",
      "Epoch [904/2500], Train Loss: 0.7457, Train Accuracy: 63.58%, Test Loss: 0.8863, Test Accuracy: 63.29%\n",
      "Epoch [905/2500], Train Loss: 0.7733, Train Accuracy: 66.71%, Test Loss: 0.8740, Test Accuracy: 63.29%\n",
      "Epoch [906/2500], Train Loss: 0.7376, Train Accuracy: 66.86%, Test Loss: 0.8672, Test Accuracy: 64.56%\n",
      "Epoch [907/2500], Train Loss: 0.7698, Train Accuracy: 65.43%, Test Loss: 0.8759, Test Accuracy: 64.56%\n",
      "Epoch [908/2500], Train Loss: 0.7532, Train Accuracy: 67.14%, Test Loss: 0.8744, Test Accuracy: 68.35%\n",
      "Epoch [909/2500], Train Loss: 0.7519, Train Accuracy: 65.01%, Test Loss: 0.8767, Test Accuracy: 65.82%\n",
      "Epoch [910/2500], Train Loss: 0.7628, Train Accuracy: 67.00%, Test Loss: 0.9046, Test Accuracy: 64.56%\n",
      "Epoch [911/2500], Train Loss: 0.7748, Train Accuracy: 64.86%, Test Loss: 0.8630, Test Accuracy: 64.56%\n",
      "Epoch [912/2500], Train Loss: 0.7579, Train Accuracy: 65.15%, Test Loss: 0.8741, Test Accuracy: 65.82%\n",
      "Epoch [913/2500], Train Loss: 0.7488, Train Accuracy: 66.57%, Test Loss: 0.8879, Test Accuracy: 65.82%\n",
      "Epoch [914/2500], Train Loss: 0.7465, Train Accuracy: 67.14%, Test Loss: 0.8913, Test Accuracy: 65.82%\n",
      "Epoch [915/2500], Train Loss: 0.7604, Train Accuracy: 66.00%, Test Loss: 0.8856, Test Accuracy: 65.82%\n",
      "Epoch [916/2500], Train Loss: 0.7572, Train Accuracy: 66.57%, Test Loss: 0.8895, Test Accuracy: 64.56%\n",
      "Epoch [917/2500], Train Loss: 0.7689, Train Accuracy: 65.72%, Test Loss: 0.8874, Test Accuracy: 64.56%\n",
      "Epoch [918/2500], Train Loss: 0.7489, Train Accuracy: 66.71%, Test Loss: 0.8777, Test Accuracy: 67.09%\n",
      "Epoch [919/2500], Train Loss: 0.7603, Train Accuracy: 66.29%, Test Loss: 0.8752, Test Accuracy: 64.56%\n",
      "Epoch [920/2500], Train Loss: 0.7354, Train Accuracy: 67.14%, Test Loss: 0.8826, Test Accuracy: 64.56%\n",
      "Epoch [921/2500], Train Loss: 0.7402, Train Accuracy: 67.28%, Test Loss: 0.8702, Test Accuracy: 67.09%\n",
      "Epoch [922/2500], Train Loss: 0.7507, Train Accuracy: 66.29%, Test Loss: 0.8771, Test Accuracy: 63.29%\n",
      "Epoch [923/2500], Train Loss: 0.7518, Train Accuracy: 66.15%, Test Loss: 0.8711, Test Accuracy: 64.56%\n",
      "Epoch [924/2500], Train Loss: 0.7127, Train Accuracy: 66.43%, Test Loss: 0.8827, Test Accuracy: 64.56%\n",
      "Epoch [925/2500], Train Loss: 0.7587, Train Accuracy: 66.29%, Test Loss: 0.8906, Test Accuracy: 65.82%\n",
      "Epoch [926/2500], Train Loss: 0.7763, Train Accuracy: 64.72%, Test Loss: 0.8750, Test Accuracy: 65.82%\n",
      "Epoch [927/2500], Train Loss: 0.7646, Train Accuracy: 66.71%, Test Loss: 0.8548, Test Accuracy: 65.82%\n",
      "Epoch [928/2500], Train Loss: 0.7594, Train Accuracy: 66.00%, Test Loss: 0.8848, Test Accuracy: 63.29%\n",
      "Epoch [929/2500], Train Loss: 0.7469, Train Accuracy: 67.14%, Test Loss: 0.8861, Test Accuracy: 63.29%\n",
      "Epoch [930/2500], Train Loss: 0.7517, Train Accuracy: 69.42%, Test Loss: 0.8886, Test Accuracy: 63.29%\n",
      "Epoch [931/2500], Train Loss: 0.7596, Train Accuracy: 66.57%, Test Loss: 0.8724, Test Accuracy: 67.09%\n",
      "Epoch [932/2500], Train Loss: 0.7384, Train Accuracy: 67.85%, Test Loss: 0.9109, Test Accuracy: 63.29%\n",
      "Epoch [933/2500], Train Loss: 0.7507, Train Accuracy: 66.15%, Test Loss: 0.8986, Test Accuracy: 65.82%\n",
      "Epoch [934/2500], Train Loss: 0.7487, Train Accuracy: 67.14%, Test Loss: 0.8914, Test Accuracy: 65.82%\n",
      "Epoch [935/2500], Train Loss: 0.7355, Train Accuracy: 67.28%, Test Loss: 0.8718, Test Accuracy: 65.82%\n",
      "Epoch [936/2500], Train Loss: 0.7781, Train Accuracy: 64.72%, Test Loss: 0.8746, Test Accuracy: 64.56%\n",
      "Epoch [937/2500], Train Loss: 0.7315, Train Accuracy: 67.99%, Test Loss: 0.8850, Test Accuracy: 63.29%\n",
      "Epoch [938/2500], Train Loss: 0.7183, Train Accuracy: 68.85%, Test Loss: 0.8912, Test Accuracy: 65.82%\n",
      "Epoch [939/2500], Train Loss: 0.7633, Train Accuracy: 65.01%, Test Loss: 0.8812, Test Accuracy: 64.56%\n",
      "Epoch [940/2500], Train Loss: 0.7630, Train Accuracy: 67.85%, Test Loss: 0.8989, Test Accuracy: 64.56%\n",
      "Epoch [941/2500], Train Loss: 0.7323, Train Accuracy: 66.00%, Test Loss: 0.8845, Test Accuracy: 64.56%\n",
      "Epoch [942/2500], Train Loss: 0.7697, Train Accuracy: 65.72%, Test Loss: 0.8830, Test Accuracy: 65.82%\n",
      "Epoch [943/2500], Train Loss: 0.7508, Train Accuracy: 65.58%, Test Loss: 0.8881, Test Accuracy: 64.56%\n",
      "Epoch [944/2500], Train Loss: 0.7577, Train Accuracy: 66.29%, Test Loss: 0.8789, Test Accuracy: 64.56%\n",
      "Epoch [945/2500], Train Loss: 0.7426, Train Accuracy: 66.86%, Test Loss: 0.8724, Test Accuracy: 65.82%\n",
      "Epoch [946/2500], Train Loss: 0.7583, Train Accuracy: 67.71%, Test Loss: 0.8896, Test Accuracy: 65.82%\n",
      "Epoch [947/2500], Train Loss: 0.7524, Train Accuracy: 67.14%, Test Loss: 0.9066, Test Accuracy: 67.09%\n",
      "Epoch [948/2500], Train Loss: 0.7590, Train Accuracy: 68.14%, Test Loss: 0.8809, Test Accuracy: 64.56%\n",
      "Epoch [949/2500], Train Loss: 0.7400, Train Accuracy: 66.71%, Test Loss: 0.9079, Test Accuracy: 64.56%\n",
      "Epoch [950/2500], Train Loss: 0.7423, Train Accuracy: 66.86%, Test Loss: 0.9189, Test Accuracy: 64.56%\n",
      "Epoch [951/2500], Train Loss: 0.7714, Train Accuracy: 66.86%, Test Loss: 0.9010, Test Accuracy: 65.82%\n",
      "Epoch [952/2500], Train Loss: 0.7343, Train Accuracy: 67.85%, Test Loss: 0.8681, Test Accuracy: 65.82%\n",
      "Epoch [953/2500], Train Loss: 0.7227, Train Accuracy: 67.00%, Test Loss: 0.8705, Test Accuracy: 65.82%\n",
      "Epoch [954/2500], Train Loss: 0.7586, Train Accuracy: 67.71%, Test Loss: 0.8939, Test Accuracy: 63.29%\n",
      "Epoch [955/2500], Train Loss: 0.7523, Train Accuracy: 66.86%, Test Loss: 0.9030, Test Accuracy: 63.29%\n",
      "Epoch [956/2500], Train Loss: 0.7558, Train Accuracy: 68.14%, Test Loss: 0.9031, Test Accuracy: 64.56%\n",
      "Epoch [957/2500], Train Loss: 0.7417, Train Accuracy: 64.58%, Test Loss: 0.8975, Test Accuracy: 64.56%\n",
      "Epoch [958/2500], Train Loss: 0.7272, Train Accuracy: 66.15%, Test Loss: 0.9097, Test Accuracy: 65.82%\n",
      "Epoch [959/2500], Train Loss: 0.7592, Train Accuracy: 65.86%, Test Loss: 0.8880, Test Accuracy: 67.09%\n",
      "Epoch [960/2500], Train Loss: 0.7506, Train Accuracy: 64.86%, Test Loss: 0.8905, Test Accuracy: 64.56%\n",
      "Epoch [961/2500], Train Loss: 0.7321, Train Accuracy: 66.29%, Test Loss: 0.8827, Test Accuracy: 67.09%\n",
      "Epoch [962/2500], Train Loss: 0.7690, Train Accuracy: 67.28%, Test Loss: 0.8854, Test Accuracy: 65.82%\n",
      "Epoch [963/2500], Train Loss: 0.7508, Train Accuracy: 67.43%, Test Loss: 0.8697, Test Accuracy: 65.82%\n",
      "Epoch [964/2500], Train Loss: 0.7390, Train Accuracy: 66.71%, Test Loss: 0.8844, Test Accuracy: 63.29%\n",
      "Epoch [965/2500], Train Loss: 0.7537, Train Accuracy: 65.58%, Test Loss: 0.8863, Test Accuracy: 64.56%\n",
      "Epoch [966/2500], Train Loss: 0.7328, Train Accuracy: 68.42%, Test Loss: 0.8838, Test Accuracy: 64.56%\n",
      "Epoch [967/2500], Train Loss: 0.7379, Train Accuracy: 67.57%, Test Loss: 0.8972, Test Accuracy: 64.56%\n",
      "Epoch [968/2500], Train Loss: 0.7304, Train Accuracy: 66.15%, Test Loss: 0.8803, Test Accuracy: 67.09%\n",
      "Epoch [969/2500], Train Loss: 0.7498, Train Accuracy: 65.72%, Test Loss: 0.8954, Test Accuracy: 65.82%\n",
      "Epoch [970/2500], Train Loss: 0.7325, Train Accuracy: 67.57%, Test Loss: 0.8954, Test Accuracy: 65.82%\n",
      "Epoch [971/2500], Train Loss: 0.7413, Train Accuracy: 67.28%, Test Loss: 0.8921, Test Accuracy: 65.82%\n",
      "Epoch [972/2500], Train Loss: 0.7450, Train Accuracy: 66.71%, Test Loss: 0.8750, Test Accuracy: 64.56%\n",
      "Epoch [973/2500], Train Loss: 0.7676, Train Accuracy: 66.29%, Test Loss: 0.8783, Test Accuracy: 64.56%\n",
      "Epoch [974/2500], Train Loss: 0.7363, Train Accuracy: 66.00%, Test Loss: 0.8768, Test Accuracy: 65.82%\n",
      "Epoch [975/2500], Train Loss: 0.7481, Train Accuracy: 65.86%, Test Loss: 0.8913, Test Accuracy: 67.09%\n",
      "Epoch [976/2500], Train Loss: 0.7256, Train Accuracy: 66.86%, Test Loss: 0.8946, Test Accuracy: 64.56%\n",
      "Epoch [977/2500], Train Loss: 0.7187, Train Accuracy: 67.99%, Test Loss: 0.9008, Test Accuracy: 67.09%\n",
      "Epoch [978/2500], Train Loss: 0.7580, Train Accuracy: 66.00%, Test Loss: 0.8855, Test Accuracy: 63.29%\n",
      "Epoch [979/2500], Train Loss: 0.7405, Train Accuracy: 67.14%, Test Loss: 0.8620, Test Accuracy: 65.82%\n",
      "Epoch [980/2500], Train Loss: 0.7525, Train Accuracy: 66.71%, Test Loss: 0.8958, Test Accuracy: 63.29%\n",
      "Epoch [981/2500], Train Loss: 0.7439, Train Accuracy: 65.58%, Test Loss: 0.9087, Test Accuracy: 64.56%\n",
      "Epoch [982/2500], Train Loss: 0.7509, Train Accuracy: 65.86%, Test Loss: 0.8754, Test Accuracy: 67.09%\n",
      "Epoch [983/2500], Train Loss: 0.7262, Train Accuracy: 69.56%, Test Loss: 0.8865, Test Accuracy: 65.82%\n",
      "Epoch [984/2500], Train Loss: 0.7608, Train Accuracy: 66.43%, Test Loss: 0.8835, Test Accuracy: 64.56%\n",
      "Epoch [985/2500], Train Loss: 0.7387, Train Accuracy: 67.85%, Test Loss: 0.9117, Test Accuracy: 64.56%\n",
      "Epoch [986/2500], Train Loss: 0.7299, Train Accuracy: 67.14%, Test Loss: 0.9009, Test Accuracy: 65.82%\n",
      "Epoch [987/2500], Train Loss: 0.7633, Train Accuracy: 66.15%, Test Loss: 0.8785, Test Accuracy: 65.82%\n",
      "Epoch [988/2500], Train Loss: 0.7273, Train Accuracy: 67.43%, Test Loss: 0.8784, Test Accuracy: 67.09%\n",
      "Epoch [989/2500], Train Loss: 0.7357, Train Accuracy: 66.57%, Test Loss: 0.8935, Test Accuracy: 64.56%\n",
      "Epoch [990/2500], Train Loss: 0.7613, Train Accuracy: 65.15%, Test Loss: 0.8963, Test Accuracy: 63.29%\n",
      "Epoch [991/2500], Train Loss: 0.7352, Train Accuracy: 68.42%, Test Loss: 0.8880, Test Accuracy: 64.56%\n",
      "Epoch [992/2500], Train Loss: 0.7443, Train Accuracy: 66.86%, Test Loss: 0.8921, Test Accuracy: 64.56%\n",
      "Epoch [993/2500], Train Loss: 0.7471, Train Accuracy: 68.28%, Test Loss: 0.8834, Test Accuracy: 64.56%\n",
      "Epoch [994/2500], Train Loss: 0.7508, Train Accuracy: 66.29%, Test Loss: 0.8921, Test Accuracy: 64.56%\n",
      "Epoch [995/2500], Train Loss: 0.7344, Train Accuracy: 67.71%, Test Loss: 0.9051, Test Accuracy: 63.29%\n",
      "Epoch [996/2500], Train Loss: 0.7512, Train Accuracy: 66.00%, Test Loss: 0.9140, Test Accuracy: 64.56%\n",
      "Epoch [997/2500], Train Loss: 0.7515, Train Accuracy: 67.28%, Test Loss: 0.9093, Test Accuracy: 63.29%\n",
      "Epoch [998/2500], Train Loss: 0.7234, Train Accuracy: 67.28%, Test Loss: 0.8974, Test Accuracy: 63.29%\n",
      "Epoch [999/2500], Train Loss: 0.7467, Train Accuracy: 68.56%, Test Loss: 0.8750, Test Accuracy: 64.56%\n",
      "Epoch [1000/2500], Train Loss: 0.7344, Train Accuracy: 69.84%, Test Loss: 0.8979, Test Accuracy: 63.29%\n",
      "Epoch [1001/2500], Train Loss: 0.7369, Train Accuracy: 67.99%, Test Loss: 0.8962, Test Accuracy: 65.82%\n",
      "Epoch [1002/2500], Train Loss: 0.7389, Train Accuracy: 66.71%, Test Loss: 0.9071, Test Accuracy: 63.29%\n",
      "Epoch [1003/2500], Train Loss: 0.7328, Train Accuracy: 67.43%, Test Loss: 0.8963, Test Accuracy: 63.29%\n",
      "Epoch [1004/2500], Train Loss: 0.7467, Train Accuracy: 64.72%, Test Loss: 0.8870, Test Accuracy: 65.82%\n",
      "Epoch [1005/2500], Train Loss: 0.7352, Train Accuracy: 65.58%, Test Loss: 0.8693, Test Accuracy: 67.09%\n",
      "Epoch [1006/2500], Train Loss: 0.7394, Train Accuracy: 66.29%, Test Loss: 0.8972, Test Accuracy: 64.56%\n",
      "Epoch [1007/2500], Train Loss: 0.7471, Train Accuracy: 64.44%, Test Loss: 0.8891, Test Accuracy: 65.82%\n",
      "Epoch [1008/2500], Train Loss: 0.7504, Train Accuracy: 64.44%, Test Loss: 0.8851, Test Accuracy: 67.09%\n",
      "Epoch [1009/2500], Train Loss: 0.7659, Train Accuracy: 65.86%, Test Loss: 0.8932, Test Accuracy: 65.82%\n",
      "Epoch [1010/2500], Train Loss: 0.7383, Train Accuracy: 66.29%, Test Loss: 0.8812, Test Accuracy: 65.82%\n",
      "Epoch [1011/2500], Train Loss: 0.7450, Train Accuracy: 66.29%, Test Loss: 0.8935, Test Accuracy: 63.29%\n",
      "Epoch [1012/2500], Train Loss: 0.7442, Train Accuracy: 68.42%, Test Loss: 0.9064, Test Accuracy: 63.29%\n",
      "Epoch [1013/2500], Train Loss: 0.7489, Train Accuracy: 66.57%, Test Loss: 0.8956, Test Accuracy: 67.09%\n",
      "Epoch [1014/2500], Train Loss: 0.7325, Train Accuracy: 67.57%, Test Loss: 0.9064, Test Accuracy: 64.56%\n",
      "Epoch [1015/2500], Train Loss: 0.7299, Train Accuracy: 68.99%, Test Loss: 0.8970, Test Accuracy: 68.35%\n",
      "Epoch [1016/2500], Train Loss: 0.7569, Train Accuracy: 66.15%, Test Loss: 0.9081, Test Accuracy: 63.29%\n",
      "Epoch [1017/2500], Train Loss: 0.7505, Train Accuracy: 67.57%, Test Loss: 0.8986, Test Accuracy: 68.35%\n",
      "Epoch [1018/2500], Train Loss: 0.7577, Train Accuracy: 65.86%, Test Loss: 0.8978, Test Accuracy: 63.29%\n",
      "Epoch [1019/2500], Train Loss: 0.7477, Train Accuracy: 67.57%, Test Loss: 0.8878, Test Accuracy: 65.82%\n",
      "Epoch [1020/2500], Train Loss: 0.7332, Train Accuracy: 67.57%, Test Loss: 0.8889, Test Accuracy: 65.82%\n",
      "Epoch [1021/2500], Train Loss: 0.7213, Train Accuracy: 68.85%, Test Loss: 0.8991, Test Accuracy: 63.29%\n",
      "Epoch [1022/2500], Train Loss: 0.7566, Train Accuracy: 67.57%, Test Loss: 0.8918, Test Accuracy: 65.82%\n",
      "Epoch [1023/2500], Train Loss: 0.7221, Train Accuracy: 66.71%, Test Loss: 0.8902, Test Accuracy: 67.09%\n",
      "Epoch [1024/2500], Train Loss: 0.7496, Train Accuracy: 66.15%, Test Loss: 0.8976, Test Accuracy: 63.29%\n",
      "Epoch [1025/2500], Train Loss: 0.7308, Train Accuracy: 67.28%, Test Loss: 0.8926, Test Accuracy: 67.09%\n",
      "Epoch [1026/2500], Train Loss: 0.7457, Train Accuracy: 67.14%, Test Loss: 0.8898, Test Accuracy: 64.56%\n",
      "Epoch [1027/2500], Train Loss: 0.7358, Train Accuracy: 67.00%, Test Loss: 0.9034, Test Accuracy: 64.56%\n",
      "Epoch [1028/2500], Train Loss: 0.7369, Train Accuracy: 66.57%, Test Loss: 0.8800, Test Accuracy: 67.09%\n",
      "Epoch [1029/2500], Train Loss: 0.7502, Train Accuracy: 65.01%, Test Loss: 0.8892, Test Accuracy: 67.09%\n",
      "Epoch [1030/2500], Train Loss: 0.7268, Train Accuracy: 66.57%, Test Loss: 0.9015, Test Accuracy: 65.82%\n",
      "Epoch [1031/2500], Train Loss: 0.7398, Train Accuracy: 65.15%, Test Loss: 0.8788, Test Accuracy: 65.82%\n",
      "Epoch [1032/2500], Train Loss: 0.7319, Train Accuracy: 67.14%, Test Loss: 0.8814, Test Accuracy: 68.35%\n",
      "Epoch [1033/2500], Train Loss: 0.7225, Train Accuracy: 67.85%, Test Loss: 0.8992, Test Accuracy: 67.09%\n",
      "Epoch [1034/2500], Train Loss: 0.7411, Train Accuracy: 67.71%, Test Loss: 0.8999, Test Accuracy: 65.82%\n",
      "Epoch [1035/2500], Train Loss: 0.7367, Train Accuracy: 67.14%, Test Loss: 0.9016, Test Accuracy: 64.56%\n",
      "Epoch [1036/2500], Train Loss: 0.7355, Train Accuracy: 67.71%, Test Loss: 0.8777, Test Accuracy: 65.82%\n",
      "Epoch [1037/2500], Train Loss: 0.7421, Train Accuracy: 67.43%, Test Loss: 0.8942, Test Accuracy: 64.56%\n",
      "Epoch [1038/2500], Train Loss: 0.7283, Train Accuracy: 69.13%, Test Loss: 0.8892, Test Accuracy: 64.56%\n",
      "Epoch [1039/2500], Train Loss: 0.7541, Train Accuracy: 68.71%, Test Loss: 0.8799, Test Accuracy: 65.82%\n",
      "Epoch [1040/2500], Train Loss: 0.7283, Train Accuracy: 68.42%, Test Loss: 0.8901, Test Accuracy: 65.82%\n",
      "Epoch [1041/2500], Train Loss: 0.7505, Train Accuracy: 66.29%, Test Loss: 0.9014, Test Accuracy: 63.29%\n",
      "Epoch [1042/2500], Train Loss: 0.7187, Train Accuracy: 67.85%, Test Loss: 0.8956, Test Accuracy: 64.56%\n",
      "Epoch [1043/2500], Train Loss: 0.7404, Train Accuracy: 67.14%, Test Loss: 0.9107, Test Accuracy: 64.56%\n",
      "Epoch [1044/2500], Train Loss: 0.7395, Train Accuracy: 67.99%, Test Loss: 0.8994, Test Accuracy: 67.09%\n",
      "Epoch [1045/2500], Train Loss: 0.7499, Train Accuracy: 66.43%, Test Loss: 0.9174, Test Accuracy: 64.56%\n",
      "Epoch [1046/2500], Train Loss: 0.7211, Train Accuracy: 68.14%, Test Loss: 0.9075, Test Accuracy: 67.09%\n",
      "Epoch [1047/2500], Train Loss: 0.7389, Train Accuracy: 67.28%, Test Loss: 0.9117, Test Accuracy: 64.56%\n",
      "Epoch [1048/2500], Train Loss: 0.7176, Train Accuracy: 67.85%, Test Loss: 0.9063, Test Accuracy: 64.56%\n",
      "Epoch [1049/2500], Train Loss: 0.7209, Train Accuracy: 68.56%, Test Loss: 0.9059, Test Accuracy: 67.09%\n",
      "Epoch [1050/2500], Train Loss: 0.7361, Train Accuracy: 66.15%, Test Loss: 0.9198, Test Accuracy: 64.56%\n",
      "Epoch [1051/2500], Train Loss: 0.6898, Train Accuracy: 69.56%, Test Loss: 0.9242, Test Accuracy: 64.56%\n",
      "Epoch [1052/2500], Train Loss: 0.7342, Train Accuracy: 65.58%, Test Loss: 0.9075, Test Accuracy: 64.56%\n",
      "Epoch [1053/2500], Train Loss: 0.7476, Train Accuracy: 68.56%, Test Loss: 0.9061, Test Accuracy: 63.29%\n",
      "Epoch [1054/2500], Train Loss: 0.7172, Train Accuracy: 68.56%, Test Loss: 0.9028, Test Accuracy: 65.82%\n",
      "Epoch [1055/2500], Train Loss: 0.7471, Train Accuracy: 68.85%, Test Loss: 0.9288, Test Accuracy: 63.29%\n",
      "Epoch [1056/2500], Train Loss: 0.7372, Train Accuracy: 67.85%, Test Loss: 0.9268, Test Accuracy: 63.29%\n",
      "Epoch [1057/2500], Train Loss: 0.7494, Train Accuracy: 66.29%, Test Loss: 0.9144, Test Accuracy: 67.09%\n",
      "Epoch [1058/2500], Train Loss: 0.7373, Train Accuracy: 67.57%, Test Loss: 0.9318, Test Accuracy: 67.09%\n",
      "Epoch [1059/2500], Train Loss: 0.7283, Train Accuracy: 66.57%, Test Loss: 0.8973, Test Accuracy: 63.29%\n",
      "Epoch [1060/2500], Train Loss: 0.7252, Train Accuracy: 67.85%, Test Loss: 0.8999, Test Accuracy: 65.82%\n",
      "Epoch [1061/2500], Train Loss: 0.7310, Train Accuracy: 67.71%, Test Loss: 0.9016, Test Accuracy: 63.29%\n",
      "Epoch [1062/2500], Train Loss: 0.7321, Train Accuracy: 67.99%, Test Loss: 0.8980, Test Accuracy: 65.82%\n",
      "Epoch [1063/2500], Train Loss: 0.7485, Train Accuracy: 66.71%, Test Loss: 0.8932, Test Accuracy: 63.29%\n",
      "Epoch [1064/2500], Train Loss: 0.7534, Train Accuracy: 65.58%, Test Loss: 0.8930, Test Accuracy: 65.82%\n",
      "Epoch [1065/2500], Train Loss: 0.7302, Train Accuracy: 66.86%, Test Loss: 0.9159, Test Accuracy: 62.03%\n",
      "Epoch [1066/2500], Train Loss: 0.7089, Train Accuracy: 68.56%, Test Loss: 0.9139, Test Accuracy: 67.09%\n",
      "Epoch [1067/2500], Train Loss: 0.7499, Train Accuracy: 67.99%, Test Loss: 0.8913, Test Accuracy: 63.29%\n",
      "Epoch [1068/2500], Train Loss: 0.7210, Train Accuracy: 68.56%, Test Loss: 0.9003, Test Accuracy: 64.56%\n",
      "Epoch [1069/2500], Train Loss: 0.7184, Train Accuracy: 67.28%, Test Loss: 0.8892, Test Accuracy: 65.82%\n",
      "Epoch [1070/2500], Train Loss: 0.7286, Train Accuracy: 66.57%, Test Loss: 0.9066, Test Accuracy: 64.56%\n",
      "Epoch [1071/2500], Train Loss: 0.7442, Train Accuracy: 66.15%, Test Loss: 0.8883, Test Accuracy: 64.56%\n",
      "Epoch [1072/2500], Train Loss: 0.7341, Train Accuracy: 67.85%, Test Loss: 0.8856, Test Accuracy: 64.56%\n",
      "Epoch [1073/2500], Train Loss: 0.7262, Train Accuracy: 68.28%, Test Loss: 0.9151, Test Accuracy: 65.82%\n",
      "Epoch [1074/2500], Train Loss: 0.7313, Train Accuracy: 68.71%, Test Loss: 0.9217, Test Accuracy: 62.03%\n",
      "Epoch [1075/2500], Train Loss: 0.7378, Train Accuracy: 65.86%, Test Loss: 0.8983, Test Accuracy: 65.82%\n",
      "Epoch [1076/2500], Train Loss: 0.7443, Train Accuracy: 66.86%, Test Loss: 0.9017, Test Accuracy: 64.56%\n",
      "Epoch [1077/2500], Train Loss: 0.7229, Train Accuracy: 65.43%, Test Loss: 0.8977, Test Accuracy: 64.56%\n",
      "Epoch [1078/2500], Train Loss: 0.7350, Train Accuracy: 65.72%, Test Loss: 0.8864, Test Accuracy: 67.09%\n",
      "Epoch [1079/2500], Train Loss: 0.7206, Train Accuracy: 67.57%, Test Loss: 0.9152, Test Accuracy: 64.56%\n",
      "Epoch [1080/2500], Train Loss: 0.7636, Train Accuracy: 68.85%, Test Loss: 0.9086, Test Accuracy: 64.56%\n",
      "Epoch [1081/2500], Train Loss: 0.7272, Train Accuracy: 67.28%, Test Loss: 0.9019, Test Accuracy: 67.09%\n",
      "Epoch [1082/2500], Train Loss: 0.7444, Train Accuracy: 67.85%, Test Loss: 0.9110, Test Accuracy: 63.29%\n",
      "Epoch [1083/2500], Train Loss: 0.7336, Train Accuracy: 66.29%, Test Loss: 0.9084, Test Accuracy: 63.29%\n",
      "Epoch [1084/2500], Train Loss: 0.7250, Train Accuracy: 68.28%, Test Loss: 0.9213, Test Accuracy: 65.82%\n",
      "Epoch [1085/2500], Train Loss: 0.7297, Train Accuracy: 67.85%, Test Loss: 0.9160, Test Accuracy: 63.29%\n",
      "Epoch [1086/2500], Train Loss: 0.7514, Train Accuracy: 65.15%, Test Loss: 0.8990, Test Accuracy: 65.82%\n",
      "Epoch [1087/2500], Train Loss: 0.7305, Train Accuracy: 68.56%, Test Loss: 0.8968, Test Accuracy: 65.82%\n",
      "Epoch [1088/2500], Train Loss: 0.7057, Train Accuracy: 69.42%, Test Loss: 0.9124, Test Accuracy: 67.09%\n",
      "Epoch [1089/2500], Train Loss: 0.7266, Train Accuracy: 67.71%, Test Loss: 0.9155, Test Accuracy: 64.56%\n",
      "Epoch [1090/2500], Train Loss: 0.7401, Train Accuracy: 66.57%, Test Loss: 0.9135, Test Accuracy: 63.29%\n",
      "Epoch [1091/2500], Train Loss: 0.7309, Train Accuracy: 68.85%, Test Loss: 0.9083, Test Accuracy: 63.29%\n",
      "Epoch [1092/2500], Train Loss: 0.7169, Train Accuracy: 67.28%, Test Loss: 0.9192, Test Accuracy: 64.56%\n",
      "Epoch [1093/2500], Train Loss: 0.7212, Train Accuracy: 68.28%, Test Loss: 0.8944, Test Accuracy: 65.82%\n",
      "Epoch [1094/2500], Train Loss: 0.7182, Train Accuracy: 67.85%, Test Loss: 0.9183, Test Accuracy: 63.29%\n",
      "Epoch [1095/2500], Train Loss: 0.7352, Train Accuracy: 67.28%, Test Loss: 0.9108, Test Accuracy: 64.56%\n",
      "Epoch [1096/2500], Train Loss: 0.7347, Train Accuracy: 67.28%, Test Loss: 0.9088, Test Accuracy: 62.03%\n",
      "Epoch [1097/2500], Train Loss: 0.7392, Train Accuracy: 66.86%, Test Loss: 0.8952, Test Accuracy: 63.29%\n",
      "Epoch [1098/2500], Train Loss: 0.7433, Train Accuracy: 66.00%, Test Loss: 0.9191, Test Accuracy: 62.03%\n",
      "Epoch [1099/2500], Train Loss: 0.7272, Train Accuracy: 67.57%, Test Loss: 0.9085, Test Accuracy: 64.56%\n",
      "Epoch [1100/2500], Train Loss: 0.7243, Train Accuracy: 67.28%, Test Loss: 0.9013, Test Accuracy: 64.56%\n",
      "Epoch [1101/2500], Train Loss: 0.7169, Train Accuracy: 67.99%, Test Loss: 0.9169, Test Accuracy: 64.56%\n",
      "Epoch [1102/2500], Train Loss: 0.7445, Train Accuracy: 66.43%, Test Loss: 0.9029, Test Accuracy: 62.03%\n",
      "Epoch [1103/2500], Train Loss: 0.7312, Train Accuracy: 66.71%, Test Loss: 0.9317, Test Accuracy: 64.56%\n",
      "Epoch [1104/2500], Train Loss: 0.7329, Train Accuracy: 66.71%, Test Loss: 0.9297, Test Accuracy: 64.56%\n",
      "Epoch [1105/2500], Train Loss: 0.7315, Train Accuracy: 67.00%, Test Loss: 0.9192, Test Accuracy: 65.82%\n",
      "Epoch [1106/2500], Train Loss: 0.7267, Train Accuracy: 68.28%, Test Loss: 0.9113, Test Accuracy: 65.82%\n",
      "Epoch [1107/2500], Train Loss: 0.7322, Train Accuracy: 67.28%, Test Loss: 0.8823, Test Accuracy: 65.82%\n",
      "Epoch [1108/2500], Train Loss: 0.7050, Train Accuracy: 68.28%, Test Loss: 0.8982, Test Accuracy: 64.56%\n",
      "Epoch [1109/2500], Train Loss: 0.7434, Train Accuracy: 68.14%, Test Loss: 0.9075, Test Accuracy: 62.03%\n",
      "Epoch [1110/2500], Train Loss: 0.7405, Train Accuracy: 67.00%, Test Loss: 0.8955, Test Accuracy: 62.03%\n",
      "Epoch [1111/2500], Train Loss: 0.7234, Train Accuracy: 68.56%, Test Loss: 0.9008, Test Accuracy: 60.76%\n",
      "Epoch [1112/2500], Train Loss: 0.7547, Train Accuracy: 68.42%, Test Loss: 0.8972, Test Accuracy: 62.03%\n",
      "Epoch [1113/2500], Train Loss: 0.7357, Train Accuracy: 68.14%, Test Loss: 0.9106, Test Accuracy: 65.82%\n",
      "Epoch [1114/2500], Train Loss: 0.7217, Train Accuracy: 68.85%, Test Loss: 0.9192, Test Accuracy: 64.56%\n",
      "Epoch [1115/2500], Train Loss: 0.7182, Train Accuracy: 68.42%, Test Loss: 0.9130, Test Accuracy: 63.29%\n",
      "Epoch [1116/2500], Train Loss: 0.7248, Train Accuracy: 67.85%, Test Loss: 0.9302, Test Accuracy: 62.03%\n",
      "Epoch [1117/2500], Train Loss: 0.7227, Train Accuracy: 68.42%, Test Loss: 0.9252, Test Accuracy: 62.03%\n",
      "Epoch [1118/2500], Train Loss: 0.7208, Train Accuracy: 67.43%, Test Loss: 0.9217, Test Accuracy: 62.03%\n",
      "Epoch [1119/2500], Train Loss: 0.7209, Train Accuracy: 67.71%, Test Loss: 0.9328, Test Accuracy: 62.03%\n",
      "Epoch [1120/2500], Train Loss: 0.7295, Train Accuracy: 67.85%, Test Loss: 0.9342, Test Accuracy: 63.29%\n",
      "Epoch [1121/2500], Train Loss: 0.7322, Train Accuracy: 67.28%, Test Loss: 0.9256, Test Accuracy: 62.03%\n",
      "Epoch [1122/2500], Train Loss: 0.7438, Train Accuracy: 66.57%, Test Loss: 0.9057, Test Accuracy: 65.82%\n",
      "Epoch [1123/2500], Train Loss: 0.7181, Train Accuracy: 66.29%, Test Loss: 0.9179, Test Accuracy: 63.29%\n",
      "Epoch [1124/2500], Train Loss: 0.7329, Train Accuracy: 67.57%, Test Loss: 0.9197, Test Accuracy: 63.29%\n",
      "Epoch [1125/2500], Train Loss: 0.7237, Train Accuracy: 67.85%, Test Loss: 0.9203, Test Accuracy: 62.03%\n",
      "Epoch [1126/2500], Train Loss: 0.7312, Train Accuracy: 66.86%, Test Loss: 0.9226, Test Accuracy: 62.03%\n",
      "Epoch [1127/2500], Train Loss: 0.7060, Train Accuracy: 68.42%, Test Loss: 0.9107, Test Accuracy: 62.03%\n",
      "Epoch [1128/2500], Train Loss: 0.7339, Train Accuracy: 65.72%, Test Loss: 0.9228, Test Accuracy: 63.29%\n",
      "Epoch [1129/2500], Train Loss: 0.7221, Train Accuracy: 67.99%, Test Loss: 0.9272, Test Accuracy: 62.03%\n",
      "Epoch [1130/2500], Train Loss: 0.7081, Train Accuracy: 67.43%, Test Loss: 0.9070, Test Accuracy: 63.29%\n",
      "Epoch [1131/2500], Train Loss: 0.7142, Train Accuracy: 69.56%, Test Loss: 0.9203, Test Accuracy: 63.29%\n",
      "Epoch [1132/2500], Train Loss: 0.7363, Train Accuracy: 66.29%, Test Loss: 0.9009, Test Accuracy: 65.82%\n",
      "Epoch [1133/2500], Train Loss: 0.7176, Train Accuracy: 67.00%, Test Loss: 0.9261, Test Accuracy: 65.82%\n",
      "Epoch [1134/2500], Train Loss: 0.7346, Train Accuracy: 69.42%, Test Loss: 0.9106, Test Accuracy: 67.09%\n",
      "Epoch [1135/2500], Train Loss: 0.7222, Train Accuracy: 66.57%, Test Loss: 0.9079, Test Accuracy: 62.03%\n",
      "Epoch [1136/2500], Train Loss: 0.7306, Train Accuracy: 67.99%, Test Loss: 0.9060, Test Accuracy: 62.03%\n",
      "Epoch [1137/2500], Train Loss: 0.7469, Train Accuracy: 66.43%, Test Loss: 0.9163, Test Accuracy: 62.03%\n",
      "Epoch [1138/2500], Train Loss: 0.7232, Train Accuracy: 70.41%, Test Loss: 0.8960, Test Accuracy: 67.09%\n",
      "Epoch [1139/2500], Train Loss: 0.7222, Train Accuracy: 67.85%, Test Loss: 0.9137, Test Accuracy: 65.82%\n",
      "Epoch [1140/2500], Train Loss: 0.7233, Train Accuracy: 67.14%, Test Loss: 0.9053, Test Accuracy: 63.29%\n",
      "Epoch [1141/2500], Train Loss: 0.7062, Train Accuracy: 68.85%, Test Loss: 0.9260, Test Accuracy: 64.56%\n",
      "Epoch [1142/2500], Train Loss: 0.7172, Train Accuracy: 69.42%, Test Loss: 0.9013, Test Accuracy: 65.82%\n",
      "Epoch [1143/2500], Train Loss: 0.7425, Train Accuracy: 66.86%, Test Loss: 0.8992, Test Accuracy: 69.62%\n",
      "Epoch [1144/2500], Train Loss: 0.7211, Train Accuracy: 68.28%, Test Loss: 0.9175, Test Accuracy: 65.82%\n",
      "Epoch [1145/2500], Train Loss: 0.7058, Train Accuracy: 67.57%, Test Loss: 0.9210, Test Accuracy: 67.09%\n",
      "Epoch [1146/2500], Train Loss: 0.7268, Train Accuracy: 68.42%, Test Loss: 0.9133, Test Accuracy: 65.82%\n",
      "Epoch [1147/2500], Train Loss: 0.7274, Train Accuracy: 67.00%, Test Loss: 0.9148, Test Accuracy: 63.29%\n",
      "Epoch [1148/2500], Train Loss: 0.7095, Train Accuracy: 69.84%, Test Loss: 0.9038, Test Accuracy: 65.82%\n",
      "Epoch [1149/2500], Train Loss: 0.7510, Train Accuracy: 67.71%, Test Loss: 0.9211, Test Accuracy: 68.35%\n",
      "Epoch [1150/2500], Train Loss: 0.7178, Train Accuracy: 68.99%, Test Loss: 0.9105, Test Accuracy: 65.82%\n",
      "Epoch [1151/2500], Train Loss: 0.7361, Train Accuracy: 66.71%, Test Loss: 0.9207, Test Accuracy: 64.56%\n",
      "Epoch [1152/2500], Train Loss: 0.6918, Train Accuracy: 68.42%, Test Loss: 0.9197, Test Accuracy: 64.56%\n",
      "Epoch [1153/2500], Train Loss: 0.7203, Train Accuracy: 68.85%, Test Loss: 0.9246, Test Accuracy: 65.82%\n",
      "Epoch [1154/2500], Train Loss: 0.7382, Train Accuracy: 66.86%, Test Loss: 0.9134, Test Accuracy: 65.82%\n",
      "Epoch [1155/2500], Train Loss: 0.7189, Train Accuracy: 68.28%, Test Loss: 0.9461, Test Accuracy: 67.09%\n",
      "Epoch [1156/2500], Train Loss: 0.7384, Train Accuracy: 67.43%, Test Loss: 0.9284, Test Accuracy: 65.82%\n",
      "Epoch [1157/2500], Train Loss: 0.7372, Train Accuracy: 66.43%, Test Loss: 0.9186, Test Accuracy: 65.82%\n",
      "Epoch [1158/2500], Train Loss: 0.7186, Train Accuracy: 68.14%, Test Loss: 0.9312, Test Accuracy: 64.56%\n",
      "Epoch [1159/2500], Train Loss: 0.7122, Train Accuracy: 68.71%, Test Loss: 0.9324, Test Accuracy: 63.29%\n",
      "Epoch [1160/2500], Train Loss: 0.7270, Train Accuracy: 66.29%, Test Loss: 0.9232, Test Accuracy: 68.35%\n",
      "Epoch [1161/2500], Train Loss: 0.7023, Train Accuracy: 69.70%, Test Loss: 0.9400, Test Accuracy: 65.82%\n",
      "Epoch [1162/2500], Train Loss: 0.7163, Train Accuracy: 67.14%, Test Loss: 0.9253, Test Accuracy: 60.76%\n",
      "Epoch [1163/2500], Train Loss: 0.6938, Train Accuracy: 69.42%, Test Loss: 0.9275, Test Accuracy: 64.56%\n",
      "Epoch [1164/2500], Train Loss: 0.7052, Train Accuracy: 69.56%, Test Loss: 0.9358, Test Accuracy: 60.76%\n",
      "Epoch [1165/2500], Train Loss: 0.7215, Train Accuracy: 68.14%, Test Loss: 0.9193, Test Accuracy: 60.76%\n",
      "Epoch [1166/2500], Train Loss: 0.7395, Train Accuracy: 67.00%, Test Loss: 0.9547, Test Accuracy: 62.03%\n",
      "Epoch [1167/2500], Train Loss: 0.7324, Train Accuracy: 68.56%, Test Loss: 0.9261, Test Accuracy: 62.03%\n",
      "Epoch [1168/2500], Train Loss: 0.6973, Train Accuracy: 69.27%, Test Loss: 0.9053, Test Accuracy: 60.76%\n",
      "Epoch [1169/2500], Train Loss: 0.7012, Train Accuracy: 69.84%, Test Loss: 0.9280, Test Accuracy: 65.82%\n",
      "Epoch [1170/2500], Train Loss: 0.7233, Train Accuracy: 66.57%, Test Loss: 0.9072, Test Accuracy: 63.29%\n",
      "Epoch [1171/2500], Train Loss: 0.7204, Train Accuracy: 67.71%, Test Loss: 0.9138, Test Accuracy: 62.03%\n",
      "Epoch [1172/2500], Train Loss: 0.7250, Train Accuracy: 68.85%, Test Loss: 0.9311, Test Accuracy: 60.76%\n",
      "Epoch [1173/2500], Train Loss: 0.7154, Train Accuracy: 69.42%, Test Loss: 0.9183, Test Accuracy: 62.03%\n",
      "Epoch [1174/2500], Train Loss: 0.7116, Train Accuracy: 69.13%, Test Loss: 0.9269, Test Accuracy: 62.03%\n",
      "Epoch [1175/2500], Train Loss: 0.7073, Train Accuracy: 68.99%, Test Loss: 0.9409, Test Accuracy: 62.03%\n",
      "Epoch [1176/2500], Train Loss: 0.7214, Train Accuracy: 67.57%, Test Loss: 0.9608, Test Accuracy: 63.29%\n",
      "Epoch [1177/2500], Train Loss: 0.7046, Train Accuracy: 71.69%, Test Loss: 0.9246, Test Accuracy: 62.03%\n",
      "Epoch [1178/2500], Train Loss: 0.7403, Train Accuracy: 69.27%, Test Loss: 0.9249, Test Accuracy: 60.76%\n",
      "Epoch [1179/2500], Train Loss: 0.7296, Train Accuracy: 66.43%, Test Loss: 0.9042, Test Accuracy: 62.03%\n",
      "Epoch [1180/2500], Train Loss: 0.7169, Train Accuracy: 67.71%, Test Loss: 0.9167, Test Accuracy: 62.03%\n",
      "Epoch [1181/2500], Train Loss: 0.7194, Train Accuracy: 66.29%, Test Loss: 0.9373, Test Accuracy: 63.29%\n",
      "Epoch [1182/2500], Train Loss: 0.7160, Train Accuracy: 69.84%, Test Loss: 0.9243, Test Accuracy: 64.56%\n",
      "Epoch [1183/2500], Train Loss: 0.7250, Train Accuracy: 68.71%, Test Loss: 0.9113, Test Accuracy: 64.56%\n",
      "Epoch [1184/2500], Train Loss: 0.7265, Train Accuracy: 66.15%, Test Loss: 0.9079, Test Accuracy: 63.29%\n",
      "Epoch [1185/2500], Train Loss: 0.7098, Train Accuracy: 68.99%, Test Loss: 0.9020, Test Accuracy: 64.56%\n",
      "Epoch [1186/2500], Train Loss: 0.7260, Train Accuracy: 65.58%, Test Loss: 0.9319, Test Accuracy: 63.29%\n",
      "Epoch [1187/2500], Train Loss: 0.7048, Train Accuracy: 67.85%, Test Loss: 0.9178, Test Accuracy: 63.29%\n",
      "Epoch [1188/2500], Train Loss: 0.7403, Train Accuracy: 67.14%, Test Loss: 0.9385, Test Accuracy: 64.56%\n",
      "Epoch [1189/2500], Train Loss: 0.7070, Train Accuracy: 69.27%, Test Loss: 0.9211, Test Accuracy: 62.03%\n",
      "Epoch [1190/2500], Train Loss: 0.7306, Train Accuracy: 68.28%, Test Loss: 0.9257, Test Accuracy: 64.56%\n",
      "Epoch [1191/2500], Train Loss: 0.7469, Train Accuracy: 66.86%, Test Loss: 0.9199, Test Accuracy: 67.09%\n",
      "Epoch [1192/2500], Train Loss: 0.7283, Train Accuracy: 67.57%, Test Loss: 0.9122, Test Accuracy: 67.09%\n",
      "Epoch [1193/2500], Train Loss: 0.7133, Train Accuracy: 67.43%, Test Loss: 0.9249, Test Accuracy: 65.82%\n",
      "Epoch [1194/2500], Train Loss: 0.7217, Train Accuracy: 66.43%, Test Loss: 0.9117, Test Accuracy: 65.82%\n",
      "Epoch [1195/2500], Train Loss: 0.7299, Train Accuracy: 68.28%, Test Loss: 0.9257, Test Accuracy: 62.03%\n",
      "Epoch [1196/2500], Train Loss: 0.7181, Train Accuracy: 67.85%, Test Loss: 0.9090, Test Accuracy: 65.82%\n",
      "Epoch [1197/2500], Train Loss: 0.7087, Train Accuracy: 67.57%, Test Loss: 0.9032, Test Accuracy: 62.03%\n",
      "Epoch [1198/2500], Train Loss: 0.7254, Train Accuracy: 67.99%, Test Loss: 0.9186, Test Accuracy: 62.03%\n",
      "Epoch [1199/2500], Train Loss: 0.7076, Train Accuracy: 67.85%, Test Loss: 0.9427, Test Accuracy: 64.56%\n",
      "Epoch [1200/2500], Train Loss: 0.7270, Train Accuracy: 68.85%, Test Loss: 0.9379, Test Accuracy: 62.03%\n",
      "Epoch [1201/2500], Train Loss: 0.7312, Train Accuracy: 69.70%, Test Loss: 0.9274, Test Accuracy: 62.03%\n",
      "Epoch [1202/2500], Train Loss: 0.7181, Train Accuracy: 67.71%, Test Loss: 0.9159, Test Accuracy: 60.76%\n",
      "Epoch [1203/2500], Train Loss: 0.7089, Train Accuracy: 67.57%, Test Loss: 0.9279, Test Accuracy: 62.03%\n",
      "Epoch [1204/2500], Train Loss: 0.7189, Train Accuracy: 66.43%, Test Loss: 0.9210, Test Accuracy: 64.56%\n",
      "Epoch [1205/2500], Train Loss: 0.7114, Train Accuracy: 69.27%, Test Loss: 0.9378, Test Accuracy: 63.29%\n",
      "Epoch [1206/2500], Train Loss: 0.7027, Train Accuracy: 69.70%, Test Loss: 0.9235, Test Accuracy: 62.03%\n",
      "Epoch [1207/2500], Train Loss: 0.7240, Train Accuracy: 69.56%, Test Loss: 0.9087, Test Accuracy: 62.03%\n",
      "Epoch [1208/2500], Train Loss: 0.7388, Train Accuracy: 67.43%, Test Loss: 0.9045, Test Accuracy: 62.03%\n",
      "Epoch [1209/2500], Train Loss: 0.7165, Train Accuracy: 66.86%, Test Loss: 0.9261, Test Accuracy: 63.29%\n",
      "Epoch [1210/2500], Train Loss: 0.7460, Train Accuracy: 67.43%, Test Loss: 0.9096, Test Accuracy: 62.03%\n",
      "Epoch [1211/2500], Train Loss: 0.7115, Train Accuracy: 68.99%, Test Loss: 0.9303, Test Accuracy: 62.03%\n",
      "Epoch [1212/2500], Train Loss: 0.7288, Train Accuracy: 64.58%, Test Loss: 0.9216, Test Accuracy: 62.03%\n",
      "Epoch [1213/2500], Train Loss: 0.7228, Train Accuracy: 67.43%, Test Loss: 0.9177, Test Accuracy: 63.29%\n",
      "Epoch [1214/2500], Train Loss: 0.7279, Train Accuracy: 68.14%, Test Loss: 0.9218, Test Accuracy: 62.03%\n",
      "Epoch [1215/2500], Train Loss: 0.7189, Train Accuracy: 68.28%, Test Loss: 0.9192, Test Accuracy: 60.76%\n",
      "Epoch [1216/2500], Train Loss: 0.7204, Train Accuracy: 66.57%, Test Loss: 0.9339, Test Accuracy: 60.76%\n",
      "Epoch [1217/2500], Train Loss: 0.7072, Train Accuracy: 68.85%, Test Loss: 0.9307, Test Accuracy: 62.03%\n",
      "Epoch [1218/2500], Train Loss: 0.7256, Train Accuracy: 67.28%, Test Loss: 0.9251, Test Accuracy: 62.03%\n",
      "Epoch [1219/2500], Train Loss: 0.7126, Train Accuracy: 68.56%, Test Loss: 0.9170, Test Accuracy: 63.29%\n",
      "Epoch [1220/2500], Train Loss: 0.7009, Train Accuracy: 68.28%, Test Loss: 0.9255, Test Accuracy: 63.29%\n",
      "Epoch [1221/2500], Train Loss: 0.7258, Train Accuracy: 68.99%, Test Loss: 0.9395, Test Accuracy: 63.29%\n",
      "Epoch [1222/2500], Train Loss: 0.6968, Train Accuracy: 70.55%, Test Loss: 0.9216, Test Accuracy: 63.29%\n",
      "Epoch [1223/2500], Train Loss: 0.7073, Train Accuracy: 66.86%, Test Loss: 0.9286, Test Accuracy: 62.03%\n",
      "Epoch [1224/2500], Train Loss: 0.6935, Train Accuracy: 69.42%, Test Loss: 0.9332, Test Accuracy: 62.03%\n",
      "Epoch [1225/2500], Train Loss: 0.7050, Train Accuracy: 67.99%, Test Loss: 0.9471, Test Accuracy: 63.29%\n",
      "Epoch [1226/2500], Train Loss: 0.7456, Train Accuracy: 67.99%, Test Loss: 0.9174, Test Accuracy: 60.76%\n",
      "Epoch [1227/2500], Train Loss: 0.7020, Train Accuracy: 69.99%, Test Loss: 0.9063, Test Accuracy: 63.29%\n",
      "Epoch [1228/2500], Train Loss: 0.7151, Train Accuracy: 68.28%, Test Loss: 0.9189, Test Accuracy: 62.03%\n",
      "Epoch [1229/2500], Train Loss: 0.7260, Train Accuracy: 65.72%, Test Loss: 0.9315, Test Accuracy: 64.56%\n",
      "Epoch [1230/2500], Train Loss: 0.7219, Train Accuracy: 67.14%, Test Loss: 0.9458, Test Accuracy: 62.03%\n",
      "Epoch [1231/2500], Train Loss: 0.7315, Train Accuracy: 66.57%, Test Loss: 0.9259, Test Accuracy: 63.29%\n",
      "Epoch [1232/2500], Train Loss: 0.7338, Train Accuracy: 67.57%, Test Loss: 0.9332, Test Accuracy: 64.56%\n",
      "Epoch [1233/2500], Train Loss: 0.7089, Train Accuracy: 67.28%, Test Loss: 0.9229, Test Accuracy: 63.29%\n",
      "Epoch [1234/2500], Train Loss: 0.7144, Train Accuracy: 67.28%, Test Loss: 0.9315, Test Accuracy: 62.03%\n",
      "Epoch [1235/2500], Train Loss: 0.7526, Train Accuracy: 67.43%, Test Loss: 0.9197, Test Accuracy: 63.29%\n",
      "Epoch [1236/2500], Train Loss: 0.7099, Train Accuracy: 70.70%, Test Loss: 0.9266, Test Accuracy: 62.03%\n",
      "Epoch [1237/2500], Train Loss: 0.7004, Train Accuracy: 67.28%, Test Loss: 0.9256, Test Accuracy: 62.03%\n",
      "Epoch [1238/2500], Train Loss: 0.7299, Train Accuracy: 65.15%, Test Loss: 0.9292, Test Accuracy: 63.29%\n",
      "Epoch [1239/2500], Train Loss: 0.7235, Train Accuracy: 67.71%, Test Loss: 0.9373, Test Accuracy: 62.03%\n",
      "Epoch [1240/2500], Train Loss: 0.7085, Train Accuracy: 69.99%, Test Loss: 0.9251, Test Accuracy: 62.03%\n",
      "Epoch [1241/2500], Train Loss: 0.7265, Train Accuracy: 67.99%, Test Loss: 0.9317, Test Accuracy: 62.03%\n",
      "Epoch [1242/2500], Train Loss: 0.7030, Train Accuracy: 67.00%, Test Loss: 0.9302, Test Accuracy: 63.29%\n",
      "Epoch [1243/2500], Train Loss: 0.7143, Train Accuracy: 68.42%, Test Loss: 0.9353, Test Accuracy: 62.03%\n",
      "Epoch [1244/2500], Train Loss: 0.7117, Train Accuracy: 67.99%, Test Loss: 0.9332, Test Accuracy: 63.29%\n",
      "Epoch [1245/2500], Train Loss: 0.6908, Train Accuracy: 68.99%, Test Loss: 0.9655, Test Accuracy: 62.03%\n",
      "Epoch [1246/2500], Train Loss: 0.7014, Train Accuracy: 67.71%, Test Loss: 0.9376, Test Accuracy: 63.29%\n",
      "Epoch [1247/2500], Train Loss: 0.7171, Train Accuracy: 68.71%, Test Loss: 0.9425, Test Accuracy: 64.56%\n",
      "Epoch [1248/2500], Train Loss: 0.7036, Train Accuracy: 69.27%, Test Loss: 0.9584, Test Accuracy: 63.29%\n",
      "Epoch [1249/2500], Train Loss: 0.7339, Train Accuracy: 67.28%, Test Loss: 0.9218, Test Accuracy: 62.03%\n",
      "Epoch [1250/2500], Train Loss: 0.7141, Train Accuracy: 68.14%, Test Loss: 0.9238, Test Accuracy: 62.03%\n",
      "Epoch [1251/2500], Train Loss: 0.7269, Train Accuracy: 65.72%, Test Loss: 0.9381, Test Accuracy: 62.03%\n",
      "Epoch [1252/2500], Train Loss: 0.7133, Train Accuracy: 69.42%, Test Loss: 0.9313, Test Accuracy: 60.76%\n",
      "Epoch [1253/2500], Train Loss: 0.7134, Train Accuracy: 67.85%, Test Loss: 0.9633, Test Accuracy: 63.29%\n",
      "Epoch [1254/2500], Train Loss: 0.7197, Train Accuracy: 68.56%, Test Loss: 0.9620, Test Accuracy: 63.29%\n",
      "Epoch [1255/2500], Train Loss: 0.7092, Train Accuracy: 69.27%, Test Loss: 0.9219, Test Accuracy: 63.29%\n",
      "Epoch [1256/2500], Train Loss: 0.6969, Train Accuracy: 71.55%, Test Loss: 0.9437, Test Accuracy: 63.29%\n",
      "Epoch [1257/2500], Train Loss: 0.7250, Train Accuracy: 69.13%, Test Loss: 0.9356, Test Accuracy: 62.03%\n",
      "Epoch [1258/2500], Train Loss: 0.7147, Train Accuracy: 68.42%, Test Loss: 0.9415, Test Accuracy: 60.76%\n",
      "Epoch [1259/2500], Train Loss: 0.7021, Train Accuracy: 69.42%, Test Loss: 0.9480, Test Accuracy: 62.03%\n",
      "Epoch [1260/2500], Train Loss: 0.7106, Train Accuracy: 67.43%, Test Loss: 0.9512, Test Accuracy: 64.56%\n",
      "Epoch [1261/2500], Train Loss: 0.7128, Train Accuracy: 68.14%, Test Loss: 0.9467, Test Accuracy: 60.76%\n",
      "Epoch [1262/2500], Train Loss: 0.7126, Train Accuracy: 68.56%, Test Loss: 0.9372, Test Accuracy: 63.29%\n",
      "Epoch [1263/2500], Train Loss: 0.7186, Train Accuracy: 69.42%, Test Loss: 0.9491, Test Accuracy: 62.03%\n",
      "Epoch [1264/2500], Train Loss: 0.7137, Train Accuracy: 69.56%, Test Loss: 0.9391, Test Accuracy: 63.29%\n",
      "Epoch [1265/2500], Train Loss: 0.7077, Train Accuracy: 68.71%, Test Loss: 0.9555, Test Accuracy: 63.29%\n",
      "Epoch [1266/2500], Train Loss: 0.6869, Train Accuracy: 68.99%, Test Loss: 0.9201, Test Accuracy: 62.03%\n",
      "Epoch [1267/2500], Train Loss: 0.7201, Train Accuracy: 69.99%, Test Loss: 0.9313, Test Accuracy: 60.76%\n",
      "Epoch [1268/2500], Train Loss: 0.7202, Train Accuracy: 68.85%, Test Loss: 0.9416, Test Accuracy: 60.76%\n",
      "Epoch [1269/2500], Train Loss: 0.6987, Train Accuracy: 67.14%, Test Loss: 0.9292, Test Accuracy: 62.03%\n",
      "Epoch [1270/2500], Train Loss: 0.7114, Train Accuracy: 70.13%, Test Loss: 0.9633, Test Accuracy: 63.29%\n",
      "Epoch [1271/2500], Train Loss: 0.7422, Train Accuracy: 66.00%, Test Loss: 0.9270, Test Accuracy: 62.03%\n",
      "Epoch [1272/2500], Train Loss: 0.7034, Train Accuracy: 69.27%, Test Loss: 0.9304, Test Accuracy: 63.29%\n",
      "Epoch [1273/2500], Train Loss: 0.7100, Train Accuracy: 68.14%, Test Loss: 0.9372, Test Accuracy: 59.49%\n",
      "Epoch [1274/2500], Train Loss: 0.7137, Train Accuracy: 67.71%, Test Loss: 0.9339, Test Accuracy: 63.29%\n",
      "Epoch [1275/2500], Train Loss: 0.6943, Train Accuracy: 68.56%, Test Loss: 0.9309, Test Accuracy: 63.29%\n",
      "Epoch [1276/2500], Train Loss: 0.7220, Train Accuracy: 67.14%, Test Loss: 0.9292, Test Accuracy: 63.29%\n",
      "Epoch [1277/2500], Train Loss: 0.6970, Train Accuracy: 68.85%, Test Loss: 0.9498, Test Accuracy: 60.76%\n",
      "Epoch [1278/2500], Train Loss: 0.7179, Train Accuracy: 68.42%, Test Loss: 0.9345, Test Accuracy: 63.29%\n",
      "Epoch [1279/2500], Train Loss: 0.7224, Train Accuracy: 68.71%, Test Loss: 0.9154, Test Accuracy: 62.03%\n",
      "Epoch [1280/2500], Train Loss: 0.7075, Train Accuracy: 67.00%, Test Loss: 0.9465, Test Accuracy: 60.76%\n",
      "Epoch [1281/2500], Train Loss: 0.7087, Train Accuracy: 68.71%, Test Loss: 0.9131, Test Accuracy: 63.29%\n",
      "Epoch [1282/2500], Train Loss: 0.7000, Train Accuracy: 70.13%, Test Loss: 0.9296, Test Accuracy: 62.03%\n",
      "Epoch [1283/2500], Train Loss: 0.6863, Train Accuracy: 69.42%, Test Loss: 0.9336, Test Accuracy: 64.56%\n",
      "Epoch [1284/2500], Train Loss: 0.7094, Train Accuracy: 68.14%, Test Loss: 0.9399, Test Accuracy: 63.29%\n",
      "Epoch [1285/2500], Train Loss: 0.7033, Train Accuracy: 69.27%, Test Loss: 0.9367, Test Accuracy: 62.03%\n",
      "Epoch [1286/2500], Train Loss: 0.7140, Train Accuracy: 68.56%, Test Loss: 0.9459, Test Accuracy: 64.56%\n",
      "Epoch [1287/2500], Train Loss: 0.7039, Train Accuracy: 67.99%, Test Loss: 0.9371, Test Accuracy: 64.56%\n",
      "Epoch [1288/2500], Train Loss: 0.6878, Train Accuracy: 69.70%, Test Loss: 0.9665, Test Accuracy: 65.82%\n",
      "Epoch [1289/2500], Train Loss: 0.6996, Train Accuracy: 69.70%, Test Loss: 0.9599, Test Accuracy: 60.76%\n",
      "Epoch [1290/2500], Train Loss: 0.7286, Train Accuracy: 69.99%, Test Loss: 0.9404, Test Accuracy: 63.29%\n",
      "Epoch [1291/2500], Train Loss: 0.6915, Train Accuracy: 69.99%, Test Loss: 0.9382, Test Accuracy: 63.29%\n",
      "Epoch [1292/2500], Train Loss: 0.6824, Train Accuracy: 70.70%, Test Loss: 0.9623, Test Accuracy: 63.29%\n",
      "Epoch [1293/2500], Train Loss: 0.7079, Train Accuracy: 68.14%, Test Loss: 0.9385, Test Accuracy: 63.29%\n",
      "Epoch [1294/2500], Train Loss: 0.7092, Train Accuracy: 68.85%, Test Loss: 0.9405, Test Accuracy: 63.29%\n",
      "Epoch [1295/2500], Train Loss: 0.6983, Train Accuracy: 68.71%, Test Loss: 0.9374, Test Accuracy: 60.76%\n",
      "Epoch [1296/2500], Train Loss: 0.7211, Train Accuracy: 67.71%, Test Loss: 0.9536, Test Accuracy: 62.03%\n",
      "Epoch [1297/2500], Train Loss: 0.6896, Train Accuracy: 69.70%, Test Loss: 0.9438, Test Accuracy: 60.76%\n",
      "Epoch [1298/2500], Train Loss: 0.6956, Train Accuracy: 66.00%, Test Loss: 0.9122, Test Accuracy: 63.29%\n",
      "Epoch [1299/2500], Train Loss: 0.7000, Train Accuracy: 68.56%, Test Loss: 0.9336, Test Accuracy: 62.03%\n",
      "Epoch [1300/2500], Train Loss: 0.7242, Train Accuracy: 67.71%, Test Loss: 0.9245, Test Accuracy: 62.03%\n",
      "Epoch [1301/2500], Train Loss: 0.6968, Train Accuracy: 68.42%, Test Loss: 0.9359, Test Accuracy: 64.56%\n",
      "Epoch [1302/2500], Train Loss: 0.6880, Train Accuracy: 69.42%, Test Loss: 0.9508, Test Accuracy: 63.29%\n",
      "Epoch [1303/2500], Train Loss: 0.7198, Train Accuracy: 67.28%, Test Loss: 0.9152, Test Accuracy: 62.03%\n",
      "Epoch [1304/2500], Train Loss: 0.6964, Train Accuracy: 68.14%, Test Loss: 0.9335, Test Accuracy: 63.29%\n",
      "Epoch [1305/2500], Train Loss: 0.7015, Train Accuracy: 69.13%, Test Loss: 0.9455, Test Accuracy: 64.56%\n",
      "Epoch [1306/2500], Train Loss: 0.7042, Train Accuracy: 67.43%, Test Loss: 0.9289, Test Accuracy: 63.29%\n",
      "Epoch [1307/2500], Train Loss: 0.7047, Train Accuracy: 69.27%, Test Loss: 0.9371, Test Accuracy: 64.56%\n",
      "Epoch [1308/2500], Train Loss: 0.7147, Train Accuracy: 68.56%, Test Loss: 0.9570, Test Accuracy: 63.29%\n",
      "Epoch [1309/2500], Train Loss: 0.7028, Train Accuracy: 68.99%, Test Loss: 0.9627, Test Accuracy: 63.29%\n",
      "Epoch [1310/2500], Train Loss: 0.6955, Train Accuracy: 69.70%, Test Loss: 0.9361, Test Accuracy: 64.56%\n",
      "Epoch [1311/2500], Train Loss: 0.6964, Train Accuracy: 68.85%, Test Loss: 0.9567, Test Accuracy: 63.29%\n",
      "Epoch [1312/2500], Train Loss: 0.7129, Train Accuracy: 68.56%, Test Loss: 0.9422, Test Accuracy: 63.29%\n",
      "Epoch [1313/2500], Train Loss: 0.7049, Train Accuracy: 67.85%, Test Loss: 0.9255, Test Accuracy: 64.56%\n",
      "Epoch [1314/2500], Train Loss: 0.7162, Train Accuracy: 66.29%, Test Loss: 0.9349, Test Accuracy: 63.29%\n",
      "Epoch [1315/2500], Train Loss: 0.6991, Train Accuracy: 68.71%, Test Loss: 0.9524, Test Accuracy: 63.29%\n",
      "Epoch [1316/2500], Train Loss: 0.7104, Train Accuracy: 68.42%, Test Loss: 0.9306, Test Accuracy: 62.03%\n",
      "Epoch [1317/2500], Train Loss: 0.7031, Train Accuracy: 69.27%, Test Loss: 0.9433, Test Accuracy: 60.76%\n",
      "Epoch [1318/2500], Train Loss: 0.7059, Train Accuracy: 67.00%, Test Loss: 0.9590, Test Accuracy: 63.29%\n",
      "Epoch [1319/2500], Train Loss: 0.6803, Train Accuracy: 70.27%, Test Loss: 0.9435, Test Accuracy: 64.56%\n",
      "Epoch [1320/2500], Train Loss: 0.6975, Train Accuracy: 68.14%, Test Loss: 0.9222, Test Accuracy: 64.56%\n",
      "Epoch [1321/2500], Train Loss: 0.7173, Train Accuracy: 67.85%, Test Loss: 0.9145, Test Accuracy: 63.29%\n",
      "Epoch [1322/2500], Train Loss: 0.6918, Train Accuracy: 67.99%, Test Loss: 0.9183, Test Accuracy: 64.56%\n",
      "Epoch [1323/2500], Train Loss: 0.6880, Train Accuracy: 69.42%, Test Loss: 0.9292, Test Accuracy: 64.56%\n",
      "Epoch [1324/2500], Train Loss: 0.6895, Train Accuracy: 69.84%, Test Loss: 0.9319, Test Accuracy: 60.76%\n",
      "Epoch [1325/2500], Train Loss: 0.7030, Train Accuracy: 69.70%, Test Loss: 0.9286, Test Accuracy: 63.29%\n",
      "Epoch [1326/2500], Train Loss: 0.6969, Train Accuracy: 69.56%, Test Loss: 0.9451, Test Accuracy: 62.03%\n",
      "Epoch [1327/2500], Train Loss: 0.7184, Train Accuracy: 68.42%, Test Loss: 0.9369, Test Accuracy: 63.29%\n",
      "Epoch [1328/2500], Train Loss: 0.7018, Train Accuracy: 70.27%, Test Loss: 0.9498, Test Accuracy: 63.29%\n",
      "Epoch [1329/2500], Train Loss: 0.6981, Train Accuracy: 70.41%, Test Loss: 0.9334, Test Accuracy: 63.29%\n",
      "Epoch [1330/2500], Train Loss: 0.7250, Train Accuracy: 68.71%, Test Loss: 0.9407, Test Accuracy: 63.29%\n",
      "Epoch [1331/2500], Train Loss: 0.6941, Train Accuracy: 68.42%, Test Loss: 0.9407, Test Accuracy: 63.29%\n",
      "Epoch [1332/2500], Train Loss: 0.7104, Train Accuracy: 69.99%, Test Loss: 0.9496, Test Accuracy: 63.29%\n",
      "Epoch [1333/2500], Train Loss: 0.7200, Train Accuracy: 67.71%, Test Loss: 0.9560, Test Accuracy: 64.56%\n",
      "Epoch [1334/2500], Train Loss: 0.7104, Train Accuracy: 70.70%, Test Loss: 0.9523, Test Accuracy: 63.29%\n",
      "Epoch [1335/2500], Train Loss: 0.7184, Train Accuracy: 68.42%, Test Loss: 0.9266, Test Accuracy: 63.29%\n",
      "Epoch [1336/2500], Train Loss: 0.7193, Train Accuracy: 69.99%, Test Loss: 0.9643, Test Accuracy: 60.76%\n",
      "Epoch [1337/2500], Train Loss: 0.7052, Train Accuracy: 67.85%, Test Loss: 0.9541, Test Accuracy: 63.29%\n",
      "Epoch [1338/2500], Train Loss: 0.7016, Train Accuracy: 68.42%, Test Loss: 0.9597, Test Accuracy: 62.03%\n",
      "Epoch [1339/2500], Train Loss: 0.7029, Train Accuracy: 67.99%, Test Loss: 0.9465, Test Accuracy: 63.29%\n",
      "Epoch [1340/2500], Train Loss: 0.6798, Train Accuracy: 69.99%, Test Loss: 0.9509, Test Accuracy: 63.29%\n",
      "Epoch [1341/2500], Train Loss: 0.7080, Train Accuracy: 68.85%, Test Loss: 0.9500, Test Accuracy: 62.03%\n",
      "Epoch [1342/2500], Train Loss: 0.6986, Train Accuracy: 68.85%, Test Loss: 0.9517, Test Accuracy: 63.29%\n",
      "Epoch [1343/2500], Train Loss: 0.7041, Train Accuracy: 66.43%, Test Loss: 0.9575, Test Accuracy: 63.29%\n",
      "Epoch [1344/2500], Train Loss: 0.7075, Train Accuracy: 68.42%, Test Loss: 0.9458, Test Accuracy: 64.56%\n",
      "Epoch [1345/2500], Train Loss: 0.7089, Train Accuracy: 69.70%, Test Loss: 0.9527, Test Accuracy: 59.49%\n",
      "Epoch [1346/2500], Train Loss: 0.6864, Train Accuracy: 69.27%, Test Loss: 0.9451, Test Accuracy: 63.29%\n",
      "Epoch [1347/2500], Train Loss: 0.6914, Train Accuracy: 70.13%, Test Loss: 0.9674, Test Accuracy: 63.29%\n",
      "Epoch [1348/2500], Train Loss: 0.7079, Train Accuracy: 68.28%, Test Loss: 0.9549, Test Accuracy: 64.56%\n",
      "Epoch [1349/2500], Train Loss: 0.7114, Train Accuracy: 70.13%, Test Loss: 0.9412, Test Accuracy: 63.29%\n",
      "Epoch [1350/2500], Train Loss: 0.6958, Train Accuracy: 68.28%, Test Loss: 0.9517, Test Accuracy: 60.76%\n",
      "Epoch [1351/2500], Train Loss: 0.7017, Train Accuracy: 68.42%, Test Loss: 0.9884, Test Accuracy: 60.76%\n",
      "Epoch [1352/2500], Train Loss: 0.6882, Train Accuracy: 67.28%, Test Loss: 0.9447, Test Accuracy: 64.56%\n",
      "Epoch [1353/2500], Train Loss: 0.6961, Train Accuracy: 68.28%, Test Loss: 0.9700, Test Accuracy: 63.29%\n",
      "Epoch [1354/2500], Train Loss: 0.6886, Train Accuracy: 69.27%, Test Loss: 0.9320, Test Accuracy: 64.56%\n",
      "Epoch [1355/2500], Train Loss: 0.7079, Train Accuracy: 67.99%, Test Loss: 0.9450, Test Accuracy: 64.56%\n",
      "Epoch [1356/2500], Train Loss: 0.7115, Train Accuracy: 66.71%, Test Loss: 0.9478, Test Accuracy: 63.29%\n",
      "Epoch [1357/2500], Train Loss: 0.7060, Train Accuracy: 68.42%, Test Loss: 0.9525, Test Accuracy: 62.03%\n",
      "Epoch [1358/2500], Train Loss: 0.6947, Train Accuracy: 70.55%, Test Loss: 0.9574, Test Accuracy: 63.29%\n",
      "Epoch [1359/2500], Train Loss: 0.7073, Train Accuracy: 68.14%, Test Loss: 0.9517, Test Accuracy: 60.76%\n",
      "Epoch [1360/2500], Train Loss: 0.6960, Train Accuracy: 68.99%, Test Loss: 0.9403, Test Accuracy: 62.03%\n",
      "Epoch [1361/2500], Train Loss: 0.7209, Train Accuracy: 65.43%, Test Loss: 0.9329, Test Accuracy: 63.29%\n",
      "Epoch [1362/2500], Train Loss: 0.6899, Train Accuracy: 69.42%, Test Loss: 0.9452, Test Accuracy: 63.29%\n",
      "Epoch [1363/2500], Train Loss: 0.6891, Train Accuracy: 68.99%, Test Loss: 0.9243, Test Accuracy: 64.56%\n",
      "Epoch [1364/2500], Train Loss: 0.7122, Train Accuracy: 66.71%, Test Loss: 0.9446, Test Accuracy: 63.29%\n",
      "Epoch [1365/2500], Train Loss: 0.6792, Train Accuracy: 70.70%, Test Loss: 0.9496, Test Accuracy: 62.03%\n",
      "Epoch [1366/2500], Train Loss: 0.6915, Train Accuracy: 67.00%, Test Loss: 0.9725, Test Accuracy: 62.03%\n",
      "Epoch [1367/2500], Train Loss: 0.7065, Train Accuracy: 70.70%, Test Loss: 0.9420, Test Accuracy: 63.29%\n",
      "Epoch [1368/2500], Train Loss: 0.7339, Train Accuracy: 67.43%, Test Loss: 0.9497, Test Accuracy: 62.03%\n",
      "Epoch [1369/2500], Train Loss: 0.7095, Train Accuracy: 69.27%, Test Loss: 0.9484, Test Accuracy: 63.29%\n",
      "Epoch [1370/2500], Train Loss: 0.6810, Train Accuracy: 71.12%, Test Loss: 0.9544, Test Accuracy: 62.03%\n",
      "Epoch [1371/2500], Train Loss: 0.7116, Train Accuracy: 68.71%, Test Loss: 0.9437, Test Accuracy: 63.29%\n",
      "Epoch [1372/2500], Train Loss: 0.7092, Train Accuracy: 69.13%, Test Loss: 0.9327, Test Accuracy: 62.03%\n",
      "Epoch [1373/2500], Train Loss: 0.6908, Train Accuracy: 68.71%, Test Loss: 0.9253, Test Accuracy: 64.56%\n",
      "Epoch [1374/2500], Train Loss: 0.7117, Train Accuracy: 67.71%, Test Loss: 0.9219, Test Accuracy: 63.29%\n",
      "Epoch [1375/2500], Train Loss: 0.6879, Train Accuracy: 69.42%, Test Loss: 0.9340, Test Accuracy: 63.29%\n",
      "Epoch [1376/2500], Train Loss: 0.7117, Train Accuracy: 68.71%, Test Loss: 0.9249, Test Accuracy: 64.56%\n",
      "Epoch [1377/2500], Train Loss: 0.7030, Train Accuracy: 68.56%, Test Loss: 0.9304, Test Accuracy: 64.56%\n",
      "Epoch [1378/2500], Train Loss: 0.6903, Train Accuracy: 69.42%, Test Loss: 0.9244, Test Accuracy: 64.56%\n",
      "Epoch [1379/2500], Train Loss: 0.6871, Train Accuracy: 68.42%, Test Loss: 0.9247, Test Accuracy: 63.29%\n",
      "Epoch [1380/2500], Train Loss: 0.6812, Train Accuracy: 69.84%, Test Loss: 0.9332, Test Accuracy: 63.29%\n",
      "Epoch [1381/2500], Train Loss: 0.7138, Train Accuracy: 68.14%, Test Loss: 0.9287, Test Accuracy: 64.56%\n",
      "Epoch [1382/2500], Train Loss: 0.6910, Train Accuracy: 70.27%, Test Loss: 0.9296, Test Accuracy: 62.03%\n",
      "Epoch [1383/2500], Train Loss: 0.7078, Train Accuracy: 68.85%, Test Loss: 0.9481, Test Accuracy: 63.29%\n",
      "Epoch [1384/2500], Train Loss: 0.6873, Train Accuracy: 69.99%, Test Loss: 0.9466, Test Accuracy: 63.29%\n",
      "Epoch [1385/2500], Train Loss: 0.6964, Train Accuracy: 68.71%, Test Loss: 0.9709, Test Accuracy: 62.03%\n",
      "Epoch [1386/2500], Train Loss: 0.7041, Train Accuracy: 68.56%, Test Loss: 0.9795, Test Accuracy: 63.29%\n",
      "Epoch [1387/2500], Train Loss: 0.6826, Train Accuracy: 69.84%, Test Loss: 0.9680, Test Accuracy: 63.29%\n",
      "Epoch [1388/2500], Train Loss: 0.7129, Train Accuracy: 67.85%, Test Loss: 0.9585, Test Accuracy: 60.76%\n",
      "Epoch [1389/2500], Train Loss: 0.7017, Train Accuracy: 70.13%, Test Loss: 0.9574, Test Accuracy: 60.76%\n",
      "Epoch [1390/2500], Train Loss: 0.6967, Train Accuracy: 68.99%, Test Loss: 0.9599, Test Accuracy: 62.03%\n",
      "Epoch [1391/2500], Train Loss: 0.7037, Train Accuracy: 67.57%, Test Loss: 0.9484, Test Accuracy: 62.03%\n",
      "Epoch [1392/2500], Train Loss: 0.7045, Train Accuracy: 68.56%, Test Loss: 0.9633, Test Accuracy: 63.29%\n",
      "Epoch [1393/2500], Train Loss: 0.6939, Train Accuracy: 68.42%, Test Loss: 0.9358, Test Accuracy: 63.29%\n",
      "Epoch [1394/2500], Train Loss: 0.6972, Train Accuracy: 68.56%, Test Loss: 0.9196, Test Accuracy: 63.29%\n",
      "Epoch [1395/2500], Train Loss: 0.6902, Train Accuracy: 68.28%, Test Loss: 0.9681, Test Accuracy: 62.03%\n",
      "Epoch [1396/2500], Train Loss: 0.7211, Train Accuracy: 67.85%, Test Loss: 0.9529, Test Accuracy: 62.03%\n",
      "Epoch [1397/2500], Train Loss: 0.7190, Train Accuracy: 67.43%, Test Loss: 0.9434, Test Accuracy: 60.76%\n",
      "Epoch [1398/2500], Train Loss: 0.6945, Train Accuracy: 68.14%, Test Loss: 0.9615, Test Accuracy: 60.76%\n",
      "Epoch [1399/2500], Train Loss: 0.6978, Train Accuracy: 66.86%, Test Loss: 0.9819, Test Accuracy: 62.03%\n",
      "Epoch [1400/2500], Train Loss: 0.7072, Train Accuracy: 68.42%, Test Loss: 0.9619, Test Accuracy: 62.03%\n",
      "Epoch [1401/2500], Train Loss: 0.7350, Train Accuracy: 65.86%, Test Loss: 0.9592, Test Accuracy: 60.76%\n",
      "Epoch [1402/2500], Train Loss: 0.6861, Train Accuracy: 71.27%, Test Loss: 0.9678, Test Accuracy: 60.76%\n",
      "Epoch [1403/2500], Train Loss: 0.7069, Train Accuracy: 68.99%, Test Loss: 0.9397, Test Accuracy: 63.29%\n",
      "Epoch [1404/2500], Train Loss: 0.6863, Train Accuracy: 69.99%, Test Loss: 0.9363, Test Accuracy: 63.29%\n",
      "Epoch [1405/2500], Train Loss: 0.7085, Train Accuracy: 67.99%, Test Loss: 0.9646, Test Accuracy: 62.03%\n",
      "Epoch [1406/2500], Train Loss: 0.7104, Train Accuracy: 68.42%, Test Loss: 0.9261, Test Accuracy: 64.56%\n",
      "Epoch [1407/2500], Train Loss: 0.6906, Train Accuracy: 68.42%, Test Loss: 0.9485, Test Accuracy: 60.76%\n",
      "Epoch [1408/2500], Train Loss: 0.6783, Train Accuracy: 69.42%, Test Loss: 0.9298, Test Accuracy: 64.56%\n",
      "Epoch [1409/2500], Train Loss: 0.6846, Train Accuracy: 67.57%, Test Loss: 0.9731, Test Accuracy: 59.49%\n",
      "Epoch [1410/2500], Train Loss: 0.7001, Train Accuracy: 69.42%, Test Loss: 0.9671, Test Accuracy: 59.49%\n",
      "Epoch [1411/2500], Train Loss: 0.7008, Train Accuracy: 67.85%, Test Loss: 0.9524, Test Accuracy: 60.76%\n",
      "Epoch [1412/2500], Train Loss: 0.6932, Train Accuracy: 70.27%, Test Loss: 0.9472, Test Accuracy: 62.03%\n",
      "Epoch [1413/2500], Train Loss: 0.6977, Train Accuracy: 68.28%, Test Loss: 0.9442, Test Accuracy: 64.56%\n",
      "Epoch [1414/2500], Train Loss: 0.6858, Train Accuracy: 68.99%, Test Loss: 0.9391, Test Accuracy: 64.56%\n",
      "Epoch [1415/2500], Train Loss: 0.6928, Train Accuracy: 70.70%, Test Loss: 0.9418, Test Accuracy: 64.56%\n",
      "Epoch [1416/2500], Train Loss: 0.6768, Train Accuracy: 70.27%, Test Loss: 0.9620, Test Accuracy: 63.29%\n",
      "Epoch [1417/2500], Train Loss: 0.6692, Train Accuracy: 71.41%, Test Loss: 0.9549, Test Accuracy: 64.56%\n",
      "Epoch [1418/2500], Train Loss: 0.6769, Train Accuracy: 68.42%, Test Loss: 0.9586, Test Accuracy: 64.56%\n",
      "Epoch [1419/2500], Train Loss: 0.7018, Train Accuracy: 69.42%, Test Loss: 0.9490, Test Accuracy: 62.03%\n",
      "Epoch [1420/2500], Train Loss: 0.6887, Train Accuracy: 70.13%, Test Loss: 1.0066, Test Accuracy: 59.49%\n",
      "Epoch [1421/2500], Train Loss: 0.6917, Train Accuracy: 69.70%, Test Loss: 0.9912, Test Accuracy: 60.76%\n",
      "Epoch [1422/2500], Train Loss: 0.6854, Train Accuracy: 68.14%, Test Loss: 0.9933, Test Accuracy: 60.76%\n",
      "Epoch [1423/2500], Train Loss: 0.6743, Train Accuracy: 70.41%, Test Loss: 0.9547, Test Accuracy: 60.76%\n",
      "Epoch [1424/2500], Train Loss: 0.6975, Train Accuracy: 68.14%, Test Loss: 0.9654, Test Accuracy: 62.03%\n",
      "Epoch [1425/2500], Train Loss: 0.7061, Train Accuracy: 65.86%, Test Loss: 1.0048, Test Accuracy: 60.76%\n",
      "Epoch [1426/2500], Train Loss: 0.6913, Train Accuracy: 69.70%, Test Loss: 1.0132, Test Accuracy: 59.49%\n",
      "Epoch [1427/2500], Train Loss: 0.6906, Train Accuracy: 68.99%, Test Loss: 0.9896, Test Accuracy: 60.76%\n",
      "Epoch [1428/2500], Train Loss: 0.6936, Train Accuracy: 68.85%, Test Loss: 0.9766, Test Accuracy: 60.76%\n",
      "Epoch [1429/2500], Train Loss: 0.6949, Train Accuracy: 71.12%, Test Loss: 0.9861, Test Accuracy: 62.03%\n",
      "Epoch [1430/2500], Train Loss: 0.6956, Train Accuracy: 69.27%, Test Loss: 0.9258, Test Accuracy: 62.03%\n",
      "Epoch [1431/2500], Train Loss: 0.6962, Train Accuracy: 69.56%, Test Loss: 0.9542, Test Accuracy: 60.76%\n",
      "Epoch [1432/2500], Train Loss: 0.6912, Train Accuracy: 70.41%, Test Loss: 0.9695, Test Accuracy: 62.03%\n",
      "Epoch [1433/2500], Train Loss: 0.6999, Train Accuracy: 69.27%, Test Loss: 0.9656, Test Accuracy: 63.29%\n",
      "Epoch [1434/2500], Train Loss: 0.6924, Train Accuracy: 67.71%, Test Loss: 0.9648, Test Accuracy: 60.76%\n",
      "Epoch [1435/2500], Train Loss: 0.7082, Train Accuracy: 68.71%, Test Loss: 0.9364, Test Accuracy: 60.76%\n",
      "Epoch [1436/2500], Train Loss: 0.6865, Train Accuracy: 69.84%, Test Loss: 0.9483, Test Accuracy: 62.03%\n",
      "Epoch [1437/2500], Train Loss: 0.7187, Train Accuracy: 66.15%, Test Loss: 0.9649, Test Accuracy: 63.29%\n",
      "Epoch [1438/2500], Train Loss: 0.6841, Train Accuracy: 68.28%, Test Loss: 0.9476, Test Accuracy: 64.56%\n",
      "Epoch [1439/2500], Train Loss: 0.7021, Train Accuracy: 68.14%, Test Loss: 0.9655, Test Accuracy: 63.29%\n",
      "Epoch [1440/2500], Train Loss: 0.6803, Train Accuracy: 69.99%, Test Loss: 0.9836, Test Accuracy: 59.49%\n",
      "Epoch [1441/2500], Train Loss: 0.6876, Train Accuracy: 70.84%, Test Loss: 0.9630, Test Accuracy: 64.56%\n",
      "Epoch [1442/2500], Train Loss: 0.6771, Train Accuracy: 70.98%, Test Loss: 0.9657, Test Accuracy: 65.82%\n",
      "Epoch [1443/2500], Train Loss: 0.6745, Train Accuracy: 67.99%, Test Loss: 0.9781, Test Accuracy: 63.29%\n",
      "Epoch [1444/2500], Train Loss: 0.6921, Train Accuracy: 67.43%, Test Loss: 0.9602, Test Accuracy: 64.56%\n",
      "Epoch [1445/2500], Train Loss: 0.6979, Train Accuracy: 68.99%, Test Loss: 0.9581, Test Accuracy: 62.03%\n",
      "Epoch [1446/2500], Train Loss: 0.6944, Train Accuracy: 69.56%, Test Loss: 0.9642, Test Accuracy: 60.76%\n",
      "Epoch [1447/2500], Train Loss: 0.6752, Train Accuracy: 69.42%, Test Loss: 0.9682, Test Accuracy: 59.49%\n",
      "Epoch [1448/2500], Train Loss: 0.6655, Train Accuracy: 69.27%, Test Loss: 0.9728, Test Accuracy: 60.76%\n",
      "Epoch [1449/2500], Train Loss: 0.6813, Train Accuracy: 69.27%, Test Loss: 0.9690, Test Accuracy: 60.76%\n",
      "Epoch [1450/2500], Train Loss: 0.6970, Train Accuracy: 68.85%, Test Loss: 0.9735, Test Accuracy: 62.03%\n",
      "Epoch [1451/2500], Train Loss: 0.7006, Train Accuracy: 70.27%, Test Loss: 0.9629, Test Accuracy: 63.29%\n",
      "Epoch [1452/2500], Train Loss: 0.6959, Train Accuracy: 69.13%, Test Loss: 0.9553, Test Accuracy: 62.03%\n",
      "Epoch [1453/2500], Train Loss: 0.6928, Train Accuracy: 69.84%, Test Loss: 0.9624, Test Accuracy: 60.76%\n",
      "Epoch [1454/2500], Train Loss: 0.6801, Train Accuracy: 70.98%, Test Loss: 0.9681, Test Accuracy: 60.76%\n",
      "Epoch [1455/2500], Train Loss: 0.6954, Train Accuracy: 69.70%, Test Loss: 0.9611, Test Accuracy: 60.76%\n",
      "Epoch [1456/2500], Train Loss: 0.7156, Train Accuracy: 67.28%, Test Loss: 0.9776, Test Accuracy: 59.49%\n",
      "Epoch [1457/2500], Train Loss: 0.6758, Train Accuracy: 69.13%, Test Loss: 0.9818, Test Accuracy: 60.76%\n",
      "Epoch [1458/2500], Train Loss: 0.6976, Train Accuracy: 67.28%, Test Loss: 0.9719, Test Accuracy: 60.76%\n",
      "Epoch [1459/2500], Train Loss: 0.6918, Train Accuracy: 68.85%, Test Loss: 0.9651, Test Accuracy: 62.03%\n",
      "Epoch [1460/2500], Train Loss: 0.6878, Train Accuracy: 68.28%, Test Loss: 0.9913, Test Accuracy: 60.76%\n",
      "Epoch [1461/2500], Train Loss: 0.6868, Train Accuracy: 69.70%, Test Loss: 0.9901, Test Accuracy: 62.03%\n",
      "Epoch [1462/2500], Train Loss: 0.6947, Train Accuracy: 71.55%, Test Loss: 1.0276, Test Accuracy: 63.29%\n",
      "Epoch [1463/2500], Train Loss: 0.6812, Train Accuracy: 69.56%, Test Loss: 0.9802, Test Accuracy: 64.56%\n",
      "Epoch [1464/2500], Train Loss: 0.7139, Train Accuracy: 70.55%, Test Loss: 0.9579, Test Accuracy: 64.56%\n",
      "Epoch [1465/2500], Train Loss: 0.6900, Train Accuracy: 69.42%, Test Loss: 0.9538, Test Accuracy: 60.76%\n",
      "Epoch [1466/2500], Train Loss: 0.6866, Train Accuracy: 71.12%, Test Loss: 0.9652, Test Accuracy: 60.76%\n",
      "Epoch [1467/2500], Train Loss: 0.6857, Train Accuracy: 69.84%, Test Loss: 0.9810, Test Accuracy: 62.03%\n",
      "Epoch [1468/2500], Train Loss: 0.7101, Train Accuracy: 67.57%, Test Loss: 0.9683, Test Accuracy: 64.56%\n",
      "Epoch [1469/2500], Train Loss: 0.6966, Train Accuracy: 69.99%, Test Loss: 0.9402, Test Accuracy: 63.29%\n",
      "Epoch [1470/2500], Train Loss: 0.6780, Train Accuracy: 70.13%, Test Loss: 0.9384, Test Accuracy: 65.82%\n",
      "Epoch [1471/2500], Train Loss: 0.7019, Train Accuracy: 68.56%, Test Loss: 0.9455, Test Accuracy: 65.82%\n",
      "Epoch [1472/2500], Train Loss: 0.6910, Train Accuracy: 70.70%, Test Loss: 0.9872, Test Accuracy: 63.29%\n",
      "Epoch [1473/2500], Train Loss: 0.6956, Train Accuracy: 68.99%, Test Loss: 0.9290, Test Accuracy: 62.03%\n",
      "Epoch [1474/2500], Train Loss: 0.6804, Train Accuracy: 69.42%, Test Loss: 0.9632, Test Accuracy: 62.03%\n",
      "Epoch [1475/2500], Train Loss: 0.6958, Train Accuracy: 69.56%, Test Loss: 0.9685, Test Accuracy: 65.82%\n",
      "Epoch [1476/2500], Train Loss: 0.7031, Train Accuracy: 71.27%, Test Loss: 0.9678, Test Accuracy: 60.76%\n",
      "Epoch [1477/2500], Train Loss: 0.6948, Train Accuracy: 71.27%, Test Loss: 0.9620, Test Accuracy: 62.03%\n",
      "Epoch [1478/2500], Train Loss: 0.7022, Train Accuracy: 68.99%, Test Loss: 0.9635, Test Accuracy: 63.29%\n",
      "Epoch [1479/2500], Train Loss: 0.6781, Train Accuracy: 71.12%, Test Loss: 0.9648, Test Accuracy: 63.29%\n",
      "Epoch [1480/2500], Train Loss: 0.6901, Train Accuracy: 68.28%, Test Loss: 0.9665, Test Accuracy: 62.03%\n",
      "Epoch [1481/2500], Train Loss: 0.6758, Train Accuracy: 70.13%, Test Loss: 0.9627, Test Accuracy: 62.03%\n",
      "Epoch [1482/2500], Train Loss: 0.7024, Train Accuracy: 69.70%, Test Loss: 0.9504, Test Accuracy: 62.03%\n",
      "Epoch [1483/2500], Train Loss: 0.6945, Train Accuracy: 70.41%, Test Loss: 0.9655, Test Accuracy: 62.03%\n",
      "Epoch [1484/2500], Train Loss: 0.6883, Train Accuracy: 69.56%, Test Loss: 0.9603, Test Accuracy: 64.56%\n",
      "Epoch [1485/2500], Train Loss: 0.6822, Train Accuracy: 70.70%, Test Loss: 0.9824, Test Accuracy: 64.56%\n",
      "Epoch [1486/2500], Train Loss: 0.6951, Train Accuracy: 69.99%, Test Loss: 0.9966, Test Accuracy: 62.03%\n",
      "Epoch [1487/2500], Train Loss: 0.6739, Train Accuracy: 70.98%, Test Loss: 0.9782, Test Accuracy: 63.29%\n",
      "Epoch [1488/2500], Train Loss: 0.7165, Train Accuracy: 68.71%, Test Loss: 0.9609, Test Accuracy: 63.29%\n",
      "Epoch [1489/2500], Train Loss: 0.6865, Train Accuracy: 70.41%, Test Loss: 0.9765, Test Accuracy: 64.56%\n",
      "Epoch [1490/2500], Train Loss: 0.6746, Train Accuracy: 69.99%, Test Loss: 0.9794, Test Accuracy: 63.29%\n",
      "Epoch [1491/2500], Train Loss: 0.6910, Train Accuracy: 68.56%, Test Loss: 0.9334, Test Accuracy: 64.56%\n",
      "Epoch [1492/2500], Train Loss: 0.6707, Train Accuracy: 69.27%, Test Loss: 0.9679, Test Accuracy: 62.03%\n",
      "Epoch [1493/2500], Train Loss: 0.6741, Train Accuracy: 71.27%, Test Loss: 0.9661, Test Accuracy: 62.03%\n",
      "Epoch [1494/2500], Train Loss: 0.6911, Train Accuracy: 68.42%, Test Loss: 0.9408, Test Accuracy: 63.29%\n",
      "Epoch [1495/2500], Train Loss: 0.6915, Train Accuracy: 69.84%, Test Loss: 0.9533, Test Accuracy: 63.29%\n",
      "Epoch [1496/2500], Train Loss: 0.6653, Train Accuracy: 69.27%, Test Loss: 0.9618, Test Accuracy: 63.29%\n",
      "Epoch [1497/2500], Train Loss: 0.6819, Train Accuracy: 68.85%, Test Loss: 0.9760, Test Accuracy: 60.76%\n",
      "Epoch [1498/2500], Train Loss: 0.6868, Train Accuracy: 69.70%, Test Loss: 0.9679, Test Accuracy: 62.03%\n",
      "Epoch [1499/2500], Train Loss: 0.6992, Train Accuracy: 69.42%, Test Loss: 0.9786, Test Accuracy: 62.03%\n",
      "Epoch [1500/2500], Train Loss: 0.6911, Train Accuracy: 68.85%, Test Loss: 0.9528, Test Accuracy: 63.29%\n",
      "Epoch [1501/2500], Train Loss: 0.6815, Train Accuracy: 67.57%, Test Loss: 0.9548, Test Accuracy: 60.76%\n",
      "Epoch [1502/2500], Train Loss: 0.6838, Train Accuracy: 69.84%, Test Loss: 0.9767, Test Accuracy: 60.76%\n",
      "Epoch [1503/2500], Train Loss: 0.7053, Train Accuracy: 68.56%, Test Loss: 0.9678, Test Accuracy: 62.03%\n",
      "Epoch [1504/2500], Train Loss: 0.7012, Train Accuracy: 70.13%, Test Loss: 0.9686, Test Accuracy: 60.76%\n",
      "Epoch [1505/2500], Train Loss: 0.6759, Train Accuracy: 70.13%, Test Loss: 0.9843, Test Accuracy: 59.49%\n",
      "Epoch [1506/2500], Train Loss: 0.6795, Train Accuracy: 70.55%, Test Loss: 0.9639, Test Accuracy: 63.29%\n",
      "Epoch [1507/2500], Train Loss: 0.6977, Train Accuracy: 67.85%, Test Loss: 0.9560, Test Accuracy: 63.29%\n",
      "Epoch [1508/2500], Train Loss: 0.6956, Train Accuracy: 67.57%, Test Loss: 0.9736, Test Accuracy: 62.03%\n",
      "Epoch [1509/2500], Train Loss: 0.6967, Train Accuracy: 69.99%, Test Loss: 0.9704, Test Accuracy: 60.76%\n",
      "Epoch [1510/2500], Train Loss: 0.7157, Train Accuracy: 69.99%, Test Loss: 0.9631, Test Accuracy: 63.29%\n",
      "Epoch [1511/2500], Train Loss: 0.7009, Train Accuracy: 68.14%, Test Loss: 0.9563, Test Accuracy: 60.76%\n",
      "Epoch [1512/2500], Train Loss: 0.6911, Train Accuracy: 68.71%, Test Loss: 0.9489, Test Accuracy: 60.76%\n",
      "Epoch [1513/2500], Train Loss: 0.6704, Train Accuracy: 69.13%, Test Loss: 0.9455, Test Accuracy: 63.29%\n",
      "Epoch [1514/2500], Train Loss: 0.6821, Train Accuracy: 69.56%, Test Loss: 0.9676, Test Accuracy: 62.03%\n",
      "Epoch [1515/2500], Train Loss: 0.6611, Train Accuracy: 70.98%, Test Loss: 0.9627, Test Accuracy: 63.29%\n",
      "Epoch [1516/2500], Train Loss: 0.7036, Train Accuracy: 69.42%, Test Loss: 0.9688, Test Accuracy: 62.03%\n",
      "Epoch [1517/2500], Train Loss: 0.6899, Train Accuracy: 69.42%, Test Loss: 0.9676, Test Accuracy: 60.76%\n",
      "Epoch [1518/2500], Train Loss: 0.6921, Train Accuracy: 70.84%, Test Loss: 0.9573, Test Accuracy: 60.76%\n",
      "Epoch [1519/2500], Train Loss: 0.6922, Train Accuracy: 68.99%, Test Loss: 0.9708, Test Accuracy: 62.03%\n",
      "Epoch [1520/2500], Train Loss: 0.6909, Train Accuracy: 70.98%, Test Loss: 0.9735, Test Accuracy: 62.03%\n",
      "Epoch [1521/2500], Train Loss: 0.6777, Train Accuracy: 69.84%, Test Loss: 0.9747, Test Accuracy: 62.03%\n",
      "Epoch [1522/2500], Train Loss: 0.6799, Train Accuracy: 69.70%, Test Loss: 0.9562, Test Accuracy: 63.29%\n",
      "Epoch [1523/2500], Train Loss: 0.6776, Train Accuracy: 69.70%, Test Loss: 0.9678, Test Accuracy: 60.76%\n",
      "Epoch [1524/2500], Train Loss: 0.6630, Train Accuracy: 69.99%, Test Loss: 0.9715, Test Accuracy: 62.03%\n",
      "Epoch [1525/2500], Train Loss: 0.6932, Train Accuracy: 69.56%, Test Loss: 0.9602, Test Accuracy: 64.56%\n",
      "Epoch [1526/2500], Train Loss: 0.6805, Train Accuracy: 68.42%, Test Loss: 0.9740, Test Accuracy: 64.56%\n",
      "Epoch [1527/2500], Train Loss: 0.6810, Train Accuracy: 70.27%, Test Loss: 0.9614, Test Accuracy: 62.03%\n",
      "Epoch [1528/2500], Train Loss: 0.6921, Train Accuracy: 70.55%, Test Loss: 0.9840, Test Accuracy: 60.76%\n",
      "Epoch [1529/2500], Train Loss: 0.6741, Train Accuracy: 69.70%, Test Loss: 0.9876, Test Accuracy: 63.29%\n",
      "Epoch [1530/2500], Train Loss: 0.7167, Train Accuracy: 69.84%, Test Loss: 0.9808, Test Accuracy: 63.29%\n",
      "Epoch [1531/2500], Train Loss: 0.7003, Train Accuracy: 67.99%, Test Loss: 0.9575, Test Accuracy: 63.29%\n",
      "Epoch [1532/2500], Train Loss: 0.6844, Train Accuracy: 70.70%, Test Loss: 0.9708, Test Accuracy: 62.03%\n",
      "Epoch [1533/2500], Train Loss: 0.6733, Train Accuracy: 69.84%, Test Loss: 0.9677, Test Accuracy: 63.29%\n",
      "Epoch [1534/2500], Train Loss: 0.7112, Train Accuracy: 68.71%, Test Loss: 0.9591, Test Accuracy: 60.76%\n",
      "Epoch [1535/2500], Train Loss: 0.6685, Train Accuracy: 72.40%, Test Loss: 0.9464, Test Accuracy: 60.76%\n",
      "Epoch [1536/2500], Train Loss: 0.6841, Train Accuracy: 70.27%, Test Loss: 0.9431, Test Accuracy: 59.49%\n",
      "Epoch [1537/2500], Train Loss: 0.6906, Train Accuracy: 70.41%, Test Loss: 0.9255, Test Accuracy: 59.49%\n",
      "Epoch [1538/2500], Train Loss: 0.6796, Train Accuracy: 69.42%, Test Loss: 0.9964, Test Accuracy: 60.76%\n",
      "Epoch [1539/2500], Train Loss: 0.6931, Train Accuracy: 70.13%, Test Loss: 0.9554, Test Accuracy: 62.03%\n",
      "Epoch [1540/2500], Train Loss: 0.6924, Train Accuracy: 69.56%, Test Loss: 0.9567, Test Accuracy: 62.03%\n",
      "Epoch [1541/2500], Train Loss: 0.6918, Train Accuracy: 70.41%, Test Loss: 0.9687, Test Accuracy: 62.03%\n",
      "Epoch [1542/2500], Train Loss: 0.6817, Train Accuracy: 71.27%, Test Loss: 0.9715, Test Accuracy: 64.56%\n",
      "Epoch [1543/2500], Train Loss: 0.6820, Train Accuracy: 69.99%, Test Loss: 0.9678, Test Accuracy: 60.76%\n",
      "Epoch [1544/2500], Train Loss: 0.6838, Train Accuracy: 71.69%, Test Loss: 0.9974, Test Accuracy: 62.03%\n",
      "Epoch [1545/2500], Train Loss: 0.6718, Train Accuracy: 69.27%, Test Loss: 0.9560, Test Accuracy: 62.03%\n",
      "Epoch [1546/2500], Train Loss: 0.7049, Train Accuracy: 68.28%, Test Loss: 0.9823, Test Accuracy: 62.03%\n",
      "Epoch [1547/2500], Train Loss: 0.6857, Train Accuracy: 70.41%, Test Loss: 0.9669, Test Accuracy: 60.76%\n",
      "Epoch [1548/2500], Train Loss: 0.6947, Train Accuracy: 69.84%, Test Loss: 0.9703, Test Accuracy: 60.76%\n",
      "Epoch [1549/2500], Train Loss: 0.6917, Train Accuracy: 67.85%, Test Loss: 0.9595, Test Accuracy: 60.76%\n",
      "Epoch [1550/2500], Train Loss: 0.6984, Train Accuracy: 69.42%, Test Loss: 0.9854, Test Accuracy: 63.29%\n",
      "Epoch [1551/2500], Train Loss: 0.6845, Train Accuracy: 68.28%, Test Loss: 0.9904, Test Accuracy: 62.03%\n",
      "Epoch [1552/2500], Train Loss: 0.6822, Train Accuracy: 69.42%, Test Loss: 0.9986, Test Accuracy: 62.03%\n",
      "Epoch [1553/2500], Train Loss: 0.6885, Train Accuracy: 69.84%, Test Loss: 1.0073, Test Accuracy: 60.76%\n",
      "Epoch [1554/2500], Train Loss: 0.6720, Train Accuracy: 71.12%, Test Loss: 1.0328, Test Accuracy: 62.03%\n",
      "Epoch [1555/2500], Train Loss: 0.6841, Train Accuracy: 70.84%, Test Loss: 0.9743, Test Accuracy: 60.76%\n",
      "Epoch [1556/2500], Train Loss: 0.6811, Train Accuracy: 70.84%, Test Loss: 0.9789, Test Accuracy: 60.76%\n",
      "Epoch [1557/2500], Train Loss: 0.6867, Train Accuracy: 69.84%, Test Loss: 0.9883, Test Accuracy: 62.03%\n",
      "Epoch [1558/2500], Train Loss: 0.6697, Train Accuracy: 71.55%, Test Loss: 0.9930, Test Accuracy: 60.76%\n",
      "Epoch [1559/2500], Train Loss: 0.6814, Train Accuracy: 69.84%, Test Loss: 0.9828, Test Accuracy: 63.29%\n",
      "Epoch [1560/2500], Train Loss: 0.6767, Train Accuracy: 70.84%, Test Loss: 0.9811, Test Accuracy: 62.03%\n",
      "Epoch [1561/2500], Train Loss: 0.6675, Train Accuracy: 70.27%, Test Loss: 0.9579, Test Accuracy: 62.03%\n",
      "Epoch [1562/2500], Train Loss: 0.6727, Train Accuracy: 71.69%, Test Loss: 0.9794, Test Accuracy: 62.03%\n",
      "Epoch [1563/2500], Train Loss: 0.6782, Train Accuracy: 70.13%, Test Loss: 1.0043, Test Accuracy: 62.03%\n",
      "Epoch [1564/2500], Train Loss: 0.6900, Train Accuracy: 67.85%, Test Loss: 0.9703, Test Accuracy: 62.03%\n",
      "Epoch [1565/2500], Train Loss: 0.6818, Train Accuracy: 72.26%, Test Loss: 0.9805, Test Accuracy: 59.49%\n",
      "Epoch [1566/2500], Train Loss: 0.6724, Train Accuracy: 69.56%, Test Loss: 0.9808, Test Accuracy: 60.76%\n",
      "Epoch [1567/2500], Train Loss: 0.7097, Train Accuracy: 70.41%, Test Loss: 0.9784, Test Accuracy: 60.76%\n",
      "Epoch [1568/2500], Train Loss: 0.6807, Train Accuracy: 70.41%, Test Loss: 0.9671, Test Accuracy: 63.29%\n",
      "Epoch [1569/2500], Train Loss: 0.6852, Train Accuracy: 69.70%, Test Loss: 0.9774, Test Accuracy: 58.23%\n",
      "Epoch [1570/2500], Train Loss: 0.6848, Train Accuracy: 69.27%, Test Loss: 0.9859, Test Accuracy: 64.56%\n",
      "Epoch [1571/2500], Train Loss: 0.6810, Train Accuracy: 69.27%, Test Loss: 1.0202, Test Accuracy: 60.76%\n",
      "Epoch [1572/2500], Train Loss: 0.6908, Train Accuracy: 70.13%, Test Loss: 0.9856, Test Accuracy: 62.03%\n",
      "Epoch [1573/2500], Train Loss: 0.6843, Train Accuracy: 71.27%, Test Loss: 1.0485, Test Accuracy: 59.49%\n",
      "Epoch [1574/2500], Train Loss: 0.6703, Train Accuracy: 70.27%, Test Loss: 1.0251, Test Accuracy: 59.49%\n",
      "Epoch [1575/2500], Train Loss: 0.6873, Train Accuracy: 70.27%, Test Loss: 0.9971, Test Accuracy: 60.76%\n",
      "Epoch [1576/2500], Train Loss: 0.6987, Train Accuracy: 67.71%, Test Loss: 0.9975, Test Accuracy: 60.76%\n",
      "Epoch [1577/2500], Train Loss: 0.6797, Train Accuracy: 68.42%, Test Loss: 0.9912, Test Accuracy: 59.49%\n",
      "Epoch [1578/2500], Train Loss: 0.6837, Train Accuracy: 71.27%, Test Loss: 0.9931, Test Accuracy: 60.76%\n",
      "Epoch [1579/2500], Train Loss: 0.6757, Train Accuracy: 71.55%, Test Loss: 0.9751, Test Accuracy: 58.23%\n",
      "Epoch [1580/2500], Train Loss: 0.6803, Train Accuracy: 69.99%, Test Loss: 0.9804, Test Accuracy: 60.76%\n",
      "Epoch [1581/2500], Train Loss: 0.6896, Train Accuracy: 68.99%, Test Loss: 0.9589, Test Accuracy: 58.23%\n",
      "Epoch [1582/2500], Train Loss: 0.6834, Train Accuracy: 69.99%, Test Loss: 0.9590, Test Accuracy: 60.76%\n",
      "Epoch [1583/2500], Train Loss: 0.6870, Train Accuracy: 68.42%, Test Loss: 0.9864, Test Accuracy: 60.76%\n",
      "Epoch [1584/2500], Train Loss: 0.6845, Train Accuracy: 69.84%, Test Loss: 0.9941, Test Accuracy: 62.03%\n",
      "Epoch [1585/2500], Train Loss: 0.6733, Train Accuracy: 69.84%, Test Loss: 0.9721, Test Accuracy: 60.76%\n",
      "Epoch [1586/2500], Train Loss: 0.6934, Train Accuracy: 68.85%, Test Loss: 0.9779, Test Accuracy: 60.76%\n",
      "Epoch [1587/2500], Train Loss: 0.6937, Train Accuracy: 69.27%, Test Loss: 0.9760, Test Accuracy: 62.03%\n",
      "Epoch [1588/2500], Train Loss: 0.6959, Train Accuracy: 68.85%, Test Loss: 0.9977, Test Accuracy: 59.49%\n",
      "Epoch [1589/2500], Train Loss: 0.6989, Train Accuracy: 70.13%, Test Loss: 1.0007, Test Accuracy: 62.03%\n",
      "Epoch [1590/2500], Train Loss: 0.6985, Train Accuracy: 68.28%, Test Loss: 0.9973, Test Accuracy: 60.76%\n",
      "Epoch [1591/2500], Train Loss: 0.6850, Train Accuracy: 69.13%, Test Loss: 0.9877, Test Accuracy: 60.76%\n",
      "Epoch [1592/2500], Train Loss: 0.6718, Train Accuracy: 69.56%, Test Loss: 0.9765, Test Accuracy: 59.49%\n",
      "Epoch [1593/2500], Train Loss: 0.6863, Train Accuracy: 69.42%, Test Loss: 0.9732, Test Accuracy: 62.03%\n",
      "Epoch [1594/2500], Train Loss: 0.7115, Train Accuracy: 69.42%, Test Loss: 0.9750, Test Accuracy: 60.76%\n",
      "Epoch [1595/2500], Train Loss: 0.6674, Train Accuracy: 69.42%, Test Loss: 0.9796, Test Accuracy: 62.03%\n",
      "Epoch [1596/2500], Train Loss: 0.6819, Train Accuracy: 69.56%, Test Loss: 0.9616, Test Accuracy: 64.56%\n",
      "Epoch [1597/2500], Train Loss: 0.6670, Train Accuracy: 68.85%, Test Loss: 0.9941, Test Accuracy: 63.29%\n",
      "Epoch [1598/2500], Train Loss: 0.6578, Train Accuracy: 70.98%, Test Loss: 1.0076, Test Accuracy: 59.49%\n",
      "Epoch [1599/2500], Train Loss: 0.6599, Train Accuracy: 71.83%, Test Loss: 1.0196, Test Accuracy: 59.49%\n",
      "Epoch [1600/2500], Train Loss: 0.6815, Train Accuracy: 69.99%, Test Loss: 0.9956, Test Accuracy: 59.49%\n",
      "Epoch [1601/2500], Train Loss: 0.6608, Train Accuracy: 70.13%, Test Loss: 0.9958, Test Accuracy: 60.76%\n",
      "Epoch [1602/2500], Train Loss: 0.6765, Train Accuracy: 69.42%, Test Loss: 0.9669, Test Accuracy: 60.76%\n",
      "Epoch [1603/2500], Train Loss: 0.6702, Train Accuracy: 70.98%, Test Loss: 1.0115, Test Accuracy: 62.03%\n",
      "Epoch [1604/2500], Train Loss: 0.6543, Train Accuracy: 72.97%, Test Loss: 1.0115, Test Accuracy: 60.76%\n",
      "Epoch [1605/2500], Train Loss: 0.6983, Train Accuracy: 68.71%, Test Loss: 0.9923, Test Accuracy: 62.03%\n",
      "Epoch [1606/2500], Train Loss: 0.7024, Train Accuracy: 67.99%, Test Loss: 1.0179, Test Accuracy: 60.76%\n",
      "Epoch [1607/2500], Train Loss: 0.6777, Train Accuracy: 70.98%, Test Loss: 1.0089, Test Accuracy: 60.76%\n",
      "Epoch [1608/2500], Train Loss: 0.6695, Train Accuracy: 72.26%, Test Loss: 0.9942, Test Accuracy: 59.49%\n",
      "Epoch [1609/2500], Train Loss: 0.6675, Train Accuracy: 70.84%, Test Loss: 0.9944, Test Accuracy: 62.03%\n",
      "Epoch [1610/2500], Train Loss: 0.6560, Train Accuracy: 72.55%, Test Loss: 0.9532, Test Accuracy: 62.03%\n",
      "Epoch [1611/2500], Train Loss: 0.6737, Train Accuracy: 71.12%, Test Loss: 0.9627, Test Accuracy: 60.76%\n",
      "Epoch [1612/2500], Train Loss: 0.6611, Train Accuracy: 68.85%, Test Loss: 0.9673, Test Accuracy: 60.76%\n",
      "Epoch [1613/2500], Train Loss: 0.6825, Train Accuracy: 68.71%, Test Loss: 0.9900, Test Accuracy: 59.49%\n",
      "Epoch [1614/2500], Train Loss: 0.6696, Train Accuracy: 68.99%, Test Loss: 0.9746, Test Accuracy: 60.76%\n",
      "Epoch [1615/2500], Train Loss: 0.6819, Train Accuracy: 69.99%, Test Loss: 0.9764, Test Accuracy: 60.76%\n",
      "Epoch [1616/2500], Train Loss: 0.6559, Train Accuracy: 69.99%, Test Loss: 0.9969, Test Accuracy: 63.29%\n",
      "Epoch [1617/2500], Train Loss: 0.6870, Train Accuracy: 69.84%, Test Loss: 0.9895, Test Accuracy: 60.76%\n",
      "Epoch [1618/2500], Train Loss: 0.6898, Train Accuracy: 69.42%, Test Loss: 0.9857, Test Accuracy: 62.03%\n",
      "Epoch [1619/2500], Train Loss: 0.6898, Train Accuracy: 69.42%, Test Loss: 0.9916, Test Accuracy: 60.76%\n",
      "Epoch [1620/2500], Train Loss: 0.6870, Train Accuracy: 69.99%, Test Loss: 0.9992, Test Accuracy: 59.49%\n",
      "Epoch [1621/2500], Train Loss: 0.6853, Train Accuracy: 69.42%, Test Loss: 0.9918, Test Accuracy: 60.76%\n",
      "Epoch [1622/2500], Train Loss: 0.6853, Train Accuracy: 68.71%, Test Loss: 0.9686, Test Accuracy: 60.76%\n",
      "Epoch [1623/2500], Train Loss: 0.6825, Train Accuracy: 68.28%, Test Loss: 0.9630, Test Accuracy: 62.03%\n",
      "Epoch [1624/2500], Train Loss: 0.6704, Train Accuracy: 68.42%, Test Loss: 0.9637, Test Accuracy: 60.76%\n",
      "Epoch [1625/2500], Train Loss: 0.6730, Train Accuracy: 70.84%, Test Loss: 0.9697, Test Accuracy: 62.03%\n",
      "Epoch [1626/2500], Train Loss: 0.6881, Train Accuracy: 69.56%, Test Loss: 0.9651, Test Accuracy: 60.76%\n",
      "Epoch [1627/2500], Train Loss: 0.6842, Train Accuracy: 68.56%, Test Loss: 0.9655, Test Accuracy: 60.76%\n",
      "Epoch [1628/2500], Train Loss: 0.6527, Train Accuracy: 71.12%, Test Loss: 0.9569, Test Accuracy: 60.76%\n",
      "Epoch [1629/2500], Train Loss: 0.6921, Train Accuracy: 70.84%, Test Loss: 0.9573, Test Accuracy: 62.03%\n",
      "Epoch [1630/2500], Train Loss: 0.6888, Train Accuracy: 70.84%, Test Loss: 0.9462, Test Accuracy: 59.49%\n",
      "Epoch [1631/2500], Train Loss: 0.6729, Train Accuracy: 69.42%, Test Loss: 0.9538, Test Accuracy: 60.76%\n",
      "Epoch [1632/2500], Train Loss: 0.6816, Train Accuracy: 70.84%, Test Loss: 0.9448, Test Accuracy: 59.49%\n",
      "Epoch [1633/2500], Train Loss: 0.6637, Train Accuracy: 70.13%, Test Loss: 0.9458, Test Accuracy: 60.76%\n",
      "Epoch [1634/2500], Train Loss: 0.6811, Train Accuracy: 71.41%, Test Loss: 0.9574, Test Accuracy: 60.76%\n",
      "Epoch [1635/2500], Train Loss: 0.6846, Train Accuracy: 69.42%, Test Loss: 0.9647, Test Accuracy: 59.49%\n",
      "Epoch [1636/2500], Train Loss: 0.6610, Train Accuracy: 70.41%, Test Loss: 0.9997, Test Accuracy: 58.23%\n",
      "Epoch [1637/2500], Train Loss: 0.6663, Train Accuracy: 71.69%, Test Loss: 1.0169, Test Accuracy: 58.23%\n",
      "Epoch [1638/2500], Train Loss: 0.6760, Train Accuracy: 69.13%, Test Loss: 0.9656, Test Accuracy: 60.76%\n",
      "Epoch [1639/2500], Train Loss: 0.6518, Train Accuracy: 69.84%, Test Loss: 0.9825, Test Accuracy: 60.76%\n",
      "Epoch [1640/2500], Train Loss: 0.6701, Train Accuracy: 69.99%, Test Loss: 1.0122, Test Accuracy: 59.49%\n",
      "Epoch [1641/2500], Train Loss: 0.6763, Train Accuracy: 70.41%, Test Loss: 1.0124, Test Accuracy: 59.49%\n",
      "Epoch [1642/2500], Train Loss: 0.6676, Train Accuracy: 70.55%, Test Loss: 0.9836, Test Accuracy: 59.49%\n",
      "Epoch [1643/2500], Train Loss: 0.6949, Train Accuracy: 68.14%, Test Loss: 1.0343, Test Accuracy: 56.96%\n",
      "Epoch [1644/2500], Train Loss: 0.6803, Train Accuracy: 68.71%, Test Loss: 1.0050, Test Accuracy: 60.76%\n",
      "Epoch [1645/2500], Train Loss: 0.6658, Train Accuracy: 70.84%, Test Loss: 1.0050, Test Accuracy: 60.76%\n",
      "Epoch [1646/2500], Train Loss: 0.6798, Train Accuracy: 70.98%, Test Loss: 0.9846, Test Accuracy: 60.76%\n",
      "Epoch [1647/2500], Train Loss: 0.6895, Train Accuracy: 70.70%, Test Loss: 0.9911, Test Accuracy: 60.76%\n",
      "Epoch [1648/2500], Train Loss: 0.6928, Train Accuracy: 68.71%, Test Loss: 0.9901, Test Accuracy: 58.23%\n",
      "Epoch [1649/2500], Train Loss: 0.6708, Train Accuracy: 70.27%, Test Loss: 1.0039, Test Accuracy: 56.96%\n",
      "Epoch [1650/2500], Train Loss: 0.6929, Train Accuracy: 69.70%, Test Loss: 0.9997, Test Accuracy: 59.49%\n",
      "Epoch [1651/2500], Train Loss: 0.6892, Train Accuracy: 68.99%, Test Loss: 1.0072, Test Accuracy: 60.76%\n",
      "Epoch [1652/2500], Train Loss: 0.6970, Train Accuracy: 69.56%, Test Loss: 0.9707, Test Accuracy: 62.03%\n",
      "Epoch [1653/2500], Train Loss: 0.6950, Train Accuracy: 69.84%, Test Loss: 0.9905, Test Accuracy: 60.76%\n",
      "Epoch [1654/2500], Train Loss: 0.6827, Train Accuracy: 68.56%, Test Loss: 0.9714, Test Accuracy: 60.76%\n",
      "Epoch [1655/2500], Train Loss: 0.6770, Train Accuracy: 69.56%, Test Loss: 1.0021, Test Accuracy: 59.49%\n",
      "Epoch [1656/2500], Train Loss: 0.6897, Train Accuracy: 70.13%, Test Loss: 0.9900, Test Accuracy: 60.76%\n",
      "Epoch [1657/2500], Train Loss: 0.6498, Train Accuracy: 71.55%, Test Loss: 0.9899, Test Accuracy: 62.03%\n",
      "Epoch [1658/2500], Train Loss: 0.6650, Train Accuracy: 69.99%, Test Loss: 0.9929, Test Accuracy: 62.03%\n",
      "Epoch [1659/2500], Train Loss: 0.6547, Train Accuracy: 70.84%, Test Loss: 1.0011, Test Accuracy: 60.76%\n",
      "Epoch [1660/2500], Train Loss: 0.6900, Train Accuracy: 68.71%, Test Loss: 1.0025, Test Accuracy: 59.49%\n",
      "Epoch [1661/2500], Train Loss: 0.6607, Train Accuracy: 71.69%, Test Loss: 1.0125, Test Accuracy: 60.76%\n",
      "Epoch [1662/2500], Train Loss: 0.6716, Train Accuracy: 69.84%, Test Loss: 0.9926, Test Accuracy: 59.49%\n",
      "Epoch [1663/2500], Train Loss: 0.6536, Train Accuracy: 70.84%, Test Loss: 0.9823, Test Accuracy: 59.49%\n",
      "Epoch [1664/2500], Train Loss: 0.6986, Train Accuracy: 69.84%, Test Loss: 1.0199, Test Accuracy: 56.96%\n",
      "Epoch [1665/2500], Train Loss: 0.6644, Train Accuracy: 70.41%, Test Loss: 0.9774, Test Accuracy: 60.76%\n",
      "Epoch [1666/2500], Train Loss: 0.6696, Train Accuracy: 71.12%, Test Loss: 0.9846, Test Accuracy: 59.49%\n",
      "Epoch [1667/2500], Train Loss: 0.6770, Train Accuracy: 69.99%, Test Loss: 1.0046, Test Accuracy: 59.49%\n",
      "Epoch [1668/2500], Train Loss: 0.6594, Train Accuracy: 70.27%, Test Loss: 1.0112, Test Accuracy: 59.49%\n",
      "Epoch [1669/2500], Train Loss: 0.6573, Train Accuracy: 72.55%, Test Loss: 0.9992, Test Accuracy: 62.03%\n",
      "Epoch [1670/2500], Train Loss: 0.7099, Train Accuracy: 71.41%, Test Loss: 0.9919, Test Accuracy: 62.03%\n",
      "Epoch [1671/2500], Train Loss: 0.6669, Train Accuracy: 69.56%, Test Loss: 0.9683, Test Accuracy: 63.29%\n",
      "Epoch [1672/2500], Train Loss: 0.6659, Train Accuracy: 71.27%, Test Loss: 0.9901, Test Accuracy: 62.03%\n",
      "Epoch [1673/2500], Train Loss: 0.6741, Train Accuracy: 70.27%, Test Loss: 1.0258, Test Accuracy: 59.49%\n",
      "Epoch [1674/2500], Train Loss: 0.6615, Train Accuracy: 71.41%, Test Loss: 1.0006, Test Accuracy: 62.03%\n",
      "Epoch [1675/2500], Train Loss: 0.6780, Train Accuracy: 71.55%, Test Loss: 0.9688, Test Accuracy: 62.03%\n",
      "Epoch [1676/2500], Train Loss: 0.6595, Train Accuracy: 70.98%, Test Loss: 0.9885, Test Accuracy: 60.76%\n",
      "Epoch [1677/2500], Train Loss: 0.6670, Train Accuracy: 71.27%, Test Loss: 0.9701, Test Accuracy: 60.76%\n",
      "Epoch [1678/2500], Train Loss: 0.6854, Train Accuracy: 70.55%, Test Loss: 0.9895, Test Accuracy: 60.76%\n",
      "Epoch [1679/2500], Train Loss: 0.6504, Train Accuracy: 70.41%, Test Loss: 0.9806, Test Accuracy: 63.29%\n",
      "Epoch [1680/2500], Train Loss: 0.6649, Train Accuracy: 70.13%, Test Loss: 0.9955, Test Accuracy: 63.29%\n",
      "Epoch [1681/2500], Train Loss: 0.6598, Train Accuracy: 70.41%, Test Loss: 0.9806, Test Accuracy: 62.03%\n",
      "Epoch [1682/2500], Train Loss: 0.6664, Train Accuracy: 70.13%, Test Loss: 0.9853, Test Accuracy: 62.03%\n",
      "Epoch [1683/2500], Train Loss: 0.6695, Train Accuracy: 70.41%, Test Loss: 0.9898, Test Accuracy: 63.29%\n",
      "Epoch [1684/2500], Train Loss: 0.6538, Train Accuracy: 71.98%, Test Loss: 0.9662, Test Accuracy: 62.03%\n",
      "Epoch [1685/2500], Train Loss: 0.6529, Train Accuracy: 70.84%, Test Loss: 0.9943, Test Accuracy: 60.76%\n",
      "Epoch [1686/2500], Train Loss: 0.6828, Train Accuracy: 70.55%, Test Loss: 0.9929, Test Accuracy: 60.76%\n",
      "Epoch [1687/2500], Train Loss: 0.6713, Train Accuracy: 70.98%, Test Loss: 0.9993, Test Accuracy: 63.29%\n",
      "Epoch [1688/2500], Train Loss: 0.6858, Train Accuracy: 68.14%, Test Loss: 1.0009, Test Accuracy: 59.49%\n",
      "Epoch [1689/2500], Train Loss: 0.6627, Train Accuracy: 71.69%, Test Loss: 0.9822, Test Accuracy: 63.29%\n",
      "Epoch [1690/2500], Train Loss: 0.6716, Train Accuracy: 70.70%, Test Loss: 0.9790, Test Accuracy: 62.03%\n",
      "Epoch [1691/2500], Train Loss: 0.6594, Train Accuracy: 70.70%, Test Loss: 0.9779, Test Accuracy: 60.76%\n",
      "Epoch [1692/2500], Train Loss: 0.6696, Train Accuracy: 69.84%, Test Loss: 1.0070, Test Accuracy: 59.49%\n",
      "Epoch [1693/2500], Train Loss: 0.6803, Train Accuracy: 69.99%, Test Loss: 1.0054, Test Accuracy: 59.49%\n",
      "Epoch [1694/2500], Train Loss: 0.6890, Train Accuracy: 68.71%, Test Loss: 0.9846, Test Accuracy: 59.49%\n",
      "Epoch [1695/2500], Train Loss: 0.6526, Train Accuracy: 71.27%, Test Loss: 1.0176, Test Accuracy: 58.23%\n",
      "Epoch [1696/2500], Train Loss: 0.6588, Train Accuracy: 69.70%, Test Loss: 1.0441, Test Accuracy: 60.76%\n",
      "Epoch [1697/2500], Train Loss: 0.6659, Train Accuracy: 70.27%, Test Loss: 1.0234, Test Accuracy: 58.23%\n",
      "Epoch [1698/2500], Train Loss: 0.6866, Train Accuracy: 69.42%, Test Loss: 1.0323, Test Accuracy: 59.49%\n",
      "Epoch [1699/2500], Train Loss: 0.6758, Train Accuracy: 68.99%, Test Loss: 1.0140, Test Accuracy: 56.96%\n",
      "Epoch [1700/2500], Train Loss: 0.6782, Train Accuracy: 70.27%, Test Loss: 1.0365, Test Accuracy: 60.76%\n",
      "Epoch [1701/2500], Train Loss: 0.6851, Train Accuracy: 70.84%, Test Loss: 1.0064, Test Accuracy: 60.76%\n",
      "Epoch [1702/2500], Train Loss: 0.6926, Train Accuracy: 69.99%, Test Loss: 1.0106, Test Accuracy: 58.23%\n",
      "Epoch [1703/2500], Train Loss: 0.6705, Train Accuracy: 69.70%, Test Loss: 1.0160, Test Accuracy: 58.23%\n",
      "Epoch [1704/2500], Train Loss: 0.6664, Train Accuracy: 69.42%, Test Loss: 1.0411, Test Accuracy: 56.96%\n",
      "Epoch [1705/2500], Train Loss: 0.6777, Train Accuracy: 69.56%, Test Loss: 1.0102, Test Accuracy: 59.49%\n",
      "Epoch [1706/2500], Train Loss: 0.6757, Train Accuracy: 69.70%, Test Loss: 1.0153, Test Accuracy: 60.76%\n",
      "Epoch [1707/2500], Train Loss: 0.6822, Train Accuracy: 68.71%, Test Loss: 0.9849, Test Accuracy: 59.49%\n",
      "Epoch [1708/2500], Train Loss: 0.6713, Train Accuracy: 71.41%, Test Loss: 0.9832, Test Accuracy: 59.49%\n",
      "Epoch [1709/2500], Train Loss: 0.6743, Train Accuracy: 70.13%, Test Loss: 0.9619, Test Accuracy: 59.49%\n",
      "Epoch [1710/2500], Train Loss: 0.6547, Train Accuracy: 71.41%, Test Loss: 0.9577, Test Accuracy: 59.49%\n",
      "Epoch [1711/2500], Train Loss: 0.6510, Train Accuracy: 71.69%, Test Loss: 0.9570, Test Accuracy: 63.29%\n",
      "Epoch [1712/2500], Train Loss: 0.6764, Train Accuracy: 70.84%, Test Loss: 0.9665, Test Accuracy: 62.03%\n",
      "Epoch [1713/2500], Train Loss: 0.6757, Train Accuracy: 69.27%, Test Loss: 0.9619, Test Accuracy: 60.76%\n",
      "Epoch [1714/2500], Train Loss: 0.6686, Train Accuracy: 71.12%, Test Loss: 0.9452, Test Accuracy: 63.29%\n",
      "Epoch [1715/2500], Train Loss: 0.6766, Train Accuracy: 69.56%, Test Loss: 0.9805, Test Accuracy: 59.49%\n",
      "Epoch [1716/2500], Train Loss: 0.6601, Train Accuracy: 71.41%, Test Loss: 0.9560, Test Accuracy: 60.76%\n",
      "Epoch [1717/2500], Train Loss: 0.6691, Train Accuracy: 71.12%, Test Loss: 0.9757, Test Accuracy: 60.76%\n",
      "Epoch [1718/2500], Train Loss: 0.6809, Train Accuracy: 69.70%, Test Loss: 0.9655, Test Accuracy: 59.49%\n",
      "Epoch [1719/2500], Train Loss: 0.6457, Train Accuracy: 69.99%, Test Loss: 0.9567, Test Accuracy: 59.49%\n",
      "Epoch [1720/2500], Train Loss: 0.6770, Train Accuracy: 69.84%, Test Loss: 0.9675, Test Accuracy: 59.49%\n",
      "Epoch [1721/2500], Train Loss: 0.6691, Train Accuracy: 70.13%, Test Loss: 0.9715, Test Accuracy: 59.49%\n",
      "Epoch [1722/2500], Train Loss: 0.6545, Train Accuracy: 70.41%, Test Loss: 0.9671, Test Accuracy: 60.76%\n",
      "Epoch [1723/2500], Train Loss: 0.6782, Train Accuracy: 68.99%, Test Loss: 0.9899, Test Accuracy: 60.76%\n",
      "Epoch [1724/2500], Train Loss: 0.6617, Train Accuracy: 70.70%, Test Loss: 0.9555, Test Accuracy: 58.23%\n",
      "Epoch [1725/2500], Train Loss: 0.6545, Train Accuracy: 71.98%, Test Loss: 0.9528, Test Accuracy: 59.49%\n",
      "Epoch [1726/2500], Train Loss: 0.6754, Train Accuracy: 69.27%, Test Loss: 0.9819, Test Accuracy: 62.03%\n",
      "Epoch [1727/2500], Train Loss: 0.6746, Train Accuracy: 69.70%, Test Loss: 1.0032, Test Accuracy: 62.03%\n",
      "Epoch [1728/2500], Train Loss: 0.6660, Train Accuracy: 70.98%, Test Loss: 1.0161, Test Accuracy: 56.96%\n",
      "Epoch [1729/2500], Train Loss: 0.6828, Train Accuracy: 70.13%, Test Loss: 0.9929, Test Accuracy: 59.49%\n",
      "Epoch [1730/2500], Train Loss: 0.6817, Train Accuracy: 72.26%, Test Loss: 1.0081, Test Accuracy: 59.49%\n",
      "Epoch [1731/2500], Train Loss: 0.6433, Train Accuracy: 71.69%, Test Loss: 1.0223, Test Accuracy: 58.23%\n",
      "Epoch [1732/2500], Train Loss: 0.6541, Train Accuracy: 69.84%, Test Loss: 1.0136, Test Accuracy: 59.49%\n",
      "Epoch [1733/2500], Train Loss: 0.6846, Train Accuracy: 69.99%, Test Loss: 0.9937, Test Accuracy: 60.76%\n",
      "Epoch [1734/2500], Train Loss: 0.6691, Train Accuracy: 70.55%, Test Loss: 1.0228, Test Accuracy: 59.49%\n",
      "Epoch [1735/2500], Train Loss: 0.6732, Train Accuracy: 68.99%, Test Loss: 0.9610, Test Accuracy: 59.49%\n",
      "Epoch [1736/2500], Train Loss: 0.6619, Train Accuracy: 72.55%, Test Loss: 1.0001, Test Accuracy: 63.29%\n",
      "Epoch [1737/2500], Train Loss: 0.6824, Train Accuracy: 69.13%, Test Loss: 0.9831, Test Accuracy: 60.76%\n",
      "Epoch [1738/2500], Train Loss: 0.6626, Train Accuracy: 69.99%, Test Loss: 0.9627, Test Accuracy: 59.49%\n",
      "Epoch [1739/2500], Train Loss: 0.6771, Train Accuracy: 70.84%, Test Loss: 0.9692, Test Accuracy: 59.49%\n",
      "Epoch [1740/2500], Train Loss: 0.6795, Train Accuracy: 68.99%, Test Loss: 0.9931, Test Accuracy: 59.49%\n",
      "Epoch [1741/2500], Train Loss: 0.6692, Train Accuracy: 70.98%, Test Loss: 0.9889, Test Accuracy: 59.49%\n",
      "Epoch [1742/2500], Train Loss: 0.6740, Train Accuracy: 69.99%, Test Loss: 1.0041, Test Accuracy: 58.23%\n",
      "Epoch [1743/2500], Train Loss: 0.6354, Train Accuracy: 71.83%, Test Loss: 1.0167, Test Accuracy: 59.49%\n",
      "Epoch [1744/2500], Train Loss: 0.6602, Train Accuracy: 71.98%, Test Loss: 0.9925, Test Accuracy: 60.76%\n",
      "Epoch [1745/2500], Train Loss: 0.6696, Train Accuracy: 69.56%, Test Loss: 0.9631, Test Accuracy: 58.23%\n",
      "Epoch [1746/2500], Train Loss: 0.6767, Train Accuracy: 69.13%, Test Loss: 0.9665, Test Accuracy: 60.76%\n",
      "Epoch [1747/2500], Train Loss: 0.6762, Train Accuracy: 69.84%, Test Loss: 0.9612, Test Accuracy: 59.49%\n",
      "Epoch [1748/2500], Train Loss: 0.6605, Train Accuracy: 69.84%, Test Loss: 0.9451, Test Accuracy: 59.49%\n",
      "Epoch [1749/2500], Train Loss: 0.6738, Train Accuracy: 71.41%, Test Loss: 0.9688, Test Accuracy: 58.23%\n",
      "Epoch [1750/2500], Train Loss: 0.6577, Train Accuracy: 70.41%, Test Loss: 1.0012, Test Accuracy: 58.23%\n",
      "Epoch [1751/2500], Train Loss: 0.6678, Train Accuracy: 69.99%, Test Loss: 0.9925, Test Accuracy: 59.49%\n",
      "Epoch [1752/2500], Train Loss: 0.6769, Train Accuracy: 70.70%, Test Loss: 1.0093, Test Accuracy: 59.49%\n",
      "Epoch [1753/2500], Train Loss: 0.6542, Train Accuracy: 71.27%, Test Loss: 0.9815, Test Accuracy: 60.76%\n",
      "Epoch [1754/2500], Train Loss: 0.6659, Train Accuracy: 71.69%, Test Loss: 1.0039, Test Accuracy: 58.23%\n",
      "Epoch [1755/2500], Train Loss: 0.6486, Train Accuracy: 73.54%, Test Loss: 0.9904, Test Accuracy: 56.96%\n",
      "Epoch [1756/2500], Train Loss: 0.6605, Train Accuracy: 71.55%, Test Loss: 0.9888, Test Accuracy: 55.70%\n",
      "Epoch [1757/2500], Train Loss: 0.6745, Train Accuracy: 70.27%, Test Loss: 1.0304, Test Accuracy: 56.96%\n",
      "Epoch [1758/2500], Train Loss: 0.6780, Train Accuracy: 68.85%, Test Loss: 1.0139, Test Accuracy: 58.23%\n",
      "Epoch [1759/2500], Train Loss: 0.6495, Train Accuracy: 71.27%, Test Loss: 0.9742, Test Accuracy: 60.76%\n",
      "Epoch [1760/2500], Train Loss: 0.6702, Train Accuracy: 71.12%, Test Loss: 1.0152, Test Accuracy: 58.23%\n",
      "Epoch [1761/2500], Train Loss: 0.6620, Train Accuracy: 71.12%, Test Loss: 1.0597, Test Accuracy: 58.23%\n",
      "Epoch [1762/2500], Train Loss: 0.6652, Train Accuracy: 69.56%, Test Loss: 1.0833, Test Accuracy: 56.96%\n",
      "Epoch [1763/2500], Train Loss: 0.6718, Train Accuracy: 68.99%, Test Loss: 0.9526, Test Accuracy: 58.23%\n",
      "Epoch [1764/2500], Train Loss: 0.6475, Train Accuracy: 73.54%, Test Loss: 0.9715, Test Accuracy: 59.49%\n",
      "Epoch [1765/2500], Train Loss: 0.6496, Train Accuracy: 71.98%, Test Loss: 1.0196, Test Accuracy: 55.70%\n",
      "Epoch [1766/2500], Train Loss: 0.6634, Train Accuracy: 71.12%, Test Loss: 1.0161, Test Accuracy: 56.96%\n",
      "Epoch [1767/2500], Train Loss: 0.6577, Train Accuracy: 69.27%, Test Loss: 1.0692, Test Accuracy: 58.23%\n",
      "Epoch [1768/2500], Train Loss: 0.6762, Train Accuracy: 67.99%, Test Loss: 1.0562, Test Accuracy: 56.96%\n",
      "Epoch [1769/2500], Train Loss: 0.6651, Train Accuracy: 71.69%, Test Loss: 1.0401, Test Accuracy: 55.70%\n",
      "Epoch [1770/2500], Train Loss: 0.6503, Train Accuracy: 71.55%, Test Loss: 1.0369, Test Accuracy: 58.23%\n",
      "Epoch [1771/2500], Train Loss: 0.6761, Train Accuracy: 69.70%, Test Loss: 0.9992, Test Accuracy: 58.23%\n",
      "Epoch [1772/2500], Train Loss: 0.6639, Train Accuracy: 72.26%, Test Loss: 0.9943, Test Accuracy: 56.96%\n",
      "Epoch [1773/2500], Train Loss: 0.7040, Train Accuracy: 70.41%, Test Loss: 0.9843, Test Accuracy: 56.96%\n",
      "Epoch [1774/2500], Train Loss: 0.6906, Train Accuracy: 69.56%, Test Loss: 1.0357, Test Accuracy: 54.43%\n",
      "Epoch [1775/2500], Train Loss: 0.6590, Train Accuracy: 70.70%, Test Loss: 1.0763, Test Accuracy: 56.96%\n",
      "Epoch [1776/2500], Train Loss: 0.6756, Train Accuracy: 69.42%, Test Loss: 1.0676, Test Accuracy: 58.23%\n",
      "Epoch [1777/2500], Train Loss: 0.6541, Train Accuracy: 71.83%, Test Loss: 1.0224, Test Accuracy: 59.49%\n",
      "Epoch [1778/2500], Train Loss: 0.6605, Train Accuracy: 71.98%, Test Loss: 0.9850, Test Accuracy: 58.23%\n",
      "Epoch [1779/2500], Train Loss: 0.6709, Train Accuracy: 71.83%, Test Loss: 0.9906, Test Accuracy: 59.49%\n",
      "Epoch [1780/2500], Train Loss: 0.6656, Train Accuracy: 70.41%, Test Loss: 0.9762, Test Accuracy: 60.76%\n",
      "Epoch [1781/2500], Train Loss: 0.6772, Train Accuracy: 69.56%, Test Loss: 1.0070, Test Accuracy: 58.23%\n",
      "Epoch [1782/2500], Train Loss: 0.6829, Train Accuracy: 69.99%, Test Loss: 0.9937, Test Accuracy: 59.49%\n",
      "Epoch [1783/2500], Train Loss: 0.6626, Train Accuracy: 71.98%, Test Loss: 1.0178, Test Accuracy: 63.29%\n",
      "Epoch [1784/2500], Train Loss: 0.6725, Train Accuracy: 68.42%, Test Loss: 0.9970, Test Accuracy: 60.76%\n",
      "Epoch [1785/2500], Train Loss: 0.6512, Train Accuracy: 69.13%, Test Loss: 0.9747, Test Accuracy: 58.23%\n",
      "Epoch [1786/2500], Train Loss: 0.6744, Train Accuracy: 68.71%, Test Loss: 0.9854, Test Accuracy: 58.23%\n",
      "Epoch [1787/2500], Train Loss: 0.6810, Train Accuracy: 70.27%, Test Loss: 0.9648, Test Accuracy: 59.49%\n",
      "Epoch [1788/2500], Train Loss: 0.6441, Train Accuracy: 71.12%, Test Loss: 0.9951, Test Accuracy: 56.96%\n",
      "Epoch [1789/2500], Train Loss: 0.6591, Train Accuracy: 71.55%, Test Loss: 0.9836, Test Accuracy: 60.76%\n",
      "Epoch [1790/2500], Train Loss: 0.6619, Train Accuracy: 72.40%, Test Loss: 0.9719, Test Accuracy: 62.03%\n",
      "Epoch [1791/2500], Train Loss: 0.6572, Train Accuracy: 71.69%, Test Loss: 0.9552, Test Accuracy: 59.49%\n",
      "Epoch [1792/2500], Train Loss: 0.6504, Train Accuracy: 69.13%, Test Loss: 0.9790, Test Accuracy: 59.49%\n",
      "Epoch [1793/2500], Train Loss: 0.6696, Train Accuracy: 69.42%, Test Loss: 0.9907, Test Accuracy: 59.49%\n",
      "Epoch [1794/2500], Train Loss: 0.6630, Train Accuracy: 72.97%, Test Loss: 0.9854, Test Accuracy: 59.49%\n",
      "Epoch [1795/2500], Train Loss: 0.6762, Train Accuracy: 69.84%, Test Loss: 0.9934, Test Accuracy: 58.23%\n",
      "Epoch [1796/2500], Train Loss: 0.6749, Train Accuracy: 69.70%, Test Loss: 0.9945, Test Accuracy: 58.23%\n",
      "Epoch [1797/2500], Train Loss: 0.6659, Train Accuracy: 69.84%, Test Loss: 1.0029, Test Accuracy: 59.49%\n",
      "Epoch [1798/2500], Train Loss: 0.6543, Train Accuracy: 69.84%, Test Loss: 0.9800, Test Accuracy: 60.76%\n",
      "Epoch [1799/2500], Train Loss: 0.6709, Train Accuracy: 69.84%, Test Loss: 0.9974, Test Accuracy: 60.76%\n",
      "Epoch [1800/2500], Train Loss: 0.6800, Train Accuracy: 69.56%, Test Loss: 1.0074, Test Accuracy: 59.49%\n",
      "Epoch [1801/2500], Train Loss: 0.6787, Train Accuracy: 71.83%, Test Loss: 0.9997, Test Accuracy: 58.23%\n",
      "Epoch [1802/2500], Train Loss: 0.6735, Train Accuracy: 69.56%, Test Loss: 1.0101, Test Accuracy: 59.49%\n",
      "Epoch [1803/2500], Train Loss: 0.6539, Train Accuracy: 70.27%, Test Loss: 1.0300, Test Accuracy: 58.23%\n",
      "Epoch [1804/2500], Train Loss: 0.6663, Train Accuracy: 70.27%, Test Loss: 1.0553, Test Accuracy: 58.23%\n",
      "Epoch [1805/2500], Train Loss: 0.6659, Train Accuracy: 71.69%, Test Loss: 1.0255, Test Accuracy: 58.23%\n",
      "Epoch [1806/2500], Train Loss: 0.6690, Train Accuracy: 69.70%, Test Loss: 0.9931, Test Accuracy: 58.23%\n",
      "Epoch [1807/2500], Train Loss: 0.6572, Train Accuracy: 69.56%, Test Loss: 1.0129, Test Accuracy: 59.49%\n",
      "Epoch [1808/2500], Train Loss: 0.6539, Train Accuracy: 71.12%, Test Loss: 1.0040, Test Accuracy: 59.49%\n",
      "Epoch [1809/2500], Train Loss: 0.6725, Train Accuracy: 70.84%, Test Loss: 1.0130, Test Accuracy: 60.76%\n",
      "Epoch [1810/2500], Train Loss: 0.6671, Train Accuracy: 70.41%, Test Loss: 0.9924, Test Accuracy: 62.03%\n",
      "Epoch [1811/2500], Train Loss: 0.6629, Train Accuracy: 71.83%, Test Loss: 0.9949, Test Accuracy: 60.76%\n",
      "Epoch [1812/2500], Train Loss: 0.6723, Train Accuracy: 72.69%, Test Loss: 0.9876, Test Accuracy: 62.03%\n",
      "Epoch [1813/2500], Train Loss: 0.6688, Train Accuracy: 69.99%, Test Loss: 0.9688, Test Accuracy: 63.29%\n",
      "Epoch [1814/2500], Train Loss: 0.6657, Train Accuracy: 70.41%, Test Loss: 0.9623, Test Accuracy: 62.03%\n",
      "Epoch [1815/2500], Train Loss: 0.6431, Train Accuracy: 70.70%, Test Loss: 0.9925, Test Accuracy: 60.76%\n",
      "Epoch [1816/2500], Train Loss: 0.6817, Train Accuracy: 69.27%, Test Loss: 0.9935, Test Accuracy: 59.49%\n",
      "Epoch [1817/2500], Train Loss: 0.6680, Train Accuracy: 70.41%, Test Loss: 0.9904, Test Accuracy: 63.29%\n",
      "Epoch [1818/2500], Train Loss: 0.6497, Train Accuracy: 68.56%, Test Loss: 0.9745, Test Accuracy: 60.76%\n",
      "Epoch [1819/2500], Train Loss: 0.6667, Train Accuracy: 71.83%, Test Loss: 0.9930, Test Accuracy: 59.49%\n",
      "Epoch [1820/2500], Train Loss: 0.6724, Train Accuracy: 69.99%, Test Loss: 0.9809, Test Accuracy: 60.76%\n",
      "Epoch [1821/2500], Train Loss: 0.6845, Train Accuracy: 68.42%, Test Loss: 0.9916, Test Accuracy: 62.03%\n",
      "Epoch [1822/2500], Train Loss: 0.6624, Train Accuracy: 70.70%, Test Loss: 0.9838, Test Accuracy: 59.49%\n",
      "Epoch [1823/2500], Train Loss: 0.6487, Train Accuracy: 71.12%, Test Loss: 0.9621, Test Accuracy: 60.76%\n",
      "Epoch [1824/2500], Train Loss: 0.6547, Train Accuracy: 73.12%, Test Loss: 0.9792, Test Accuracy: 60.76%\n",
      "Epoch [1825/2500], Train Loss: 0.6429, Train Accuracy: 70.70%, Test Loss: 1.0043, Test Accuracy: 62.03%\n",
      "Epoch [1826/2500], Train Loss: 0.6828, Train Accuracy: 71.27%, Test Loss: 0.9760, Test Accuracy: 62.03%\n",
      "Epoch [1827/2500], Train Loss: 0.6594, Train Accuracy: 69.70%, Test Loss: 0.9814, Test Accuracy: 60.76%\n",
      "Epoch [1828/2500], Train Loss: 0.6313, Train Accuracy: 71.27%, Test Loss: 0.9951, Test Accuracy: 59.49%\n",
      "Epoch [1829/2500], Train Loss: 0.6441, Train Accuracy: 72.12%, Test Loss: 0.9808, Test Accuracy: 60.76%\n",
      "Epoch [1830/2500], Train Loss: 0.6715, Train Accuracy: 71.69%, Test Loss: 1.0270, Test Accuracy: 60.76%\n",
      "Epoch [1831/2500], Train Loss: 0.6405, Train Accuracy: 71.12%, Test Loss: 1.0019, Test Accuracy: 59.49%\n",
      "Epoch [1832/2500], Train Loss: 0.6549, Train Accuracy: 69.84%, Test Loss: 1.0292, Test Accuracy: 59.49%\n",
      "Epoch [1833/2500], Train Loss: 0.6386, Train Accuracy: 73.40%, Test Loss: 1.0176, Test Accuracy: 60.76%\n",
      "Epoch [1834/2500], Train Loss: 0.6494, Train Accuracy: 72.26%, Test Loss: 0.9575, Test Accuracy: 63.29%\n",
      "Epoch [1835/2500], Train Loss: 0.6363, Train Accuracy: 72.55%, Test Loss: 0.9940, Test Accuracy: 60.76%\n",
      "Epoch [1836/2500], Train Loss: 0.6599, Train Accuracy: 72.12%, Test Loss: 0.9917, Test Accuracy: 63.29%\n",
      "Epoch [1837/2500], Train Loss: 0.6621, Train Accuracy: 69.99%, Test Loss: 0.9542, Test Accuracy: 64.56%\n",
      "Epoch [1838/2500], Train Loss: 0.6706, Train Accuracy: 69.70%, Test Loss: 0.9759, Test Accuracy: 62.03%\n",
      "Epoch [1839/2500], Train Loss: 0.6658, Train Accuracy: 69.56%, Test Loss: 0.9731, Test Accuracy: 60.76%\n",
      "Epoch [1840/2500], Train Loss: 0.6781, Train Accuracy: 70.98%, Test Loss: 1.0048, Test Accuracy: 60.76%\n",
      "Epoch [1841/2500], Train Loss: 0.6454, Train Accuracy: 71.98%, Test Loss: 1.0173, Test Accuracy: 59.49%\n",
      "Epoch [1842/2500], Train Loss: 0.6559, Train Accuracy: 71.83%, Test Loss: 1.0339, Test Accuracy: 59.49%\n",
      "Epoch [1843/2500], Train Loss: 0.6435, Train Accuracy: 72.55%, Test Loss: 0.9970, Test Accuracy: 59.49%\n",
      "Epoch [1844/2500], Train Loss: 0.6485, Train Accuracy: 70.41%, Test Loss: 0.9885, Test Accuracy: 58.23%\n",
      "Epoch [1845/2500], Train Loss: 0.6513, Train Accuracy: 70.70%, Test Loss: 0.9923, Test Accuracy: 58.23%\n",
      "Epoch [1846/2500], Train Loss: 0.6607, Train Accuracy: 70.84%, Test Loss: 0.9955, Test Accuracy: 60.76%\n",
      "Epoch [1847/2500], Train Loss: 0.6875, Train Accuracy: 69.99%, Test Loss: 0.9999, Test Accuracy: 58.23%\n",
      "Epoch [1848/2500], Train Loss: 0.6575, Train Accuracy: 69.42%, Test Loss: 0.9971, Test Accuracy: 58.23%\n",
      "Epoch [1849/2500], Train Loss: 0.6621, Train Accuracy: 68.71%, Test Loss: 0.9705, Test Accuracy: 60.76%\n",
      "Epoch [1850/2500], Train Loss: 0.6609, Train Accuracy: 70.98%, Test Loss: 0.9604, Test Accuracy: 60.76%\n",
      "Epoch [1851/2500], Train Loss: 0.6236, Train Accuracy: 71.55%, Test Loss: 0.9757, Test Accuracy: 59.49%\n",
      "Epoch [1852/2500], Train Loss: 0.6640, Train Accuracy: 72.40%, Test Loss: 0.9918, Test Accuracy: 59.49%\n",
      "Epoch [1853/2500], Train Loss: 0.6537, Train Accuracy: 71.41%, Test Loss: 0.9992, Test Accuracy: 58.23%\n",
      "Epoch [1854/2500], Train Loss: 0.6563, Train Accuracy: 70.27%, Test Loss: 0.9860, Test Accuracy: 59.49%\n",
      "Epoch [1855/2500], Train Loss: 0.6509, Train Accuracy: 72.83%, Test Loss: 1.0036, Test Accuracy: 59.49%\n",
      "Epoch [1856/2500], Train Loss: 0.6555, Train Accuracy: 70.55%, Test Loss: 1.0157, Test Accuracy: 56.96%\n",
      "Epoch [1857/2500], Train Loss: 0.6522, Train Accuracy: 71.55%, Test Loss: 0.9940, Test Accuracy: 59.49%\n",
      "Epoch [1858/2500], Train Loss: 0.6520, Train Accuracy: 71.27%, Test Loss: 1.0047, Test Accuracy: 60.76%\n",
      "Epoch [1859/2500], Train Loss: 0.6580, Train Accuracy: 70.55%, Test Loss: 0.9935, Test Accuracy: 62.03%\n",
      "Epoch [1860/2500], Train Loss: 0.6644, Train Accuracy: 71.69%, Test Loss: 0.9783, Test Accuracy: 60.76%\n",
      "Epoch [1861/2500], Train Loss: 0.6437, Train Accuracy: 71.98%, Test Loss: 1.0020, Test Accuracy: 60.76%\n",
      "Epoch [1862/2500], Train Loss: 0.6750, Train Accuracy: 68.56%, Test Loss: 1.0032, Test Accuracy: 60.76%\n",
      "Epoch [1863/2500], Train Loss: 0.6549, Train Accuracy: 71.41%, Test Loss: 0.9527, Test Accuracy: 59.49%\n",
      "Epoch [1864/2500], Train Loss: 0.6541, Train Accuracy: 71.27%, Test Loss: 0.9852, Test Accuracy: 59.49%\n",
      "Epoch [1865/2500], Train Loss: 0.6354, Train Accuracy: 72.26%, Test Loss: 0.9908, Test Accuracy: 60.76%\n",
      "Epoch [1866/2500], Train Loss: 0.6505, Train Accuracy: 70.98%, Test Loss: 1.0154, Test Accuracy: 59.49%\n",
      "Epoch [1867/2500], Train Loss: 0.6683, Train Accuracy: 70.41%, Test Loss: 0.9752, Test Accuracy: 60.76%\n",
      "Epoch [1868/2500], Train Loss: 0.6553, Train Accuracy: 70.55%, Test Loss: 1.0278, Test Accuracy: 62.03%\n",
      "Epoch [1869/2500], Train Loss: 0.6796, Train Accuracy: 70.13%, Test Loss: 1.0190, Test Accuracy: 59.49%\n",
      "Epoch [1870/2500], Train Loss: 0.6686, Train Accuracy: 70.27%, Test Loss: 0.9996, Test Accuracy: 60.76%\n",
      "Epoch [1871/2500], Train Loss: 0.6482, Train Accuracy: 71.27%, Test Loss: 1.0422, Test Accuracy: 58.23%\n",
      "Epoch [1872/2500], Train Loss: 0.6457, Train Accuracy: 71.41%, Test Loss: 1.0320, Test Accuracy: 60.76%\n",
      "Epoch [1873/2500], Train Loss: 0.6756, Train Accuracy: 71.27%, Test Loss: 1.0410, Test Accuracy: 60.76%\n",
      "Epoch [1874/2500], Train Loss: 0.6543, Train Accuracy: 71.98%, Test Loss: 1.0093, Test Accuracy: 60.76%\n",
      "Epoch [1875/2500], Train Loss: 0.6577, Train Accuracy: 70.70%, Test Loss: 0.9650, Test Accuracy: 59.49%\n",
      "Epoch [1876/2500], Train Loss: 0.6342, Train Accuracy: 70.55%, Test Loss: 0.9767, Test Accuracy: 62.03%\n",
      "Epoch [1877/2500], Train Loss: 0.6336, Train Accuracy: 72.26%, Test Loss: 0.9917, Test Accuracy: 60.76%\n",
      "Epoch [1878/2500], Train Loss: 0.6456, Train Accuracy: 70.13%, Test Loss: 1.0408, Test Accuracy: 62.03%\n",
      "Epoch [1879/2500], Train Loss: 0.6193, Train Accuracy: 71.69%, Test Loss: 1.0218, Test Accuracy: 60.76%\n",
      "Epoch [1880/2500], Train Loss: 0.6459, Train Accuracy: 70.84%, Test Loss: 0.9963, Test Accuracy: 60.76%\n",
      "Epoch [1881/2500], Train Loss: 0.6743, Train Accuracy: 71.83%, Test Loss: 0.9832, Test Accuracy: 59.49%\n",
      "Epoch [1882/2500], Train Loss: 0.6524, Train Accuracy: 71.55%, Test Loss: 0.9815, Test Accuracy: 59.49%\n",
      "Epoch [1883/2500], Train Loss: 0.6398, Train Accuracy: 71.12%, Test Loss: 1.0039, Test Accuracy: 59.49%\n",
      "Epoch [1884/2500], Train Loss: 0.6713, Train Accuracy: 70.13%, Test Loss: 1.0028, Test Accuracy: 59.49%\n",
      "Epoch [1885/2500], Train Loss: 0.6423, Train Accuracy: 72.40%, Test Loss: 1.0088, Test Accuracy: 59.49%\n",
      "Epoch [1886/2500], Train Loss: 0.6573, Train Accuracy: 71.55%, Test Loss: 1.0025, Test Accuracy: 59.49%\n",
      "Epoch [1887/2500], Train Loss: 0.6685, Train Accuracy: 69.27%, Test Loss: 1.0090, Test Accuracy: 59.49%\n",
      "Epoch [1888/2500], Train Loss: 0.6444, Train Accuracy: 70.41%, Test Loss: 1.0136, Test Accuracy: 62.03%\n",
      "Epoch [1889/2500], Train Loss: 0.6273, Train Accuracy: 72.26%, Test Loss: 1.0078, Test Accuracy: 60.76%\n",
      "Epoch [1890/2500], Train Loss: 0.6693, Train Accuracy: 71.69%, Test Loss: 0.9965, Test Accuracy: 58.23%\n",
      "Epoch [1891/2500], Train Loss: 0.6529, Train Accuracy: 70.13%, Test Loss: 1.0190, Test Accuracy: 59.49%\n",
      "Epoch [1892/2500], Train Loss: 0.6572, Train Accuracy: 69.99%, Test Loss: 1.0066, Test Accuracy: 59.49%\n",
      "Epoch [1893/2500], Train Loss: 0.6430, Train Accuracy: 70.41%, Test Loss: 1.0380, Test Accuracy: 58.23%\n",
      "Epoch [1894/2500], Train Loss: 0.6347, Train Accuracy: 73.97%, Test Loss: 1.0086, Test Accuracy: 59.49%\n",
      "Epoch [1895/2500], Train Loss: 0.6591, Train Accuracy: 70.70%, Test Loss: 1.0572, Test Accuracy: 54.43%\n",
      "Epoch [1896/2500], Train Loss: 0.6368, Train Accuracy: 71.69%, Test Loss: 1.0035, Test Accuracy: 58.23%\n",
      "Epoch [1897/2500], Train Loss: 0.6638, Train Accuracy: 69.84%, Test Loss: 0.9995, Test Accuracy: 58.23%\n",
      "Epoch [1898/2500], Train Loss: 0.6654, Train Accuracy: 71.12%, Test Loss: 1.0076, Test Accuracy: 56.96%\n",
      "Epoch [1899/2500], Train Loss: 0.6389, Train Accuracy: 72.26%, Test Loss: 1.0106, Test Accuracy: 59.49%\n",
      "Epoch [1900/2500], Train Loss: 0.6564, Train Accuracy: 71.27%, Test Loss: 1.0196, Test Accuracy: 58.23%\n",
      "Epoch [1901/2500], Train Loss: 0.6576, Train Accuracy: 71.27%, Test Loss: 0.9925, Test Accuracy: 60.76%\n",
      "Epoch [1902/2500], Train Loss: 0.6446, Train Accuracy: 69.70%, Test Loss: 0.9834, Test Accuracy: 55.70%\n",
      "Epoch [1903/2500], Train Loss: 0.6732, Train Accuracy: 69.70%, Test Loss: 0.9968, Test Accuracy: 58.23%\n",
      "Epoch [1904/2500], Train Loss: 0.6591, Train Accuracy: 70.13%, Test Loss: 1.0248, Test Accuracy: 58.23%\n",
      "Epoch [1905/2500], Train Loss: 0.6519, Train Accuracy: 71.83%, Test Loss: 1.0100, Test Accuracy: 59.49%\n",
      "Epoch [1906/2500], Train Loss: 0.6684, Train Accuracy: 71.41%, Test Loss: 0.9992, Test Accuracy: 60.76%\n",
      "Epoch [1907/2500], Train Loss: 0.6340, Train Accuracy: 72.55%, Test Loss: 1.0164, Test Accuracy: 56.96%\n",
      "Epoch [1908/2500], Train Loss: 0.6585, Train Accuracy: 72.40%, Test Loss: 1.0255, Test Accuracy: 59.49%\n",
      "Epoch [1909/2500], Train Loss: 0.6539, Train Accuracy: 70.70%, Test Loss: 1.0194, Test Accuracy: 59.49%\n",
      "Epoch [1910/2500], Train Loss: 0.6813, Train Accuracy: 71.12%, Test Loss: 1.0420, Test Accuracy: 58.23%\n",
      "Epoch [1911/2500], Train Loss: 0.6484, Train Accuracy: 70.98%, Test Loss: 1.0431, Test Accuracy: 58.23%\n",
      "Epoch [1912/2500], Train Loss: 0.6520, Train Accuracy: 70.13%, Test Loss: 0.9894, Test Accuracy: 58.23%\n",
      "Epoch [1913/2500], Train Loss: 0.6282, Train Accuracy: 72.83%, Test Loss: 1.0140, Test Accuracy: 59.49%\n",
      "Epoch [1914/2500], Train Loss: 0.6583, Train Accuracy: 71.27%, Test Loss: 1.0150, Test Accuracy: 59.49%\n",
      "Epoch [1915/2500], Train Loss: 0.6673, Train Accuracy: 71.27%, Test Loss: 1.0282, Test Accuracy: 60.76%\n",
      "Epoch [1916/2500], Train Loss: 0.6267, Train Accuracy: 70.84%, Test Loss: 1.0229, Test Accuracy: 60.76%\n",
      "Epoch [1917/2500], Train Loss: 0.6622, Train Accuracy: 70.27%, Test Loss: 1.0767, Test Accuracy: 58.23%\n",
      "Epoch [1918/2500], Train Loss: 0.6448, Train Accuracy: 71.55%, Test Loss: 1.0275, Test Accuracy: 60.76%\n",
      "Epoch [1919/2500], Train Loss: 0.6401, Train Accuracy: 72.55%, Test Loss: 1.0229, Test Accuracy: 58.23%\n",
      "Epoch [1920/2500], Train Loss: 0.6548, Train Accuracy: 70.13%, Test Loss: 0.9941, Test Accuracy: 60.76%\n",
      "Epoch [1921/2500], Train Loss: 0.6641, Train Accuracy: 69.13%, Test Loss: 1.0165, Test Accuracy: 58.23%\n",
      "Epoch [1922/2500], Train Loss: 0.6547, Train Accuracy: 71.27%, Test Loss: 1.0383, Test Accuracy: 59.49%\n",
      "Epoch [1923/2500], Train Loss: 0.6489, Train Accuracy: 71.69%, Test Loss: 0.9916, Test Accuracy: 56.96%\n",
      "Epoch [1924/2500], Train Loss: 0.6616, Train Accuracy: 71.55%, Test Loss: 1.0545, Test Accuracy: 58.23%\n",
      "Epoch [1925/2500], Train Loss: 0.6415, Train Accuracy: 71.27%, Test Loss: 1.0135, Test Accuracy: 59.49%\n",
      "Epoch [1926/2500], Train Loss: 0.6409, Train Accuracy: 72.55%, Test Loss: 1.0166, Test Accuracy: 60.76%\n",
      "Epoch [1927/2500], Train Loss: 0.6510, Train Accuracy: 71.12%, Test Loss: 0.9928, Test Accuracy: 62.03%\n",
      "Epoch [1928/2500], Train Loss: 0.6492, Train Accuracy: 73.54%, Test Loss: 1.0113, Test Accuracy: 59.49%\n",
      "Epoch [1929/2500], Train Loss: 0.6390, Train Accuracy: 72.55%, Test Loss: 1.0084, Test Accuracy: 59.49%\n",
      "Epoch [1930/2500], Train Loss: 0.6429, Train Accuracy: 70.27%, Test Loss: 0.9885, Test Accuracy: 59.49%\n",
      "Epoch [1931/2500], Train Loss: 0.6352, Train Accuracy: 71.98%, Test Loss: 1.0126, Test Accuracy: 60.76%\n",
      "Epoch [1932/2500], Train Loss: 0.6485, Train Accuracy: 71.41%, Test Loss: 1.0143, Test Accuracy: 59.49%\n",
      "Epoch [1933/2500], Train Loss: 0.6586, Train Accuracy: 69.56%, Test Loss: 0.9903, Test Accuracy: 60.76%\n",
      "Epoch [1934/2500], Train Loss: 0.6208, Train Accuracy: 73.12%, Test Loss: 0.9817, Test Accuracy: 62.03%\n",
      "Epoch [1935/2500], Train Loss: 0.6470, Train Accuracy: 71.83%, Test Loss: 0.9902, Test Accuracy: 60.76%\n",
      "Epoch [1936/2500], Train Loss: 0.6484, Train Accuracy: 71.83%, Test Loss: 1.0380, Test Accuracy: 59.49%\n",
      "Epoch [1937/2500], Train Loss: 0.6691, Train Accuracy: 71.27%, Test Loss: 0.9729, Test Accuracy: 59.49%\n",
      "Epoch [1938/2500], Train Loss: 0.6512, Train Accuracy: 73.40%, Test Loss: 0.9796, Test Accuracy: 58.23%\n",
      "Epoch [1939/2500], Train Loss: 0.6524, Train Accuracy: 70.41%, Test Loss: 0.9947, Test Accuracy: 58.23%\n",
      "Epoch [1940/2500], Train Loss: 0.6363, Train Accuracy: 72.26%, Test Loss: 0.9977, Test Accuracy: 59.49%\n",
      "Epoch [1941/2500], Train Loss: 0.6313, Train Accuracy: 72.55%, Test Loss: 0.9724, Test Accuracy: 60.76%\n",
      "Epoch [1942/2500], Train Loss: 0.6499, Train Accuracy: 72.12%, Test Loss: 0.9849, Test Accuracy: 62.03%\n",
      "Epoch [1943/2500], Train Loss: 0.6534, Train Accuracy: 71.55%, Test Loss: 0.9881, Test Accuracy: 60.76%\n",
      "Epoch [1944/2500], Train Loss: 0.6422, Train Accuracy: 70.70%, Test Loss: 0.9831, Test Accuracy: 59.49%\n",
      "Epoch [1945/2500], Train Loss: 0.6286, Train Accuracy: 71.69%, Test Loss: 0.9936, Test Accuracy: 58.23%\n",
      "Epoch [1946/2500], Train Loss: 0.6535, Train Accuracy: 70.55%, Test Loss: 1.0111, Test Accuracy: 59.49%\n",
      "Epoch [1947/2500], Train Loss: 0.6662, Train Accuracy: 70.84%, Test Loss: 1.0113, Test Accuracy: 59.49%\n",
      "Epoch [1948/2500], Train Loss: 0.6523, Train Accuracy: 72.69%, Test Loss: 1.0079, Test Accuracy: 56.96%\n",
      "Epoch [1949/2500], Train Loss: 0.6400, Train Accuracy: 71.12%, Test Loss: 0.9921, Test Accuracy: 59.49%\n",
      "Epoch [1950/2500], Train Loss: 0.6611, Train Accuracy: 69.13%, Test Loss: 0.9863, Test Accuracy: 58.23%\n",
      "Epoch [1951/2500], Train Loss: 0.6225, Train Accuracy: 73.12%, Test Loss: 0.9880, Test Accuracy: 59.49%\n",
      "Epoch [1952/2500], Train Loss: 0.6726, Train Accuracy: 72.97%, Test Loss: 0.9966, Test Accuracy: 59.49%\n",
      "Epoch [1953/2500], Train Loss: 0.6615, Train Accuracy: 71.69%, Test Loss: 0.9908, Test Accuracy: 59.49%\n",
      "Epoch [1954/2500], Train Loss: 0.6529, Train Accuracy: 71.27%, Test Loss: 1.0048, Test Accuracy: 56.96%\n",
      "Epoch [1955/2500], Train Loss: 0.6583, Train Accuracy: 70.13%, Test Loss: 1.0233, Test Accuracy: 59.49%\n",
      "Epoch [1956/2500], Train Loss: 0.6427, Train Accuracy: 72.69%, Test Loss: 1.0181, Test Accuracy: 58.23%\n",
      "Epoch [1957/2500], Train Loss: 0.6588, Train Accuracy: 71.83%, Test Loss: 1.0126, Test Accuracy: 58.23%\n",
      "Epoch [1958/2500], Train Loss: 0.6435, Train Accuracy: 72.12%, Test Loss: 1.0080, Test Accuracy: 59.49%\n",
      "Epoch [1959/2500], Train Loss: 0.6460, Train Accuracy: 71.12%, Test Loss: 0.9933, Test Accuracy: 60.76%\n",
      "Epoch [1960/2500], Train Loss: 0.6567, Train Accuracy: 71.55%, Test Loss: 1.0027, Test Accuracy: 58.23%\n",
      "Epoch [1961/2500], Train Loss: 0.6554, Train Accuracy: 69.99%, Test Loss: 1.0044, Test Accuracy: 56.96%\n",
      "Epoch [1962/2500], Train Loss: 0.6668, Train Accuracy: 71.12%, Test Loss: 1.0175, Test Accuracy: 59.49%\n",
      "Epoch [1963/2500], Train Loss: 0.6453, Train Accuracy: 71.27%, Test Loss: 1.0104, Test Accuracy: 59.49%\n",
      "Epoch [1964/2500], Train Loss: 0.6530, Train Accuracy: 71.27%, Test Loss: 0.9803, Test Accuracy: 58.23%\n",
      "Epoch [1965/2500], Train Loss: 0.6487, Train Accuracy: 72.83%, Test Loss: 1.0072, Test Accuracy: 59.49%\n",
      "Epoch [1966/2500], Train Loss: 0.6376, Train Accuracy: 73.26%, Test Loss: 1.0097, Test Accuracy: 59.49%\n",
      "Epoch [1967/2500], Train Loss: 0.6407, Train Accuracy: 71.41%, Test Loss: 1.0137, Test Accuracy: 56.96%\n",
      "Epoch [1968/2500], Train Loss: 0.6515, Train Accuracy: 69.84%, Test Loss: 1.0016, Test Accuracy: 59.49%\n",
      "Epoch [1969/2500], Train Loss: 0.6623, Train Accuracy: 72.12%, Test Loss: 1.0067, Test Accuracy: 59.49%\n",
      "Epoch [1970/2500], Train Loss: 0.6435, Train Accuracy: 71.83%, Test Loss: 0.9869, Test Accuracy: 59.49%\n",
      "Epoch [1971/2500], Train Loss: 0.6607, Train Accuracy: 71.27%, Test Loss: 0.9968, Test Accuracy: 56.96%\n",
      "Epoch [1972/2500], Train Loss: 0.6410, Train Accuracy: 70.13%, Test Loss: 0.9983, Test Accuracy: 59.49%\n",
      "Epoch [1973/2500], Train Loss: 0.6602, Train Accuracy: 71.27%, Test Loss: 1.0112, Test Accuracy: 59.49%\n",
      "Epoch [1974/2500], Train Loss: 0.6686, Train Accuracy: 69.56%, Test Loss: 1.0251, Test Accuracy: 56.96%\n",
      "Epoch [1975/2500], Train Loss: 0.6563, Train Accuracy: 71.55%, Test Loss: 0.9856, Test Accuracy: 58.23%\n",
      "Epoch [1976/2500], Train Loss: 0.6591, Train Accuracy: 70.55%, Test Loss: 0.9986, Test Accuracy: 62.03%\n",
      "Epoch [1977/2500], Train Loss: 0.6472, Train Accuracy: 70.27%, Test Loss: 1.0036, Test Accuracy: 58.23%\n",
      "Epoch [1978/2500], Train Loss: 0.6367, Train Accuracy: 71.98%, Test Loss: 1.0132, Test Accuracy: 58.23%\n",
      "Epoch [1979/2500], Train Loss: 0.6278, Train Accuracy: 72.40%, Test Loss: 1.0324, Test Accuracy: 60.76%\n",
      "Epoch [1980/2500], Train Loss: 0.6789, Train Accuracy: 70.55%, Test Loss: 1.0006, Test Accuracy: 56.96%\n",
      "Epoch [1981/2500], Train Loss: 0.6508, Train Accuracy: 70.41%, Test Loss: 0.9936, Test Accuracy: 58.23%\n",
      "Epoch [1982/2500], Train Loss: 0.6521, Train Accuracy: 71.12%, Test Loss: 1.0316, Test Accuracy: 58.23%\n",
      "Epoch [1983/2500], Train Loss: 0.6316, Train Accuracy: 71.12%, Test Loss: 1.0221, Test Accuracy: 58.23%\n",
      "Epoch [1984/2500], Train Loss: 0.6356, Train Accuracy: 72.40%, Test Loss: 1.0166, Test Accuracy: 58.23%\n",
      "Epoch [1985/2500], Train Loss: 0.6336, Train Accuracy: 72.26%, Test Loss: 1.0107, Test Accuracy: 58.23%\n",
      "Epoch [1986/2500], Train Loss: 0.6527, Train Accuracy: 71.98%, Test Loss: 1.0227, Test Accuracy: 58.23%\n",
      "Epoch [1987/2500], Train Loss: 0.6547, Train Accuracy: 72.55%, Test Loss: 1.0042, Test Accuracy: 58.23%\n",
      "Epoch [1988/2500], Train Loss: 0.6403, Train Accuracy: 71.83%, Test Loss: 1.0148, Test Accuracy: 59.49%\n",
      "Epoch [1989/2500], Train Loss: 0.6635, Train Accuracy: 70.98%, Test Loss: 1.0026, Test Accuracy: 56.96%\n",
      "Epoch [1990/2500], Train Loss: 0.6260, Train Accuracy: 70.98%, Test Loss: 1.0202, Test Accuracy: 58.23%\n",
      "Epoch [1991/2500], Train Loss: 0.6503, Train Accuracy: 72.83%, Test Loss: 1.0048, Test Accuracy: 58.23%\n",
      "Epoch [1992/2500], Train Loss: 0.6410, Train Accuracy: 72.26%, Test Loss: 1.0156, Test Accuracy: 58.23%\n",
      "Epoch [1993/2500], Train Loss: 0.6316, Train Accuracy: 72.26%, Test Loss: 1.0290, Test Accuracy: 58.23%\n",
      "Epoch [1994/2500], Train Loss: 0.6293, Train Accuracy: 72.40%, Test Loss: 1.0122, Test Accuracy: 56.96%\n",
      "Epoch [1995/2500], Train Loss: 0.6164, Train Accuracy: 73.68%, Test Loss: 1.0121, Test Accuracy: 58.23%\n",
      "Epoch [1996/2500], Train Loss: 0.6235, Train Accuracy: 73.83%, Test Loss: 1.0145, Test Accuracy: 58.23%\n",
      "Epoch [1997/2500], Train Loss: 0.6573, Train Accuracy: 70.41%, Test Loss: 1.0019, Test Accuracy: 58.23%\n",
      "Epoch [1998/2500], Train Loss: 0.6520, Train Accuracy: 71.83%, Test Loss: 1.0321, Test Accuracy: 59.49%\n",
      "Epoch [1999/2500], Train Loss: 0.6488, Train Accuracy: 71.98%, Test Loss: 1.0457, Test Accuracy: 59.49%\n",
      "Epoch [2000/2500], Train Loss: 0.6608, Train Accuracy: 72.12%, Test Loss: 1.0018, Test Accuracy: 59.49%\n",
      "Epoch [2001/2500], Train Loss: 0.6437, Train Accuracy: 71.69%, Test Loss: 1.0078, Test Accuracy: 58.23%\n",
      "Epoch [2002/2500], Train Loss: 0.6642, Train Accuracy: 70.13%, Test Loss: 1.0345, Test Accuracy: 59.49%\n",
      "Epoch [2003/2500], Train Loss: 0.6360, Train Accuracy: 70.98%, Test Loss: 1.0117, Test Accuracy: 60.76%\n",
      "Epoch [2004/2500], Train Loss: 0.6631, Train Accuracy: 71.69%, Test Loss: 1.0480, Test Accuracy: 62.03%\n",
      "Epoch [2005/2500], Train Loss: 0.6403, Train Accuracy: 71.69%, Test Loss: 1.0272, Test Accuracy: 58.23%\n",
      "Epoch [2006/2500], Train Loss: 0.6340, Train Accuracy: 72.12%, Test Loss: 1.0025, Test Accuracy: 58.23%\n",
      "Epoch [2007/2500], Train Loss: 0.6099, Train Accuracy: 73.12%, Test Loss: 1.0160, Test Accuracy: 58.23%\n",
      "Epoch [2008/2500], Train Loss: 0.6365, Train Accuracy: 73.68%, Test Loss: 1.0244, Test Accuracy: 58.23%\n",
      "Epoch [2009/2500], Train Loss: 0.6396, Train Accuracy: 71.27%, Test Loss: 1.0046, Test Accuracy: 58.23%\n",
      "Epoch [2010/2500], Train Loss: 0.6316, Train Accuracy: 71.69%, Test Loss: 1.0244, Test Accuracy: 59.49%\n",
      "Epoch [2011/2500], Train Loss: 0.6397, Train Accuracy: 71.27%, Test Loss: 0.9966, Test Accuracy: 59.49%\n",
      "Epoch [2012/2500], Train Loss: 0.6404, Train Accuracy: 73.97%, Test Loss: 0.9963, Test Accuracy: 60.76%\n",
      "Epoch [2013/2500], Train Loss: 0.6416, Train Accuracy: 71.27%, Test Loss: 1.0209, Test Accuracy: 59.49%\n",
      "Epoch [2014/2500], Train Loss: 0.6568, Train Accuracy: 72.26%, Test Loss: 1.0201, Test Accuracy: 59.49%\n",
      "Epoch [2015/2500], Train Loss: 0.6548, Train Accuracy: 71.69%, Test Loss: 1.0166, Test Accuracy: 58.23%\n",
      "Epoch [2016/2500], Train Loss: 0.6341, Train Accuracy: 72.40%, Test Loss: 0.9974, Test Accuracy: 59.49%\n",
      "Epoch [2017/2500], Train Loss: 0.6115, Train Accuracy: 73.97%, Test Loss: 0.9874, Test Accuracy: 59.49%\n",
      "Epoch [2018/2500], Train Loss: 0.6432, Train Accuracy: 72.12%, Test Loss: 0.9780, Test Accuracy: 60.76%\n",
      "Epoch [2019/2500], Train Loss: 0.6339, Train Accuracy: 72.55%, Test Loss: 0.9925, Test Accuracy: 58.23%\n",
      "Epoch [2020/2500], Train Loss: 0.6617, Train Accuracy: 71.12%, Test Loss: 0.9839, Test Accuracy: 60.76%\n",
      "Epoch [2021/2500], Train Loss: 0.6403, Train Accuracy: 72.83%, Test Loss: 1.0036, Test Accuracy: 60.76%\n",
      "Epoch [2022/2500], Train Loss: 0.6352, Train Accuracy: 71.83%, Test Loss: 1.0472, Test Accuracy: 60.76%\n",
      "Epoch [2023/2500], Train Loss: 0.6534, Train Accuracy: 70.27%, Test Loss: 1.0360, Test Accuracy: 60.76%\n",
      "Epoch [2024/2500], Train Loss: 0.6330, Train Accuracy: 71.55%, Test Loss: 1.0336, Test Accuracy: 59.49%\n",
      "Epoch [2025/2500], Train Loss: 0.6167, Train Accuracy: 74.54%, Test Loss: 1.0261, Test Accuracy: 59.49%\n",
      "Epoch [2026/2500], Train Loss: 0.6323, Train Accuracy: 72.69%, Test Loss: 1.0382, Test Accuracy: 56.96%\n",
      "Epoch [2027/2500], Train Loss: 0.6286, Train Accuracy: 72.97%, Test Loss: 1.0007, Test Accuracy: 58.23%\n",
      "Epoch [2028/2500], Train Loss: 0.6571, Train Accuracy: 70.98%, Test Loss: 0.9964, Test Accuracy: 59.49%\n",
      "Epoch [2029/2500], Train Loss: 0.6458, Train Accuracy: 70.41%, Test Loss: 0.9958, Test Accuracy: 59.49%\n",
      "Epoch [2030/2500], Train Loss: 0.6295, Train Accuracy: 72.40%, Test Loss: 0.9992, Test Accuracy: 56.96%\n",
      "Epoch [2031/2500], Train Loss: 0.6495, Train Accuracy: 71.69%, Test Loss: 1.0113, Test Accuracy: 59.49%\n",
      "Epoch [2032/2500], Train Loss: 0.6350, Train Accuracy: 72.12%, Test Loss: 0.9901, Test Accuracy: 59.49%\n",
      "Epoch [2033/2500], Train Loss: 0.6533, Train Accuracy: 71.27%, Test Loss: 0.9706, Test Accuracy: 59.49%\n",
      "Epoch [2034/2500], Train Loss: 0.6172, Train Accuracy: 71.98%, Test Loss: 0.9972, Test Accuracy: 56.96%\n",
      "Epoch [2035/2500], Train Loss: 0.6514, Train Accuracy: 70.27%, Test Loss: 1.0290, Test Accuracy: 59.49%\n",
      "Epoch [2036/2500], Train Loss: 0.6326, Train Accuracy: 71.83%, Test Loss: 1.0207, Test Accuracy: 59.49%\n",
      "Epoch [2037/2500], Train Loss: 0.6430, Train Accuracy: 71.55%, Test Loss: 1.0123, Test Accuracy: 56.96%\n",
      "Epoch [2038/2500], Train Loss: 0.6346, Train Accuracy: 72.12%, Test Loss: 1.0249, Test Accuracy: 60.76%\n",
      "Epoch [2039/2500], Train Loss: 0.6506, Train Accuracy: 72.12%, Test Loss: 0.9869, Test Accuracy: 58.23%\n",
      "Epoch [2040/2500], Train Loss: 0.6357, Train Accuracy: 71.83%, Test Loss: 0.9932, Test Accuracy: 59.49%\n",
      "Epoch [2041/2500], Train Loss: 0.6370, Train Accuracy: 72.12%, Test Loss: 0.9954, Test Accuracy: 58.23%\n",
      "Epoch [2042/2500], Train Loss: 0.6399, Train Accuracy: 72.97%, Test Loss: 0.9722, Test Accuracy: 56.96%\n",
      "Epoch [2043/2500], Train Loss: 0.6293, Train Accuracy: 71.83%, Test Loss: 0.9950, Test Accuracy: 58.23%\n",
      "Epoch [2044/2500], Train Loss: 0.6200, Train Accuracy: 73.68%, Test Loss: 1.0118, Test Accuracy: 59.49%\n",
      "Epoch [2045/2500], Train Loss: 0.6363, Train Accuracy: 72.55%, Test Loss: 1.0251, Test Accuracy: 59.49%\n",
      "Epoch [2046/2500], Train Loss: 0.6172, Train Accuracy: 71.27%, Test Loss: 1.0316, Test Accuracy: 60.76%\n",
      "Epoch [2047/2500], Train Loss: 0.6259, Train Accuracy: 70.84%, Test Loss: 1.0091, Test Accuracy: 60.76%\n",
      "Epoch [2048/2500], Train Loss: 0.6650, Train Accuracy: 69.84%, Test Loss: 1.0355, Test Accuracy: 59.49%\n",
      "Epoch [2049/2500], Train Loss: 0.6349, Train Accuracy: 72.12%, Test Loss: 0.9967, Test Accuracy: 62.03%\n",
      "Epoch [2050/2500], Train Loss: 0.6311, Train Accuracy: 71.55%, Test Loss: 1.0091, Test Accuracy: 60.76%\n",
      "Epoch [2051/2500], Train Loss: 0.6767, Train Accuracy: 70.41%, Test Loss: 1.0104, Test Accuracy: 60.76%\n",
      "Epoch [2052/2500], Train Loss: 0.6482, Train Accuracy: 71.27%, Test Loss: 1.0209, Test Accuracy: 59.49%\n",
      "Epoch [2053/2500], Train Loss: 0.6478, Train Accuracy: 71.98%, Test Loss: 1.0208, Test Accuracy: 58.23%\n",
      "Epoch [2054/2500], Train Loss: 0.6404, Train Accuracy: 71.41%, Test Loss: 1.0381, Test Accuracy: 60.76%\n",
      "Epoch [2055/2500], Train Loss: 0.6313, Train Accuracy: 72.83%, Test Loss: 1.0190, Test Accuracy: 59.49%\n",
      "Epoch [2056/2500], Train Loss: 0.6304, Train Accuracy: 72.40%, Test Loss: 1.0352, Test Accuracy: 59.49%\n",
      "Epoch [2057/2500], Train Loss: 0.6307, Train Accuracy: 72.40%, Test Loss: 1.0514, Test Accuracy: 59.49%\n",
      "Epoch [2058/2500], Train Loss: 0.6304, Train Accuracy: 72.12%, Test Loss: 1.0259, Test Accuracy: 59.49%\n",
      "Epoch [2059/2500], Train Loss: 0.6351, Train Accuracy: 72.97%, Test Loss: 1.0417, Test Accuracy: 59.49%\n",
      "Epoch [2060/2500], Train Loss: 0.6352, Train Accuracy: 72.26%, Test Loss: 1.0472, Test Accuracy: 59.49%\n",
      "Epoch [2061/2500], Train Loss: 0.6265, Train Accuracy: 71.83%, Test Loss: 1.0346, Test Accuracy: 58.23%\n",
      "Epoch [2062/2500], Train Loss: 0.6649, Train Accuracy: 70.98%, Test Loss: 1.0370, Test Accuracy: 55.70%\n",
      "Epoch [2063/2500], Train Loss: 0.6385, Train Accuracy: 72.69%, Test Loss: 1.0700, Test Accuracy: 55.70%\n",
      "Epoch [2064/2500], Train Loss: 0.6272, Train Accuracy: 72.26%, Test Loss: 1.0900, Test Accuracy: 56.96%\n",
      "Epoch [2065/2500], Train Loss: 0.6227, Train Accuracy: 73.54%, Test Loss: 1.0430, Test Accuracy: 58.23%\n",
      "Epoch [2066/2500], Train Loss: 0.6411, Train Accuracy: 72.97%, Test Loss: 1.0367, Test Accuracy: 59.49%\n",
      "Epoch [2067/2500], Train Loss: 0.6494, Train Accuracy: 70.27%, Test Loss: 1.0864, Test Accuracy: 56.96%\n",
      "Epoch [2068/2500], Train Loss: 0.6409, Train Accuracy: 70.84%, Test Loss: 1.0211, Test Accuracy: 56.96%\n",
      "Epoch [2069/2500], Train Loss: 0.6554, Train Accuracy: 70.98%, Test Loss: 1.0408, Test Accuracy: 59.49%\n",
      "Epoch [2070/2500], Train Loss: 0.6362, Train Accuracy: 72.12%, Test Loss: 1.0088, Test Accuracy: 58.23%\n",
      "Epoch [2071/2500], Train Loss: 0.6291, Train Accuracy: 72.55%, Test Loss: 1.0195, Test Accuracy: 58.23%\n",
      "Epoch [2072/2500], Train Loss: 0.6302, Train Accuracy: 72.83%, Test Loss: 1.0164, Test Accuracy: 56.96%\n",
      "Epoch [2073/2500], Train Loss: 0.6480, Train Accuracy: 71.83%, Test Loss: 1.0308, Test Accuracy: 56.96%\n",
      "Epoch [2074/2500], Train Loss: 0.6364, Train Accuracy: 73.26%, Test Loss: 0.9966, Test Accuracy: 56.96%\n",
      "Epoch [2075/2500], Train Loss: 0.6438, Train Accuracy: 72.26%, Test Loss: 1.0029, Test Accuracy: 56.96%\n",
      "Epoch [2076/2500], Train Loss: 0.6422, Train Accuracy: 71.12%, Test Loss: 1.0108, Test Accuracy: 55.70%\n",
      "Epoch [2077/2500], Train Loss: 0.6355, Train Accuracy: 70.13%, Test Loss: 1.0260, Test Accuracy: 58.23%\n",
      "Epoch [2078/2500], Train Loss: 0.6368, Train Accuracy: 70.84%, Test Loss: 1.0672, Test Accuracy: 56.96%\n",
      "Epoch [2079/2500], Train Loss: 0.6437, Train Accuracy: 72.55%, Test Loss: 1.0233, Test Accuracy: 58.23%\n",
      "Epoch [2080/2500], Train Loss: 0.6361, Train Accuracy: 73.26%, Test Loss: 1.0477, Test Accuracy: 55.70%\n",
      "Epoch [2081/2500], Train Loss: 0.6327, Train Accuracy: 71.83%, Test Loss: 1.0435, Test Accuracy: 58.23%\n",
      "Epoch [2082/2500], Train Loss: 0.6239, Train Accuracy: 72.26%, Test Loss: 1.0513, Test Accuracy: 60.76%\n",
      "Epoch [2083/2500], Train Loss: 0.6427, Train Accuracy: 71.12%, Test Loss: 1.0590, Test Accuracy: 60.76%\n",
      "Epoch [2084/2500], Train Loss: 0.6506, Train Accuracy: 71.83%, Test Loss: 1.0071, Test Accuracy: 60.76%\n",
      "Epoch [2085/2500], Train Loss: 0.6458, Train Accuracy: 73.68%, Test Loss: 1.0611, Test Accuracy: 59.49%\n",
      "Epoch [2086/2500], Train Loss: 0.6334, Train Accuracy: 72.83%, Test Loss: 1.0856, Test Accuracy: 58.23%\n",
      "Epoch [2087/2500], Train Loss: 0.6286, Train Accuracy: 73.68%, Test Loss: 1.1044, Test Accuracy: 58.23%\n",
      "Epoch [2088/2500], Train Loss: 0.6244, Train Accuracy: 70.13%, Test Loss: 1.0868, Test Accuracy: 55.70%\n",
      "Epoch [2089/2500], Train Loss: 0.6175, Train Accuracy: 73.40%, Test Loss: 1.0707, Test Accuracy: 56.96%\n",
      "Epoch [2090/2500], Train Loss: 0.6214, Train Accuracy: 73.97%, Test Loss: 1.0388, Test Accuracy: 59.49%\n",
      "Epoch [2091/2500], Train Loss: 0.6379, Train Accuracy: 72.12%, Test Loss: 1.0128, Test Accuracy: 59.49%\n",
      "Epoch [2092/2500], Train Loss: 0.6095, Train Accuracy: 73.12%, Test Loss: 1.0378, Test Accuracy: 58.23%\n",
      "Epoch [2093/2500], Train Loss: 0.6235, Train Accuracy: 72.55%, Test Loss: 1.0694, Test Accuracy: 59.49%\n",
      "Epoch [2094/2500], Train Loss: 0.6156, Train Accuracy: 72.83%, Test Loss: 1.0853, Test Accuracy: 56.96%\n",
      "Epoch [2095/2500], Train Loss: 0.6368, Train Accuracy: 71.27%, Test Loss: 1.0917, Test Accuracy: 58.23%\n",
      "Epoch [2096/2500], Train Loss: 0.6326, Train Accuracy: 72.12%, Test Loss: 1.0686, Test Accuracy: 60.76%\n",
      "Epoch [2097/2500], Train Loss: 0.6401, Train Accuracy: 71.12%, Test Loss: 1.0408, Test Accuracy: 59.49%\n",
      "Epoch [2098/2500], Train Loss: 0.6164, Train Accuracy: 72.83%, Test Loss: 1.0567, Test Accuracy: 60.76%\n",
      "Epoch [2099/2500], Train Loss: 0.6336, Train Accuracy: 72.83%, Test Loss: 1.0432, Test Accuracy: 60.76%\n",
      "Epoch [2100/2500], Train Loss: 0.6300, Train Accuracy: 72.55%, Test Loss: 1.0614, Test Accuracy: 59.49%\n",
      "Epoch [2101/2500], Train Loss: 0.6388, Train Accuracy: 72.12%, Test Loss: 1.0435, Test Accuracy: 58.23%\n",
      "Epoch [2102/2500], Train Loss: 0.6483, Train Accuracy: 72.40%, Test Loss: 1.0307, Test Accuracy: 59.49%\n",
      "Epoch [2103/2500], Train Loss: 0.6275, Train Accuracy: 72.83%, Test Loss: 1.0693, Test Accuracy: 58.23%\n",
      "Epoch [2104/2500], Train Loss: 0.6302, Train Accuracy: 73.26%, Test Loss: 1.0983, Test Accuracy: 56.96%\n",
      "Epoch [2105/2500], Train Loss: 0.6307, Train Accuracy: 73.83%, Test Loss: 1.0704, Test Accuracy: 56.96%\n",
      "Epoch [2106/2500], Train Loss: 0.6183, Train Accuracy: 72.69%, Test Loss: 1.0979, Test Accuracy: 58.23%\n",
      "Epoch [2107/2500], Train Loss: 0.6495, Train Accuracy: 71.98%, Test Loss: 1.0521, Test Accuracy: 56.96%\n",
      "Epoch [2108/2500], Train Loss: 0.6429, Train Accuracy: 71.27%, Test Loss: 1.0523, Test Accuracy: 58.23%\n",
      "Epoch [2109/2500], Train Loss: 0.6298, Train Accuracy: 71.98%, Test Loss: 1.0213, Test Accuracy: 56.96%\n",
      "Epoch [2110/2500], Train Loss: 0.6311, Train Accuracy: 71.98%, Test Loss: 1.0682, Test Accuracy: 58.23%\n",
      "Epoch [2111/2500], Train Loss: 0.6327, Train Accuracy: 70.84%, Test Loss: 1.0453, Test Accuracy: 60.76%\n",
      "Epoch [2112/2500], Train Loss: 0.6247, Train Accuracy: 72.83%, Test Loss: 1.0749, Test Accuracy: 56.96%\n",
      "Epoch [2113/2500], Train Loss: 0.6285, Train Accuracy: 73.12%, Test Loss: 1.1085, Test Accuracy: 59.49%\n",
      "Epoch [2114/2500], Train Loss: 0.6327, Train Accuracy: 71.27%, Test Loss: 1.1004, Test Accuracy: 58.23%\n",
      "Epoch [2115/2500], Train Loss: 0.6230, Train Accuracy: 73.12%, Test Loss: 1.0378, Test Accuracy: 58.23%\n",
      "Epoch [2116/2500], Train Loss: 0.6360, Train Accuracy: 72.97%, Test Loss: 1.0572, Test Accuracy: 58.23%\n",
      "Epoch [2117/2500], Train Loss: 0.6325, Train Accuracy: 70.55%, Test Loss: 1.0372, Test Accuracy: 58.23%\n",
      "Epoch [2118/2500], Train Loss: 0.6356, Train Accuracy: 70.98%, Test Loss: 1.0551, Test Accuracy: 56.96%\n",
      "Epoch [2119/2500], Train Loss: 0.6357, Train Accuracy: 72.26%, Test Loss: 1.0719, Test Accuracy: 59.49%\n",
      "Epoch [2120/2500], Train Loss: 0.6232, Train Accuracy: 72.69%, Test Loss: 1.0319, Test Accuracy: 56.96%\n",
      "Epoch [2121/2500], Train Loss: 0.6395, Train Accuracy: 73.12%, Test Loss: 1.1016, Test Accuracy: 58.23%\n",
      "Epoch [2122/2500], Train Loss: 0.6310, Train Accuracy: 73.12%, Test Loss: 1.0493, Test Accuracy: 60.76%\n",
      "Epoch [2123/2500], Train Loss: 0.6105, Train Accuracy: 73.83%, Test Loss: 1.0427, Test Accuracy: 56.96%\n",
      "Epoch [2124/2500], Train Loss: 0.6468, Train Accuracy: 71.55%, Test Loss: 1.0448, Test Accuracy: 56.96%\n",
      "Epoch [2125/2500], Train Loss: 0.6295, Train Accuracy: 73.26%, Test Loss: 1.0302, Test Accuracy: 56.96%\n",
      "Epoch [2126/2500], Train Loss: 0.6187, Train Accuracy: 72.55%, Test Loss: 1.0571, Test Accuracy: 58.23%\n",
      "Epoch [2127/2500], Train Loss: 0.6411, Train Accuracy: 72.69%, Test Loss: 1.0649, Test Accuracy: 58.23%\n",
      "Epoch [2128/2500], Train Loss: 0.6293, Train Accuracy: 71.83%, Test Loss: 1.0889, Test Accuracy: 56.96%\n",
      "Epoch [2129/2500], Train Loss: 0.6318, Train Accuracy: 72.26%, Test Loss: 1.0394, Test Accuracy: 59.49%\n",
      "Epoch [2130/2500], Train Loss: 0.6260, Train Accuracy: 73.26%, Test Loss: 1.0410, Test Accuracy: 59.49%\n",
      "Epoch [2131/2500], Train Loss: 0.5929, Train Accuracy: 72.83%, Test Loss: 1.0205, Test Accuracy: 56.96%\n",
      "Epoch [2132/2500], Train Loss: 0.6340, Train Accuracy: 73.26%, Test Loss: 1.0455, Test Accuracy: 59.49%\n",
      "Epoch [2133/2500], Train Loss: 0.6260, Train Accuracy: 73.68%, Test Loss: 1.0299, Test Accuracy: 59.49%\n",
      "Epoch [2134/2500], Train Loss: 0.6512, Train Accuracy: 71.69%, Test Loss: 1.0132, Test Accuracy: 60.76%\n",
      "Epoch [2135/2500], Train Loss: 0.6457, Train Accuracy: 71.83%, Test Loss: 1.0152, Test Accuracy: 59.49%\n",
      "Epoch [2136/2500], Train Loss: 0.6381, Train Accuracy: 73.68%, Test Loss: 1.0168, Test Accuracy: 60.76%\n",
      "Epoch [2137/2500], Train Loss: 0.6404, Train Accuracy: 70.70%, Test Loss: 1.0254, Test Accuracy: 59.49%\n",
      "Epoch [2138/2500], Train Loss: 0.6389, Train Accuracy: 71.69%, Test Loss: 1.0236, Test Accuracy: 59.49%\n",
      "Epoch [2139/2500], Train Loss: 0.6212, Train Accuracy: 73.97%, Test Loss: 1.0269, Test Accuracy: 59.49%\n",
      "Epoch [2140/2500], Train Loss: 0.6449, Train Accuracy: 71.12%, Test Loss: 1.0290, Test Accuracy: 60.76%\n",
      "Epoch [2141/2500], Train Loss: 0.6308, Train Accuracy: 72.69%, Test Loss: 1.0441, Test Accuracy: 58.23%\n",
      "Epoch [2142/2500], Train Loss: 0.6347, Train Accuracy: 71.69%, Test Loss: 1.0267, Test Accuracy: 58.23%\n",
      "Epoch [2143/2500], Train Loss: 0.6373, Train Accuracy: 70.41%, Test Loss: 1.0300, Test Accuracy: 58.23%\n",
      "Epoch [2144/2500], Train Loss: 0.6125, Train Accuracy: 71.83%, Test Loss: 1.0487, Test Accuracy: 59.49%\n",
      "Epoch [2145/2500], Train Loss: 0.6399, Train Accuracy: 70.70%, Test Loss: 1.0333, Test Accuracy: 59.49%\n",
      "Epoch [2146/2500], Train Loss: 0.6420, Train Accuracy: 72.40%, Test Loss: 1.0792, Test Accuracy: 58.23%\n",
      "Epoch [2147/2500], Train Loss: 0.6090, Train Accuracy: 72.40%, Test Loss: 1.0341, Test Accuracy: 59.49%\n",
      "Epoch [2148/2500], Train Loss: 0.6183, Train Accuracy: 72.83%, Test Loss: 1.0079, Test Accuracy: 59.49%\n",
      "Epoch [2149/2500], Train Loss: 0.6196, Train Accuracy: 71.55%, Test Loss: 1.0300, Test Accuracy: 58.23%\n",
      "Epoch [2150/2500], Train Loss: 0.6343, Train Accuracy: 70.98%, Test Loss: 1.0363, Test Accuracy: 59.49%\n",
      "Epoch [2151/2500], Train Loss: 0.6569, Train Accuracy: 70.13%, Test Loss: 1.0061, Test Accuracy: 56.96%\n",
      "Epoch [2152/2500], Train Loss: 0.6113, Train Accuracy: 72.55%, Test Loss: 1.0068, Test Accuracy: 59.49%\n",
      "Epoch [2153/2500], Train Loss: 0.6561, Train Accuracy: 71.27%, Test Loss: 0.9912, Test Accuracy: 58.23%\n",
      "Epoch [2154/2500], Train Loss: 0.6337, Train Accuracy: 72.69%, Test Loss: 1.0320, Test Accuracy: 56.96%\n",
      "Epoch [2155/2500], Train Loss: 0.6307, Train Accuracy: 72.40%, Test Loss: 1.0027, Test Accuracy: 58.23%\n",
      "Epoch [2156/2500], Train Loss: 0.6479, Train Accuracy: 71.41%, Test Loss: 1.0102, Test Accuracy: 58.23%\n",
      "Epoch [2157/2500], Train Loss: 0.6142, Train Accuracy: 72.69%, Test Loss: 0.9968, Test Accuracy: 56.96%\n",
      "Epoch [2158/2500], Train Loss: 0.6306, Train Accuracy: 71.41%, Test Loss: 1.0190, Test Accuracy: 58.23%\n",
      "Epoch [2159/2500], Train Loss: 0.6311, Train Accuracy: 70.13%, Test Loss: 1.0137, Test Accuracy: 59.49%\n",
      "Epoch [2160/2500], Train Loss: 0.6383, Train Accuracy: 71.98%, Test Loss: 1.0532, Test Accuracy: 59.49%\n",
      "Epoch [2161/2500], Train Loss: 0.6431, Train Accuracy: 72.97%, Test Loss: 1.0456, Test Accuracy: 59.49%\n",
      "Epoch [2162/2500], Train Loss: 0.6364, Train Accuracy: 71.41%, Test Loss: 1.0406, Test Accuracy: 58.23%\n",
      "Epoch [2163/2500], Train Loss: 0.6493, Train Accuracy: 71.55%, Test Loss: 1.0407, Test Accuracy: 58.23%\n",
      "Epoch [2164/2500], Train Loss: 0.6435, Train Accuracy: 69.70%, Test Loss: 1.0279, Test Accuracy: 58.23%\n",
      "Epoch [2165/2500], Train Loss: 0.6256, Train Accuracy: 71.27%, Test Loss: 1.0218, Test Accuracy: 56.96%\n",
      "Epoch [2166/2500], Train Loss: 0.6187, Train Accuracy: 73.97%, Test Loss: 1.0204, Test Accuracy: 56.96%\n",
      "Epoch [2167/2500], Train Loss: 0.6300, Train Accuracy: 70.84%, Test Loss: 1.0253, Test Accuracy: 58.23%\n",
      "Epoch [2168/2500], Train Loss: 0.6274, Train Accuracy: 73.26%, Test Loss: 1.0130, Test Accuracy: 56.96%\n",
      "Epoch [2169/2500], Train Loss: 0.6333, Train Accuracy: 72.12%, Test Loss: 1.0138, Test Accuracy: 59.49%\n",
      "Epoch [2170/2500], Train Loss: 0.6491, Train Accuracy: 71.55%, Test Loss: 1.0160, Test Accuracy: 56.96%\n",
      "Epoch [2171/2500], Train Loss: 0.5984, Train Accuracy: 72.97%, Test Loss: 1.0623, Test Accuracy: 59.49%\n",
      "Epoch [2172/2500], Train Loss: 0.6245, Train Accuracy: 73.12%, Test Loss: 1.0306, Test Accuracy: 58.23%\n",
      "Epoch [2173/2500], Train Loss: 0.6086, Train Accuracy: 72.97%, Test Loss: 1.0231, Test Accuracy: 56.96%\n",
      "Epoch [2174/2500], Train Loss: 0.6458, Train Accuracy: 71.83%, Test Loss: 0.9950, Test Accuracy: 58.23%\n",
      "Epoch [2175/2500], Train Loss: 0.6272, Train Accuracy: 72.83%, Test Loss: 1.0536, Test Accuracy: 58.23%\n",
      "Epoch [2176/2500], Train Loss: 0.6266, Train Accuracy: 70.55%, Test Loss: 1.0378, Test Accuracy: 58.23%\n",
      "Epoch [2177/2500], Train Loss: 0.6268, Train Accuracy: 73.26%, Test Loss: 1.0032, Test Accuracy: 58.23%\n",
      "Epoch [2178/2500], Train Loss: 0.6417, Train Accuracy: 71.55%, Test Loss: 1.0131, Test Accuracy: 58.23%\n",
      "Epoch [2179/2500], Train Loss: 0.6287, Train Accuracy: 72.26%, Test Loss: 1.0352, Test Accuracy: 58.23%\n",
      "Epoch [2180/2500], Train Loss: 0.6255, Train Accuracy: 71.41%, Test Loss: 1.0195, Test Accuracy: 58.23%\n",
      "Epoch [2181/2500], Train Loss: 0.6128, Train Accuracy: 73.12%, Test Loss: 1.0142, Test Accuracy: 58.23%\n",
      "Epoch [2182/2500], Train Loss: 0.6192, Train Accuracy: 72.83%, Test Loss: 0.9944, Test Accuracy: 58.23%\n",
      "Epoch [2183/2500], Train Loss: 0.6426, Train Accuracy: 70.70%, Test Loss: 1.0130, Test Accuracy: 59.49%\n",
      "Epoch [2184/2500], Train Loss: 0.6282, Train Accuracy: 70.98%, Test Loss: 1.0124, Test Accuracy: 58.23%\n",
      "Epoch [2185/2500], Train Loss: 0.6406, Train Accuracy: 73.26%, Test Loss: 1.0207, Test Accuracy: 58.23%\n",
      "Epoch [2186/2500], Train Loss: 0.6282, Train Accuracy: 72.26%, Test Loss: 1.0428, Test Accuracy: 58.23%\n",
      "Epoch [2187/2500], Train Loss: 0.6202, Train Accuracy: 72.55%, Test Loss: 1.0173, Test Accuracy: 56.96%\n",
      "Epoch [2188/2500], Train Loss: 0.6410, Train Accuracy: 71.98%, Test Loss: 1.0396, Test Accuracy: 55.70%\n",
      "Epoch [2189/2500], Train Loss: 0.6063, Train Accuracy: 73.68%, Test Loss: 1.0335, Test Accuracy: 58.23%\n",
      "Epoch [2190/2500], Train Loss: 0.6285, Train Accuracy: 72.40%, Test Loss: 1.0192, Test Accuracy: 58.23%\n",
      "Epoch [2191/2500], Train Loss: 0.6162, Train Accuracy: 71.69%, Test Loss: 1.0145, Test Accuracy: 58.23%\n",
      "Epoch [2192/2500], Train Loss: 0.6413, Train Accuracy: 72.83%, Test Loss: 1.0166, Test Accuracy: 56.96%\n",
      "Epoch [2193/2500], Train Loss: 0.6373, Train Accuracy: 71.83%, Test Loss: 1.0147, Test Accuracy: 60.76%\n",
      "Epoch [2194/2500], Train Loss: 0.6138, Train Accuracy: 72.40%, Test Loss: 1.0205, Test Accuracy: 60.76%\n",
      "Epoch [2195/2500], Train Loss: 0.6293, Train Accuracy: 72.40%, Test Loss: 1.0584, Test Accuracy: 62.03%\n",
      "Epoch [2196/2500], Train Loss: 0.6194, Train Accuracy: 71.55%, Test Loss: 1.0216, Test Accuracy: 60.76%\n",
      "Epoch [2197/2500], Train Loss: 0.6364, Train Accuracy: 72.55%, Test Loss: 0.9924, Test Accuracy: 59.49%\n",
      "Epoch [2198/2500], Train Loss: 0.6139, Train Accuracy: 73.54%, Test Loss: 1.0350, Test Accuracy: 60.76%\n",
      "Epoch [2199/2500], Train Loss: 0.6252, Train Accuracy: 73.12%, Test Loss: 1.0330, Test Accuracy: 59.49%\n",
      "Epoch [2200/2500], Train Loss: 0.6245, Train Accuracy: 73.68%, Test Loss: 1.0412, Test Accuracy: 58.23%\n",
      "Epoch [2201/2500], Train Loss: 0.6258, Train Accuracy: 72.26%, Test Loss: 1.0491, Test Accuracy: 59.49%\n",
      "Epoch [2202/2500], Train Loss: 0.6175, Train Accuracy: 72.12%, Test Loss: 1.0568, Test Accuracy: 58.23%\n",
      "Epoch [2203/2500], Train Loss: 0.6264, Train Accuracy: 71.55%, Test Loss: 1.0540, Test Accuracy: 58.23%\n",
      "Epoch [2204/2500], Train Loss: 0.6305, Train Accuracy: 73.26%, Test Loss: 1.0546, Test Accuracy: 60.76%\n",
      "Epoch [2205/2500], Train Loss: 0.6294, Train Accuracy: 71.12%, Test Loss: 1.0252, Test Accuracy: 59.49%\n",
      "Epoch [2206/2500], Train Loss: 0.6278, Train Accuracy: 72.69%, Test Loss: 0.9887, Test Accuracy: 59.49%\n",
      "Epoch [2207/2500], Train Loss: 0.6156, Train Accuracy: 72.69%, Test Loss: 1.0001, Test Accuracy: 59.49%\n",
      "Epoch [2208/2500], Train Loss: 0.6421, Train Accuracy: 71.55%, Test Loss: 1.0336, Test Accuracy: 58.23%\n",
      "Epoch [2209/2500], Train Loss: 0.6253, Train Accuracy: 71.83%, Test Loss: 1.0161, Test Accuracy: 58.23%\n",
      "Epoch [2210/2500], Train Loss: 0.6296, Train Accuracy: 71.83%, Test Loss: 1.0410, Test Accuracy: 58.23%\n",
      "Epoch [2211/2500], Train Loss: 0.6428, Train Accuracy: 72.26%, Test Loss: 1.0284, Test Accuracy: 55.70%\n",
      "Epoch [2212/2500], Train Loss: 0.6297, Train Accuracy: 71.83%, Test Loss: 1.0012, Test Accuracy: 59.49%\n",
      "Epoch [2213/2500], Train Loss: 0.6300, Train Accuracy: 73.68%, Test Loss: 1.0202, Test Accuracy: 60.76%\n",
      "Epoch [2214/2500], Train Loss: 0.6297, Train Accuracy: 72.55%, Test Loss: 1.0000, Test Accuracy: 58.23%\n",
      "Epoch [2215/2500], Train Loss: 0.6323, Train Accuracy: 71.69%, Test Loss: 1.0037, Test Accuracy: 56.96%\n",
      "Epoch [2216/2500], Train Loss: 0.6226, Train Accuracy: 72.69%, Test Loss: 1.0309, Test Accuracy: 59.49%\n",
      "Epoch [2217/2500], Train Loss: 0.6336, Train Accuracy: 71.83%, Test Loss: 1.0507, Test Accuracy: 59.49%\n",
      "Epoch [2218/2500], Train Loss: 0.6348, Train Accuracy: 71.41%, Test Loss: 1.0760, Test Accuracy: 58.23%\n",
      "Epoch [2219/2500], Train Loss: 0.6469, Train Accuracy: 71.55%, Test Loss: 1.0507, Test Accuracy: 58.23%\n",
      "Epoch [2220/2500], Train Loss: 0.6231, Train Accuracy: 73.68%, Test Loss: 1.0242, Test Accuracy: 55.70%\n",
      "Epoch [2221/2500], Train Loss: 0.6353, Train Accuracy: 72.12%, Test Loss: 1.0218, Test Accuracy: 59.49%\n",
      "Epoch [2222/2500], Train Loss: 0.5992, Train Accuracy: 73.83%, Test Loss: 1.0229, Test Accuracy: 59.49%\n",
      "Epoch [2223/2500], Train Loss: 0.6166, Train Accuracy: 73.54%, Test Loss: 1.0002, Test Accuracy: 58.23%\n",
      "Epoch [2224/2500], Train Loss: 0.6615, Train Accuracy: 71.27%, Test Loss: 1.0310, Test Accuracy: 56.96%\n",
      "Epoch [2225/2500], Train Loss: 0.6115, Train Accuracy: 71.41%, Test Loss: 1.0707, Test Accuracy: 59.49%\n",
      "Epoch [2226/2500], Train Loss: 0.6234, Train Accuracy: 72.83%, Test Loss: 1.0501, Test Accuracy: 59.49%\n",
      "Epoch [2227/2500], Train Loss: 0.6246, Train Accuracy: 70.13%, Test Loss: 1.0349, Test Accuracy: 60.76%\n",
      "Epoch [2228/2500], Train Loss: 0.6266, Train Accuracy: 72.69%, Test Loss: 1.0461, Test Accuracy: 62.03%\n",
      "Epoch [2229/2500], Train Loss: 0.6192, Train Accuracy: 72.26%, Test Loss: 1.0370, Test Accuracy: 55.70%\n",
      "Epoch [2230/2500], Train Loss: 0.6066, Train Accuracy: 73.26%, Test Loss: 1.0320, Test Accuracy: 59.49%\n",
      "Epoch [2231/2500], Train Loss: 0.6051, Train Accuracy: 73.83%, Test Loss: 1.0273, Test Accuracy: 59.49%\n",
      "Epoch [2232/2500], Train Loss: 0.6525, Train Accuracy: 71.41%, Test Loss: 1.0431, Test Accuracy: 60.76%\n",
      "Epoch [2233/2500], Train Loss: 0.6293, Train Accuracy: 72.40%, Test Loss: 1.0100, Test Accuracy: 63.29%\n",
      "Epoch [2234/2500], Train Loss: 0.6270, Train Accuracy: 73.97%, Test Loss: 1.0148, Test Accuracy: 60.76%\n",
      "Epoch [2235/2500], Train Loss: 0.6265, Train Accuracy: 71.98%, Test Loss: 1.0033, Test Accuracy: 60.76%\n",
      "Epoch [2236/2500], Train Loss: 0.6251, Train Accuracy: 72.69%, Test Loss: 0.9994, Test Accuracy: 58.23%\n",
      "Epoch [2237/2500], Train Loss: 0.5991, Train Accuracy: 73.54%, Test Loss: 1.0273, Test Accuracy: 59.49%\n",
      "Epoch [2238/2500], Train Loss: 0.6307, Train Accuracy: 70.55%, Test Loss: 1.0190, Test Accuracy: 58.23%\n",
      "Epoch [2239/2500], Train Loss: 0.6275, Train Accuracy: 72.26%, Test Loss: 1.0119, Test Accuracy: 59.49%\n",
      "Epoch [2240/2500], Train Loss: 0.6254, Train Accuracy: 71.98%, Test Loss: 1.0496, Test Accuracy: 59.49%\n",
      "Epoch [2241/2500], Train Loss: 0.6112, Train Accuracy: 73.68%, Test Loss: 1.0060, Test Accuracy: 60.76%\n",
      "Epoch [2242/2500], Train Loss: 0.6502, Train Accuracy: 71.55%, Test Loss: 0.9959, Test Accuracy: 60.76%\n",
      "Epoch [2243/2500], Train Loss: 0.6195, Train Accuracy: 72.97%, Test Loss: 1.0245, Test Accuracy: 59.49%\n",
      "Epoch [2244/2500], Train Loss: 0.6041, Train Accuracy: 73.97%, Test Loss: 1.0375, Test Accuracy: 60.76%\n",
      "Epoch [2245/2500], Train Loss: 0.5940, Train Accuracy: 73.54%, Test Loss: 1.0182, Test Accuracy: 62.03%\n",
      "Epoch [2246/2500], Train Loss: 0.6253, Train Accuracy: 73.97%, Test Loss: 0.9975, Test Accuracy: 59.49%\n",
      "Epoch [2247/2500], Train Loss: 0.6458, Train Accuracy: 71.12%, Test Loss: 1.0071, Test Accuracy: 60.76%\n",
      "Epoch [2248/2500], Train Loss: 0.6013, Train Accuracy: 72.83%, Test Loss: 1.0148, Test Accuracy: 60.76%\n",
      "Epoch [2249/2500], Train Loss: 0.6467, Train Accuracy: 71.41%, Test Loss: 1.0354, Test Accuracy: 60.76%\n",
      "Epoch [2250/2500], Train Loss: 0.5937, Train Accuracy: 73.97%, Test Loss: 1.0559, Test Accuracy: 58.23%\n",
      "Epoch [2251/2500], Train Loss: 0.6334, Train Accuracy: 70.98%, Test Loss: 1.0720, Test Accuracy: 56.96%\n",
      "Epoch [2252/2500], Train Loss: 0.6163, Train Accuracy: 72.83%, Test Loss: 1.0246, Test Accuracy: 59.49%\n",
      "Epoch [2253/2500], Train Loss: 0.6120, Train Accuracy: 72.12%, Test Loss: 1.0756, Test Accuracy: 56.96%\n",
      "Epoch [2254/2500], Train Loss: 0.6220, Train Accuracy: 73.97%, Test Loss: 1.0543, Test Accuracy: 55.70%\n",
      "Epoch [2255/2500], Train Loss: 0.6176, Train Accuracy: 71.98%, Test Loss: 1.0821, Test Accuracy: 58.23%\n",
      "Epoch [2256/2500], Train Loss: 0.6422, Train Accuracy: 72.40%, Test Loss: 1.0317, Test Accuracy: 59.49%\n",
      "Epoch [2257/2500], Train Loss: 0.6238, Train Accuracy: 71.98%, Test Loss: 1.0574, Test Accuracy: 59.49%\n",
      "Epoch [2258/2500], Train Loss: 0.6214, Train Accuracy: 72.12%, Test Loss: 1.0868, Test Accuracy: 58.23%\n",
      "Epoch [2259/2500], Train Loss: 0.6254, Train Accuracy: 71.41%, Test Loss: 1.0547, Test Accuracy: 60.76%\n",
      "Epoch [2260/2500], Train Loss: 0.6266, Train Accuracy: 72.26%, Test Loss: 1.0592, Test Accuracy: 59.49%\n",
      "Epoch [2261/2500], Train Loss: 0.6177, Train Accuracy: 74.40%, Test Loss: 1.0487, Test Accuracy: 58.23%\n",
      "Epoch [2262/2500], Train Loss: 0.6029, Train Accuracy: 72.55%, Test Loss: 1.0298, Test Accuracy: 60.76%\n",
      "Epoch [2263/2500], Train Loss: 0.6252, Train Accuracy: 72.69%, Test Loss: 1.0254, Test Accuracy: 60.76%\n",
      "Epoch [2264/2500], Train Loss: 0.6125, Train Accuracy: 70.98%, Test Loss: 1.0501, Test Accuracy: 58.23%\n",
      "Epoch [2265/2500], Train Loss: 0.6316, Train Accuracy: 72.12%, Test Loss: 1.0565, Test Accuracy: 56.96%\n",
      "Epoch [2266/2500], Train Loss: 0.6010, Train Accuracy: 74.82%, Test Loss: 1.1370, Test Accuracy: 56.96%\n",
      "Epoch [2267/2500], Train Loss: 0.6239, Train Accuracy: 73.68%, Test Loss: 1.0739, Test Accuracy: 55.70%\n",
      "Epoch [2268/2500], Train Loss: 0.6141, Train Accuracy: 71.27%, Test Loss: 1.0510, Test Accuracy: 59.49%\n",
      "Epoch [2269/2500], Train Loss: 0.6367, Train Accuracy: 72.12%, Test Loss: 1.0721, Test Accuracy: 60.76%\n",
      "Epoch [2270/2500], Train Loss: 0.6203, Train Accuracy: 72.83%, Test Loss: 1.0395, Test Accuracy: 59.49%\n",
      "Epoch [2271/2500], Train Loss: 0.6360, Train Accuracy: 72.26%, Test Loss: 1.0279, Test Accuracy: 58.23%\n",
      "Epoch [2272/2500], Train Loss: 0.6288, Train Accuracy: 71.98%, Test Loss: 1.0886, Test Accuracy: 59.49%\n",
      "Epoch [2273/2500], Train Loss: 0.6261, Train Accuracy: 72.40%, Test Loss: 1.0625, Test Accuracy: 59.49%\n",
      "Epoch [2274/2500], Train Loss: 0.6270, Train Accuracy: 71.27%, Test Loss: 1.0779, Test Accuracy: 59.49%\n",
      "Epoch [2275/2500], Train Loss: 0.6174, Train Accuracy: 72.55%, Test Loss: 1.0438, Test Accuracy: 59.49%\n",
      "Epoch [2276/2500], Train Loss: 0.6186, Train Accuracy: 70.70%, Test Loss: 1.0314, Test Accuracy: 58.23%\n",
      "Epoch [2277/2500], Train Loss: 0.6320, Train Accuracy: 72.55%, Test Loss: 1.0363, Test Accuracy: 59.49%\n",
      "Epoch [2278/2500], Train Loss: 0.6101, Train Accuracy: 72.12%, Test Loss: 1.0736, Test Accuracy: 56.96%\n",
      "Epoch [2279/2500], Train Loss: 0.6028, Train Accuracy: 72.97%, Test Loss: 1.0254, Test Accuracy: 59.49%\n",
      "Epoch [2280/2500], Train Loss: 0.6291, Train Accuracy: 72.55%, Test Loss: 1.0253, Test Accuracy: 58.23%\n",
      "Epoch [2281/2500], Train Loss: 0.6454, Train Accuracy: 71.12%, Test Loss: 1.0574, Test Accuracy: 59.49%\n",
      "Epoch [2282/2500], Train Loss: 0.6377, Train Accuracy: 73.97%, Test Loss: 1.0345, Test Accuracy: 59.49%\n",
      "Epoch [2283/2500], Train Loss: 0.6106, Train Accuracy: 71.27%, Test Loss: 1.0367, Test Accuracy: 60.76%\n",
      "Epoch [2284/2500], Train Loss: 0.6148, Train Accuracy: 72.83%, Test Loss: 1.0622, Test Accuracy: 58.23%\n",
      "Epoch [2285/2500], Train Loss: 0.6282, Train Accuracy: 71.98%, Test Loss: 1.0409, Test Accuracy: 58.23%\n",
      "Epoch [2286/2500], Train Loss: 0.6382, Train Accuracy: 73.97%, Test Loss: 1.0481, Test Accuracy: 59.49%\n",
      "Epoch [2287/2500], Train Loss: 0.6317, Train Accuracy: 72.83%, Test Loss: 1.0169, Test Accuracy: 60.76%\n",
      "Epoch [2288/2500], Train Loss: 0.6332, Train Accuracy: 71.55%, Test Loss: 1.0414, Test Accuracy: 58.23%\n",
      "Epoch [2289/2500], Train Loss: 0.6110, Train Accuracy: 75.39%, Test Loss: 1.0154, Test Accuracy: 62.03%\n",
      "Epoch [2290/2500], Train Loss: 0.6350, Train Accuracy: 71.41%, Test Loss: 1.0307, Test Accuracy: 60.76%\n",
      "Epoch [2291/2500], Train Loss: 0.6292, Train Accuracy: 71.98%, Test Loss: 1.0231, Test Accuracy: 60.76%\n",
      "Epoch [2292/2500], Train Loss: 0.6104, Train Accuracy: 73.97%, Test Loss: 1.0382, Test Accuracy: 60.76%\n",
      "Epoch [2293/2500], Train Loss: 0.6143, Train Accuracy: 72.26%, Test Loss: 1.0610, Test Accuracy: 59.49%\n",
      "Epoch [2294/2500], Train Loss: 0.6226, Train Accuracy: 72.12%, Test Loss: 1.0585, Test Accuracy: 60.76%\n",
      "Epoch [2295/2500], Train Loss: 0.6360, Train Accuracy: 74.11%, Test Loss: 1.0614, Test Accuracy: 58.23%\n",
      "Epoch [2296/2500], Train Loss: 0.6227, Train Accuracy: 71.41%, Test Loss: 1.0469, Test Accuracy: 58.23%\n",
      "Epoch [2297/2500], Train Loss: 0.6108, Train Accuracy: 74.40%, Test Loss: 1.0258, Test Accuracy: 60.76%\n",
      "Epoch [2298/2500], Train Loss: 0.6202, Train Accuracy: 73.83%, Test Loss: 1.0308, Test Accuracy: 58.23%\n",
      "Epoch [2299/2500], Train Loss: 0.6084, Train Accuracy: 74.82%, Test Loss: 1.0274, Test Accuracy: 59.49%\n",
      "Epoch [2300/2500], Train Loss: 0.6171, Train Accuracy: 72.40%, Test Loss: 1.0409, Test Accuracy: 59.49%\n",
      "Epoch [2301/2500], Train Loss: 0.6588, Train Accuracy: 70.41%, Test Loss: 1.0198, Test Accuracy: 56.96%\n",
      "Epoch [2302/2500], Train Loss: 0.5902, Train Accuracy: 72.83%, Test Loss: 1.0125, Test Accuracy: 58.23%\n",
      "Epoch [2303/2500], Train Loss: 0.6291, Train Accuracy: 71.55%, Test Loss: 1.0373, Test Accuracy: 58.23%\n",
      "Epoch [2304/2500], Train Loss: 0.6246, Train Accuracy: 71.27%, Test Loss: 1.0477, Test Accuracy: 60.76%\n",
      "Epoch [2305/2500], Train Loss: 0.6181, Train Accuracy: 72.83%, Test Loss: 1.0534, Test Accuracy: 60.76%\n",
      "Epoch [2306/2500], Train Loss: 0.6182, Train Accuracy: 71.98%, Test Loss: 1.0556, Test Accuracy: 58.23%\n",
      "Epoch [2307/2500], Train Loss: 0.6361, Train Accuracy: 72.69%, Test Loss: 1.0310, Test Accuracy: 62.03%\n",
      "Epoch [2308/2500], Train Loss: 0.6035, Train Accuracy: 74.25%, Test Loss: 1.0632, Test Accuracy: 60.76%\n",
      "Epoch [2309/2500], Train Loss: 0.6185, Train Accuracy: 72.12%, Test Loss: 1.0448, Test Accuracy: 58.23%\n",
      "Epoch [2310/2500], Train Loss: 0.6291, Train Accuracy: 72.97%, Test Loss: 1.0517, Test Accuracy: 59.49%\n",
      "Epoch [2311/2500], Train Loss: 0.6216, Train Accuracy: 72.26%, Test Loss: 1.0526, Test Accuracy: 58.23%\n",
      "Epoch [2312/2500], Train Loss: 0.6294, Train Accuracy: 73.26%, Test Loss: 1.0573, Test Accuracy: 60.76%\n",
      "Epoch [2313/2500], Train Loss: 0.6442, Train Accuracy: 72.55%, Test Loss: 1.0143, Test Accuracy: 59.49%\n",
      "Epoch [2314/2500], Train Loss: 0.6381, Train Accuracy: 71.55%, Test Loss: 1.0149, Test Accuracy: 59.49%\n",
      "Epoch [2315/2500], Train Loss: 0.6145, Train Accuracy: 73.26%, Test Loss: 1.0455, Test Accuracy: 59.49%\n",
      "Epoch [2316/2500], Train Loss: 0.6333, Train Accuracy: 71.98%, Test Loss: 0.9979, Test Accuracy: 62.03%\n",
      "Epoch [2317/2500], Train Loss: 0.6186, Train Accuracy: 73.97%, Test Loss: 1.0132, Test Accuracy: 59.49%\n",
      "Epoch [2318/2500], Train Loss: 0.6203, Train Accuracy: 74.54%, Test Loss: 1.0195, Test Accuracy: 60.76%\n",
      "Epoch [2319/2500], Train Loss: 0.6197, Train Accuracy: 73.40%, Test Loss: 1.0337, Test Accuracy: 60.76%\n",
      "Epoch [2320/2500], Train Loss: 0.6164, Train Accuracy: 71.12%, Test Loss: 1.0094, Test Accuracy: 59.49%\n",
      "Epoch [2321/2500], Train Loss: 0.6210, Train Accuracy: 72.55%, Test Loss: 1.0010, Test Accuracy: 56.96%\n",
      "Epoch [2322/2500], Train Loss: 0.6277, Train Accuracy: 74.68%, Test Loss: 0.9945, Test Accuracy: 59.49%\n",
      "Epoch [2323/2500], Train Loss: 0.6217, Train Accuracy: 73.26%, Test Loss: 1.0368, Test Accuracy: 59.49%\n",
      "Epoch [2324/2500], Train Loss: 0.6120, Train Accuracy: 72.97%, Test Loss: 1.0594, Test Accuracy: 59.49%\n",
      "Epoch [2325/2500], Train Loss: 0.6115, Train Accuracy: 72.69%, Test Loss: 1.0276, Test Accuracy: 56.96%\n",
      "Epoch [2326/2500], Train Loss: 0.6182, Train Accuracy: 73.12%, Test Loss: 1.0100, Test Accuracy: 56.96%\n",
      "Epoch [2327/2500], Train Loss: 0.6252, Train Accuracy: 72.97%, Test Loss: 1.0149, Test Accuracy: 56.96%\n",
      "Epoch [2328/2500], Train Loss: 0.6112, Train Accuracy: 72.26%, Test Loss: 1.0067, Test Accuracy: 62.03%\n",
      "Epoch [2329/2500], Train Loss: 0.5998, Train Accuracy: 73.12%, Test Loss: 1.0208, Test Accuracy: 60.76%\n",
      "Epoch [2330/2500], Train Loss: 0.6163, Train Accuracy: 71.83%, Test Loss: 1.0172, Test Accuracy: 60.76%\n",
      "Epoch [2331/2500], Train Loss: 0.6298, Train Accuracy: 71.27%, Test Loss: 1.0456, Test Accuracy: 58.23%\n",
      "Epoch [2332/2500], Train Loss: 0.6233, Train Accuracy: 72.97%, Test Loss: 1.0336, Test Accuracy: 59.49%\n",
      "Epoch [2333/2500], Train Loss: 0.6099, Train Accuracy: 71.27%, Test Loss: 1.0084, Test Accuracy: 62.03%\n",
      "Epoch [2334/2500], Train Loss: 0.6259, Train Accuracy: 71.41%, Test Loss: 1.0124, Test Accuracy: 60.76%\n",
      "Epoch [2335/2500], Train Loss: 0.6159, Train Accuracy: 73.54%, Test Loss: 1.0329, Test Accuracy: 60.76%\n",
      "Epoch [2336/2500], Train Loss: 0.6291, Train Accuracy: 72.40%, Test Loss: 0.9832, Test Accuracy: 59.49%\n",
      "Epoch [2337/2500], Train Loss: 0.5887, Train Accuracy: 74.68%, Test Loss: 1.0094, Test Accuracy: 59.49%\n",
      "Epoch [2338/2500], Train Loss: 0.6305, Train Accuracy: 71.83%, Test Loss: 1.0360, Test Accuracy: 59.49%\n",
      "Epoch [2339/2500], Train Loss: 0.6135, Train Accuracy: 71.98%, Test Loss: 1.0351, Test Accuracy: 58.23%\n",
      "Epoch [2340/2500], Train Loss: 0.6050, Train Accuracy: 73.97%, Test Loss: 1.0527, Test Accuracy: 56.96%\n",
      "Epoch [2341/2500], Train Loss: 0.6352, Train Accuracy: 71.55%, Test Loss: 1.0087, Test Accuracy: 62.03%\n",
      "Epoch [2342/2500], Train Loss: 0.5974, Train Accuracy: 74.96%, Test Loss: 1.0178, Test Accuracy: 56.96%\n",
      "Epoch [2343/2500], Train Loss: 0.6202, Train Accuracy: 73.68%, Test Loss: 1.0254, Test Accuracy: 59.49%\n",
      "Epoch [2344/2500], Train Loss: 0.6162, Train Accuracy: 74.40%, Test Loss: 1.0367, Test Accuracy: 62.03%\n",
      "Epoch [2345/2500], Train Loss: 0.6388, Train Accuracy: 71.83%, Test Loss: 1.0201, Test Accuracy: 60.76%\n",
      "Epoch [2346/2500], Train Loss: 0.6227, Train Accuracy: 73.12%, Test Loss: 1.0201, Test Accuracy: 59.49%\n",
      "Epoch [2347/2500], Train Loss: 0.5875, Train Accuracy: 72.97%, Test Loss: 1.0183, Test Accuracy: 60.76%\n",
      "Epoch [2348/2500], Train Loss: 0.5947, Train Accuracy: 74.40%, Test Loss: 1.0516, Test Accuracy: 59.49%\n",
      "Epoch [2349/2500], Train Loss: 0.5959, Train Accuracy: 74.82%, Test Loss: 1.0829, Test Accuracy: 59.49%\n",
      "Epoch [2350/2500], Train Loss: 0.6059, Train Accuracy: 72.69%, Test Loss: 1.0611, Test Accuracy: 60.76%\n",
      "Epoch [2351/2500], Train Loss: 0.6324, Train Accuracy: 73.40%, Test Loss: 1.0621, Test Accuracy: 60.76%\n",
      "Epoch [2352/2500], Train Loss: 0.6297, Train Accuracy: 74.40%, Test Loss: 1.0211, Test Accuracy: 59.49%\n",
      "Epoch [2353/2500], Train Loss: 0.6162, Train Accuracy: 71.83%, Test Loss: 1.0476, Test Accuracy: 59.49%\n",
      "Epoch [2354/2500], Train Loss: 0.6113, Train Accuracy: 73.68%, Test Loss: 1.0367, Test Accuracy: 59.49%\n",
      "Epoch [2355/2500], Train Loss: 0.6117, Train Accuracy: 73.12%, Test Loss: 1.0358, Test Accuracy: 60.76%\n",
      "Epoch [2356/2500], Train Loss: 0.6223, Train Accuracy: 72.26%, Test Loss: 1.0298, Test Accuracy: 62.03%\n",
      "Epoch [2357/2500], Train Loss: 0.6177, Train Accuracy: 73.68%, Test Loss: 1.0461, Test Accuracy: 59.49%\n",
      "Epoch [2358/2500], Train Loss: 0.6257, Train Accuracy: 71.55%, Test Loss: 1.0525, Test Accuracy: 59.49%\n",
      "Epoch [2359/2500], Train Loss: 0.6122, Train Accuracy: 74.25%, Test Loss: 1.0591, Test Accuracy: 58.23%\n",
      "Epoch [2360/2500], Train Loss: 0.6063, Train Accuracy: 71.69%, Test Loss: 1.0492, Test Accuracy: 58.23%\n",
      "Epoch [2361/2500], Train Loss: 0.6058, Train Accuracy: 71.98%, Test Loss: 1.0737, Test Accuracy: 58.23%\n",
      "Epoch [2362/2500], Train Loss: 0.6323, Train Accuracy: 71.12%, Test Loss: 1.0532, Test Accuracy: 60.76%\n",
      "Epoch [2363/2500], Train Loss: 0.6271, Train Accuracy: 73.40%, Test Loss: 1.0395, Test Accuracy: 59.49%\n",
      "Epoch [2364/2500], Train Loss: 0.6181, Train Accuracy: 74.11%, Test Loss: 1.0444, Test Accuracy: 60.76%\n",
      "Epoch [2365/2500], Train Loss: 0.6247, Train Accuracy: 70.84%, Test Loss: 1.0375, Test Accuracy: 59.49%\n",
      "Epoch [2366/2500], Train Loss: 0.6242, Train Accuracy: 73.26%, Test Loss: 1.0816, Test Accuracy: 59.49%\n",
      "Epoch [2367/2500], Train Loss: 0.6206, Train Accuracy: 71.98%, Test Loss: 1.0394, Test Accuracy: 59.49%\n",
      "Epoch [2368/2500], Train Loss: 0.6267, Train Accuracy: 72.55%, Test Loss: 1.0814, Test Accuracy: 56.96%\n",
      "Epoch [2369/2500], Train Loss: 0.6313, Train Accuracy: 72.69%, Test Loss: 1.0751, Test Accuracy: 55.70%\n",
      "Epoch [2370/2500], Train Loss: 0.6015, Train Accuracy: 72.55%, Test Loss: 1.1015, Test Accuracy: 59.49%\n",
      "Epoch [2371/2500], Train Loss: 0.6302, Train Accuracy: 72.83%, Test Loss: 1.0667, Test Accuracy: 59.49%\n",
      "Epoch [2372/2500], Train Loss: 0.6045, Train Accuracy: 71.41%, Test Loss: 1.0568, Test Accuracy: 56.96%\n",
      "Epoch [2373/2500], Train Loss: 0.6135, Train Accuracy: 72.83%, Test Loss: 1.0580, Test Accuracy: 56.96%\n",
      "Epoch [2374/2500], Train Loss: 0.6181, Train Accuracy: 73.40%, Test Loss: 1.0939, Test Accuracy: 58.23%\n",
      "Epoch [2375/2500], Train Loss: 0.6119, Train Accuracy: 74.40%, Test Loss: 1.0844, Test Accuracy: 58.23%\n",
      "Epoch [2376/2500], Train Loss: 0.6078, Train Accuracy: 70.98%, Test Loss: 1.0912, Test Accuracy: 58.23%\n",
      "Epoch [2377/2500], Train Loss: 0.6310, Train Accuracy: 72.69%, Test Loss: 1.0626, Test Accuracy: 56.96%\n",
      "Epoch [2378/2500], Train Loss: 0.6090, Train Accuracy: 73.40%, Test Loss: 1.0693, Test Accuracy: 58.23%\n",
      "Epoch [2379/2500], Train Loss: 0.5845, Train Accuracy: 75.25%, Test Loss: 1.0747, Test Accuracy: 59.49%\n",
      "Epoch [2380/2500], Train Loss: 0.6185, Train Accuracy: 73.26%, Test Loss: 1.0800, Test Accuracy: 56.96%\n",
      "Epoch [2381/2500], Train Loss: 0.6206, Train Accuracy: 74.25%, Test Loss: 1.0786, Test Accuracy: 56.96%\n",
      "Epoch [2382/2500], Train Loss: 0.6026, Train Accuracy: 72.40%, Test Loss: 1.0738, Test Accuracy: 58.23%\n",
      "Epoch [2383/2500], Train Loss: 0.6028, Train Accuracy: 74.54%, Test Loss: 1.0364, Test Accuracy: 56.96%\n",
      "Epoch [2384/2500], Train Loss: 0.6128, Train Accuracy: 71.83%, Test Loss: 1.0492, Test Accuracy: 59.49%\n",
      "Epoch [2385/2500], Train Loss: 0.6105, Train Accuracy: 74.68%, Test Loss: 1.0413, Test Accuracy: 56.96%\n",
      "Epoch [2386/2500], Train Loss: 0.6015, Train Accuracy: 73.40%, Test Loss: 1.0620, Test Accuracy: 59.49%\n",
      "Epoch [2387/2500], Train Loss: 0.6189, Train Accuracy: 73.54%, Test Loss: 1.0816, Test Accuracy: 56.96%\n",
      "Epoch [2388/2500], Train Loss: 0.6247, Train Accuracy: 71.55%, Test Loss: 1.0712, Test Accuracy: 56.96%\n",
      "Epoch [2389/2500], Train Loss: 0.6057, Train Accuracy: 74.11%, Test Loss: 1.0592, Test Accuracy: 58.23%\n",
      "Epoch [2390/2500], Train Loss: 0.6230, Train Accuracy: 71.41%, Test Loss: 1.0745, Test Accuracy: 58.23%\n",
      "Epoch [2391/2500], Train Loss: 0.5943, Train Accuracy: 75.25%, Test Loss: 1.0647, Test Accuracy: 56.96%\n",
      "Epoch [2392/2500], Train Loss: 0.6390, Train Accuracy: 71.83%, Test Loss: 1.0712, Test Accuracy: 60.76%\n",
      "Epoch [2393/2500], Train Loss: 0.6171, Train Accuracy: 71.69%, Test Loss: 1.0630, Test Accuracy: 59.49%\n",
      "Epoch [2394/2500], Train Loss: 0.6083, Train Accuracy: 73.97%, Test Loss: 1.0475, Test Accuracy: 62.03%\n",
      "Epoch [2395/2500], Train Loss: 0.6276, Train Accuracy: 71.55%, Test Loss: 1.0598, Test Accuracy: 59.49%\n",
      "Epoch [2396/2500], Train Loss: 0.6058, Train Accuracy: 72.55%, Test Loss: 1.1055, Test Accuracy: 59.49%\n",
      "Epoch [2397/2500], Train Loss: 0.6075, Train Accuracy: 73.54%, Test Loss: 1.0743, Test Accuracy: 58.23%\n",
      "Epoch [2398/2500], Train Loss: 0.6133, Train Accuracy: 73.54%, Test Loss: 1.0548, Test Accuracy: 60.76%\n",
      "Epoch [2399/2500], Train Loss: 0.6397, Train Accuracy: 73.26%, Test Loss: 1.0525, Test Accuracy: 59.49%\n",
      "Epoch [2400/2500], Train Loss: 0.6284, Train Accuracy: 73.83%, Test Loss: 1.0569, Test Accuracy: 59.49%\n",
      "Epoch [2401/2500], Train Loss: 0.6076, Train Accuracy: 73.40%, Test Loss: 1.0599, Test Accuracy: 56.96%\n",
      "Epoch [2402/2500], Train Loss: 0.6396, Train Accuracy: 72.26%, Test Loss: 1.0674, Test Accuracy: 59.49%\n",
      "Epoch [2403/2500], Train Loss: 0.6285, Train Accuracy: 71.69%, Test Loss: 1.0908, Test Accuracy: 59.49%\n",
      "Epoch [2404/2500], Train Loss: 0.6043, Train Accuracy: 73.40%, Test Loss: 1.0609, Test Accuracy: 60.76%\n",
      "Epoch [2405/2500], Train Loss: 0.6149, Train Accuracy: 74.25%, Test Loss: 1.0534, Test Accuracy: 60.76%\n",
      "Epoch [2406/2500], Train Loss: 0.6037, Train Accuracy: 73.68%, Test Loss: 1.0554, Test Accuracy: 59.49%\n",
      "Epoch [2407/2500], Train Loss: 0.5855, Train Accuracy: 75.25%, Test Loss: 1.0714, Test Accuracy: 60.76%\n",
      "Epoch [2408/2500], Train Loss: 0.6322, Train Accuracy: 71.41%, Test Loss: 1.0634, Test Accuracy: 59.49%\n",
      "Epoch [2409/2500], Train Loss: 0.6071, Train Accuracy: 73.26%, Test Loss: 1.0908, Test Accuracy: 58.23%\n",
      "Epoch [2410/2500], Train Loss: 0.5910, Train Accuracy: 75.11%, Test Loss: 1.0999, Test Accuracy: 56.96%\n",
      "Epoch [2411/2500], Train Loss: 0.6249, Train Accuracy: 71.12%, Test Loss: 1.0784, Test Accuracy: 56.96%\n",
      "Epoch [2412/2500], Train Loss: 0.6085, Train Accuracy: 73.12%, Test Loss: 1.0663, Test Accuracy: 60.76%\n",
      "Epoch [2413/2500], Train Loss: 0.6077, Train Accuracy: 73.12%, Test Loss: 1.1014, Test Accuracy: 58.23%\n",
      "Epoch [2414/2500], Train Loss: 0.5881, Train Accuracy: 74.11%, Test Loss: 1.0968, Test Accuracy: 58.23%\n",
      "Epoch [2415/2500], Train Loss: 0.6217, Train Accuracy: 72.69%, Test Loss: 1.1031, Test Accuracy: 58.23%\n",
      "Epoch [2416/2500], Train Loss: 0.6054, Train Accuracy: 73.68%, Test Loss: 1.0984, Test Accuracy: 56.96%\n",
      "Epoch [2417/2500], Train Loss: 0.6084, Train Accuracy: 72.55%, Test Loss: 1.0553, Test Accuracy: 59.49%\n",
      "Epoch [2418/2500], Train Loss: 0.6250, Train Accuracy: 72.55%, Test Loss: 1.0868, Test Accuracy: 59.49%\n",
      "Epoch [2419/2500], Train Loss: 0.6131, Train Accuracy: 73.97%, Test Loss: 1.0633, Test Accuracy: 60.76%\n",
      "Epoch [2420/2500], Train Loss: 0.6052, Train Accuracy: 73.26%, Test Loss: 1.0784, Test Accuracy: 58.23%\n",
      "Epoch [2421/2500], Train Loss: 0.6015, Train Accuracy: 72.83%, Test Loss: 1.0517, Test Accuracy: 58.23%\n",
      "Epoch [2422/2500], Train Loss: 0.6158, Train Accuracy: 72.12%, Test Loss: 1.0464, Test Accuracy: 58.23%\n",
      "Epoch [2423/2500], Train Loss: 0.6173, Train Accuracy: 73.68%, Test Loss: 1.0837, Test Accuracy: 56.96%\n",
      "Epoch [2424/2500], Train Loss: 0.6135, Train Accuracy: 73.40%, Test Loss: 1.0552, Test Accuracy: 59.49%\n",
      "Epoch [2425/2500], Train Loss: 0.6276, Train Accuracy: 72.97%, Test Loss: 1.0682, Test Accuracy: 59.49%\n",
      "Epoch [2426/2500], Train Loss: 0.6080, Train Accuracy: 72.83%, Test Loss: 1.0798, Test Accuracy: 59.49%\n",
      "Epoch [2427/2500], Train Loss: 0.5976, Train Accuracy: 73.97%, Test Loss: 1.0541, Test Accuracy: 59.49%\n",
      "Epoch [2428/2500], Train Loss: 0.6154, Train Accuracy: 72.26%, Test Loss: 1.0780, Test Accuracy: 59.49%\n",
      "Epoch [2429/2500], Train Loss: 0.5976, Train Accuracy: 72.40%, Test Loss: 1.0901, Test Accuracy: 60.76%\n",
      "Epoch [2430/2500], Train Loss: 0.6167, Train Accuracy: 72.40%, Test Loss: 1.0471, Test Accuracy: 59.49%\n",
      "Epoch [2431/2500], Train Loss: 0.6291, Train Accuracy: 71.83%, Test Loss: 1.0463, Test Accuracy: 60.76%\n",
      "Epoch [2432/2500], Train Loss: 0.6119, Train Accuracy: 74.11%, Test Loss: 1.0435, Test Accuracy: 59.49%\n",
      "Epoch [2433/2500], Train Loss: 0.6140, Train Accuracy: 72.55%, Test Loss: 1.0451, Test Accuracy: 58.23%\n",
      "Epoch [2434/2500], Train Loss: 0.5979, Train Accuracy: 73.40%, Test Loss: 1.0379, Test Accuracy: 59.49%\n",
      "Epoch [2435/2500], Train Loss: 0.6168, Train Accuracy: 72.12%, Test Loss: 1.0322, Test Accuracy: 56.96%\n",
      "Epoch [2436/2500], Train Loss: 0.6081, Train Accuracy: 73.83%, Test Loss: 1.0952, Test Accuracy: 58.23%\n",
      "Epoch [2437/2500], Train Loss: 0.6241, Train Accuracy: 70.84%, Test Loss: 1.0521, Test Accuracy: 59.49%\n",
      "Epoch [2438/2500], Train Loss: 0.6311, Train Accuracy: 72.40%, Test Loss: 1.0831, Test Accuracy: 56.96%\n",
      "Epoch [2439/2500], Train Loss: 0.6274, Train Accuracy: 72.97%, Test Loss: 1.1080, Test Accuracy: 56.96%\n",
      "Epoch [2440/2500], Train Loss: 0.5978, Train Accuracy: 72.12%, Test Loss: 1.0866, Test Accuracy: 56.96%\n",
      "Epoch [2441/2500], Train Loss: 0.6093, Train Accuracy: 71.83%, Test Loss: 1.0989, Test Accuracy: 59.49%\n",
      "Epoch [2442/2500], Train Loss: 0.6056, Train Accuracy: 72.26%, Test Loss: 1.0511, Test Accuracy: 56.96%\n",
      "Epoch [2443/2500], Train Loss: 0.6118, Train Accuracy: 71.27%, Test Loss: 1.0520, Test Accuracy: 55.70%\n",
      "Epoch [2444/2500], Train Loss: 0.5998, Train Accuracy: 73.54%, Test Loss: 1.0886, Test Accuracy: 56.96%\n",
      "Epoch [2445/2500], Train Loss: 0.5913, Train Accuracy: 73.12%, Test Loss: 1.0514, Test Accuracy: 59.49%\n",
      "Epoch [2446/2500], Train Loss: 0.5893, Train Accuracy: 73.97%, Test Loss: 1.0735, Test Accuracy: 58.23%\n",
      "Epoch [2447/2500], Train Loss: 0.6192, Train Accuracy: 74.11%, Test Loss: 1.0629, Test Accuracy: 56.96%\n",
      "Epoch [2448/2500], Train Loss: 0.6154, Train Accuracy: 74.82%, Test Loss: 1.0238, Test Accuracy: 60.76%\n",
      "Epoch [2449/2500], Train Loss: 0.6336, Train Accuracy: 72.55%, Test Loss: 1.0611, Test Accuracy: 59.49%\n",
      "Epoch [2450/2500], Train Loss: 0.6089, Train Accuracy: 73.26%, Test Loss: 1.0590, Test Accuracy: 56.96%\n",
      "Epoch [2451/2500], Train Loss: 0.5991, Train Accuracy: 74.11%, Test Loss: 1.0905, Test Accuracy: 59.49%\n",
      "Epoch [2452/2500], Train Loss: 0.6159, Train Accuracy: 74.25%, Test Loss: 1.0663, Test Accuracy: 59.49%\n",
      "Epoch [2453/2500], Train Loss: 0.6191, Train Accuracy: 73.97%, Test Loss: 1.0372, Test Accuracy: 56.96%\n",
      "Epoch [2454/2500], Train Loss: 0.6247, Train Accuracy: 74.40%, Test Loss: 1.0307, Test Accuracy: 56.96%\n",
      "Epoch [2455/2500], Train Loss: 0.5869, Train Accuracy: 75.11%, Test Loss: 1.0900, Test Accuracy: 59.49%\n",
      "Epoch [2456/2500], Train Loss: 0.6182, Train Accuracy: 71.27%, Test Loss: 1.0592, Test Accuracy: 58.23%\n",
      "Epoch [2457/2500], Train Loss: 0.6068, Train Accuracy: 73.40%, Test Loss: 1.0435, Test Accuracy: 58.23%\n",
      "Epoch [2458/2500], Train Loss: 0.6023, Train Accuracy: 72.97%, Test Loss: 1.0576, Test Accuracy: 56.96%\n",
      "Epoch [2459/2500], Train Loss: 0.5945, Train Accuracy: 74.11%, Test Loss: 1.0605, Test Accuracy: 58.23%\n",
      "Epoch [2460/2500], Train Loss: 0.6033, Train Accuracy: 74.40%, Test Loss: 1.0320, Test Accuracy: 59.49%\n",
      "Epoch [2461/2500], Train Loss: 0.6106, Train Accuracy: 74.54%, Test Loss: 1.0296, Test Accuracy: 58.23%\n",
      "Epoch [2462/2500], Train Loss: 0.6149, Train Accuracy: 72.83%, Test Loss: 1.0469, Test Accuracy: 62.03%\n",
      "Epoch [2463/2500], Train Loss: 0.5850, Train Accuracy: 76.39%, Test Loss: 1.0499, Test Accuracy: 59.49%\n",
      "Epoch [2464/2500], Train Loss: 0.5874, Train Accuracy: 72.69%, Test Loss: 1.0810, Test Accuracy: 59.49%\n",
      "Epoch [2465/2500], Train Loss: 0.6047, Train Accuracy: 72.69%, Test Loss: 1.0214, Test Accuracy: 59.49%\n",
      "Epoch [2466/2500], Train Loss: 0.6246, Train Accuracy: 71.83%, Test Loss: 1.0401, Test Accuracy: 60.76%\n",
      "Epoch [2467/2500], Train Loss: 0.6190, Train Accuracy: 74.11%, Test Loss: 1.0449, Test Accuracy: 62.03%\n",
      "Epoch [2468/2500], Train Loss: 0.6021, Train Accuracy: 74.54%, Test Loss: 1.0636, Test Accuracy: 60.76%\n",
      "Epoch [2469/2500], Train Loss: 0.6031, Train Accuracy: 73.54%, Test Loss: 1.0736, Test Accuracy: 59.49%\n",
      "Epoch [2470/2500], Train Loss: 0.6064, Train Accuracy: 73.97%, Test Loss: 1.0745, Test Accuracy: 59.49%\n",
      "Epoch [2471/2500], Train Loss: 0.6045, Train Accuracy: 72.26%, Test Loss: 1.0834, Test Accuracy: 59.49%\n",
      "Epoch [2472/2500], Train Loss: 0.5991, Train Accuracy: 74.11%, Test Loss: 1.0674, Test Accuracy: 60.76%\n",
      "Epoch [2473/2500], Train Loss: 0.5884, Train Accuracy: 74.25%, Test Loss: 1.0688, Test Accuracy: 59.49%\n",
      "Epoch [2474/2500], Train Loss: 0.6003, Train Accuracy: 73.68%, Test Loss: 1.0848, Test Accuracy: 58.23%\n",
      "Epoch [2475/2500], Train Loss: 0.6107, Train Accuracy: 74.96%, Test Loss: 1.1416, Test Accuracy: 59.49%\n",
      "Epoch [2476/2500], Train Loss: 0.6217, Train Accuracy: 72.69%, Test Loss: 1.1028, Test Accuracy: 59.49%\n",
      "Epoch [2477/2500], Train Loss: 0.6046, Train Accuracy: 73.40%, Test Loss: 1.0724, Test Accuracy: 56.96%\n",
      "Epoch [2478/2500], Train Loss: 0.5894, Train Accuracy: 75.25%, Test Loss: 1.0696, Test Accuracy: 56.96%\n",
      "Epoch [2479/2500], Train Loss: 0.5973, Train Accuracy: 74.25%, Test Loss: 1.0816, Test Accuracy: 62.03%\n",
      "Epoch [2480/2500], Train Loss: 0.6097, Train Accuracy: 72.69%, Test Loss: 1.1305, Test Accuracy: 59.49%\n",
      "Epoch [2481/2500], Train Loss: 0.6157, Train Accuracy: 73.40%, Test Loss: 1.0561, Test Accuracy: 59.49%\n",
      "Epoch [2482/2500], Train Loss: 0.6056, Train Accuracy: 72.97%, Test Loss: 1.1114, Test Accuracy: 59.49%\n",
      "Epoch [2483/2500], Train Loss: 0.6072, Train Accuracy: 72.97%, Test Loss: 1.0633, Test Accuracy: 60.76%\n",
      "Epoch [2484/2500], Train Loss: 0.6000, Train Accuracy: 73.83%, Test Loss: 1.0722, Test Accuracy: 58.23%\n",
      "Epoch [2485/2500], Train Loss: 0.6140, Train Accuracy: 73.68%, Test Loss: 1.0527, Test Accuracy: 56.96%\n",
      "Epoch [2486/2500], Train Loss: 0.6013, Train Accuracy: 73.12%, Test Loss: 1.1044, Test Accuracy: 58.23%\n",
      "Epoch [2487/2500], Train Loss: 0.5974, Train Accuracy: 74.54%, Test Loss: 1.0910, Test Accuracy: 56.96%\n",
      "Epoch [2488/2500], Train Loss: 0.5802, Train Accuracy: 75.53%, Test Loss: 1.0467, Test Accuracy: 58.23%\n",
      "Epoch [2489/2500], Train Loss: 0.6037, Train Accuracy: 73.12%, Test Loss: 1.0859, Test Accuracy: 62.03%\n",
      "Epoch [2490/2500], Train Loss: 0.5993, Train Accuracy: 73.40%, Test Loss: 1.0699, Test Accuracy: 60.76%\n",
      "Epoch [2491/2500], Train Loss: 0.6033, Train Accuracy: 72.83%, Test Loss: 1.0666, Test Accuracy: 60.76%\n",
      "Epoch [2492/2500], Train Loss: 0.6081, Train Accuracy: 72.26%, Test Loss: 1.0673, Test Accuracy: 59.49%\n",
      "Epoch [2493/2500], Train Loss: 0.6086, Train Accuracy: 73.12%, Test Loss: 1.1030, Test Accuracy: 59.49%\n",
      "Epoch [2494/2500], Train Loss: 0.6243, Train Accuracy: 73.26%, Test Loss: 1.1009, Test Accuracy: 58.23%\n",
      "Epoch [2495/2500], Train Loss: 0.6221, Train Accuracy: 73.12%, Test Loss: 1.0895, Test Accuracy: 58.23%\n",
      "Epoch [2496/2500], Train Loss: 0.6066, Train Accuracy: 73.40%, Test Loss: 1.1016, Test Accuracy: 59.49%\n",
      "Epoch [2497/2500], Train Loss: 0.6196, Train Accuracy: 73.40%, Test Loss: 1.1244, Test Accuracy: 56.96%\n",
      "Epoch [2498/2500], Train Loss: 0.6044, Train Accuracy: 71.55%, Test Loss: 1.0733, Test Accuracy: 58.23%\n",
      "Epoch [2499/2500], Train Loss: 0.6035, Train Accuracy: 72.83%, Test Loss: 1.0703, Test Accuracy: 59.49%\n",
      "Epoch [2500/2500], Train Loss: 0.6056, Train Accuracy: 73.83%, Test Loss: 1.0669, Test Accuracy: 58.23%\n",
      "model_cnn1d_att saved as model_cnn1d_att_4class_best.pth\n",
      "\n",
      "Metrics for model_cnn1d_att saved as model_cnn1d_att_4class_metrics.csv\n",
      "\n",
      "Training model_cnn1dlstm_att\n",
      "Epoch [1/2500], Train Loss: 1.3861, Train Accuracy: 33.57%, Test Loss: 1.3820, Test Accuracy: 39.24%\n",
      "Epoch [2/2500], Train Loss: 1.3845, Train Accuracy: 35.28%, Test Loss: 1.3798, Test Accuracy: 39.24%\n",
      "Epoch [3/2500], Train Loss: 1.3830, Train Accuracy: 35.28%, Test Loss: 1.3776, Test Accuracy: 39.24%\n",
      "Epoch [4/2500], Train Loss: 1.3808, Train Accuracy: 35.28%, Test Loss: 1.3755, Test Accuracy: 39.24%\n",
      "Epoch [5/2500], Train Loss: 1.3794, Train Accuracy: 35.28%, Test Loss: 1.3736, Test Accuracy: 39.24%\n",
      "Epoch [6/2500], Train Loss: 1.3777, Train Accuracy: 35.28%, Test Loss: 1.3716, Test Accuracy: 39.24%\n",
      "Epoch [7/2500], Train Loss: 1.3762, Train Accuracy: 35.28%, Test Loss: 1.3698, Test Accuracy: 39.24%\n",
      "Epoch [8/2500], Train Loss: 1.3743, Train Accuracy: 35.28%, Test Loss: 1.3680, Test Accuracy: 39.24%\n",
      "Epoch [9/2500], Train Loss: 1.3736, Train Accuracy: 35.28%, Test Loss: 1.3663, Test Accuracy: 39.24%\n",
      "Epoch [10/2500], Train Loss: 1.3720, Train Accuracy: 35.28%, Test Loss: 1.3647, Test Accuracy: 39.24%\n",
      "Epoch [11/2500], Train Loss: 1.3711, Train Accuracy: 35.28%, Test Loss: 1.3632, Test Accuracy: 39.24%\n",
      "Epoch [12/2500], Train Loss: 1.3697, Train Accuracy: 35.28%, Test Loss: 1.3616, Test Accuracy: 39.24%\n",
      "Epoch [13/2500], Train Loss: 1.3685, Train Accuracy: 35.28%, Test Loss: 1.3602, Test Accuracy: 39.24%\n",
      "Epoch [14/2500], Train Loss: 1.3675, Train Accuracy: 35.28%, Test Loss: 1.3588, Test Accuracy: 39.24%\n",
      "Epoch [15/2500], Train Loss: 1.3667, Train Accuracy: 35.28%, Test Loss: 1.3576, Test Accuracy: 39.24%\n",
      "Epoch [16/2500], Train Loss: 1.3652, Train Accuracy: 35.28%, Test Loss: 1.3562, Test Accuracy: 39.24%\n",
      "Epoch [17/2500], Train Loss: 1.3644, Train Accuracy: 35.28%, Test Loss: 1.3551, Test Accuracy: 39.24%\n",
      "Epoch [18/2500], Train Loss: 1.3636, Train Accuracy: 35.28%, Test Loss: 1.3538, Test Accuracy: 39.24%\n",
      "Epoch [19/2500], Train Loss: 1.3629, Train Accuracy: 35.28%, Test Loss: 1.3527, Test Accuracy: 39.24%\n",
      "Epoch [20/2500], Train Loss: 1.3619, Train Accuracy: 35.28%, Test Loss: 1.3516, Test Accuracy: 39.24%\n",
      "Epoch [21/2500], Train Loss: 1.3608, Train Accuracy: 35.28%, Test Loss: 1.3506, Test Accuracy: 39.24%\n",
      "Epoch [22/2500], Train Loss: 1.3602, Train Accuracy: 35.28%, Test Loss: 1.3496, Test Accuracy: 39.24%\n",
      "Epoch [23/2500], Train Loss: 1.3594, Train Accuracy: 35.28%, Test Loss: 1.3487, Test Accuracy: 39.24%\n",
      "Epoch [24/2500], Train Loss: 1.3587, Train Accuracy: 35.28%, Test Loss: 1.3477, Test Accuracy: 39.24%\n",
      "Epoch [25/2500], Train Loss: 1.3586, Train Accuracy: 35.28%, Test Loss: 1.3468, Test Accuracy: 39.24%\n",
      "Epoch [26/2500], Train Loss: 1.3575, Train Accuracy: 35.28%, Test Loss: 1.3459, Test Accuracy: 39.24%\n",
      "Epoch [27/2500], Train Loss: 1.3569, Train Accuracy: 35.28%, Test Loss: 1.3451, Test Accuracy: 39.24%\n",
      "Epoch [28/2500], Train Loss: 1.3563, Train Accuracy: 35.28%, Test Loss: 1.3444, Test Accuracy: 39.24%\n",
      "Epoch [29/2500], Train Loss: 1.3557, Train Accuracy: 35.28%, Test Loss: 1.3436, Test Accuracy: 39.24%\n",
      "Epoch [30/2500], Train Loss: 1.3554, Train Accuracy: 35.28%, Test Loss: 1.3428, Test Accuracy: 39.24%\n",
      "Epoch [31/2500], Train Loss: 1.3546, Train Accuracy: 35.28%, Test Loss: 1.3421, Test Accuracy: 39.24%\n",
      "Epoch [32/2500], Train Loss: 1.3546, Train Accuracy: 35.28%, Test Loss: 1.3414, Test Accuracy: 39.24%\n",
      "Epoch [33/2500], Train Loss: 1.3541, Train Accuracy: 35.28%, Test Loss: 1.3407, Test Accuracy: 39.24%\n",
      "Epoch [34/2500], Train Loss: 1.3534, Train Accuracy: 35.28%, Test Loss: 1.3401, Test Accuracy: 39.24%\n",
      "Epoch [35/2500], Train Loss: 1.3526, Train Accuracy: 35.28%, Test Loss: 1.3395, Test Accuracy: 39.24%\n",
      "Epoch [36/2500], Train Loss: 1.3527, Train Accuracy: 35.28%, Test Loss: 1.3389, Test Accuracy: 39.24%\n",
      "Epoch [37/2500], Train Loss: 1.3517, Train Accuracy: 35.28%, Test Loss: 1.3383, Test Accuracy: 39.24%\n",
      "Epoch [38/2500], Train Loss: 1.3518, Train Accuracy: 35.28%, Test Loss: 1.3377, Test Accuracy: 39.24%\n",
      "Epoch [39/2500], Train Loss: 1.3514, Train Accuracy: 35.28%, Test Loss: 1.3372, Test Accuracy: 39.24%\n",
      "Epoch [40/2500], Train Loss: 1.3508, Train Accuracy: 35.28%, Test Loss: 1.3368, Test Accuracy: 39.24%\n",
      "Epoch [41/2500], Train Loss: 1.3507, Train Accuracy: 35.28%, Test Loss: 1.3362, Test Accuracy: 39.24%\n",
      "Epoch [42/2500], Train Loss: 1.3500, Train Accuracy: 35.28%, Test Loss: 1.3358, Test Accuracy: 39.24%\n",
      "Epoch [43/2500], Train Loss: 1.3500, Train Accuracy: 35.28%, Test Loss: 1.3353, Test Accuracy: 39.24%\n",
      "Epoch [44/2500], Train Loss: 1.3498, Train Accuracy: 35.28%, Test Loss: 1.3348, Test Accuracy: 39.24%\n",
      "Epoch [45/2500], Train Loss: 1.3494, Train Accuracy: 35.28%, Test Loss: 1.3344, Test Accuracy: 39.24%\n",
      "Epoch [46/2500], Train Loss: 1.3491, Train Accuracy: 35.28%, Test Loss: 1.3340, Test Accuracy: 39.24%\n",
      "Epoch [47/2500], Train Loss: 1.3491, Train Accuracy: 35.28%, Test Loss: 1.3335, Test Accuracy: 39.24%\n",
      "Epoch [48/2500], Train Loss: 1.3486, Train Accuracy: 35.28%, Test Loss: 1.3332, Test Accuracy: 39.24%\n",
      "Epoch [49/2500], Train Loss: 1.3484, Train Accuracy: 35.28%, Test Loss: 1.3328, Test Accuracy: 39.24%\n",
      "Epoch [50/2500], Train Loss: 1.3482, Train Accuracy: 35.28%, Test Loss: 1.3324, Test Accuracy: 39.24%\n",
      "Epoch [51/2500], Train Loss: 1.3481, Train Accuracy: 35.28%, Test Loss: 1.3320, Test Accuracy: 39.24%\n",
      "Epoch [52/2500], Train Loss: 1.3476, Train Accuracy: 35.28%, Test Loss: 1.3317, Test Accuracy: 39.24%\n",
      "Epoch [53/2500], Train Loss: 1.3473, Train Accuracy: 35.28%, Test Loss: 1.3314, Test Accuracy: 39.24%\n",
      "Epoch [54/2500], Train Loss: 1.3469, Train Accuracy: 35.28%, Test Loss: 1.3310, Test Accuracy: 39.24%\n",
      "Epoch [55/2500], Train Loss: 1.3472, Train Accuracy: 35.28%, Test Loss: 1.3307, Test Accuracy: 39.24%\n",
      "Epoch [56/2500], Train Loss: 1.3470, Train Accuracy: 35.28%, Test Loss: 1.3304, Test Accuracy: 39.24%\n",
      "Epoch [57/2500], Train Loss: 1.3466, Train Accuracy: 35.28%, Test Loss: 1.3301, Test Accuracy: 39.24%\n",
      "Epoch [58/2500], Train Loss: 1.3463, Train Accuracy: 35.28%, Test Loss: 1.3298, Test Accuracy: 39.24%\n",
      "Epoch [59/2500], Train Loss: 1.3464, Train Accuracy: 35.28%, Test Loss: 1.3296, Test Accuracy: 39.24%\n",
      "Epoch [60/2500], Train Loss: 1.3463, Train Accuracy: 35.28%, Test Loss: 1.3293, Test Accuracy: 39.24%\n",
      "Epoch [61/2500], Train Loss: 1.3463, Train Accuracy: 35.28%, Test Loss: 1.3290, Test Accuracy: 39.24%\n",
      "Epoch [62/2500], Train Loss: 1.3462, Train Accuracy: 35.28%, Test Loss: 1.3287, Test Accuracy: 39.24%\n",
      "Epoch [63/2500], Train Loss: 1.3463, Train Accuracy: 35.28%, Test Loss: 1.3286, Test Accuracy: 39.24%\n",
      "Epoch [64/2500], Train Loss: 1.3458, Train Accuracy: 35.28%, Test Loss: 1.3283, Test Accuracy: 39.24%\n",
      "Epoch [65/2500], Train Loss: 1.3454, Train Accuracy: 35.28%, Test Loss: 1.3280, Test Accuracy: 39.24%\n",
      "Epoch [66/2500], Train Loss: 1.3453, Train Accuracy: 35.28%, Test Loss: 1.3279, Test Accuracy: 39.24%\n",
      "Epoch [67/2500], Train Loss: 1.3450, Train Accuracy: 35.28%, Test Loss: 1.3276, Test Accuracy: 39.24%\n",
      "Epoch [68/2500], Train Loss: 1.3450, Train Accuracy: 35.28%, Test Loss: 1.3274, Test Accuracy: 39.24%\n",
      "Epoch [69/2500], Train Loss: 1.3450, Train Accuracy: 35.28%, Test Loss: 1.3272, Test Accuracy: 39.24%\n",
      "Epoch [70/2500], Train Loss: 1.3454, Train Accuracy: 35.28%, Test Loss: 1.3270, Test Accuracy: 39.24%\n",
      "Epoch [71/2500], Train Loss: 1.3448, Train Accuracy: 35.28%, Test Loss: 1.3268, Test Accuracy: 39.24%\n",
      "Epoch [72/2500], Train Loss: 1.3446, Train Accuracy: 35.28%, Test Loss: 1.3266, Test Accuracy: 39.24%\n",
      "Epoch [73/2500], Train Loss: 1.3447, Train Accuracy: 35.28%, Test Loss: 1.3264, Test Accuracy: 39.24%\n",
      "Epoch [74/2500], Train Loss: 1.3448, Train Accuracy: 35.28%, Test Loss: 1.3263, Test Accuracy: 39.24%\n",
      "Epoch [75/2500], Train Loss: 1.3446, Train Accuracy: 35.28%, Test Loss: 1.3261, Test Accuracy: 39.24%\n",
      "Epoch [76/2500], Train Loss: 1.3439, Train Accuracy: 35.28%, Test Loss: 1.3259, Test Accuracy: 39.24%\n",
      "Epoch [77/2500], Train Loss: 1.3443, Train Accuracy: 35.28%, Test Loss: 1.3257, Test Accuracy: 39.24%\n",
      "Epoch [78/2500], Train Loss: 1.3446, Train Accuracy: 35.28%, Test Loss: 1.3255, Test Accuracy: 39.24%\n",
      "Epoch [79/2500], Train Loss: 1.3441, Train Accuracy: 35.28%, Test Loss: 1.3254, Test Accuracy: 39.24%\n",
      "Epoch [80/2500], Train Loss: 1.3443, Train Accuracy: 35.28%, Test Loss: 1.3253, Test Accuracy: 39.24%\n",
      "Epoch [81/2500], Train Loss: 1.3441, Train Accuracy: 35.28%, Test Loss: 1.3250, Test Accuracy: 39.24%\n",
      "Epoch [82/2500], Train Loss: 1.3437, Train Accuracy: 35.28%, Test Loss: 1.3249, Test Accuracy: 39.24%\n",
      "Epoch [83/2500], Train Loss: 1.3436, Train Accuracy: 35.28%, Test Loss: 1.3249, Test Accuracy: 39.24%\n",
      "Epoch [84/2500], Train Loss: 1.3436, Train Accuracy: 35.28%, Test Loss: 1.3247, Test Accuracy: 39.24%\n",
      "Epoch [85/2500], Train Loss: 1.3440, Train Accuracy: 35.28%, Test Loss: 1.3246, Test Accuracy: 39.24%\n",
      "Epoch [86/2500], Train Loss: 1.3441, Train Accuracy: 35.28%, Test Loss: 1.3244, Test Accuracy: 39.24%\n",
      "Epoch [87/2500], Train Loss: 1.3437, Train Accuracy: 35.28%, Test Loss: 1.3243, Test Accuracy: 39.24%\n",
      "Epoch [88/2500], Train Loss: 1.3434, Train Accuracy: 35.28%, Test Loss: 1.3242, Test Accuracy: 39.24%\n",
      "Epoch [89/2500], Train Loss: 1.3437, Train Accuracy: 35.28%, Test Loss: 1.3240, Test Accuracy: 39.24%\n",
      "Epoch [90/2500], Train Loss: 1.3436, Train Accuracy: 35.28%, Test Loss: 1.3239, Test Accuracy: 39.24%\n",
      "Epoch [91/2500], Train Loss: 1.3432, Train Accuracy: 35.28%, Test Loss: 1.3238, Test Accuracy: 39.24%\n",
      "Epoch [92/2500], Train Loss: 1.3437, Train Accuracy: 35.28%, Test Loss: 1.3237, Test Accuracy: 39.24%\n",
      "Epoch [93/2500], Train Loss: 1.3434, Train Accuracy: 35.28%, Test Loss: 1.3236, Test Accuracy: 39.24%\n",
      "Epoch [94/2500], Train Loss: 1.3428, Train Accuracy: 35.28%, Test Loss: 1.3235, Test Accuracy: 39.24%\n",
      "Epoch [95/2500], Train Loss: 1.3437, Train Accuracy: 35.28%, Test Loss: 1.3234, Test Accuracy: 39.24%\n",
      "Epoch [96/2500], Train Loss: 1.3432, Train Accuracy: 35.28%, Test Loss: 1.3233, Test Accuracy: 39.24%\n",
      "Epoch [97/2500], Train Loss: 1.3432, Train Accuracy: 35.28%, Test Loss: 1.3232, Test Accuracy: 39.24%\n",
      "Epoch [98/2500], Train Loss: 1.3429, Train Accuracy: 35.28%, Test Loss: 1.3230, Test Accuracy: 39.24%\n",
      "Epoch [99/2500], Train Loss: 1.3429, Train Accuracy: 35.28%, Test Loss: 1.3230, Test Accuracy: 39.24%\n",
      "Epoch [100/2500], Train Loss: 1.3434, Train Accuracy: 35.28%, Test Loss: 1.3229, Test Accuracy: 39.24%\n",
      "Epoch [101/2500], Train Loss: 1.3423, Train Accuracy: 35.28%, Test Loss: 1.3228, Test Accuracy: 39.24%\n",
      "Epoch [102/2500], Train Loss: 1.3430, Train Accuracy: 35.28%, Test Loss: 1.3227, Test Accuracy: 39.24%\n",
      "Epoch [103/2500], Train Loss: 1.3429, Train Accuracy: 35.28%, Test Loss: 1.3226, Test Accuracy: 39.24%\n",
      "Epoch [104/2500], Train Loss: 1.3429, Train Accuracy: 35.28%, Test Loss: 1.3225, Test Accuracy: 39.24%\n",
      "Epoch [105/2500], Train Loss: 1.3428, Train Accuracy: 35.28%, Test Loss: 1.3225, Test Accuracy: 39.24%\n",
      "Epoch [106/2500], Train Loss: 1.3430, Train Accuracy: 35.28%, Test Loss: 1.3223, Test Accuracy: 39.24%\n",
      "Epoch [107/2500], Train Loss: 1.3427, Train Accuracy: 35.28%, Test Loss: 1.3223, Test Accuracy: 39.24%\n",
      "Epoch [108/2500], Train Loss: 1.3424, Train Accuracy: 35.28%, Test Loss: 1.3223, Test Accuracy: 39.24%\n",
      "Epoch [109/2500], Train Loss: 1.3427, Train Accuracy: 35.28%, Test Loss: 1.3221, Test Accuracy: 39.24%\n",
      "Epoch [110/2500], Train Loss: 1.3427, Train Accuracy: 35.28%, Test Loss: 1.3221, Test Accuracy: 39.24%\n",
      "Epoch [111/2500], Train Loss: 1.3423, Train Accuracy: 35.28%, Test Loss: 1.3220, Test Accuracy: 39.24%\n",
      "Epoch [112/2500], Train Loss: 1.3427, Train Accuracy: 35.28%, Test Loss: 1.3219, Test Accuracy: 39.24%\n",
      "Epoch [113/2500], Train Loss: 1.3430, Train Accuracy: 35.28%, Test Loss: 1.3218, Test Accuracy: 39.24%\n",
      "Epoch [114/2500], Train Loss: 1.3422, Train Accuracy: 35.28%, Test Loss: 1.3218, Test Accuracy: 39.24%\n",
      "Epoch [115/2500], Train Loss: 1.3429, Train Accuracy: 35.28%, Test Loss: 1.3217, Test Accuracy: 39.24%\n",
      "Epoch [116/2500], Train Loss: 1.3425, Train Accuracy: 35.28%, Test Loss: 1.3216, Test Accuracy: 39.24%\n",
      "Epoch [117/2500], Train Loss: 1.3423, Train Accuracy: 35.28%, Test Loss: 1.3215, Test Accuracy: 39.24%\n",
      "Epoch [118/2500], Train Loss: 1.3425, Train Accuracy: 35.28%, Test Loss: 1.3215, Test Accuracy: 39.24%\n",
      "Epoch [119/2500], Train Loss: 1.3428, Train Accuracy: 35.28%, Test Loss: 1.3214, Test Accuracy: 39.24%\n",
      "Epoch [120/2500], Train Loss: 1.3425, Train Accuracy: 35.28%, Test Loss: 1.3214, Test Accuracy: 39.24%\n",
      "Epoch [121/2500], Train Loss: 1.3428, Train Accuracy: 35.28%, Test Loss: 1.3213, Test Accuracy: 39.24%\n",
      "Epoch [122/2500], Train Loss: 1.3424, Train Accuracy: 35.28%, Test Loss: 1.3212, Test Accuracy: 39.24%\n",
      "Epoch [123/2500], Train Loss: 1.3425, Train Accuracy: 35.28%, Test Loss: 1.3212, Test Accuracy: 39.24%\n",
      "Epoch [124/2500], Train Loss: 1.3429, Train Accuracy: 35.28%, Test Loss: 1.3211, Test Accuracy: 39.24%\n",
      "Epoch [125/2500], Train Loss: 1.3427, Train Accuracy: 35.28%, Test Loss: 1.3211, Test Accuracy: 39.24%\n",
      "Epoch [126/2500], Train Loss: 1.3422, Train Accuracy: 35.28%, Test Loss: 1.3210, Test Accuracy: 39.24%\n",
      "Epoch [127/2500], Train Loss: 1.3421, Train Accuracy: 35.28%, Test Loss: 1.3209, Test Accuracy: 39.24%\n",
      "Epoch [128/2500], Train Loss: 1.3426, Train Accuracy: 35.28%, Test Loss: 1.3209, Test Accuracy: 39.24%\n",
      "Epoch [129/2500], Train Loss: 1.3422, Train Accuracy: 35.28%, Test Loss: 1.3208, Test Accuracy: 39.24%\n",
      "Epoch [130/2500], Train Loss: 1.3422, Train Accuracy: 35.28%, Test Loss: 1.3208, Test Accuracy: 39.24%\n",
      "Epoch [131/2500], Train Loss: 1.3421, Train Accuracy: 35.28%, Test Loss: 1.3207, Test Accuracy: 39.24%\n",
      "Epoch [132/2500], Train Loss: 1.3425, Train Accuracy: 35.28%, Test Loss: 1.3208, Test Accuracy: 39.24%\n",
      "Epoch [133/2500], Train Loss: 1.3421, Train Accuracy: 35.28%, Test Loss: 1.3207, Test Accuracy: 39.24%\n",
      "Epoch [134/2500], Train Loss: 1.3422, Train Accuracy: 35.28%, Test Loss: 1.3206, Test Accuracy: 39.24%\n",
      "Epoch [135/2500], Train Loss: 1.3423, Train Accuracy: 35.28%, Test Loss: 1.3206, Test Accuracy: 39.24%\n",
      "Epoch [136/2500], Train Loss: 1.3424, Train Accuracy: 35.28%, Test Loss: 1.3205, Test Accuracy: 39.24%\n",
      "Epoch [137/2500], Train Loss: 1.3423, Train Accuracy: 35.28%, Test Loss: 1.3204, Test Accuracy: 39.24%\n",
      "Epoch [138/2500], Train Loss: 1.3424, Train Accuracy: 35.28%, Test Loss: 1.3204, Test Accuracy: 39.24%\n",
      "Epoch [139/2500], Train Loss: 1.3421, Train Accuracy: 35.28%, Test Loss: 1.3204, Test Accuracy: 39.24%\n",
      "Epoch [140/2500], Train Loss: 1.3423, Train Accuracy: 35.28%, Test Loss: 1.3203, Test Accuracy: 39.24%\n",
      "Epoch [141/2500], Train Loss: 1.3421, Train Accuracy: 35.28%, Test Loss: 1.3203, Test Accuracy: 39.24%\n",
      "Epoch [142/2500], Train Loss: 1.3418, Train Accuracy: 35.28%, Test Loss: 1.3203, Test Accuracy: 39.24%\n",
      "Epoch [143/2500], Train Loss: 1.3425, Train Accuracy: 35.28%, Test Loss: 1.3202, Test Accuracy: 39.24%\n",
      "Epoch [144/2500], Train Loss: 1.3422, Train Accuracy: 35.28%, Test Loss: 1.3202, Test Accuracy: 39.24%\n",
      "Epoch [145/2500], Train Loss: 1.3422, Train Accuracy: 35.28%, Test Loss: 1.3201, Test Accuracy: 39.24%\n",
      "Epoch [146/2500], Train Loss: 1.3422, Train Accuracy: 35.28%, Test Loss: 1.3201, Test Accuracy: 39.24%\n",
      "Epoch [147/2500], Train Loss: 1.3423, Train Accuracy: 35.28%, Test Loss: 1.3200, Test Accuracy: 39.24%\n",
      "Epoch [148/2500], Train Loss: 1.3423, Train Accuracy: 35.28%, Test Loss: 1.3201, Test Accuracy: 39.24%\n",
      "Epoch [149/2500], Train Loss: 1.3422, Train Accuracy: 35.28%, Test Loss: 1.3200, Test Accuracy: 39.24%\n",
      "Epoch [150/2500], Train Loss: 1.3422, Train Accuracy: 35.28%, Test Loss: 1.3200, Test Accuracy: 39.24%\n",
      "Epoch [151/2500], Train Loss: 1.3416, Train Accuracy: 35.28%, Test Loss: 1.3199, Test Accuracy: 39.24%\n",
      "Epoch [152/2500], Train Loss: 1.3422, Train Accuracy: 35.28%, Test Loss: 1.3199, Test Accuracy: 39.24%\n",
      "Epoch [153/2500], Train Loss: 1.3417, Train Accuracy: 35.28%, Test Loss: 1.3199, Test Accuracy: 39.24%\n",
      "Epoch [154/2500], Train Loss: 1.3424, Train Accuracy: 35.28%, Test Loss: 1.3199, Test Accuracy: 39.24%\n",
      "Epoch [155/2500], Train Loss: 1.3424, Train Accuracy: 35.28%, Test Loss: 1.3198, Test Accuracy: 39.24%\n",
      "Epoch [156/2500], Train Loss: 1.3422, Train Accuracy: 35.28%, Test Loss: 1.3198, Test Accuracy: 39.24%\n",
      "Epoch [157/2500], Train Loss: 1.3420, Train Accuracy: 35.28%, Test Loss: 1.3197, Test Accuracy: 39.24%\n",
      "Epoch [158/2500], Train Loss: 1.3419, Train Accuracy: 35.28%, Test Loss: 1.3197, Test Accuracy: 39.24%\n",
      "Epoch [159/2500], Train Loss: 1.3423, Train Accuracy: 35.28%, Test Loss: 1.3197, Test Accuracy: 39.24%\n",
      "Epoch [160/2500], Train Loss: 1.3424, Train Accuracy: 35.28%, Test Loss: 1.3196, Test Accuracy: 39.24%\n",
      "Epoch [161/2500], Train Loss: 1.3419, Train Accuracy: 35.28%, Test Loss: 1.3196, Test Accuracy: 39.24%\n",
      "Epoch [162/2500], Train Loss: 1.3420, Train Accuracy: 35.28%, Test Loss: 1.3195, Test Accuracy: 39.24%\n",
      "Epoch [163/2500], Train Loss: 1.3422, Train Accuracy: 35.28%, Test Loss: 1.3196, Test Accuracy: 39.24%\n",
      "Epoch [164/2500], Train Loss: 1.3421, Train Accuracy: 35.28%, Test Loss: 1.3195, Test Accuracy: 39.24%\n",
      "Epoch [165/2500], Train Loss: 1.3418, Train Accuracy: 35.28%, Test Loss: 1.3194, Test Accuracy: 39.24%\n",
      "Epoch [166/2500], Train Loss: 1.3420, Train Accuracy: 35.28%, Test Loss: 1.3194, Test Accuracy: 39.24%\n",
      "Epoch [167/2500], Train Loss: 1.3420, Train Accuracy: 35.28%, Test Loss: 1.3194, Test Accuracy: 39.24%\n",
      "Epoch [168/2500], Train Loss: 1.3422, Train Accuracy: 35.28%, Test Loss: 1.3194, Test Accuracy: 39.24%\n",
      "Epoch [169/2500], Train Loss: 1.3424, Train Accuracy: 35.28%, Test Loss: 1.3193, Test Accuracy: 39.24%\n",
      "Epoch [170/2500], Train Loss: 1.3422, Train Accuracy: 35.28%, Test Loss: 1.3193, Test Accuracy: 39.24%\n",
      "Epoch [171/2500], Train Loss: 1.3419, Train Accuracy: 35.28%, Test Loss: 1.3193, Test Accuracy: 39.24%\n",
      "Epoch [172/2500], Train Loss: 1.3418, Train Accuracy: 35.28%, Test Loss: 1.3193, Test Accuracy: 39.24%\n",
      "Epoch [173/2500], Train Loss: 1.3418, Train Accuracy: 35.28%, Test Loss: 1.3193, Test Accuracy: 39.24%\n",
      "Epoch [174/2500], Train Loss: 1.3415, Train Accuracy: 35.28%, Test Loss: 1.3192, Test Accuracy: 39.24%\n",
      "Epoch [175/2500], Train Loss: 1.3420, Train Accuracy: 35.28%, Test Loss: 1.3192, Test Accuracy: 39.24%\n",
      "Epoch [176/2500], Train Loss: 1.3419, Train Accuracy: 35.28%, Test Loss: 1.3191, Test Accuracy: 39.24%\n",
      "Epoch [177/2500], Train Loss: 1.3419, Train Accuracy: 35.28%, Test Loss: 1.3191, Test Accuracy: 39.24%\n",
      "Epoch [178/2500], Train Loss: 1.3421, Train Accuracy: 35.28%, Test Loss: 1.3191, Test Accuracy: 39.24%\n",
      "Epoch [179/2500], Train Loss: 1.3417, Train Accuracy: 35.28%, Test Loss: 1.3190, Test Accuracy: 39.24%\n",
      "Epoch [180/2500], Train Loss: 1.3419, Train Accuracy: 35.28%, Test Loss: 1.3190, Test Accuracy: 39.24%\n",
      "Epoch [181/2500], Train Loss: 1.3421, Train Accuracy: 35.28%, Test Loss: 1.3191, Test Accuracy: 39.24%\n",
      "Epoch [182/2500], Train Loss: 1.3421, Train Accuracy: 35.28%, Test Loss: 1.3190, Test Accuracy: 39.24%\n",
      "Epoch [183/2500], Train Loss: 1.3418, Train Accuracy: 35.28%, Test Loss: 1.3190, Test Accuracy: 39.24%\n",
      "Epoch [184/2500], Train Loss: 1.3420, Train Accuracy: 35.28%, Test Loss: 1.3190, Test Accuracy: 39.24%\n",
      "Epoch [185/2500], Train Loss: 1.3424, Train Accuracy: 35.28%, Test Loss: 1.3189, Test Accuracy: 39.24%\n",
      "Epoch [186/2500], Train Loss: 1.3421, Train Accuracy: 35.28%, Test Loss: 1.3189, Test Accuracy: 39.24%\n",
      "Epoch [187/2500], Train Loss: 1.3422, Train Accuracy: 35.28%, Test Loss: 1.3190, Test Accuracy: 39.24%\n",
      "Epoch [188/2500], Train Loss: 1.3415, Train Accuracy: 35.28%, Test Loss: 1.3188, Test Accuracy: 39.24%\n",
      "Epoch [189/2500], Train Loss: 1.3418, Train Accuracy: 35.28%, Test Loss: 1.3188, Test Accuracy: 39.24%\n",
      "Epoch [190/2500], Train Loss: 1.3418, Train Accuracy: 35.28%, Test Loss: 1.3189, Test Accuracy: 39.24%\n",
      "Epoch [191/2500], Train Loss: 1.3419, Train Accuracy: 35.28%, Test Loss: 1.3188, Test Accuracy: 39.24%\n",
      "Epoch [192/2500], Train Loss: 1.3416, Train Accuracy: 35.28%, Test Loss: 1.3189, Test Accuracy: 39.24%\n",
      "Epoch [193/2500], Train Loss: 1.3420, Train Accuracy: 35.28%, Test Loss: 1.3187, Test Accuracy: 39.24%\n",
      "Epoch [194/2500], Train Loss: 1.3416, Train Accuracy: 35.28%, Test Loss: 1.3188, Test Accuracy: 39.24%\n",
      "Epoch [195/2500], Train Loss: 1.3417, Train Accuracy: 35.28%, Test Loss: 1.3186, Test Accuracy: 39.24%\n",
      "Epoch [196/2500], Train Loss: 1.3419, Train Accuracy: 35.28%, Test Loss: 1.3187, Test Accuracy: 39.24%\n",
      "Epoch [197/2500], Train Loss: 1.3417, Train Accuracy: 35.28%, Test Loss: 1.3187, Test Accuracy: 39.24%\n",
      "Epoch [198/2500], Train Loss: 1.3417, Train Accuracy: 35.28%, Test Loss: 1.3187, Test Accuracy: 39.24%\n",
      "Epoch [199/2500], Train Loss: 1.3421, Train Accuracy: 35.28%, Test Loss: 1.3186, Test Accuracy: 39.24%\n",
      "Epoch [200/2500], Train Loss: 1.3420, Train Accuracy: 35.28%, Test Loss: 1.3187, Test Accuracy: 39.24%\n",
      "Epoch [201/2500], Train Loss: 1.3415, Train Accuracy: 35.28%, Test Loss: 1.3187, Test Accuracy: 39.24%\n",
      "Epoch [202/2500], Train Loss: 1.3422, Train Accuracy: 35.28%, Test Loss: 1.3186, Test Accuracy: 39.24%\n",
      "Epoch [203/2500], Train Loss: 1.3416, Train Accuracy: 35.28%, Test Loss: 1.3186, Test Accuracy: 39.24%\n",
      "Epoch [204/2500], Train Loss: 1.3424, Train Accuracy: 35.28%, Test Loss: 1.3185, Test Accuracy: 39.24%\n",
      "Epoch [205/2500], Train Loss: 1.3416, Train Accuracy: 35.28%, Test Loss: 1.3185, Test Accuracy: 39.24%\n",
      "Epoch [206/2500], Train Loss: 1.3420, Train Accuracy: 35.28%, Test Loss: 1.3185, Test Accuracy: 39.24%\n",
      "Epoch [207/2500], Train Loss: 1.3417, Train Accuracy: 35.28%, Test Loss: 1.3185, Test Accuracy: 39.24%\n",
      "Epoch [208/2500], Train Loss: 1.3418, Train Accuracy: 35.28%, Test Loss: 1.3184, Test Accuracy: 39.24%\n",
      "Epoch [209/2500], Train Loss: 1.3415, Train Accuracy: 35.28%, Test Loss: 1.3184, Test Accuracy: 39.24%\n",
      "Epoch [210/2500], Train Loss: 1.3416, Train Accuracy: 35.28%, Test Loss: 1.3184, Test Accuracy: 39.24%\n",
      "Epoch [211/2500], Train Loss: 1.3415, Train Accuracy: 35.28%, Test Loss: 1.3184, Test Accuracy: 39.24%\n",
      "Epoch [212/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3184, Test Accuracy: 39.24%\n",
      "Epoch [213/2500], Train Loss: 1.3420, Train Accuracy: 35.28%, Test Loss: 1.3184, Test Accuracy: 39.24%\n",
      "Epoch [214/2500], Train Loss: 1.3416, Train Accuracy: 35.28%, Test Loss: 1.3184, Test Accuracy: 39.24%\n",
      "Epoch [215/2500], Train Loss: 1.3419, Train Accuracy: 35.28%, Test Loss: 1.3183, Test Accuracy: 39.24%\n",
      "Epoch [216/2500], Train Loss: 1.3417, Train Accuracy: 35.28%, Test Loss: 1.3183, Test Accuracy: 39.24%\n",
      "Epoch [217/2500], Train Loss: 1.3417, Train Accuracy: 35.28%, Test Loss: 1.3183, Test Accuracy: 39.24%\n",
      "Epoch [218/2500], Train Loss: 1.3414, Train Accuracy: 35.28%, Test Loss: 1.3183, Test Accuracy: 39.24%\n",
      "Epoch [219/2500], Train Loss: 1.3419, Train Accuracy: 35.28%, Test Loss: 1.3183, Test Accuracy: 39.24%\n",
      "Epoch [220/2500], Train Loss: 1.3416, Train Accuracy: 35.28%, Test Loss: 1.3183, Test Accuracy: 39.24%\n",
      "Epoch [221/2500], Train Loss: 1.3416, Train Accuracy: 35.28%, Test Loss: 1.3182, Test Accuracy: 39.24%\n",
      "Epoch [222/2500], Train Loss: 1.3417, Train Accuracy: 35.28%, Test Loss: 1.3183, Test Accuracy: 39.24%\n",
      "Epoch [223/2500], Train Loss: 1.3417, Train Accuracy: 35.28%, Test Loss: 1.3182, Test Accuracy: 39.24%\n",
      "Epoch [224/2500], Train Loss: 1.3419, Train Accuracy: 35.28%, Test Loss: 1.3182, Test Accuracy: 39.24%\n",
      "Epoch [225/2500], Train Loss: 1.3417, Train Accuracy: 35.28%, Test Loss: 1.3182, Test Accuracy: 39.24%\n",
      "Epoch [226/2500], Train Loss: 1.3414, Train Accuracy: 35.28%, Test Loss: 1.3182, Test Accuracy: 39.24%\n",
      "Epoch [227/2500], Train Loss: 1.3419, Train Accuracy: 35.28%, Test Loss: 1.3182, Test Accuracy: 39.24%\n",
      "Epoch [228/2500], Train Loss: 1.3415, Train Accuracy: 35.28%, Test Loss: 1.3181, Test Accuracy: 39.24%\n",
      "Epoch [229/2500], Train Loss: 1.3420, Train Accuracy: 35.28%, Test Loss: 1.3181, Test Accuracy: 39.24%\n",
      "Epoch [230/2500], Train Loss: 1.3420, Train Accuracy: 35.28%, Test Loss: 1.3181, Test Accuracy: 39.24%\n",
      "Epoch [231/2500], Train Loss: 1.3417, Train Accuracy: 35.28%, Test Loss: 1.3181, Test Accuracy: 39.24%\n",
      "Epoch [232/2500], Train Loss: 1.3424, Train Accuracy: 35.28%, Test Loss: 1.3181, Test Accuracy: 39.24%\n",
      "Epoch [233/2500], Train Loss: 1.3418, Train Accuracy: 35.28%, Test Loss: 1.3180, Test Accuracy: 39.24%\n",
      "Epoch [234/2500], Train Loss: 1.3418, Train Accuracy: 35.28%, Test Loss: 1.3182, Test Accuracy: 39.24%\n",
      "Epoch [235/2500], Train Loss: 1.3419, Train Accuracy: 35.28%, Test Loss: 1.3182, Test Accuracy: 39.24%\n",
      "Epoch [236/2500], Train Loss: 1.3416, Train Accuracy: 35.28%, Test Loss: 1.3180, Test Accuracy: 39.24%\n",
      "Epoch [237/2500], Train Loss: 1.3416, Train Accuracy: 35.28%, Test Loss: 1.3180, Test Accuracy: 39.24%\n",
      "Epoch [238/2500], Train Loss: 1.3417, Train Accuracy: 35.28%, Test Loss: 1.3180, Test Accuracy: 39.24%\n",
      "Epoch [239/2500], Train Loss: 1.3416, Train Accuracy: 35.28%, Test Loss: 1.3181, Test Accuracy: 39.24%\n",
      "Epoch [240/2500], Train Loss: 1.3417, Train Accuracy: 35.28%, Test Loss: 1.3180, Test Accuracy: 39.24%\n",
      "Epoch [241/2500], Train Loss: 1.3415, Train Accuracy: 35.28%, Test Loss: 1.3179, Test Accuracy: 39.24%\n",
      "Epoch [242/2500], Train Loss: 1.3412, Train Accuracy: 35.28%, Test Loss: 1.3180, Test Accuracy: 39.24%\n",
      "Epoch [243/2500], Train Loss: 1.3418, Train Accuracy: 35.28%, Test Loss: 1.3179, Test Accuracy: 39.24%\n",
      "Epoch [244/2500], Train Loss: 1.3417, Train Accuracy: 35.28%, Test Loss: 1.3179, Test Accuracy: 39.24%\n",
      "Epoch [245/2500], Train Loss: 1.3417, Train Accuracy: 35.28%, Test Loss: 1.3179, Test Accuracy: 39.24%\n",
      "Epoch [246/2500], Train Loss: 1.3418, Train Accuracy: 35.28%, Test Loss: 1.3179, Test Accuracy: 39.24%\n",
      "Epoch [247/2500], Train Loss: 1.3416, Train Accuracy: 35.28%, Test Loss: 1.3179, Test Accuracy: 39.24%\n",
      "Epoch [248/2500], Train Loss: 1.3420, Train Accuracy: 35.28%, Test Loss: 1.3179, Test Accuracy: 39.24%\n",
      "Epoch [249/2500], Train Loss: 1.3424, Train Accuracy: 35.28%, Test Loss: 1.3179, Test Accuracy: 39.24%\n",
      "Epoch [250/2500], Train Loss: 1.3418, Train Accuracy: 35.28%, Test Loss: 1.3177, Test Accuracy: 39.24%\n",
      "Epoch [251/2500], Train Loss: 1.3415, Train Accuracy: 35.28%, Test Loss: 1.3178, Test Accuracy: 39.24%\n",
      "Epoch [252/2500], Train Loss: 1.3414, Train Accuracy: 35.28%, Test Loss: 1.3178, Test Accuracy: 39.24%\n",
      "Epoch [253/2500], Train Loss: 1.3418, Train Accuracy: 35.28%, Test Loss: 1.3178, Test Accuracy: 39.24%\n",
      "Epoch [254/2500], Train Loss: 1.3416, Train Accuracy: 35.28%, Test Loss: 1.3178, Test Accuracy: 39.24%\n",
      "Epoch [255/2500], Train Loss: 1.3419, Train Accuracy: 35.28%, Test Loss: 1.3177, Test Accuracy: 39.24%\n",
      "Epoch [256/2500], Train Loss: 1.3415, Train Accuracy: 35.28%, Test Loss: 1.3178, Test Accuracy: 39.24%\n",
      "Epoch [257/2500], Train Loss: 1.3415, Train Accuracy: 35.28%, Test Loss: 1.3178, Test Accuracy: 39.24%\n",
      "Epoch [258/2500], Train Loss: 1.3414, Train Accuracy: 35.28%, Test Loss: 1.3178, Test Accuracy: 39.24%\n",
      "Epoch [259/2500], Train Loss: 1.3419, Train Accuracy: 35.28%, Test Loss: 1.3177, Test Accuracy: 39.24%\n",
      "Epoch [260/2500], Train Loss: 1.3415, Train Accuracy: 35.28%, Test Loss: 1.3177, Test Accuracy: 39.24%\n",
      "Epoch [261/2500], Train Loss: 1.3418, Train Accuracy: 35.28%, Test Loss: 1.3177, Test Accuracy: 39.24%\n",
      "Epoch [262/2500], Train Loss: 1.3419, Train Accuracy: 35.28%, Test Loss: 1.3177, Test Accuracy: 39.24%\n",
      "Epoch [263/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3176, Test Accuracy: 39.24%\n",
      "Epoch [264/2500], Train Loss: 1.3420, Train Accuracy: 35.28%, Test Loss: 1.3177, Test Accuracy: 39.24%\n",
      "Epoch [265/2500], Train Loss: 1.3412, Train Accuracy: 35.28%, Test Loss: 1.3177, Test Accuracy: 39.24%\n",
      "Epoch [266/2500], Train Loss: 1.3418, Train Accuracy: 35.28%, Test Loss: 1.3176, Test Accuracy: 39.24%\n",
      "Epoch [267/2500], Train Loss: 1.3416, Train Accuracy: 35.28%, Test Loss: 1.3176, Test Accuracy: 39.24%\n",
      "Epoch [268/2500], Train Loss: 1.3418, Train Accuracy: 35.28%, Test Loss: 1.3176, Test Accuracy: 39.24%\n",
      "Epoch [269/2500], Train Loss: 1.3417, Train Accuracy: 35.28%, Test Loss: 1.3175, Test Accuracy: 39.24%\n",
      "Epoch [270/2500], Train Loss: 1.3418, Train Accuracy: 35.28%, Test Loss: 1.3175, Test Accuracy: 39.24%\n",
      "Epoch [271/2500], Train Loss: 1.3410, Train Accuracy: 35.28%, Test Loss: 1.3176, Test Accuracy: 39.24%\n",
      "Epoch [272/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3175, Test Accuracy: 39.24%\n",
      "Epoch [273/2500], Train Loss: 1.3416, Train Accuracy: 35.28%, Test Loss: 1.3175, Test Accuracy: 39.24%\n",
      "Epoch [274/2500], Train Loss: 1.3414, Train Accuracy: 35.28%, Test Loss: 1.3174, Test Accuracy: 39.24%\n",
      "Epoch [275/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3176, Test Accuracy: 39.24%\n",
      "Epoch [276/2500], Train Loss: 1.3412, Train Accuracy: 35.28%, Test Loss: 1.3175, Test Accuracy: 39.24%\n",
      "Epoch [277/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3175, Test Accuracy: 39.24%\n",
      "Epoch [278/2500], Train Loss: 1.3414, Train Accuracy: 35.28%, Test Loss: 1.3175, Test Accuracy: 39.24%\n",
      "Epoch [279/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3175, Test Accuracy: 39.24%\n",
      "Epoch [280/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3175, Test Accuracy: 39.24%\n",
      "Epoch [281/2500], Train Loss: 1.3415, Train Accuracy: 35.28%, Test Loss: 1.3175, Test Accuracy: 39.24%\n",
      "Epoch [282/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3174, Test Accuracy: 39.24%\n",
      "Epoch [283/2500], Train Loss: 1.3414, Train Accuracy: 35.28%, Test Loss: 1.3174, Test Accuracy: 39.24%\n",
      "Epoch [284/2500], Train Loss: 1.3419, Train Accuracy: 35.28%, Test Loss: 1.3174, Test Accuracy: 39.24%\n",
      "Epoch [285/2500], Train Loss: 1.3414, Train Accuracy: 35.28%, Test Loss: 1.3174, Test Accuracy: 39.24%\n",
      "Epoch [286/2500], Train Loss: 1.3415, Train Accuracy: 35.28%, Test Loss: 1.3173, Test Accuracy: 39.24%\n",
      "Epoch [287/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3173, Test Accuracy: 39.24%\n",
      "Epoch [288/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3174, Test Accuracy: 39.24%\n",
      "Epoch [289/2500], Train Loss: 1.3414, Train Accuracy: 35.28%, Test Loss: 1.3174, Test Accuracy: 39.24%\n",
      "Epoch [290/2500], Train Loss: 1.3408, Train Accuracy: 35.28%, Test Loss: 1.3172, Test Accuracy: 39.24%\n",
      "Epoch [291/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3173, Test Accuracy: 39.24%\n",
      "Epoch [292/2500], Train Loss: 1.3419, Train Accuracy: 35.28%, Test Loss: 1.3173, Test Accuracy: 39.24%\n",
      "Epoch [293/2500], Train Loss: 1.3423, Train Accuracy: 35.28%, Test Loss: 1.3172, Test Accuracy: 39.24%\n",
      "Epoch [294/2500], Train Loss: 1.3418, Train Accuracy: 35.28%, Test Loss: 1.3171, Test Accuracy: 39.24%\n",
      "Epoch [295/2500], Train Loss: 1.3414, Train Accuracy: 35.28%, Test Loss: 1.3173, Test Accuracy: 39.24%\n",
      "Epoch [296/2500], Train Loss: 1.3416, Train Accuracy: 35.28%, Test Loss: 1.3172, Test Accuracy: 39.24%\n",
      "Epoch [297/2500], Train Loss: 1.3416, Train Accuracy: 35.28%, Test Loss: 1.3173, Test Accuracy: 39.24%\n",
      "Epoch [298/2500], Train Loss: 1.3419, Train Accuracy: 35.28%, Test Loss: 1.3172, Test Accuracy: 39.24%\n",
      "Epoch [299/2500], Train Loss: 1.3421, Train Accuracy: 35.28%, Test Loss: 1.3172, Test Accuracy: 39.24%\n",
      "Epoch [300/2500], Train Loss: 1.3415, Train Accuracy: 35.28%, Test Loss: 1.3172, Test Accuracy: 39.24%\n",
      "Epoch [301/2500], Train Loss: 1.3418, Train Accuracy: 35.28%, Test Loss: 1.3171, Test Accuracy: 39.24%\n",
      "Epoch [302/2500], Train Loss: 1.3415, Train Accuracy: 35.28%, Test Loss: 1.3172, Test Accuracy: 39.24%\n",
      "Epoch [303/2500], Train Loss: 1.3414, Train Accuracy: 35.28%, Test Loss: 1.3172, Test Accuracy: 39.24%\n",
      "Epoch [304/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3171, Test Accuracy: 39.24%\n",
      "Epoch [305/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3171, Test Accuracy: 39.24%\n",
      "Epoch [306/2500], Train Loss: 1.3412, Train Accuracy: 35.28%, Test Loss: 1.3171, Test Accuracy: 39.24%\n",
      "Epoch [307/2500], Train Loss: 1.3416, Train Accuracy: 35.28%, Test Loss: 1.3171, Test Accuracy: 39.24%\n",
      "Epoch [308/2500], Train Loss: 1.3415, Train Accuracy: 35.28%, Test Loss: 1.3170, Test Accuracy: 39.24%\n",
      "Epoch [309/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3170, Test Accuracy: 39.24%\n",
      "Epoch [310/2500], Train Loss: 1.3415, Train Accuracy: 35.28%, Test Loss: 1.3170, Test Accuracy: 39.24%\n",
      "Epoch [311/2500], Train Loss: 1.3415, Train Accuracy: 35.28%, Test Loss: 1.3171, Test Accuracy: 39.24%\n",
      "Epoch [312/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3170, Test Accuracy: 39.24%\n",
      "Epoch [313/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3170, Test Accuracy: 39.24%\n",
      "Epoch [314/2500], Train Loss: 1.3420, Train Accuracy: 35.28%, Test Loss: 1.3171, Test Accuracy: 39.24%\n",
      "Epoch [315/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3170, Test Accuracy: 39.24%\n",
      "Epoch [316/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3169, Test Accuracy: 39.24%\n",
      "Epoch [317/2500], Train Loss: 1.3414, Train Accuracy: 35.28%, Test Loss: 1.3170, Test Accuracy: 39.24%\n",
      "Epoch [318/2500], Train Loss: 1.3412, Train Accuracy: 35.28%, Test Loss: 1.3169, Test Accuracy: 39.24%\n",
      "Epoch [319/2500], Train Loss: 1.3416, Train Accuracy: 35.28%, Test Loss: 1.3170, Test Accuracy: 39.24%\n",
      "Epoch [320/2500], Train Loss: 1.3414, Train Accuracy: 35.28%, Test Loss: 1.3169, Test Accuracy: 39.24%\n",
      "Epoch [321/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3170, Test Accuracy: 39.24%\n",
      "Epoch [322/2500], Train Loss: 1.3417, Train Accuracy: 35.28%, Test Loss: 1.3169, Test Accuracy: 39.24%\n",
      "Epoch [323/2500], Train Loss: 1.3412, Train Accuracy: 35.28%, Test Loss: 1.3169, Test Accuracy: 39.24%\n",
      "Epoch [324/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3169, Test Accuracy: 39.24%\n",
      "Epoch [325/2500], Train Loss: 1.3414, Train Accuracy: 35.28%, Test Loss: 1.3169, Test Accuracy: 39.24%\n",
      "Epoch [326/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3169, Test Accuracy: 39.24%\n",
      "Epoch [327/2500], Train Loss: 1.3418, Train Accuracy: 35.28%, Test Loss: 1.3169, Test Accuracy: 39.24%\n",
      "Epoch [328/2500], Train Loss: 1.3419, Train Accuracy: 35.28%, Test Loss: 1.3169, Test Accuracy: 39.24%\n",
      "Epoch [329/2500], Train Loss: 1.3418, Train Accuracy: 35.28%, Test Loss: 1.3169, Test Accuracy: 39.24%\n",
      "Epoch [330/2500], Train Loss: 1.3419, Train Accuracy: 35.28%, Test Loss: 1.3168, Test Accuracy: 39.24%\n",
      "Epoch [331/2500], Train Loss: 1.3414, Train Accuracy: 35.28%, Test Loss: 1.3168, Test Accuracy: 39.24%\n",
      "Epoch [332/2500], Train Loss: 1.3410, Train Accuracy: 35.28%, Test Loss: 1.3169, Test Accuracy: 39.24%\n",
      "Epoch [333/2500], Train Loss: 1.3415, Train Accuracy: 35.28%, Test Loss: 1.3169, Test Accuracy: 39.24%\n",
      "Epoch [334/2500], Train Loss: 1.3415, Train Accuracy: 35.28%, Test Loss: 1.3168, Test Accuracy: 39.24%\n",
      "Epoch [335/2500], Train Loss: 1.3417, Train Accuracy: 35.28%, Test Loss: 1.3168, Test Accuracy: 39.24%\n",
      "Epoch [336/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3169, Test Accuracy: 39.24%\n",
      "Epoch [337/2500], Train Loss: 1.3410, Train Accuracy: 35.28%, Test Loss: 1.3168, Test Accuracy: 39.24%\n",
      "Epoch [338/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3168, Test Accuracy: 39.24%\n",
      "Epoch [339/2500], Train Loss: 1.3416, Train Accuracy: 35.28%, Test Loss: 1.3167, Test Accuracy: 39.24%\n",
      "Epoch [340/2500], Train Loss: 1.3410, Train Accuracy: 35.28%, Test Loss: 1.3168, Test Accuracy: 39.24%\n",
      "Epoch [341/2500], Train Loss: 1.3417, Train Accuracy: 35.28%, Test Loss: 1.3167, Test Accuracy: 39.24%\n",
      "Epoch [342/2500], Train Loss: 1.3415, Train Accuracy: 35.28%, Test Loss: 1.3167, Test Accuracy: 39.24%\n",
      "Epoch [343/2500], Train Loss: 1.3414, Train Accuracy: 35.28%, Test Loss: 1.3168, Test Accuracy: 39.24%\n",
      "Epoch [344/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3166, Test Accuracy: 39.24%\n",
      "Epoch [345/2500], Train Loss: 1.3415, Train Accuracy: 35.28%, Test Loss: 1.3167, Test Accuracy: 39.24%\n",
      "Epoch [346/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3167, Test Accuracy: 39.24%\n",
      "Epoch [347/2500], Train Loss: 1.3410, Train Accuracy: 35.28%, Test Loss: 1.3168, Test Accuracy: 39.24%\n",
      "Epoch [348/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3166, Test Accuracy: 39.24%\n",
      "Epoch [349/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3167, Test Accuracy: 39.24%\n",
      "Epoch [350/2500], Train Loss: 1.3415, Train Accuracy: 35.28%, Test Loss: 1.3166, Test Accuracy: 39.24%\n",
      "Epoch [351/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3166, Test Accuracy: 39.24%\n",
      "Epoch [352/2500], Train Loss: 1.3419, Train Accuracy: 35.28%, Test Loss: 1.3166, Test Accuracy: 39.24%\n",
      "Epoch [353/2500], Train Loss: 1.3408, Train Accuracy: 35.28%, Test Loss: 1.3167, Test Accuracy: 39.24%\n",
      "Epoch [354/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3166, Test Accuracy: 39.24%\n",
      "Epoch [355/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3166, Test Accuracy: 39.24%\n",
      "Epoch [356/2500], Train Loss: 1.3410, Train Accuracy: 35.28%, Test Loss: 1.3165, Test Accuracy: 39.24%\n",
      "Epoch [357/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3166, Test Accuracy: 39.24%\n",
      "Epoch [358/2500], Train Loss: 1.3414, Train Accuracy: 35.28%, Test Loss: 1.3166, Test Accuracy: 39.24%\n",
      "Epoch [359/2500], Train Loss: 1.3408, Train Accuracy: 35.28%, Test Loss: 1.3165, Test Accuracy: 39.24%\n",
      "Epoch [360/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3166, Test Accuracy: 39.24%\n",
      "Epoch [361/2500], Train Loss: 1.3412, Train Accuracy: 35.28%, Test Loss: 1.3164, Test Accuracy: 39.24%\n",
      "Epoch [362/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3164, Test Accuracy: 39.24%\n",
      "Epoch [363/2500], Train Loss: 1.3414, Train Accuracy: 35.28%, Test Loss: 1.3164, Test Accuracy: 39.24%\n",
      "Epoch [364/2500], Train Loss: 1.3416, Train Accuracy: 35.28%, Test Loss: 1.3165, Test Accuracy: 39.24%\n",
      "Epoch [365/2500], Train Loss: 1.3412, Train Accuracy: 35.28%, Test Loss: 1.3164, Test Accuracy: 39.24%\n",
      "Epoch [366/2500], Train Loss: 1.3412, Train Accuracy: 35.28%, Test Loss: 1.3164, Test Accuracy: 39.24%\n",
      "Epoch [367/2500], Train Loss: 1.3415, Train Accuracy: 35.28%, Test Loss: 1.3164, Test Accuracy: 39.24%\n",
      "Epoch [368/2500], Train Loss: 1.3412, Train Accuracy: 35.28%, Test Loss: 1.3164, Test Accuracy: 39.24%\n",
      "Epoch [369/2500], Train Loss: 1.3406, Train Accuracy: 35.28%, Test Loss: 1.3164, Test Accuracy: 39.24%\n",
      "Epoch [370/2500], Train Loss: 1.3414, Train Accuracy: 35.28%, Test Loss: 1.3164, Test Accuracy: 39.24%\n",
      "Epoch [371/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3164, Test Accuracy: 39.24%\n",
      "Epoch [372/2500], Train Loss: 1.3416, Train Accuracy: 35.28%, Test Loss: 1.3164, Test Accuracy: 39.24%\n",
      "Epoch [373/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3162, Test Accuracy: 39.24%\n",
      "Epoch [374/2500], Train Loss: 1.3414, Train Accuracy: 35.28%, Test Loss: 1.3163, Test Accuracy: 39.24%\n",
      "Epoch [375/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3163, Test Accuracy: 39.24%\n",
      "Epoch [376/2500], Train Loss: 1.3412, Train Accuracy: 35.28%, Test Loss: 1.3164, Test Accuracy: 39.24%\n",
      "Epoch [377/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3165, Test Accuracy: 39.24%\n",
      "Epoch [378/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3163, Test Accuracy: 39.24%\n",
      "Epoch [379/2500], Train Loss: 1.3410, Train Accuracy: 35.28%, Test Loss: 1.3163, Test Accuracy: 39.24%\n",
      "Epoch [380/2500], Train Loss: 1.3415, Train Accuracy: 35.28%, Test Loss: 1.3163, Test Accuracy: 39.24%\n",
      "Epoch [381/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3163, Test Accuracy: 39.24%\n",
      "Epoch [382/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3162, Test Accuracy: 39.24%\n",
      "Epoch [383/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3161, Test Accuracy: 39.24%\n",
      "Epoch [384/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3163, Test Accuracy: 39.24%\n",
      "Epoch [385/2500], Train Loss: 1.3410, Train Accuracy: 35.28%, Test Loss: 1.3162, Test Accuracy: 39.24%\n",
      "Epoch [386/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3162, Test Accuracy: 39.24%\n",
      "Epoch [387/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3162, Test Accuracy: 39.24%\n",
      "Epoch [388/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3163, Test Accuracy: 39.24%\n",
      "Epoch [389/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3161, Test Accuracy: 39.24%\n",
      "Epoch [390/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3162, Test Accuracy: 39.24%\n",
      "Epoch [391/2500], Train Loss: 1.3410, Train Accuracy: 35.28%, Test Loss: 1.3160, Test Accuracy: 39.24%\n",
      "Epoch [392/2500], Train Loss: 1.3410, Train Accuracy: 35.28%, Test Loss: 1.3161, Test Accuracy: 39.24%\n",
      "Epoch [393/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3163, Test Accuracy: 39.24%\n",
      "Epoch [394/2500], Train Loss: 1.3405, Train Accuracy: 35.28%, Test Loss: 1.3160, Test Accuracy: 39.24%\n",
      "Epoch [395/2500], Train Loss: 1.3410, Train Accuracy: 35.28%, Test Loss: 1.3162, Test Accuracy: 39.24%\n",
      "Epoch [396/2500], Train Loss: 1.3414, Train Accuracy: 35.28%, Test Loss: 1.3161, Test Accuracy: 39.24%\n",
      "Epoch [397/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3163, Test Accuracy: 39.24%\n",
      "Epoch [398/2500], Train Loss: 1.3410, Train Accuracy: 35.28%, Test Loss: 1.3162, Test Accuracy: 39.24%\n",
      "Epoch [399/2500], Train Loss: 1.3412, Train Accuracy: 35.28%, Test Loss: 1.3161, Test Accuracy: 39.24%\n",
      "Epoch [400/2500], Train Loss: 1.3412, Train Accuracy: 35.28%, Test Loss: 1.3160, Test Accuracy: 39.24%\n",
      "Epoch [401/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3160, Test Accuracy: 39.24%\n",
      "Epoch [402/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3161, Test Accuracy: 39.24%\n",
      "Epoch [403/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3159, Test Accuracy: 39.24%\n",
      "Epoch [404/2500], Train Loss: 1.3408, Train Accuracy: 35.28%, Test Loss: 1.3160, Test Accuracy: 39.24%\n",
      "Epoch [405/2500], Train Loss: 1.3410, Train Accuracy: 35.28%, Test Loss: 1.3160, Test Accuracy: 39.24%\n",
      "Epoch [406/2500], Train Loss: 1.3410, Train Accuracy: 35.28%, Test Loss: 1.3160, Test Accuracy: 39.24%\n",
      "Epoch [407/2500], Train Loss: 1.3414, Train Accuracy: 35.28%, Test Loss: 1.3159, Test Accuracy: 39.24%\n",
      "Epoch [408/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3159, Test Accuracy: 39.24%\n",
      "Epoch [409/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3159, Test Accuracy: 39.24%\n",
      "Epoch [410/2500], Train Loss: 1.3410, Train Accuracy: 35.28%, Test Loss: 1.3159, Test Accuracy: 39.24%\n",
      "Epoch [411/2500], Train Loss: 1.3408, Train Accuracy: 35.28%, Test Loss: 1.3158, Test Accuracy: 39.24%\n",
      "Epoch [412/2500], Train Loss: 1.3408, Train Accuracy: 35.28%, Test Loss: 1.3158, Test Accuracy: 39.24%\n",
      "Epoch [413/2500], Train Loss: 1.3407, Train Accuracy: 35.28%, Test Loss: 1.3158, Test Accuracy: 39.24%\n",
      "Epoch [414/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3159, Test Accuracy: 39.24%\n",
      "Epoch [415/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3159, Test Accuracy: 39.24%\n",
      "Epoch [416/2500], Train Loss: 1.3407, Train Accuracy: 35.28%, Test Loss: 1.3159, Test Accuracy: 39.24%\n",
      "Epoch [417/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3157, Test Accuracy: 39.24%\n",
      "Epoch [418/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3158, Test Accuracy: 39.24%\n",
      "Epoch [419/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3160, Test Accuracy: 39.24%\n",
      "Epoch [420/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3158, Test Accuracy: 39.24%\n",
      "Epoch [421/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3158, Test Accuracy: 39.24%\n",
      "Epoch [422/2500], Train Loss: 1.3410, Train Accuracy: 35.28%, Test Loss: 1.3158, Test Accuracy: 39.24%\n",
      "Epoch [423/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3159, Test Accuracy: 39.24%\n",
      "Epoch [424/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3158, Test Accuracy: 39.24%\n",
      "Epoch [425/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3156, Test Accuracy: 39.24%\n",
      "Epoch [426/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3156, Test Accuracy: 39.24%\n",
      "Epoch [427/2500], Train Loss: 1.3410, Train Accuracy: 35.28%, Test Loss: 1.3157, Test Accuracy: 39.24%\n",
      "Epoch [428/2500], Train Loss: 1.3408, Train Accuracy: 35.28%, Test Loss: 1.3157, Test Accuracy: 39.24%\n",
      "Epoch [429/2500], Train Loss: 1.3404, Train Accuracy: 35.28%, Test Loss: 1.3158, Test Accuracy: 39.24%\n",
      "Epoch [430/2500], Train Loss: 1.3410, Train Accuracy: 35.28%, Test Loss: 1.3158, Test Accuracy: 39.24%\n",
      "Epoch [431/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3158, Test Accuracy: 39.24%\n",
      "Epoch [432/2500], Train Loss: 1.3412, Train Accuracy: 35.28%, Test Loss: 1.3157, Test Accuracy: 39.24%\n",
      "Epoch [433/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3158, Test Accuracy: 39.24%\n",
      "Epoch [434/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3156, Test Accuracy: 39.24%\n",
      "Epoch [435/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3158, Test Accuracy: 39.24%\n",
      "Epoch [436/2500], Train Loss: 1.3406, Train Accuracy: 35.28%, Test Loss: 1.3156, Test Accuracy: 39.24%\n",
      "Epoch [437/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3156, Test Accuracy: 39.24%\n",
      "Epoch [438/2500], Train Loss: 1.3407, Train Accuracy: 35.28%, Test Loss: 1.3156, Test Accuracy: 39.24%\n",
      "Epoch [439/2500], Train Loss: 1.3406, Train Accuracy: 35.28%, Test Loss: 1.3157, Test Accuracy: 39.24%\n",
      "Epoch [440/2500], Train Loss: 1.3410, Train Accuracy: 35.28%, Test Loss: 1.3155, Test Accuracy: 39.24%\n",
      "Epoch [441/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3157, Test Accuracy: 39.24%\n",
      "Epoch [442/2500], Train Loss: 1.3407, Train Accuracy: 35.28%, Test Loss: 1.3155, Test Accuracy: 39.24%\n",
      "Epoch [443/2500], Train Loss: 1.3408, Train Accuracy: 35.28%, Test Loss: 1.3154, Test Accuracy: 39.24%\n",
      "Epoch [444/2500], Train Loss: 1.3408, Train Accuracy: 35.28%, Test Loss: 1.3155, Test Accuracy: 39.24%\n",
      "Epoch [445/2500], Train Loss: 1.3404, Train Accuracy: 35.28%, Test Loss: 1.3155, Test Accuracy: 39.24%\n",
      "Epoch [446/2500], Train Loss: 1.3408, Train Accuracy: 35.28%, Test Loss: 1.3155, Test Accuracy: 39.24%\n",
      "Epoch [447/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3155, Test Accuracy: 39.24%\n",
      "Epoch [448/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3155, Test Accuracy: 39.24%\n",
      "Epoch [449/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3155, Test Accuracy: 39.24%\n",
      "Epoch [450/2500], Train Loss: 1.3410, Train Accuracy: 35.28%, Test Loss: 1.3154, Test Accuracy: 39.24%\n",
      "Epoch [451/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3155, Test Accuracy: 39.24%\n",
      "Epoch [452/2500], Train Loss: 1.3404, Train Accuracy: 35.28%, Test Loss: 1.3155, Test Accuracy: 39.24%\n",
      "Epoch [453/2500], Train Loss: 1.3405, Train Accuracy: 35.28%, Test Loss: 1.3155, Test Accuracy: 39.24%\n",
      "Epoch [454/2500], Train Loss: 1.3406, Train Accuracy: 35.28%, Test Loss: 1.3154, Test Accuracy: 39.24%\n",
      "Epoch [455/2500], Train Loss: 1.3408, Train Accuracy: 35.28%, Test Loss: 1.3154, Test Accuracy: 39.24%\n",
      "Epoch [456/2500], Train Loss: 1.3412, Train Accuracy: 35.28%, Test Loss: 1.3153, Test Accuracy: 39.24%\n",
      "Epoch [457/2500], Train Loss: 1.3407, Train Accuracy: 35.28%, Test Loss: 1.3153, Test Accuracy: 39.24%\n",
      "Epoch [458/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3154, Test Accuracy: 39.24%\n",
      "Epoch [459/2500], Train Loss: 1.3408, Train Accuracy: 35.28%, Test Loss: 1.3153, Test Accuracy: 39.24%\n",
      "Epoch [460/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3155, Test Accuracy: 39.24%\n",
      "Epoch [461/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3154, Test Accuracy: 39.24%\n",
      "Epoch [462/2500], Train Loss: 1.3408, Train Accuracy: 35.28%, Test Loss: 1.3154, Test Accuracy: 39.24%\n",
      "Epoch [463/2500], Train Loss: 1.3406, Train Accuracy: 35.28%, Test Loss: 1.3153, Test Accuracy: 39.24%\n",
      "Epoch [464/2500], Train Loss: 1.3411, Train Accuracy: 35.28%, Test Loss: 1.3151, Test Accuracy: 39.24%\n",
      "Epoch [465/2500], Train Loss: 1.3413, Train Accuracy: 35.28%, Test Loss: 1.3153, Test Accuracy: 39.24%\n",
      "Epoch [466/2500], Train Loss: 1.3406, Train Accuracy: 35.28%, Test Loss: 1.3151, Test Accuracy: 39.24%\n",
      "Epoch [467/2500], Train Loss: 1.3403, Train Accuracy: 35.28%, Test Loss: 1.3151, Test Accuracy: 39.24%\n",
      "Epoch [468/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3149, Test Accuracy: 39.24%\n",
      "Epoch [469/2500], Train Loss: 1.3410, Train Accuracy: 35.28%, Test Loss: 1.3151, Test Accuracy: 39.24%\n",
      "Epoch [470/2500], Train Loss: 1.3404, Train Accuracy: 35.28%, Test Loss: 1.3151, Test Accuracy: 39.24%\n",
      "Epoch [471/2500], Train Loss: 1.3398, Train Accuracy: 35.28%, Test Loss: 1.3151, Test Accuracy: 39.24%\n",
      "Epoch [472/2500], Train Loss: 1.3406, Train Accuracy: 35.28%, Test Loss: 1.3151, Test Accuracy: 39.24%\n",
      "Epoch [473/2500], Train Loss: 1.3406, Train Accuracy: 35.28%, Test Loss: 1.3150, Test Accuracy: 39.24%\n",
      "Epoch [474/2500], Train Loss: 1.3412, Train Accuracy: 35.28%, Test Loss: 1.3150, Test Accuracy: 39.24%\n",
      "Epoch [475/2500], Train Loss: 1.3403, Train Accuracy: 35.28%, Test Loss: 1.3151, Test Accuracy: 39.24%\n",
      "Epoch [476/2500], Train Loss: 1.3407, Train Accuracy: 35.28%, Test Loss: 1.3150, Test Accuracy: 39.24%\n",
      "Epoch [477/2500], Train Loss: 1.3403, Train Accuracy: 35.28%, Test Loss: 1.3152, Test Accuracy: 39.24%\n",
      "Epoch [478/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3149, Test Accuracy: 39.24%\n",
      "Epoch [479/2500], Train Loss: 1.3412, Train Accuracy: 35.28%, Test Loss: 1.3151, Test Accuracy: 39.24%\n",
      "Epoch [480/2500], Train Loss: 1.3406, Train Accuracy: 35.28%, Test Loss: 1.3150, Test Accuracy: 39.24%\n",
      "Epoch [481/2500], Train Loss: 1.3407, Train Accuracy: 35.28%, Test Loss: 1.3149, Test Accuracy: 39.24%\n",
      "Epoch [482/2500], Train Loss: 1.3402, Train Accuracy: 35.28%, Test Loss: 1.3153, Test Accuracy: 39.24%\n",
      "Epoch [483/2500], Train Loss: 1.3407, Train Accuracy: 35.28%, Test Loss: 1.3150, Test Accuracy: 39.24%\n",
      "Epoch [484/2500], Train Loss: 1.3407, Train Accuracy: 35.28%, Test Loss: 1.3149, Test Accuracy: 39.24%\n",
      "Epoch [485/2500], Train Loss: 1.3408, Train Accuracy: 35.28%, Test Loss: 1.3148, Test Accuracy: 39.24%\n",
      "Epoch [486/2500], Train Loss: 1.3404, Train Accuracy: 35.28%, Test Loss: 1.3151, Test Accuracy: 39.24%\n",
      "Epoch [487/2500], Train Loss: 1.3403, Train Accuracy: 35.28%, Test Loss: 1.3149, Test Accuracy: 39.24%\n",
      "Epoch [488/2500], Train Loss: 1.3406, Train Accuracy: 35.28%, Test Loss: 1.3149, Test Accuracy: 39.24%\n",
      "Epoch [489/2500], Train Loss: 1.3407, Train Accuracy: 35.28%, Test Loss: 1.3147, Test Accuracy: 39.24%\n",
      "Epoch [490/2500], Train Loss: 1.3404, Train Accuracy: 35.28%, Test Loss: 1.3146, Test Accuracy: 39.24%\n",
      "Epoch [491/2500], Train Loss: 1.3405, Train Accuracy: 35.28%, Test Loss: 1.3148, Test Accuracy: 39.24%\n",
      "Epoch [492/2500], Train Loss: 1.3403, Train Accuracy: 35.28%, Test Loss: 1.3147, Test Accuracy: 39.24%\n",
      "Epoch [493/2500], Train Loss: 1.3406, Train Accuracy: 35.28%, Test Loss: 1.3147, Test Accuracy: 39.24%\n",
      "Epoch [494/2500], Train Loss: 1.3404, Train Accuracy: 35.28%, Test Loss: 1.3147, Test Accuracy: 39.24%\n",
      "Epoch [495/2500], Train Loss: 1.3404, Train Accuracy: 35.28%, Test Loss: 1.3147, Test Accuracy: 39.24%\n",
      "Epoch [496/2500], Train Loss: 1.3408, Train Accuracy: 35.28%, Test Loss: 1.3147, Test Accuracy: 39.24%\n",
      "Epoch [497/2500], Train Loss: 1.3408, Train Accuracy: 35.28%, Test Loss: 1.3146, Test Accuracy: 39.24%\n",
      "Epoch [498/2500], Train Loss: 1.3403, Train Accuracy: 35.28%, Test Loss: 1.3148, Test Accuracy: 39.24%\n",
      "Epoch [499/2500], Train Loss: 1.3408, Train Accuracy: 35.28%, Test Loss: 1.3149, Test Accuracy: 39.24%\n",
      "Epoch [500/2500], Train Loss: 1.3401, Train Accuracy: 35.28%, Test Loss: 1.3146, Test Accuracy: 39.24%\n",
      "Epoch [501/2500], Train Loss: 1.3402, Train Accuracy: 35.28%, Test Loss: 1.3145, Test Accuracy: 39.24%\n",
      "Epoch [502/2500], Train Loss: 1.3405, Train Accuracy: 35.28%, Test Loss: 1.3146, Test Accuracy: 39.24%\n",
      "Epoch [503/2500], Train Loss: 1.3406, Train Accuracy: 35.28%, Test Loss: 1.3144, Test Accuracy: 39.24%\n",
      "Epoch [504/2500], Train Loss: 1.3405, Train Accuracy: 35.28%, Test Loss: 1.3144, Test Accuracy: 39.24%\n",
      "Epoch [505/2500], Train Loss: 1.3407, Train Accuracy: 35.28%, Test Loss: 1.3145, Test Accuracy: 39.24%\n",
      "Epoch [506/2500], Train Loss: 1.3403, Train Accuracy: 35.28%, Test Loss: 1.3148, Test Accuracy: 39.24%\n",
      "Epoch [507/2500], Train Loss: 1.3403, Train Accuracy: 35.28%, Test Loss: 1.3147, Test Accuracy: 39.24%\n",
      "Epoch [508/2500], Train Loss: 1.3405, Train Accuracy: 35.28%, Test Loss: 1.3145, Test Accuracy: 39.24%\n",
      "Epoch [509/2500], Train Loss: 1.3404, Train Accuracy: 35.28%, Test Loss: 1.3145, Test Accuracy: 39.24%\n",
      "Epoch [510/2500], Train Loss: 1.3405, Train Accuracy: 35.28%, Test Loss: 1.3145, Test Accuracy: 39.24%\n",
      "Epoch [511/2500], Train Loss: 1.3403, Train Accuracy: 35.28%, Test Loss: 1.3146, Test Accuracy: 39.24%\n",
      "Epoch [512/2500], Train Loss: 1.3407, Train Accuracy: 35.28%, Test Loss: 1.3146, Test Accuracy: 39.24%\n",
      "Epoch [513/2500], Train Loss: 1.3410, Train Accuracy: 35.28%, Test Loss: 1.3145, Test Accuracy: 39.24%\n",
      "Epoch [514/2500], Train Loss: 1.3409, Train Accuracy: 35.28%, Test Loss: 1.3146, Test Accuracy: 39.24%\n",
      "Epoch [515/2500], Train Loss: 1.3400, Train Accuracy: 35.28%, Test Loss: 1.3143, Test Accuracy: 39.24%\n",
      "Epoch [516/2500], Train Loss: 1.3400, Train Accuracy: 35.28%, Test Loss: 1.3142, Test Accuracy: 39.24%\n",
      "Epoch [517/2500], Train Loss: 1.3401, Train Accuracy: 35.28%, Test Loss: 1.3143, Test Accuracy: 39.24%\n",
      "Epoch [518/2500], Train Loss: 1.3406, Train Accuracy: 35.28%, Test Loss: 1.3144, Test Accuracy: 39.24%\n",
      "Epoch [519/2500], Train Loss: 1.3402, Train Accuracy: 35.28%, Test Loss: 1.3143, Test Accuracy: 39.24%\n",
      "Epoch [520/2500], Train Loss: 1.3401, Train Accuracy: 35.28%, Test Loss: 1.3144, Test Accuracy: 39.24%\n",
      "Epoch [521/2500], Train Loss: 1.3408, Train Accuracy: 35.28%, Test Loss: 1.3142, Test Accuracy: 39.24%\n",
      "Epoch [522/2500], Train Loss: 1.3401, Train Accuracy: 35.28%, Test Loss: 1.3141, Test Accuracy: 39.24%\n",
      "Epoch [523/2500], Train Loss: 1.3402, Train Accuracy: 35.28%, Test Loss: 1.3142, Test Accuracy: 39.24%\n",
      "Epoch [524/2500], Train Loss: 1.3403, Train Accuracy: 35.28%, Test Loss: 1.3144, Test Accuracy: 39.24%\n",
      "Epoch [525/2500], Train Loss: 1.3401, Train Accuracy: 35.28%, Test Loss: 1.3142, Test Accuracy: 39.24%\n",
      "Epoch [526/2500], Train Loss: 1.3400, Train Accuracy: 35.28%, Test Loss: 1.3143, Test Accuracy: 39.24%\n",
      "Epoch [527/2500], Train Loss: 1.3404, Train Accuracy: 35.28%, Test Loss: 1.3142, Test Accuracy: 39.24%\n",
      "Epoch [528/2500], Train Loss: 1.3406, Train Accuracy: 35.28%, Test Loss: 1.3140, Test Accuracy: 39.24%\n",
      "Epoch [529/2500], Train Loss: 1.3402, Train Accuracy: 35.28%, Test Loss: 1.3143, Test Accuracy: 39.24%\n",
      "Epoch [530/2500], Train Loss: 1.3406, Train Accuracy: 35.28%, Test Loss: 1.3142, Test Accuracy: 39.24%\n",
      "Epoch [531/2500], Train Loss: 1.3402, Train Accuracy: 35.28%, Test Loss: 1.3139, Test Accuracy: 39.24%\n",
      "Epoch [532/2500], Train Loss: 1.3403, Train Accuracy: 35.28%, Test Loss: 1.3140, Test Accuracy: 39.24%\n",
      "Epoch [533/2500], Train Loss: 1.3402, Train Accuracy: 35.28%, Test Loss: 1.3143, Test Accuracy: 39.24%\n",
      "Epoch [534/2500], Train Loss: 1.3397, Train Accuracy: 35.28%, Test Loss: 1.3143, Test Accuracy: 39.24%\n",
      "Epoch [535/2500], Train Loss: 1.3399, Train Accuracy: 35.28%, Test Loss: 1.3140, Test Accuracy: 39.24%\n",
      "Epoch [536/2500], Train Loss: 1.3400, Train Accuracy: 35.28%, Test Loss: 1.3139, Test Accuracy: 39.24%\n",
      "Epoch [537/2500], Train Loss: 1.3399, Train Accuracy: 35.28%, Test Loss: 1.3140, Test Accuracy: 39.24%\n",
      "Epoch [538/2500], Train Loss: 1.3405, Train Accuracy: 35.28%, Test Loss: 1.3140, Test Accuracy: 39.24%\n",
      "Epoch [539/2500], Train Loss: 1.3400, Train Accuracy: 35.28%, Test Loss: 1.3137, Test Accuracy: 39.24%\n",
      "Epoch [540/2500], Train Loss: 1.3401, Train Accuracy: 35.28%, Test Loss: 1.3140, Test Accuracy: 39.24%\n",
      "Epoch [541/2500], Train Loss: 1.3404, Train Accuracy: 35.28%, Test Loss: 1.3137, Test Accuracy: 39.24%\n",
      "Epoch [542/2500], Train Loss: 1.3399, Train Accuracy: 35.28%, Test Loss: 1.3139, Test Accuracy: 39.24%\n",
      "Epoch [543/2500], Train Loss: 1.3400, Train Accuracy: 35.28%, Test Loss: 1.3137, Test Accuracy: 39.24%\n",
      "Epoch [544/2500], Train Loss: 1.3403, Train Accuracy: 35.28%, Test Loss: 1.3136, Test Accuracy: 39.24%\n",
      "Epoch [545/2500], Train Loss: 1.3401, Train Accuracy: 35.28%, Test Loss: 1.3138, Test Accuracy: 39.24%\n",
      "Epoch [546/2500], Train Loss: 1.3398, Train Accuracy: 35.28%, Test Loss: 1.3137, Test Accuracy: 39.24%\n",
      "Epoch [547/2500], Train Loss: 1.3400, Train Accuracy: 35.28%, Test Loss: 1.3139, Test Accuracy: 39.24%\n",
      "Epoch [548/2500], Train Loss: 1.3397, Train Accuracy: 35.28%, Test Loss: 1.3138, Test Accuracy: 39.24%\n",
      "Epoch [549/2500], Train Loss: 1.3400, Train Accuracy: 35.28%, Test Loss: 1.3137, Test Accuracy: 39.24%\n",
      "Epoch [550/2500], Train Loss: 1.3400, Train Accuracy: 35.28%, Test Loss: 1.3139, Test Accuracy: 39.24%\n",
      "Epoch [551/2500], Train Loss: 1.3400, Train Accuracy: 35.28%, Test Loss: 1.3137, Test Accuracy: 39.24%\n",
      "Epoch [552/2500], Train Loss: 1.3401, Train Accuracy: 35.28%, Test Loss: 1.3137, Test Accuracy: 39.24%\n",
      "Epoch [553/2500], Train Loss: 1.3400, Train Accuracy: 35.28%, Test Loss: 1.3139, Test Accuracy: 39.24%\n",
      "Epoch [554/2500], Train Loss: 1.3400, Train Accuracy: 35.28%, Test Loss: 1.3137, Test Accuracy: 39.24%\n",
      "Epoch [555/2500], Train Loss: 1.3401, Train Accuracy: 35.28%, Test Loss: 1.3136, Test Accuracy: 39.24%\n",
      "Epoch [556/2500], Train Loss: 1.3398, Train Accuracy: 35.28%, Test Loss: 1.3134, Test Accuracy: 39.24%\n",
      "Epoch [557/2500], Train Loss: 1.3401, Train Accuracy: 35.28%, Test Loss: 1.3136, Test Accuracy: 39.24%\n",
      "Epoch [558/2500], Train Loss: 1.3401, Train Accuracy: 35.28%, Test Loss: 1.3135, Test Accuracy: 39.24%\n",
      "Epoch [559/2500], Train Loss: 1.3400, Train Accuracy: 35.28%, Test Loss: 1.3135, Test Accuracy: 39.24%\n",
      "Epoch [560/2500], Train Loss: 1.3400, Train Accuracy: 35.28%, Test Loss: 1.3135, Test Accuracy: 39.24%\n",
      "Epoch [561/2500], Train Loss: 1.3397, Train Accuracy: 35.28%, Test Loss: 1.3132, Test Accuracy: 39.24%\n",
      "Epoch [562/2500], Train Loss: 1.3404, Train Accuracy: 35.28%, Test Loss: 1.3133, Test Accuracy: 39.24%\n",
      "Epoch [563/2500], Train Loss: 1.3396, Train Accuracy: 35.28%, Test Loss: 1.3134, Test Accuracy: 39.24%\n",
      "Epoch [564/2500], Train Loss: 1.3405, Train Accuracy: 35.28%, Test Loss: 1.3134, Test Accuracy: 39.24%\n",
      "Epoch [565/2500], Train Loss: 1.3401, Train Accuracy: 35.28%, Test Loss: 1.3135, Test Accuracy: 39.24%\n",
      "Epoch [566/2500], Train Loss: 1.3396, Train Accuracy: 35.28%, Test Loss: 1.3135, Test Accuracy: 39.24%\n",
      "Epoch [567/2500], Train Loss: 1.3400, Train Accuracy: 35.28%, Test Loss: 1.3132, Test Accuracy: 39.24%\n",
      "Epoch [568/2500], Train Loss: 1.3404, Train Accuracy: 35.28%, Test Loss: 1.3132, Test Accuracy: 39.24%\n",
      "Epoch [569/2500], Train Loss: 1.3405, Train Accuracy: 35.28%, Test Loss: 1.3132, Test Accuracy: 39.24%\n",
      "Epoch [570/2500], Train Loss: 1.3397, Train Accuracy: 35.28%, Test Loss: 1.3133, Test Accuracy: 39.24%\n",
      "Epoch [571/2500], Train Loss: 1.3397, Train Accuracy: 35.28%, Test Loss: 1.3132, Test Accuracy: 39.24%\n",
      "Epoch [572/2500], Train Loss: 1.3397, Train Accuracy: 35.28%, Test Loss: 1.3133, Test Accuracy: 39.24%\n",
      "Epoch [573/2500], Train Loss: 1.3403, Train Accuracy: 35.28%, Test Loss: 1.3131, Test Accuracy: 39.24%\n",
      "Epoch [574/2500], Train Loss: 1.3401, Train Accuracy: 35.28%, Test Loss: 1.3131, Test Accuracy: 39.24%\n",
      "Epoch [575/2500], Train Loss: 1.3398, Train Accuracy: 35.28%, Test Loss: 1.3132, Test Accuracy: 39.24%\n",
      "Epoch [576/2500], Train Loss: 1.3404, Train Accuracy: 35.28%, Test Loss: 1.3132, Test Accuracy: 39.24%\n",
      "Epoch [577/2500], Train Loss: 1.3399, Train Accuracy: 35.28%, Test Loss: 1.3129, Test Accuracy: 39.24%\n",
      "Epoch [578/2500], Train Loss: 1.3396, Train Accuracy: 35.28%, Test Loss: 1.3131, Test Accuracy: 39.24%\n",
      "Epoch [579/2500], Train Loss: 1.3398, Train Accuracy: 35.28%, Test Loss: 1.3129, Test Accuracy: 39.24%\n",
      "Epoch [580/2500], Train Loss: 1.3399, Train Accuracy: 35.28%, Test Loss: 1.3132, Test Accuracy: 39.24%\n",
      "Epoch [581/2500], Train Loss: 1.3396, Train Accuracy: 35.28%, Test Loss: 1.3129, Test Accuracy: 39.24%\n",
      "Epoch [582/2500], Train Loss: 1.3407, Train Accuracy: 35.28%, Test Loss: 1.3127, Test Accuracy: 39.24%\n",
      "Epoch [583/2500], Train Loss: 1.3396, Train Accuracy: 35.28%, Test Loss: 1.3127, Test Accuracy: 39.24%\n",
      "Epoch [584/2500], Train Loss: 1.3392, Train Accuracy: 35.28%, Test Loss: 1.3129, Test Accuracy: 39.24%\n",
      "Epoch [585/2500], Train Loss: 1.3402, Train Accuracy: 35.28%, Test Loss: 1.3128, Test Accuracy: 39.24%\n",
      "Epoch [586/2500], Train Loss: 1.3395, Train Accuracy: 35.28%, Test Loss: 1.3127, Test Accuracy: 39.24%\n",
      "Epoch [587/2500], Train Loss: 1.3403, Train Accuracy: 35.28%, Test Loss: 1.3130, Test Accuracy: 39.24%\n",
      "Epoch [588/2500], Train Loss: 1.3398, Train Accuracy: 35.28%, Test Loss: 1.3127, Test Accuracy: 39.24%\n",
      "Epoch [589/2500], Train Loss: 1.3404, Train Accuracy: 35.28%, Test Loss: 1.3127, Test Accuracy: 39.24%\n",
      "Epoch [590/2500], Train Loss: 1.3396, Train Accuracy: 35.28%, Test Loss: 1.3126, Test Accuracy: 39.24%\n",
      "Epoch [591/2500], Train Loss: 1.3398, Train Accuracy: 35.28%, Test Loss: 1.3127, Test Accuracy: 39.24%\n",
      "Epoch [592/2500], Train Loss: 1.3399, Train Accuracy: 35.28%, Test Loss: 1.3127, Test Accuracy: 39.24%\n",
      "Epoch [593/2500], Train Loss: 1.3399, Train Accuracy: 35.28%, Test Loss: 1.3125, Test Accuracy: 39.24%\n",
      "Epoch [594/2500], Train Loss: 1.3398, Train Accuracy: 35.28%, Test Loss: 1.3125, Test Accuracy: 39.24%\n",
      "Epoch [595/2500], Train Loss: 1.3394, Train Accuracy: 35.28%, Test Loss: 1.3123, Test Accuracy: 39.24%\n",
      "Epoch [596/2500], Train Loss: 1.3402, Train Accuracy: 35.28%, Test Loss: 1.3123, Test Accuracy: 39.24%\n",
      "Epoch [597/2500], Train Loss: 1.3399, Train Accuracy: 35.28%, Test Loss: 1.3123, Test Accuracy: 39.24%\n",
      "Epoch [598/2500], Train Loss: 1.3398, Train Accuracy: 35.28%, Test Loss: 1.3124, Test Accuracy: 39.24%\n",
      "Epoch [599/2500], Train Loss: 1.3396, Train Accuracy: 35.28%, Test Loss: 1.3121, Test Accuracy: 39.24%\n",
      "Epoch [600/2500], Train Loss: 1.3401, Train Accuracy: 35.28%, Test Loss: 1.3124, Test Accuracy: 39.24%\n",
      "Epoch [601/2500], Train Loss: 1.3395, Train Accuracy: 35.28%, Test Loss: 1.3124, Test Accuracy: 39.24%\n",
      "Epoch [602/2500], Train Loss: 1.3394, Train Accuracy: 35.28%, Test Loss: 1.3127, Test Accuracy: 39.24%\n",
      "Epoch [603/2500], Train Loss: 1.3401, Train Accuracy: 35.28%, Test Loss: 1.3118, Test Accuracy: 39.24%\n",
      "Epoch [604/2500], Train Loss: 1.3395, Train Accuracy: 35.28%, Test Loss: 1.3121, Test Accuracy: 39.24%\n",
      "Epoch [605/2500], Train Loss: 1.3387, Train Accuracy: 35.28%, Test Loss: 1.3122, Test Accuracy: 39.24%\n",
      "Epoch [606/2500], Train Loss: 1.3393, Train Accuracy: 35.28%, Test Loss: 1.3122, Test Accuracy: 39.24%\n",
      "Epoch [607/2500], Train Loss: 1.3397, Train Accuracy: 35.28%, Test Loss: 1.3123, Test Accuracy: 39.24%\n",
      "Epoch [608/2500], Train Loss: 1.3391, Train Accuracy: 35.28%, Test Loss: 1.3124, Test Accuracy: 39.24%\n",
      "Epoch [609/2500], Train Loss: 1.3393, Train Accuracy: 35.28%, Test Loss: 1.3122, Test Accuracy: 39.24%\n",
      "Epoch [610/2500], Train Loss: 1.3394, Train Accuracy: 35.28%, Test Loss: 1.3118, Test Accuracy: 39.24%\n",
      "Epoch [611/2500], Train Loss: 1.3390, Train Accuracy: 35.28%, Test Loss: 1.3119, Test Accuracy: 39.24%\n",
      "Epoch [612/2500], Train Loss: 1.3392, Train Accuracy: 35.28%, Test Loss: 1.3120, Test Accuracy: 39.24%\n",
      "Epoch [613/2500], Train Loss: 1.3396, Train Accuracy: 35.28%, Test Loss: 1.3118, Test Accuracy: 39.24%\n",
      "Epoch [614/2500], Train Loss: 1.3394, Train Accuracy: 35.28%, Test Loss: 1.3119, Test Accuracy: 39.24%\n",
      "Epoch [615/2500], Train Loss: 1.3386, Train Accuracy: 35.28%, Test Loss: 1.3120, Test Accuracy: 39.24%\n",
      "Epoch [616/2500], Train Loss: 1.3394, Train Accuracy: 35.28%, Test Loss: 1.3117, Test Accuracy: 39.24%\n",
      "Epoch [617/2500], Train Loss: 1.3391, Train Accuracy: 35.28%, Test Loss: 1.3117, Test Accuracy: 39.24%\n",
      "Epoch [618/2500], Train Loss: 1.3390, Train Accuracy: 35.28%, Test Loss: 1.3116, Test Accuracy: 39.24%\n",
      "Epoch [619/2500], Train Loss: 1.3393, Train Accuracy: 35.28%, Test Loss: 1.3119, Test Accuracy: 39.24%\n",
      "Epoch [620/2500], Train Loss: 1.3389, Train Accuracy: 35.28%, Test Loss: 1.3117, Test Accuracy: 39.24%\n",
      "Epoch [621/2500], Train Loss: 1.3392, Train Accuracy: 35.28%, Test Loss: 1.3117, Test Accuracy: 39.24%\n",
      "Epoch [622/2500], Train Loss: 1.3398, Train Accuracy: 35.28%, Test Loss: 1.3115, Test Accuracy: 39.24%\n",
      "Epoch [623/2500], Train Loss: 1.3385, Train Accuracy: 35.28%, Test Loss: 1.3114, Test Accuracy: 39.24%\n",
      "Epoch [624/2500], Train Loss: 1.3391, Train Accuracy: 35.28%, Test Loss: 1.3116, Test Accuracy: 39.24%\n",
      "Epoch [625/2500], Train Loss: 1.3396, Train Accuracy: 35.28%, Test Loss: 1.3114, Test Accuracy: 39.24%\n",
      "Epoch [626/2500], Train Loss: 1.3395, Train Accuracy: 35.28%, Test Loss: 1.3114, Test Accuracy: 39.24%\n",
      "Epoch [627/2500], Train Loss: 1.3393, Train Accuracy: 35.28%, Test Loss: 1.3116, Test Accuracy: 39.24%\n",
      "Epoch [628/2500], Train Loss: 1.3390, Train Accuracy: 35.28%, Test Loss: 1.3113, Test Accuracy: 39.24%\n",
      "Epoch [629/2500], Train Loss: 1.3388, Train Accuracy: 35.28%, Test Loss: 1.3114, Test Accuracy: 39.24%\n",
      "Epoch [630/2500], Train Loss: 1.3391, Train Accuracy: 35.28%, Test Loss: 1.3111, Test Accuracy: 39.24%\n",
      "Epoch [631/2500], Train Loss: 1.3390, Train Accuracy: 35.28%, Test Loss: 1.3114, Test Accuracy: 39.24%\n",
      "Epoch [632/2500], Train Loss: 1.3389, Train Accuracy: 35.28%, Test Loss: 1.3113, Test Accuracy: 39.24%\n",
      "Epoch [633/2500], Train Loss: 1.3396, Train Accuracy: 35.28%, Test Loss: 1.3114, Test Accuracy: 39.24%\n",
      "Epoch [634/2500], Train Loss: 1.3388, Train Accuracy: 35.28%, Test Loss: 1.3112, Test Accuracy: 39.24%\n",
      "Epoch [635/2500], Train Loss: 1.3391, Train Accuracy: 35.28%, Test Loss: 1.3112, Test Accuracy: 39.24%\n",
      "Epoch [636/2500], Train Loss: 1.3398, Train Accuracy: 35.28%, Test Loss: 1.3112, Test Accuracy: 39.24%\n",
      "Epoch [637/2500], Train Loss: 1.3386, Train Accuracy: 35.28%, Test Loss: 1.3111, Test Accuracy: 39.24%\n",
      "Epoch [638/2500], Train Loss: 1.3393, Train Accuracy: 35.28%, Test Loss: 1.3111, Test Accuracy: 39.24%\n",
      "Epoch [639/2500], Train Loss: 1.3387, Train Accuracy: 35.28%, Test Loss: 1.3107, Test Accuracy: 39.24%\n",
      "Epoch [640/2500], Train Loss: 1.3386, Train Accuracy: 35.28%, Test Loss: 1.3106, Test Accuracy: 39.24%\n",
      "Epoch [641/2500], Train Loss: 1.3393, Train Accuracy: 35.28%, Test Loss: 1.3110, Test Accuracy: 39.24%\n",
      "Epoch [642/2500], Train Loss: 1.3392, Train Accuracy: 35.28%, Test Loss: 1.3111, Test Accuracy: 39.24%\n",
      "Epoch [643/2500], Train Loss: 1.3388, Train Accuracy: 35.28%, Test Loss: 1.3111, Test Accuracy: 39.24%\n",
      "Epoch [644/2500], Train Loss: 1.3388, Train Accuracy: 35.28%, Test Loss: 1.3108, Test Accuracy: 39.24%\n",
      "Epoch [645/2500], Train Loss: 1.3388, Train Accuracy: 35.28%, Test Loss: 1.3106, Test Accuracy: 39.24%\n",
      "Epoch [646/2500], Train Loss: 1.3385, Train Accuracy: 35.28%, Test Loss: 1.3108, Test Accuracy: 39.24%\n",
      "Epoch [647/2500], Train Loss: 1.3394, Train Accuracy: 35.28%, Test Loss: 1.3107, Test Accuracy: 39.24%\n",
      "Epoch [648/2500], Train Loss: 1.3390, Train Accuracy: 35.28%, Test Loss: 1.3108, Test Accuracy: 39.24%\n",
      "Epoch [649/2500], Train Loss: 1.3393, Train Accuracy: 35.28%, Test Loss: 1.3106, Test Accuracy: 39.24%\n",
      "Epoch [650/2500], Train Loss: 1.3382, Train Accuracy: 35.28%, Test Loss: 1.3111, Test Accuracy: 39.24%\n",
      "Epoch [651/2500], Train Loss: 1.3388, Train Accuracy: 35.28%, Test Loss: 1.3107, Test Accuracy: 39.24%\n",
      "Epoch [652/2500], Train Loss: 1.3384, Train Accuracy: 35.28%, Test Loss: 1.3105, Test Accuracy: 39.24%\n",
      "Epoch [653/2500], Train Loss: 1.3384, Train Accuracy: 35.28%, Test Loss: 1.3101, Test Accuracy: 39.24%\n",
      "Epoch [654/2500], Train Loss: 1.3391, Train Accuracy: 35.28%, Test Loss: 1.3101, Test Accuracy: 39.24%\n",
      "Epoch [655/2500], Train Loss: 1.3386, Train Accuracy: 35.28%, Test Loss: 1.3103, Test Accuracy: 39.24%\n",
      "Epoch [656/2500], Train Loss: 1.3384, Train Accuracy: 35.28%, Test Loss: 1.3103, Test Accuracy: 39.24%\n",
      "Epoch [657/2500], Train Loss: 1.3382, Train Accuracy: 35.28%, Test Loss: 1.3101, Test Accuracy: 39.24%\n",
      "Epoch [658/2500], Train Loss: 1.3381, Train Accuracy: 35.28%, Test Loss: 1.3102, Test Accuracy: 39.24%\n",
      "Epoch [659/2500], Train Loss: 1.3385, Train Accuracy: 35.28%, Test Loss: 1.3106, Test Accuracy: 39.24%\n",
      "Epoch [660/2500], Train Loss: 1.3383, Train Accuracy: 35.28%, Test Loss: 1.3102, Test Accuracy: 39.24%\n",
      "Epoch [661/2500], Train Loss: 1.3380, Train Accuracy: 35.28%, Test Loss: 1.3097, Test Accuracy: 39.24%\n",
      "Epoch [662/2500], Train Loss: 1.3384, Train Accuracy: 35.28%, Test Loss: 1.3098, Test Accuracy: 39.24%\n",
      "Epoch [663/2500], Train Loss: 1.3378, Train Accuracy: 35.28%, Test Loss: 1.3097, Test Accuracy: 39.24%\n",
      "Epoch [664/2500], Train Loss: 1.3380, Train Accuracy: 35.28%, Test Loss: 1.3099, Test Accuracy: 39.24%\n",
      "Epoch [665/2500], Train Loss: 1.3374, Train Accuracy: 35.28%, Test Loss: 1.3100, Test Accuracy: 39.24%\n",
      "Epoch [666/2500], Train Loss: 1.3378, Train Accuracy: 35.28%, Test Loss: 1.3093, Test Accuracy: 39.24%\n",
      "Epoch [667/2500], Train Loss: 1.3384, Train Accuracy: 35.28%, Test Loss: 1.3098, Test Accuracy: 39.24%\n",
      "Epoch [668/2500], Train Loss: 1.3384, Train Accuracy: 35.28%, Test Loss: 1.3097, Test Accuracy: 39.24%\n",
      "Epoch [669/2500], Train Loss: 1.3384, Train Accuracy: 35.28%, Test Loss: 1.3100, Test Accuracy: 39.24%\n",
      "Epoch [670/2500], Train Loss: 1.3383, Train Accuracy: 35.28%, Test Loss: 1.3095, Test Accuracy: 39.24%\n",
      "Epoch [671/2500], Train Loss: 1.3379, Train Accuracy: 35.28%, Test Loss: 1.3099, Test Accuracy: 39.24%\n",
      "Epoch [672/2500], Train Loss: 1.3381, Train Accuracy: 35.28%, Test Loss: 1.3095, Test Accuracy: 39.24%\n",
      "Epoch [673/2500], Train Loss: 1.3376, Train Accuracy: 35.28%, Test Loss: 1.3094, Test Accuracy: 39.24%\n",
      "Epoch [674/2500], Train Loss: 1.3380, Train Accuracy: 35.28%, Test Loss: 1.3094, Test Accuracy: 39.24%\n",
      "Epoch [675/2500], Train Loss: 1.3381, Train Accuracy: 35.28%, Test Loss: 1.3090, Test Accuracy: 39.24%\n",
      "Epoch [676/2500], Train Loss: 1.3385, Train Accuracy: 35.28%, Test Loss: 1.3092, Test Accuracy: 39.24%\n",
      "Epoch [677/2500], Train Loss: 1.3379, Train Accuracy: 35.28%, Test Loss: 1.3088, Test Accuracy: 39.24%\n",
      "Epoch [678/2500], Train Loss: 1.3383, Train Accuracy: 35.28%, Test Loss: 1.3090, Test Accuracy: 39.24%\n",
      "Epoch [679/2500], Train Loss: 1.3381, Train Accuracy: 35.28%, Test Loss: 1.3089, Test Accuracy: 39.24%\n",
      "Epoch [680/2500], Train Loss: 1.3384, Train Accuracy: 35.28%, Test Loss: 1.3095, Test Accuracy: 39.24%\n",
      "Epoch [681/2500], Train Loss: 1.3376, Train Accuracy: 35.28%, Test Loss: 1.3091, Test Accuracy: 39.24%\n",
      "Epoch [682/2500], Train Loss: 1.3377, Train Accuracy: 35.28%, Test Loss: 1.3087, Test Accuracy: 39.24%\n",
      "Epoch [683/2500], Train Loss: 1.3377, Train Accuracy: 35.28%, Test Loss: 1.3089, Test Accuracy: 39.24%\n",
      "Epoch [684/2500], Train Loss: 1.3380, Train Accuracy: 35.28%, Test Loss: 1.3092, Test Accuracy: 39.24%\n",
      "Epoch [685/2500], Train Loss: 1.3374, Train Accuracy: 35.28%, Test Loss: 1.3086, Test Accuracy: 39.24%\n",
      "Epoch [686/2500], Train Loss: 1.3383, Train Accuracy: 35.28%, Test Loss: 1.3084, Test Accuracy: 39.24%\n",
      "Epoch [687/2500], Train Loss: 1.3375, Train Accuracy: 35.28%, Test Loss: 1.3087, Test Accuracy: 39.24%\n",
      "Epoch [688/2500], Train Loss: 1.3378, Train Accuracy: 35.28%, Test Loss: 1.3087, Test Accuracy: 39.24%\n",
      "Epoch [689/2500], Train Loss: 1.3378, Train Accuracy: 35.28%, Test Loss: 1.3086, Test Accuracy: 39.24%\n",
      "Epoch [690/2500], Train Loss: 1.3381, Train Accuracy: 35.28%, Test Loss: 1.3081, Test Accuracy: 39.24%\n",
      "Epoch [691/2500], Train Loss: 1.3374, Train Accuracy: 35.28%, Test Loss: 1.3086, Test Accuracy: 39.24%\n",
      "Epoch [692/2500], Train Loss: 1.3382, Train Accuracy: 35.28%, Test Loss: 1.3081, Test Accuracy: 39.24%\n",
      "Epoch [693/2500], Train Loss: 1.3381, Train Accuracy: 35.28%, Test Loss: 1.3082, Test Accuracy: 39.24%\n",
      "Epoch [694/2500], Train Loss: 1.3374, Train Accuracy: 35.28%, Test Loss: 1.3081, Test Accuracy: 39.24%\n",
      "Epoch [695/2500], Train Loss: 1.3375, Train Accuracy: 35.28%, Test Loss: 1.3082, Test Accuracy: 39.24%\n",
      "Epoch [696/2500], Train Loss: 1.3377, Train Accuracy: 35.28%, Test Loss: 1.3079, Test Accuracy: 39.24%\n",
      "Epoch [697/2500], Train Loss: 1.3377, Train Accuracy: 35.28%, Test Loss: 1.3081, Test Accuracy: 39.24%\n",
      "Epoch [698/2500], Train Loss: 1.3379, Train Accuracy: 35.28%, Test Loss: 1.3080, Test Accuracy: 39.24%\n",
      "Epoch [699/2500], Train Loss: 1.3373, Train Accuracy: 35.28%, Test Loss: 1.3077, Test Accuracy: 39.24%\n",
      "Epoch [700/2500], Train Loss: 1.3376, Train Accuracy: 35.28%, Test Loss: 1.3080, Test Accuracy: 39.24%\n",
      "Epoch [701/2500], Train Loss: 1.3376, Train Accuracy: 35.28%, Test Loss: 1.3072, Test Accuracy: 39.24%\n",
      "Epoch [702/2500], Train Loss: 1.3379, Train Accuracy: 35.28%, Test Loss: 1.3078, Test Accuracy: 39.24%\n",
      "Epoch [703/2500], Train Loss: 1.3370, Train Accuracy: 35.28%, Test Loss: 1.3078, Test Accuracy: 39.24%\n",
      "Epoch [704/2500], Train Loss: 1.3376, Train Accuracy: 35.28%, Test Loss: 1.3079, Test Accuracy: 39.24%\n",
      "Epoch [705/2500], Train Loss: 1.3376, Train Accuracy: 35.28%, Test Loss: 1.3069, Test Accuracy: 39.24%\n",
      "Epoch [706/2500], Train Loss: 1.3371, Train Accuracy: 35.28%, Test Loss: 1.3072, Test Accuracy: 39.24%\n",
      "Epoch [707/2500], Train Loss: 1.3367, Train Accuracy: 35.28%, Test Loss: 1.3074, Test Accuracy: 39.24%\n",
      "Epoch [708/2500], Train Loss: 1.3374, Train Accuracy: 35.28%, Test Loss: 1.3069, Test Accuracy: 39.24%\n",
      "Epoch [709/2500], Train Loss: 1.3367, Train Accuracy: 35.28%, Test Loss: 1.3067, Test Accuracy: 39.24%\n",
      "Epoch [710/2500], Train Loss: 1.3372, Train Accuracy: 35.28%, Test Loss: 1.3067, Test Accuracy: 39.24%\n",
      "Epoch [711/2500], Train Loss: 1.3370, Train Accuracy: 35.28%, Test Loss: 1.3069, Test Accuracy: 39.24%\n",
      "Epoch [712/2500], Train Loss: 1.3371, Train Accuracy: 35.28%, Test Loss: 1.3065, Test Accuracy: 39.24%\n",
      "Epoch [713/2500], Train Loss: 1.3369, Train Accuracy: 35.28%, Test Loss: 1.3068, Test Accuracy: 39.24%\n",
      "Epoch [714/2500], Train Loss: 1.3375, Train Accuracy: 35.28%, Test Loss: 1.3069, Test Accuracy: 39.24%\n",
      "Epoch [715/2500], Train Loss: 1.3363, Train Accuracy: 35.28%, Test Loss: 1.3064, Test Accuracy: 39.24%\n",
      "Epoch [716/2500], Train Loss: 1.3373, Train Accuracy: 35.28%, Test Loss: 1.3060, Test Accuracy: 39.24%\n",
      "Epoch [717/2500], Train Loss: 1.3372, Train Accuracy: 35.28%, Test Loss: 1.3061, Test Accuracy: 39.24%\n",
      "Epoch [718/2500], Train Loss: 1.3375, Train Accuracy: 35.28%, Test Loss: 1.3066, Test Accuracy: 39.24%\n",
      "Epoch [719/2500], Train Loss: 1.3370, Train Accuracy: 35.28%, Test Loss: 1.3060, Test Accuracy: 39.24%\n",
      "Epoch [720/2500], Train Loss: 1.3365, Train Accuracy: 35.28%, Test Loss: 1.3061, Test Accuracy: 39.24%\n",
      "Epoch [721/2500], Train Loss: 1.3370, Train Accuracy: 35.28%, Test Loss: 1.3055, Test Accuracy: 39.24%\n",
      "Epoch [722/2500], Train Loss: 1.3362, Train Accuracy: 35.28%, Test Loss: 1.3058, Test Accuracy: 39.24%\n",
      "Epoch [723/2500], Train Loss: 1.3367, Train Accuracy: 35.28%, Test Loss: 1.3057, Test Accuracy: 39.24%\n",
      "Epoch [724/2500], Train Loss: 1.3371, Train Accuracy: 35.28%, Test Loss: 1.3058, Test Accuracy: 39.24%\n",
      "Epoch [725/2500], Train Loss: 1.3365, Train Accuracy: 35.28%, Test Loss: 1.3047, Test Accuracy: 39.24%\n",
      "Epoch [726/2500], Train Loss: 1.3370, Train Accuracy: 35.28%, Test Loss: 1.3057, Test Accuracy: 39.24%\n",
      "Epoch [727/2500], Train Loss: 1.3363, Train Accuracy: 35.28%, Test Loss: 1.3049, Test Accuracy: 39.24%\n",
      "Epoch [728/2500], Train Loss: 1.3360, Train Accuracy: 35.28%, Test Loss: 1.3058, Test Accuracy: 39.24%\n",
      "Epoch [729/2500], Train Loss: 1.3366, Train Accuracy: 35.28%, Test Loss: 1.3047, Test Accuracy: 39.24%\n",
      "Epoch [730/2500], Train Loss: 1.3365, Train Accuracy: 35.28%, Test Loss: 1.3046, Test Accuracy: 39.24%\n",
      "Epoch [731/2500], Train Loss: 1.3362, Train Accuracy: 35.28%, Test Loss: 1.3050, Test Accuracy: 39.24%\n",
      "Epoch [732/2500], Train Loss: 1.3349, Train Accuracy: 35.28%, Test Loss: 1.3043, Test Accuracy: 39.24%\n",
      "Epoch [733/2500], Train Loss: 1.3361, Train Accuracy: 35.28%, Test Loss: 1.3052, Test Accuracy: 39.24%\n",
      "Epoch [734/2500], Train Loss: 1.3362, Train Accuracy: 35.28%, Test Loss: 1.3048, Test Accuracy: 39.24%\n",
      "Epoch [735/2500], Train Loss: 1.3365, Train Accuracy: 35.28%, Test Loss: 1.3046, Test Accuracy: 39.24%\n",
      "Epoch [736/2500], Train Loss: 1.3347, Train Accuracy: 35.28%, Test Loss: 1.3044, Test Accuracy: 39.24%\n",
      "Epoch [737/2500], Train Loss: 1.3362, Train Accuracy: 35.28%, Test Loss: 1.3044, Test Accuracy: 39.24%\n",
      "Epoch [738/2500], Train Loss: 1.3356, Train Accuracy: 35.28%, Test Loss: 1.3043, Test Accuracy: 39.24%\n",
      "Epoch [739/2500], Train Loss: 1.3355, Train Accuracy: 35.28%, Test Loss: 1.3040, Test Accuracy: 39.24%\n",
      "Epoch [740/2500], Train Loss: 1.3348, Train Accuracy: 35.28%, Test Loss: 1.3043, Test Accuracy: 39.24%\n",
      "Epoch [741/2500], Train Loss: 1.3361, Train Accuracy: 35.28%, Test Loss: 1.3044, Test Accuracy: 39.24%\n",
      "Epoch [742/2500], Train Loss: 1.3359, Train Accuracy: 35.28%, Test Loss: 1.3035, Test Accuracy: 39.24%\n",
      "Epoch [743/2500], Train Loss: 1.3353, Train Accuracy: 35.28%, Test Loss: 1.3031, Test Accuracy: 39.24%\n",
      "Epoch [744/2500], Train Loss: 1.3354, Train Accuracy: 35.28%, Test Loss: 1.3030, Test Accuracy: 39.24%\n",
      "Epoch [745/2500], Train Loss: 1.3354, Train Accuracy: 35.28%, Test Loss: 1.3038, Test Accuracy: 39.24%\n",
      "Epoch [746/2500], Train Loss: 1.3350, Train Accuracy: 35.28%, Test Loss: 1.3023, Test Accuracy: 39.24%\n",
      "Epoch [747/2500], Train Loss: 1.3355, Train Accuracy: 35.28%, Test Loss: 1.3029, Test Accuracy: 39.24%\n",
      "Epoch [748/2500], Train Loss: 1.3356, Train Accuracy: 35.28%, Test Loss: 1.3024, Test Accuracy: 39.24%\n",
      "Epoch [749/2500], Train Loss: 1.3358, Train Accuracy: 35.28%, Test Loss: 1.3027, Test Accuracy: 39.24%\n",
      "Epoch [750/2500], Train Loss: 1.3355, Train Accuracy: 35.28%, Test Loss: 1.3024, Test Accuracy: 39.24%\n",
      "Epoch [751/2500], Train Loss: 1.3351, Train Accuracy: 35.28%, Test Loss: 1.3026, Test Accuracy: 39.24%\n",
      "Epoch [752/2500], Train Loss: 1.3347, Train Accuracy: 35.28%, Test Loss: 1.3018, Test Accuracy: 39.24%\n",
      "Epoch [753/2500], Train Loss: 1.3351, Train Accuracy: 35.28%, Test Loss: 1.3013, Test Accuracy: 39.24%\n",
      "Epoch [754/2500], Train Loss: 1.3353, Train Accuracy: 35.28%, Test Loss: 1.3019, Test Accuracy: 39.24%\n",
      "Epoch [755/2500], Train Loss: 1.3341, Train Accuracy: 35.28%, Test Loss: 1.3017, Test Accuracy: 39.24%\n",
      "Epoch [756/2500], Train Loss: 1.3344, Train Accuracy: 35.28%, Test Loss: 1.3016, Test Accuracy: 39.24%\n",
      "Epoch [757/2500], Train Loss: 1.3349, Train Accuracy: 35.28%, Test Loss: 1.3012, Test Accuracy: 39.24%\n",
      "Epoch [758/2500], Train Loss: 1.3343, Train Accuracy: 35.28%, Test Loss: 1.3012, Test Accuracy: 39.24%\n",
      "Epoch [759/2500], Train Loss: 1.3342, Train Accuracy: 35.28%, Test Loss: 1.3011, Test Accuracy: 39.24%\n",
      "Epoch [760/2500], Train Loss: 1.3352, Train Accuracy: 35.28%, Test Loss: 1.3004, Test Accuracy: 39.24%\n",
      "Epoch [761/2500], Train Loss: 1.3343, Train Accuracy: 35.28%, Test Loss: 1.3011, Test Accuracy: 39.24%\n",
      "Epoch [762/2500], Train Loss: 1.3337, Train Accuracy: 35.28%, Test Loss: 1.3014, Test Accuracy: 39.24%\n",
      "Epoch [763/2500], Train Loss: 1.3340, Train Accuracy: 35.28%, Test Loss: 1.3004, Test Accuracy: 39.24%\n",
      "Epoch [764/2500], Train Loss: 1.3349, Train Accuracy: 35.28%, Test Loss: 1.3010, Test Accuracy: 39.24%\n",
      "Epoch [765/2500], Train Loss: 1.3338, Train Accuracy: 35.28%, Test Loss: 1.3001, Test Accuracy: 39.24%\n",
      "Epoch [766/2500], Train Loss: 1.3339, Train Accuracy: 35.28%, Test Loss: 1.3003, Test Accuracy: 39.24%\n",
      "Epoch [767/2500], Train Loss: 1.3336, Train Accuracy: 35.28%, Test Loss: 1.3001, Test Accuracy: 39.24%\n",
      "Epoch [768/2500], Train Loss: 1.3330, Train Accuracy: 35.28%, Test Loss: 1.2999, Test Accuracy: 39.24%\n",
      "Epoch [769/2500], Train Loss: 1.3328, Train Accuracy: 35.28%, Test Loss: 1.2994, Test Accuracy: 39.24%\n",
      "Epoch [770/2500], Train Loss: 1.3339, Train Accuracy: 35.28%, Test Loss: 1.3000, Test Accuracy: 39.24%\n",
      "Epoch [771/2500], Train Loss: 1.3328, Train Accuracy: 35.28%, Test Loss: 1.2990, Test Accuracy: 39.24%\n",
      "Epoch [772/2500], Train Loss: 1.3323, Train Accuracy: 35.28%, Test Loss: 1.2983, Test Accuracy: 39.24%\n",
      "Epoch [773/2500], Train Loss: 1.3329, Train Accuracy: 35.28%, Test Loss: 1.2984, Test Accuracy: 39.24%\n",
      "Epoch [774/2500], Train Loss: 1.3329, Train Accuracy: 35.28%, Test Loss: 1.2978, Test Accuracy: 39.24%\n",
      "Epoch [775/2500], Train Loss: 1.3339, Train Accuracy: 35.28%, Test Loss: 1.2983, Test Accuracy: 39.24%\n",
      "Epoch [776/2500], Train Loss: 1.3335, Train Accuracy: 35.28%, Test Loss: 1.2980, Test Accuracy: 39.24%\n",
      "Epoch [777/2500], Train Loss: 1.3331, Train Accuracy: 35.28%, Test Loss: 1.2977, Test Accuracy: 39.24%\n",
      "Epoch [778/2500], Train Loss: 1.3319, Train Accuracy: 35.28%, Test Loss: 1.2974, Test Accuracy: 39.24%\n",
      "Epoch [779/2500], Train Loss: 1.3320, Train Accuracy: 35.28%, Test Loss: 1.2984, Test Accuracy: 39.24%\n",
      "Epoch [780/2500], Train Loss: 1.3326, Train Accuracy: 35.28%, Test Loss: 1.2968, Test Accuracy: 39.24%\n",
      "Epoch [781/2500], Train Loss: 1.3327, Train Accuracy: 35.28%, Test Loss: 1.2969, Test Accuracy: 39.24%\n",
      "Epoch [782/2500], Train Loss: 1.3330, Train Accuracy: 35.28%, Test Loss: 1.2968, Test Accuracy: 39.24%\n",
      "Epoch [783/2500], Train Loss: 1.3333, Train Accuracy: 35.28%, Test Loss: 1.2969, Test Accuracy: 39.24%\n",
      "Epoch [784/2500], Train Loss: 1.3323, Train Accuracy: 35.28%, Test Loss: 1.2964, Test Accuracy: 39.24%\n",
      "Epoch [785/2500], Train Loss: 1.3309, Train Accuracy: 35.28%, Test Loss: 1.2953, Test Accuracy: 39.24%\n",
      "Epoch [786/2500], Train Loss: 1.3317, Train Accuracy: 35.28%, Test Loss: 1.2965, Test Accuracy: 39.24%\n",
      "Epoch [787/2500], Train Loss: 1.3316, Train Accuracy: 35.28%, Test Loss: 1.2955, Test Accuracy: 39.24%\n",
      "Epoch [788/2500], Train Loss: 1.3325, Train Accuracy: 35.28%, Test Loss: 1.2946, Test Accuracy: 39.24%\n",
      "Epoch [789/2500], Train Loss: 1.3321, Train Accuracy: 35.28%, Test Loss: 1.2949, Test Accuracy: 39.24%\n",
      "Epoch [790/2500], Train Loss: 1.3303, Train Accuracy: 35.28%, Test Loss: 1.2943, Test Accuracy: 39.24%\n",
      "Epoch [791/2500], Train Loss: 1.3311, Train Accuracy: 35.28%, Test Loss: 1.2950, Test Accuracy: 39.24%\n",
      "Epoch [792/2500], Train Loss: 1.3306, Train Accuracy: 35.28%, Test Loss: 1.2937, Test Accuracy: 39.24%\n",
      "Epoch [793/2500], Train Loss: 1.3309, Train Accuracy: 35.28%, Test Loss: 1.2947, Test Accuracy: 39.24%\n",
      "Epoch [794/2500], Train Loss: 1.3310, Train Accuracy: 35.28%, Test Loss: 1.2927, Test Accuracy: 39.24%\n",
      "Epoch [795/2500], Train Loss: 1.3301, Train Accuracy: 35.28%, Test Loss: 1.2930, Test Accuracy: 39.24%\n",
      "Epoch [796/2500], Train Loss: 1.3297, Train Accuracy: 35.28%, Test Loss: 1.2937, Test Accuracy: 39.24%\n",
      "Epoch [797/2500], Train Loss: 1.3305, Train Accuracy: 35.28%, Test Loss: 1.2923, Test Accuracy: 39.24%\n",
      "Epoch [798/2500], Train Loss: 1.3306, Train Accuracy: 35.28%, Test Loss: 1.2926, Test Accuracy: 39.24%\n",
      "Epoch [799/2500], Train Loss: 1.3302, Train Accuracy: 35.28%, Test Loss: 1.2913, Test Accuracy: 39.24%\n",
      "Epoch [800/2500], Train Loss: 1.3293, Train Accuracy: 35.28%, Test Loss: 1.2917, Test Accuracy: 39.24%\n",
      "Epoch [801/2500], Train Loss: 1.3288, Train Accuracy: 35.28%, Test Loss: 1.2921, Test Accuracy: 39.24%\n",
      "Epoch [802/2500], Train Loss: 1.3293, Train Accuracy: 35.28%, Test Loss: 1.2901, Test Accuracy: 39.24%\n",
      "Epoch [803/2500], Train Loss: 1.3297, Train Accuracy: 35.28%, Test Loss: 1.2907, Test Accuracy: 39.24%\n",
      "Epoch [804/2500], Train Loss: 1.3301, Train Accuracy: 35.28%, Test Loss: 1.2896, Test Accuracy: 39.24%\n",
      "Epoch [805/2500], Train Loss: 1.3294, Train Accuracy: 35.28%, Test Loss: 1.2890, Test Accuracy: 39.24%\n",
      "Epoch [806/2500], Train Loss: 1.3305, Train Accuracy: 35.28%, Test Loss: 1.2900, Test Accuracy: 39.24%\n",
      "Epoch [807/2500], Train Loss: 1.3269, Train Accuracy: 35.28%, Test Loss: 1.2877, Test Accuracy: 39.24%\n",
      "Epoch [808/2500], Train Loss: 1.3284, Train Accuracy: 35.28%, Test Loss: 1.2885, Test Accuracy: 39.24%\n",
      "Epoch [809/2500], Train Loss: 1.3269, Train Accuracy: 35.28%, Test Loss: 1.2890, Test Accuracy: 39.24%\n",
      "Epoch [810/2500], Train Loss: 1.3282, Train Accuracy: 35.28%, Test Loss: 1.2869, Test Accuracy: 39.24%\n",
      "Epoch [811/2500], Train Loss: 1.3260, Train Accuracy: 35.28%, Test Loss: 1.2867, Test Accuracy: 39.24%\n",
      "Epoch [812/2500], Train Loss: 1.3244, Train Accuracy: 35.28%, Test Loss: 1.2861, Test Accuracy: 39.24%\n",
      "Epoch [813/2500], Train Loss: 1.3280, Train Accuracy: 35.28%, Test Loss: 1.2863, Test Accuracy: 39.24%\n",
      "Epoch [814/2500], Train Loss: 1.3269, Train Accuracy: 35.28%, Test Loss: 1.2865, Test Accuracy: 39.24%\n",
      "Epoch [815/2500], Train Loss: 1.3267, Train Accuracy: 35.28%, Test Loss: 1.2848, Test Accuracy: 39.24%\n",
      "Epoch [816/2500], Train Loss: 1.3263, Train Accuracy: 35.28%, Test Loss: 1.2830, Test Accuracy: 39.24%\n",
      "Epoch [817/2500], Train Loss: 1.3266, Train Accuracy: 35.28%, Test Loss: 1.2845, Test Accuracy: 39.24%\n",
      "Epoch [818/2500], Train Loss: 1.3269, Train Accuracy: 35.28%, Test Loss: 1.2829, Test Accuracy: 39.24%\n",
      "Epoch [819/2500], Train Loss: 1.3248, Train Accuracy: 35.28%, Test Loss: 1.2835, Test Accuracy: 39.24%\n",
      "Epoch [820/2500], Train Loss: 1.3257, Train Accuracy: 35.28%, Test Loss: 1.2824, Test Accuracy: 39.24%\n",
      "Epoch [821/2500], Train Loss: 1.3238, Train Accuracy: 35.28%, Test Loss: 1.2828, Test Accuracy: 39.24%\n",
      "Epoch [822/2500], Train Loss: 1.3243, Train Accuracy: 35.28%, Test Loss: 1.2824, Test Accuracy: 39.24%\n",
      "Epoch [823/2500], Train Loss: 1.3249, Train Accuracy: 35.28%, Test Loss: 1.2791, Test Accuracy: 39.24%\n",
      "Epoch [824/2500], Train Loss: 1.3238, Train Accuracy: 35.28%, Test Loss: 1.2806, Test Accuracy: 39.24%\n",
      "Epoch [825/2500], Train Loss: 1.3239, Train Accuracy: 35.28%, Test Loss: 1.2782, Test Accuracy: 39.24%\n",
      "Epoch [826/2500], Train Loss: 1.3246, Train Accuracy: 35.28%, Test Loss: 1.2780, Test Accuracy: 39.24%\n",
      "Epoch [827/2500], Train Loss: 1.3252, Train Accuracy: 35.28%, Test Loss: 1.2789, Test Accuracy: 39.24%\n",
      "Epoch [828/2500], Train Loss: 1.3239, Train Accuracy: 35.28%, Test Loss: 1.2779, Test Accuracy: 39.24%\n",
      "Epoch [829/2500], Train Loss: 1.3206, Train Accuracy: 35.28%, Test Loss: 1.2757, Test Accuracy: 39.24%\n",
      "Epoch [830/2500], Train Loss: 1.3211, Train Accuracy: 35.28%, Test Loss: 1.2783, Test Accuracy: 39.24%\n",
      "Epoch [831/2500], Train Loss: 1.3220, Train Accuracy: 35.28%, Test Loss: 1.2744, Test Accuracy: 39.24%\n",
      "Epoch [832/2500], Train Loss: 1.3192, Train Accuracy: 35.28%, Test Loss: 1.2744, Test Accuracy: 39.24%\n",
      "Epoch [833/2500], Train Loss: 1.3200, Train Accuracy: 35.28%, Test Loss: 1.2739, Test Accuracy: 39.24%\n",
      "Epoch [834/2500], Train Loss: 1.3186, Train Accuracy: 35.28%, Test Loss: 1.2717, Test Accuracy: 39.24%\n",
      "Epoch [835/2500], Train Loss: 1.3197, Train Accuracy: 35.28%, Test Loss: 1.2723, Test Accuracy: 39.24%\n",
      "Epoch [836/2500], Train Loss: 1.3167, Train Accuracy: 35.28%, Test Loss: 1.2706, Test Accuracy: 39.24%\n",
      "Epoch [837/2500], Train Loss: 1.3178, Train Accuracy: 35.28%, Test Loss: 1.2679, Test Accuracy: 39.24%\n",
      "Epoch [838/2500], Train Loss: 1.3180, Train Accuracy: 35.28%, Test Loss: 1.2677, Test Accuracy: 39.24%\n",
      "Epoch [839/2500], Train Loss: 1.3163, Train Accuracy: 35.28%, Test Loss: 1.2663, Test Accuracy: 39.24%\n",
      "Epoch [840/2500], Train Loss: 1.3189, Train Accuracy: 35.28%, Test Loss: 1.2665, Test Accuracy: 39.24%\n",
      "Epoch [841/2500], Train Loss: 1.3184, Train Accuracy: 35.28%, Test Loss: 1.2666, Test Accuracy: 39.24%\n",
      "Epoch [842/2500], Train Loss: 1.3147, Train Accuracy: 35.28%, Test Loss: 1.2624, Test Accuracy: 39.24%\n",
      "Epoch [843/2500], Train Loss: 1.3130, Train Accuracy: 35.28%, Test Loss: 1.2612, Test Accuracy: 39.24%\n",
      "Epoch [844/2500], Train Loss: 1.3168, Train Accuracy: 35.28%, Test Loss: 1.2603, Test Accuracy: 39.24%\n",
      "Epoch [845/2500], Train Loss: 1.3150, Train Accuracy: 35.28%, Test Loss: 1.2590, Test Accuracy: 39.24%\n",
      "Epoch [846/2500], Train Loss: 1.3124, Train Accuracy: 35.28%, Test Loss: 1.2589, Test Accuracy: 39.24%\n",
      "Epoch [847/2500], Train Loss: 1.3145, Train Accuracy: 35.28%, Test Loss: 1.2585, Test Accuracy: 39.24%\n",
      "Epoch [848/2500], Train Loss: 1.3087, Train Accuracy: 35.28%, Test Loss: 1.2539, Test Accuracy: 39.24%\n",
      "Epoch [849/2500], Train Loss: 1.3076, Train Accuracy: 35.28%, Test Loss: 1.2531, Test Accuracy: 39.24%\n",
      "Epoch [850/2500], Train Loss: 1.3081, Train Accuracy: 35.28%, Test Loss: 1.2522, Test Accuracy: 39.24%\n",
      "Epoch [851/2500], Train Loss: 1.3037, Train Accuracy: 35.28%, Test Loss: 1.2495, Test Accuracy: 39.24%\n",
      "Epoch [852/2500], Train Loss: 1.3069, Train Accuracy: 35.28%, Test Loss: 1.2494, Test Accuracy: 39.24%\n",
      "Epoch [853/2500], Train Loss: 1.3069, Train Accuracy: 35.28%, Test Loss: 1.2487, Test Accuracy: 39.24%\n",
      "Epoch [854/2500], Train Loss: 1.3064, Train Accuracy: 35.28%, Test Loss: 1.2443, Test Accuracy: 39.24%\n",
      "Epoch [855/2500], Train Loss: 1.3020, Train Accuracy: 35.28%, Test Loss: 1.2435, Test Accuracy: 39.24%\n",
      "Epoch [856/2500], Train Loss: 1.3025, Train Accuracy: 35.28%, Test Loss: 1.2414, Test Accuracy: 39.24%\n",
      "Epoch [857/2500], Train Loss: 1.3009, Train Accuracy: 35.28%, Test Loss: 1.2386, Test Accuracy: 39.24%\n",
      "Epoch [858/2500], Train Loss: 1.2963, Train Accuracy: 35.28%, Test Loss: 1.2358, Test Accuracy: 39.24%\n",
      "Epoch [859/2500], Train Loss: 1.3019, Train Accuracy: 35.28%, Test Loss: 1.2328, Test Accuracy: 39.24%\n",
      "Epoch [860/2500], Train Loss: 1.2978, Train Accuracy: 35.42%, Test Loss: 1.2320, Test Accuracy: 39.24%\n",
      "Epoch [861/2500], Train Loss: 1.2967, Train Accuracy: 35.42%, Test Loss: 1.2286, Test Accuracy: 39.24%\n",
      "Epoch [862/2500], Train Loss: 1.2949, Train Accuracy: 35.28%, Test Loss: 1.2277, Test Accuracy: 39.24%\n",
      "Epoch [863/2500], Train Loss: 1.2913, Train Accuracy: 35.42%, Test Loss: 1.2239, Test Accuracy: 39.24%\n",
      "Epoch [864/2500], Train Loss: 1.2876, Train Accuracy: 35.28%, Test Loss: 1.2235, Test Accuracy: 39.24%\n",
      "Epoch [865/2500], Train Loss: 1.2958, Train Accuracy: 35.28%, Test Loss: 1.2224, Test Accuracy: 39.24%\n",
      "Epoch [866/2500], Train Loss: 1.2834, Train Accuracy: 35.70%, Test Loss: 1.2173, Test Accuracy: 39.24%\n",
      "Epoch [867/2500], Train Loss: 1.2900, Train Accuracy: 35.70%, Test Loss: 1.2162, Test Accuracy: 39.24%\n",
      "Epoch [868/2500], Train Loss: 1.2806, Train Accuracy: 36.13%, Test Loss: 1.2099, Test Accuracy: 40.51%\n",
      "Epoch [869/2500], Train Loss: 1.2820, Train Accuracy: 36.13%, Test Loss: 1.2081, Test Accuracy: 44.30%\n",
      "Epoch [870/2500], Train Loss: 1.2857, Train Accuracy: 35.70%, Test Loss: 1.2061, Test Accuracy: 45.57%\n",
      "Epoch [871/2500], Train Loss: 1.2744, Train Accuracy: 36.27%, Test Loss: 1.2012, Test Accuracy: 45.57%\n",
      "Epoch [872/2500], Train Loss: 1.2760, Train Accuracy: 36.70%, Test Loss: 1.1984, Test Accuracy: 48.10%\n",
      "Epoch [873/2500], Train Loss: 1.2788, Train Accuracy: 36.84%, Test Loss: 1.1960, Test Accuracy: 46.84%\n",
      "Epoch [874/2500], Train Loss: 1.2734, Train Accuracy: 37.98%, Test Loss: 1.1943, Test Accuracy: 50.63%\n",
      "Epoch [875/2500], Train Loss: 1.2706, Train Accuracy: 37.70%, Test Loss: 1.1878, Test Accuracy: 50.63%\n",
      "Epoch [876/2500], Train Loss: 1.2658, Train Accuracy: 38.83%, Test Loss: 1.1860, Test Accuracy: 49.37%\n",
      "Epoch [877/2500], Train Loss: 1.2657, Train Accuracy: 38.41%, Test Loss: 1.1781, Test Accuracy: 50.63%\n",
      "Epoch [878/2500], Train Loss: 1.2548, Train Accuracy: 40.40%, Test Loss: 1.1764, Test Accuracy: 50.63%\n",
      "Epoch [879/2500], Train Loss: 1.2567, Train Accuracy: 41.11%, Test Loss: 1.1714, Test Accuracy: 50.63%\n",
      "Epoch [880/2500], Train Loss: 1.2594, Train Accuracy: 42.39%, Test Loss: 1.1686, Test Accuracy: 51.90%\n",
      "Epoch [881/2500], Train Loss: 1.2539, Train Accuracy: 42.96%, Test Loss: 1.1685, Test Accuracy: 50.63%\n",
      "Epoch [882/2500], Train Loss: 1.2458, Train Accuracy: 41.82%, Test Loss: 1.1603, Test Accuracy: 51.90%\n",
      "Epoch [883/2500], Train Loss: 1.2477, Train Accuracy: 41.39%, Test Loss: 1.1567, Test Accuracy: 51.90%\n",
      "Epoch [884/2500], Train Loss: 1.2441, Train Accuracy: 41.82%, Test Loss: 1.1554, Test Accuracy: 50.63%\n",
      "Epoch [885/2500], Train Loss: 1.2483, Train Accuracy: 43.10%, Test Loss: 1.1500, Test Accuracy: 50.63%\n",
      "Epoch [886/2500], Train Loss: 1.2347, Train Accuracy: 45.38%, Test Loss: 1.1464, Test Accuracy: 50.63%\n",
      "Epoch [887/2500], Train Loss: 1.2395, Train Accuracy: 44.24%, Test Loss: 1.1418, Test Accuracy: 49.37%\n",
      "Epoch [888/2500], Train Loss: 1.2244, Train Accuracy: 45.66%, Test Loss: 1.1447, Test Accuracy: 50.63%\n",
      "Epoch [889/2500], Train Loss: 1.2321, Train Accuracy: 46.94%, Test Loss: 1.1364, Test Accuracy: 49.37%\n",
      "Epoch [890/2500], Train Loss: 1.2184, Train Accuracy: 48.08%, Test Loss: 1.1312, Test Accuracy: 49.37%\n",
      "Epoch [891/2500], Train Loss: 1.2192, Train Accuracy: 46.09%, Test Loss: 1.1298, Test Accuracy: 49.37%\n",
      "Epoch [892/2500], Train Loss: 1.2140, Train Accuracy: 47.80%, Test Loss: 1.1302, Test Accuracy: 49.37%\n",
      "Epoch [893/2500], Train Loss: 1.2141, Train Accuracy: 47.65%, Test Loss: 1.1259, Test Accuracy: 49.37%\n",
      "Epoch [894/2500], Train Loss: 1.2110, Train Accuracy: 48.08%, Test Loss: 1.1076, Test Accuracy: 49.37%\n",
      "Epoch [895/2500], Train Loss: 1.2074, Train Accuracy: 47.37%, Test Loss: 1.1190, Test Accuracy: 49.37%\n",
      "Epoch [896/2500], Train Loss: 1.2181, Train Accuracy: 48.36%, Test Loss: 1.1170, Test Accuracy: 49.37%\n",
      "Epoch [897/2500], Train Loss: 1.2014, Train Accuracy: 49.36%, Test Loss: 1.1172, Test Accuracy: 49.37%\n",
      "Epoch [898/2500], Train Loss: 1.1944, Train Accuracy: 48.08%, Test Loss: 1.1064, Test Accuracy: 50.63%\n",
      "Epoch [899/2500], Train Loss: 1.1849, Train Accuracy: 48.93%, Test Loss: 1.0989, Test Accuracy: 50.63%\n",
      "Epoch [900/2500], Train Loss: 1.1890, Train Accuracy: 48.36%, Test Loss: 1.0897, Test Accuracy: 50.63%\n",
      "Epoch [901/2500], Train Loss: 1.1867, Train Accuracy: 48.93%, Test Loss: 1.0991, Test Accuracy: 50.63%\n",
      "Epoch [902/2500], Train Loss: 1.1917, Train Accuracy: 47.65%, Test Loss: 1.0933, Test Accuracy: 50.63%\n",
      "Epoch [903/2500], Train Loss: 1.1905, Train Accuracy: 49.22%, Test Loss: 1.0986, Test Accuracy: 50.63%\n",
      "Epoch [904/2500], Train Loss: 1.1776, Train Accuracy: 49.22%, Test Loss: 1.0924, Test Accuracy: 50.63%\n",
      "Epoch [905/2500], Train Loss: 1.1833, Train Accuracy: 49.22%, Test Loss: 1.0944, Test Accuracy: 50.63%\n",
      "Epoch [906/2500], Train Loss: 1.1745, Train Accuracy: 49.36%, Test Loss: 1.0858, Test Accuracy: 50.63%\n",
      "Epoch [907/2500], Train Loss: 1.1810, Train Accuracy: 49.36%, Test Loss: 1.0838, Test Accuracy: 50.63%\n",
      "Epoch [908/2500], Train Loss: 1.1591, Train Accuracy: 50.36%, Test Loss: 1.0861, Test Accuracy: 50.63%\n",
      "Epoch [909/2500], Train Loss: 1.1505, Train Accuracy: 50.21%, Test Loss: 1.0736, Test Accuracy: 50.63%\n",
      "Epoch [910/2500], Train Loss: 1.1551, Train Accuracy: 48.79%, Test Loss: 1.0705, Test Accuracy: 50.63%\n",
      "Epoch [911/2500], Train Loss: 1.1456, Train Accuracy: 51.21%, Test Loss: 1.0839, Test Accuracy: 51.90%\n",
      "Epoch [912/2500], Train Loss: 1.1592, Train Accuracy: 50.21%, Test Loss: 1.0658, Test Accuracy: 50.63%\n",
      "Epoch [913/2500], Train Loss: 1.1604, Train Accuracy: 50.36%, Test Loss: 1.0635, Test Accuracy: 50.63%\n",
      "Epoch [914/2500], Train Loss: 1.1367, Train Accuracy: 50.78%, Test Loss: 1.0689, Test Accuracy: 50.63%\n",
      "Epoch [915/2500], Train Loss: 1.1251, Train Accuracy: 51.49%, Test Loss: 1.0706, Test Accuracy: 50.63%\n",
      "Epoch [916/2500], Train Loss: 1.1282, Train Accuracy: 50.21%, Test Loss: 1.0590, Test Accuracy: 50.63%\n",
      "Epoch [917/2500], Train Loss: 1.1336, Train Accuracy: 50.78%, Test Loss: 1.0760, Test Accuracy: 50.63%\n",
      "Epoch [918/2500], Train Loss: 1.1329, Train Accuracy: 49.79%, Test Loss: 1.0417, Test Accuracy: 50.63%\n",
      "Epoch [919/2500], Train Loss: 1.1184, Train Accuracy: 51.35%, Test Loss: 1.0654, Test Accuracy: 50.63%\n",
      "Epoch [920/2500], Train Loss: 1.1166, Train Accuracy: 51.49%, Test Loss: 1.0722, Test Accuracy: 50.63%\n",
      "Epoch [921/2500], Train Loss: 1.1279, Train Accuracy: 50.21%, Test Loss: 1.0634, Test Accuracy: 50.63%\n",
      "Epoch [922/2500], Train Loss: 1.1256, Train Accuracy: 51.49%, Test Loss: 1.0641, Test Accuracy: 50.63%\n",
      "Epoch [923/2500], Train Loss: 1.1106, Train Accuracy: 51.21%, Test Loss: 1.0599, Test Accuracy: 51.90%\n",
      "Epoch [924/2500], Train Loss: 1.1247, Train Accuracy: 51.21%, Test Loss: 1.0629, Test Accuracy: 51.90%\n",
      "Epoch [925/2500], Train Loss: 1.1222, Train Accuracy: 50.92%, Test Loss: 1.0643, Test Accuracy: 51.90%\n",
      "Epoch [926/2500], Train Loss: 1.1006, Train Accuracy: 50.36%, Test Loss: 1.0660, Test Accuracy: 51.90%\n",
      "Epoch [927/2500], Train Loss: 1.1103, Train Accuracy: 51.78%, Test Loss: 1.0672, Test Accuracy: 53.16%\n",
      "Epoch [928/2500], Train Loss: 1.1117, Train Accuracy: 52.06%, Test Loss: 1.0623, Test Accuracy: 53.16%\n",
      "Epoch [929/2500], Train Loss: 1.0803, Train Accuracy: 52.35%, Test Loss: 1.0625, Test Accuracy: 51.90%\n",
      "Epoch [930/2500], Train Loss: 1.1174, Train Accuracy: 51.64%, Test Loss: 1.0517, Test Accuracy: 50.63%\n",
      "Epoch [931/2500], Train Loss: 1.1151, Train Accuracy: 52.20%, Test Loss: 1.0387, Test Accuracy: 50.63%\n",
      "Epoch [932/2500], Train Loss: 1.0995, Train Accuracy: 52.92%, Test Loss: 1.0530, Test Accuracy: 54.43%\n",
      "Epoch [933/2500], Train Loss: 1.1108, Train Accuracy: 51.64%, Test Loss: 1.0471, Test Accuracy: 54.43%\n",
      "Epoch [934/2500], Train Loss: 1.0785, Train Accuracy: 53.06%, Test Loss: 1.0416, Test Accuracy: 54.43%\n",
      "Epoch [935/2500], Train Loss: 1.0957, Train Accuracy: 51.92%, Test Loss: 1.0222, Test Accuracy: 51.90%\n",
      "Epoch [936/2500], Train Loss: 1.0864, Train Accuracy: 52.35%, Test Loss: 1.0265, Test Accuracy: 51.90%\n",
      "Epoch [937/2500], Train Loss: 1.0916, Train Accuracy: 53.63%, Test Loss: 1.0276, Test Accuracy: 53.16%\n",
      "Epoch [938/2500], Train Loss: 1.0936, Train Accuracy: 52.77%, Test Loss: 1.0204, Test Accuracy: 53.16%\n",
      "Epoch [939/2500], Train Loss: 1.0737, Train Accuracy: 52.63%, Test Loss: 1.0569, Test Accuracy: 54.43%\n",
      "Epoch [940/2500], Train Loss: 1.0883, Train Accuracy: 51.92%, Test Loss: 1.0443, Test Accuracy: 54.43%\n",
      "Epoch [941/2500], Train Loss: 1.0839, Train Accuracy: 51.78%, Test Loss: 1.0420, Test Accuracy: 53.16%\n",
      "Epoch [942/2500], Train Loss: 1.0973, Train Accuracy: 52.49%, Test Loss: 1.0312, Test Accuracy: 53.16%\n",
      "Epoch [943/2500], Train Loss: 1.0797, Train Accuracy: 53.34%, Test Loss: 1.0230, Test Accuracy: 54.43%\n",
      "Epoch [944/2500], Train Loss: 1.0831, Train Accuracy: 54.05%, Test Loss: 1.0243, Test Accuracy: 55.70%\n",
      "Epoch [945/2500], Train Loss: 1.0746, Train Accuracy: 53.91%, Test Loss: 1.0240, Test Accuracy: 55.70%\n",
      "Epoch [946/2500], Train Loss: 1.0550, Train Accuracy: 52.77%, Test Loss: 1.0442, Test Accuracy: 53.16%\n",
      "Epoch [947/2500], Train Loss: 1.0710, Train Accuracy: 54.34%, Test Loss: 1.0377, Test Accuracy: 53.16%\n",
      "Epoch [948/2500], Train Loss: 1.0791, Train Accuracy: 52.63%, Test Loss: 1.0272, Test Accuracy: 54.43%\n",
      "Epoch [949/2500], Train Loss: 1.0605, Train Accuracy: 54.62%, Test Loss: 1.0334, Test Accuracy: 51.90%\n",
      "Epoch [950/2500], Train Loss: 1.0661, Train Accuracy: 53.77%, Test Loss: 1.0301, Test Accuracy: 56.96%\n",
      "Epoch [951/2500], Train Loss: 1.0640, Train Accuracy: 53.63%, Test Loss: 1.0364, Test Accuracy: 55.70%\n",
      "Epoch [952/2500], Train Loss: 1.0819, Train Accuracy: 52.49%, Test Loss: 1.0255, Test Accuracy: 55.70%\n",
      "Epoch [953/2500], Train Loss: 1.0616, Train Accuracy: 54.20%, Test Loss: 1.0168, Test Accuracy: 56.96%\n",
      "Epoch [954/2500], Train Loss: 1.0602, Train Accuracy: 53.77%, Test Loss: 1.0258, Test Accuracy: 58.23%\n",
      "Epoch [955/2500], Train Loss: 1.0779, Train Accuracy: 53.91%, Test Loss: 1.0334, Test Accuracy: 56.96%\n",
      "Epoch [956/2500], Train Loss: 1.0882, Train Accuracy: 52.92%, Test Loss: 1.0333, Test Accuracy: 56.96%\n",
      "Epoch [957/2500], Train Loss: 1.0371, Train Accuracy: 55.76%, Test Loss: 1.0266, Test Accuracy: 58.23%\n",
      "Epoch [958/2500], Train Loss: 1.0631, Train Accuracy: 54.05%, Test Loss: 1.0147, Test Accuracy: 56.96%\n",
      "Epoch [959/2500], Train Loss: 1.0620, Train Accuracy: 53.63%, Test Loss: 1.0534, Test Accuracy: 55.70%\n",
      "Epoch [960/2500], Train Loss: 1.0549, Train Accuracy: 53.34%, Test Loss: 1.0104, Test Accuracy: 56.96%\n",
      "Epoch [961/2500], Train Loss: 1.0752, Train Accuracy: 53.20%, Test Loss: 1.0111, Test Accuracy: 56.96%\n",
      "Epoch [962/2500], Train Loss: 1.0423, Train Accuracy: 56.19%, Test Loss: 1.0169, Test Accuracy: 58.23%\n",
      "Epoch [963/2500], Train Loss: 1.0666, Train Accuracy: 55.05%, Test Loss: 1.0290, Test Accuracy: 58.23%\n",
      "Epoch [964/2500], Train Loss: 1.0573, Train Accuracy: 54.91%, Test Loss: 1.0170, Test Accuracy: 59.49%\n",
      "Epoch [965/2500], Train Loss: 1.0617, Train Accuracy: 55.19%, Test Loss: 1.0174, Test Accuracy: 59.49%\n",
      "Epoch [966/2500], Train Loss: 1.0533, Train Accuracy: 55.76%, Test Loss: 1.0198, Test Accuracy: 59.49%\n",
      "Epoch [967/2500], Train Loss: 1.0437, Train Accuracy: 55.33%, Test Loss: 1.0234, Test Accuracy: 58.23%\n",
      "Epoch [968/2500], Train Loss: 1.0531, Train Accuracy: 55.05%, Test Loss: 1.0195, Test Accuracy: 59.49%\n",
      "Epoch [969/2500], Train Loss: 1.0475, Train Accuracy: 56.33%, Test Loss: 1.0031, Test Accuracy: 58.23%\n",
      "Epoch [970/2500], Train Loss: 1.0470, Train Accuracy: 55.48%, Test Loss: 1.0044, Test Accuracy: 58.23%\n",
      "Epoch [971/2500], Train Loss: 1.0573, Train Accuracy: 54.91%, Test Loss: 1.0032, Test Accuracy: 59.49%\n",
      "Epoch [972/2500], Train Loss: 1.0454, Train Accuracy: 54.05%, Test Loss: 1.0036, Test Accuracy: 58.23%\n",
      "Epoch [973/2500], Train Loss: 1.0582, Train Accuracy: 55.19%, Test Loss: 1.0211, Test Accuracy: 59.49%\n",
      "Epoch [974/2500], Train Loss: 1.0398, Train Accuracy: 55.33%, Test Loss: 1.0053, Test Accuracy: 59.49%\n",
      "Epoch [975/2500], Train Loss: 1.0568, Train Accuracy: 55.33%, Test Loss: 1.0227, Test Accuracy: 59.49%\n",
      "Epoch [976/2500], Train Loss: 1.0600, Train Accuracy: 55.62%, Test Loss: 1.0186, Test Accuracy: 58.23%\n",
      "Epoch [977/2500], Train Loss: 1.0468, Train Accuracy: 55.76%, Test Loss: 1.0012, Test Accuracy: 58.23%\n",
      "Epoch [978/2500], Train Loss: 1.0506, Train Accuracy: 54.20%, Test Loss: 1.0015, Test Accuracy: 58.23%\n",
      "Epoch [979/2500], Train Loss: 1.0442, Train Accuracy: 55.48%, Test Loss: 1.0097, Test Accuracy: 59.49%\n",
      "Epoch [980/2500], Train Loss: 1.0540, Train Accuracy: 55.90%, Test Loss: 0.9969, Test Accuracy: 58.23%\n",
      "Epoch [981/2500], Train Loss: 1.0548, Train Accuracy: 53.20%, Test Loss: 1.0082, Test Accuracy: 59.49%\n",
      "Epoch [982/2500], Train Loss: 1.0481, Train Accuracy: 55.90%, Test Loss: 1.0044, Test Accuracy: 60.76%\n",
      "Epoch [983/2500], Train Loss: 1.0421, Train Accuracy: 55.19%, Test Loss: 1.0015, Test Accuracy: 58.23%\n",
      "Epoch [984/2500], Train Loss: 1.0562, Train Accuracy: 56.76%, Test Loss: 1.0093, Test Accuracy: 59.49%\n",
      "Epoch [985/2500], Train Loss: 1.0498, Train Accuracy: 55.48%, Test Loss: 1.0204, Test Accuracy: 59.49%\n",
      "Epoch [986/2500], Train Loss: 1.0549, Train Accuracy: 55.48%, Test Loss: 0.9965, Test Accuracy: 58.23%\n",
      "Epoch [987/2500], Train Loss: 1.0375, Train Accuracy: 54.62%, Test Loss: 1.0032, Test Accuracy: 58.23%\n",
      "Epoch [988/2500], Train Loss: 1.0438, Train Accuracy: 56.47%, Test Loss: 1.0067, Test Accuracy: 60.76%\n",
      "Epoch [989/2500], Train Loss: 1.0469, Train Accuracy: 54.48%, Test Loss: 1.0086, Test Accuracy: 60.76%\n",
      "Epoch [990/2500], Train Loss: 1.0390, Train Accuracy: 56.19%, Test Loss: 0.9999, Test Accuracy: 60.76%\n",
      "Epoch [991/2500], Train Loss: 1.0633, Train Accuracy: 54.48%, Test Loss: 1.0016, Test Accuracy: 60.76%\n",
      "Epoch [992/2500], Train Loss: 1.0288, Train Accuracy: 55.90%, Test Loss: 1.0033, Test Accuracy: 60.76%\n",
      "Epoch [993/2500], Train Loss: 1.0273, Train Accuracy: 55.90%, Test Loss: 1.0104, Test Accuracy: 60.76%\n",
      "Epoch [994/2500], Train Loss: 1.0297, Train Accuracy: 57.18%, Test Loss: 1.0105, Test Accuracy: 60.76%\n",
      "Epoch [995/2500], Train Loss: 1.0319, Train Accuracy: 55.76%, Test Loss: 1.0018, Test Accuracy: 60.76%\n",
      "Epoch [996/2500], Train Loss: 1.0366, Train Accuracy: 55.48%, Test Loss: 1.0002, Test Accuracy: 60.76%\n",
      "Epoch [997/2500], Train Loss: 1.0280, Train Accuracy: 57.89%, Test Loss: 0.9950, Test Accuracy: 60.76%\n",
      "Epoch [998/2500], Train Loss: 1.0371, Train Accuracy: 55.62%, Test Loss: 0.9974, Test Accuracy: 60.76%\n",
      "Epoch [999/2500], Train Loss: 1.0298, Train Accuracy: 55.90%, Test Loss: 1.0014, Test Accuracy: 60.76%\n",
      "Epoch [1000/2500], Train Loss: 1.0352, Train Accuracy: 56.47%, Test Loss: 1.0070, Test Accuracy: 60.76%\n",
      "Epoch [1001/2500], Train Loss: 1.0448, Train Accuracy: 56.33%, Test Loss: 1.0083, Test Accuracy: 60.76%\n",
      "Epoch [1002/2500], Train Loss: 1.0314, Train Accuracy: 56.90%, Test Loss: 1.0005, Test Accuracy: 60.76%\n",
      "Epoch [1003/2500], Train Loss: 1.0179, Train Accuracy: 55.76%, Test Loss: 0.9999, Test Accuracy: 59.49%\n",
      "Epoch [1004/2500], Train Loss: 1.0363, Train Accuracy: 55.76%, Test Loss: 0.9963, Test Accuracy: 58.23%\n",
      "Epoch [1005/2500], Train Loss: 1.0211, Train Accuracy: 57.33%, Test Loss: 0.9973, Test Accuracy: 59.49%\n",
      "Epoch [1006/2500], Train Loss: 1.0339, Train Accuracy: 56.33%, Test Loss: 1.0047, Test Accuracy: 60.76%\n",
      "Epoch [1007/2500], Train Loss: 1.0438, Train Accuracy: 55.76%, Test Loss: 0.9981, Test Accuracy: 59.49%\n",
      "Epoch [1008/2500], Train Loss: 1.0314, Train Accuracy: 56.76%, Test Loss: 0.9939, Test Accuracy: 59.49%\n",
      "Epoch [1009/2500], Train Loss: 1.0206, Train Accuracy: 55.05%, Test Loss: 1.0009, Test Accuracy: 60.76%\n",
      "Epoch [1010/2500], Train Loss: 1.0214, Train Accuracy: 57.18%, Test Loss: 0.9926, Test Accuracy: 59.49%\n",
      "Epoch [1011/2500], Train Loss: 1.0257, Train Accuracy: 56.33%, Test Loss: 0.9913, Test Accuracy: 59.49%\n",
      "Epoch [1012/2500], Train Loss: 1.0255, Train Accuracy: 56.61%, Test Loss: 0.9938, Test Accuracy: 60.76%\n",
      "Epoch [1013/2500], Train Loss: 1.0040, Train Accuracy: 55.62%, Test Loss: 0.9901, Test Accuracy: 60.76%\n",
      "Epoch [1014/2500], Train Loss: 1.0073, Train Accuracy: 57.61%, Test Loss: 0.9922, Test Accuracy: 60.76%\n",
      "Epoch [1015/2500], Train Loss: 1.0370, Train Accuracy: 56.76%, Test Loss: 0.9901, Test Accuracy: 60.76%\n",
      "Epoch [1016/2500], Train Loss: 1.0159, Train Accuracy: 56.19%, Test Loss: 0.9890, Test Accuracy: 59.49%\n",
      "Epoch [1017/2500], Train Loss: 1.0262, Train Accuracy: 56.05%, Test Loss: 0.9927, Test Accuracy: 60.76%\n",
      "Epoch [1018/2500], Train Loss: 1.0190, Train Accuracy: 56.76%, Test Loss: 0.9893, Test Accuracy: 60.76%\n",
      "Epoch [1019/2500], Train Loss: 1.0113, Train Accuracy: 56.76%, Test Loss: 0.9913, Test Accuracy: 60.76%\n",
      "Epoch [1020/2500], Train Loss: 1.0317, Train Accuracy: 55.48%, Test Loss: 0.9881, Test Accuracy: 60.76%\n",
      "Epoch [1021/2500], Train Loss: 1.0282, Train Accuracy: 54.77%, Test Loss: 0.9891, Test Accuracy: 60.76%\n",
      "Epoch [1022/2500], Train Loss: 1.0254, Train Accuracy: 57.47%, Test Loss: 0.9934, Test Accuracy: 60.76%\n",
      "Epoch [1023/2500], Train Loss: 1.0208, Train Accuracy: 57.33%, Test Loss: 0.9953, Test Accuracy: 60.76%\n",
      "Epoch [1024/2500], Train Loss: 1.0086, Train Accuracy: 57.04%, Test Loss: 0.9925, Test Accuracy: 60.76%\n",
      "Epoch [1025/2500], Train Loss: 1.0002, Train Accuracy: 57.33%, Test Loss: 0.9934, Test Accuracy: 60.76%\n",
      "Epoch [1026/2500], Train Loss: 1.0265, Train Accuracy: 55.05%, Test Loss: 0.9871, Test Accuracy: 59.49%\n",
      "Epoch [1027/2500], Train Loss: 1.0162, Train Accuracy: 57.61%, Test Loss: 0.9887, Test Accuracy: 60.76%\n",
      "Epoch [1028/2500], Train Loss: 1.0360, Train Accuracy: 56.90%, Test Loss: 0.9882, Test Accuracy: 60.76%\n",
      "Epoch [1029/2500], Train Loss: 1.0398, Train Accuracy: 57.33%, Test Loss: 0.9846, Test Accuracy: 60.76%\n",
      "Epoch [1030/2500], Train Loss: 1.0435, Train Accuracy: 55.90%, Test Loss: 0.9831, Test Accuracy: 60.76%\n",
      "Epoch [1031/2500], Train Loss: 1.0092, Train Accuracy: 57.04%, Test Loss: 0.9868, Test Accuracy: 60.76%\n",
      "Epoch [1032/2500], Train Loss: 1.0144, Train Accuracy: 57.89%, Test Loss: 0.9839, Test Accuracy: 59.49%\n",
      "Epoch [1033/2500], Train Loss: 1.0074, Train Accuracy: 56.61%, Test Loss: 0.9894, Test Accuracy: 60.76%\n",
      "Epoch [1034/2500], Train Loss: 1.0162, Train Accuracy: 58.75%, Test Loss: 0.9889, Test Accuracy: 60.76%\n",
      "Epoch [1035/2500], Train Loss: 1.0142, Train Accuracy: 56.33%, Test Loss: 0.9851, Test Accuracy: 59.49%\n",
      "Epoch [1036/2500], Train Loss: 1.0201, Train Accuracy: 56.47%, Test Loss: 0.9891, Test Accuracy: 60.76%\n",
      "Epoch [1037/2500], Train Loss: 1.0047, Train Accuracy: 56.90%, Test Loss: 0.9812, Test Accuracy: 59.49%\n",
      "Epoch [1038/2500], Train Loss: 1.0176, Train Accuracy: 57.47%, Test Loss: 0.9840, Test Accuracy: 58.23%\n",
      "Epoch [1039/2500], Train Loss: 1.0134, Train Accuracy: 57.75%, Test Loss: 0.9854, Test Accuracy: 59.49%\n",
      "Epoch [1040/2500], Train Loss: 0.9954, Train Accuracy: 58.32%, Test Loss: 0.9866, Test Accuracy: 60.76%\n",
      "Epoch [1041/2500], Train Loss: 1.0121, Train Accuracy: 55.90%, Test Loss: 0.9846, Test Accuracy: 60.76%\n",
      "Epoch [1042/2500], Train Loss: 1.0092, Train Accuracy: 57.47%, Test Loss: 0.9820, Test Accuracy: 59.49%\n",
      "Epoch [1043/2500], Train Loss: 1.0087, Train Accuracy: 56.76%, Test Loss: 0.9847, Test Accuracy: 60.76%\n",
      "Epoch [1044/2500], Train Loss: 1.0116, Train Accuracy: 56.90%, Test Loss: 0.9893, Test Accuracy: 60.76%\n",
      "Epoch [1045/2500], Train Loss: 1.0153, Train Accuracy: 56.76%, Test Loss: 0.9825, Test Accuracy: 60.76%\n",
      "Epoch [1046/2500], Train Loss: 0.9996, Train Accuracy: 56.76%, Test Loss: 1.0073, Test Accuracy: 60.76%\n",
      "Epoch [1047/2500], Train Loss: 1.0007, Train Accuracy: 56.33%, Test Loss: 0.9871, Test Accuracy: 59.49%\n",
      "Epoch [1048/2500], Train Loss: 1.0047, Train Accuracy: 55.90%, Test Loss: 0.9867, Test Accuracy: 59.49%\n",
      "Epoch [1049/2500], Train Loss: 1.0060, Train Accuracy: 57.33%, Test Loss: 0.9849, Test Accuracy: 59.49%\n",
      "Epoch [1050/2500], Train Loss: 0.9969, Train Accuracy: 56.19%, Test Loss: 0.9833, Test Accuracy: 60.76%\n",
      "Epoch [1051/2500], Train Loss: 1.0156, Train Accuracy: 56.47%, Test Loss: 0.9799, Test Accuracy: 59.49%\n",
      "Epoch [1052/2500], Train Loss: 1.0005, Train Accuracy: 57.47%, Test Loss: 0.9852, Test Accuracy: 60.76%\n",
      "Epoch [1053/2500], Train Loss: 1.0114, Train Accuracy: 56.33%, Test Loss: 0.9902, Test Accuracy: 59.49%\n",
      "Epoch [1054/2500], Train Loss: 1.0022, Train Accuracy: 58.18%, Test Loss: 0.9872, Test Accuracy: 60.76%\n",
      "Epoch [1055/2500], Train Loss: 1.0202, Train Accuracy: 57.33%, Test Loss: 0.9856, Test Accuracy: 59.49%\n",
      "Epoch [1056/2500], Train Loss: 0.9967, Train Accuracy: 57.75%, Test Loss: 0.9811, Test Accuracy: 59.49%\n",
      "Epoch [1057/2500], Train Loss: 0.9950, Train Accuracy: 58.32%, Test Loss: 0.9833, Test Accuracy: 59.49%\n",
      "Epoch [1058/2500], Train Loss: 0.9953, Train Accuracy: 57.75%, Test Loss: 0.9880, Test Accuracy: 59.49%\n",
      "Epoch [1059/2500], Train Loss: 1.0096, Train Accuracy: 56.61%, Test Loss: 0.9785, Test Accuracy: 59.49%\n",
      "Epoch [1060/2500], Train Loss: 1.0002, Train Accuracy: 57.61%, Test Loss: 0.9841, Test Accuracy: 59.49%\n",
      "Epoch [1061/2500], Train Loss: 1.0047, Train Accuracy: 57.61%, Test Loss: 0.9809, Test Accuracy: 59.49%\n",
      "Epoch [1062/2500], Train Loss: 0.9949, Train Accuracy: 56.33%, Test Loss: 0.9800, Test Accuracy: 59.49%\n",
      "Epoch [1063/2500], Train Loss: 0.9883, Train Accuracy: 56.61%, Test Loss: 0.9832, Test Accuracy: 59.49%\n",
      "Epoch [1064/2500], Train Loss: 1.0038, Train Accuracy: 57.33%, Test Loss: 0.9842, Test Accuracy: 59.49%\n",
      "Epoch [1065/2500], Train Loss: 0.9991, Train Accuracy: 58.61%, Test Loss: 0.9824, Test Accuracy: 59.49%\n",
      "Epoch [1066/2500], Train Loss: 0.9940, Train Accuracy: 56.76%, Test Loss: 0.9819, Test Accuracy: 59.49%\n",
      "Epoch [1067/2500], Train Loss: 1.0181, Train Accuracy: 57.89%, Test Loss: 0.9795, Test Accuracy: 59.49%\n",
      "Epoch [1068/2500], Train Loss: 0.9994, Train Accuracy: 57.47%, Test Loss: 0.9787, Test Accuracy: 59.49%\n",
      "Epoch [1069/2500], Train Loss: 0.9812, Train Accuracy: 58.04%, Test Loss: 0.9787, Test Accuracy: 59.49%\n",
      "Epoch [1070/2500], Train Loss: 0.9956, Train Accuracy: 57.61%, Test Loss: 0.9828, Test Accuracy: 59.49%\n",
      "Epoch [1071/2500], Train Loss: 1.0018, Train Accuracy: 57.33%, Test Loss: 0.9806, Test Accuracy: 59.49%\n",
      "Epoch [1072/2500], Train Loss: 0.9944, Train Accuracy: 56.05%, Test Loss: 0.9858, Test Accuracy: 59.49%\n",
      "Epoch [1073/2500], Train Loss: 0.9999, Train Accuracy: 55.90%, Test Loss: 0.9804, Test Accuracy: 59.49%\n",
      "Epoch [1074/2500], Train Loss: 0.9855, Train Accuracy: 57.33%, Test Loss: 0.9835, Test Accuracy: 59.49%\n",
      "Epoch [1075/2500], Train Loss: 1.0009, Train Accuracy: 57.18%, Test Loss: 0.9800, Test Accuracy: 59.49%\n",
      "Epoch [1076/2500], Train Loss: 0.9811, Train Accuracy: 57.33%, Test Loss: 0.9810, Test Accuracy: 59.49%\n",
      "Epoch [1077/2500], Train Loss: 0.9827, Train Accuracy: 58.18%, Test Loss: 0.9781, Test Accuracy: 59.49%\n",
      "Epoch [1078/2500], Train Loss: 0.9850, Train Accuracy: 57.89%, Test Loss: 0.9791, Test Accuracy: 59.49%\n",
      "Epoch [1079/2500], Train Loss: 0.9836, Train Accuracy: 56.61%, Test Loss: 0.9834, Test Accuracy: 59.49%\n",
      "Epoch [1080/2500], Train Loss: 1.0074, Train Accuracy: 57.33%, Test Loss: 0.9846, Test Accuracy: 59.49%\n",
      "Epoch [1081/2500], Train Loss: 1.0236, Train Accuracy: 56.61%, Test Loss: 0.9749, Test Accuracy: 59.49%\n",
      "Epoch [1082/2500], Train Loss: 0.9936, Train Accuracy: 56.61%, Test Loss: 0.9765, Test Accuracy: 59.49%\n",
      "Epoch [1083/2500], Train Loss: 0.9872, Train Accuracy: 56.61%, Test Loss: 0.9734, Test Accuracy: 59.49%\n",
      "Epoch [1084/2500], Train Loss: 0.9980, Train Accuracy: 56.90%, Test Loss: 0.9723, Test Accuracy: 59.49%\n",
      "Epoch [1085/2500], Train Loss: 0.9908, Train Accuracy: 56.47%, Test Loss: 0.9766, Test Accuracy: 59.49%\n",
      "Epoch [1086/2500], Train Loss: 0.9959, Train Accuracy: 56.61%, Test Loss: 0.9727, Test Accuracy: 59.49%\n",
      "Epoch [1087/2500], Train Loss: 0.9864, Train Accuracy: 57.61%, Test Loss: 0.9776, Test Accuracy: 59.49%\n",
      "Epoch [1088/2500], Train Loss: 1.0176, Train Accuracy: 56.61%, Test Loss: 0.9688, Test Accuracy: 58.23%\n",
      "Epoch [1089/2500], Train Loss: 0.9754, Train Accuracy: 57.75%, Test Loss: 0.9729, Test Accuracy: 59.49%\n",
      "Epoch [1090/2500], Train Loss: 0.9949, Train Accuracy: 55.90%, Test Loss: 0.9733, Test Accuracy: 59.49%\n",
      "Epoch [1091/2500], Train Loss: 0.9689, Train Accuracy: 58.32%, Test Loss: 0.9702, Test Accuracy: 59.49%\n",
      "Epoch [1092/2500], Train Loss: 0.9838, Train Accuracy: 57.89%, Test Loss: 0.9868, Test Accuracy: 59.49%\n",
      "Epoch [1093/2500], Train Loss: 0.9902, Train Accuracy: 56.76%, Test Loss: 0.9818, Test Accuracy: 59.49%\n",
      "Epoch [1094/2500], Train Loss: 0.9780, Train Accuracy: 59.03%, Test Loss: 0.9757, Test Accuracy: 59.49%\n",
      "Epoch [1095/2500], Train Loss: 0.9797, Train Accuracy: 57.04%, Test Loss: 0.9773, Test Accuracy: 59.49%\n",
      "Epoch [1096/2500], Train Loss: 0.9774, Train Accuracy: 57.33%, Test Loss: 0.9799, Test Accuracy: 59.49%\n",
      "Epoch [1097/2500], Train Loss: 0.9953, Train Accuracy: 57.18%, Test Loss: 0.9841, Test Accuracy: 59.49%\n",
      "Epoch [1098/2500], Train Loss: 0.9935, Train Accuracy: 57.47%, Test Loss: 0.9824, Test Accuracy: 59.49%\n",
      "Epoch [1099/2500], Train Loss: 0.9881, Train Accuracy: 57.33%, Test Loss: 0.9808, Test Accuracy: 59.49%\n",
      "Epoch [1100/2500], Train Loss: 0.9926, Train Accuracy: 57.18%, Test Loss: 0.9715, Test Accuracy: 58.23%\n",
      "Epoch [1101/2500], Train Loss: 0.9823, Train Accuracy: 57.47%, Test Loss: 0.9743, Test Accuracy: 59.49%\n",
      "Epoch [1102/2500], Train Loss: 0.9679, Train Accuracy: 57.61%, Test Loss: 0.9783, Test Accuracy: 59.49%\n",
      "Epoch [1103/2500], Train Loss: 0.9847, Train Accuracy: 58.18%, Test Loss: 0.9792, Test Accuracy: 59.49%\n",
      "Epoch [1104/2500], Train Loss: 0.9822, Train Accuracy: 58.18%, Test Loss: 0.9783, Test Accuracy: 59.49%\n",
      "Epoch [1105/2500], Train Loss: 0.9761, Train Accuracy: 57.75%, Test Loss: 0.9719, Test Accuracy: 58.23%\n",
      "Epoch [1106/2500], Train Loss: 0.9911, Train Accuracy: 57.89%, Test Loss: 0.9829, Test Accuracy: 59.49%\n",
      "Epoch [1107/2500], Train Loss: 1.0024, Train Accuracy: 57.18%, Test Loss: 0.9736, Test Accuracy: 58.23%\n",
      "Epoch [1108/2500], Train Loss: 0.9756, Train Accuracy: 58.61%, Test Loss: 0.9764, Test Accuracy: 59.49%\n",
      "Epoch [1109/2500], Train Loss: 0.9925, Train Accuracy: 56.33%, Test Loss: 0.9839, Test Accuracy: 59.49%\n",
      "Epoch [1110/2500], Train Loss: 0.9829, Train Accuracy: 57.89%, Test Loss: 0.9895, Test Accuracy: 60.76%\n",
      "Epoch [1111/2500], Train Loss: 0.9916, Train Accuracy: 57.04%, Test Loss: 0.9879, Test Accuracy: 59.49%\n",
      "Epoch [1112/2500], Train Loss: 0.9787, Train Accuracy: 58.04%, Test Loss: 0.9772, Test Accuracy: 59.49%\n",
      "Epoch [1113/2500], Train Loss: 0.9892, Train Accuracy: 57.75%, Test Loss: 0.9802, Test Accuracy: 59.49%\n",
      "Epoch [1114/2500], Train Loss: 0.9729, Train Accuracy: 57.04%, Test Loss: 0.9879, Test Accuracy: 59.49%\n",
      "Epoch [1115/2500], Train Loss: 0.9755, Train Accuracy: 57.33%, Test Loss: 0.9761, Test Accuracy: 59.49%\n",
      "Epoch [1116/2500], Train Loss: 0.9804, Train Accuracy: 58.46%, Test Loss: 0.9744, Test Accuracy: 59.49%\n",
      "Epoch [1117/2500], Train Loss: 0.9874, Train Accuracy: 56.76%, Test Loss: 0.9758, Test Accuracy: 59.49%\n",
      "Epoch [1118/2500], Train Loss: 0.9836, Train Accuracy: 57.18%, Test Loss: 0.9901, Test Accuracy: 59.49%\n",
      "Epoch [1119/2500], Train Loss: 0.9847, Train Accuracy: 56.33%, Test Loss: 0.9732, Test Accuracy: 59.49%\n",
      "Epoch [1120/2500], Train Loss: 0.9684, Train Accuracy: 58.32%, Test Loss: 0.9755, Test Accuracy: 59.49%\n",
      "Epoch [1121/2500], Train Loss: 0.9930, Train Accuracy: 57.61%, Test Loss: 0.9778, Test Accuracy: 59.49%\n",
      "Epoch [1122/2500], Train Loss: 0.9796, Train Accuracy: 56.61%, Test Loss: 0.9762, Test Accuracy: 59.49%\n",
      "Epoch [1123/2500], Train Loss: 0.9844, Train Accuracy: 57.75%, Test Loss: 0.9744, Test Accuracy: 59.49%\n",
      "Epoch [1124/2500], Train Loss: 0.9884, Train Accuracy: 58.32%, Test Loss: 0.9689, Test Accuracy: 59.49%\n",
      "Epoch [1125/2500], Train Loss: 0.9766, Train Accuracy: 58.18%, Test Loss: 0.9648, Test Accuracy: 59.49%\n",
      "Epoch [1126/2500], Train Loss: 0.9753, Train Accuracy: 57.33%, Test Loss: 0.9679, Test Accuracy: 59.49%\n",
      "Epoch [1127/2500], Train Loss: 0.9875, Train Accuracy: 58.46%, Test Loss: 0.9653, Test Accuracy: 59.49%\n",
      "Epoch [1128/2500], Train Loss: 0.9620, Train Accuracy: 57.61%, Test Loss: 0.9629, Test Accuracy: 59.49%\n",
      "Epoch [1129/2500], Train Loss: 0.9483, Train Accuracy: 58.75%, Test Loss: 0.9599, Test Accuracy: 59.49%\n",
      "Epoch [1130/2500], Train Loss: 0.9731, Train Accuracy: 58.32%, Test Loss: 0.9583, Test Accuracy: 59.49%\n",
      "Epoch [1131/2500], Train Loss: 0.9856, Train Accuracy: 57.47%, Test Loss: 0.9588, Test Accuracy: 59.49%\n",
      "Epoch [1132/2500], Train Loss: 0.9879, Train Accuracy: 57.04%, Test Loss: 0.9692, Test Accuracy: 59.49%\n",
      "Epoch [1133/2500], Train Loss: 0.9624, Train Accuracy: 58.04%, Test Loss: 0.9700, Test Accuracy: 59.49%\n",
      "Epoch [1134/2500], Train Loss: 0.9773, Train Accuracy: 56.19%, Test Loss: 0.9682, Test Accuracy: 59.49%\n",
      "Epoch [1135/2500], Train Loss: 0.9741, Train Accuracy: 57.89%, Test Loss: 0.9591, Test Accuracy: 59.49%\n",
      "Epoch [1136/2500], Train Loss: 0.9708, Train Accuracy: 57.04%, Test Loss: 0.9545, Test Accuracy: 59.49%\n",
      "Epoch [1137/2500], Train Loss: 0.9615, Train Accuracy: 57.89%, Test Loss: 0.9633, Test Accuracy: 59.49%\n",
      "Epoch [1138/2500], Train Loss: 0.9734, Train Accuracy: 57.61%, Test Loss: 0.9607, Test Accuracy: 59.49%\n",
      "Epoch [1139/2500], Train Loss: 0.9542, Train Accuracy: 57.18%, Test Loss: 0.9686, Test Accuracy: 59.49%\n",
      "Epoch [1140/2500], Train Loss: 0.9910, Train Accuracy: 57.04%, Test Loss: 0.9592, Test Accuracy: 59.49%\n",
      "Epoch [1141/2500], Train Loss: 0.9843, Train Accuracy: 57.18%, Test Loss: 0.9642, Test Accuracy: 59.49%\n",
      "Epoch [1142/2500], Train Loss: 0.9703, Train Accuracy: 57.75%, Test Loss: 0.9692, Test Accuracy: 59.49%\n",
      "Epoch [1143/2500], Train Loss: 0.9815, Train Accuracy: 56.76%, Test Loss: 0.9682, Test Accuracy: 59.49%\n",
      "Epoch [1144/2500], Train Loss: 0.9839, Train Accuracy: 58.32%, Test Loss: 0.9636, Test Accuracy: 59.49%\n",
      "Epoch [1145/2500], Train Loss: 0.9651, Train Accuracy: 58.32%, Test Loss: 0.9701, Test Accuracy: 59.49%\n",
      "Epoch [1146/2500], Train Loss: 0.9768, Train Accuracy: 57.75%, Test Loss: 0.9578, Test Accuracy: 59.49%\n",
      "Epoch [1147/2500], Train Loss: 0.9597, Train Accuracy: 58.46%, Test Loss: 0.9658, Test Accuracy: 59.49%\n",
      "Epoch [1148/2500], Train Loss: 0.9654, Train Accuracy: 57.89%, Test Loss: 0.9606, Test Accuracy: 59.49%\n",
      "Epoch [1149/2500], Train Loss: 0.9751, Train Accuracy: 57.61%, Test Loss: 0.9674, Test Accuracy: 59.49%\n",
      "Epoch [1150/2500], Train Loss: 0.9778, Train Accuracy: 57.33%, Test Loss: 0.9756, Test Accuracy: 60.76%\n",
      "Epoch [1151/2500], Train Loss: 0.9744, Train Accuracy: 57.47%, Test Loss: 0.9607, Test Accuracy: 59.49%\n",
      "Epoch [1152/2500], Train Loss: 0.9660, Train Accuracy: 58.04%, Test Loss: 0.9610, Test Accuracy: 59.49%\n",
      "Epoch [1153/2500], Train Loss: 0.9621, Train Accuracy: 57.47%, Test Loss: 0.9639, Test Accuracy: 59.49%\n",
      "Epoch [1154/2500], Train Loss: 0.9676, Train Accuracy: 56.90%, Test Loss: 0.9546, Test Accuracy: 59.49%\n",
      "Epoch [1155/2500], Train Loss: 0.9640, Train Accuracy: 58.32%, Test Loss: 0.9538, Test Accuracy: 59.49%\n",
      "Epoch [1156/2500], Train Loss: 0.9717, Train Accuracy: 58.46%, Test Loss: 0.9485, Test Accuracy: 59.49%\n",
      "Epoch [1157/2500], Train Loss: 0.9660, Train Accuracy: 57.18%, Test Loss: 0.9627, Test Accuracy: 59.49%\n",
      "Epoch [1158/2500], Train Loss: 0.9570, Train Accuracy: 57.47%, Test Loss: 0.9477, Test Accuracy: 59.49%\n",
      "Epoch [1159/2500], Train Loss: 0.9602, Train Accuracy: 57.61%, Test Loss: 0.9411, Test Accuracy: 59.49%\n",
      "Epoch [1160/2500], Train Loss: 0.9639, Train Accuracy: 57.18%, Test Loss: 0.9515, Test Accuracy: 59.49%\n",
      "Epoch [1161/2500], Train Loss: 0.9535, Train Accuracy: 58.04%, Test Loss: 0.9472, Test Accuracy: 59.49%\n",
      "Epoch [1162/2500], Train Loss: 0.9604, Train Accuracy: 56.61%, Test Loss: 0.9615, Test Accuracy: 59.49%\n",
      "Epoch [1163/2500], Train Loss: 0.9652, Train Accuracy: 58.18%, Test Loss: 0.9357, Test Accuracy: 59.49%\n",
      "Epoch [1164/2500], Train Loss: 0.9773, Train Accuracy: 57.33%, Test Loss: 0.9508, Test Accuracy: 59.49%\n",
      "Epoch [1165/2500], Train Loss: 0.9560, Train Accuracy: 57.75%, Test Loss: 0.9552, Test Accuracy: 59.49%\n",
      "Epoch [1166/2500], Train Loss: 0.9552, Train Accuracy: 58.32%, Test Loss: 0.9577, Test Accuracy: 59.49%\n",
      "Epoch [1167/2500], Train Loss: 0.9865, Train Accuracy: 57.33%, Test Loss: 0.9487, Test Accuracy: 59.49%\n",
      "Epoch [1168/2500], Train Loss: 0.9846, Train Accuracy: 56.47%, Test Loss: 0.9430, Test Accuracy: 59.49%\n",
      "Epoch [1169/2500], Train Loss: 0.9745, Train Accuracy: 57.89%, Test Loss: 0.9573, Test Accuracy: 59.49%\n",
      "Epoch [1170/2500], Train Loss: 0.9649, Train Accuracy: 58.04%, Test Loss: 0.9420, Test Accuracy: 59.49%\n",
      "Epoch [1171/2500], Train Loss: 0.9590, Train Accuracy: 56.90%, Test Loss: 0.9637, Test Accuracy: 59.49%\n",
      "Epoch [1172/2500], Train Loss: 0.9572, Train Accuracy: 58.46%, Test Loss: 0.9543, Test Accuracy: 59.49%\n",
      "Epoch [1173/2500], Train Loss: 0.9609, Train Accuracy: 56.90%, Test Loss: 0.9541, Test Accuracy: 59.49%\n",
      "Epoch [1174/2500], Train Loss: 0.9577, Train Accuracy: 58.75%, Test Loss: 0.9397, Test Accuracy: 59.49%\n",
      "Epoch [1175/2500], Train Loss: 0.9466, Train Accuracy: 58.18%, Test Loss: 0.9564, Test Accuracy: 59.49%\n",
      "Epoch [1176/2500], Train Loss: 0.9414, Train Accuracy: 58.18%, Test Loss: 0.9603, Test Accuracy: 59.49%\n",
      "Epoch [1177/2500], Train Loss: 0.9693, Train Accuracy: 58.46%, Test Loss: 0.9431, Test Accuracy: 59.49%\n",
      "Epoch [1178/2500], Train Loss: 0.9655, Train Accuracy: 57.47%, Test Loss: 0.9465, Test Accuracy: 59.49%\n",
      "Epoch [1179/2500], Train Loss: 0.9591, Train Accuracy: 57.33%, Test Loss: 0.9701, Test Accuracy: 60.76%\n",
      "Epoch [1180/2500], Train Loss: 0.9725, Train Accuracy: 57.61%, Test Loss: 0.9688, Test Accuracy: 59.49%\n",
      "Epoch [1181/2500], Train Loss: 0.9523, Train Accuracy: 58.18%, Test Loss: 0.9507, Test Accuracy: 59.49%\n",
      "Epoch [1182/2500], Train Loss: 0.9407, Train Accuracy: 58.46%, Test Loss: 0.9657, Test Accuracy: 59.49%\n",
      "Epoch [1183/2500], Train Loss: 0.9760, Train Accuracy: 58.32%, Test Loss: 0.9639, Test Accuracy: 59.49%\n",
      "Epoch [1184/2500], Train Loss: 0.9592, Train Accuracy: 56.90%, Test Loss: 0.9671, Test Accuracy: 60.76%\n",
      "Epoch [1185/2500], Train Loss: 0.9572, Train Accuracy: 57.33%, Test Loss: 0.9373, Test Accuracy: 59.49%\n",
      "Epoch [1186/2500], Train Loss: 0.9757, Train Accuracy: 58.04%, Test Loss: 0.9560, Test Accuracy: 59.49%\n",
      "Epoch [1187/2500], Train Loss: 0.9725, Train Accuracy: 57.61%, Test Loss: 0.9650, Test Accuracy: 60.76%\n",
      "Epoch [1188/2500], Train Loss: 0.9540, Train Accuracy: 58.04%, Test Loss: 0.9563, Test Accuracy: 59.49%\n",
      "Epoch [1189/2500], Train Loss: 0.9629, Train Accuracy: 57.75%, Test Loss: 0.9494, Test Accuracy: 59.49%\n",
      "Epoch [1190/2500], Train Loss: 0.9521, Train Accuracy: 57.47%, Test Loss: 0.9348, Test Accuracy: 59.49%\n",
      "Epoch [1191/2500], Train Loss: 0.9734, Train Accuracy: 58.32%, Test Loss: 0.9611, Test Accuracy: 59.49%\n",
      "Epoch [1192/2500], Train Loss: 0.9557, Train Accuracy: 58.89%, Test Loss: 0.9525, Test Accuracy: 59.49%\n",
      "Epoch [1193/2500], Train Loss: 0.9591, Train Accuracy: 57.61%, Test Loss: 0.9605, Test Accuracy: 60.76%\n",
      "Epoch [1194/2500], Train Loss: 0.9563, Train Accuracy: 58.32%, Test Loss: 0.9471, Test Accuracy: 59.49%\n",
      "Epoch [1195/2500], Train Loss: 0.9669, Train Accuracy: 57.61%, Test Loss: 0.9667, Test Accuracy: 60.76%\n",
      "Epoch [1196/2500], Train Loss: 0.9460, Train Accuracy: 57.61%, Test Loss: 0.9462, Test Accuracy: 59.49%\n",
      "Epoch [1197/2500], Train Loss: 0.9344, Train Accuracy: 58.32%, Test Loss: 0.9419, Test Accuracy: 59.49%\n",
      "Epoch [1198/2500], Train Loss: 0.9592, Train Accuracy: 57.89%, Test Loss: 0.9388, Test Accuracy: 59.49%\n",
      "Epoch [1199/2500], Train Loss: 0.9691, Train Accuracy: 58.04%, Test Loss: 0.9610, Test Accuracy: 60.76%\n",
      "Epoch [1200/2500], Train Loss: 0.9431, Train Accuracy: 58.32%, Test Loss: 0.9596, Test Accuracy: 58.23%\n",
      "Epoch [1201/2500], Train Loss: 0.9534, Train Accuracy: 59.03%, Test Loss: 0.9514, Test Accuracy: 58.23%\n",
      "Epoch [1202/2500], Train Loss: 0.9493, Train Accuracy: 57.61%, Test Loss: 0.9619, Test Accuracy: 58.23%\n",
      "Epoch [1203/2500], Train Loss: 0.9581, Train Accuracy: 57.47%, Test Loss: 0.9340, Test Accuracy: 59.49%\n",
      "Epoch [1204/2500], Train Loss: 0.9583, Train Accuracy: 58.32%, Test Loss: 0.9465, Test Accuracy: 60.76%\n",
      "Epoch [1205/2500], Train Loss: 0.9700, Train Accuracy: 57.33%, Test Loss: 0.9379, Test Accuracy: 60.76%\n",
      "Epoch [1206/2500], Train Loss: 0.9564, Train Accuracy: 57.47%, Test Loss: 0.9320, Test Accuracy: 59.49%\n",
      "Epoch [1207/2500], Train Loss: 0.9527, Train Accuracy: 57.04%, Test Loss: 0.9403, Test Accuracy: 59.49%\n",
      "Epoch [1208/2500], Train Loss: 0.9380, Train Accuracy: 57.89%, Test Loss: 0.9373, Test Accuracy: 58.23%\n",
      "Epoch [1209/2500], Train Loss: 0.9499, Train Accuracy: 57.61%, Test Loss: 0.9443, Test Accuracy: 59.49%\n",
      "Epoch [1210/2500], Train Loss: 0.9498, Train Accuracy: 57.33%, Test Loss: 0.9443, Test Accuracy: 59.49%\n",
      "Epoch [1211/2500], Train Loss: 0.9441, Train Accuracy: 58.75%, Test Loss: 0.9581, Test Accuracy: 58.23%\n",
      "Epoch [1212/2500], Train Loss: 0.9706, Train Accuracy: 57.47%, Test Loss: 0.9584, Test Accuracy: 59.49%\n",
      "Epoch [1213/2500], Train Loss: 0.9607, Train Accuracy: 57.75%, Test Loss: 0.9483, Test Accuracy: 59.49%\n",
      "Epoch [1214/2500], Train Loss: 0.9601, Train Accuracy: 57.61%, Test Loss: 0.9588, Test Accuracy: 59.49%\n",
      "Epoch [1215/2500], Train Loss: 0.9554, Train Accuracy: 56.76%, Test Loss: 0.9351, Test Accuracy: 60.76%\n",
      "Epoch [1216/2500], Train Loss: 0.9448, Train Accuracy: 57.75%, Test Loss: 0.9201, Test Accuracy: 59.49%\n",
      "Epoch [1217/2500], Train Loss: 0.9387, Train Accuracy: 59.03%, Test Loss: 0.9363, Test Accuracy: 59.49%\n",
      "Epoch [1218/2500], Train Loss: 0.9397, Train Accuracy: 58.32%, Test Loss: 0.9444, Test Accuracy: 58.23%\n",
      "Epoch [1219/2500], Train Loss: 0.9403, Train Accuracy: 57.75%, Test Loss: 0.9416, Test Accuracy: 60.76%\n",
      "Epoch [1220/2500], Train Loss: 0.9459, Train Accuracy: 57.75%, Test Loss: 0.9485, Test Accuracy: 58.23%\n",
      "Epoch [1221/2500], Train Loss: 0.9561, Train Accuracy: 58.75%, Test Loss: 0.9368, Test Accuracy: 59.49%\n",
      "Epoch [1222/2500], Train Loss: 0.9582, Train Accuracy: 58.04%, Test Loss: 0.9682, Test Accuracy: 58.23%\n",
      "Epoch [1223/2500], Train Loss: 0.9506, Train Accuracy: 57.75%, Test Loss: 0.9450, Test Accuracy: 59.49%\n",
      "Epoch [1224/2500], Train Loss: 0.9536, Train Accuracy: 59.17%, Test Loss: 0.9641, Test Accuracy: 58.23%\n",
      "Epoch [1225/2500], Train Loss: 0.9437, Train Accuracy: 58.04%, Test Loss: 0.9432, Test Accuracy: 58.23%\n",
      "Epoch [1226/2500], Train Loss: 0.9408, Train Accuracy: 57.61%, Test Loss: 0.9587, Test Accuracy: 58.23%\n",
      "Epoch [1227/2500], Train Loss: 0.9632, Train Accuracy: 57.18%, Test Loss: 0.9334, Test Accuracy: 58.23%\n",
      "Epoch [1228/2500], Train Loss: 0.9430, Train Accuracy: 60.17%, Test Loss: 0.9398, Test Accuracy: 58.23%\n",
      "Epoch [1229/2500], Train Loss: 0.9271, Train Accuracy: 58.89%, Test Loss: 0.9410, Test Accuracy: 59.49%\n",
      "Epoch [1230/2500], Train Loss: 0.9602, Train Accuracy: 56.90%, Test Loss: 0.9304, Test Accuracy: 58.23%\n",
      "Epoch [1231/2500], Train Loss: 0.9554, Train Accuracy: 58.04%, Test Loss: 0.9383, Test Accuracy: 58.23%\n",
      "Epoch [1232/2500], Train Loss: 0.9554, Train Accuracy: 59.17%, Test Loss: 0.9294, Test Accuracy: 58.23%\n",
      "Epoch [1233/2500], Train Loss: 0.9376, Train Accuracy: 58.32%, Test Loss: 0.9435, Test Accuracy: 59.49%\n",
      "Epoch [1234/2500], Train Loss: 0.9292, Train Accuracy: 58.89%, Test Loss: 0.9321, Test Accuracy: 59.49%\n",
      "Epoch [1235/2500], Train Loss: 0.9501, Train Accuracy: 58.18%, Test Loss: 0.9239, Test Accuracy: 59.49%\n",
      "Epoch [1236/2500], Train Loss: 0.9399, Train Accuracy: 58.18%, Test Loss: 0.9291, Test Accuracy: 58.23%\n",
      "Epoch [1237/2500], Train Loss: 0.9380, Train Accuracy: 58.18%, Test Loss: 0.9363, Test Accuracy: 59.49%\n",
      "Epoch [1238/2500], Train Loss: 0.9457, Train Accuracy: 57.89%, Test Loss: 0.9222, Test Accuracy: 58.23%\n",
      "Epoch [1239/2500], Train Loss: 0.9551, Train Accuracy: 57.61%, Test Loss: 0.9359, Test Accuracy: 59.49%\n",
      "Epoch [1240/2500], Train Loss: 0.9218, Train Accuracy: 58.61%, Test Loss: 0.9395, Test Accuracy: 58.23%\n",
      "Epoch [1241/2500], Train Loss: 0.9574, Train Accuracy: 57.89%, Test Loss: 0.9463, Test Accuracy: 59.49%\n",
      "Epoch [1242/2500], Train Loss: 0.9526, Train Accuracy: 58.61%, Test Loss: 0.9302, Test Accuracy: 58.23%\n",
      "Epoch [1243/2500], Train Loss: 0.9419, Train Accuracy: 56.76%, Test Loss: 0.9446, Test Accuracy: 59.49%\n",
      "Epoch [1244/2500], Train Loss: 0.9421, Train Accuracy: 58.18%, Test Loss: 0.9382, Test Accuracy: 59.49%\n",
      "Epoch [1245/2500], Train Loss: 0.9546, Train Accuracy: 58.18%, Test Loss: 0.9275, Test Accuracy: 58.23%\n",
      "Epoch [1246/2500], Train Loss: 0.9660, Train Accuracy: 58.04%, Test Loss: 0.9355, Test Accuracy: 59.49%\n",
      "Epoch [1247/2500], Train Loss: 0.9488, Train Accuracy: 58.89%, Test Loss: 0.9239, Test Accuracy: 59.49%\n",
      "Epoch [1248/2500], Train Loss: 0.9450, Train Accuracy: 57.04%, Test Loss: 0.9525, Test Accuracy: 59.49%\n",
      "Epoch [1249/2500], Train Loss: 0.9579, Train Accuracy: 58.61%, Test Loss: 0.9255, Test Accuracy: 59.49%\n",
      "Epoch [1250/2500], Train Loss: 0.9625, Train Accuracy: 57.33%, Test Loss: 0.9492, Test Accuracy: 59.49%\n",
      "Epoch [1251/2500], Train Loss: 0.9486, Train Accuracy: 58.89%, Test Loss: 0.9264, Test Accuracy: 59.49%\n",
      "Epoch [1252/2500], Train Loss: 0.9636, Train Accuracy: 58.46%, Test Loss: 0.9370, Test Accuracy: 59.49%\n",
      "Epoch [1253/2500], Train Loss: 0.9312, Train Accuracy: 58.32%, Test Loss: 0.9324, Test Accuracy: 59.49%\n",
      "Epoch [1254/2500], Train Loss: 0.9468, Train Accuracy: 57.61%, Test Loss: 0.9253, Test Accuracy: 59.49%\n",
      "Epoch [1255/2500], Train Loss: 0.9395, Train Accuracy: 58.04%, Test Loss: 0.9271, Test Accuracy: 59.49%\n",
      "Epoch [1256/2500], Train Loss: 0.9426, Train Accuracy: 57.47%, Test Loss: 0.9239, Test Accuracy: 59.49%\n",
      "Epoch [1257/2500], Train Loss: 0.9540, Train Accuracy: 57.47%, Test Loss: 0.9136, Test Accuracy: 59.49%\n",
      "Epoch [1258/2500], Train Loss: 0.9460, Train Accuracy: 58.46%, Test Loss: 0.9219, Test Accuracy: 59.49%\n",
      "Epoch [1259/2500], Train Loss: 0.9600, Train Accuracy: 57.61%, Test Loss: 0.9145, Test Accuracy: 59.49%\n",
      "Epoch [1260/2500], Train Loss: 0.9375, Train Accuracy: 58.04%, Test Loss: 0.9282, Test Accuracy: 59.49%\n",
      "Epoch [1261/2500], Train Loss: 0.9630, Train Accuracy: 57.47%, Test Loss: 0.9188, Test Accuracy: 59.49%\n",
      "Epoch [1262/2500], Train Loss: 0.9491, Train Accuracy: 57.18%, Test Loss: 0.9236, Test Accuracy: 60.76%\n",
      "Epoch [1263/2500], Train Loss: 0.9378, Train Accuracy: 57.75%, Test Loss: 0.9150, Test Accuracy: 59.49%\n",
      "Epoch [1264/2500], Train Loss: 0.9600, Train Accuracy: 57.33%, Test Loss: 0.9221, Test Accuracy: 59.49%\n",
      "Epoch [1265/2500], Train Loss: 0.9427, Train Accuracy: 59.17%, Test Loss: 0.9305, Test Accuracy: 59.49%\n",
      "Epoch [1266/2500], Train Loss: 0.9341, Train Accuracy: 59.03%, Test Loss: 0.9337, Test Accuracy: 59.49%\n",
      "Epoch [1267/2500], Train Loss: 0.9354, Train Accuracy: 58.32%, Test Loss: 0.9128, Test Accuracy: 59.49%\n",
      "Epoch [1268/2500], Train Loss: 0.9304, Train Accuracy: 57.89%, Test Loss: 0.9276, Test Accuracy: 60.76%\n",
      "Epoch [1269/2500], Train Loss: 0.9313, Train Accuracy: 58.32%, Test Loss: 0.9255, Test Accuracy: 60.76%\n",
      "Epoch [1270/2500], Train Loss: 0.9440, Train Accuracy: 59.46%, Test Loss: 0.9299, Test Accuracy: 60.76%\n",
      "Epoch [1271/2500], Train Loss: 0.9254, Train Accuracy: 58.89%, Test Loss: 0.9210, Test Accuracy: 60.76%\n",
      "Epoch [1272/2500], Train Loss: 0.9528, Train Accuracy: 58.18%, Test Loss: 0.9096, Test Accuracy: 60.76%\n",
      "Epoch [1273/2500], Train Loss: 0.9291, Train Accuracy: 59.74%, Test Loss: 0.9187, Test Accuracy: 59.49%\n",
      "Epoch [1274/2500], Train Loss: 0.9357, Train Accuracy: 58.32%, Test Loss: 0.9162, Test Accuracy: 59.49%\n",
      "Epoch [1275/2500], Train Loss: 0.9316, Train Accuracy: 58.61%, Test Loss: 0.9151, Test Accuracy: 60.76%\n",
      "Epoch [1276/2500], Train Loss: 0.9486, Train Accuracy: 58.61%, Test Loss: 0.9094, Test Accuracy: 60.76%\n",
      "Epoch [1277/2500], Train Loss: 0.9365, Train Accuracy: 58.75%, Test Loss: 0.9165, Test Accuracy: 60.76%\n",
      "Epoch [1278/2500], Train Loss: 0.9436, Train Accuracy: 59.03%, Test Loss: 0.9146, Test Accuracy: 60.76%\n",
      "Epoch [1279/2500], Train Loss: 0.9446, Train Accuracy: 58.18%, Test Loss: 0.9120, Test Accuracy: 60.76%\n",
      "Epoch [1280/2500], Train Loss: 0.9295, Train Accuracy: 58.04%, Test Loss: 0.9051, Test Accuracy: 60.76%\n",
      "Epoch [1281/2500], Train Loss: 0.9266, Train Accuracy: 59.74%, Test Loss: 0.9110, Test Accuracy: 60.76%\n",
      "Epoch [1282/2500], Train Loss: 0.9261, Train Accuracy: 59.60%, Test Loss: 0.9198, Test Accuracy: 60.76%\n",
      "Epoch [1283/2500], Train Loss: 0.9407, Train Accuracy: 58.32%, Test Loss: 0.9241, Test Accuracy: 60.76%\n",
      "Epoch [1284/2500], Train Loss: 0.9485, Train Accuracy: 56.76%, Test Loss: 0.9224, Test Accuracy: 60.76%\n",
      "Epoch [1285/2500], Train Loss: 0.9292, Train Accuracy: 59.32%, Test Loss: 0.9193, Test Accuracy: 60.76%\n",
      "Epoch [1286/2500], Train Loss: 0.9292, Train Accuracy: 57.89%, Test Loss: 0.9203, Test Accuracy: 60.76%\n",
      "Epoch [1287/2500], Train Loss: 0.9355, Train Accuracy: 57.89%, Test Loss: 0.9222, Test Accuracy: 60.76%\n",
      "Epoch [1288/2500], Train Loss: 0.9222, Train Accuracy: 59.46%, Test Loss: 0.9373, Test Accuracy: 62.03%\n",
      "Epoch [1289/2500], Train Loss: 0.9267, Train Accuracy: 58.75%, Test Loss: 0.9230, Test Accuracy: 60.76%\n",
      "Epoch [1290/2500], Train Loss: 0.9397, Train Accuracy: 57.18%, Test Loss: 0.9354, Test Accuracy: 62.03%\n",
      "Epoch [1291/2500], Train Loss: 0.9274, Train Accuracy: 58.18%, Test Loss: 0.9292, Test Accuracy: 62.03%\n",
      "Epoch [1292/2500], Train Loss: 0.9172, Train Accuracy: 57.75%, Test Loss: 0.9319, Test Accuracy: 62.03%\n",
      "Epoch [1293/2500], Train Loss: 0.9362, Train Accuracy: 58.32%, Test Loss: 0.9344, Test Accuracy: 62.03%\n",
      "Epoch [1294/2500], Train Loss: 0.9178, Train Accuracy: 59.32%, Test Loss: 0.9436, Test Accuracy: 59.49%\n",
      "Epoch [1295/2500], Train Loss: 0.9224, Train Accuracy: 59.03%, Test Loss: 0.9365, Test Accuracy: 62.03%\n",
      "Epoch [1296/2500], Train Loss: 0.9463, Train Accuracy: 58.18%, Test Loss: 0.9262, Test Accuracy: 60.76%\n",
      "Epoch [1297/2500], Train Loss: 0.9383, Train Accuracy: 59.32%, Test Loss: 0.9304, Test Accuracy: 62.03%\n",
      "Epoch [1298/2500], Train Loss: 0.9485, Train Accuracy: 57.33%, Test Loss: 0.9267, Test Accuracy: 62.03%\n",
      "Epoch [1299/2500], Train Loss: 0.9551, Train Accuracy: 58.32%, Test Loss: 0.9160, Test Accuracy: 62.03%\n",
      "Epoch [1300/2500], Train Loss: 0.9331, Train Accuracy: 58.04%, Test Loss: 0.8998, Test Accuracy: 60.76%\n",
      "Epoch [1301/2500], Train Loss: 0.9139, Train Accuracy: 58.89%, Test Loss: 0.9195, Test Accuracy: 62.03%\n",
      "Epoch [1302/2500], Train Loss: 0.9313, Train Accuracy: 57.89%, Test Loss: 0.9019, Test Accuracy: 60.76%\n",
      "Epoch [1303/2500], Train Loss: 0.9193, Train Accuracy: 58.46%, Test Loss: 0.8997, Test Accuracy: 60.76%\n",
      "Epoch [1304/2500], Train Loss: 0.9355, Train Accuracy: 60.31%, Test Loss: 0.9210, Test Accuracy: 60.76%\n",
      "Epoch [1305/2500], Train Loss: 0.9349, Train Accuracy: 58.75%, Test Loss: 0.9056, Test Accuracy: 62.03%\n",
      "Epoch [1306/2500], Train Loss: 0.9268, Train Accuracy: 59.46%, Test Loss: 0.9050, Test Accuracy: 62.03%\n",
      "Epoch [1307/2500], Train Loss: 0.9162, Train Accuracy: 58.89%, Test Loss: 0.9120, Test Accuracy: 60.76%\n",
      "Epoch [1308/2500], Train Loss: 0.9295, Train Accuracy: 59.17%, Test Loss: 0.9124, Test Accuracy: 62.03%\n",
      "Epoch [1309/2500], Train Loss: 0.9154, Train Accuracy: 60.31%, Test Loss: 0.9368, Test Accuracy: 59.49%\n",
      "Epoch [1310/2500], Train Loss: 0.9308, Train Accuracy: 58.32%, Test Loss: 0.9259, Test Accuracy: 59.49%\n",
      "Epoch [1311/2500], Train Loss: 0.9146, Train Accuracy: 60.17%, Test Loss: 0.9339, Test Accuracy: 59.49%\n",
      "Epoch [1312/2500], Train Loss: 0.9090, Train Accuracy: 58.18%, Test Loss: 0.9101, Test Accuracy: 62.03%\n",
      "Epoch [1313/2500], Train Loss: 0.9274, Train Accuracy: 57.18%, Test Loss: 0.9300, Test Accuracy: 62.03%\n",
      "Epoch [1314/2500], Train Loss: 0.9280, Train Accuracy: 58.89%, Test Loss: 0.9185, Test Accuracy: 62.03%\n",
      "Epoch [1315/2500], Train Loss: 0.9339, Train Accuracy: 57.18%, Test Loss: 0.9092, Test Accuracy: 62.03%\n",
      "Epoch [1316/2500], Train Loss: 0.9323, Train Accuracy: 58.46%, Test Loss: 0.9133, Test Accuracy: 62.03%\n",
      "Epoch [1317/2500], Train Loss: 0.9308, Train Accuracy: 57.47%, Test Loss: 0.9149, Test Accuracy: 62.03%\n",
      "Epoch [1318/2500], Train Loss: 0.9282, Train Accuracy: 59.17%, Test Loss: 0.9337, Test Accuracy: 59.49%\n",
      "Epoch [1319/2500], Train Loss: 0.9154, Train Accuracy: 59.03%, Test Loss: 0.9386, Test Accuracy: 59.49%\n",
      "Epoch [1320/2500], Train Loss: 0.9204, Train Accuracy: 57.89%, Test Loss: 0.9217, Test Accuracy: 59.49%\n",
      "Epoch [1321/2500], Train Loss: 0.9176, Train Accuracy: 59.74%, Test Loss: 0.8972, Test Accuracy: 62.03%\n",
      "Epoch [1322/2500], Train Loss: 0.9272, Train Accuracy: 59.17%, Test Loss: 0.9027, Test Accuracy: 62.03%\n",
      "Epoch [1323/2500], Train Loss: 0.9308, Train Accuracy: 59.60%, Test Loss: 0.9004, Test Accuracy: 60.76%\n",
      "Epoch [1324/2500], Train Loss: 0.9108, Train Accuracy: 60.17%, Test Loss: 0.9086, Test Accuracy: 62.03%\n",
      "Epoch [1325/2500], Train Loss: 0.9175, Train Accuracy: 58.32%, Test Loss: 0.9013, Test Accuracy: 62.03%\n",
      "Epoch [1326/2500], Train Loss: 0.9252, Train Accuracy: 59.46%, Test Loss: 0.9052, Test Accuracy: 62.03%\n",
      "Epoch [1327/2500], Train Loss: 0.9189, Train Accuracy: 58.89%, Test Loss: 0.8946, Test Accuracy: 62.03%\n",
      "Epoch [1328/2500], Train Loss: 0.9058, Train Accuracy: 59.89%, Test Loss: 0.9095, Test Accuracy: 60.76%\n",
      "Epoch [1329/2500], Train Loss: 0.9159, Train Accuracy: 59.46%, Test Loss: 0.9106, Test Accuracy: 62.03%\n",
      "Epoch [1330/2500], Train Loss: 0.9200, Train Accuracy: 57.89%, Test Loss: 0.9106, Test Accuracy: 62.03%\n",
      "Epoch [1331/2500], Train Loss: 0.9211, Train Accuracy: 59.03%, Test Loss: 0.9278, Test Accuracy: 60.76%\n",
      "Epoch [1332/2500], Train Loss: 0.9357, Train Accuracy: 59.60%, Test Loss: 0.8974, Test Accuracy: 63.29%\n",
      "Epoch [1333/2500], Train Loss: 0.9225, Train Accuracy: 58.61%, Test Loss: 0.9239, Test Accuracy: 60.76%\n",
      "Epoch [1334/2500], Train Loss: 0.9038, Train Accuracy: 61.31%, Test Loss: 0.9128, Test Accuracy: 62.03%\n",
      "Epoch [1335/2500], Train Loss: 0.9046, Train Accuracy: 60.46%, Test Loss: 0.9151, Test Accuracy: 59.49%\n",
      "Epoch [1336/2500], Train Loss: 0.9147, Train Accuracy: 59.46%, Test Loss: 0.9090, Test Accuracy: 62.03%\n",
      "Epoch [1337/2500], Train Loss: 0.8934, Train Accuracy: 60.17%, Test Loss: 0.9422, Test Accuracy: 59.49%\n",
      "Epoch [1338/2500], Train Loss: 0.9090, Train Accuracy: 59.17%, Test Loss: 0.9114, Test Accuracy: 62.03%\n",
      "Epoch [1339/2500], Train Loss: 0.9189, Train Accuracy: 60.03%, Test Loss: 0.9089, Test Accuracy: 62.03%\n",
      "Epoch [1340/2500], Train Loss: 0.9146, Train Accuracy: 60.46%, Test Loss: 0.9082, Test Accuracy: 62.03%\n",
      "Epoch [1341/2500], Train Loss: 0.9354, Train Accuracy: 59.03%, Test Loss: 0.9122, Test Accuracy: 62.03%\n",
      "Epoch [1342/2500], Train Loss: 0.9451, Train Accuracy: 58.32%, Test Loss: 0.9192, Test Accuracy: 62.03%\n",
      "Epoch [1343/2500], Train Loss: 0.8981, Train Accuracy: 59.46%, Test Loss: 0.9164, Test Accuracy: 60.76%\n",
      "Epoch [1344/2500], Train Loss: 0.9308, Train Accuracy: 59.03%, Test Loss: 0.9032, Test Accuracy: 63.29%\n",
      "Epoch [1345/2500], Train Loss: 0.9198, Train Accuracy: 58.89%, Test Loss: 0.9019, Test Accuracy: 63.29%\n",
      "Epoch [1346/2500], Train Loss: 0.9201, Train Accuracy: 57.61%, Test Loss: 0.8942, Test Accuracy: 63.29%\n",
      "Epoch [1347/2500], Train Loss: 0.9014, Train Accuracy: 59.60%, Test Loss: 0.9062, Test Accuracy: 59.49%\n",
      "Epoch [1348/2500], Train Loss: 0.8969, Train Accuracy: 58.32%, Test Loss: 0.8988, Test Accuracy: 59.49%\n",
      "Epoch [1349/2500], Train Loss: 0.9317, Train Accuracy: 59.46%, Test Loss: 0.8847, Test Accuracy: 62.03%\n",
      "Epoch [1350/2500], Train Loss: 0.9132, Train Accuracy: 59.60%, Test Loss: 0.9100, Test Accuracy: 59.49%\n",
      "Epoch [1351/2500], Train Loss: 0.9303, Train Accuracy: 59.03%, Test Loss: 0.8842, Test Accuracy: 60.76%\n",
      "Epoch [1352/2500], Train Loss: 0.9237, Train Accuracy: 59.03%, Test Loss: 0.8981, Test Accuracy: 62.03%\n",
      "Epoch [1353/2500], Train Loss: 0.9018, Train Accuracy: 59.89%, Test Loss: 0.8824, Test Accuracy: 62.03%\n",
      "Epoch [1354/2500], Train Loss: 0.8930, Train Accuracy: 61.31%, Test Loss: 0.9125, Test Accuracy: 59.49%\n",
      "Epoch [1355/2500], Train Loss: 0.9113, Train Accuracy: 59.60%, Test Loss: 0.8883, Test Accuracy: 62.03%\n",
      "Epoch [1356/2500], Train Loss: 0.9299, Train Accuracy: 59.74%, Test Loss: 0.8936, Test Accuracy: 62.03%\n",
      "Epoch [1357/2500], Train Loss: 0.9202, Train Accuracy: 60.03%, Test Loss: 0.9005, Test Accuracy: 62.03%\n",
      "Epoch [1358/2500], Train Loss: 0.8955, Train Accuracy: 59.03%, Test Loss: 0.9124, Test Accuracy: 62.03%\n",
      "Epoch [1359/2500], Train Loss: 0.9189, Train Accuracy: 59.03%, Test Loss: 0.8919, Test Accuracy: 63.29%\n",
      "Epoch [1360/2500], Train Loss: 0.9044, Train Accuracy: 60.17%, Test Loss: 0.9032, Test Accuracy: 60.76%\n",
      "Epoch [1361/2500], Train Loss: 0.9045, Train Accuracy: 60.31%, Test Loss: 0.8940, Test Accuracy: 62.03%\n",
      "Epoch [1362/2500], Train Loss: 0.9074, Train Accuracy: 59.17%, Test Loss: 0.9177, Test Accuracy: 60.76%\n",
      "Epoch [1363/2500], Train Loss: 0.9169, Train Accuracy: 59.32%, Test Loss: 0.8982, Test Accuracy: 63.29%\n",
      "Epoch [1364/2500], Train Loss: 0.9159, Train Accuracy: 60.60%, Test Loss: 0.9040, Test Accuracy: 62.03%\n",
      "Epoch [1365/2500], Train Loss: 0.9034, Train Accuracy: 58.89%, Test Loss: 0.8985, Test Accuracy: 62.03%\n",
      "Epoch [1366/2500], Train Loss: 0.9403, Train Accuracy: 58.46%, Test Loss: 0.8987, Test Accuracy: 60.76%\n",
      "Epoch [1367/2500], Train Loss: 0.9059, Train Accuracy: 60.03%, Test Loss: 0.8936, Test Accuracy: 62.03%\n",
      "Epoch [1368/2500], Train Loss: 0.9046, Train Accuracy: 58.61%, Test Loss: 0.8995, Test Accuracy: 62.03%\n",
      "Epoch [1369/2500], Train Loss: 0.9001, Train Accuracy: 60.17%, Test Loss: 0.8951, Test Accuracy: 62.03%\n",
      "Epoch [1370/2500], Train Loss: 0.8777, Train Accuracy: 59.46%, Test Loss: 0.8913, Test Accuracy: 62.03%\n",
      "Epoch [1371/2500], Train Loss: 0.9000, Train Accuracy: 60.74%, Test Loss: 0.8851, Test Accuracy: 62.03%\n",
      "Epoch [1372/2500], Train Loss: 0.9215, Train Accuracy: 59.46%, Test Loss: 0.8927, Test Accuracy: 62.03%\n",
      "Epoch [1373/2500], Train Loss: 0.9187, Train Accuracy: 57.89%, Test Loss: 0.8981, Test Accuracy: 63.29%\n",
      "Epoch [1374/2500], Train Loss: 0.9155, Train Accuracy: 59.74%, Test Loss: 0.9098, Test Accuracy: 60.76%\n",
      "Epoch [1375/2500], Train Loss: 0.9191, Train Accuracy: 60.17%, Test Loss: 0.9128, Test Accuracy: 62.03%\n",
      "Epoch [1376/2500], Train Loss: 0.8943, Train Accuracy: 59.03%, Test Loss: 0.9063, Test Accuracy: 62.03%\n",
      "Epoch [1377/2500], Train Loss: 0.9240, Train Accuracy: 59.17%, Test Loss: 0.8828, Test Accuracy: 63.29%\n",
      "Epoch [1378/2500], Train Loss: 0.8886, Train Accuracy: 60.88%, Test Loss: 0.8988, Test Accuracy: 62.03%\n",
      "Epoch [1379/2500], Train Loss: 0.9158, Train Accuracy: 58.75%, Test Loss: 0.8969, Test Accuracy: 62.03%\n",
      "Epoch [1380/2500], Train Loss: 0.9054, Train Accuracy: 60.03%, Test Loss: 0.8948, Test Accuracy: 62.03%\n",
      "Epoch [1381/2500], Train Loss: 0.8923, Train Accuracy: 60.88%, Test Loss: 0.8986, Test Accuracy: 62.03%\n",
      "Epoch [1382/2500], Train Loss: 0.9092, Train Accuracy: 59.74%, Test Loss: 0.9080, Test Accuracy: 62.03%\n",
      "Epoch [1383/2500], Train Loss: 0.9071, Train Accuracy: 60.46%, Test Loss: 0.9026, Test Accuracy: 62.03%\n",
      "Epoch [1384/2500], Train Loss: 0.8904, Train Accuracy: 59.32%, Test Loss: 0.9128, Test Accuracy: 62.03%\n",
      "Epoch [1385/2500], Train Loss: 0.9281, Train Accuracy: 60.74%, Test Loss: 0.8930, Test Accuracy: 62.03%\n",
      "Epoch [1386/2500], Train Loss: 0.8987, Train Accuracy: 59.89%, Test Loss: 0.8933, Test Accuracy: 62.03%\n",
      "Epoch [1387/2500], Train Loss: 0.9019, Train Accuracy: 58.61%, Test Loss: 0.8852, Test Accuracy: 62.03%\n",
      "Epoch [1388/2500], Train Loss: 0.9011, Train Accuracy: 58.89%, Test Loss: 0.8795, Test Accuracy: 62.03%\n",
      "Epoch [1389/2500], Train Loss: 0.8908, Train Accuracy: 62.02%, Test Loss: 0.8902, Test Accuracy: 62.03%\n",
      "Epoch [1390/2500], Train Loss: 0.9029, Train Accuracy: 59.89%, Test Loss: 0.8810, Test Accuracy: 62.03%\n",
      "Epoch [1391/2500], Train Loss: 0.8964, Train Accuracy: 59.46%, Test Loss: 0.8748, Test Accuracy: 62.03%\n",
      "Epoch [1392/2500], Train Loss: 0.8864, Train Accuracy: 60.17%, Test Loss: 0.8774, Test Accuracy: 62.03%\n",
      "Epoch [1393/2500], Train Loss: 0.9129, Train Accuracy: 59.32%, Test Loss: 0.8870, Test Accuracy: 62.03%\n",
      "Epoch [1394/2500], Train Loss: 0.8949, Train Accuracy: 61.02%, Test Loss: 0.9010, Test Accuracy: 62.03%\n",
      "Epoch [1395/2500], Train Loss: 0.8942, Train Accuracy: 60.17%, Test Loss: 0.8957, Test Accuracy: 62.03%\n",
      "Epoch [1396/2500], Train Loss: 0.9177, Train Accuracy: 59.32%, Test Loss: 0.8838, Test Accuracy: 60.76%\n",
      "Epoch [1397/2500], Train Loss: 0.8940, Train Accuracy: 58.89%, Test Loss: 0.8811, Test Accuracy: 62.03%\n",
      "Epoch [1398/2500], Train Loss: 0.8945, Train Accuracy: 61.31%, Test Loss: 0.9158, Test Accuracy: 59.49%\n",
      "Epoch [1399/2500], Train Loss: 0.9026, Train Accuracy: 61.02%, Test Loss: 0.9046, Test Accuracy: 62.03%\n",
      "Epoch [1400/2500], Train Loss: 0.9101, Train Accuracy: 61.17%, Test Loss: 0.8913, Test Accuracy: 60.76%\n",
      "Epoch [1401/2500], Train Loss: 0.8853, Train Accuracy: 60.60%, Test Loss: 0.9063, Test Accuracy: 59.49%\n",
      "Epoch [1402/2500], Train Loss: 0.8902, Train Accuracy: 61.17%, Test Loss: 0.8767, Test Accuracy: 62.03%\n",
      "Epoch [1403/2500], Train Loss: 0.8950, Train Accuracy: 61.02%, Test Loss: 0.8880, Test Accuracy: 60.76%\n",
      "Epoch [1404/2500], Train Loss: 0.9192, Train Accuracy: 58.75%, Test Loss: 0.8819, Test Accuracy: 60.76%\n",
      "Epoch [1405/2500], Train Loss: 0.9026, Train Accuracy: 60.88%, Test Loss: 0.8930, Test Accuracy: 60.76%\n",
      "Epoch [1406/2500], Train Loss: 0.8921, Train Accuracy: 59.74%, Test Loss: 0.8913, Test Accuracy: 60.76%\n",
      "Epoch [1407/2500], Train Loss: 0.8959, Train Accuracy: 60.17%, Test Loss: 0.9141, Test Accuracy: 62.03%\n",
      "Epoch [1408/2500], Train Loss: 0.9080, Train Accuracy: 59.46%, Test Loss: 0.8963, Test Accuracy: 60.76%\n",
      "Epoch [1409/2500], Train Loss: 0.8924, Train Accuracy: 59.89%, Test Loss: 0.9010, Test Accuracy: 60.76%\n",
      "Epoch [1410/2500], Train Loss: 0.9220, Train Accuracy: 59.17%, Test Loss: 0.8909, Test Accuracy: 62.03%\n",
      "Epoch [1411/2500], Train Loss: 0.8882, Train Accuracy: 60.74%, Test Loss: 0.8939, Test Accuracy: 60.76%\n",
      "Epoch [1412/2500], Train Loss: 0.8898, Train Accuracy: 61.59%, Test Loss: 0.8894, Test Accuracy: 60.76%\n",
      "Epoch [1413/2500], Train Loss: 0.8966, Train Accuracy: 61.02%, Test Loss: 0.9034, Test Accuracy: 60.76%\n",
      "Epoch [1414/2500], Train Loss: 0.8744, Train Accuracy: 60.31%, Test Loss: 0.8864, Test Accuracy: 60.76%\n",
      "Epoch [1415/2500], Train Loss: 0.8958, Train Accuracy: 62.02%, Test Loss: 0.8837, Test Accuracy: 62.03%\n",
      "Epoch [1416/2500], Train Loss: 0.8944, Train Accuracy: 61.17%, Test Loss: 0.8948, Test Accuracy: 60.76%\n",
      "Epoch [1417/2500], Train Loss: 0.8972, Train Accuracy: 62.16%, Test Loss: 0.8799, Test Accuracy: 60.76%\n",
      "Epoch [1418/2500], Train Loss: 0.9055, Train Accuracy: 60.17%, Test Loss: 0.8907, Test Accuracy: 60.76%\n",
      "Epoch [1419/2500], Train Loss: 0.8870, Train Accuracy: 62.30%, Test Loss: 0.8795, Test Accuracy: 60.76%\n",
      "Epoch [1420/2500], Train Loss: 0.8944, Train Accuracy: 60.17%, Test Loss: 0.9007, Test Accuracy: 60.76%\n",
      "Epoch [1421/2500], Train Loss: 0.8693, Train Accuracy: 59.89%, Test Loss: 0.9048, Test Accuracy: 60.76%\n",
      "Epoch [1422/2500], Train Loss: 0.8906, Train Accuracy: 59.74%, Test Loss: 0.9189, Test Accuracy: 62.03%\n",
      "Epoch [1423/2500], Train Loss: 0.8780, Train Accuracy: 62.45%, Test Loss: 0.8866, Test Accuracy: 60.76%\n",
      "Epoch [1424/2500], Train Loss: 0.8741, Train Accuracy: 60.60%, Test Loss: 0.8886, Test Accuracy: 60.76%\n",
      "Epoch [1425/2500], Train Loss: 0.8862, Train Accuracy: 59.89%, Test Loss: 0.8946, Test Accuracy: 60.76%\n",
      "Epoch [1426/2500], Train Loss: 0.9033, Train Accuracy: 61.45%, Test Loss: 0.9021, Test Accuracy: 60.76%\n",
      "Epoch [1427/2500], Train Loss: 0.8897, Train Accuracy: 61.59%, Test Loss: 0.9136, Test Accuracy: 62.03%\n",
      "Epoch [1428/2500], Train Loss: 0.8896, Train Accuracy: 59.89%, Test Loss: 0.8843, Test Accuracy: 62.03%\n",
      "Epoch [1429/2500], Train Loss: 0.8986, Train Accuracy: 59.17%, Test Loss: 0.9249, Test Accuracy: 60.76%\n",
      "Epoch [1430/2500], Train Loss: 0.8945, Train Accuracy: 60.03%, Test Loss: 0.8873, Test Accuracy: 60.76%\n",
      "Epoch [1431/2500], Train Loss: 0.8957, Train Accuracy: 59.60%, Test Loss: 0.8887, Test Accuracy: 60.76%\n",
      "Epoch [1432/2500], Train Loss: 0.9058, Train Accuracy: 61.17%, Test Loss: 0.8905, Test Accuracy: 62.03%\n",
      "Epoch [1433/2500], Train Loss: 0.8852, Train Accuracy: 61.02%, Test Loss: 0.8961, Test Accuracy: 62.03%\n",
      "Epoch [1434/2500], Train Loss: 0.8922, Train Accuracy: 59.89%, Test Loss: 0.8763, Test Accuracy: 60.76%\n",
      "Epoch [1435/2500], Train Loss: 0.8859, Train Accuracy: 61.02%, Test Loss: 0.9050, Test Accuracy: 62.03%\n",
      "Epoch [1436/2500], Train Loss: 0.8880, Train Accuracy: 59.89%, Test Loss: 0.8944, Test Accuracy: 60.76%\n",
      "Epoch [1437/2500], Train Loss: 0.8916, Train Accuracy: 61.17%, Test Loss: 0.8932, Test Accuracy: 60.76%\n",
      "Epoch [1438/2500], Train Loss: 0.8587, Train Accuracy: 63.02%, Test Loss: 0.9090, Test Accuracy: 60.76%\n",
      "Epoch [1439/2500], Train Loss: 0.8715, Train Accuracy: 61.17%, Test Loss: 0.9049, Test Accuracy: 60.76%\n",
      "Epoch [1440/2500], Train Loss: 0.8784, Train Accuracy: 60.17%, Test Loss: 0.8870, Test Accuracy: 60.76%\n",
      "Epoch [1441/2500], Train Loss: 0.9037, Train Accuracy: 59.89%, Test Loss: 0.8812, Test Accuracy: 62.03%\n",
      "Epoch [1442/2500], Train Loss: 0.8903, Train Accuracy: 59.03%, Test Loss: 0.8926, Test Accuracy: 62.03%\n",
      "Epoch [1443/2500], Train Loss: 0.8779, Train Accuracy: 60.60%, Test Loss: 0.9158, Test Accuracy: 62.03%\n",
      "Epoch [1444/2500], Train Loss: 0.8795, Train Accuracy: 61.02%, Test Loss: 0.8915, Test Accuracy: 60.76%\n",
      "Epoch [1445/2500], Train Loss: 0.8860, Train Accuracy: 60.03%, Test Loss: 0.8810, Test Accuracy: 60.76%\n",
      "Epoch [1446/2500], Train Loss: 0.8558, Train Accuracy: 61.74%, Test Loss: 0.9015, Test Accuracy: 63.29%\n",
      "Epoch [1447/2500], Train Loss: 0.8840, Train Accuracy: 62.30%, Test Loss: 0.8916, Test Accuracy: 59.49%\n",
      "Epoch [1448/2500], Train Loss: 0.8888, Train Accuracy: 60.46%, Test Loss: 0.8702, Test Accuracy: 60.76%\n",
      "Epoch [1449/2500], Train Loss: 0.9174, Train Accuracy: 60.03%, Test Loss: 0.8894, Test Accuracy: 63.29%\n",
      "Epoch [1450/2500], Train Loss: 0.8727, Train Accuracy: 61.02%, Test Loss: 0.8899, Test Accuracy: 63.29%\n",
      "Epoch [1451/2500], Train Loss: 0.8774, Train Accuracy: 61.59%, Test Loss: 0.8935, Test Accuracy: 63.29%\n",
      "Epoch [1452/2500], Train Loss: 0.8833, Train Accuracy: 61.45%, Test Loss: 0.8915, Test Accuracy: 60.76%\n",
      "Epoch [1453/2500], Train Loss: 0.8640, Train Accuracy: 60.74%, Test Loss: 0.8962, Test Accuracy: 63.29%\n",
      "Epoch [1454/2500], Train Loss: 0.8944, Train Accuracy: 62.16%, Test Loss: 0.8849, Test Accuracy: 60.76%\n",
      "Epoch [1455/2500], Train Loss: 0.8822, Train Accuracy: 60.60%, Test Loss: 0.8894, Test Accuracy: 60.76%\n",
      "Epoch [1456/2500], Train Loss: 0.8893, Train Accuracy: 62.87%, Test Loss: 0.8925, Test Accuracy: 60.76%\n",
      "Epoch [1457/2500], Train Loss: 0.8866, Train Accuracy: 61.74%, Test Loss: 0.8932, Test Accuracy: 59.49%\n",
      "Epoch [1458/2500], Train Loss: 0.8800, Train Accuracy: 59.89%, Test Loss: 0.8792, Test Accuracy: 62.03%\n",
      "Epoch [1459/2500], Train Loss: 0.8716, Train Accuracy: 62.30%, Test Loss: 0.8934, Test Accuracy: 63.29%\n",
      "Epoch [1460/2500], Train Loss: 0.8622, Train Accuracy: 62.73%, Test Loss: 0.8753, Test Accuracy: 62.03%\n",
      "Epoch [1461/2500], Train Loss: 0.8857, Train Accuracy: 60.31%, Test Loss: 0.8832, Test Accuracy: 64.56%\n",
      "Epoch [1462/2500], Train Loss: 0.8653, Train Accuracy: 60.74%, Test Loss: 0.8755, Test Accuracy: 63.29%\n",
      "Epoch [1463/2500], Train Loss: 0.8858, Train Accuracy: 61.17%, Test Loss: 0.9108, Test Accuracy: 63.29%\n",
      "Epoch [1464/2500], Train Loss: 0.8804, Train Accuracy: 61.02%, Test Loss: 0.8827, Test Accuracy: 60.76%\n",
      "Epoch [1465/2500], Train Loss: 0.8915, Train Accuracy: 61.02%, Test Loss: 0.8845, Test Accuracy: 60.76%\n",
      "Epoch [1466/2500], Train Loss: 0.8755, Train Accuracy: 60.03%, Test Loss: 0.8972, Test Accuracy: 60.76%\n",
      "Epoch [1467/2500], Train Loss: 0.8892, Train Accuracy: 61.59%, Test Loss: 0.8890, Test Accuracy: 59.49%\n",
      "Epoch [1468/2500], Train Loss: 0.9029, Train Accuracy: 61.45%, Test Loss: 0.8878, Test Accuracy: 60.76%\n",
      "Epoch [1469/2500], Train Loss: 0.8565, Train Accuracy: 61.74%, Test Loss: 0.9178, Test Accuracy: 63.29%\n",
      "Epoch [1470/2500], Train Loss: 0.8945, Train Accuracy: 60.31%, Test Loss: 0.9102, Test Accuracy: 62.03%\n",
      "Epoch [1471/2500], Train Loss: 0.8976, Train Accuracy: 59.32%, Test Loss: 0.8940, Test Accuracy: 60.76%\n",
      "Epoch [1472/2500], Train Loss: 0.8752, Train Accuracy: 60.74%, Test Loss: 0.8954, Test Accuracy: 63.29%\n",
      "Epoch [1473/2500], Train Loss: 0.8625, Train Accuracy: 60.74%, Test Loss: 0.8874, Test Accuracy: 60.76%\n",
      "Epoch [1474/2500], Train Loss: 0.8872, Train Accuracy: 62.59%, Test Loss: 0.9021, Test Accuracy: 63.29%\n",
      "Epoch [1475/2500], Train Loss: 0.8639, Train Accuracy: 61.74%, Test Loss: 0.9183, Test Accuracy: 62.03%\n",
      "Epoch [1476/2500], Train Loss: 0.9052, Train Accuracy: 61.02%, Test Loss: 0.8993, Test Accuracy: 60.76%\n",
      "Epoch [1477/2500], Train Loss: 0.8721, Train Accuracy: 61.59%, Test Loss: 0.8987, Test Accuracy: 62.03%\n",
      "Epoch [1478/2500], Train Loss: 0.8755, Train Accuracy: 61.17%, Test Loss: 0.9014, Test Accuracy: 62.03%\n",
      "Epoch [1479/2500], Train Loss: 0.8599, Train Accuracy: 62.16%, Test Loss: 0.8923, Test Accuracy: 62.03%\n",
      "Epoch [1480/2500], Train Loss: 0.8749, Train Accuracy: 61.74%, Test Loss: 0.9010, Test Accuracy: 62.03%\n",
      "Epoch [1481/2500], Train Loss: 0.8770, Train Accuracy: 61.17%, Test Loss: 0.8943, Test Accuracy: 62.03%\n",
      "Epoch [1482/2500], Train Loss: 0.8859, Train Accuracy: 62.02%, Test Loss: 0.9079, Test Accuracy: 62.03%\n",
      "Epoch [1483/2500], Train Loss: 0.8752, Train Accuracy: 60.60%, Test Loss: 0.8896, Test Accuracy: 62.03%\n",
      "Epoch [1484/2500], Train Loss: 0.8964, Train Accuracy: 60.46%, Test Loss: 0.8875, Test Accuracy: 64.56%\n",
      "Epoch [1485/2500], Train Loss: 0.8636, Train Accuracy: 61.74%, Test Loss: 0.8922, Test Accuracy: 64.56%\n",
      "Epoch [1486/2500], Train Loss: 0.8829, Train Accuracy: 60.74%, Test Loss: 0.8816, Test Accuracy: 62.03%\n",
      "Epoch [1487/2500], Train Loss: 0.8903, Train Accuracy: 61.02%, Test Loss: 0.8811, Test Accuracy: 64.56%\n",
      "Epoch [1488/2500], Train Loss: 0.8567, Train Accuracy: 61.74%, Test Loss: 0.8778, Test Accuracy: 60.76%\n",
      "Epoch [1489/2500], Train Loss: 0.8783, Train Accuracy: 61.45%, Test Loss: 0.9001, Test Accuracy: 64.56%\n",
      "Epoch [1490/2500], Train Loss: 0.8782, Train Accuracy: 60.46%, Test Loss: 0.8816, Test Accuracy: 64.56%\n",
      "Epoch [1491/2500], Train Loss: 0.8747, Train Accuracy: 60.74%, Test Loss: 0.8925, Test Accuracy: 65.82%\n",
      "Epoch [1492/2500], Train Loss: 0.8420, Train Accuracy: 63.58%, Test Loss: 0.8944, Test Accuracy: 64.56%\n",
      "Epoch [1493/2500], Train Loss: 0.8326, Train Accuracy: 63.02%, Test Loss: 0.8860, Test Accuracy: 64.56%\n",
      "Epoch [1494/2500], Train Loss: 0.8751, Train Accuracy: 60.46%, Test Loss: 0.9102, Test Accuracy: 64.56%\n",
      "Epoch [1495/2500], Train Loss: 0.8734, Train Accuracy: 59.32%, Test Loss: 0.8837, Test Accuracy: 64.56%\n",
      "Epoch [1496/2500], Train Loss: 0.8570, Train Accuracy: 61.31%, Test Loss: 0.8883, Test Accuracy: 64.56%\n",
      "Epoch [1497/2500], Train Loss: 0.8814, Train Accuracy: 62.87%, Test Loss: 0.8843, Test Accuracy: 64.56%\n",
      "Epoch [1498/2500], Train Loss: 0.8519, Train Accuracy: 63.30%, Test Loss: 0.8820, Test Accuracy: 62.03%\n",
      "Epoch [1499/2500], Train Loss: 0.8562, Train Accuracy: 60.88%, Test Loss: 0.9147, Test Accuracy: 65.82%\n",
      "Epoch [1500/2500], Train Loss: 0.8870, Train Accuracy: 59.89%, Test Loss: 0.8891, Test Accuracy: 63.29%\n",
      "Epoch [1501/2500], Train Loss: 0.8528, Train Accuracy: 61.02%, Test Loss: 0.8797, Test Accuracy: 65.82%\n",
      "Epoch [1502/2500], Train Loss: 0.8800, Train Accuracy: 62.30%, Test Loss: 0.9020, Test Accuracy: 65.82%\n",
      "Epoch [1503/2500], Train Loss: 0.8583, Train Accuracy: 61.59%, Test Loss: 0.9021, Test Accuracy: 65.82%\n",
      "Epoch [1504/2500], Train Loss: 0.8630, Train Accuracy: 62.30%, Test Loss: 0.9008, Test Accuracy: 64.56%\n",
      "Epoch [1505/2500], Train Loss: 0.8745, Train Accuracy: 61.88%, Test Loss: 0.9051, Test Accuracy: 67.09%\n",
      "Epoch [1506/2500], Train Loss: 0.8900, Train Accuracy: 60.60%, Test Loss: 0.8807, Test Accuracy: 67.09%\n",
      "Epoch [1507/2500], Train Loss: 0.8677, Train Accuracy: 62.73%, Test Loss: 0.8898, Test Accuracy: 65.82%\n",
      "Epoch [1508/2500], Train Loss: 0.8724, Train Accuracy: 62.59%, Test Loss: 0.8816, Test Accuracy: 62.03%\n",
      "Epoch [1509/2500], Train Loss: 0.8528, Train Accuracy: 61.74%, Test Loss: 0.8893, Test Accuracy: 62.03%\n",
      "Epoch [1510/2500], Train Loss: 0.8597, Train Accuracy: 63.30%, Test Loss: 0.9033, Test Accuracy: 62.03%\n",
      "Epoch [1511/2500], Train Loss: 0.8670, Train Accuracy: 61.17%, Test Loss: 0.8750, Test Accuracy: 63.29%\n",
      "Epoch [1512/2500], Train Loss: 0.8676, Train Accuracy: 61.59%, Test Loss: 0.8853, Test Accuracy: 63.29%\n",
      "Epoch [1513/2500], Train Loss: 0.8745, Train Accuracy: 61.59%, Test Loss: 0.8770, Test Accuracy: 62.03%\n",
      "Epoch [1514/2500], Train Loss: 0.8780, Train Accuracy: 61.59%, Test Loss: 0.9044, Test Accuracy: 62.03%\n",
      "Epoch [1515/2500], Train Loss: 0.8784, Train Accuracy: 61.31%, Test Loss: 0.8833, Test Accuracy: 65.82%\n",
      "Epoch [1516/2500], Train Loss: 0.8713, Train Accuracy: 61.17%, Test Loss: 0.8796, Test Accuracy: 62.03%\n",
      "Epoch [1517/2500], Train Loss: 0.8439, Train Accuracy: 63.58%, Test Loss: 0.8880, Test Accuracy: 62.03%\n",
      "Epoch [1518/2500], Train Loss: 0.8729, Train Accuracy: 62.87%, Test Loss: 0.9023, Test Accuracy: 67.09%\n",
      "Epoch [1519/2500], Train Loss: 0.8726, Train Accuracy: 61.31%, Test Loss: 0.8703, Test Accuracy: 64.56%\n",
      "Epoch [1520/2500], Train Loss: 0.8740, Train Accuracy: 60.88%, Test Loss: 0.8752, Test Accuracy: 64.56%\n",
      "Epoch [1521/2500], Train Loss: 0.8679, Train Accuracy: 61.45%, Test Loss: 0.8800, Test Accuracy: 64.56%\n",
      "Epoch [1522/2500], Train Loss: 0.8392, Train Accuracy: 62.73%, Test Loss: 0.8743, Test Accuracy: 65.82%\n",
      "Epoch [1523/2500], Train Loss: 0.8708, Train Accuracy: 60.60%, Test Loss: 0.8781, Test Accuracy: 63.29%\n",
      "Epoch [1524/2500], Train Loss: 0.8509, Train Accuracy: 62.45%, Test Loss: 0.8795, Test Accuracy: 63.29%\n",
      "Epoch [1525/2500], Train Loss: 0.8885, Train Accuracy: 61.59%, Test Loss: 0.8740, Test Accuracy: 63.29%\n",
      "Epoch [1526/2500], Train Loss: 0.8478, Train Accuracy: 63.87%, Test Loss: 0.8732, Test Accuracy: 64.56%\n",
      "Epoch [1527/2500], Train Loss: 0.8613, Train Accuracy: 60.17%, Test Loss: 0.8693, Test Accuracy: 64.56%\n",
      "Epoch [1528/2500], Train Loss: 0.8567, Train Accuracy: 62.16%, Test Loss: 0.8763, Test Accuracy: 65.82%\n",
      "Epoch [1529/2500], Train Loss: 0.8548, Train Accuracy: 62.87%, Test Loss: 0.8632, Test Accuracy: 64.56%\n",
      "Epoch [1530/2500], Train Loss: 0.8522, Train Accuracy: 61.31%, Test Loss: 0.8747, Test Accuracy: 64.56%\n",
      "Epoch [1531/2500], Train Loss: 0.8573, Train Accuracy: 63.02%, Test Loss: 0.8755, Test Accuracy: 64.56%\n",
      "Epoch [1532/2500], Train Loss: 0.8572, Train Accuracy: 61.74%, Test Loss: 0.8731, Test Accuracy: 64.56%\n",
      "Epoch [1533/2500], Train Loss: 0.8533, Train Accuracy: 62.87%, Test Loss: 0.8731, Test Accuracy: 64.56%\n",
      "Epoch [1534/2500], Train Loss: 0.8696, Train Accuracy: 62.16%, Test Loss: 0.8852, Test Accuracy: 63.29%\n",
      "Epoch [1535/2500], Train Loss: 0.8374, Train Accuracy: 63.58%, Test Loss: 0.8652, Test Accuracy: 62.03%\n",
      "Epoch [1536/2500], Train Loss: 0.8588, Train Accuracy: 62.16%, Test Loss: 0.8797, Test Accuracy: 64.56%\n",
      "Epoch [1537/2500], Train Loss: 0.8707, Train Accuracy: 61.02%, Test Loss: 0.8767, Test Accuracy: 65.82%\n",
      "Epoch [1538/2500], Train Loss: 0.8550, Train Accuracy: 62.87%, Test Loss: 0.8741, Test Accuracy: 62.03%\n",
      "Epoch [1539/2500], Train Loss: 0.8472, Train Accuracy: 62.87%, Test Loss: 0.8830, Test Accuracy: 64.56%\n",
      "Epoch [1540/2500], Train Loss: 0.8438, Train Accuracy: 61.45%, Test Loss: 0.8676, Test Accuracy: 64.56%\n",
      "Epoch [1541/2500], Train Loss: 0.8559, Train Accuracy: 63.02%, Test Loss: 0.8747, Test Accuracy: 63.29%\n",
      "Epoch [1542/2500], Train Loss: 0.8690, Train Accuracy: 62.16%, Test Loss: 0.8883, Test Accuracy: 67.09%\n",
      "Epoch [1543/2500], Train Loss: 0.8569, Train Accuracy: 62.73%, Test Loss: 0.8921, Test Accuracy: 65.82%\n",
      "Epoch [1544/2500], Train Loss: 0.8402, Train Accuracy: 62.30%, Test Loss: 0.8972, Test Accuracy: 64.56%\n",
      "Epoch [1545/2500], Train Loss: 0.8560, Train Accuracy: 63.30%, Test Loss: 0.8684, Test Accuracy: 62.03%\n",
      "Epoch [1546/2500], Train Loss: 0.8648, Train Accuracy: 62.59%, Test Loss: 0.8747, Test Accuracy: 63.29%\n",
      "Epoch [1547/2500], Train Loss: 0.8434, Train Accuracy: 63.02%, Test Loss: 0.8905, Test Accuracy: 68.35%\n",
      "Epoch [1548/2500], Train Loss: 0.8483, Train Accuracy: 63.58%, Test Loss: 0.8811, Test Accuracy: 65.82%\n",
      "Epoch [1549/2500], Train Loss: 0.8482, Train Accuracy: 62.45%, Test Loss: 0.8877, Test Accuracy: 68.35%\n",
      "Epoch [1550/2500], Train Loss: 0.8537, Train Accuracy: 62.59%, Test Loss: 0.8875, Test Accuracy: 65.82%\n",
      "Epoch [1551/2500], Train Loss: 0.8635, Train Accuracy: 62.02%, Test Loss: 0.8801, Test Accuracy: 65.82%\n",
      "Epoch [1552/2500], Train Loss: 0.8899, Train Accuracy: 61.45%, Test Loss: 0.8808, Test Accuracy: 67.09%\n",
      "Epoch [1553/2500], Train Loss: 0.8556, Train Accuracy: 62.30%, Test Loss: 0.8817, Test Accuracy: 67.09%\n",
      "Epoch [1554/2500], Train Loss: 0.8565, Train Accuracy: 61.88%, Test Loss: 0.8643, Test Accuracy: 65.82%\n",
      "Epoch [1555/2500], Train Loss: 0.8638, Train Accuracy: 63.16%, Test Loss: 0.8748, Test Accuracy: 65.82%\n",
      "Epoch [1556/2500], Train Loss: 0.8591, Train Accuracy: 60.03%, Test Loss: 0.8861, Test Accuracy: 65.82%\n",
      "Epoch [1557/2500], Train Loss: 0.8563, Train Accuracy: 61.17%, Test Loss: 0.8769, Test Accuracy: 65.82%\n",
      "Epoch [1558/2500], Train Loss: 0.8443, Train Accuracy: 62.73%, Test Loss: 0.8750, Test Accuracy: 67.09%\n",
      "Epoch [1559/2500], Train Loss: 0.8524, Train Accuracy: 62.30%, Test Loss: 0.8699, Test Accuracy: 65.82%\n",
      "Epoch [1560/2500], Train Loss: 0.8524, Train Accuracy: 63.02%, Test Loss: 0.8742, Test Accuracy: 65.82%\n",
      "Epoch [1561/2500], Train Loss: 0.8681, Train Accuracy: 62.59%, Test Loss: 0.8743, Test Accuracy: 67.09%\n",
      "Epoch [1562/2500], Train Loss: 0.8603, Train Accuracy: 61.74%, Test Loss: 0.8901, Test Accuracy: 65.82%\n",
      "Epoch [1563/2500], Train Loss: 0.8812, Train Accuracy: 60.31%, Test Loss: 0.8788, Test Accuracy: 64.56%\n",
      "Epoch [1564/2500], Train Loss: 0.8655, Train Accuracy: 61.31%, Test Loss: 0.8861, Test Accuracy: 65.82%\n",
      "Epoch [1565/2500], Train Loss: 0.8580, Train Accuracy: 62.59%, Test Loss: 0.8740, Test Accuracy: 65.82%\n",
      "Epoch [1566/2500], Train Loss: 0.8180, Train Accuracy: 63.44%, Test Loss: 0.8929, Test Accuracy: 65.82%\n",
      "Epoch [1567/2500], Train Loss: 0.8544, Train Accuracy: 62.73%, Test Loss: 0.8884, Test Accuracy: 65.82%\n",
      "Epoch [1568/2500], Train Loss: 0.8694, Train Accuracy: 62.02%, Test Loss: 0.8816, Test Accuracy: 65.82%\n",
      "Epoch [1569/2500], Train Loss: 0.8500, Train Accuracy: 61.17%, Test Loss: 0.8938, Test Accuracy: 67.09%\n",
      "Epoch [1570/2500], Train Loss: 0.8451, Train Accuracy: 64.01%, Test Loss: 0.8756, Test Accuracy: 65.82%\n",
      "Epoch [1571/2500], Train Loss: 0.8412, Train Accuracy: 62.73%, Test Loss: 0.8712, Test Accuracy: 65.82%\n",
      "Epoch [1572/2500], Train Loss: 0.8696, Train Accuracy: 61.17%, Test Loss: 0.8696, Test Accuracy: 63.29%\n",
      "Epoch [1573/2500], Train Loss: 0.8426, Train Accuracy: 62.73%, Test Loss: 0.8602, Test Accuracy: 64.56%\n",
      "Epoch [1574/2500], Train Loss: 0.8703, Train Accuracy: 61.88%, Test Loss: 0.8663, Test Accuracy: 64.56%\n",
      "Epoch [1575/2500], Train Loss: 0.8722, Train Accuracy: 61.59%, Test Loss: 0.8789, Test Accuracy: 68.35%\n",
      "Epoch [1576/2500], Train Loss: 0.8764, Train Accuracy: 61.31%, Test Loss: 0.8665, Test Accuracy: 64.56%\n",
      "Epoch [1577/2500], Train Loss: 0.8647, Train Accuracy: 60.74%, Test Loss: 0.8808, Test Accuracy: 67.09%\n",
      "Epoch [1578/2500], Train Loss: 0.8317, Train Accuracy: 63.44%, Test Loss: 0.8915, Test Accuracy: 65.82%\n",
      "Epoch [1579/2500], Train Loss: 0.8351, Train Accuracy: 64.72%, Test Loss: 0.8721, Test Accuracy: 64.56%\n",
      "Epoch [1580/2500], Train Loss: 0.8533, Train Accuracy: 62.30%, Test Loss: 0.8851, Test Accuracy: 67.09%\n",
      "Epoch [1581/2500], Train Loss: 0.8398, Train Accuracy: 64.86%, Test Loss: 0.8714, Test Accuracy: 67.09%\n",
      "Epoch [1582/2500], Train Loss: 0.8399, Train Accuracy: 64.44%, Test Loss: 0.8883, Test Accuracy: 67.09%\n",
      "Epoch [1583/2500], Train Loss: 0.8459, Train Accuracy: 62.45%, Test Loss: 0.8777, Test Accuracy: 68.35%\n",
      "Epoch [1584/2500], Train Loss: 0.8372, Train Accuracy: 63.44%, Test Loss: 0.9033, Test Accuracy: 64.56%\n",
      "Epoch [1585/2500], Train Loss: 0.8547, Train Accuracy: 63.44%, Test Loss: 0.8829, Test Accuracy: 65.82%\n",
      "Epoch [1586/2500], Train Loss: 0.8753, Train Accuracy: 62.87%, Test Loss: 0.8862, Test Accuracy: 67.09%\n",
      "Epoch [1587/2500], Train Loss: 0.8537, Train Accuracy: 62.87%, Test Loss: 0.8704, Test Accuracy: 67.09%\n",
      "Epoch [1588/2500], Train Loss: 0.8480, Train Accuracy: 62.16%, Test Loss: 0.8610, Test Accuracy: 67.09%\n",
      "Epoch [1589/2500], Train Loss: 0.8779, Train Accuracy: 60.74%, Test Loss: 0.8783, Test Accuracy: 68.35%\n",
      "Epoch [1590/2500], Train Loss: 0.8579, Train Accuracy: 61.31%, Test Loss: 0.8711, Test Accuracy: 67.09%\n",
      "Epoch [1591/2500], Train Loss: 0.8461, Train Accuracy: 62.87%, Test Loss: 0.8738, Test Accuracy: 65.82%\n",
      "Epoch [1592/2500], Train Loss: 0.8380, Train Accuracy: 64.01%, Test Loss: 0.8690, Test Accuracy: 67.09%\n",
      "Epoch [1593/2500], Train Loss: 0.8253, Train Accuracy: 63.58%, Test Loss: 0.8694, Test Accuracy: 67.09%\n",
      "Epoch [1594/2500], Train Loss: 0.8384, Train Accuracy: 62.73%, Test Loss: 0.8646, Test Accuracy: 67.09%\n",
      "Epoch [1595/2500], Train Loss: 0.8593, Train Accuracy: 62.16%, Test Loss: 0.8808, Test Accuracy: 65.82%\n",
      "Epoch [1596/2500], Train Loss: 0.8377, Train Accuracy: 63.87%, Test Loss: 0.8669, Test Accuracy: 68.35%\n",
      "Epoch [1597/2500], Train Loss: 0.8440, Train Accuracy: 61.17%, Test Loss: 0.8935, Test Accuracy: 64.56%\n",
      "Epoch [1598/2500], Train Loss: 0.8592, Train Accuracy: 61.17%, Test Loss: 0.8747, Test Accuracy: 67.09%\n",
      "Epoch [1599/2500], Train Loss: 0.8342, Train Accuracy: 61.59%, Test Loss: 0.9008, Test Accuracy: 64.56%\n",
      "Epoch [1600/2500], Train Loss: 0.8507, Train Accuracy: 61.74%, Test Loss: 0.8668, Test Accuracy: 68.35%\n",
      "Epoch [1601/2500], Train Loss: 0.8265, Train Accuracy: 64.30%, Test Loss: 0.8858, Test Accuracy: 67.09%\n",
      "Epoch [1602/2500], Train Loss: 0.8377, Train Accuracy: 64.15%, Test Loss: 0.8945, Test Accuracy: 67.09%\n",
      "Epoch [1603/2500], Train Loss: 0.8452, Train Accuracy: 63.30%, Test Loss: 0.8761, Test Accuracy: 65.82%\n",
      "Epoch [1604/2500], Train Loss: 0.8625, Train Accuracy: 62.73%, Test Loss: 0.8972, Test Accuracy: 68.35%\n",
      "Epoch [1605/2500], Train Loss: 0.8232, Train Accuracy: 64.44%, Test Loss: 0.8719, Test Accuracy: 68.35%\n",
      "Epoch [1606/2500], Train Loss: 0.8385, Train Accuracy: 63.44%, Test Loss: 0.8823, Test Accuracy: 68.35%\n",
      "Epoch [1607/2500], Train Loss: 0.8493, Train Accuracy: 62.87%, Test Loss: 0.8670, Test Accuracy: 68.35%\n",
      "Epoch [1608/2500], Train Loss: 0.8519, Train Accuracy: 61.17%, Test Loss: 0.9142, Test Accuracy: 64.56%\n",
      "Epoch [1609/2500], Train Loss: 0.8357, Train Accuracy: 62.16%, Test Loss: 0.8675, Test Accuracy: 68.35%\n",
      "Epoch [1610/2500], Train Loss: 0.8448, Train Accuracy: 62.45%, Test Loss: 0.8666, Test Accuracy: 67.09%\n",
      "Epoch [1611/2500], Train Loss: 0.8371, Train Accuracy: 62.87%, Test Loss: 0.8644, Test Accuracy: 69.62%\n",
      "Epoch [1612/2500], Train Loss: 0.8532, Train Accuracy: 62.02%, Test Loss: 0.8542, Test Accuracy: 68.35%\n",
      "Epoch [1613/2500], Train Loss: 0.8350, Train Accuracy: 63.44%, Test Loss: 0.8834, Test Accuracy: 67.09%\n",
      "Epoch [1614/2500], Train Loss: 0.8412, Train Accuracy: 61.74%, Test Loss: 0.8784, Test Accuracy: 67.09%\n",
      "Epoch [1615/2500], Train Loss: 0.8366, Train Accuracy: 62.87%, Test Loss: 0.8723, Test Accuracy: 67.09%\n",
      "Epoch [1616/2500], Train Loss: 0.8305, Train Accuracy: 63.58%, Test Loss: 0.8767, Test Accuracy: 67.09%\n",
      "Epoch [1617/2500], Train Loss: 0.8331, Train Accuracy: 60.88%, Test Loss: 0.8743, Test Accuracy: 67.09%\n",
      "Epoch [1618/2500], Train Loss: 0.8503, Train Accuracy: 64.01%, Test Loss: 0.8699, Test Accuracy: 68.35%\n",
      "Epoch [1619/2500], Train Loss: 0.8328, Train Accuracy: 64.44%, Test Loss: 0.8879, Test Accuracy: 68.35%\n",
      "Epoch [1620/2500], Train Loss: 0.8353, Train Accuracy: 62.87%, Test Loss: 0.8715, Test Accuracy: 68.35%\n",
      "Epoch [1621/2500], Train Loss: 0.8576, Train Accuracy: 62.73%, Test Loss: 0.8797, Test Accuracy: 68.35%\n",
      "Epoch [1622/2500], Train Loss: 0.8504, Train Accuracy: 61.31%, Test Loss: 0.8766, Test Accuracy: 67.09%\n",
      "Epoch [1623/2500], Train Loss: 0.8571, Train Accuracy: 61.17%, Test Loss: 0.8687, Test Accuracy: 65.82%\n",
      "Epoch [1624/2500], Train Loss: 0.8348, Train Accuracy: 65.58%, Test Loss: 0.8606, Test Accuracy: 70.89%\n",
      "Epoch [1625/2500], Train Loss: 0.8312, Train Accuracy: 62.87%, Test Loss: 0.8615, Test Accuracy: 69.62%\n",
      "Epoch [1626/2500], Train Loss: 0.8380, Train Accuracy: 63.30%, Test Loss: 0.8749, Test Accuracy: 65.82%\n",
      "Epoch [1627/2500], Train Loss: 0.8631, Train Accuracy: 60.88%, Test Loss: 0.8827, Test Accuracy: 67.09%\n",
      "Epoch [1628/2500], Train Loss: 0.8492, Train Accuracy: 61.74%, Test Loss: 0.8793, Test Accuracy: 69.62%\n",
      "Epoch [1629/2500], Train Loss: 0.8280, Train Accuracy: 65.15%, Test Loss: 0.8726, Test Accuracy: 69.62%\n",
      "Epoch [1630/2500], Train Loss: 0.8355, Train Accuracy: 61.59%, Test Loss: 0.8840, Test Accuracy: 65.82%\n",
      "Epoch [1631/2500], Train Loss: 0.8482, Train Accuracy: 62.02%, Test Loss: 0.8809, Test Accuracy: 67.09%\n",
      "Epoch [1632/2500], Train Loss: 0.8271, Train Accuracy: 61.74%, Test Loss: 0.8824, Test Accuracy: 68.35%\n",
      "Epoch [1633/2500], Train Loss: 0.8468, Train Accuracy: 62.02%, Test Loss: 0.9245, Test Accuracy: 60.76%\n",
      "Epoch [1634/2500], Train Loss: 0.8348, Train Accuracy: 62.45%, Test Loss: 0.8918, Test Accuracy: 67.09%\n",
      "Epoch [1635/2500], Train Loss: 0.8412, Train Accuracy: 63.30%, Test Loss: 0.9177, Test Accuracy: 60.76%\n",
      "Epoch [1636/2500], Train Loss: 0.8287, Train Accuracy: 63.73%, Test Loss: 0.8693, Test Accuracy: 72.15%\n",
      "Epoch [1637/2500], Train Loss: 0.8368, Train Accuracy: 65.01%, Test Loss: 0.8812, Test Accuracy: 67.09%\n",
      "Epoch [1638/2500], Train Loss: 0.8274, Train Accuracy: 61.31%, Test Loss: 0.8824, Test Accuracy: 67.09%\n",
      "Epoch [1639/2500], Train Loss: 0.8451, Train Accuracy: 64.01%, Test Loss: 0.8986, Test Accuracy: 62.03%\n",
      "Epoch [1640/2500], Train Loss: 0.8213, Train Accuracy: 63.44%, Test Loss: 0.8928, Test Accuracy: 65.82%\n",
      "Epoch [1641/2500], Train Loss: 0.8083, Train Accuracy: 63.73%, Test Loss: 0.8965, Test Accuracy: 65.82%\n",
      "Epoch [1642/2500], Train Loss: 0.8295, Train Accuracy: 63.87%, Test Loss: 0.8811, Test Accuracy: 69.62%\n",
      "Epoch [1643/2500], Train Loss: 0.8349, Train Accuracy: 63.44%, Test Loss: 0.8887, Test Accuracy: 64.56%\n",
      "Epoch [1644/2500], Train Loss: 0.8084, Train Accuracy: 64.86%, Test Loss: 0.8829, Test Accuracy: 67.09%\n",
      "Epoch [1645/2500], Train Loss: 0.8439, Train Accuracy: 60.46%, Test Loss: 0.8808, Test Accuracy: 67.09%\n",
      "Epoch [1646/2500], Train Loss: 0.8267, Train Accuracy: 65.43%, Test Loss: 0.8737, Test Accuracy: 70.89%\n",
      "Epoch [1647/2500], Train Loss: 0.8642, Train Accuracy: 60.74%, Test Loss: 0.8716, Test Accuracy: 72.15%\n",
      "Epoch [1648/2500], Train Loss: 0.8165, Train Accuracy: 63.73%, Test Loss: 0.8972, Test Accuracy: 64.56%\n",
      "Epoch [1649/2500], Train Loss: 0.8535, Train Accuracy: 62.30%, Test Loss: 0.8954, Test Accuracy: 64.56%\n",
      "Epoch [1650/2500], Train Loss: 0.8305, Train Accuracy: 63.58%, Test Loss: 0.8810, Test Accuracy: 68.35%\n",
      "Epoch [1651/2500], Train Loss: 0.8247, Train Accuracy: 63.30%, Test Loss: 0.8757, Test Accuracy: 67.09%\n",
      "Epoch [1652/2500], Train Loss: 0.8529, Train Accuracy: 62.30%, Test Loss: 0.8789, Test Accuracy: 68.35%\n",
      "Epoch [1653/2500], Train Loss: 0.8402, Train Accuracy: 63.02%, Test Loss: 0.8710, Test Accuracy: 65.82%\n",
      "Epoch [1654/2500], Train Loss: 0.8173, Train Accuracy: 63.44%, Test Loss: 0.8699, Test Accuracy: 68.35%\n",
      "Epoch [1655/2500], Train Loss: 0.8257, Train Accuracy: 63.30%, Test Loss: 0.8762, Test Accuracy: 69.62%\n",
      "Epoch [1656/2500], Train Loss: 0.8091, Train Accuracy: 64.15%, Test Loss: 0.8710, Test Accuracy: 68.35%\n",
      "Epoch [1657/2500], Train Loss: 0.8194, Train Accuracy: 62.87%, Test Loss: 0.8686, Test Accuracy: 69.62%\n",
      "Epoch [1658/2500], Train Loss: 0.8617, Train Accuracy: 61.74%, Test Loss: 0.8752, Test Accuracy: 69.62%\n",
      "Epoch [1659/2500], Train Loss: 0.8284, Train Accuracy: 62.87%, Test Loss: 0.8676, Test Accuracy: 69.62%\n",
      "Epoch [1660/2500], Train Loss: 0.8200, Train Accuracy: 60.60%, Test Loss: 0.8908, Test Accuracy: 63.29%\n",
      "Epoch [1661/2500], Train Loss: 0.8219, Train Accuracy: 63.16%, Test Loss: 0.8825, Test Accuracy: 67.09%\n",
      "Epoch [1662/2500], Train Loss: 0.8490, Train Accuracy: 61.31%, Test Loss: 0.9025, Test Accuracy: 64.56%\n",
      "Epoch [1663/2500], Train Loss: 0.8260, Train Accuracy: 63.30%, Test Loss: 0.8762, Test Accuracy: 69.62%\n",
      "Epoch [1664/2500], Train Loss: 0.8280, Train Accuracy: 64.30%, Test Loss: 0.8825, Test Accuracy: 67.09%\n",
      "Epoch [1665/2500], Train Loss: 0.8426, Train Accuracy: 64.15%, Test Loss: 0.8707, Test Accuracy: 68.35%\n",
      "Epoch [1666/2500], Train Loss: 0.8508, Train Accuracy: 62.02%, Test Loss: 0.8751, Test Accuracy: 65.82%\n",
      "Epoch [1667/2500], Train Loss: 0.8060, Train Accuracy: 64.58%, Test Loss: 0.8783, Test Accuracy: 68.35%\n",
      "Epoch [1668/2500], Train Loss: 0.8265, Train Accuracy: 63.16%, Test Loss: 0.8935, Test Accuracy: 63.29%\n",
      "Epoch [1669/2500], Train Loss: 0.8269, Train Accuracy: 64.30%, Test Loss: 0.8976, Test Accuracy: 63.29%\n",
      "Epoch [1670/2500], Train Loss: 0.8279, Train Accuracy: 63.58%, Test Loss: 0.8901, Test Accuracy: 64.56%\n",
      "Epoch [1671/2500], Train Loss: 0.8086, Train Accuracy: 65.86%, Test Loss: 0.8966, Test Accuracy: 63.29%\n",
      "Epoch [1672/2500], Train Loss: 0.8507, Train Accuracy: 61.74%, Test Loss: 0.9046, Test Accuracy: 64.56%\n",
      "Epoch [1673/2500], Train Loss: 0.8366, Train Accuracy: 62.87%, Test Loss: 0.8956, Test Accuracy: 63.29%\n",
      "Epoch [1674/2500], Train Loss: 0.8431, Train Accuracy: 61.88%, Test Loss: 0.8662, Test Accuracy: 70.89%\n",
      "Epoch [1675/2500], Train Loss: 0.8307, Train Accuracy: 64.44%, Test Loss: 0.8930, Test Accuracy: 64.56%\n",
      "Epoch [1676/2500], Train Loss: 0.8345, Train Accuracy: 64.30%, Test Loss: 0.8770, Test Accuracy: 69.62%\n",
      "Epoch [1677/2500], Train Loss: 0.8089, Train Accuracy: 64.01%, Test Loss: 0.8720, Test Accuracy: 69.62%\n",
      "Epoch [1678/2500], Train Loss: 0.8179, Train Accuracy: 64.15%, Test Loss: 0.8982, Test Accuracy: 63.29%\n",
      "Epoch [1679/2500], Train Loss: 0.8154, Train Accuracy: 63.16%, Test Loss: 0.8728, Test Accuracy: 72.15%\n",
      "Epoch [1680/2500], Train Loss: 0.8159, Train Accuracy: 66.71%, Test Loss: 0.8781, Test Accuracy: 70.89%\n",
      "Epoch [1681/2500], Train Loss: 0.8272, Train Accuracy: 62.02%, Test Loss: 0.8898, Test Accuracy: 67.09%\n",
      "Epoch [1682/2500], Train Loss: 0.8461, Train Accuracy: 64.15%, Test Loss: 0.8888, Test Accuracy: 64.56%\n",
      "Epoch [1683/2500], Train Loss: 0.8340, Train Accuracy: 63.30%, Test Loss: 0.8714, Test Accuracy: 70.89%\n",
      "Epoch [1684/2500], Train Loss: 0.8220, Train Accuracy: 63.30%, Test Loss: 0.8841, Test Accuracy: 65.82%\n",
      "Epoch [1685/2500], Train Loss: 0.8055, Train Accuracy: 66.00%, Test Loss: 0.8805, Test Accuracy: 68.35%\n",
      "Epoch [1686/2500], Train Loss: 0.8227, Train Accuracy: 63.16%, Test Loss: 0.9046, Test Accuracy: 62.03%\n",
      "Epoch [1687/2500], Train Loss: 0.8560, Train Accuracy: 61.45%, Test Loss: 0.9370, Test Accuracy: 62.03%\n",
      "Epoch [1688/2500], Train Loss: 0.8391, Train Accuracy: 63.58%, Test Loss: 0.8805, Test Accuracy: 67.09%\n",
      "Epoch [1689/2500], Train Loss: 0.8279, Train Accuracy: 63.44%, Test Loss: 0.8830, Test Accuracy: 63.29%\n",
      "Epoch [1690/2500], Train Loss: 0.8319, Train Accuracy: 63.58%, Test Loss: 0.8836, Test Accuracy: 64.56%\n",
      "Epoch [1691/2500], Train Loss: 0.8264, Train Accuracy: 63.73%, Test Loss: 0.9337, Test Accuracy: 62.03%\n",
      "Epoch [1692/2500], Train Loss: 0.8100, Train Accuracy: 65.58%, Test Loss: 0.8835, Test Accuracy: 63.29%\n",
      "Epoch [1693/2500], Train Loss: 0.8494, Train Accuracy: 61.31%, Test Loss: 0.8710, Test Accuracy: 64.56%\n",
      "Epoch [1694/2500], Train Loss: 0.7973, Train Accuracy: 64.86%, Test Loss: 0.9175, Test Accuracy: 63.29%\n",
      "Epoch [1695/2500], Train Loss: 0.8338, Train Accuracy: 63.87%, Test Loss: 0.8820, Test Accuracy: 63.29%\n",
      "Epoch [1696/2500], Train Loss: 0.8368, Train Accuracy: 64.30%, Test Loss: 0.8878, Test Accuracy: 64.56%\n",
      "Epoch [1697/2500], Train Loss: 0.8263, Train Accuracy: 63.73%, Test Loss: 0.8622, Test Accuracy: 70.89%\n",
      "Epoch [1698/2500], Train Loss: 0.8368, Train Accuracy: 62.73%, Test Loss: 0.9053, Test Accuracy: 62.03%\n",
      "Epoch [1699/2500], Train Loss: 0.8082, Train Accuracy: 64.30%, Test Loss: 0.8862, Test Accuracy: 62.03%\n",
      "Epoch [1700/2500], Train Loss: 0.8260, Train Accuracy: 64.72%, Test Loss: 0.8870, Test Accuracy: 62.03%\n",
      "Epoch [1701/2500], Train Loss: 0.8393, Train Accuracy: 62.87%, Test Loss: 0.9018, Test Accuracy: 63.29%\n",
      "Epoch [1702/2500], Train Loss: 0.8246, Train Accuracy: 63.30%, Test Loss: 0.8699, Test Accuracy: 67.09%\n",
      "Epoch [1703/2500], Train Loss: 0.8074, Train Accuracy: 63.73%, Test Loss: 0.8767, Test Accuracy: 65.82%\n",
      "Epoch [1704/2500], Train Loss: 0.8178, Train Accuracy: 63.44%, Test Loss: 0.8800, Test Accuracy: 63.29%\n",
      "Epoch [1705/2500], Train Loss: 0.8450, Train Accuracy: 62.87%, Test Loss: 0.8841, Test Accuracy: 62.03%\n",
      "Epoch [1706/2500], Train Loss: 0.8188, Train Accuracy: 65.29%, Test Loss: 0.8710, Test Accuracy: 67.09%\n",
      "Epoch [1707/2500], Train Loss: 0.8240, Train Accuracy: 62.73%, Test Loss: 0.8697, Test Accuracy: 67.09%\n",
      "Epoch [1708/2500], Train Loss: 0.8348, Train Accuracy: 64.15%, Test Loss: 0.8627, Test Accuracy: 70.89%\n",
      "Epoch [1709/2500], Train Loss: 0.8165, Train Accuracy: 62.73%, Test Loss: 0.8648, Test Accuracy: 69.62%\n",
      "Epoch [1710/2500], Train Loss: 0.8246, Train Accuracy: 63.02%, Test Loss: 0.8657, Test Accuracy: 69.62%\n",
      "Epoch [1711/2500], Train Loss: 0.8331, Train Accuracy: 62.02%, Test Loss: 0.8738, Test Accuracy: 64.56%\n",
      "Epoch [1712/2500], Train Loss: 0.8160, Train Accuracy: 64.01%, Test Loss: 0.8632, Test Accuracy: 70.89%\n",
      "Epoch [1713/2500], Train Loss: 0.8419, Train Accuracy: 64.01%, Test Loss: 0.8941, Test Accuracy: 62.03%\n",
      "Epoch [1714/2500], Train Loss: 0.8052, Train Accuracy: 63.73%, Test Loss: 0.8650, Test Accuracy: 70.89%\n",
      "Epoch [1715/2500], Train Loss: 0.8377, Train Accuracy: 63.73%, Test Loss: 0.8544, Test Accuracy: 69.62%\n",
      "Epoch [1716/2500], Train Loss: 0.8132, Train Accuracy: 64.01%, Test Loss: 0.8694, Test Accuracy: 64.56%\n",
      "Epoch [1717/2500], Train Loss: 0.8340, Train Accuracy: 61.17%, Test Loss: 0.8544, Test Accuracy: 69.62%\n",
      "Epoch [1718/2500], Train Loss: 0.8139, Train Accuracy: 63.73%, Test Loss: 0.8784, Test Accuracy: 63.29%\n",
      "Epoch [1719/2500], Train Loss: 0.8309, Train Accuracy: 63.16%, Test Loss: 0.8654, Test Accuracy: 68.35%\n",
      "Epoch [1720/2500], Train Loss: 0.8115, Train Accuracy: 64.44%, Test Loss: 0.8818, Test Accuracy: 64.56%\n",
      "Epoch [1721/2500], Train Loss: 0.8199, Train Accuracy: 63.44%, Test Loss: 0.8605, Test Accuracy: 70.89%\n",
      "Epoch [1722/2500], Train Loss: 0.8289, Train Accuracy: 63.73%, Test Loss: 0.8622, Test Accuracy: 68.35%\n",
      "Epoch [1723/2500], Train Loss: 0.8197, Train Accuracy: 65.43%, Test Loss: 0.8684, Test Accuracy: 64.56%\n",
      "Epoch [1724/2500], Train Loss: 0.8105, Train Accuracy: 64.01%, Test Loss: 0.8619, Test Accuracy: 65.82%\n",
      "Epoch [1725/2500], Train Loss: 0.8181, Train Accuracy: 63.02%, Test Loss: 0.8951, Test Accuracy: 62.03%\n",
      "Epoch [1726/2500], Train Loss: 0.8219, Train Accuracy: 65.29%, Test Loss: 0.8699, Test Accuracy: 68.35%\n",
      "Epoch [1727/2500], Train Loss: 0.8280, Train Accuracy: 64.01%, Test Loss: 0.8699, Test Accuracy: 67.09%\n",
      "Epoch [1728/2500], Train Loss: 0.8226, Train Accuracy: 63.58%, Test Loss: 0.8677, Test Accuracy: 69.62%\n",
      "Epoch [1729/2500], Train Loss: 0.8336, Train Accuracy: 66.00%, Test Loss: 0.8669, Test Accuracy: 69.62%\n",
      "Epoch [1730/2500], Train Loss: 0.8371, Train Accuracy: 63.87%, Test Loss: 0.8898, Test Accuracy: 62.03%\n",
      "Epoch [1731/2500], Train Loss: 0.8126, Train Accuracy: 65.72%, Test Loss: 0.8686, Test Accuracy: 65.82%\n",
      "Epoch [1732/2500], Train Loss: 0.8018, Train Accuracy: 66.15%, Test Loss: 0.8637, Test Accuracy: 69.62%\n",
      "Epoch [1733/2500], Train Loss: 0.7983, Train Accuracy: 65.15%, Test Loss: 0.8663, Test Accuracy: 68.35%\n",
      "Epoch [1734/2500], Train Loss: 0.8314, Train Accuracy: 63.73%, Test Loss: 0.8721, Test Accuracy: 68.35%\n",
      "Epoch [1735/2500], Train Loss: 0.8266, Train Accuracy: 64.72%, Test Loss: 0.8905, Test Accuracy: 63.29%\n",
      "Epoch [1736/2500], Train Loss: 0.8184, Train Accuracy: 63.58%, Test Loss: 0.8933, Test Accuracy: 63.29%\n",
      "Epoch [1737/2500], Train Loss: 0.8257, Train Accuracy: 62.87%, Test Loss: 0.8873, Test Accuracy: 65.82%\n",
      "Epoch [1738/2500], Train Loss: 0.8189, Train Accuracy: 63.02%, Test Loss: 0.9089, Test Accuracy: 62.03%\n",
      "Epoch [1739/2500], Train Loss: 0.8237, Train Accuracy: 63.87%, Test Loss: 0.8856, Test Accuracy: 60.76%\n",
      "Epoch [1740/2500], Train Loss: 0.8078, Train Accuracy: 66.57%, Test Loss: 0.8754, Test Accuracy: 65.82%\n",
      "Epoch [1741/2500], Train Loss: 0.8097, Train Accuracy: 65.15%, Test Loss: 0.9148, Test Accuracy: 63.29%\n",
      "Epoch [1742/2500], Train Loss: 0.7862, Train Accuracy: 63.58%, Test Loss: 0.9265, Test Accuracy: 63.29%\n",
      "Epoch [1743/2500], Train Loss: 0.8047, Train Accuracy: 65.15%, Test Loss: 0.9337, Test Accuracy: 63.29%\n",
      "Epoch [1744/2500], Train Loss: 0.7926, Train Accuracy: 65.29%, Test Loss: 0.8548, Test Accuracy: 70.89%\n",
      "Epoch [1745/2500], Train Loss: 0.8222, Train Accuracy: 63.87%, Test Loss: 0.8698, Test Accuracy: 69.62%\n",
      "Epoch [1746/2500], Train Loss: 0.7971, Train Accuracy: 66.00%, Test Loss: 0.8863, Test Accuracy: 65.82%\n",
      "Epoch [1747/2500], Train Loss: 0.8192, Train Accuracy: 65.15%, Test Loss: 0.8939, Test Accuracy: 64.56%\n",
      "Epoch [1748/2500], Train Loss: 0.8067, Train Accuracy: 64.44%, Test Loss: 0.9060, Test Accuracy: 62.03%\n",
      "Epoch [1749/2500], Train Loss: 0.8077, Train Accuracy: 65.29%, Test Loss: 0.9113, Test Accuracy: 62.03%\n",
      "Epoch [1750/2500], Train Loss: 0.8386, Train Accuracy: 62.45%, Test Loss: 0.9011, Test Accuracy: 63.29%\n",
      "Epoch [1751/2500], Train Loss: 0.8207, Train Accuracy: 64.72%, Test Loss: 0.8770, Test Accuracy: 69.62%\n",
      "Epoch [1752/2500], Train Loss: 0.8265, Train Accuracy: 64.30%, Test Loss: 0.9055, Test Accuracy: 62.03%\n",
      "Epoch [1753/2500], Train Loss: 0.8072, Train Accuracy: 63.02%, Test Loss: 0.8925, Test Accuracy: 63.29%\n",
      "Epoch [1754/2500], Train Loss: 0.8354, Train Accuracy: 64.44%, Test Loss: 0.9186, Test Accuracy: 62.03%\n",
      "Epoch [1755/2500], Train Loss: 0.8351, Train Accuracy: 63.58%, Test Loss: 0.8751, Test Accuracy: 69.62%\n",
      "Epoch [1756/2500], Train Loss: 0.8306, Train Accuracy: 64.15%, Test Loss: 0.8926, Test Accuracy: 63.29%\n",
      "Epoch [1757/2500], Train Loss: 0.8030, Train Accuracy: 64.44%, Test Loss: 0.8799, Test Accuracy: 67.09%\n",
      "Epoch [1758/2500], Train Loss: 0.7866, Train Accuracy: 66.29%, Test Loss: 0.8974, Test Accuracy: 62.03%\n",
      "Epoch [1759/2500], Train Loss: 0.8120, Train Accuracy: 65.43%, Test Loss: 0.8662, Test Accuracy: 64.56%\n",
      "Epoch [1760/2500], Train Loss: 0.8354, Train Accuracy: 63.87%, Test Loss: 0.9050, Test Accuracy: 62.03%\n",
      "Epoch [1761/2500], Train Loss: 0.8237, Train Accuracy: 66.00%, Test Loss: 0.8698, Test Accuracy: 64.56%\n",
      "Epoch [1762/2500], Train Loss: 0.7949, Train Accuracy: 65.43%, Test Loss: 0.8860, Test Accuracy: 63.29%\n",
      "Epoch [1763/2500], Train Loss: 0.8073, Train Accuracy: 62.16%, Test Loss: 0.8992, Test Accuracy: 62.03%\n",
      "Epoch [1764/2500], Train Loss: 0.8305, Train Accuracy: 63.58%, Test Loss: 0.8713, Test Accuracy: 65.82%\n",
      "Epoch [1765/2500], Train Loss: 0.8195, Train Accuracy: 64.86%, Test Loss: 0.8690, Test Accuracy: 68.35%\n",
      "Epoch [1766/2500], Train Loss: 0.8045, Train Accuracy: 66.57%, Test Loss: 0.8832, Test Accuracy: 62.03%\n",
      "Epoch [1767/2500], Train Loss: 0.7994, Train Accuracy: 64.58%, Test Loss: 0.8644, Test Accuracy: 69.62%\n",
      "Epoch [1768/2500], Train Loss: 0.8138, Train Accuracy: 65.86%, Test Loss: 0.8706, Test Accuracy: 65.82%\n",
      "Epoch [1769/2500], Train Loss: 0.8109, Train Accuracy: 65.72%, Test Loss: 0.8869, Test Accuracy: 65.82%\n",
      "Epoch [1770/2500], Train Loss: 0.8200, Train Accuracy: 62.73%, Test Loss: 0.8690, Test Accuracy: 65.82%\n",
      "Epoch [1771/2500], Train Loss: 0.8203, Train Accuracy: 63.30%, Test Loss: 0.8645, Test Accuracy: 67.09%\n",
      "Epoch [1772/2500], Train Loss: 0.8358, Train Accuracy: 65.29%, Test Loss: 0.8789, Test Accuracy: 64.56%\n",
      "Epoch [1773/2500], Train Loss: 0.8113, Train Accuracy: 64.15%, Test Loss: 0.8781, Test Accuracy: 65.82%\n",
      "Epoch [1774/2500], Train Loss: 0.8363, Train Accuracy: 64.01%, Test Loss: 0.8735, Test Accuracy: 64.56%\n",
      "Epoch [1775/2500], Train Loss: 0.7951, Train Accuracy: 65.43%, Test Loss: 0.8824, Test Accuracy: 63.29%\n",
      "Epoch [1776/2500], Train Loss: 0.8264, Train Accuracy: 62.45%, Test Loss: 0.8684, Test Accuracy: 65.82%\n",
      "Epoch [1777/2500], Train Loss: 0.8151, Train Accuracy: 63.58%, Test Loss: 0.8681, Test Accuracy: 68.35%\n",
      "Epoch [1778/2500], Train Loss: 0.8278, Train Accuracy: 63.87%, Test Loss: 0.8693, Test Accuracy: 67.09%\n",
      "Epoch [1779/2500], Train Loss: 0.7919, Train Accuracy: 67.00%, Test Loss: 0.8481, Test Accuracy: 68.35%\n",
      "Epoch [1780/2500], Train Loss: 0.8177, Train Accuracy: 63.16%, Test Loss: 0.8683, Test Accuracy: 65.82%\n",
      "Epoch [1781/2500], Train Loss: 0.8236, Train Accuracy: 63.58%, Test Loss: 0.8599, Test Accuracy: 65.82%\n",
      "Epoch [1782/2500], Train Loss: 0.8141, Train Accuracy: 62.87%, Test Loss: 0.8656, Test Accuracy: 67.09%\n",
      "Epoch [1783/2500], Train Loss: 0.8064, Train Accuracy: 64.01%, Test Loss: 0.8730, Test Accuracy: 65.82%\n",
      "Epoch [1784/2500], Train Loss: 0.8109, Train Accuracy: 64.44%, Test Loss: 0.8465, Test Accuracy: 69.62%\n",
      "Epoch [1785/2500], Train Loss: 0.8068, Train Accuracy: 66.15%, Test Loss: 0.8680, Test Accuracy: 67.09%\n",
      "Epoch [1786/2500], Train Loss: 0.8083, Train Accuracy: 64.01%, Test Loss: 0.9058, Test Accuracy: 62.03%\n",
      "Epoch [1787/2500], Train Loss: 0.7966, Train Accuracy: 66.71%, Test Loss: 0.8646, Test Accuracy: 69.62%\n",
      "Epoch [1788/2500], Train Loss: 0.8170, Train Accuracy: 62.73%, Test Loss: 0.9084, Test Accuracy: 62.03%\n",
      "Epoch [1789/2500], Train Loss: 0.8128, Train Accuracy: 63.58%, Test Loss: 0.8639, Test Accuracy: 68.35%\n",
      "Epoch [1790/2500], Train Loss: 0.7944, Train Accuracy: 65.86%, Test Loss: 0.8741, Test Accuracy: 65.82%\n",
      "Epoch [1791/2500], Train Loss: 0.8030, Train Accuracy: 65.58%, Test Loss: 0.8572, Test Accuracy: 69.62%\n",
      "Epoch [1792/2500], Train Loss: 0.8021, Train Accuracy: 64.15%, Test Loss: 0.8601, Test Accuracy: 67.09%\n",
      "Epoch [1793/2500], Train Loss: 0.8092, Train Accuracy: 63.73%, Test Loss: 0.8639, Test Accuracy: 65.82%\n",
      "Epoch [1794/2500], Train Loss: 0.7863, Train Accuracy: 65.43%, Test Loss: 0.8663, Test Accuracy: 67.09%\n",
      "Epoch [1795/2500], Train Loss: 0.8218, Train Accuracy: 64.01%, Test Loss: 0.8532, Test Accuracy: 72.15%\n",
      "Epoch [1796/2500], Train Loss: 0.8180, Train Accuracy: 63.87%, Test Loss: 0.8757, Test Accuracy: 65.82%\n",
      "Epoch [1797/2500], Train Loss: 0.7818, Train Accuracy: 65.58%, Test Loss: 0.8514, Test Accuracy: 67.09%\n",
      "Epoch [1798/2500], Train Loss: 0.7976, Train Accuracy: 66.00%, Test Loss: 0.8519, Test Accuracy: 67.09%\n",
      "Epoch [1799/2500], Train Loss: 0.8015, Train Accuracy: 63.30%, Test Loss: 0.8693, Test Accuracy: 67.09%\n",
      "Epoch [1800/2500], Train Loss: 0.8007, Train Accuracy: 64.58%, Test Loss: 0.8408, Test Accuracy: 69.62%\n",
      "Epoch [1801/2500], Train Loss: 0.8099, Train Accuracy: 63.30%, Test Loss: 0.8486, Test Accuracy: 68.35%\n",
      "Epoch [1802/2500], Train Loss: 0.7856, Train Accuracy: 66.00%, Test Loss: 0.8765, Test Accuracy: 63.29%\n",
      "Epoch [1803/2500], Train Loss: 0.7969, Train Accuracy: 64.86%, Test Loss: 0.8775, Test Accuracy: 64.56%\n",
      "Epoch [1804/2500], Train Loss: 0.8121, Train Accuracy: 64.30%, Test Loss: 0.8585, Test Accuracy: 65.82%\n",
      "Epoch [1805/2500], Train Loss: 0.8056, Train Accuracy: 65.58%, Test Loss: 0.8489, Test Accuracy: 67.09%\n",
      "Epoch [1806/2500], Train Loss: 0.7712, Train Accuracy: 66.29%, Test Loss: 0.8690, Test Accuracy: 67.09%\n",
      "Epoch [1807/2500], Train Loss: 0.8148, Train Accuracy: 63.73%, Test Loss: 0.8791, Test Accuracy: 65.82%\n",
      "Epoch [1808/2500], Train Loss: 0.7841, Train Accuracy: 65.72%, Test Loss: 0.8582, Test Accuracy: 67.09%\n",
      "Epoch [1809/2500], Train Loss: 0.7694, Train Accuracy: 67.85%, Test Loss: 0.8828, Test Accuracy: 67.09%\n",
      "Epoch [1810/2500], Train Loss: 0.8015, Train Accuracy: 66.00%, Test Loss: 0.8758, Test Accuracy: 63.29%\n",
      "Epoch [1811/2500], Train Loss: 0.7976, Train Accuracy: 66.29%, Test Loss: 0.8741, Test Accuracy: 65.82%\n",
      "Epoch [1812/2500], Train Loss: 0.7968, Train Accuracy: 62.73%, Test Loss: 0.8748, Test Accuracy: 64.56%\n",
      "Epoch [1813/2500], Train Loss: 0.7958, Train Accuracy: 65.72%, Test Loss: 0.8809, Test Accuracy: 64.56%\n",
      "Epoch [1814/2500], Train Loss: 0.7780, Train Accuracy: 65.58%, Test Loss: 0.8667, Test Accuracy: 67.09%\n",
      "Epoch [1815/2500], Train Loss: 0.8263, Train Accuracy: 64.15%, Test Loss: 0.8639, Test Accuracy: 65.82%\n",
      "Epoch [1816/2500], Train Loss: 0.8054, Train Accuracy: 64.15%, Test Loss: 0.8416, Test Accuracy: 70.89%\n",
      "Epoch [1817/2500], Train Loss: 0.8148, Train Accuracy: 63.02%, Test Loss: 0.8636, Test Accuracy: 67.09%\n",
      "Epoch [1818/2500], Train Loss: 0.7954, Train Accuracy: 64.72%, Test Loss: 0.8592, Test Accuracy: 65.82%\n",
      "Epoch [1819/2500], Train Loss: 0.7717, Train Accuracy: 65.15%, Test Loss: 0.8536, Test Accuracy: 68.35%\n",
      "Epoch [1820/2500], Train Loss: 0.7991, Train Accuracy: 64.30%, Test Loss: 0.8508, Test Accuracy: 68.35%\n",
      "Epoch [1821/2500], Train Loss: 0.7889, Train Accuracy: 66.00%, Test Loss: 0.9005, Test Accuracy: 64.56%\n",
      "Epoch [1822/2500], Train Loss: 0.8169, Train Accuracy: 65.29%, Test Loss: 0.8527, Test Accuracy: 67.09%\n",
      "Epoch [1823/2500], Train Loss: 0.8179, Train Accuracy: 65.58%, Test Loss: 0.8883, Test Accuracy: 65.82%\n",
      "Epoch [1824/2500], Train Loss: 0.7905, Train Accuracy: 64.72%, Test Loss: 0.8437, Test Accuracy: 68.35%\n",
      "Epoch [1825/2500], Train Loss: 0.8052, Train Accuracy: 63.73%, Test Loss: 0.8876, Test Accuracy: 64.56%\n",
      "Epoch [1826/2500], Train Loss: 0.8174, Train Accuracy: 62.59%, Test Loss: 0.8558, Test Accuracy: 68.35%\n",
      "Epoch [1827/2500], Train Loss: 0.7914, Train Accuracy: 63.02%, Test Loss: 0.8729, Test Accuracy: 65.82%\n",
      "Epoch [1828/2500], Train Loss: 0.8078, Train Accuracy: 65.86%, Test Loss: 0.8640, Test Accuracy: 65.82%\n",
      "Epoch [1829/2500], Train Loss: 0.7928, Train Accuracy: 65.58%, Test Loss: 0.8934, Test Accuracy: 64.56%\n",
      "Epoch [1830/2500], Train Loss: 0.7993, Train Accuracy: 65.43%, Test Loss: 0.8468, Test Accuracy: 69.62%\n",
      "Epoch [1831/2500], Train Loss: 0.8023, Train Accuracy: 65.86%, Test Loss: 0.8946, Test Accuracy: 64.56%\n",
      "Epoch [1832/2500], Train Loss: 0.7834, Train Accuracy: 64.86%, Test Loss: 0.9154, Test Accuracy: 63.29%\n",
      "Epoch [1833/2500], Train Loss: 0.8101, Train Accuracy: 64.86%, Test Loss: 0.8955, Test Accuracy: 64.56%\n",
      "Epoch [1834/2500], Train Loss: 0.7953, Train Accuracy: 64.30%, Test Loss: 0.8807, Test Accuracy: 64.56%\n",
      "Epoch [1835/2500], Train Loss: 0.7922, Train Accuracy: 65.29%, Test Loss: 0.8940, Test Accuracy: 64.56%\n",
      "Epoch [1836/2500], Train Loss: 0.7959, Train Accuracy: 66.15%, Test Loss: 0.8733, Test Accuracy: 64.56%\n",
      "Epoch [1837/2500], Train Loss: 0.7835, Train Accuracy: 65.58%, Test Loss: 0.8889, Test Accuracy: 64.56%\n",
      "Epoch [1838/2500], Train Loss: 0.7957, Train Accuracy: 64.72%, Test Loss: 0.8573, Test Accuracy: 65.82%\n",
      "Epoch [1839/2500], Train Loss: 0.8044, Train Accuracy: 65.58%, Test Loss: 0.8629, Test Accuracy: 64.56%\n",
      "Epoch [1840/2500], Train Loss: 0.7755, Train Accuracy: 63.73%, Test Loss: 0.8692, Test Accuracy: 64.56%\n",
      "Epoch [1841/2500], Train Loss: 0.8132, Train Accuracy: 63.30%, Test Loss: 0.8487, Test Accuracy: 65.82%\n",
      "Epoch [1842/2500], Train Loss: 0.7969, Train Accuracy: 65.01%, Test Loss: 0.8684, Test Accuracy: 65.82%\n",
      "Epoch [1843/2500], Train Loss: 0.8069, Train Accuracy: 62.30%, Test Loss: 0.8704, Test Accuracy: 65.82%\n",
      "Epoch [1844/2500], Train Loss: 0.7974, Train Accuracy: 65.29%, Test Loss: 0.8573, Test Accuracy: 68.35%\n",
      "Epoch [1845/2500], Train Loss: 0.7913, Train Accuracy: 64.86%, Test Loss: 0.8721, Test Accuracy: 65.82%\n",
      "Epoch [1846/2500], Train Loss: 0.7912, Train Accuracy: 63.73%, Test Loss: 0.8507, Test Accuracy: 69.62%\n",
      "Epoch [1847/2500], Train Loss: 0.7754, Train Accuracy: 64.86%, Test Loss: 0.8788, Test Accuracy: 67.09%\n",
      "Epoch [1848/2500], Train Loss: 0.7705, Train Accuracy: 68.28%, Test Loss: 0.8810, Test Accuracy: 64.56%\n",
      "Epoch [1849/2500], Train Loss: 0.7848, Train Accuracy: 65.15%, Test Loss: 0.8781, Test Accuracy: 68.35%\n",
      "Epoch [1850/2500], Train Loss: 0.8009, Train Accuracy: 65.58%, Test Loss: 0.8911, Test Accuracy: 65.82%\n",
      "Epoch [1851/2500], Train Loss: 0.7972, Train Accuracy: 63.58%, Test Loss: 0.8845, Test Accuracy: 65.82%\n",
      "Epoch [1852/2500], Train Loss: 0.8082, Train Accuracy: 64.44%, Test Loss: 0.8972, Test Accuracy: 63.29%\n",
      "Epoch [1853/2500], Train Loss: 0.7807, Train Accuracy: 65.43%, Test Loss: 0.8400, Test Accuracy: 70.89%\n",
      "Epoch [1854/2500], Train Loss: 0.7900, Train Accuracy: 63.87%, Test Loss: 0.8656, Test Accuracy: 68.35%\n",
      "Epoch [1855/2500], Train Loss: 0.8052, Train Accuracy: 64.72%, Test Loss: 0.8539, Test Accuracy: 68.35%\n",
      "Epoch [1856/2500], Train Loss: 0.8263, Train Accuracy: 63.16%, Test Loss: 0.8656, Test Accuracy: 65.82%\n",
      "Epoch [1857/2500], Train Loss: 0.7884, Train Accuracy: 65.01%, Test Loss: 0.8717, Test Accuracy: 67.09%\n",
      "Epoch [1858/2500], Train Loss: 0.7982, Train Accuracy: 64.72%, Test Loss: 0.8876, Test Accuracy: 64.56%\n",
      "Epoch [1859/2500], Train Loss: 0.7571, Train Accuracy: 65.86%, Test Loss: 0.8886, Test Accuracy: 64.56%\n",
      "Epoch [1860/2500], Train Loss: 0.7882, Train Accuracy: 64.72%, Test Loss: 0.9118, Test Accuracy: 64.56%\n",
      "Epoch [1861/2500], Train Loss: 0.7903, Train Accuracy: 66.86%, Test Loss: 0.8638, Test Accuracy: 67.09%\n",
      "Epoch [1862/2500], Train Loss: 0.7861, Train Accuracy: 65.29%, Test Loss: 0.8711, Test Accuracy: 68.35%\n",
      "Epoch [1863/2500], Train Loss: 0.7988, Train Accuracy: 65.29%, Test Loss: 0.8775, Test Accuracy: 65.82%\n",
      "Epoch [1864/2500], Train Loss: 0.7889, Train Accuracy: 64.44%, Test Loss: 0.8724, Test Accuracy: 68.35%\n",
      "Epoch [1865/2500], Train Loss: 0.7746, Train Accuracy: 66.15%, Test Loss: 0.9101, Test Accuracy: 63.29%\n",
      "Epoch [1866/2500], Train Loss: 0.8008, Train Accuracy: 66.29%, Test Loss: 0.8787, Test Accuracy: 65.82%\n",
      "Epoch [1867/2500], Train Loss: 0.8126, Train Accuracy: 63.44%, Test Loss: 0.8884, Test Accuracy: 65.82%\n",
      "Epoch [1868/2500], Train Loss: 0.7900, Train Accuracy: 63.02%, Test Loss: 0.8637, Test Accuracy: 67.09%\n",
      "Epoch [1869/2500], Train Loss: 0.8014, Train Accuracy: 64.01%, Test Loss: 0.8775, Test Accuracy: 64.56%\n",
      "Epoch [1870/2500], Train Loss: 0.7827, Train Accuracy: 63.58%, Test Loss: 0.8615, Test Accuracy: 68.35%\n",
      "Epoch [1871/2500], Train Loss: 0.7909, Train Accuracy: 63.87%, Test Loss: 0.8924, Test Accuracy: 64.56%\n",
      "Epoch [1872/2500], Train Loss: 0.8051, Train Accuracy: 64.72%, Test Loss: 0.8758, Test Accuracy: 68.35%\n",
      "Epoch [1873/2500], Train Loss: 0.7920, Train Accuracy: 65.29%, Test Loss: 0.8652, Test Accuracy: 67.09%\n",
      "Epoch [1874/2500], Train Loss: 0.7799, Train Accuracy: 65.29%, Test Loss: 0.9117, Test Accuracy: 64.56%\n",
      "Epoch [1875/2500], Train Loss: 0.7720, Train Accuracy: 66.00%, Test Loss: 0.8630, Test Accuracy: 68.35%\n",
      "Epoch [1876/2500], Train Loss: 0.7865, Train Accuracy: 64.72%, Test Loss: 0.8805, Test Accuracy: 65.82%\n",
      "Epoch [1877/2500], Train Loss: 0.7832, Train Accuracy: 66.29%, Test Loss: 0.8586, Test Accuracy: 68.35%\n",
      "Epoch [1878/2500], Train Loss: 0.7827, Train Accuracy: 65.58%, Test Loss: 0.8681, Test Accuracy: 68.35%\n",
      "Epoch [1879/2500], Train Loss: 0.7921, Train Accuracy: 64.86%, Test Loss: 0.8982, Test Accuracy: 64.56%\n",
      "Epoch [1880/2500], Train Loss: 0.7756, Train Accuracy: 64.30%, Test Loss: 0.9086, Test Accuracy: 63.29%\n",
      "Epoch [1881/2500], Train Loss: 0.7723, Train Accuracy: 67.43%, Test Loss: 0.8443, Test Accuracy: 69.62%\n",
      "Epoch [1882/2500], Train Loss: 0.7914, Train Accuracy: 62.73%, Test Loss: 0.9441, Test Accuracy: 64.56%\n",
      "Epoch [1883/2500], Train Loss: 0.7808, Train Accuracy: 66.43%, Test Loss: 0.8900, Test Accuracy: 64.56%\n",
      "Epoch [1884/2500], Train Loss: 0.8082, Train Accuracy: 63.87%, Test Loss: 0.8691, Test Accuracy: 67.09%\n",
      "Epoch [1885/2500], Train Loss: 0.7845, Train Accuracy: 64.72%, Test Loss: 0.8761, Test Accuracy: 65.82%\n",
      "Epoch [1886/2500], Train Loss: 0.7759, Train Accuracy: 66.57%, Test Loss: 0.8558, Test Accuracy: 68.35%\n",
      "Epoch [1887/2500], Train Loss: 0.7862, Train Accuracy: 66.43%, Test Loss: 0.8500, Test Accuracy: 69.62%\n",
      "Epoch [1888/2500], Train Loss: 0.7841, Train Accuracy: 65.86%, Test Loss: 0.9068, Test Accuracy: 64.56%\n",
      "Epoch [1889/2500], Train Loss: 0.7825, Train Accuracy: 65.43%, Test Loss: 0.8464, Test Accuracy: 68.35%\n",
      "Epoch [1890/2500], Train Loss: 0.7950, Train Accuracy: 65.58%, Test Loss: 0.8841, Test Accuracy: 65.82%\n",
      "Epoch [1891/2500], Train Loss: 0.7725, Train Accuracy: 66.86%, Test Loss: 0.8790, Test Accuracy: 67.09%\n",
      "Epoch [1892/2500], Train Loss: 0.7872, Train Accuracy: 64.44%, Test Loss: 0.8579, Test Accuracy: 69.62%\n",
      "Epoch [1893/2500], Train Loss: 0.7823, Train Accuracy: 64.58%, Test Loss: 0.8862, Test Accuracy: 65.82%\n",
      "Epoch [1894/2500], Train Loss: 0.7931, Train Accuracy: 64.86%, Test Loss: 0.8613, Test Accuracy: 70.89%\n",
      "Epoch [1895/2500], Train Loss: 0.7968, Train Accuracy: 63.16%, Test Loss: 0.8906, Test Accuracy: 65.82%\n",
      "Epoch [1896/2500], Train Loss: 0.7809, Train Accuracy: 64.01%, Test Loss: 0.8848, Test Accuracy: 64.56%\n",
      "Epoch [1897/2500], Train Loss: 0.7976, Train Accuracy: 63.73%, Test Loss: 0.8863, Test Accuracy: 65.82%\n",
      "Epoch [1898/2500], Train Loss: 0.7635, Train Accuracy: 66.71%, Test Loss: 0.8871, Test Accuracy: 64.56%\n",
      "Epoch [1899/2500], Train Loss: 0.7862, Train Accuracy: 65.58%, Test Loss: 0.8602, Test Accuracy: 68.35%\n",
      "Epoch [1900/2500], Train Loss: 0.7818, Train Accuracy: 65.86%, Test Loss: 0.8673, Test Accuracy: 68.35%\n",
      "Epoch [1901/2500], Train Loss: 0.8076, Train Accuracy: 64.01%, Test Loss: 0.8761, Test Accuracy: 65.82%\n",
      "Epoch [1902/2500], Train Loss: 0.7748, Train Accuracy: 64.15%, Test Loss: 0.8751, Test Accuracy: 65.82%\n",
      "Epoch [1903/2500], Train Loss: 0.7892, Train Accuracy: 65.29%, Test Loss: 0.9068, Test Accuracy: 64.56%\n",
      "Epoch [1904/2500], Train Loss: 0.7894, Train Accuracy: 66.15%, Test Loss: 0.8476, Test Accuracy: 69.62%\n",
      "Epoch [1905/2500], Train Loss: 0.7729, Train Accuracy: 65.58%, Test Loss: 0.8570, Test Accuracy: 68.35%\n",
      "Epoch [1906/2500], Train Loss: 0.7670, Train Accuracy: 66.00%, Test Loss: 0.8586, Test Accuracy: 68.35%\n",
      "Epoch [1907/2500], Train Loss: 0.7744, Train Accuracy: 66.71%, Test Loss: 0.8838, Test Accuracy: 67.09%\n",
      "Epoch [1908/2500], Train Loss: 0.7938, Train Accuracy: 65.01%, Test Loss: 0.8558, Test Accuracy: 67.09%\n",
      "Epoch [1909/2500], Train Loss: 0.7913, Train Accuracy: 66.71%, Test Loss: 0.8712, Test Accuracy: 68.35%\n",
      "Epoch [1910/2500], Train Loss: 0.7835, Train Accuracy: 65.29%, Test Loss: 0.8621, Test Accuracy: 69.62%\n",
      "Epoch [1911/2500], Train Loss: 0.7917, Train Accuracy: 65.29%, Test Loss: 0.8990, Test Accuracy: 64.56%\n",
      "Epoch [1912/2500], Train Loss: 0.7672, Train Accuracy: 66.43%, Test Loss: 0.8479, Test Accuracy: 67.09%\n",
      "Epoch [1913/2500], Train Loss: 0.7793, Train Accuracy: 64.44%, Test Loss: 0.8661, Test Accuracy: 68.35%\n",
      "Epoch [1914/2500], Train Loss: 0.7958, Train Accuracy: 63.87%, Test Loss: 0.8744, Test Accuracy: 65.82%\n",
      "Epoch [1915/2500], Train Loss: 0.7574, Train Accuracy: 64.15%, Test Loss: 0.8939, Test Accuracy: 65.82%\n",
      "Epoch [1916/2500], Train Loss: 0.7678, Train Accuracy: 67.71%, Test Loss: 0.8635, Test Accuracy: 70.89%\n",
      "Epoch [1917/2500], Train Loss: 0.7662, Train Accuracy: 67.14%, Test Loss: 0.9004, Test Accuracy: 64.56%\n",
      "Epoch [1918/2500], Train Loss: 0.7830, Train Accuracy: 65.58%, Test Loss: 0.8626, Test Accuracy: 69.62%\n",
      "Epoch [1919/2500], Train Loss: 0.7674, Train Accuracy: 64.86%, Test Loss: 0.8795, Test Accuracy: 68.35%\n",
      "Epoch [1920/2500], Train Loss: 0.7780, Train Accuracy: 66.86%, Test Loss: 0.9062, Test Accuracy: 64.56%\n",
      "Epoch [1921/2500], Train Loss: 0.7626, Train Accuracy: 67.71%, Test Loss: 0.8644, Test Accuracy: 69.62%\n",
      "Epoch [1922/2500], Train Loss: 0.7629, Train Accuracy: 66.86%, Test Loss: 0.8788, Test Accuracy: 68.35%\n",
      "Epoch [1923/2500], Train Loss: 0.7726, Train Accuracy: 65.15%, Test Loss: 0.8594, Test Accuracy: 70.89%\n",
      "Epoch [1924/2500], Train Loss: 0.7535, Train Accuracy: 66.29%, Test Loss: 0.8969, Test Accuracy: 65.82%\n",
      "Epoch [1925/2500], Train Loss: 0.7785, Train Accuracy: 66.29%, Test Loss: 0.8978, Test Accuracy: 65.82%\n",
      "Epoch [1926/2500], Train Loss: 0.7558, Train Accuracy: 66.57%, Test Loss: 0.9339, Test Accuracy: 63.29%\n",
      "Epoch [1927/2500], Train Loss: 0.7857, Train Accuracy: 66.15%, Test Loss: 0.8753, Test Accuracy: 68.35%\n",
      "Epoch [1928/2500], Train Loss: 0.7756, Train Accuracy: 65.15%, Test Loss: 0.9516, Test Accuracy: 63.29%\n",
      "Epoch [1929/2500], Train Loss: 0.7727, Train Accuracy: 67.00%, Test Loss: 0.8863, Test Accuracy: 67.09%\n",
      "Epoch [1930/2500], Train Loss: 0.7807, Train Accuracy: 65.72%, Test Loss: 0.9274, Test Accuracy: 64.56%\n",
      "Epoch [1931/2500], Train Loss: 0.7738, Train Accuracy: 66.57%, Test Loss: 0.8801, Test Accuracy: 65.82%\n",
      "Epoch [1932/2500], Train Loss: 0.7752, Train Accuracy: 67.00%, Test Loss: 0.9078, Test Accuracy: 65.82%\n",
      "Epoch [1933/2500], Train Loss: 0.7687, Train Accuracy: 66.15%, Test Loss: 0.8499, Test Accuracy: 69.62%\n",
      "Epoch [1934/2500], Train Loss: 0.7978, Train Accuracy: 65.15%, Test Loss: 0.8533, Test Accuracy: 69.62%\n",
      "Epoch [1935/2500], Train Loss: 0.7798, Train Accuracy: 66.43%, Test Loss: 0.8847, Test Accuracy: 65.82%\n",
      "Epoch [1936/2500], Train Loss: 0.7701, Train Accuracy: 66.15%, Test Loss: 0.8552, Test Accuracy: 69.62%\n",
      "Epoch [1937/2500], Train Loss: 0.7379, Train Accuracy: 69.13%, Test Loss: 0.8695, Test Accuracy: 67.09%\n",
      "Epoch [1938/2500], Train Loss: 0.7912, Train Accuracy: 64.72%, Test Loss: 0.8827, Test Accuracy: 65.82%\n",
      "Epoch [1939/2500], Train Loss: 0.7692, Train Accuracy: 67.71%, Test Loss: 0.8976, Test Accuracy: 63.29%\n",
      "Epoch [1940/2500], Train Loss: 0.7852, Train Accuracy: 66.57%, Test Loss: 0.8757, Test Accuracy: 65.82%\n",
      "Epoch [1941/2500], Train Loss: 0.7656, Train Accuracy: 66.86%, Test Loss: 0.9345, Test Accuracy: 62.03%\n",
      "Epoch [1942/2500], Train Loss: 0.7795, Train Accuracy: 66.43%, Test Loss: 0.8843, Test Accuracy: 64.56%\n",
      "Epoch [1943/2500], Train Loss: 0.8009, Train Accuracy: 67.00%, Test Loss: 0.8696, Test Accuracy: 65.82%\n",
      "Epoch [1944/2500], Train Loss: 0.7721, Train Accuracy: 66.57%, Test Loss: 0.9053, Test Accuracy: 64.56%\n",
      "Epoch [1945/2500], Train Loss: 0.7758, Train Accuracy: 66.15%, Test Loss: 0.8497, Test Accuracy: 69.62%\n",
      "Epoch [1946/2500], Train Loss: 0.7794, Train Accuracy: 65.86%, Test Loss: 0.8987, Test Accuracy: 63.29%\n",
      "Epoch [1947/2500], Train Loss: 0.7518, Train Accuracy: 66.86%, Test Loss: 0.8995, Test Accuracy: 63.29%\n",
      "Epoch [1948/2500], Train Loss: 0.7697, Train Accuracy: 65.86%, Test Loss: 0.9040, Test Accuracy: 64.56%\n",
      "Epoch [1949/2500], Train Loss: 0.7913, Train Accuracy: 64.86%, Test Loss: 0.8865, Test Accuracy: 65.82%\n",
      "Epoch [1950/2500], Train Loss: 0.7927, Train Accuracy: 63.87%, Test Loss: 0.8513, Test Accuracy: 70.89%\n",
      "Epoch [1951/2500], Train Loss: 0.7808, Train Accuracy: 65.29%, Test Loss: 0.8777, Test Accuracy: 65.82%\n",
      "Epoch [1952/2500], Train Loss: 0.7650, Train Accuracy: 64.86%, Test Loss: 0.8612, Test Accuracy: 65.82%\n",
      "Epoch [1953/2500], Train Loss: 0.7685, Train Accuracy: 66.15%, Test Loss: 0.8590, Test Accuracy: 68.35%\n",
      "Epoch [1954/2500], Train Loss: 0.7567, Train Accuracy: 66.43%, Test Loss: 0.9033, Test Accuracy: 63.29%\n",
      "Epoch [1955/2500], Train Loss: 0.7833, Train Accuracy: 65.29%, Test Loss: 0.8935, Test Accuracy: 64.56%\n",
      "Epoch [1956/2500], Train Loss: 0.7770, Train Accuracy: 66.29%, Test Loss: 0.8705, Test Accuracy: 68.35%\n",
      "Epoch [1957/2500], Train Loss: 0.7985, Train Accuracy: 63.30%, Test Loss: 0.8499, Test Accuracy: 68.35%\n",
      "Epoch [1958/2500], Train Loss: 0.7662, Train Accuracy: 65.01%, Test Loss: 0.8453, Test Accuracy: 70.89%\n",
      "Epoch [1959/2500], Train Loss: 0.7714, Train Accuracy: 66.57%, Test Loss: 0.8553, Test Accuracy: 68.35%\n",
      "Epoch [1960/2500], Train Loss: 0.7870, Train Accuracy: 65.29%, Test Loss: 0.9033, Test Accuracy: 64.56%\n",
      "Epoch [1961/2500], Train Loss: 0.7485, Train Accuracy: 66.00%, Test Loss: 0.8658, Test Accuracy: 67.09%\n",
      "Epoch [1962/2500], Train Loss: 0.7868, Train Accuracy: 65.43%, Test Loss: 0.8786, Test Accuracy: 65.82%\n",
      "Epoch [1963/2500], Train Loss: 0.7780, Train Accuracy: 65.58%, Test Loss: 0.8573, Test Accuracy: 68.35%\n",
      "Epoch [1964/2500], Train Loss: 0.7855, Train Accuracy: 65.86%, Test Loss: 0.8704, Test Accuracy: 67.09%\n",
      "Epoch [1965/2500], Train Loss: 0.7856, Train Accuracy: 65.72%, Test Loss: 0.9037, Test Accuracy: 64.56%\n",
      "Epoch [1966/2500], Train Loss: 0.7562, Train Accuracy: 67.00%, Test Loss: 0.8900, Test Accuracy: 65.82%\n",
      "Epoch [1967/2500], Train Loss: 0.7967, Train Accuracy: 66.15%, Test Loss: 0.8633, Test Accuracy: 67.09%\n",
      "Epoch [1968/2500], Train Loss: 0.7598, Train Accuracy: 64.58%, Test Loss: 0.8722, Test Accuracy: 68.35%\n",
      "Epoch [1969/2500], Train Loss: 0.7724, Train Accuracy: 64.86%, Test Loss: 0.8849, Test Accuracy: 65.82%\n",
      "Epoch [1970/2500], Train Loss: 0.7732, Train Accuracy: 64.30%, Test Loss: 0.8916, Test Accuracy: 65.82%\n",
      "Epoch [1971/2500], Train Loss: 0.7619, Train Accuracy: 67.14%, Test Loss: 0.8690, Test Accuracy: 67.09%\n",
      "Epoch [1972/2500], Train Loss: 0.7575, Train Accuracy: 65.15%, Test Loss: 0.8678, Test Accuracy: 67.09%\n",
      "Epoch [1973/2500], Train Loss: 0.7488, Train Accuracy: 67.28%, Test Loss: 0.9018, Test Accuracy: 64.56%\n",
      "Epoch [1974/2500], Train Loss: 0.7625, Train Accuracy: 64.72%, Test Loss: 0.8622, Test Accuracy: 68.35%\n",
      "Epoch [1975/2500], Train Loss: 0.7624, Train Accuracy: 67.43%, Test Loss: 0.9247, Test Accuracy: 64.56%\n",
      "Epoch [1976/2500], Train Loss: 0.7931, Train Accuracy: 65.01%, Test Loss: 0.9033, Test Accuracy: 65.82%\n",
      "Epoch [1977/2500], Train Loss: 0.7758, Train Accuracy: 64.86%, Test Loss: 0.8851, Test Accuracy: 65.82%\n",
      "Epoch [1978/2500], Train Loss: 0.7403, Train Accuracy: 66.00%, Test Loss: 0.8906, Test Accuracy: 65.82%\n",
      "Epoch [1979/2500], Train Loss: 0.7939, Train Accuracy: 64.58%, Test Loss: 0.8709, Test Accuracy: 65.82%\n",
      "Epoch [1980/2500], Train Loss: 0.7823, Train Accuracy: 66.15%, Test Loss: 0.9398, Test Accuracy: 63.29%\n",
      "Epoch [1981/2500], Train Loss: 0.7538, Train Accuracy: 67.99%, Test Loss: 0.9110, Test Accuracy: 64.56%\n",
      "Epoch [1982/2500], Train Loss: 0.7860, Train Accuracy: 64.86%, Test Loss: 0.8952, Test Accuracy: 65.82%\n",
      "Epoch [1983/2500], Train Loss: 0.7769, Train Accuracy: 66.15%, Test Loss: 0.9126, Test Accuracy: 64.56%\n",
      "Epoch [1984/2500], Train Loss: 0.7768, Train Accuracy: 67.00%, Test Loss: 0.9301, Test Accuracy: 63.29%\n",
      "Epoch [1985/2500], Train Loss: 0.7790, Train Accuracy: 67.00%, Test Loss: 0.8753, Test Accuracy: 65.82%\n",
      "Epoch [1986/2500], Train Loss: 0.7718, Train Accuracy: 67.00%, Test Loss: 0.8953, Test Accuracy: 64.56%\n",
      "Epoch [1987/2500], Train Loss: 0.7637, Train Accuracy: 67.85%, Test Loss: 0.9092, Test Accuracy: 64.56%\n",
      "Epoch [1988/2500], Train Loss: 0.7556, Train Accuracy: 65.72%, Test Loss: 0.8887, Test Accuracy: 65.82%\n",
      "Epoch [1989/2500], Train Loss: 0.7650, Train Accuracy: 65.72%, Test Loss: 0.9297, Test Accuracy: 64.56%\n",
      "Epoch [1990/2500], Train Loss: 0.7879, Train Accuracy: 65.01%, Test Loss: 0.8813, Test Accuracy: 69.62%\n",
      "Epoch [1991/2500], Train Loss: 0.7799, Train Accuracy: 65.86%, Test Loss: 0.9013, Test Accuracy: 65.82%\n",
      "Epoch [1992/2500], Train Loss: 0.7671, Train Accuracy: 65.86%, Test Loss: 0.8644, Test Accuracy: 69.62%\n",
      "Epoch [1993/2500], Train Loss: 0.7793, Train Accuracy: 65.58%, Test Loss: 0.8874, Test Accuracy: 65.82%\n",
      "Epoch [1994/2500], Train Loss: 0.7572, Train Accuracy: 66.57%, Test Loss: 0.8613, Test Accuracy: 69.62%\n",
      "Epoch [1995/2500], Train Loss: 0.7941, Train Accuracy: 65.15%, Test Loss: 0.8979, Test Accuracy: 65.82%\n",
      "Epoch [1996/2500], Train Loss: 0.7619, Train Accuracy: 68.71%, Test Loss: 0.9015, Test Accuracy: 65.82%\n",
      "Epoch [1997/2500], Train Loss: 0.7531, Train Accuracy: 68.85%, Test Loss: 0.8952, Test Accuracy: 65.82%\n",
      "Epoch [1998/2500], Train Loss: 0.7585, Train Accuracy: 66.57%, Test Loss: 0.8731, Test Accuracy: 64.56%\n",
      "Epoch [1999/2500], Train Loss: 0.7484, Train Accuracy: 66.15%, Test Loss: 0.8812, Test Accuracy: 65.82%\n",
      "Epoch [2000/2500], Train Loss: 0.7639, Train Accuracy: 64.86%, Test Loss: 0.8852, Test Accuracy: 64.56%\n",
      "Epoch [2001/2500], Train Loss: 0.7611, Train Accuracy: 66.57%, Test Loss: 0.8755, Test Accuracy: 65.82%\n",
      "Epoch [2002/2500], Train Loss: 0.7607, Train Accuracy: 66.00%, Test Loss: 0.8842, Test Accuracy: 65.82%\n",
      "Epoch [2003/2500], Train Loss: 0.7643, Train Accuracy: 65.29%, Test Loss: 0.8745, Test Accuracy: 67.09%\n",
      "Epoch [2004/2500], Train Loss: 0.7834, Train Accuracy: 67.00%, Test Loss: 0.9003, Test Accuracy: 65.82%\n",
      "Epoch [2005/2500], Train Loss: 0.7808, Train Accuracy: 62.87%, Test Loss: 0.8892, Test Accuracy: 67.09%\n",
      "Epoch [2006/2500], Train Loss: 0.7629, Train Accuracy: 66.86%, Test Loss: 0.9258, Test Accuracy: 64.56%\n",
      "Epoch [2007/2500], Train Loss: 0.7819, Train Accuracy: 65.86%, Test Loss: 0.8486, Test Accuracy: 72.15%\n",
      "Epoch [2008/2500], Train Loss: 0.7459, Train Accuracy: 67.14%, Test Loss: 0.9000, Test Accuracy: 65.82%\n",
      "Epoch [2009/2500], Train Loss: 0.7759, Train Accuracy: 65.01%, Test Loss: 0.8910, Test Accuracy: 64.56%\n",
      "Epoch [2010/2500], Train Loss: 0.7848, Train Accuracy: 65.58%, Test Loss: 0.8766, Test Accuracy: 65.82%\n",
      "Epoch [2011/2500], Train Loss: 0.7628, Train Accuracy: 67.85%, Test Loss: 0.8958, Test Accuracy: 64.56%\n",
      "Epoch [2012/2500], Train Loss: 0.7698, Train Accuracy: 67.99%, Test Loss: 0.8818, Test Accuracy: 67.09%\n",
      "Epoch [2013/2500], Train Loss: 0.7654, Train Accuracy: 66.29%, Test Loss: 0.8739, Test Accuracy: 67.09%\n",
      "Epoch [2014/2500], Train Loss: 0.7854, Train Accuracy: 67.14%, Test Loss: 0.8788, Test Accuracy: 65.82%\n",
      "Epoch [2015/2500], Train Loss: 0.7666, Train Accuracy: 65.43%, Test Loss: 0.8853, Test Accuracy: 65.82%\n",
      "Epoch [2016/2500], Train Loss: 0.7900, Train Accuracy: 64.86%, Test Loss: 0.8842, Test Accuracy: 65.82%\n",
      "Epoch [2017/2500], Train Loss: 0.7534, Train Accuracy: 68.71%, Test Loss: 0.8950, Test Accuracy: 65.82%\n",
      "Epoch [2018/2500], Train Loss: 0.7720, Train Accuracy: 65.29%, Test Loss: 0.9425, Test Accuracy: 63.29%\n",
      "Epoch [2019/2500], Train Loss: 0.7632, Train Accuracy: 67.00%, Test Loss: 0.8837, Test Accuracy: 65.82%\n",
      "Epoch [2020/2500], Train Loss: 0.7797, Train Accuracy: 64.86%, Test Loss: 0.9177, Test Accuracy: 64.56%\n",
      "Epoch [2021/2500], Train Loss: 0.7597, Train Accuracy: 65.58%, Test Loss: 0.8611, Test Accuracy: 69.62%\n",
      "Epoch [2022/2500], Train Loss: 0.7394, Train Accuracy: 68.28%, Test Loss: 0.9170, Test Accuracy: 64.56%\n",
      "Epoch [2023/2500], Train Loss: 0.7725, Train Accuracy: 66.86%, Test Loss: 0.9039, Test Accuracy: 64.56%\n",
      "Epoch [2024/2500], Train Loss: 0.7450, Train Accuracy: 67.99%, Test Loss: 0.8834, Test Accuracy: 67.09%\n",
      "Epoch [2025/2500], Train Loss: 0.7624, Train Accuracy: 66.57%, Test Loss: 0.8997, Test Accuracy: 64.56%\n",
      "Epoch [2026/2500], Train Loss: 0.7755, Train Accuracy: 64.58%, Test Loss: 0.8794, Test Accuracy: 67.09%\n",
      "Epoch [2027/2500], Train Loss: 0.7760, Train Accuracy: 65.29%, Test Loss: 0.9020, Test Accuracy: 64.56%\n",
      "Epoch [2028/2500], Train Loss: 0.7854, Train Accuracy: 65.72%, Test Loss: 0.8736, Test Accuracy: 67.09%\n",
      "Epoch [2029/2500], Train Loss: 0.7586, Train Accuracy: 66.43%, Test Loss: 0.9135, Test Accuracy: 64.56%\n",
      "Epoch [2030/2500], Train Loss: 0.7765, Train Accuracy: 66.15%, Test Loss: 0.9348, Test Accuracy: 62.03%\n",
      "Epoch [2031/2500], Train Loss: 0.7618, Train Accuracy: 66.71%, Test Loss: 0.8822, Test Accuracy: 65.82%\n",
      "Epoch [2032/2500], Train Loss: 0.7626, Train Accuracy: 66.15%, Test Loss: 0.9288, Test Accuracy: 63.29%\n",
      "Epoch [2033/2500], Train Loss: 0.8040, Train Accuracy: 65.01%, Test Loss: 0.9161, Test Accuracy: 63.29%\n",
      "Epoch [2034/2500], Train Loss: 0.7518, Train Accuracy: 66.57%, Test Loss: 0.8995, Test Accuracy: 64.56%\n",
      "Epoch [2035/2500], Train Loss: 0.7763, Train Accuracy: 66.15%, Test Loss: 0.9087, Test Accuracy: 63.29%\n",
      "Epoch [2036/2500], Train Loss: 0.7481, Train Accuracy: 67.71%, Test Loss: 0.8978, Test Accuracy: 64.56%\n",
      "Epoch [2037/2500], Train Loss: 0.7779, Train Accuracy: 65.01%, Test Loss: 0.8351, Test Accuracy: 70.89%\n",
      "Epoch [2038/2500], Train Loss: 0.7566, Train Accuracy: 65.86%, Test Loss: 0.9170, Test Accuracy: 63.29%\n",
      "Epoch [2039/2500], Train Loss: 0.7741, Train Accuracy: 67.28%, Test Loss: 0.8748, Test Accuracy: 67.09%\n",
      "Epoch [2040/2500], Train Loss: 0.7373, Train Accuracy: 66.43%, Test Loss: 0.8565, Test Accuracy: 68.35%\n",
      "Epoch [2041/2500], Train Loss: 0.7540, Train Accuracy: 67.43%, Test Loss: 0.8952, Test Accuracy: 64.56%\n",
      "Epoch [2042/2500], Train Loss: 0.7517, Train Accuracy: 68.71%, Test Loss: 0.8714, Test Accuracy: 69.62%\n",
      "Epoch [2043/2500], Train Loss: 0.7320, Train Accuracy: 67.71%, Test Loss: 0.8738, Test Accuracy: 68.35%\n",
      "Epoch [2044/2500], Train Loss: 0.7392, Train Accuracy: 68.28%, Test Loss: 0.8570, Test Accuracy: 69.62%\n",
      "Epoch [2045/2500], Train Loss: 0.8008, Train Accuracy: 64.30%, Test Loss: 0.8582, Test Accuracy: 67.09%\n",
      "Epoch [2046/2500], Train Loss: 0.7262, Train Accuracy: 69.13%, Test Loss: 0.8910, Test Accuracy: 64.56%\n",
      "Epoch [2047/2500], Train Loss: 0.7707, Train Accuracy: 64.44%, Test Loss: 0.8763, Test Accuracy: 65.82%\n",
      "Epoch [2048/2500], Train Loss: 0.8008, Train Accuracy: 65.15%, Test Loss: 0.8912, Test Accuracy: 65.82%\n",
      "Epoch [2049/2500], Train Loss: 0.7491, Train Accuracy: 67.00%, Test Loss: 0.8905, Test Accuracy: 65.82%\n",
      "Epoch [2050/2500], Train Loss: 0.7643, Train Accuracy: 67.00%, Test Loss: 0.9040, Test Accuracy: 65.82%\n",
      "Epoch [2051/2500], Train Loss: 0.7435, Train Accuracy: 68.28%, Test Loss: 0.9167, Test Accuracy: 64.56%\n",
      "Epoch [2052/2500], Train Loss: 0.7674, Train Accuracy: 67.28%, Test Loss: 0.8913, Test Accuracy: 68.35%\n",
      "Epoch [2053/2500], Train Loss: 0.7633, Train Accuracy: 64.58%, Test Loss: 0.9399, Test Accuracy: 63.29%\n",
      "Epoch [2054/2500], Train Loss: 0.7572, Train Accuracy: 66.71%, Test Loss: 0.9325, Test Accuracy: 64.56%\n",
      "Epoch [2055/2500], Train Loss: 0.7311, Train Accuracy: 67.28%, Test Loss: 0.9053, Test Accuracy: 65.82%\n",
      "Epoch [2056/2500], Train Loss: 0.7482, Train Accuracy: 66.29%, Test Loss: 0.9400, Test Accuracy: 64.56%\n",
      "Epoch [2057/2500], Train Loss: 0.7540, Train Accuracy: 66.29%, Test Loss: 0.9178, Test Accuracy: 64.56%\n",
      "Epoch [2058/2500], Train Loss: 0.7303, Train Accuracy: 69.56%, Test Loss: 0.8907, Test Accuracy: 65.82%\n",
      "Epoch [2059/2500], Train Loss: 0.7507, Train Accuracy: 66.71%, Test Loss: 0.8677, Test Accuracy: 68.35%\n",
      "Epoch [2060/2500], Train Loss: 0.7607, Train Accuracy: 67.57%, Test Loss: 0.8783, Test Accuracy: 65.82%\n",
      "Epoch [2061/2500], Train Loss: 0.7736, Train Accuracy: 64.86%, Test Loss: 0.9757, Test Accuracy: 60.76%\n",
      "Epoch [2062/2500], Train Loss: 0.7758, Train Accuracy: 65.43%, Test Loss: 0.9515, Test Accuracy: 60.76%\n",
      "Epoch [2063/2500], Train Loss: 0.7607, Train Accuracy: 67.14%, Test Loss: 0.8807, Test Accuracy: 65.82%\n",
      "Epoch [2064/2500], Train Loss: 0.7732, Train Accuracy: 65.58%, Test Loss: 0.8812, Test Accuracy: 68.35%\n",
      "Epoch [2065/2500], Train Loss: 0.7578, Train Accuracy: 67.99%, Test Loss: 0.8789, Test Accuracy: 65.82%\n",
      "Epoch [2066/2500], Train Loss: 0.7478, Train Accuracy: 66.15%, Test Loss: 0.8929, Test Accuracy: 65.82%\n",
      "Epoch [2067/2500], Train Loss: 0.7733, Train Accuracy: 64.72%, Test Loss: 0.9078, Test Accuracy: 64.56%\n",
      "Epoch [2068/2500], Train Loss: 0.7496, Train Accuracy: 67.14%, Test Loss: 0.8848, Test Accuracy: 65.82%\n",
      "Epoch [2069/2500], Train Loss: 0.7758, Train Accuracy: 65.86%, Test Loss: 0.8723, Test Accuracy: 65.82%\n",
      "Epoch [2070/2500], Train Loss: 0.7545, Train Accuracy: 66.86%, Test Loss: 0.8572, Test Accuracy: 69.62%\n",
      "Epoch [2071/2500], Train Loss: 0.7681, Train Accuracy: 65.86%, Test Loss: 0.9160, Test Accuracy: 63.29%\n",
      "Epoch [2072/2500], Train Loss: 0.7716, Train Accuracy: 65.72%, Test Loss: 0.8645, Test Accuracy: 67.09%\n",
      "Epoch [2073/2500], Train Loss: 0.7590, Train Accuracy: 67.71%, Test Loss: 0.8963, Test Accuracy: 65.82%\n",
      "Epoch [2074/2500], Train Loss: 0.7486, Train Accuracy: 67.00%, Test Loss: 0.9248, Test Accuracy: 62.03%\n",
      "Epoch [2075/2500], Train Loss: 0.8009, Train Accuracy: 64.01%, Test Loss: 0.9010, Test Accuracy: 64.56%\n",
      "Epoch [2076/2500], Train Loss: 0.7544, Train Accuracy: 67.28%, Test Loss: 0.8653, Test Accuracy: 65.82%\n",
      "Epoch [2077/2500], Train Loss: 0.7530, Train Accuracy: 67.57%, Test Loss: 0.8806, Test Accuracy: 65.82%\n",
      "Epoch [2078/2500], Train Loss: 0.7817, Train Accuracy: 64.44%, Test Loss: 0.8770, Test Accuracy: 65.82%\n",
      "Epoch [2079/2500], Train Loss: 0.7585, Train Accuracy: 67.99%, Test Loss: 0.8685, Test Accuracy: 68.35%\n",
      "Epoch [2080/2500], Train Loss: 0.7360, Train Accuracy: 67.43%, Test Loss: 0.8878, Test Accuracy: 65.82%\n",
      "Epoch [2081/2500], Train Loss: 0.7584, Train Accuracy: 65.86%, Test Loss: 0.9602, Test Accuracy: 60.76%\n",
      "Epoch [2082/2500], Train Loss: 0.7532, Train Accuracy: 65.01%, Test Loss: 0.9157, Test Accuracy: 63.29%\n",
      "Epoch [2083/2500], Train Loss: 0.7566, Train Accuracy: 65.58%, Test Loss: 0.8773, Test Accuracy: 65.82%\n",
      "Epoch [2084/2500], Train Loss: 0.7409, Train Accuracy: 68.42%, Test Loss: 0.8811, Test Accuracy: 65.82%\n",
      "Epoch [2085/2500], Train Loss: 0.7234, Train Accuracy: 67.43%, Test Loss: 0.9466, Test Accuracy: 62.03%\n",
      "Epoch [2086/2500], Train Loss: 0.7728, Train Accuracy: 65.72%, Test Loss: 0.8792, Test Accuracy: 65.82%\n",
      "Epoch [2087/2500], Train Loss: 0.7502, Train Accuracy: 68.42%, Test Loss: 0.8844, Test Accuracy: 65.82%\n",
      "Epoch [2088/2500], Train Loss: 0.7418, Train Accuracy: 65.86%, Test Loss: 0.9046, Test Accuracy: 65.82%\n",
      "Epoch [2089/2500], Train Loss: 0.7532, Train Accuracy: 65.29%, Test Loss: 0.9213, Test Accuracy: 64.56%\n",
      "Epoch [2090/2500], Train Loss: 0.7601, Train Accuracy: 67.85%, Test Loss: 0.9260, Test Accuracy: 62.03%\n",
      "Epoch [2091/2500], Train Loss: 0.7585, Train Accuracy: 67.43%, Test Loss: 0.8840, Test Accuracy: 64.56%\n",
      "Epoch [2092/2500], Train Loss: 0.7408, Train Accuracy: 66.15%, Test Loss: 0.8951, Test Accuracy: 64.56%\n",
      "Epoch [2093/2500], Train Loss: 0.7634, Train Accuracy: 65.72%, Test Loss: 0.9130, Test Accuracy: 64.56%\n",
      "Epoch [2094/2500], Train Loss: 0.7415, Train Accuracy: 68.71%, Test Loss: 0.8854, Test Accuracy: 65.82%\n",
      "Epoch [2095/2500], Train Loss: 0.7565, Train Accuracy: 66.57%, Test Loss: 0.9255, Test Accuracy: 63.29%\n",
      "Epoch [2096/2500], Train Loss: 0.7556, Train Accuracy: 66.15%, Test Loss: 0.8618, Test Accuracy: 65.82%\n",
      "Epoch [2097/2500], Train Loss: 0.7811, Train Accuracy: 67.43%, Test Loss: 0.8950, Test Accuracy: 65.82%\n",
      "Epoch [2098/2500], Train Loss: 0.7756, Train Accuracy: 66.57%, Test Loss: 0.8956, Test Accuracy: 64.56%\n",
      "Epoch [2099/2500], Train Loss: 0.7525, Train Accuracy: 66.43%, Test Loss: 0.8944, Test Accuracy: 64.56%\n",
      "Epoch [2100/2500], Train Loss: 0.7547, Train Accuracy: 66.29%, Test Loss: 0.8937, Test Accuracy: 64.56%\n",
      "Epoch [2101/2500], Train Loss: 0.7251, Train Accuracy: 67.71%, Test Loss: 0.9031, Test Accuracy: 64.56%\n",
      "Epoch [2102/2500], Train Loss: 0.7461, Train Accuracy: 67.28%, Test Loss: 0.8905, Test Accuracy: 65.82%\n",
      "Epoch [2103/2500], Train Loss: 0.7476, Train Accuracy: 67.43%, Test Loss: 0.9494, Test Accuracy: 62.03%\n",
      "Epoch [2104/2500], Train Loss: 0.7639, Train Accuracy: 66.15%, Test Loss: 0.9017, Test Accuracy: 64.56%\n",
      "Epoch [2105/2500], Train Loss: 0.7328, Train Accuracy: 65.72%, Test Loss: 0.8964, Test Accuracy: 65.82%\n",
      "Epoch [2106/2500], Train Loss: 0.7521, Train Accuracy: 67.14%, Test Loss: 0.9040, Test Accuracy: 65.82%\n",
      "Epoch [2107/2500], Train Loss: 0.7685, Train Accuracy: 67.00%, Test Loss: 0.9060, Test Accuracy: 64.56%\n",
      "Epoch [2108/2500], Train Loss: 0.7268, Train Accuracy: 67.00%, Test Loss: 0.9087, Test Accuracy: 64.56%\n",
      "Epoch [2109/2500], Train Loss: 0.7526, Train Accuracy: 64.01%, Test Loss: 0.8828, Test Accuracy: 65.82%\n",
      "Epoch [2110/2500], Train Loss: 0.7478, Train Accuracy: 67.00%, Test Loss: 0.9165, Test Accuracy: 63.29%\n",
      "Epoch [2111/2500], Train Loss: 0.7455, Train Accuracy: 66.71%, Test Loss: 0.9106, Test Accuracy: 63.29%\n",
      "Epoch [2112/2500], Train Loss: 0.7459, Train Accuracy: 66.00%, Test Loss: 0.9081, Test Accuracy: 63.29%\n",
      "Epoch [2113/2500], Train Loss: 0.7612, Train Accuracy: 66.71%, Test Loss: 0.8870, Test Accuracy: 67.09%\n",
      "Epoch [2114/2500], Train Loss: 0.7553, Train Accuracy: 66.57%, Test Loss: 0.9006, Test Accuracy: 64.56%\n",
      "Epoch [2115/2500], Train Loss: 0.7581, Train Accuracy: 67.28%, Test Loss: 0.8878, Test Accuracy: 64.56%\n",
      "Epoch [2116/2500], Train Loss: 0.7786, Train Accuracy: 64.86%, Test Loss: 0.8953, Test Accuracy: 64.56%\n",
      "Epoch [2117/2500], Train Loss: 0.7271, Train Accuracy: 68.28%, Test Loss: 0.9014, Test Accuracy: 64.56%\n",
      "Epoch [2118/2500], Train Loss: 0.7444, Train Accuracy: 67.43%, Test Loss: 0.8970, Test Accuracy: 63.29%\n",
      "Epoch [2119/2500], Train Loss: 0.7567, Train Accuracy: 66.86%, Test Loss: 0.8697, Test Accuracy: 68.35%\n",
      "Epoch [2120/2500], Train Loss: 0.7467, Train Accuracy: 66.86%, Test Loss: 0.8958, Test Accuracy: 62.03%\n",
      "Epoch [2121/2500], Train Loss: 0.7479, Train Accuracy: 67.99%, Test Loss: 0.9456, Test Accuracy: 60.76%\n",
      "Epoch [2122/2500], Train Loss: 0.7725, Train Accuracy: 67.14%, Test Loss: 0.8580, Test Accuracy: 67.09%\n",
      "Epoch [2123/2500], Train Loss: 0.7329, Train Accuracy: 67.14%, Test Loss: 0.9214, Test Accuracy: 62.03%\n",
      "Epoch [2124/2500], Train Loss: 0.7697, Train Accuracy: 66.00%, Test Loss: 0.8751, Test Accuracy: 65.82%\n",
      "Epoch [2125/2500], Train Loss: 0.7356, Train Accuracy: 66.71%, Test Loss: 0.8836, Test Accuracy: 65.82%\n",
      "Epoch [2126/2500], Train Loss: 0.7482, Train Accuracy: 67.14%, Test Loss: 0.8810, Test Accuracy: 65.82%\n",
      "Epoch [2127/2500], Train Loss: 0.7303, Train Accuracy: 67.28%, Test Loss: 0.9073, Test Accuracy: 63.29%\n",
      "Epoch [2128/2500], Train Loss: 0.7515, Train Accuracy: 65.86%, Test Loss: 0.8713, Test Accuracy: 65.82%\n",
      "Epoch [2129/2500], Train Loss: 0.7522, Train Accuracy: 66.86%, Test Loss: 0.9301, Test Accuracy: 63.29%\n",
      "Epoch [2130/2500], Train Loss: 0.7499, Train Accuracy: 67.28%, Test Loss: 0.9089, Test Accuracy: 64.56%\n",
      "Epoch [2131/2500], Train Loss: 0.7305, Train Accuracy: 68.28%, Test Loss: 0.8908, Test Accuracy: 64.56%\n",
      "Epoch [2132/2500], Train Loss: 0.7450, Train Accuracy: 67.85%, Test Loss: 0.9166, Test Accuracy: 64.56%\n",
      "Epoch [2133/2500], Train Loss: 0.7390, Train Accuracy: 67.99%, Test Loss: 0.8873, Test Accuracy: 67.09%\n",
      "Epoch [2134/2500], Train Loss: 0.7391, Train Accuracy: 66.71%, Test Loss: 0.9415, Test Accuracy: 63.29%\n",
      "Epoch [2135/2500], Train Loss: 0.7840, Train Accuracy: 65.01%, Test Loss: 0.8889, Test Accuracy: 64.56%\n",
      "Epoch [2136/2500], Train Loss: 0.7782, Train Accuracy: 64.72%, Test Loss: 0.8705, Test Accuracy: 65.82%\n",
      "Epoch [2137/2500], Train Loss: 0.7403, Train Accuracy: 66.15%, Test Loss: 0.8532, Test Accuracy: 68.35%\n",
      "Epoch [2138/2500], Train Loss: 0.7467, Train Accuracy: 66.29%, Test Loss: 0.8704, Test Accuracy: 65.82%\n",
      "Epoch [2139/2500], Train Loss: 0.7454, Train Accuracy: 68.28%, Test Loss: 0.9196, Test Accuracy: 63.29%\n",
      "Epoch [2140/2500], Train Loss: 0.7535, Train Accuracy: 66.29%, Test Loss: 0.9292, Test Accuracy: 62.03%\n",
      "Epoch [2141/2500], Train Loss: 0.7711, Train Accuracy: 66.57%, Test Loss: 0.8945, Test Accuracy: 64.56%\n",
      "Epoch [2142/2500], Train Loss: 0.7329, Train Accuracy: 67.43%, Test Loss: 0.9229, Test Accuracy: 62.03%\n",
      "Epoch [2143/2500], Train Loss: 0.7372, Train Accuracy: 68.42%, Test Loss: 0.8712, Test Accuracy: 64.56%\n",
      "Epoch [2144/2500], Train Loss: 0.7472, Train Accuracy: 67.28%, Test Loss: 0.9288, Test Accuracy: 62.03%\n",
      "Epoch [2145/2500], Train Loss: 0.7752, Train Accuracy: 65.86%, Test Loss: 0.9525, Test Accuracy: 63.29%\n",
      "Epoch [2146/2500], Train Loss: 0.7206, Train Accuracy: 69.27%, Test Loss: 0.9295, Test Accuracy: 62.03%\n",
      "Epoch [2147/2500], Train Loss: 0.7257, Train Accuracy: 66.43%, Test Loss: 0.8871, Test Accuracy: 65.82%\n",
      "Epoch [2148/2500], Train Loss: 0.7416, Train Accuracy: 67.71%, Test Loss: 0.8689, Test Accuracy: 67.09%\n",
      "Epoch [2149/2500], Train Loss: 0.7509, Train Accuracy: 67.14%, Test Loss: 0.9447, Test Accuracy: 62.03%\n",
      "Epoch [2150/2500], Train Loss: 0.7496, Train Accuracy: 66.29%, Test Loss: 0.8645, Test Accuracy: 67.09%\n",
      "Epoch [2151/2500], Train Loss: 0.7409, Train Accuracy: 67.99%, Test Loss: 0.8591, Test Accuracy: 68.35%\n",
      "Epoch [2152/2500], Train Loss: 0.7351, Train Accuracy: 67.43%, Test Loss: 0.8706, Test Accuracy: 67.09%\n",
      "Epoch [2153/2500], Train Loss: 0.7569, Train Accuracy: 67.57%, Test Loss: 0.9101, Test Accuracy: 63.29%\n",
      "Epoch [2154/2500], Train Loss: 0.7588, Train Accuracy: 66.86%, Test Loss: 0.8872, Test Accuracy: 67.09%\n",
      "Epoch [2155/2500], Train Loss: 0.7332, Train Accuracy: 67.99%, Test Loss: 0.9103, Test Accuracy: 65.82%\n",
      "Epoch [2156/2500], Train Loss: 0.7471, Train Accuracy: 66.43%, Test Loss: 0.8892, Test Accuracy: 64.56%\n",
      "Epoch [2157/2500], Train Loss: 0.7326, Train Accuracy: 67.71%, Test Loss: 0.9054, Test Accuracy: 63.29%\n",
      "Epoch [2158/2500], Train Loss: 0.7261, Train Accuracy: 68.56%, Test Loss: 0.8793, Test Accuracy: 65.82%\n",
      "Epoch [2159/2500], Train Loss: 0.7395, Train Accuracy: 66.43%, Test Loss: 0.9039, Test Accuracy: 64.56%\n",
      "Epoch [2160/2500], Train Loss: 0.7451, Train Accuracy: 67.14%, Test Loss: 0.8741, Test Accuracy: 67.09%\n",
      "Epoch [2161/2500], Train Loss: 0.7757, Train Accuracy: 65.72%, Test Loss: 0.8919, Test Accuracy: 64.56%\n",
      "Epoch [2162/2500], Train Loss: 0.7406, Train Accuracy: 67.14%, Test Loss: 0.9226, Test Accuracy: 62.03%\n",
      "Epoch [2163/2500], Train Loss: 0.7545, Train Accuracy: 66.15%, Test Loss: 0.9300, Test Accuracy: 62.03%\n",
      "Epoch [2164/2500], Train Loss: 0.7486, Train Accuracy: 66.71%, Test Loss: 0.8506, Test Accuracy: 69.62%\n",
      "Epoch [2165/2500], Train Loss: 0.7416, Train Accuracy: 66.00%, Test Loss: 0.9020, Test Accuracy: 64.56%\n",
      "Epoch [2166/2500], Train Loss: 0.7465, Train Accuracy: 67.85%, Test Loss: 0.8915, Test Accuracy: 63.29%\n",
      "Epoch [2167/2500], Train Loss: 0.7529, Train Accuracy: 67.14%, Test Loss: 0.9160, Test Accuracy: 63.29%\n",
      "Epoch [2168/2500], Train Loss: 0.7487, Train Accuracy: 67.00%, Test Loss: 0.8634, Test Accuracy: 67.09%\n",
      "Epoch [2169/2500], Train Loss: 0.7411, Train Accuracy: 66.00%, Test Loss: 0.9077, Test Accuracy: 62.03%\n",
      "Epoch [2170/2500], Train Loss: 0.7465, Train Accuracy: 67.28%, Test Loss: 0.9314, Test Accuracy: 62.03%\n",
      "Epoch [2171/2500], Train Loss: 0.7248, Train Accuracy: 70.41%, Test Loss: 0.8575, Test Accuracy: 67.09%\n",
      "Epoch [2172/2500], Train Loss: 0.7584, Train Accuracy: 66.57%, Test Loss: 0.9419, Test Accuracy: 60.76%\n",
      "Epoch [2173/2500], Train Loss: 0.7510, Train Accuracy: 66.71%, Test Loss: 0.8523, Test Accuracy: 68.35%\n",
      "Epoch [2174/2500], Train Loss: 0.7397, Train Accuracy: 66.57%, Test Loss: 0.9263, Test Accuracy: 62.03%\n",
      "Epoch [2175/2500], Train Loss: 0.7405, Train Accuracy: 68.14%, Test Loss: 0.8350, Test Accuracy: 69.62%\n",
      "Epoch [2176/2500], Train Loss: 0.7187, Train Accuracy: 68.85%, Test Loss: 0.8283, Test Accuracy: 72.15%\n",
      "Epoch [2177/2500], Train Loss: 0.7384, Train Accuracy: 68.99%, Test Loss: 0.8948, Test Accuracy: 63.29%\n",
      "Epoch [2178/2500], Train Loss: 0.7572, Train Accuracy: 66.57%, Test Loss: 0.8813, Test Accuracy: 65.82%\n",
      "Epoch [2179/2500], Train Loss: 0.7440, Train Accuracy: 65.58%, Test Loss: 0.9478, Test Accuracy: 60.76%\n",
      "Epoch [2180/2500], Train Loss: 0.7393, Train Accuracy: 68.71%, Test Loss: 0.8779, Test Accuracy: 65.82%\n",
      "Epoch [2181/2500], Train Loss: 0.7125, Train Accuracy: 67.14%, Test Loss: 0.9181, Test Accuracy: 63.29%\n",
      "Epoch [2182/2500], Train Loss: 0.7365, Train Accuracy: 67.71%, Test Loss: 0.9083, Test Accuracy: 63.29%\n",
      "Epoch [2183/2500], Train Loss: 0.7583, Train Accuracy: 66.15%, Test Loss: 0.8986, Test Accuracy: 63.29%\n",
      "Epoch [2184/2500], Train Loss: 0.7328, Train Accuracy: 67.43%, Test Loss: 0.9540, Test Accuracy: 62.03%\n",
      "Epoch [2185/2500], Train Loss: 0.7459, Train Accuracy: 67.14%, Test Loss: 0.9148, Test Accuracy: 63.29%\n",
      "Epoch [2186/2500], Train Loss: 0.7435, Train Accuracy: 68.42%, Test Loss: 0.8783, Test Accuracy: 67.09%\n",
      "Epoch [2187/2500], Train Loss: 0.7422, Train Accuracy: 68.56%, Test Loss: 0.9486, Test Accuracy: 60.76%\n",
      "Epoch [2188/2500], Train Loss: 0.7499, Train Accuracy: 65.86%, Test Loss: 0.9008, Test Accuracy: 64.56%\n",
      "Epoch [2189/2500], Train Loss: 0.7153, Train Accuracy: 68.85%, Test Loss: 0.9337, Test Accuracy: 60.76%\n",
      "Epoch [2190/2500], Train Loss: 0.7480, Train Accuracy: 67.71%, Test Loss: 0.9322, Test Accuracy: 60.76%\n",
      "Epoch [2191/2500], Train Loss: 0.7388, Train Accuracy: 66.86%, Test Loss: 0.8754, Test Accuracy: 68.35%\n",
      "Epoch [2192/2500], Train Loss: 0.7296, Train Accuracy: 67.85%, Test Loss: 0.9353, Test Accuracy: 60.76%\n",
      "Epoch [2193/2500], Train Loss: 0.7349, Train Accuracy: 68.14%, Test Loss: 0.9626, Test Accuracy: 60.76%\n",
      "Epoch [2194/2500], Train Loss: 0.7564, Train Accuracy: 68.71%, Test Loss: 0.8939, Test Accuracy: 63.29%\n",
      "Epoch [2195/2500], Train Loss: 0.7036, Train Accuracy: 68.99%, Test Loss: 0.9128, Test Accuracy: 63.29%\n",
      "Epoch [2196/2500], Train Loss: 0.7413, Train Accuracy: 67.43%, Test Loss: 0.8776, Test Accuracy: 65.82%\n",
      "Epoch [2197/2500], Train Loss: 0.7061, Train Accuracy: 69.99%, Test Loss: 0.8934, Test Accuracy: 64.56%\n",
      "Epoch [2198/2500], Train Loss: 0.7484, Train Accuracy: 67.14%, Test Loss: 0.8690, Test Accuracy: 68.35%\n",
      "Epoch [2199/2500], Train Loss: 0.7424, Train Accuracy: 67.43%, Test Loss: 0.9160, Test Accuracy: 63.29%\n",
      "Epoch [2200/2500], Train Loss: 0.7462, Train Accuracy: 67.57%, Test Loss: 0.8945, Test Accuracy: 64.56%\n",
      "Epoch [2201/2500], Train Loss: 0.7455, Train Accuracy: 66.43%, Test Loss: 0.8922, Test Accuracy: 64.56%\n",
      "Epoch [2202/2500], Train Loss: 0.7711, Train Accuracy: 66.15%, Test Loss: 0.9423, Test Accuracy: 60.76%\n",
      "Epoch [2203/2500], Train Loss: 0.7353, Train Accuracy: 67.00%, Test Loss: 0.9474, Test Accuracy: 60.76%\n",
      "Epoch [2204/2500], Train Loss: 0.7286, Train Accuracy: 68.71%, Test Loss: 0.9126, Test Accuracy: 60.76%\n",
      "Epoch [2205/2500], Train Loss: 0.7525, Train Accuracy: 65.72%, Test Loss: 0.9069, Test Accuracy: 62.03%\n",
      "Epoch [2206/2500], Train Loss: 0.7127, Train Accuracy: 68.28%, Test Loss: 0.9588, Test Accuracy: 59.49%\n",
      "Epoch [2207/2500], Train Loss: 0.7432, Train Accuracy: 68.85%, Test Loss: 0.9544, Test Accuracy: 60.76%\n",
      "Epoch [2208/2500], Train Loss: 0.7323, Train Accuracy: 67.28%, Test Loss: 0.9278, Test Accuracy: 62.03%\n",
      "Epoch [2209/2500], Train Loss: 0.7353, Train Accuracy: 67.28%, Test Loss: 0.8969, Test Accuracy: 65.82%\n",
      "Epoch [2210/2500], Train Loss: 0.7160, Train Accuracy: 70.13%, Test Loss: 0.8743, Test Accuracy: 65.82%\n",
      "Epoch [2211/2500], Train Loss: 0.7465, Train Accuracy: 68.56%, Test Loss: 0.9107, Test Accuracy: 65.82%\n",
      "Epoch [2212/2500], Train Loss: 0.7425, Train Accuracy: 67.85%, Test Loss: 0.9074, Test Accuracy: 65.82%\n",
      "Epoch [2213/2500], Train Loss: 0.7222, Train Accuracy: 67.28%, Test Loss: 0.8705, Test Accuracy: 65.82%\n",
      "Epoch [2214/2500], Train Loss: 0.7337, Train Accuracy: 68.71%, Test Loss: 0.9224, Test Accuracy: 62.03%\n",
      "Epoch [2215/2500], Train Loss: 0.7379, Train Accuracy: 67.14%, Test Loss: 0.8731, Test Accuracy: 64.56%\n",
      "Epoch [2216/2500], Train Loss: 0.7576, Train Accuracy: 66.43%, Test Loss: 0.8617, Test Accuracy: 67.09%\n",
      "Epoch [2217/2500], Train Loss: 0.7264, Train Accuracy: 67.28%, Test Loss: 0.8991, Test Accuracy: 63.29%\n",
      "Epoch [2218/2500], Train Loss: 0.7291, Train Accuracy: 68.14%, Test Loss: 0.8990, Test Accuracy: 64.56%\n",
      "Epoch [2219/2500], Train Loss: 0.7198, Train Accuracy: 68.28%, Test Loss: 0.8736, Test Accuracy: 65.82%\n",
      "Epoch [2220/2500], Train Loss: 0.7134, Train Accuracy: 69.99%, Test Loss: 0.8726, Test Accuracy: 65.82%\n",
      "Epoch [2221/2500], Train Loss: 0.7278, Train Accuracy: 67.57%, Test Loss: 0.9291, Test Accuracy: 60.76%\n",
      "Epoch [2222/2500], Train Loss: 0.7226, Train Accuracy: 69.27%, Test Loss: 0.9202, Test Accuracy: 62.03%\n",
      "Epoch [2223/2500], Train Loss: 0.7259, Train Accuracy: 67.57%, Test Loss: 0.9127, Test Accuracy: 65.82%\n",
      "Epoch [2224/2500], Train Loss: 0.7316, Train Accuracy: 68.14%, Test Loss: 0.9046, Test Accuracy: 64.56%\n",
      "Epoch [2225/2500], Train Loss: 0.7416, Train Accuracy: 67.57%, Test Loss: 0.8757, Test Accuracy: 68.35%\n",
      "Epoch [2226/2500], Train Loss: 0.7477, Train Accuracy: 66.29%, Test Loss: 0.8940, Test Accuracy: 64.56%\n",
      "Epoch [2227/2500], Train Loss: 0.7212, Train Accuracy: 68.42%, Test Loss: 0.8873, Test Accuracy: 64.56%\n",
      "Epoch [2228/2500], Train Loss: 0.7244, Train Accuracy: 67.14%, Test Loss: 0.8830, Test Accuracy: 67.09%\n",
      "Epoch [2229/2500], Train Loss: 0.7466, Train Accuracy: 68.14%, Test Loss: 0.8632, Test Accuracy: 70.89%\n",
      "Epoch [2230/2500], Train Loss: 0.7437, Train Accuracy: 67.99%, Test Loss: 0.8875, Test Accuracy: 65.82%\n",
      "Epoch [2231/2500], Train Loss: 0.7347, Train Accuracy: 67.71%, Test Loss: 0.8857, Test Accuracy: 67.09%\n",
      "Epoch [2232/2500], Train Loss: 0.7435, Train Accuracy: 67.28%, Test Loss: 0.9170, Test Accuracy: 64.56%\n",
      "Epoch [2233/2500], Train Loss: 0.7578, Train Accuracy: 66.15%, Test Loss: 0.9028, Test Accuracy: 67.09%\n",
      "Epoch [2234/2500], Train Loss: 0.7016, Train Accuracy: 69.70%, Test Loss: 0.9044, Test Accuracy: 65.82%\n",
      "Epoch [2235/2500], Train Loss: 0.7375, Train Accuracy: 67.14%, Test Loss: 0.8852, Test Accuracy: 68.35%\n",
      "Epoch [2236/2500], Train Loss: 0.7251, Train Accuracy: 69.56%, Test Loss: 0.9004, Test Accuracy: 63.29%\n",
      "Epoch [2237/2500], Train Loss: 0.7160, Train Accuracy: 69.13%, Test Loss: 0.8659, Test Accuracy: 65.82%\n",
      "Epoch [2238/2500], Train Loss: 0.7413, Train Accuracy: 67.28%, Test Loss: 0.9561, Test Accuracy: 60.76%\n",
      "Epoch [2239/2500], Train Loss: 0.7201, Train Accuracy: 67.71%, Test Loss: 0.9402, Test Accuracy: 60.76%\n",
      "Epoch [2240/2500], Train Loss: 0.7492, Train Accuracy: 65.29%, Test Loss: 0.9206, Test Accuracy: 62.03%\n",
      "Epoch [2241/2500], Train Loss: 0.7185, Train Accuracy: 69.27%, Test Loss: 0.8739, Test Accuracy: 64.56%\n",
      "Epoch [2242/2500], Train Loss: 0.7145, Train Accuracy: 68.99%, Test Loss: 0.9002, Test Accuracy: 67.09%\n",
      "Epoch [2243/2500], Train Loss: 0.7560, Train Accuracy: 68.85%, Test Loss: 0.8880, Test Accuracy: 64.56%\n",
      "Epoch [2244/2500], Train Loss: 0.7391, Train Accuracy: 67.99%, Test Loss: 0.8762, Test Accuracy: 69.62%\n",
      "Epoch [2245/2500], Train Loss: 0.7244, Train Accuracy: 67.99%, Test Loss: 0.9210, Test Accuracy: 63.29%\n",
      "Epoch [2246/2500], Train Loss: 0.7423, Train Accuracy: 67.28%, Test Loss: 0.8984, Test Accuracy: 64.56%\n",
      "Epoch [2247/2500], Train Loss: 0.7180, Train Accuracy: 69.27%, Test Loss: 0.9064, Test Accuracy: 65.82%\n",
      "Epoch [2248/2500], Train Loss: 0.7503, Train Accuracy: 68.28%, Test Loss: 0.9315, Test Accuracy: 62.03%\n",
      "Epoch [2249/2500], Train Loss: 0.7276, Train Accuracy: 69.99%, Test Loss: 0.8914, Test Accuracy: 65.82%\n",
      "Epoch [2250/2500], Train Loss: 0.7434, Train Accuracy: 68.56%, Test Loss: 0.9257, Test Accuracy: 60.76%\n",
      "Epoch [2251/2500], Train Loss: 0.7344, Train Accuracy: 68.99%, Test Loss: 0.8912, Test Accuracy: 67.09%\n",
      "Epoch [2252/2500], Train Loss: 0.7400, Train Accuracy: 67.99%, Test Loss: 0.9160, Test Accuracy: 63.29%\n",
      "Epoch [2253/2500], Train Loss: 0.7357, Train Accuracy: 65.86%, Test Loss: 0.8939, Test Accuracy: 65.82%\n",
      "Epoch [2254/2500], Train Loss: 0.7246, Train Accuracy: 68.42%, Test Loss: 0.8835, Test Accuracy: 68.35%\n",
      "Epoch [2255/2500], Train Loss: 0.7196, Train Accuracy: 68.85%, Test Loss: 0.9516, Test Accuracy: 60.76%\n",
      "Epoch [2256/2500], Train Loss: 0.7222, Train Accuracy: 69.13%, Test Loss: 0.9092, Test Accuracy: 64.56%\n",
      "Epoch [2257/2500], Train Loss: 0.7261, Train Accuracy: 67.85%, Test Loss: 0.9284, Test Accuracy: 62.03%\n",
      "Epoch [2258/2500], Train Loss: 0.7162, Train Accuracy: 67.71%, Test Loss: 0.9250, Test Accuracy: 62.03%\n",
      "Epoch [2259/2500], Train Loss: 0.7061, Train Accuracy: 68.85%, Test Loss: 0.9354, Test Accuracy: 62.03%\n",
      "Epoch [2260/2500], Train Loss: 0.7375, Train Accuracy: 67.28%, Test Loss: 0.9210, Test Accuracy: 63.29%\n",
      "Epoch [2261/2500], Train Loss: 0.7515, Train Accuracy: 67.28%, Test Loss: 0.9366, Test Accuracy: 63.29%\n",
      "Epoch [2262/2500], Train Loss: 0.7465, Train Accuracy: 66.43%, Test Loss: 0.9694, Test Accuracy: 60.76%\n",
      "Epoch [2263/2500], Train Loss: 0.7291, Train Accuracy: 67.99%, Test Loss: 0.9060, Test Accuracy: 64.56%\n",
      "Epoch [2264/2500], Train Loss: 0.7487, Train Accuracy: 65.15%, Test Loss: 0.9431, Test Accuracy: 62.03%\n",
      "Epoch [2265/2500], Train Loss: 0.7210, Train Accuracy: 66.71%, Test Loss: 0.9143, Test Accuracy: 63.29%\n",
      "Epoch [2266/2500], Train Loss: 0.7380, Train Accuracy: 67.43%, Test Loss: 0.8955, Test Accuracy: 64.56%\n",
      "Epoch [2267/2500], Train Loss: 0.7203, Train Accuracy: 69.27%, Test Loss: 0.9196, Test Accuracy: 63.29%\n",
      "Epoch [2268/2500], Train Loss: 0.7360, Train Accuracy: 68.99%, Test Loss: 0.9824, Test Accuracy: 60.76%\n",
      "Epoch [2269/2500], Train Loss: 0.7656, Train Accuracy: 68.56%, Test Loss: 0.8958, Test Accuracy: 68.35%\n",
      "Epoch [2270/2500], Train Loss: 0.7235, Train Accuracy: 69.42%, Test Loss: 0.9193, Test Accuracy: 63.29%\n",
      "Epoch [2271/2500], Train Loss: 0.7249, Train Accuracy: 69.13%, Test Loss: 0.8515, Test Accuracy: 68.35%\n",
      "Epoch [2272/2500], Train Loss: 0.7343, Train Accuracy: 68.85%, Test Loss: 0.8900, Test Accuracy: 67.09%\n",
      "Epoch [2273/2500], Train Loss: 0.7418, Train Accuracy: 67.71%, Test Loss: 0.9275, Test Accuracy: 63.29%\n",
      "Epoch [2274/2500], Train Loss: 0.7595, Train Accuracy: 67.00%, Test Loss: 0.9362, Test Accuracy: 63.29%\n",
      "Epoch [2275/2500], Train Loss: 0.7039, Train Accuracy: 71.12%, Test Loss: 0.8988, Test Accuracy: 65.82%\n",
      "Epoch [2276/2500], Train Loss: 0.7190, Train Accuracy: 69.13%, Test Loss: 0.8408, Test Accuracy: 72.15%\n",
      "Epoch [2277/2500], Train Loss: 0.7373, Train Accuracy: 67.28%, Test Loss: 0.9028, Test Accuracy: 63.29%\n",
      "Epoch [2278/2500], Train Loss: 0.7634, Train Accuracy: 67.00%, Test Loss: 0.9028, Test Accuracy: 63.29%\n",
      "Epoch [2279/2500], Train Loss: 0.7228, Train Accuracy: 68.28%, Test Loss: 0.8965, Test Accuracy: 64.56%\n",
      "Epoch [2280/2500], Train Loss: 0.7110, Train Accuracy: 68.85%, Test Loss: 0.9079, Test Accuracy: 62.03%\n",
      "Epoch [2281/2500], Train Loss: 0.7091, Train Accuracy: 68.99%, Test Loss: 0.8809, Test Accuracy: 67.09%\n",
      "Epoch [2282/2500], Train Loss: 0.7382, Train Accuracy: 67.43%, Test Loss: 0.9548, Test Accuracy: 62.03%\n",
      "Epoch [2283/2500], Train Loss: 0.7311, Train Accuracy: 66.71%, Test Loss: 0.8798, Test Accuracy: 67.09%\n",
      "Epoch [2284/2500], Train Loss: 0.7231, Train Accuracy: 67.57%, Test Loss: 0.9786, Test Accuracy: 62.03%\n",
      "Epoch [2285/2500], Train Loss: 0.7353, Train Accuracy: 69.27%, Test Loss: 0.8894, Test Accuracy: 65.82%\n",
      "Epoch [2286/2500], Train Loss: 0.7340, Train Accuracy: 67.85%, Test Loss: 0.9110, Test Accuracy: 63.29%\n",
      "Epoch [2287/2500], Train Loss: 0.7292, Train Accuracy: 69.13%, Test Loss: 0.9411, Test Accuracy: 63.29%\n",
      "Epoch [2288/2500], Train Loss: 0.7243, Train Accuracy: 68.28%, Test Loss: 0.8842, Test Accuracy: 68.35%\n",
      "Epoch [2289/2500], Train Loss: 0.7536, Train Accuracy: 66.00%, Test Loss: 0.8902, Test Accuracy: 67.09%\n",
      "Epoch [2290/2500], Train Loss: 0.7209, Train Accuracy: 68.14%, Test Loss: 0.8834, Test Accuracy: 67.09%\n",
      "Epoch [2291/2500], Train Loss: 0.7332, Train Accuracy: 67.57%, Test Loss: 0.9057, Test Accuracy: 63.29%\n",
      "Epoch [2292/2500], Train Loss: 0.7156, Train Accuracy: 69.99%, Test Loss: 0.9016, Test Accuracy: 64.56%\n",
      "Epoch [2293/2500], Train Loss: 0.7149, Train Accuracy: 67.99%, Test Loss: 0.8982, Test Accuracy: 64.56%\n",
      "Epoch [2294/2500], Train Loss: 0.7030, Train Accuracy: 68.28%, Test Loss: 0.9060, Test Accuracy: 64.56%\n",
      "Epoch [2295/2500], Train Loss: 0.7304, Train Accuracy: 69.42%, Test Loss: 0.8884, Test Accuracy: 67.09%\n",
      "Epoch [2296/2500], Train Loss: 0.7136, Train Accuracy: 69.13%, Test Loss: 0.8692, Test Accuracy: 72.15%\n",
      "Epoch [2297/2500], Train Loss: 0.7284, Train Accuracy: 67.71%, Test Loss: 0.9136, Test Accuracy: 65.82%\n",
      "Epoch [2298/2500], Train Loss: 0.7266, Train Accuracy: 67.14%, Test Loss: 0.9073, Test Accuracy: 68.35%\n",
      "Epoch [2299/2500], Train Loss: 0.7317, Train Accuracy: 66.43%, Test Loss: 0.8999, Test Accuracy: 67.09%\n",
      "Epoch [2300/2500], Train Loss: 0.6989, Train Accuracy: 68.42%, Test Loss: 0.9442, Test Accuracy: 62.03%\n",
      "Epoch [2301/2500], Train Loss: 0.7125, Train Accuracy: 69.84%, Test Loss: 0.9017, Test Accuracy: 64.56%\n",
      "Epoch [2302/2500], Train Loss: 0.7362, Train Accuracy: 69.42%, Test Loss: 0.9256, Test Accuracy: 64.56%\n",
      "Epoch [2303/2500], Train Loss: 0.7132, Train Accuracy: 67.71%, Test Loss: 0.9273, Test Accuracy: 62.03%\n",
      "Epoch [2304/2500], Train Loss: 0.7057, Train Accuracy: 69.84%, Test Loss: 0.9071, Test Accuracy: 63.29%\n",
      "Epoch [2305/2500], Train Loss: 0.7156, Train Accuracy: 68.28%, Test Loss: 0.8879, Test Accuracy: 68.35%\n",
      "Epoch [2306/2500], Train Loss: 0.7118, Train Accuracy: 68.42%, Test Loss: 0.9168, Test Accuracy: 64.56%\n",
      "Epoch [2307/2500], Train Loss: 0.7036, Train Accuracy: 68.56%, Test Loss: 0.9581, Test Accuracy: 62.03%\n",
      "Epoch [2308/2500], Train Loss: 0.7122, Train Accuracy: 67.85%, Test Loss: 0.8785, Test Accuracy: 67.09%\n",
      "Epoch [2309/2500], Train Loss: 0.7170, Train Accuracy: 68.85%, Test Loss: 0.8959, Test Accuracy: 67.09%\n",
      "Epoch [2310/2500], Train Loss: 0.7171, Train Accuracy: 67.43%, Test Loss: 0.8841, Test Accuracy: 70.89%\n",
      "Epoch [2311/2500], Train Loss: 0.7157, Train Accuracy: 69.84%, Test Loss: 0.9439, Test Accuracy: 63.29%\n",
      "Epoch [2312/2500], Train Loss: 0.7040, Train Accuracy: 68.85%, Test Loss: 0.8994, Test Accuracy: 67.09%\n",
      "Epoch [2313/2500], Train Loss: 0.6931, Train Accuracy: 67.85%, Test Loss: 0.8961, Test Accuracy: 67.09%\n",
      "Epoch [2314/2500], Train Loss: 0.7314, Train Accuracy: 69.42%, Test Loss: 0.8781, Test Accuracy: 67.09%\n",
      "Epoch [2315/2500], Train Loss: 0.7237, Train Accuracy: 67.99%, Test Loss: 0.9269, Test Accuracy: 62.03%\n",
      "Epoch [2316/2500], Train Loss: 0.7458, Train Accuracy: 67.99%, Test Loss: 0.9209, Test Accuracy: 62.03%\n",
      "Epoch [2317/2500], Train Loss: 0.7112, Train Accuracy: 69.42%, Test Loss: 0.8693, Test Accuracy: 69.62%\n",
      "Epoch [2318/2500], Train Loss: 0.7366, Train Accuracy: 65.72%, Test Loss: 0.8952, Test Accuracy: 64.56%\n",
      "Epoch [2319/2500], Train Loss: 0.7322, Train Accuracy: 67.99%, Test Loss: 0.9011, Test Accuracy: 64.56%\n",
      "Epoch [2320/2500], Train Loss: 0.7533, Train Accuracy: 66.15%, Test Loss: 0.9372, Test Accuracy: 62.03%\n",
      "Epoch [2321/2500], Train Loss: 0.7320, Train Accuracy: 67.71%, Test Loss: 0.8997, Test Accuracy: 63.29%\n",
      "Epoch [2322/2500], Train Loss: 0.7116, Train Accuracy: 67.57%, Test Loss: 0.9490, Test Accuracy: 60.76%\n",
      "Epoch [2323/2500], Train Loss: 0.7105, Train Accuracy: 68.42%, Test Loss: 0.9303, Test Accuracy: 63.29%\n",
      "Epoch [2324/2500], Train Loss: 0.7256, Train Accuracy: 69.13%, Test Loss: 0.9174, Test Accuracy: 64.56%\n",
      "Epoch [2325/2500], Train Loss: 0.7057, Train Accuracy: 67.85%, Test Loss: 0.9304, Test Accuracy: 62.03%\n",
      "Epoch [2326/2500], Train Loss: 0.7121, Train Accuracy: 68.56%, Test Loss: 0.8770, Test Accuracy: 67.09%\n",
      "Epoch [2327/2500], Train Loss: 0.7222, Train Accuracy: 69.42%, Test Loss: 0.9223, Test Accuracy: 62.03%\n",
      "Epoch [2328/2500], Train Loss: 0.7321, Train Accuracy: 68.42%, Test Loss: 0.8635, Test Accuracy: 69.62%\n",
      "Epoch [2329/2500], Train Loss: 0.7396, Train Accuracy: 67.71%, Test Loss: 0.8931, Test Accuracy: 63.29%\n",
      "Epoch [2330/2500], Train Loss: 0.7190, Train Accuracy: 68.14%, Test Loss: 0.9497, Test Accuracy: 62.03%\n",
      "Epoch [2331/2500], Train Loss: 0.6956, Train Accuracy: 69.70%, Test Loss: 0.8758, Test Accuracy: 69.62%\n",
      "Epoch [2332/2500], Train Loss: 0.7390, Train Accuracy: 67.28%, Test Loss: 0.8818, Test Accuracy: 67.09%\n",
      "Epoch [2333/2500], Train Loss: 0.7405, Train Accuracy: 65.72%, Test Loss: 0.9094, Test Accuracy: 63.29%\n",
      "Epoch [2334/2500], Train Loss: 0.7252, Train Accuracy: 68.56%, Test Loss: 0.9002, Test Accuracy: 63.29%\n",
      "Epoch [2335/2500], Train Loss: 0.7409, Train Accuracy: 67.14%, Test Loss: 0.9342, Test Accuracy: 62.03%\n",
      "Epoch [2336/2500], Train Loss: 0.7217, Train Accuracy: 67.28%, Test Loss: 0.8846, Test Accuracy: 67.09%\n",
      "Epoch [2337/2500], Train Loss: 0.7201, Train Accuracy: 68.56%, Test Loss: 0.8526, Test Accuracy: 69.62%\n",
      "Epoch [2338/2500], Train Loss: 0.7206, Train Accuracy: 69.99%, Test Loss: 0.9226, Test Accuracy: 62.03%\n",
      "Epoch [2339/2500], Train Loss: 0.7254, Train Accuracy: 67.99%, Test Loss: 0.8940, Test Accuracy: 64.56%\n",
      "Epoch [2340/2500], Train Loss: 0.7118, Train Accuracy: 68.99%, Test Loss: 0.9304, Test Accuracy: 63.29%\n",
      "Epoch [2341/2500], Train Loss: 0.7290, Train Accuracy: 67.00%, Test Loss: 0.9069, Test Accuracy: 63.29%\n",
      "Epoch [2342/2500], Train Loss: 0.7422, Train Accuracy: 68.85%, Test Loss: 0.8748, Test Accuracy: 67.09%\n",
      "Epoch [2343/2500], Train Loss: 0.7324, Train Accuracy: 67.99%, Test Loss: 0.8852, Test Accuracy: 67.09%\n",
      "Epoch [2344/2500], Train Loss: 0.7049, Train Accuracy: 66.71%, Test Loss: 0.8775, Test Accuracy: 65.82%\n",
      "Epoch [2345/2500], Train Loss: 0.7087, Train Accuracy: 69.56%, Test Loss: 0.8972, Test Accuracy: 62.03%\n",
      "Epoch [2346/2500], Train Loss: 0.7070, Train Accuracy: 68.85%, Test Loss: 0.8741, Test Accuracy: 67.09%\n",
      "Epoch [2347/2500], Train Loss: 0.7146, Train Accuracy: 68.85%, Test Loss: 0.8879, Test Accuracy: 65.82%\n",
      "Epoch [2348/2500], Train Loss: 0.7179, Train Accuracy: 68.28%, Test Loss: 0.8854, Test Accuracy: 65.82%\n",
      "Epoch [2349/2500], Train Loss: 0.7094, Train Accuracy: 67.85%, Test Loss: 0.9060, Test Accuracy: 63.29%\n",
      "Epoch [2350/2500], Train Loss: 0.7248, Train Accuracy: 67.14%, Test Loss: 0.8693, Test Accuracy: 68.35%\n",
      "Epoch [2351/2500], Train Loss: 0.7199, Train Accuracy: 67.99%, Test Loss: 0.9105, Test Accuracy: 62.03%\n",
      "Epoch [2352/2500], Train Loss: 0.7088, Train Accuracy: 70.13%, Test Loss: 0.8918, Test Accuracy: 64.56%\n",
      "Epoch [2353/2500], Train Loss: 0.7092, Train Accuracy: 69.42%, Test Loss: 0.9093, Test Accuracy: 63.29%\n",
      "Epoch [2354/2500], Train Loss: 0.7266, Train Accuracy: 67.85%, Test Loss: 0.8956, Test Accuracy: 62.03%\n",
      "Epoch [2355/2500], Train Loss: 0.7100, Train Accuracy: 68.14%, Test Loss: 0.8465, Test Accuracy: 69.62%\n",
      "Epoch [2356/2500], Train Loss: 0.7453, Train Accuracy: 66.57%, Test Loss: 0.8994, Test Accuracy: 64.56%\n",
      "Epoch [2357/2500], Train Loss: 0.7069, Train Accuracy: 69.56%, Test Loss: 0.9279, Test Accuracy: 62.03%\n",
      "Epoch [2358/2500], Train Loss: 0.6844, Train Accuracy: 70.98%, Test Loss: 0.9570, Test Accuracy: 60.76%\n",
      "Epoch [2359/2500], Train Loss: 0.7147, Train Accuracy: 68.42%, Test Loss: 0.9294, Test Accuracy: 62.03%\n",
      "Epoch [2360/2500], Train Loss: 0.7409, Train Accuracy: 69.27%, Test Loss: 0.8654, Test Accuracy: 69.62%\n",
      "Epoch [2361/2500], Train Loss: 0.7113, Train Accuracy: 68.85%, Test Loss: 0.9066, Test Accuracy: 62.03%\n",
      "Epoch [2362/2500], Train Loss: 0.7385, Train Accuracy: 66.43%, Test Loss: 0.8751, Test Accuracy: 69.62%\n",
      "Epoch [2363/2500], Train Loss: 0.7419, Train Accuracy: 67.85%, Test Loss: 0.8683, Test Accuracy: 69.62%\n",
      "Epoch [2364/2500], Train Loss: 0.7113, Train Accuracy: 68.42%, Test Loss: 0.9024, Test Accuracy: 65.82%\n",
      "Epoch [2365/2500], Train Loss: 0.6986, Train Accuracy: 70.41%, Test Loss: 0.8875, Test Accuracy: 67.09%\n",
      "Epoch [2366/2500], Train Loss: 0.7140, Train Accuracy: 67.99%, Test Loss: 0.9412, Test Accuracy: 63.29%\n",
      "Epoch [2367/2500], Train Loss: 0.7252, Train Accuracy: 67.71%, Test Loss: 0.8976, Test Accuracy: 63.29%\n",
      "Epoch [2368/2500], Train Loss: 0.7171, Train Accuracy: 68.28%, Test Loss: 0.8746, Test Accuracy: 69.62%\n",
      "Epoch [2369/2500], Train Loss: 0.7041, Train Accuracy: 69.42%, Test Loss: 0.9390, Test Accuracy: 63.29%\n",
      "Epoch [2370/2500], Train Loss: 0.7134, Train Accuracy: 67.57%, Test Loss: 0.9668, Test Accuracy: 63.29%\n",
      "Epoch [2371/2500], Train Loss: 0.7289, Train Accuracy: 68.28%, Test Loss: 0.8981, Test Accuracy: 67.09%\n",
      "Epoch [2372/2500], Train Loss: 0.6883, Train Accuracy: 69.13%, Test Loss: 0.8977, Test Accuracy: 67.09%\n",
      "Epoch [2373/2500], Train Loss: 0.7160, Train Accuracy: 67.28%, Test Loss: 0.9328, Test Accuracy: 63.29%\n",
      "Epoch [2374/2500], Train Loss: 0.7195, Train Accuracy: 67.14%, Test Loss: 0.9625, Test Accuracy: 62.03%\n",
      "Epoch [2375/2500], Train Loss: 0.6948, Train Accuracy: 70.13%, Test Loss: 0.9278, Test Accuracy: 62.03%\n",
      "Epoch [2376/2500], Train Loss: 0.7117, Train Accuracy: 69.13%, Test Loss: 0.9070, Test Accuracy: 64.56%\n",
      "Epoch [2377/2500], Train Loss: 0.7146, Train Accuracy: 67.99%, Test Loss: 0.9384, Test Accuracy: 62.03%\n",
      "Epoch [2378/2500], Train Loss: 0.7384, Train Accuracy: 68.42%, Test Loss: 0.9159, Test Accuracy: 63.29%\n",
      "Epoch [2379/2500], Train Loss: 0.7162, Train Accuracy: 69.13%, Test Loss: 0.8808, Test Accuracy: 63.29%\n",
      "Epoch [2380/2500], Train Loss: 0.7165, Train Accuracy: 67.99%, Test Loss: 0.9155, Test Accuracy: 63.29%\n",
      "Epoch [2381/2500], Train Loss: 0.7353, Train Accuracy: 67.28%, Test Loss: 0.9010, Test Accuracy: 64.56%\n",
      "Epoch [2382/2500], Train Loss: 0.7032, Train Accuracy: 67.99%, Test Loss: 0.8910, Test Accuracy: 67.09%\n",
      "Epoch [2383/2500], Train Loss: 0.7495, Train Accuracy: 67.00%, Test Loss: 0.8440, Test Accuracy: 70.89%\n",
      "Epoch [2384/2500], Train Loss: 0.7099, Train Accuracy: 69.42%, Test Loss: 0.8794, Test Accuracy: 68.35%\n",
      "Epoch [2385/2500], Train Loss: 0.7228, Train Accuracy: 68.14%, Test Loss: 0.8850, Test Accuracy: 65.82%\n",
      "Epoch [2386/2500], Train Loss: 0.7299, Train Accuracy: 68.14%, Test Loss: 0.9085, Test Accuracy: 63.29%\n",
      "Epoch [2387/2500], Train Loss: 0.7232, Train Accuracy: 69.84%, Test Loss: 0.8491, Test Accuracy: 69.62%\n",
      "Epoch [2388/2500], Train Loss: 0.7161, Train Accuracy: 67.00%, Test Loss: 0.9420, Test Accuracy: 63.29%\n",
      "Epoch [2389/2500], Train Loss: 0.7193, Train Accuracy: 69.27%, Test Loss: 0.8945, Test Accuracy: 64.56%\n",
      "Epoch [2390/2500], Train Loss: 0.7047, Train Accuracy: 69.13%, Test Loss: 0.8855, Test Accuracy: 64.56%\n",
      "Epoch [2391/2500], Train Loss: 0.7328, Train Accuracy: 68.71%, Test Loss: 0.8607, Test Accuracy: 68.35%\n",
      "Epoch [2392/2500], Train Loss: 0.6983, Train Accuracy: 70.84%, Test Loss: 0.9119, Test Accuracy: 63.29%\n",
      "Epoch [2393/2500], Train Loss: 0.6971, Train Accuracy: 68.99%, Test Loss: 0.8892, Test Accuracy: 63.29%\n",
      "Epoch [2394/2500], Train Loss: 0.7176, Train Accuracy: 68.56%, Test Loss: 0.9080, Test Accuracy: 63.29%\n",
      "Epoch [2395/2500], Train Loss: 0.7094, Train Accuracy: 68.28%, Test Loss: 0.8663, Test Accuracy: 70.89%\n",
      "Epoch [2396/2500], Train Loss: 0.6945, Train Accuracy: 70.41%, Test Loss: 0.9262, Test Accuracy: 64.56%\n",
      "Epoch [2397/2500], Train Loss: 0.7263, Train Accuracy: 66.86%, Test Loss: 0.9269, Test Accuracy: 62.03%\n",
      "Epoch [2398/2500], Train Loss: 0.7274, Train Accuracy: 67.85%, Test Loss: 0.8825, Test Accuracy: 65.82%\n",
      "Epoch [2399/2500], Train Loss: 0.6885, Train Accuracy: 70.70%, Test Loss: 0.9568, Test Accuracy: 63.29%\n",
      "Epoch [2400/2500], Train Loss: 0.7331, Train Accuracy: 68.56%, Test Loss: 0.9714, Test Accuracy: 62.03%\n",
      "Epoch [2401/2500], Train Loss: 0.7327, Train Accuracy: 68.71%, Test Loss: 0.9159, Test Accuracy: 63.29%\n",
      "Epoch [2402/2500], Train Loss: 0.7254, Train Accuracy: 67.28%, Test Loss: 0.9192, Test Accuracy: 63.29%\n",
      "Epoch [2403/2500], Train Loss: 0.7139, Train Accuracy: 68.85%, Test Loss: 0.9135, Test Accuracy: 62.03%\n",
      "Epoch [2404/2500], Train Loss: 0.7110, Train Accuracy: 68.85%, Test Loss: 0.8652, Test Accuracy: 69.62%\n",
      "Epoch [2405/2500], Train Loss: 0.7106, Train Accuracy: 68.28%, Test Loss: 0.8952, Test Accuracy: 67.09%\n",
      "Epoch [2406/2500], Train Loss: 0.7115, Train Accuracy: 69.84%, Test Loss: 0.9212, Test Accuracy: 63.29%\n",
      "Epoch [2407/2500], Train Loss: 0.7388, Train Accuracy: 66.43%, Test Loss: 0.9103, Test Accuracy: 62.03%\n",
      "Epoch [2408/2500], Train Loss: 0.7186, Train Accuracy: 68.99%, Test Loss: 0.9048, Test Accuracy: 63.29%\n",
      "Epoch [2409/2500], Train Loss: 0.6970, Train Accuracy: 69.70%, Test Loss: 0.9106, Test Accuracy: 64.56%\n",
      "Epoch [2410/2500], Train Loss: 0.6994, Train Accuracy: 69.27%, Test Loss: 0.9428, Test Accuracy: 63.29%\n",
      "Epoch [2411/2500], Train Loss: 0.7140, Train Accuracy: 68.14%, Test Loss: 0.9272, Test Accuracy: 64.56%\n",
      "Epoch [2412/2500], Train Loss: 0.7140, Train Accuracy: 68.71%, Test Loss: 0.9018, Test Accuracy: 63.29%\n",
      "Epoch [2413/2500], Train Loss: 0.6925, Train Accuracy: 70.13%, Test Loss: 0.9387, Test Accuracy: 62.03%\n",
      "Epoch [2414/2500], Train Loss: 0.6945, Train Accuracy: 70.70%, Test Loss: 0.8691, Test Accuracy: 69.62%\n",
      "Epoch [2415/2500], Train Loss: 0.7128, Train Accuracy: 67.85%, Test Loss: 0.9062, Test Accuracy: 63.29%\n",
      "Epoch [2416/2500], Train Loss: 0.7216, Train Accuracy: 69.56%, Test Loss: 0.9018, Test Accuracy: 64.56%\n",
      "Epoch [2417/2500], Train Loss: 0.7190, Train Accuracy: 68.14%, Test Loss: 0.9001, Test Accuracy: 68.35%\n",
      "Epoch [2418/2500], Train Loss: 0.6883, Train Accuracy: 70.27%, Test Loss: 0.9066, Test Accuracy: 64.56%\n",
      "Epoch [2419/2500], Train Loss: 0.7357, Train Accuracy: 68.28%, Test Loss: 0.9478, Test Accuracy: 63.29%\n",
      "Epoch [2420/2500], Train Loss: 0.7262, Train Accuracy: 67.57%, Test Loss: 0.8539, Test Accuracy: 69.62%\n",
      "Epoch [2421/2500], Train Loss: 0.7021, Train Accuracy: 69.84%, Test Loss: 0.9264, Test Accuracy: 63.29%\n",
      "Epoch [2422/2500], Train Loss: 0.7153, Train Accuracy: 69.70%, Test Loss: 0.8995, Test Accuracy: 63.29%\n",
      "Epoch [2423/2500], Train Loss: 0.7308, Train Accuracy: 67.57%, Test Loss: 0.9146, Test Accuracy: 64.56%\n",
      "Epoch [2424/2500], Train Loss: 0.7324, Train Accuracy: 67.43%, Test Loss: 0.9392, Test Accuracy: 63.29%\n",
      "Epoch [2425/2500], Train Loss: 0.7432, Train Accuracy: 67.85%, Test Loss: 0.8916, Test Accuracy: 64.56%\n",
      "Epoch [2426/2500], Train Loss: 0.7131, Train Accuracy: 68.71%, Test Loss: 0.8885, Test Accuracy: 63.29%\n",
      "Epoch [2427/2500], Train Loss: 0.7117, Train Accuracy: 68.56%, Test Loss: 0.8705, Test Accuracy: 69.62%\n",
      "Epoch [2428/2500], Train Loss: 0.7019, Train Accuracy: 68.28%, Test Loss: 0.9064, Test Accuracy: 64.56%\n",
      "Epoch [2429/2500], Train Loss: 0.7143, Train Accuracy: 68.85%, Test Loss: 0.8881, Test Accuracy: 67.09%\n",
      "Epoch [2430/2500], Train Loss: 0.7045, Train Accuracy: 67.43%, Test Loss: 0.9241, Test Accuracy: 63.29%\n",
      "Epoch [2431/2500], Train Loss: 0.7198, Train Accuracy: 68.71%, Test Loss: 0.9245, Test Accuracy: 64.56%\n",
      "Epoch [2432/2500], Train Loss: 0.7315, Train Accuracy: 69.13%, Test Loss: 0.9069, Test Accuracy: 64.56%\n",
      "Epoch [2433/2500], Train Loss: 0.7052, Train Accuracy: 68.71%, Test Loss: 0.9034, Test Accuracy: 64.56%\n",
      "Epoch [2434/2500], Train Loss: 0.6970, Train Accuracy: 71.27%, Test Loss: 0.9363, Test Accuracy: 62.03%\n",
      "Epoch [2435/2500], Train Loss: 0.7129, Train Accuracy: 68.42%, Test Loss: 0.9580, Test Accuracy: 62.03%\n",
      "Epoch [2436/2500], Train Loss: 0.7177, Train Accuracy: 68.56%, Test Loss: 0.9023, Test Accuracy: 62.03%\n",
      "Epoch [2437/2500], Train Loss: 0.7017, Train Accuracy: 69.27%, Test Loss: 0.9215, Test Accuracy: 63.29%\n",
      "Epoch [2438/2500], Train Loss: 0.7075, Train Accuracy: 69.99%, Test Loss: 0.9371, Test Accuracy: 63.29%\n",
      "Epoch [2439/2500], Train Loss: 0.7042, Train Accuracy: 69.70%, Test Loss: 0.8826, Test Accuracy: 67.09%\n",
      "Epoch [2440/2500], Train Loss: 0.7033, Train Accuracy: 68.71%, Test Loss: 0.9014, Test Accuracy: 65.82%\n",
      "Epoch [2441/2500], Train Loss: 0.7169, Train Accuracy: 68.71%, Test Loss: 0.9386, Test Accuracy: 64.56%\n",
      "Epoch [2442/2500], Train Loss: 0.7078, Train Accuracy: 68.56%, Test Loss: 0.8575, Test Accuracy: 72.15%\n",
      "Epoch [2443/2500], Train Loss: 0.7172, Train Accuracy: 67.85%, Test Loss: 0.9064, Test Accuracy: 63.29%\n",
      "Epoch [2444/2500], Train Loss: 0.7042, Train Accuracy: 68.42%, Test Loss: 0.8983, Test Accuracy: 63.29%\n",
      "Epoch [2445/2500], Train Loss: 0.7141, Train Accuracy: 69.27%, Test Loss: 0.9583, Test Accuracy: 62.03%\n",
      "Epoch [2446/2500], Train Loss: 0.7189, Train Accuracy: 68.42%, Test Loss: 0.9564, Test Accuracy: 62.03%\n",
      "Epoch [2447/2500], Train Loss: 0.6992, Train Accuracy: 70.27%, Test Loss: 0.9170, Test Accuracy: 63.29%\n",
      "Epoch [2448/2500], Train Loss: 0.7172, Train Accuracy: 68.56%, Test Loss: 0.9024, Test Accuracy: 64.56%\n",
      "Epoch [2449/2500], Train Loss: 0.6954, Train Accuracy: 68.85%, Test Loss: 0.9291, Test Accuracy: 64.56%\n",
      "Epoch [2450/2500], Train Loss: 0.7010, Train Accuracy: 66.57%, Test Loss: 0.9072, Test Accuracy: 63.29%\n",
      "Epoch [2451/2500], Train Loss: 0.7048, Train Accuracy: 70.98%, Test Loss: 0.9022, Test Accuracy: 64.56%\n",
      "Epoch [2452/2500], Train Loss: 0.6856, Train Accuracy: 70.41%, Test Loss: 0.8961, Test Accuracy: 64.56%\n",
      "Epoch [2453/2500], Train Loss: 0.7131, Train Accuracy: 69.56%, Test Loss: 0.8556, Test Accuracy: 70.89%\n",
      "Epoch [2454/2500], Train Loss: 0.7033, Train Accuracy: 69.56%, Test Loss: 0.9499, Test Accuracy: 63.29%\n",
      "Epoch [2455/2500], Train Loss: 0.7014, Train Accuracy: 70.27%, Test Loss: 0.8708, Test Accuracy: 67.09%\n",
      "Epoch [2456/2500], Train Loss: 0.6841, Train Accuracy: 69.99%, Test Loss: 0.9156, Test Accuracy: 67.09%\n",
      "Epoch [2457/2500], Train Loss: 0.6839, Train Accuracy: 71.83%, Test Loss: 0.9388, Test Accuracy: 64.56%\n",
      "Epoch [2458/2500], Train Loss: 0.7137, Train Accuracy: 68.99%, Test Loss: 0.9246, Test Accuracy: 65.82%\n",
      "Epoch [2459/2500], Train Loss: 0.7168, Train Accuracy: 66.43%, Test Loss: 0.9394, Test Accuracy: 63.29%\n",
      "Epoch [2460/2500], Train Loss: 0.7107, Train Accuracy: 70.13%, Test Loss: 0.8557, Test Accuracy: 70.89%\n",
      "Epoch [2461/2500], Train Loss: 0.7137, Train Accuracy: 69.70%, Test Loss: 0.9321, Test Accuracy: 64.56%\n",
      "Epoch [2462/2500], Train Loss: 0.6769, Train Accuracy: 68.71%, Test Loss: 0.8909, Test Accuracy: 65.82%\n",
      "Epoch [2463/2500], Train Loss: 0.6986, Train Accuracy: 69.13%, Test Loss: 0.8836, Test Accuracy: 64.56%\n",
      "Epoch [2464/2500], Train Loss: 0.7220, Train Accuracy: 67.71%, Test Loss: 0.8949, Test Accuracy: 64.56%\n",
      "Epoch [2465/2500], Train Loss: 0.7079, Train Accuracy: 69.56%, Test Loss: 0.8894, Test Accuracy: 67.09%\n",
      "Epoch [2466/2500], Train Loss: 0.7343, Train Accuracy: 66.57%, Test Loss: 0.8870, Test Accuracy: 65.82%\n",
      "Epoch [2467/2500], Train Loss: 0.6729, Train Accuracy: 71.12%, Test Loss: 0.9263, Test Accuracy: 65.82%\n",
      "Epoch [2468/2500], Train Loss: 0.7189, Train Accuracy: 68.56%, Test Loss: 0.9469, Test Accuracy: 64.56%\n",
      "Epoch [2469/2500], Train Loss: 0.7133, Train Accuracy: 68.71%, Test Loss: 0.8759, Test Accuracy: 67.09%\n",
      "Epoch [2470/2500], Train Loss: 0.7089, Train Accuracy: 68.56%, Test Loss: 0.8929, Test Accuracy: 65.82%\n",
      "Epoch [2471/2500], Train Loss: 0.7100, Train Accuracy: 68.28%, Test Loss: 0.8966, Test Accuracy: 67.09%\n",
      "Epoch [2472/2500], Train Loss: 0.6791, Train Accuracy: 68.99%, Test Loss: 0.8952, Test Accuracy: 65.82%\n",
      "Epoch [2473/2500], Train Loss: 0.7042, Train Accuracy: 68.85%, Test Loss: 0.8716, Test Accuracy: 70.89%\n",
      "Epoch [2474/2500], Train Loss: 0.6929, Train Accuracy: 69.56%, Test Loss: 0.9008, Test Accuracy: 63.29%\n",
      "Epoch [2475/2500], Train Loss: 0.7010, Train Accuracy: 69.70%, Test Loss: 0.9421, Test Accuracy: 60.76%\n",
      "Epoch [2476/2500], Train Loss: 0.7088, Train Accuracy: 69.27%, Test Loss: 0.9463, Test Accuracy: 62.03%\n",
      "Epoch [2477/2500], Train Loss: 0.6877, Train Accuracy: 69.99%, Test Loss: 0.9636, Test Accuracy: 62.03%\n",
      "Epoch [2478/2500], Train Loss: 0.6972, Train Accuracy: 69.42%, Test Loss: 0.8888, Test Accuracy: 67.09%\n",
      "Epoch [2479/2500], Train Loss: 0.6793, Train Accuracy: 71.27%, Test Loss: 0.9390, Test Accuracy: 63.29%\n",
      "Epoch [2480/2500], Train Loss: 0.7053, Train Accuracy: 69.70%, Test Loss: 0.8791, Test Accuracy: 68.35%\n",
      "Epoch [2481/2500], Train Loss: 0.6971, Train Accuracy: 68.71%, Test Loss: 0.9490, Test Accuracy: 60.76%\n",
      "Epoch [2482/2500], Train Loss: 0.7003, Train Accuracy: 68.14%, Test Loss: 0.8936, Test Accuracy: 65.82%\n",
      "Epoch [2483/2500], Train Loss: 0.7178, Train Accuracy: 69.42%, Test Loss: 0.8991, Test Accuracy: 67.09%\n",
      "Epoch [2484/2500], Train Loss: 0.7125, Train Accuracy: 67.85%, Test Loss: 0.8814, Test Accuracy: 68.35%\n",
      "Epoch [2485/2500], Train Loss: 0.6877, Train Accuracy: 69.13%, Test Loss: 0.9294, Test Accuracy: 63.29%\n",
      "Epoch [2486/2500], Train Loss: 0.7126, Train Accuracy: 69.27%, Test Loss: 0.8987, Test Accuracy: 65.82%\n",
      "Epoch [2487/2500], Train Loss: 0.7414, Train Accuracy: 68.28%, Test Loss: 0.9079, Test Accuracy: 64.56%\n",
      "Epoch [2488/2500], Train Loss: 0.7113, Train Accuracy: 69.99%, Test Loss: 0.8894, Test Accuracy: 65.82%\n",
      "Epoch [2489/2500], Train Loss: 0.6918, Train Accuracy: 69.70%, Test Loss: 0.9162, Test Accuracy: 62.03%\n",
      "Epoch [2490/2500], Train Loss: 0.7025, Train Accuracy: 69.56%, Test Loss: 0.9049, Test Accuracy: 62.03%\n",
      "Epoch [2491/2500], Train Loss: 0.7095, Train Accuracy: 68.85%, Test Loss: 0.8999, Test Accuracy: 63.29%\n",
      "Epoch [2492/2500], Train Loss: 0.7156, Train Accuracy: 69.70%, Test Loss: 0.8983, Test Accuracy: 64.56%\n",
      "Epoch [2493/2500], Train Loss: 0.7145, Train Accuracy: 68.14%, Test Loss: 0.8976, Test Accuracy: 63.29%\n",
      "Epoch [2494/2500], Train Loss: 0.6965, Train Accuracy: 70.13%, Test Loss: 0.9044, Test Accuracy: 63.29%\n",
      "Epoch [2495/2500], Train Loss: 0.7215, Train Accuracy: 68.85%, Test Loss: 0.9022, Test Accuracy: 63.29%\n",
      "Epoch [2496/2500], Train Loss: 0.7049, Train Accuracy: 68.56%, Test Loss: 0.9034, Test Accuracy: 63.29%\n",
      "Epoch [2497/2500], Train Loss: 0.6903, Train Accuracy: 71.41%, Test Loss: 0.8580, Test Accuracy: 70.89%\n",
      "Epoch [2498/2500], Train Loss: 0.7012, Train Accuracy: 69.42%, Test Loss: 0.9016, Test Accuracy: 64.56%\n",
      "Epoch [2499/2500], Train Loss: 0.7344, Train Accuracy: 68.28%, Test Loss: 0.8913, Test Accuracy: 64.56%\n",
      "Epoch [2500/2500], Train Loss: 0.6998, Train Accuracy: 68.42%, Test Loss: 0.8983, Test Accuracy: 65.82%\n",
      "model_cnn1dlstm_att saved as model_cnn1dlstm_att_4class_best.pth\n",
      "\n",
      "Metrics for model_cnn1dlstm_att saved as model_cnn1dlstm_att_4class_metrics.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD, Adam\n",
    "\n",
    "# Loop through each model in the model_list\n",
    "for model_name, model_class in model_1D.items():\n",
    "    print(f\"Training {model_name}\")\n",
    "\n",
    "    # Initialize the model and move it to the device\n",
    "    model = model_class(input_size=input_size, num_classes=num_classes).to(DEVICE)\n",
    "    optimizer = SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Metrics storage\n",
    "    metrics = {\n",
    "        \"epoch\": [],\n",
    "        \"train_loss\": [],\n",
    "        \"train_accuracy\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_accuracy\": []\n",
    "    }\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for inputs, labels in train_loader:  \n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)  \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Calculate training accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "        # Model Evaluation (on the test set)\n",
    "        model.eval()\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:  # Assume test_loader is already defined\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "        avg_val_loss = running_val_loss / len(test_loader)\n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "        # Print metrics for each epoch\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Test Loss: {avg_val_loss:.4f}, Test Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "        # Save metrics to dictionary\n",
    "        metrics[\"epoch\"].append(epoch + 1)\n",
    "        metrics[\"train_loss\"].append(avg_train_loss)\n",
    "        metrics[\"train_accuracy\"].append(train_accuracy)\n",
    "        metrics[\"test_loss\"].append(avg_val_loss)\n",
    "        metrics[\"test_accuracy\"].append(val_accuracy)\n",
    "\n",
    "    # Save the model (optional)\n",
    "    torch.save(model.state_dict(), f\"{model_name}_{mapping_object}_best.pth\")\n",
    "    print(f\"{model_name} saved as {model_name}_{mapping_object}_best.pth\\n\")\n",
    "\n",
    "    # Save the metrics to a CSV file\n",
    "    df = pd.DataFrame(metrics)\n",
    "    df.to_csv(f\"{model_name}_{mapping_object}_metrics.csv\", index=False)\n",
    "    print(f\"Metrics for {model_name} saved as {model_name}_{mapping_object}_metrics.csv\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model_cnn2d\n",
      "Epoch [1/2500], Train Loss: 1.4341, Train Accuracy: 39.69%, Test Loss: 1.2580, Test Accuracy: 49.37%\n",
      "Epoch [2/2500], Train Loss: 1.2616, Train Accuracy: 46.51%, Test Loss: 1.3211, Test Accuracy: 49.37%\n",
      "Epoch [3/2500], Train Loss: 1.2427, Train Accuracy: 50.64%, Test Loss: 1.0626, Test Accuracy: 58.23%\n",
      "Epoch [4/2500], Train Loss: 1.2436, Train Accuracy: 48.22%, Test Loss: 0.9817, Test Accuracy: 56.96%\n",
      "Epoch [5/2500], Train Loss: 1.2314, Train Accuracy: 50.21%, Test Loss: 1.2870, Test Accuracy: 48.10%\n",
      "Epoch [6/2500], Train Loss: 1.2085, Train Accuracy: 49.79%, Test Loss: 1.0182, Test Accuracy: 56.96%\n",
      "Epoch [7/2500], Train Loss: 1.2184, Train Accuracy: 50.07%, Test Loss: 1.2408, Test Accuracy: 44.30%\n",
      "Epoch [8/2500], Train Loss: 1.1865, Train Accuracy: 52.20%, Test Loss: 1.0578, Test Accuracy: 62.03%\n",
      "Epoch [9/2500], Train Loss: 1.1710, Train Accuracy: 50.78%, Test Loss: 1.1902, Test Accuracy: 58.23%\n",
      "Epoch [10/2500], Train Loss: 1.1103, Train Accuracy: 53.77%, Test Loss: 1.1842, Test Accuracy: 54.43%\n",
      "Epoch [11/2500], Train Loss: 1.1522, Train Accuracy: 52.77%, Test Loss: 1.1752, Test Accuracy: 53.16%\n",
      "Epoch [12/2500], Train Loss: 1.1384, Train Accuracy: 54.05%, Test Loss: 1.0087, Test Accuracy: 60.76%\n",
      "Epoch [13/2500], Train Loss: 1.1505, Train Accuracy: 55.19%, Test Loss: 0.9478, Test Accuracy: 56.96%\n",
      "Epoch [14/2500], Train Loss: 1.1289, Train Accuracy: 54.77%, Test Loss: 1.1111, Test Accuracy: 59.49%\n",
      "Epoch [15/2500], Train Loss: 1.1265, Train Accuracy: 53.06%, Test Loss: 1.0186, Test Accuracy: 56.96%\n",
      "Epoch [16/2500], Train Loss: 1.1205, Train Accuracy: 53.34%, Test Loss: 1.0426, Test Accuracy: 60.76%\n",
      "Epoch [17/2500], Train Loss: 1.0777, Train Accuracy: 55.76%, Test Loss: 0.9706, Test Accuracy: 55.70%\n",
      "Epoch [18/2500], Train Loss: 1.1291, Train Accuracy: 54.91%, Test Loss: 1.2687, Test Accuracy: 55.70%\n",
      "Epoch [19/2500], Train Loss: 1.1174, Train Accuracy: 54.91%, Test Loss: 0.9404, Test Accuracy: 59.49%\n",
      "Epoch [20/2500], Train Loss: 1.1034, Train Accuracy: 54.62%, Test Loss: 0.9307, Test Accuracy: 59.49%\n",
      "Epoch [21/2500], Train Loss: 1.0921, Train Accuracy: 54.62%, Test Loss: 1.0260, Test Accuracy: 58.23%\n",
      "Epoch [22/2500], Train Loss: 1.0948, Train Accuracy: 57.47%, Test Loss: 1.0597, Test Accuracy: 64.56%\n",
      "Epoch [23/2500], Train Loss: 1.0879, Train Accuracy: 54.62%, Test Loss: 0.9521, Test Accuracy: 59.49%\n",
      "Epoch [24/2500], Train Loss: 1.1137, Train Accuracy: 56.33%, Test Loss: 0.9271, Test Accuracy: 62.03%\n",
      "Epoch [25/2500], Train Loss: 1.1203, Train Accuracy: 53.91%, Test Loss: 1.2766, Test Accuracy: 46.84%\n",
      "Epoch [26/2500], Train Loss: 1.0828, Train Accuracy: 55.05%, Test Loss: 1.2079, Test Accuracy: 49.37%\n",
      "Epoch [27/2500], Train Loss: 1.1036, Train Accuracy: 54.48%, Test Loss: 1.3742, Test Accuracy: 53.16%\n",
      "Epoch [28/2500], Train Loss: 1.0776, Train Accuracy: 56.33%, Test Loss: 0.9144, Test Accuracy: 63.29%\n",
      "Epoch [29/2500], Train Loss: 1.0746, Train Accuracy: 57.04%, Test Loss: 1.0949, Test Accuracy: 64.56%\n",
      "Epoch [30/2500], Train Loss: 1.0414, Train Accuracy: 59.17%, Test Loss: 1.0996, Test Accuracy: 58.23%\n",
      "Epoch [31/2500], Train Loss: 1.0534, Train Accuracy: 58.04%, Test Loss: 1.0595, Test Accuracy: 55.70%\n",
      "Epoch [32/2500], Train Loss: 1.0963, Train Accuracy: 54.20%, Test Loss: 0.8811, Test Accuracy: 62.03%\n",
      "Epoch [33/2500], Train Loss: 1.0663, Train Accuracy: 57.18%, Test Loss: 0.8886, Test Accuracy: 60.76%\n",
      "Epoch [34/2500], Train Loss: 1.1191, Train Accuracy: 53.49%, Test Loss: 1.0873, Test Accuracy: 62.03%\n",
      "Epoch [35/2500], Train Loss: 1.0201, Train Accuracy: 58.89%, Test Loss: 0.9637, Test Accuracy: 59.49%\n",
      "Epoch [36/2500], Train Loss: 1.0631, Train Accuracy: 56.90%, Test Loss: 0.8865, Test Accuracy: 62.03%\n",
      "Epoch [37/2500], Train Loss: 1.0528, Train Accuracy: 57.04%, Test Loss: 0.8815, Test Accuracy: 64.56%\n",
      "Epoch [38/2500], Train Loss: 1.0937, Train Accuracy: 55.62%, Test Loss: 0.8777, Test Accuracy: 60.76%\n",
      "Epoch [39/2500], Train Loss: 1.0714, Train Accuracy: 55.76%, Test Loss: 0.8925, Test Accuracy: 60.76%\n",
      "Epoch [40/2500], Train Loss: 1.0286, Train Accuracy: 56.76%, Test Loss: 1.0832, Test Accuracy: 63.29%\n",
      "Epoch [41/2500], Train Loss: 1.1000, Train Accuracy: 54.05%, Test Loss: 1.0216, Test Accuracy: 64.56%\n",
      "Epoch [42/2500], Train Loss: 1.0105, Train Accuracy: 57.04%, Test Loss: 0.9719, Test Accuracy: 64.56%\n",
      "Epoch [43/2500], Train Loss: 1.0813, Train Accuracy: 55.48%, Test Loss: 1.2569, Test Accuracy: 55.70%\n",
      "Epoch [44/2500], Train Loss: 1.0498, Train Accuracy: 56.19%, Test Loss: 0.9151, Test Accuracy: 64.56%\n",
      "Epoch [45/2500], Train Loss: 1.0892, Train Accuracy: 54.91%, Test Loss: 1.1433, Test Accuracy: 56.96%\n",
      "Epoch [46/2500], Train Loss: 1.0449, Train Accuracy: 57.33%, Test Loss: 0.9608, Test Accuracy: 64.56%\n",
      "Epoch [47/2500], Train Loss: 1.0138, Train Accuracy: 58.32%, Test Loss: 0.9639, Test Accuracy: 63.29%\n",
      "Epoch [48/2500], Train Loss: 1.0245, Train Accuracy: 58.32%, Test Loss: 0.9258, Test Accuracy: 64.56%\n",
      "Epoch [49/2500], Train Loss: 1.0301, Train Accuracy: 57.47%, Test Loss: 0.9746, Test Accuracy: 62.03%\n",
      "Epoch [50/2500], Train Loss: 1.0609, Train Accuracy: 57.47%, Test Loss: 1.1696, Test Accuracy: 53.16%\n",
      "Epoch [51/2500], Train Loss: 1.0509, Train Accuracy: 57.04%, Test Loss: 0.9150, Test Accuracy: 59.49%\n",
      "Epoch [52/2500], Train Loss: 1.0433, Train Accuracy: 58.32%, Test Loss: 1.0421, Test Accuracy: 60.76%\n",
      "Epoch [53/2500], Train Loss: 0.9970, Train Accuracy: 59.03%, Test Loss: 0.8938, Test Accuracy: 64.56%\n",
      "Epoch [54/2500], Train Loss: 1.0117, Train Accuracy: 56.76%, Test Loss: 0.9619, Test Accuracy: 62.03%\n",
      "Epoch [55/2500], Train Loss: 1.0330, Train Accuracy: 56.33%, Test Loss: 0.9171, Test Accuracy: 59.49%\n",
      "Epoch [56/2500], Train Loss: 1.0450, Train Accuracy: 57.33%, Test Loss: 0.9858, Test Accuracy: 53.16%\n",
      "Epoch [57/2500], Train Loss: 0.9806, Train Accuracy: 60.46%, Test Loss: 1.1250, Test Accuracy: 54.43%\n",
      "Epoch [58/2500], Train Loss: 1.0254, Train Accuracy: 57.89%, Test Loss: 0.9286, Test Accuracy: 60.76%\n",
      "Epoch [59/2500], Train Loss: 1.0175, Train Accuracy: 56.90%, Test Loss: 1.0800, Test Accuracy: 56.96%\n",
      "Epoch [60/2500], Train Loss: 1.0218, Train Accuracy: 58.61%, Test Loss: 0.8533, Test Accuracy: 62.03%\n",
      "Epoch [61/2500], Train Loss: 1.0359, Train Accuracy: 57.89%, Test Loss: 0.9727, Test Accuracy: 60.76%\n",
      "Epoch [62/2500], Train Loss: 1.0293, Train Accuracy: 57.18%, Test Loss: 0.9311, Test Accuracy: 63.29%\n",
      "Epoch [63/2500], Train Loss: 0.9998, Train Accuracy: 59.03%, Test Loss: 0.8483, Test Accuracy: 63.29%\n",
      "Epoch [64/2500], Train Loss: 1.0024, Train Accuracy: 60.17%, Test Loss: 0.8585, Test Accuracy: 65.82%\n",
      "Epoch [65/2500], Train Loss: 1.0555, Train Accuracy: 56.90%, Test Loss: 0.8631, Test Accuracy: 62.03%\n",
      "Epoch [66/2500], Train Loss: 1.0805, Train Accuracy: 54.62%, Test Loss: 0.8905, Test Accuracy: 60.76%\n",
      "Epoch [67/2500], Train Loss: 0.9786, Train Accuracy: 59.17%, Test Loss: 0.9906, Test Accuracy: 55.70%\n",
      "Epoch [68/2500], Train Loss: 0.9996, Train Accuracy: 57.75%, Test Loss: 0.9298, Test Accuracy: 68.35%\n",
      "Epoch [69/2500], Train Loss: 1.0374, Train Accuracy: 55.19%, Test Loss: 0.9287, Test Accuracy: 60.76%\n",
      "Epoch [70/2500], Train Loss: 0.9893, Train Accuracy: 58.61%, Test Loss: 0.9670, Test Accuracy: 68.35%\n",
      "Epoch [71/2500], Train Loss: 0.9905, Train Accuracy: 58.18%, Test Loss: 0.9062, Test Accuracy: 62.03%\n",
      "Epoch [72/2500], Train Loss: 0.9825, Train Accuracy: 58.32%, Test Loss: 0.8698, Test Accuracy: 65.82%\n",
      "Epoch [73/2500], Train Loss: 1.0157, Train Accuracy: 57.89%, Test Loss: 1.0185, Test Accuracy: 60.76%\n",
      "Epoch [74/2500], Train Loss: 0.9846, Train Accuracy: 58.32%, Test Loss: 0.8430, Test Accuracy: 67.09%\n",
      "Epoch [75/2500], Train Loss: 0.9846, Train Accuracy: 59.89%, Test Loss: 0.8339, Test Accuracy: 62.03%\n",
      "Epoch [76/2500], Train Loss: 0.9677, Train Accuracy: 59.46%, Test Loss: 0.9235, Test Accuracy: 62.03%\n",
      "Epoch [77/2500], Train Loss: 1.0389, Train Accuracy: 56.47%, Test Loss: 0.8421, Test Accuracy: 67.09%\n",
      "Epoch [78/2500], Train Loss: 0.9994, Train Accuracy: 58.04%, Test Loss: 0.9163, Test Accuracy: 65.82%\n",
      "Epoch [79/2500], Train Loss: 0.9969, Train Accuracy: 57.04%, Test Loss: 1.0574, Test Accuracy: 58.23%\n",
      "Epoch [80/2500], Train Loss: 1.0014, Train Accuracy: 58.04%, Test Loss: 0.8803, Test Accuracy: 59.49%\n",
      "Epoch [81/2500], Train Loss: 1.0032, Train Accuracy: 59.17%, Test Loss: 0.8609, Test Accuracy: 64.56%\n",
      "Epoch [82/2500], Train Loss: 0.9876, Train Accuracy: 60.46%, Test Loss: 0.8502, Test Accuracy: 64.56%\n",
      "Epoch [83/2500], Train Loss: 0.9956, Train Accuracy: 59.46%, Test Loss: 0.9114, Test Accuracy: 65.82%\n",
      "Epoch [84/2500], Train Loss: 1.0248, Train Accuracy: 56.90%, Test Loss: 0.9376, Test Accuracy: 64.56%\n",
      "Epoch [85/2500], Train Loss: 0.9950, Train Accuracy: 58.46%, Test Loss: 0.9461, Test Accuracy: 63.29%\n",
      "Epoch [86/2500], Train Loss: 0.9979, Train Accuracy: 58.61%, Test Loss: 0.9095, Test Accuracy: 62.03%\n",
      "Epoch [87/2500], Train Loss: 0.9872, Train Accuracy: 58.46%, Test Loss: 1.0236, Test Accuracy: 59.49%\n",
      "Epoch [88/2500], Train Loss: 1.0112, Train Accuracy: 59.89%, Test Loss: 0.8795, Test Accuracy: 63.29%\n",
      "Epoch [89/2500], Train Loss: 1.0019, Train Accuracy: 59.74%, Test Loss: 0.9081, Test Accuracy: 60.76%\n",
      "Epoch [90/2500], Train Loss: 0.9990, Train Accuracy: 58.75%, Test Loss: 0.8753, Test Accuracy: 65.82%\n",
      "Epoch [91/2500], Train Loss: 0.9722, Train Accuracy: 58.89%, Test Loss: 0.9253, Test Accuracy: 59.49%\n",
      "Epoch [92/2500], Train Loss: 1.0162, Train Accuracy: 58.18%, Test Loss: 0.8467, Test Accuracy: 62.03%\n",
      "Epoch [93/2500], Train Loss: 0.9718, Train Accuracy: 59.46%, Test Loss: 0.9211, Test Accuracy: 65.82%\n",
      "Epoch [94/2500], Train Loss: 0.9667, Train Accuracy: 59.46%, Test Loss: 0.8957, Test Accuracy: 62.03%\n",
      "Epoch [95/2500], Train Loss: 0.9755, Train Accuracy: 60.60%, Test Loss: 0.8259, Test Accuracy: 70.89%\n",
      "Epoch [96/2500], Train Loss: 0.9861, Train Accuracy: 58.32%, Test Loss: 0.8989, Test Accuracy: 63.29%\n",
      "Epoch [97/2500], Train Loss: 0.9751, Train Accuracy: 60.03%, Test Loss: 1.0250, Test Accuracy: 67.09%\n",
      "Epoch [98/2500], Train Loss: 0.9625, Train Accuracy: 59.32%, Test Loss: 0.8888, Test Accuracy: 62.03%\n",
      "Epoch [99/2500], Train Loss: 0.9576, Train Accuracy: 60.74%, Test Loss: 0.8813, Test Accuracy: 62.03%\n",
      "Epoch [100/2500], Train Loss: 0.9819, Train Accuracy: 58.89%, Test Loss: 0.9548, Test Accuracy: 64.56%\n",
      "Epoch [101/2500], Train Loss: 0.9980, Train Accuracy: 58.46%, Test Loss: 1.0475, Test Accuracy: 55.70%\n",
      "Epoch [102/2500], Train Loss: 0.9814, Train Accuracy: 60.74%, Test Loss: 1.0556, Test Accuracy: 62.03%\n",
      "Epoch [103/2500], Train Loss: 0.9552, Train Accuracy: 62.02%, Test Loss: 0.9077, Test Accuracy: 62.03%\n",
      "Epoch [104/2500], Train Loss: 0.9878, Train Accuracy: 58.46%, Test Loss: 1.0082, Test Accuracy: 64.56%\n",
      "Epoch [105/2500], Train Loss: 0.9896, Train Accuracy: 57.61%, Test Loss: 0.9764, Test Accuracy: 63.29%\n",
      "Epoch [106/2500], Train Loss: 0.9658, Train Accuracy: 59.03%, Test Loss: 1.0009, Test Accuracy: 64.56%\n",
      "Epoch [107/2500], Train Loss: 0.9543, Train Accuracy: 60.31%, Test Loss: 0.9660, Test Accuracy: 58.23%\n",
      "Epoch [108/2500], Train Loss: 1.0036, Train Accuracy: 55.48%, Test Loss: 1.0319, Test Accuracy: 59.49%\n",
      "Epoch [109/2500], Train Loss: 0.9530, Train Accuracy: 60.31%, Test Loss: 0.8585, Test Accuracy: 63.29%\n",
      "Epoch [110/2500], Train Loss: 0.9810, Train Accuracy: 57.61%, Test Loss: 0.8978, Test Accuracy: 67.09%\n",
      "Epoch [111/2500], Train Loss: 0.9704, Train Accuracy: 60.17%, Test Loss: 0.8675, Test Accuracy: 65.82%\n",
      "Epoch [112/2500], Train Loss: 0.9705, Train Accuracy: 58.89%, Test Loss: 0.8622, Test Accuracy: 63.29%\n",
      "Epoch [113/2500], Train Loss: 0.9700, Train Accuracy: 59.32%, Test Loss: 0.8863, Test Accuracy: 68.35%\n",
      "Epoch [114/2500], Train Loss: 0.9665, Train Accuracy: 59.89%, Test Loss: 0.8801, Test Accuracy: 62.03%\n",
      "Epoch [115/2500], Train Loss: 0.9956, Train Accuracy: 57.04%, Test Loss: 0.8246, Test Accuracy: 68.35%\n",
      "Epoch [116/2500], Train Loss: 0.9684, Train Accuracy: 59.03%, Test Loss: 0.9080, Test Accuracy: 63.29%\n",
      "Epoch [117/2500], Train Loss: 0.9804, Train Accuracy: 59.17%, Test Loss: 0.8783, Test Accuracy: 62.03%\n",
      "Epoch [118/2500], Train Loss: 0.9786, Train Accuracy: 58.89%, Test Loss: 1.0111, Test Accuracy: 69.62%\n",
      "Epoch [119/2500], Train Loss: 0.9709, Train Accuracy: 60.88%, Test Loss: 1.1337, Test Accuracy: 59.49%\n",
      "Epoch [120/2500], Train Loss: 0.9665, Train Accuracy: 60.17%, Test Loss: 0.8681, Test Accuracy: 72.15%\n",
      "Epoch [121/2500], Train Loss: 0.9537, Train Accuracy: 61.31%, Test Loss: 1.0798, Test Accuracy: 58.23%\n",
      "Epoch [122/2500], Train Loss: 0.9611, Train Accuracy: 59.74%, Test Loss: 0.9230, Test Accuracy: 62.03%\n",
      "Epoch [123/2500], Train Loss: 0.9374, Train Accuracy: 60.03%, Test Loss: 0.8640, Test Accuracy: 64.56%\n",
      "Epoch [124/2500], Train Loss: 0.9733, Train Accuracy: 60.17%, Test Loss: 0.8332, Test Accuracy: 68.35%\n",
      "Epoch [125/2500], Train Loss: 0.9373, Train Accuracy: 61.31%, Test Loss: 0.9784, Test Accuracy: 60.76%\n",
      "Epoch [126/2500], Train Loss: 0.9803, Train Accuracy: 59.60%, Test Loss: 1.0228, Test Accuracy: 59.49%\n",
      "Epoch [127/2500], Train Loss: 0.9808, Train Accuracy: 59.32%, Test Loss: 0.8812, Test Accuracy: 59.49%\n",
      "Epoch [128/2500], Train Loss: 0.9719, Train Accuracy: 58.75%, Test Loss: 1.1428, Test Accuracy: 62.03%\n",
      "Epoch [129/2500], Train Loss: 0.9486, Train Accuracy: 59.32%, Test Loss: 0.9123, Test Accuracy: 60.76%\n",
      "Epoch [130/2500], Train Loss: 0.9940, Train Accuracy: 56.61%, Test Loss: 0.8489, Test Accuracy: 70.89%\n",
      "Epoch [131/2500], Train Loss: 0.9590, Train Accuracy: 60.03%, Test Loss: 1.1235, Test Accuracy: 62.03%\n",
      "Epoch [132/2500], Train Loss: 0.9346, Train Accuracy: 60.74%, Test Loss: 0.9525, Test Accuracy: 67.09%\n",
      "Epoch [133/2500], Train Loss: 0.9212, Train Accuracy: 58.46%, Test Loss: 0.8553, Test Accuracy: 73.42%\n",
      "Epoch [134/2500], Train Loss: 0.9358, Train Accuracy: 61.31%, Test Loss: 0.9226, Test Accuracy: 58.23%\n",
      "Epoch [135/2500], Train Loss: 0.9573, Train Accuracy: 60.17%, Test Loss: 0.8152, Test Accuracy: 68.35%\n",
      "Epoch [136/2500], Train Loss: 0.9648, Train Accuracy: 56.19%, Test Loss: 0.8517, Test Accuracy: 63.29%\n",
      "Epoch [137/2500], Train Loss: 0.9192, Train Accuracy: 62.02%, Test Loss: 0.8116, Test Accuracy: 59.49%\n",
      "Epoch [138/2500], Train Loss: 0.9190, Train Accuracy: 61.59%, Test Loss: 0.9398, Test Accuracy: 63.29%\n",
      "Epoch [139/2500], Train Loss: 0.9548, Train Accuracy: 61.45%, Test Loss: 0.8205, Test Accuracy: 62.03%\n",
      "Epoch [140/2500], Train Loss: 0.9640, Train Accuracy: 60.17%, Test Loss: 0.9159, Test Accuracy: 69.62%\n",
      "Epoch [141/2500], Train Loss: 0.9680, Train Accuracy: 59.46%, Test Loss: 0.8302, Test Accuracy: 64.56%\n",
      "Epoch [142/2500], Train Loss: 0.9436, Train Accuracy: 59.74%, Test Loss: 0.8345, Test Accuracy: 62.03%\n",
      "Epoch [143/2500], Train Loss: 0.9178, Train Accuracy: 60.88%, Test Loss: 1.1265, Test Accuracy: 59.49%\n",
      "Epoch [144/2500], Train Loss: 0.9817, Train Accuracy: 58.61%, Test Loss: 0.8307, Test Accuracy: 64.56%\n",
      "Epoch [145/2500], Train Loss: 0.9554, Train Accuracy: 58.61%, Test Loss: 0.8193, Test Accuracy: 70.89%\n",
      "Epoch [146/2500], Train Loss: 0.9463, Train Accuracy: 60.60%, Test Loss: 1.0456, Test Accuracy: 60.76%\n",
      "Epoch [147/2500], Train Loss: 0.9422, Train Accuracy: 61.74%, Test Loss: 0.8141, Test Accuracy: 62.03%\n",
      "Epoch [148/2500], Train Loss: 0.9631, Train Accuracy: 60.46%, Test Loss: 0.8606, Test Accuracy: 62.03%\n",
      "Epoch [149/2500], Train Loss: 0.9228, Train Accuracy: 61.74%, Test Loss: 0.8130, Test Accuracy: 67.09%\n",
      "Epoch [150/2500], Train Loss: 0.9049, Train Accuracy: 62.45%, Test Loss: 1.0033, Test Accuracy: 59.49%\n",
      "Epoch [151/2500], Train Loss: 0.9336, Train Accuracy: 59.89%, Test Loss: 0.8111, Test Accuracy: 67.09%\n",
      "Epoch [152/2500], Train Loss: 0.9503, Train Accuracy: 59.60%, Test Loss: 0.8463, Test Accuracy: 72.15%\n",
      "Epoch [153/2500], Train Loss: 0.9167, Train Accuracy: 59.46%, Test Loss: 1.1218, Test Accuracy: 54.43%\n",
      "Epoch [154/2500], Train Loss: 0.9234, Train Accuracy: 61.74%, Test Loss: 0.8162, Test Accuracy: 65.82%\n",
      "Epoch [155/2500], Train Loss: 0.9267, Train Accuracy: 62.02%, Test Loss: 0.9565, Test Accuracy: 59.49%\n",
      "Epoch [156/2500], Train Loss: 0.9149, Train Accuracy: 61.59%, Test Loss: 1.0357, Test Accuracy: 62.03%\n",
      "Epoch [157/2500], Train Loss: 0.9232, Train Accuracy: 59.74%, Test Loss: 0.9444, Test Accuracy: 64.56%\n",
      "Epoch [158/2500], Train Loss: 0.9532, Train Accuracy: 59.74%, Test Loss: 0.9407, Test Accuracy: 63.29%\n",
      "Epoch [159/2500], Train Loss: 0.9568, Train Accuracy: 60.17%, Test Loss: 0.8367, Test Accuracy: 68.35%\n",
      "Epoch [160/2500], Train Loss: 0.9339, Train Accuracy: 59.03%, Test Loss: 0.8194, Test Accuracy: 68.35%\n",
      "Epoch [161/2500], Train Loss: 0.9361, Train Accuracy: 61.74%, Test Loss: 0.9346, Test Accuracy: 64.56%\n",
      "Epoch [162/2500], Train Loss: 0.9256, Train Accuracy: 60.31%, Test Loss: 0.9563, Test Accuracy: 58.23%\n",
      "Epoch [163/2500], Train Loss: 0.9262, Train Accuracy: 61.31%, Test Loss: 0.8910, Test Accuracy: 59.49%\n",
      "Epoch [164/2500], Train Loss: 0.9305, Train Accuracy: 59.17%, Test Loss: 0.8095, Test Accuracy: 54.43%\n",
      "Epoch [165/2500], Train Loss: 0.9435, Train Accuracy: 58.89%, Test Loss: 0.8408, Test Accuracy: 63.29%\n",
      "Epoch [166/2500], Train Loss: 0.9330, Train Accuracy: 60.31%, Test Loss: 0.8797, Test Accuracy: 62.03%\n",
      "Epoch [167/2500], Train Loss: 0.8862, Train Accuracy: 62.30%, Test Loss: 0.8212, Test Accuracy: 63.29%\n",
      "Epoch [168/2500], Train Loss: 0.9063, Train Accuracy: 63.02%, Test Loss: 0.8116, Test Accuracy: 60.76%\n",
      "Epoch [169/2500], Train Loss: 0.9017, Train Accuracy: 63.73%, Test Loss: 1.1156, Test Accuracy: 58.23%\n",
      "Epoch [170/2500], Train Loss: 0.9541, Train Accuracy: 61.45%, Test Loss: 0.8512, Test Accuracy: 63.29%\n",
      "Epoch [171/2500], Train Loss: 0.9294, Train Accuracy: 60.46%, Test Loss: 0.9778, Test Accuracy: 60.76%\n",
      "Epoch [172/2500], Train Loss: 0.9231, Train Accuracy: 61.45%, Test Loss: 0.8825, Test Accuracy: 70.89%\n",
      "Epoch [173/2500], Train Loss: 0.9150, Train Accuracy: 62.02%, Test Loss: 0.8202, Test Accuracy: 67.09%\n",
      "Epoch [174/2500], Train Loss: 0.9341, Train Accuracy: 59.89%, Test Loss: 0.9549, Test Accuracy: 60.76%\n",
      "Epoch [175/2500], Train Loss: 0.9437, Train Accuracy: 61.02%, Test Loss: 0.8353, Test Accuracy: 73.42%\n",
      "Epoch [176/2500], Train Loss: 0.9127, Train Accuracy: 61.88%, Test Loss: 0.9620, Test Accuracy: 67.09%\n",
      "Epoch [177/2500], Train Loss: 0.9203, Train Accuracy: 61.17%, Test Loss: 0.7984, Test Accuracy: 59.49%\n",
      "Epoch [178/2500], Train Loss: 0.9472, Train Accuracy: 60.31%, Test Loss: 0.8692, Test Accuracy: 60.76%\n",
      "Epoch [179/2500], Train Loss: 0.9159, Train Accuracy: 61.74%, Test Loss: 0.8352, Test Accuracy: 65.82%\n",
      "Epoch [180/2500], Train Loss: 0.9134, Train Accuracy: 61.31%, Test Loss: 0.7962, Test Accuracy: 65.82%\n",
      "Epoch [181/2500], Train Loss: 0.9358, Train Accuracy: 61.88%, Test Loss: 0.8081, Test Accuracy: 70.89%\n",
      "Epoch [182/2500], Train Loss: 0.9022, Train Accuracy: 62.16%, Test Loss: 1.1860, Test Accuracy: 55.70%\n",
      "Epoch [183/2500], Train Loss: 0.9865, Train Accuracy: 61.17%, Test Loss: 0.8299, Test Accuracy: 74.68%\n",
      "Epoch [184/2500], Train Loss: 0.9389, Train Accuracy: 59.46%, Test Loss: 0.8175, Test Accuracy: 67.09%\n",
      "Epoch [185/2500], Train Loss: 0.9294, Train Accuracy: 61.17%, Test Loss: 1.0208, Test Accuracy: 65.82%\n",
      "Epoch [186/2500], Train Loss: 0.9326, Train Accuracy: 61.45%, Test Loss: 1.1075, Test Accuracy: 54.43%\n",
      "Epoch [187/2500], Train Loss: 0.8929, Train Accuracy: 62.73%, Test Loss: 0.8301, Test Accuracy: 64.56%\n",
      "Epoch [188/2500], Train Loss: 0.9348, Train Accuracy: 60.74%, Test Loss: 0.8418, Test Accuracy: 59.49%\n",
      "Epoch [189/2500], Train Loss: 0.9177, Train Accuracy: 61.02%, Test Loss: 0.8259, Test Accuracy: 73.42%\n",
      "Epoch [190/2500], Train Loss: 0.9511, Train Accuracy: 60.17%, Test Loss: 0.8653, Test Accuracy: 67.09%\n",
      "Epoch [191/2500], Train Loss: 0.9186, Train Accuracy: 62.30%, Test Loss: 0.7865, Test Accuracy: 56.96%\n",
      "Epoch [192/2500], Train Loss: 0.9259, Train Accuracy: 60.74%, Test Loss: 0.9689, Test Accuracy: 67.09%\n",
      "Epoch [193/2500], Train Loss: 0.8989, Train Accuracy: 60.31%, Test Loss: 0.9265, Test Accuracy: 67.09%\n",
      "Epoch [194/2500], Train Loss: 0.8966, Train Accuracy: 60.88%, Test Loss: 0.8754, Test Accuracy: 67.09%\n",
      "Epoch [195/2500], Train Loss: 0.9003, Train Accuracy: 61.74%, Test Loss: 0.8186, Test Accuracy: 62.03%\n",
      "Epoch [196/2500], Train Loss: 0.9082, Train Accuracy: 62.87%, Test Loss: 0.7983, Test Accuracy: 67.09%\n",
      "Epoch [197/2500], Train Loss: 0.9190, Train Accuracy: 60.46%, Test Loss: 0.9850, Test Accuracy: 63.29%\n",
      "Epoch [198/2500], Train Loss: 0.9226, Train Accuracy: 61.45%, Test Loss: 0.8140, Test Accuracy: 64.56%\n",
      "Epoch [199/2500], Train Loss: 0.9186, Train Accuracy: 60.03%, Test Loss: 0.8231, Test Accuracy: 63.29%\n",
      "Epoch [200/2500], Train Loss: 0.9039, Train Accuracy: 61.88%, Test Loss: 0.8920, Test Accuracy: 63.29%\n",
      "Epoch [201/2500], Train Loss: 0.9190, Train Accuracy: 60.74%, Test Loss: 0.7846, Test Accuracy: 63.29%\n",
      "Epoch [202/2500], Train Loss: 0.9134, Train Accuracy: 60.60%, Test Loss: 0.8170, Test Accuracy: 64.56%\n",
      "Epoch [203/2500], Train Loss: 0.9180, Train Accuracy: 62.02%, Test Loss: 0.8174, Test Accuracy: 69.62%\n",
      "Epoch [204/2500], Train Loss: 0.9264, Train Accuracy: 58.89%, Test Loss: 1.0683, Test Accuracy: 56.96%\n",
      "Epoch [205/2500], Train Loss: 0.9061, Train Accuracy: 61.74%, Test Loss: 0.8201, Test Accuracy: 69.62%\n",
      "Epoch [206/2500], Train Loss: 0.9278, Train Accuracy: 58.89%, Test Loss: 0.7990, Test Accuracy: 63.29%\n",
      "Epoch [207/2500], Train Loss: 0.8700, Train Accuracy: 63.30%, Test Loss: 0.7994, Test Accuracy: 67.09%\n",
      "Epoch [208/2500], Train Loss: 0.8963, Train Accuracy: 63.02%, Test Loss: 0.7966, Test Accuracy: 69.62%\n",
      "Epoch [209/2500], Train Loss: 0.9072, Train Accuracy: 60.74%, Test Loss: 0.8980, Test Accuracy: 65.82%\n",
      "Epoch [210/2500], Train Loss: 0.9063, Train Accuracy: 59.89%, Test Loss: 0.8920, Test Accuracy: 62.03%\n",
      "Epoch [211/2500], Train Loss: 0.9276, Train Accuracy: 61.17%, Test Loss: 0.8863, Test Accuracy: 62.03%\n",
      "Epoch [212/2500], Train Loss: 0.9001, Train Accuracy: 62.30%, Test Loss: 0.8330, Test Accuracy: 67.09%\n",
      "Epoch [213/2500], Train Loss: 0.9189, Train Accuracy: 61.88%, Test Loss: 0.8041, Test Accuracy: 63.29%\n",
      "Epoch [214/2500], Train Loss: 0.9015, Train Accuracy: 62.16%, Test Loss: 0.9224, Test Accuracy: 62.03%\n",
      "Epoch [215/2500], Train Loss: 0.8954, Train Accuracy: 62.02%, Test Loss: 0.8522, Test Accuracy: 62.03%\n",
      "Epoch [216/2500], Train Loss: 0.9720, Train Accuracy: 61.02%, Test Loss: 1.1519, Test Accuracy: 53.16%\n",
      "Epoch [217/2500], Train Loss: 0.9216, Train Accuracy: 60.88%, Test Loss: 0.8039, Test Accuracy: 67.09%\n",
      "Epoch [218/2500], Train Loss: 0.8942, Train Accuracy: 62.02%, Test Loss: 1.0187, Test Accuracy: 59.49%\n",
      "Epoch [219/2500], Train Loss: 0.9194, Train Accuracy: 59.60%, Test Loss: 0.8717, Test Accuracy: 68.35%\n",
      "Epoch [220/2500], Train Loss: 0.9166, Train Accuracy: 61.74%, Test Loss: 0.8175, Test Accuracy: 69.62%\n",
      "Epoch [221/2500], Train Loss: 0.8840, Train Accuracy: 61.31%, Test Loss: 0.8330, Test Accuracy: 65.82%\n",
      "Epoch [222/2500], Train Loss: 0.8858, Train Accuracy: 61.88%, Test Loss: 0.8154, Test Accuracy: 64.56%\n",
      "Epoch [223/2500], Train Loss: 0.9220, Train Accuracy: 59.89%, Test Loss: 0.9198, Test Accuracy: 62.03%\n",
      "Epoch [224/2500], Train Loss: 0.9133, Train Accuracy: 59.74%, Test Loss: 0.8424, Test Accuracy: 63.29%\n",
      "Epoch [225/2500], Train Loss: 0.8910, Train Accuracy: 62.87%, Test Loss: 0.9388, Test Accuracy: 62.03%\n",
      "Epoch [226/2500], Train Loss: 0.9120, Train Accuracy: 60.46%, Test Loss: 0.8039, Test Accuracy: 64.56%\n",
      "Epoch [227/2500], Train Loss: 0.9120, Train Accuracy: 61.74%, Test Loss: 0.7880, Test Accuracy: 65.82%\n",
      "Epoch [228/2500], Train Loss: 0.9089, Train Accuracy: 62.02%, Test Loss: 0.7938, Test Accuracy: 67.09%\n",
      "Epoch [229/2500], Train Loss: 0.8851, Train Accuracy: 61.17%, Test Loss: 0.8234, Test Accuracy: 68.35%\n",
      "Epoch [230/2500], Train Loss: 0.8748, Train Accuracy: 61.17%, Test Loss: 0.8893, Test Accuracy: 68.35%\n",
      "Epoch [231/2500], Train Loss: 0.9235, Train Accuracy: 61.59%, Test Loss: 0.8556, Test Accuracy: 65.82%\n",
      "Epoch [232/2500], Train Loss: 0.8950, Train Accuracy: 63.87%, Test Loss: 0.9229, Test Accuracy: 59.49%\n",
      "Epoch [233/2500], Train Loss: 0.9019, Train Accuracy: 61.31%, Test Loss: 0.8624, Test Accuracy: 63.29%\n",
      "Epoch [234/2500], Train Loss: 0.9063, Train Accuracy: 61.02%, Test Loss: 0.8592, Test Accuracy: 65.82%\n",
      "Epoch [235/2500], Train Loss: 0.8967, Train Accuracy: 61.31%, Test Loss: 0.8266, Test Accuracy: 64.56%\n",
      "Epoch [236/2500], Train Loss: 0.9040, Train Accuracy: 63.16%, Test Loss: 0.7784, Test Accuracy: 64.56%\n",
      "Epoch [237/2500], Train Loss: 0.9029, Train Accuracy: 61.45%, Test Loss: 0.7964, Test Accuracy: 64.56%\n",
      "Epoch [238/2500], Train Loss: 0.9256, Train Accuracy: 59.32%, Test Loss: 0.7942, Test Accuracy: 68.35%\n",
      "Epoch [239/2500], Train Loss: 0.8952, Train Accuracy: 61.17%, Test Loss: 0.9041, Test Accuracy: 59.49%\n",
      "Epoch [240/2500], Train Loss: 0.8915, Train Accuracy: 61.45%, Test Loss: 0.8470, Test Accuracy: 69.62%\n",
      "Epoch [241/2500], Train Loss: 0.8955, Train Accuracy: 61.88%, Test Loss: 0.8085, Test Accuracy: 64.56%\n",
      "Epoch [242/2500], Train Loss: 0.8973, Train Accuracy: 62.59%, Test Loss: 1.0033, Test Accuracy: 59.49%\n",
      "Epoch [243/2500], Train Loss: 0.9135, Train Accuracy: 59.46%, Test Loss: 0.7889, Test Accuracy: 62.03%\n",
      "Epoch [244/2500], Train Loss: 0.9161, Train Accuracy: 60.74%, Test Loss: 0.7692, Test Accuracy: 64.56%\n",
      "Epoch [245/2500], Train Loss: 0.8723, Train Accuracy: 63.87%, Test Loss: 0.9074, Test Accuracy: 65.82%\n",
      "Epoch [246/2500], Train Loss: 0.8816, Train Accuracy: 62.02%, Test Loss: 0.8564, Test Accuracy: 63.29%\n",
      "Epoch [247/2500], Train Loss: 0.9201, Train Accuracy: 61.17%, Test Loss: 0.8814, Test Accuracy: 64.56%\n",
      "Epoch [248/2500], Train Loss: 0.8707, Train Accuracy: 62.45%, Test Loss: 0.8173, Test Accuracy: 63.29%\n",
      "Epoch [249/2500], Train Loss: 0.9099, Train Accuracy: 61.88%, Test Loss: 0.8588, Test Accuracy: 62.03%\n",
      "Epoch [250/2500], Train Loss: 0.8755, Train Accuracy: 63.73%, Test Loss: 0.9989, Test Accuracy: 63.29%\n",
      "Epoch [251/2500], Train Loss: 0.9100, Train Accuracy: 61.17%, Test Loss: 0.8045, Test Accuracy: 69.62%\n",
      "Epoch [252/2500], Train Loss: 0.8938, Train Accuracy: 60.74%, Test Loss: 0.9512, Test Accuracy: 67.09%\n",
      "Epoch [253/2500], Train Loss: 0.8962, Train Accuracy: 60.31%, Test Loss: 0.7754, Test Accuracy: 60.76%\n",
      "Epoch [254/2500], Train Loss: 0.9077, Train Accuracy: 61.17%, Test Loss: 0.8116, Test Accuracy: 74.68%\n",
      "Epoch [255/2500], Train Loss: 0.9136, Train Accuracy: 60.60%, Test Loss: 0.8791, Test Accuracy: 68.35%\n",
      "Epoch [256/2500], Train Loss: 0.8863, Train Accuracy: 64.30%, Test Loss: 0.9456, Test Accuracy: 62.03%\n",
      "Epoch [257/2500], Train Loss: 0.9043, Train Accuracy: 59.74%, Test Loss: 0.8271, Test Accuracy: 73.42%\n",
      "Epoch [258/2500], Train Loss: 0.8957, Train Accuracy: 63.87%, Test Loss: 0.8329, Test Accuracy: 63.29%\n",
      "Epoch [259/2500], Train Loss: 0.8891, Train Accuracy: 62.73%, Test Loss: 0.7735, Test Accuracy: 62.03%\n",
      "Epoch [260/2500], Train Loss: 0.8933, Train Accuracy: 62.16%, Test Loss: 0.8720, Test Accuracy: 60.76%\n",
      "Epoch [261/2500], Train Loss: 0.9216, Train Accuracy: 60.88%, Test Loss: 0.7765, Test Accuracy: 64.56%\n",
      "Epoch [262/2500], Train Loss: 0.8895, Train Accuracy: 61.45%, Test Loss: 0.8849, Test Accuracy: 70.89%\n",
      "Epoch [263/2500], Train Loss: 0.9270, Train Accuracy: 59.46%, Test Loss: 1.0552, Test Accuracy: 65.82%\n",
      "Epoch [264/2500], Train Loss: 0.9094, Train Accuracy: 61.59%, Test Loss: 0.8144, Test Accuracy: 70.89%\n",
      "Epoch [265/2500], Train Loss: 0.8787, Train Accuracy: 62.59%, Test Loss: 0.8405, Test Accuracy: 67.09%\n",
      "Epoch [266/2500], Train Loss: 0.8824, Train Accuracy: 62.59%, Test Loss: 0.9441, Test Accuracy: 62.03%\n",
      "Epoch [267/2500], Train Loss: 0.8889, Train Accuracy: 61.02%, Test Loss: 0.7894, Test Accuracy: 67.09%\n",
      "Epoch [268/2500], Train Loss: 0.8606, Train Accuracy: 63.73%, Test Loss: 0.7993, Test Accuracy: 62.03%\n",
      "Epoch [269/2500], Train Loss: 0.8935, Train Accuracy: 61.88%, Test Loss: 0.8268, Test Accuracy: 69.62%\n",
      "Epoch [270/2500], Train Loss: 0.9324, Train Accuracy: 59.74%, Test Loss: 1.1789, Test Accuracy: 50.63%\n",
      "Epoch [271/2500], Train Loss: 0.9090, Train Accuracy: 64.15%, Test Loss: 0.7651, Test Accuracy: 64.56%\n",
      "Epoch [272/2500], Train Loss: 0.8936, Train Accuracy: 63.30%, Test Loss: 0.8416, Test Accuracy: 68.35%\n",
      "Epoch [273/2500], Train Loss: 0.9105, Train Accuracy: 61.02%, Test Loss: 0.7727, Test Accuracy: 62.03%\n",
      "Epoch [274/2500], Train Loss: 0.8917, Train Accuracy: 62.16%, Test Loss: 0.8895, Test Accuracy: 63.29%\n",
      "Epoch [275/2500], Train Loss: 0.9174, Train Accuracy: 62.02%, Test Loss: 0.8588, Test Accuracy: 63.29%\n",
      "Epoch [276/2500], Train Loss: 0.8913, Train Accuracy: 62.02%, Test Loss: 0.7726, Test Accuracy: 67.09%\n",
      "Epoch [277/2500], Train Loss: 0.8626, Train Accuracy: 64.01%, Test Loss: 0.7781, Test Accuracy: 70.89%\n",
      "Epoch [278/2500], Train Loss: 0.9190, Train Accuracy: 60.88%, Test Loss: 0.8380, Test Accuracy: 63.29%\n",
      "Epoch [279/2500], Train Loss: 0.8726, Train Accuracy: 61.02%, Test Loss: 0.8301, Test Accuracy: 63.29%\n",
      "Epoch [280/2500], Train Loss: 0.8994, Train Accuracy: 60.88%, Test Loss: 0.8215, Test Accuracy: 62.03%\n",
      "Epoch [281/2500], Train Loss: 0.8869, Train Accuracy: 62.02%, Test Loss: 0.7904, Test Accuracy: 64.56%\n",
      "Epoch [282/2500], Train Loss: 0.8979, Train Accuracy: 61.59%, Test Loss: 0.9139, Test Accuracy: 59.49%\n",
      "Epoch [283/2500], Train Loss: 0.8674, Train Accuracy: 64.44%, Test Loss: 0.7603, Test Accuracy: 62.03%\n",
      "Epoch [284/2500], Train Loss: 0.8707, Train Accuracy: 61.88%, Test Loss: 0.8406, Test Accuracy: 63.29%\n",
      "Epoch [285/2500], Train Loss: 0.9125, Train Accuracy: 61.45%, Test Loss: 0.7945, Test Accuracy: 65.82%\n",
      "Epoch [286/2500], Train Loss: 0.9004, Train Accuracy: 60.03%, Test Loss: 0.8811, Test Accuracy: 58.23%\n",
      "Epoch [287/2500], Train Loss: 0.8854, Train Accuracy: 62.02%, Test Loss: 0.8223, Test Accuracy: 63.29%\n",
      "Epoch [288/2500], Train Loss: 0.9049, Train Accuracy: 61.17%, Test Loss: 0.8058, Test Accuracy: 62.03%\n",
      "Epoch [289/2500], Train Loss: 0.8727, Train Accuracy: 62.30%, Test Loss: 0.8783, Test Accuracy: 60.76%\n",
      "Epoch [290/2500], Train Loss: 0.8773, Train Accuracy: 61.17%, Test Loss: 0.7838, Test Accuracy: 65.82%\n",
      "Epoch [291/2500], Train Loss: 0.8363, Train Accuracy: 63.44%, Test Loss: 0.8283, Test Accuracy: 67.09%\n",
      "Epoch [292/2500], Train Loss: 0.8742, Train Accuracy: 61.88%, Test Loss: 0.8093, Test Accuracy: 68.35%\n",
      "Epoch [293/2500], Train Loss: 0.8890, Train Accuracy: 62.45%, Test Loss: 0.7864, Test Accuracy: 65.82%\n",
      "Epoch [294/2500], Train Loss: 0.8414, Train Accuracy: 64.58%, Test Loss: 0.8174, Test Accuracy: 72.15%\n",
      "Epoch [295/2500], Train Loss: 0.8955, Train Accuracy: 62.16%, Test Loss: 0.8306, Test Accuracy: 63.29%\n",
      "Epoch [296/2500], Train Loss: 0.9283, Train Accuracy: 59.89%, Test Loss: 0.9485, Test Accuracy: 60.76%\n",
      "Epoch [297/2500], Train Loss: 0.9121, Train Accuracy: 61.74%, Test Loss: 0.7947, Test Accuracy: 65.82%\n",
      "Epoch [298/2500], Train Loss: 0.8564, Train Accuracy: 65.29%, Test Loss: 0.9955, Test Accuracy: 59.49%\n",
      "Epoch [299/2500], Train Loss: 0.8683, Train Accuracy: 64.86%, Test Loss: 0.8338, Test Accuracy: 69.62%\n",
      "Epoch [300/2500], Train Loss: 0.8639, Train Accuracy: 62.30%, Test Loss: 0.8200, Test Accuracy: 67.09%\n",
      "Epoch [301/2500], Train Loss: 0.8544, Train Accuracy: 62.73%, Test Loss: 0.8026, Test Accuracy: 64.56%\n",
      "Epoch [302/2500], Train Loss: 0.8397, Train Accuracy: 64.30%, Test Loss: 0.8520, Test Accuracy: 69.62%\n",
      "Epoch [303/2500], Train Loss: 0.8822, Train Accuracy: 62.02%, Test Loss: 0.8619, Test Accuracy: 62.03%\n",
      "Epoch [304/2500], Train Loss: 0.8706, Train Accuracy: 63.44%, Test Loss: 0.8223, Test Accuracy: 69.62%\n",
      "Epoch [305/2500], Train Loss: 0.8359, Train Accuracy: 63.30%, Test Loss: 0.7954, Test Accuracy: 62.03%\n",
      "Epoch [306/2500], Train Loss: 0.8729, Train Accuracy: 62.16%, Test Loss: 0.9851, Test Accuracy: 59.49%\n",
      "Epoch [307/2500], Train Loss: 0.8874, Train Accuracy: 61.88%, Test Loss: 0.8586, Test Accuracy: 65.82%\n",
      "Epoch [308/2500], Train Loss: 0.8575, Train Accuracy: 63.58%, Test Loss: 0.7819, Test Accuracy: 62.03%\n",
      "Epoch [309/2500], Train Loss: 0.8593, Train Accuracy: 62.59%, Test Loss: 0.8154, Test Accuracy: 73.42%\n",
      "Epoch [310/2500], Train Loss: 0.8776, Train Accuracy: 62.59%, Test Loss: 0.8496, Test Accuracy: 67.09%\n",
      "Epoch [311/2500], Train Loss: 0.8636, Train Accuracy: 64.58%, Test Loss: 0.7993, Test Accuracy: 69.62%\n",
      "Epoch [312/2500], Train Loss: 0.8646, Train Accuracy: 63.87%, Test Loss: 0.9164, Test Accuracy: 68.35%\n",
      "Epoch [313/2500], Train Loss: 0.8357, Train Accuracy: 65.29%, Test Loss: 0.8661, Test Accuracy: 67.09%\n",
      "Epoch [314/2500], Train Loss: 0.9132, Train Accuracy: 61.88%, Test Loss: 0.7650, Test Accuracy: 59.49%\n",
      "Epoch [315/2500], Train Loss: 0.8720, Train Accuracy: 62.45%, Test Loss: 0.8596, Test Accuracy: 70.89%\n",
      "Epoch [316/2500], Train Loss: 0.8800, Train Accuracy: 62.30%, Test Loss: 0.8590, Test Accuracy: 62.03%\n",
      "Epoch [317/2500], Train Loss: 0.8617, Train Accuracy: 62.02%, Test Loss: 0.7703, Test Accuracy: 65.82%\n",
      "Epoch [318/2500], Train Loss: 0.8751, Train Accuracy: 62.16%, Test Loss: 0.7924, Test Accuracy: 65.82%\n",
      "Epoch [319/2500], Train Loss: 0.8637, Train Accuracy: 62.45%, Test Loss: 0.8134, Test Accuracy: 70.89%\n",
      "Epoch [320/2500], Train Loss: 0.8791, Train Accuracy: 62.59%, Test Loss: 0.7727, Test Accuracy: 67.09%\n",
      "Epoch [321/2500], Train Loss: 0.8669, Train Accuracy: 63.58%, Test Loss: 0.8624, Test Accuracy: 59.49%\n",
      "Epoch [322/2500], Train Loss: 0.8803, Train Accuracy: 62.16%, Test Loss: 0.7912, Test Accuracy: 70.89%\n",
      "Epoch [323/2500], Train Loss: 0.8499, Train Accuracy: 62.87%, Test Loss: 0.8351, Test Accuracy: 67.09%\n",
      "Epoch [324/2500], Train Loss: 0.8383, Train Accuracy: 62.45%, Test Loss: 0.8570, Test Accuracy: 68.35%\n",
      "Epoch [325/2500], Train Loss: 0.8736, Train Accuracy: 61.88%, Test Loss: 0.8521, Test Accuracy: 63.29%\n",
      "Epoch [326/2500], Train Loss: 0.9117, Train Accuracy: 60.74%, Test Loss: 0.9584, Test Accuracy: 69.62%\n",
      "Epoch [327/2500], Train Loss: 0.8674, Train Accuracy: 63.02%, Test Loss: 0.7849, Test Accuracy: 67.09%\n",
      "Epoch [328/2500], Train Loss: 0.8817, Train Accuracy: 62.02%, Test Loss: 0.7625, Test Accuracy: 60.76%\n",
      "Epoch [329/2500], Train Loss: 0.8691, Train Accuracy: 64.72%, Test Loss: 0.7844, Test Accuracy: 73.42%\n",
      "Epoch [330/2500], Train Loss: 0.8847, Train Accuracy: 61.88%, Test Loss: 0.8000, Test Accuracy: 75.95%\n",
      "Epoch [331/2500], Train Loss: 0.8801, Train Accuracy: 60.60%, Test Loss: 0.7740, Test Accuracy: 72.15%\n",
      "Epoch [332/2500], Train Loss: 0.8475, Train Accuracy: 62.73%, Test Loss: 0.8064, Test Accuracy: 69.62%\n",
      "Epoch [333/2500], Train Loss: 0.9029, Train Accuracy: 63.44%, Test Loss: 0.7631, Test Accuracy: 63.29%\n",
      "Epoch [334/2500], Train Loss: 0.8950, Train Accuracy: 63.16%, Test Loss: 0.8916, Test Accuracy: 58.23%\n",
      "Epoch [335/2500], Train Loss: 0.8837, Train Accuracy: 62.02%, Test Loss: 0.7779, Test Accuracy: 69.62%\n",
      "Epoch [336/2500], Train Loss: 0.8812, Train Accuracy: 62.45%, Test Loss: 0.7727, Test Accuracy: 72.15%\n",
      "Epoch [337/2500], Train Loss: 0.8743, Train Accuracy: 63.87%, Test Loss: 0.7979, Test Accuracy: 68.35%\n",
      "Epoch [338/2500], Train Loss: 0.9063, Train Accuracy: 61.88%, Test Loss: 0.7859, Test Accuracy: 68.35%\n",
      "Epoch [339/2500], Train Loss: 0.8720, Train Accuracy: 63.02%, Test Loss: 0.7676, Test Accuracy: 70.89%\n",
      "Epoch [340/2500], Train Loss: 0.8756, Train Accuracy: 63.02%, Test Loss: 0.7709, Test Accuracy: 65.82%\n",
      "Epoch [341/2500], Train Loss: 0.8654, Train Accuracy: 60.74%, Test Loss: 0.7723, Test Accuracy: 62.03%\n",
      "Epoch [342/2500], Train Loss: 0.8510, Train Accuracy: 66.86%, Test Loss: 0.9025, Test Accuracy: 58.23%\n",
      "Epoch [343/2500], Train Loss: 0.8628, Train Accuracy: 62.59%, Test Loss: 0.8077, Test Accuracy: 67.09%\n",
      "Epoch [344/2500], Train Loss: 0.8501, Train Accuracy: 64.72%, Test Loss: 0.8291, Test Accuracy: 64.56%\n",
      "Epoch [345/2500], Train Loss: 0.8752, Train Accuracy: 61.02%, Test Loss: 0.7919, Test Accuracy: 67.09%\n",
      "Epoch [346/2500], Train Loss: 0.8679, Train Accuracy: 63.02%, Test Loss: 0.8413, Test Accuracy: 68.35%\n",
      "Epoch [347/2500], Train Loss: 0.8773, Train Accuracy: 62.30%, Test Loss: 0.9088, Test Accuracy: 64.56%\n",
      "Epoch [348/2500], Train Loss: 0.8523, Train Accuracy: 63.02%, Test Loss: 0.8053, Test Accuracy: 64.56%\n",
      "Epoch [349/2500], Train Loss: 0.8687, Train Accuracy: 63.02%, Test Loss: 0.8636, Test Accuracy: 65.82%\n",
      "Epoch [350/2500], Train Loss: 0.8518, Train Accuracy: 64.72%, Test Loss: 0.7643, Test Accuracy: 72.15%\n",
      "Epoch [351/2500], Train Loss: 0.8815, Train Accuracy: 62.73%, Test Loss: 0.9011, Test Accuracy: 67.09%\n",
      "Epoch [352/2500], Train Loss: 0.8784, Train Accuracy: 62.87%, Test Loss: 0.7722, Test Accuracy: 65.82%\n",
      "Epoch [353/2500], Train Loss: 0.8602, Train Accuracy: 63.44%, Test Loss: 0.8309, Test Accuracy: 64.56%\n",
      "Epoch [354/2500], Train Loss: 0.8915, Train Accuracy: 62.73%, Test Loss: 0.8290, Test Accuracy: 72.15%\n",
      "Epoch [355/2500], Train Loss: 0.8553, Train Accuracy: 61.45%, Test Loss: 0.9192, Test Accuracy: 60.76%\n",
      "Epoch [356/2500], Train Loss: 0.8506, Train Accuracy: 62.59%, Test Loss: 0.8905, Test Accuracy: 65.82%\n",
      "Epoch [357/2500], Train Loss: 0.8495, Train Accuracy: 64.01%, Test Loss: 0.7619, Test Accuracy: 62.03%\n",
      "Epoch [358/2500], Train Loss: 0.8625, Train Accuracy: 64.72%, Test Loss: 0.7584, Test Accuracy: 63.29%\n",
      "Epoch [359/2500], Train Loss: 0.8727, Train Accuracy: 61.17%, Test Loss: 0.9154, Test Accuracy: 62.03%\n",
      "Epoch [360/2500], Train Loss: 0.8576, Train Accuracy: 62.02%, Test Loss: 0.8438, Test Accuracy: 67.09%\n",
      "Epoch [361/2500], Train Loss: 0.8950, Train Accuracy: 61.74%, Test Loss: 0.8722, Test Accuracy: 60.76%\n",
      "Epoch [362/2500], Train Loss: 0.8795, Train Accuracy: 62.45%, Test Loss: 0.8420, Test Accuracy: 68.35%\n",
      "Epoch [363/2500], Train Loss: 0.8687, Train Accuracy: 63.87%, Test Loss: 0.7633, Test Accuracy: 70.89%\n",
      "Epoch [364/2500], Train Loss: 0.8462, Train Accuracy: 62.87%, Test Loss: 0.8074, Test Accuracy: 69.62%\n",
      "Epoch [365/2500], Train Loss: 0.8475, Train Accuracy: 64.01%, Test Loss: 0.7730, Test Accuracy: 63.29%\n",
      "Epoch [366/2500], Train Loss: 0.8563, Train Accuracy: 63.16%, Test Loss: 0.7961, Test Accuracy: 72.15%\n",
      "Epoch [367/2500], Train Loss: 0.8838, Train Accuracy: 63.58%, Test Loss: 0.8201, Test Accuracy: 63.29%\n",
      "Epoch [368/2500], Train Loss: 0.8372, Train Accuracy: 63.44%, Test Loss: 0.7848, Test Accuracy: 69.62%\n",
      "Epoch [369/2500], Train Loss: 0.8564, Train Accuracy: 63.16%, Test Loss: 0.7741, Test Accuracy: 70.89%\n",
      "Epoch [370/2500], Train Loss: 0.8663, Train Accuracy: 63.30%, Test Loss: 0.8459, Test Accuracy: 67.09%\n",
      "Epoch [371/2500], Train Loss: 0.8870, Train Accuracy: 64.58%, Test Loss: 0.9202, Test Accuracy: 65.82%\n",
      "Epoch [372/2500], Train Loss: 0.8811, Train Accuracy: 59.32%, Test Loss: 0.7636, Test Accuracy: 69.62%\n",
      "Epoch [373/2500], Train Loss: 0.8380, Train Accuracy: 64.58%, Test Loss: 0.7974, Test Accuracy: 68.35%\n",
      "Epoch [374/2500], Train Loss: 0.8280, Train Accuracy: 64.15%, Test Loss: 0.8231, Test Accuracy: 62.03%\n",
      "Epoch [375/2500], Train Loss: 0.8707, Train Accuracy: 63.73%, Test Loss: 0.8504, Test Accuracy: 62.03%\n",
      "Epoch [376/2500], Train Loss: 0.8437, Train Accuracy: 65.01%, Test Loss: 0.7473, Test Accuracy: 70.89%\n",
      "Epoch [377/2500], Train Loss: 0.8510, Train Accuracy: 63.16%, Test Loss: 0.8158, Test Accuracy: 64.56%\n",
      "Epoch [378/2500], Train Loss: 0.8525, Train Accuracy: 63.44%, Test Loss: 0.9614, Test Accuracy: 69.62%\n",
      "Epoch [379/2500], Train Loss: 0.8684, Train Accuracy: 63.58%, Test Loss: 0.8061, Test Accuracy: 68.35%\n",
      "Epoch [380/2500], Train Loss: 0.8368, Train Accuracy: 63.44%, Test Loss: 0.9117, Test Accuracy: 67.09%\n",
      "Epoch [381/2500], Train Loss: 0.8584, Train Accuracy: 63.73%, Test Loss: 0.7713, Test Accuracy: 67.09%\n",
      "Epoch [382/2500], Train Loss: 0.8887, Train Accuracy: 60.74%, Test Loss: 0.9384, Test Accuracy: 62.03%\n",
      "Epoch [383/2500], Train Loss: 0.8660, Train Accuracy: 61.74%, Test Loss: 0.7722, Test Accuracy: 72.15%\n",
      "Epoch [384/2500], Train Loss: 0.8578, Train Accuracy: 62.73%, Test Loss: 0.7583, Test Accuracy: 72.15%\n",
      "Epoch [385/2500], Train Loss: 0.8549, Train Accuracy: 64.01%, Test Loss: 0.8826, Test Accuracy: 64.56%\n",
      "Epoch [386/2500], Train Loss: 0.8599, Train Accuracy: 62.59%, Test Loss: 0.7642, Test Accuracy: 68.35%\n",
      "Epoch [387/2500], Train Loss: 0.8522, Train Accuracy: 62.30%, Test Loss: 0.9258, Test Accuracy: 64.56%\n",
      "Epoch [388/2500], Train Loss: 0.8548, Train Accuracy: 62.45%, Test Loss: 0.7700, Test Accuracy: 67.09%\n",
      "Epoch [389/2500], Train Loss: 0.8594, Train Accuracy: 60.88%, Test Loss: 0.8486, Test Accuracy: 63.29%\n",
      "Epoch [390/2500], Train Loss: 0.8485, Train Accuracy: 64.72%, Test Loss: 0.8296, Test Accuracy: 63.29%\n",
      "Epoch [391/2500], Train Loss: 0.8449, Train Accuracy: 64.58%, Test Loss: 0.8264, Test Accuracy: 63.29%\n",
      "Epoch [392/2500], Train Loss: 0.8655, Train Accuracy: 62.73%, Test Loss: 0.8680, Test Accuracy: 67.09%\n",
      "Epoch [393/2500], Train Loss: 0.8576, Train Accuracy: 63.87%, Test Loss: 0.7869, Test Accuracy: 64.56%\n",
      "Epoch [394/2500], Train Loss: 0.8582, Train Accuracy: 63.30%, Test Loss: 0.8184, Test Accuracy: 65.82%\n",
      "Epoch [395/2500], Train Loss: 0.8494, Train Accuracy: 64.72%, Test Loss: 0.8415, Test Accuracy: 63.29%\n",
      "Epoch [396/2500], Train Loss: 0.8525, Train Accuracy: 64.72%, Test Loss: 0.8002, Test Accuracy: 65.82%\n",
      "Epoch [397/2500], Train Loss: 0.8699, Train Accuracy: 63.30%, Test Loss: 0.7705, Test Accuracy: 65.82%\n",
      "Epoch [398/2500], Train Loss: 0.8527, Train Accuracy: 62.45%, Test Loss: 0.7595, Test Accuracy: 62.03%\n",
      "Epoch [399/2500], Train Loss: 0.8367, Train Accuracy: 64.72%, Test Loss: 0.8697, Test Accuracy: 69.62%\n",
      "Epoch [400/2500], Train Loss: 0.8570, Train Accuracy: 61.88%, Test Loss: 0.7700, Test Accuracy: 70.89%\n",
      "Epoch [401/2500], Train Loss: 0.8566, Train Accuracy: 63.16%, Test Loss: 0.9911, Test Accuracy: 60.76%\n",
      "Epoch [402/2500], Train Loss: 0.8371, Train Accuracy: 64.44%, Test Loss: 0.8390, Test Accuracy: 68.35%\n",
      "Epoch [403/2500], Train Loss: 0.8598, Train Accuracy: 64.44%, Test Loss: 0.7713, Test Accuracy: 72.15%\n",
      "Epoch [404/2500], Train Loss: 0.8379, Train Accuracy: 65.72%, Test Loss: 0.7582, Test Accuracy: 65.82%\n",
      "Epoch [405/2500], Train Loss: 0.8655, Train Accuracy: 61.74%, Test Loss: 0.7586, Test Accuracy: 65.82%\n",
      "Epoch [406/2500], Train Loss: 0.8633, Train Accuracy: 62.59%, Test Loss: 0.7877, Test Accuracy: 68.35%\n",
      "Epoch [407/2500], Train Loss: 0.8397, Train Accuracy: 63.02%, Test Loss: 0.8160, Test Accuracy: 70.89%\n",
      "Epoch [408/2500], Train Loss: 0.8795, Train Accuracy: 63.87%, Test Loss: 0.9543, Test Accuracy: 59.49%\n",
      "Epoch [409/2500], Train Loss: 0.8516, Train Accuracy: 63.16%, Test Loss: 0.9361, Test Accuracy: 60.76%\n",
      "Epoch [410/2500], Train Loss: 0.8405, Train Accuracy: 60.31%, Test Loss: 0.8418, Test Accuracy: 68.35%\n",
      "Epoch [411/2500], Train Loss: 0.8502, Train Accuracy: 62.16%, Test Loss: 0.7924, Test Accuracy: 68.35%\n",
      "Epoch [412/2500], Train Loss: 0.8790, Train Accuracy: 61.59%, Test Loss: 0.7984, Test Accuracy: 70.89%\n",
      "Epoch [413/2500], Train Loss: 0.8590, Train Accuracy: 59.74%, Test Loss: 0.9063, Test Accuracy: 62.03%\n",
      "Epoch [414/2500], Train Loss: 0.8931, Train Accuracy: 61.59%, Test Loss: 0.8175, Test Accuracy: 69.62%\n",
      "Epoch [415/2500], Train Loss: 0.8590, Train Accuracy: 61.74%, Test Loss: 0.7892, Test Accuracy: 68.35%\n",
      "Epoch [416/2500], Train Loss: 0.8555, Train Accuracy: 62.87%, Test Loss: 0.9522, Test Accuracy: 59.49%\n",
      "Epoch [417/2500], Train Loss: 0.8404, Train Accuracy: 65.01%, Test Loss: 0.7954, Test Accuracy: 65.82%\n",
      "Epoch [418/2500], Train Loss: 0.8760, Train Accuracy: 62.59%, Test Loss: 0.7671, Test Accuracy: 68.35%\n",
      "Epoch [419/2500], Train Loss: 0.8782, Train Accuracy: 62.16%, Test Loss: 0.8476, Test Accuracy: 68.35%\n",
      "Epoch [420/2500], Train Loss: 0.8541, Train Accuracy: 63.73%, Test Loss: 0.7697, Test Accuracy: 64.56%\n",
      "Epoch [421/2500], Train Loss: 0.8557, Train Accuracy: 62.02%, Test Loss: 0.7840, Test Accuracy: 67.09%\n",
      "Epoch [422/2500], Train Loss: 0.8564, Train Accuracy: 64.30%, Test Loss: 0.8194, Test Accuracy: 69.62%\n",
      "Epoch [423/2500], Train Loss: 0.8432, Train Accuracy: 63.73%, Test Loss: 0.7929, Test Accuracy: 64.56%\n",
      "Epoch [424/2500], Train Loss: 0.8522, Train Accuracy: 64.15%, Test Loss: 0.7527, Test Accuracy: 72.15%\n",
      "Epoch [425/2500], Train Loss: 0.8365, Train Accuracy: 64.30%, Test Loss: 0.7932, Test Accuracy: 63.29%\n",
      "Epoch [426/2500], Train Loss: 0.8612, Train Accuracy: 61.59%, Test Loss: 0.7931, Test Accuracy: 65.82%\n",
      "Epoch [427/2500], Train Loss: 0.8313, Train Accuracy: 65.15%, Test Loss: 0.8553, Test Accuracy: 63.29%\n",
      "Epoch [428/2500], Train Loss: 0.8504, Train Accuracy: 62.02%, Test Loss: 0.8212, Test Accuracy: 67.09%\n",
      "Epoch [429/2500], Train Loss: 0.8343, Train Accuracy: 65.86%, Test Loss: 0.8324, Test Accuracy: 64.56%\n",
      "Epoch [430/2500], Train Loss: 0.8271, Train Accuracy: 63.87%, Test Loss: 0.8567, Test Accuracy: 69.62%\n",
      "Epoch [431/2500], Train Loss: 0.8457, Train Accuracy: 62.87%, Test Loss: 1.0190, Test Accuracy: 64.56%\n",
      "Epoch [432/2500], Train Loss: 0.8348, Train Accuracy: 63.44%, Test Loss: 0.7903, Test Accuracy: 73.42%\n",
      "Epoch [433/2500], Train Loss: 0.8241, Train Accuracy: 64.01%, Test Loss: 0.8306, Test Accuracy: 70.89%\n",
      "Epoch [434/2500], Train Loss: 0.8159, Train Accuracy: 66.57%, Test Loss: 0.8011, Test Accuracy: 65.82%\n",
      "Epoch [435/2500], Train Loss: 0.8283, Train Accuracy: 65.15%, Test Loss: 0.7828, Test Accuracy: 64.56%\n",
      "Epoch [436/2500], Train Loss: 0.8766, Train Accuracy: 63.16%, Test Loss: 0.7448, Test Accuracy: 67.09%\n",
      "Epoch [437/2500], Train Loss: 0.8273, Train Accuracy: 64.01%, Test Loss: 0.7695, Test Accuracy: 70.89%\n",
      "Epoch [438/2500], Train Loss: 0.8407, Train Accuracy: 63.44%, Test Loss: 0.8363, Test Accuracy: 72.15%\n",
      "Epoch [439/2500], Train Loss: 0.8427, Train Accuracy: 63.44%, Test Loss: 0.7580, Test Accuracy: 60.76%\n",
      "Epoch [440/2500], Train Loss: 0.8285, Train Accuracy: 63.58%, Test Loss: 0.8869, Test Accuracy: 64.56%\n",
      "Epoch [441/2500], Train Loss: 0.8152, Train Accuracy: 65.43%, Test Loss: 0.8946, Test Accuracy: 63.29%\n",
      "Epoch [442/2500], Train Loss: 0.8111, Train Accuracy: 65.58%, Test Loss: 0.8329, Test Accuracy: 67.09%\n",
      "Epoch [443/2500], Train Loss: 0.8761, Train Accuracy: 61.59%, Test Loss: 0.7806, Test Accuracy: 69.62%\n",
      "Epoch [444/2500], Train Loss: 0.8427, Train Accuracy: 63.58%, Test Loss: 0.7872, Test Accuracy: 65.82%\n",
      "Epoch [445/2500], Train Loss: 0.8663, Train Accuracy: 62.16%, Test Loss: 0.8085, Test Accuracy: 63.29%\n",
      "Epoch [446/2500], Train Loss: 0.8314, Train Accuracy: 65.86%, Test Loss: 0.7948, Test Accuracy: 65.82%\n",
      "Epoch [447/2500], Train Loss: 0.8637, Train Accuracy: 64.58%, Test Loss: 0.9335, Test Accuracy: 62.03%\n",
      "Epoch [448/2500], Train Loss: 0.8318, Train Accuracy: 64.58%, Test Loss: 0.8465, Test Accuracy: 64.56%\n",
      "Epoch [449/2500], Train Loss: 0.7970, Train Accuracy: 65.86%, Test Loss: 0.8509, Test Accuracy: 59.49%\n",
      "Epoch [450/2500], Train Loss: 0.8517, Train Accuracy: 65.15%, Test Loss: 0.8031, Test Accuracy: 62.03%\n",
      "Epoch [451/2500], Train Loss: 0.8349, Train Accuracy: 61.02%, Test Loss: 0.7527, Test Accuracy: 64.56%\n",
      "Epoch [452/2500], Train Loss: 0.8480, Train Accuracy: 62.30%, Test Loss: 0.9560, Test Accuracy: 58.23%\n",
      "Epoch [453/2500], Train Loss: 0.8613, Train Accuracy: 64.30%, Test Loss: 0.8549, Test Accuracy: 63.29%\n",
      "Epoch [454/2500], Train Loss: 0.8255, Train Accuracy: 63.87%, Test Loss: 0.7693, Test Accuracy: 67.09%\n",
      "Epoch [455/2500], Train Loss: 0.8380, Train Accuracy: 63.02%, Test Loss: 0.7322, Test Accuracy: 68.35%\n",
      "Epoch [456/2500], Train Loss: 0.8345, Train Accuracy: 63.73%, Test Loss: 0.9819, Test Accuracy: 56.96%\n",
      "Epoch [457/2500], Train Loss: 0.8757, Train Accuracy: 62.73%, Test Loss: 0.9608, Test Accuracy: 60.76%\n",
      "Epoch [458/2500], Train Loss: 0.8723, Train Accuracy: 62.45%, Test Loss: 0.7666, Test Accuracy: 69.62%\n",
      "Epoch [459/2500], Train Loss: 0.8426, Train Accuracy: 62.30%, Test Loss: 0.7506, Test Accuracy: 72.15%\n",
      "Epoch [460/2500], Train Loss: 0.8344, Train Accuracy: 64.15%, Test Loss: 0.8766, Test Accuracy: 59.49%\n",
      "Epoch [461/2500], Train Loss: 0.8599, Train Accuracy: 62.59%, Test Loss: 0.7985, Test Accuracy: 65.82%\n",
      "Epoch [462/2500], Train Loss: 0.8455, Train Accuracy: 64.30%, Test Loss: 0.8022, Test Accuracy: 68.35%\n",
      "Epoch [463/2500], Train Loss: 0.8647, Train Accuracy: 63.73%, Test Loss: 0.7783, Test Accuracy: 67.09%\n",
      "Epoch [464/2500], Train Loss: 0.8674, Train Accuracy: 63.44%, Test Loss: 0.7786, Test Accuracy: 62.03%\n",
      "Epoch [465/2500], Train Loss: 0.8582, Train Accuracy: 61.88%, Test Loss: 0.7917, Test Accuracy: 69.62%\n",
      "Epoch [466/2500], Train Loss: 0.8369, Train Accuracy: 63.58%, Test Loss: 0.8868, Test Accuracy: 65.82%\n",
      "Epoch [467/2500], Train Loss: 0.8171, Train Accuracy: 64.30%, Test Loss: 0.7551, Test Accuracy: 65.82%\n",
      "Epoch [468/2500], Train Loss: 0.8437, Train Accuracy: 63.16%, Test Loss: 0.8203, Test Accuracy: 69.62%\n",
      "Epoch [469/2500], Train Loss: 0.8648, Train Accuracy: 63.58%, Test Loss: 0.8536, Test Accuracy: 70.89%\n",
      "Epoch [470/2500], Train Loss: 0.8266, Train Accuracy: 65.43%, Test Loss: 0.8067, Test Accuracy: 67.09%\n",
      "Epoch [471/2500], Train Loss: 0.8331, Train Accuracy: 64.86%, Test Loss: 0.9305, Test Accuracy: 65.82%\n",
      "Epoch [472/2500], Train Loss: 0.8248, Train Accuracy: 67.14%, Test Loss: 0.7943, Test Accuracy: 69.62%\n",
      "Epoch [473/2500], Train Loss: 0.8357, Train Accuracy: 63.87%, Test Loss: 0.7663, Test Accuracy: 69.62%\n",
      "Epoch [474/2500], Train Loss: 0.8423, Train Accuracy: 63.73%, Test Loss: 1.0951, Test Accuracy: 55.70%\n",
      "Epoch [475/2500], Train Loss: 0.8678, Train Accuracy: 62.45%, Test Loss: 0.8556, Test Accuracy: 69.62%\n",
      "Epoch [476/2500], Train Loss: 0.8421, Train Accuracy: 64.01%, Test Loss: 0.8393, Test Accuracy: 64.56%\n",
      "Epoch [477/2500], Train Loss: 0.8595, Train Accuracy: 63.73%, Test Loss: 0.8338, Test Accuracy: 63.29%\n",
      "Epoch [478/2500], Train Loss: 0.8475, Train Accuracy: 61.31%, Test Loss: 0.7789, Test Accuracy: 72.15%\n",
      "Epoch [479/2500], Train Loss: 0.8547, Train Accuracy: 62.30%, Test Loss: 0.8258, Test Accuracy: 64.56%\n",
      "Epoch [480/2500], Train Loss: 0.8697, Train Accuracy: 61.31%, Test Loss: 0.9489, Test Accuracy: 58.23%\n",
      "Epoch [481/2500], Train Loss: 0.8344, Train Accuracy: 63.58%, Test Loss: 0.9584, Test Accuracy: 60.76%\n",
      "Epoch [482/2500], Train Loss: 0.8509, Train Accuracy: 63.87%, Test Loss: 0.9001, Test Accuracy: 63.29%\n",
      "Epoch [483/2500], Train Loss: 0.8398, Train Accuracy: 62.87%, Test Loss: 0.7711, Test Accuracy: 70.89%\n",
      "Epoch [484/2500], Train Loss: 0.8461, Train Accuracy: 63.16%, Test Loss: 0.8511, Test Accuracy: 70.89%\n",
      "Epoch [485/2500], Train Loss: 0.8357, Train Accuracy: 62.87%, Test Loss: 0.8513, Test Accuracy: 67.09%\n",
      "Epoch [486/2500], Train Loss: 0.8599, Train Accuracy: 64.86%, Test Loss: 0.8008, Test Accuracy: 65.82%\n",
      "Epoch [487/2500], Train Loss: 0.8511, Train Accuracy: 64.86%, Test Loss: 0.8012, Test Accuracy: 67.09%\n",
      "Epoch [488/2500], Train Loss: 0.8431, Train Accuracy: 63.87%, Test Loss: 0.7992, Test Accuracy: 68.35%\n",
      "Epoch [489/2500], Train Loss: 0.8208, Train Accuracy: 66.00%, Test Loss: 0.8421, Test Accuracy: 65.82%\n",
      "Epoch [490/2500], Train Loss: 0.8104, Train Accuracy: 65.01%, Test Loss: 0.9984, Test Accuracy: 56.96%\n",
      "Epoch [491/2500], Train Loss: 0.8667, Train Accuracy: 64.15%, Test Loss: 0.8605, Test Accuracy: 68.35%\n",
      "Epoch [492/2500], Train Loss: 0.8117, Train Accuracy: 65.15%, Test Loss: 0.8516, Test Accuracy: 69.62%\n",
      "Epoch [493/2500], Train Loss: 0.8250, Train Accuracy: 65.01%, Test Loss: 0.7360, Test Accuracy: 64.56%\n",
      "Epoch [494/2500], Train Loss: 0.8310, Train Accuracy: 63.16%, Test Loss: 0.7550, Test Accuracy: 70.89%\n",
      "Epoch [495/2500], Train Loss: 0.8436, Train Accuracy: 64.44%, Test Loss: 0.9025, Test Accuracy: 63.29%\n",
      "Epoch [496/2500], Train Loss: 0.8530, Train Accuracy: 64.01%, Test Loss: 0.7868, Test Accuracy: 72.15%\n",
      "Epoch [497/2500], Train Loss: 0.7929, Train Accuracy: 65.29%, Test Loss: 0.8213, Test Accuracy: 68.35%\n",
      "Epoch [498/2500], Train Loss: 0.8349, Train Accuracy: 63.87%, Test Loss: 0.8514, Test Accuracy: 63.29%\n",
      "Epoch [499/2500], Train Loss: 0.8209, Train Accuracy: 63.87%, Test Loss: 0.7826, Test Accuracy: 65.82%\n",
      "Epoch [500/2500], Train Loss: 0.8166, Train Accuracy: 63.87%, Test Loss: 0.7819, Test Accuracy: 63.29%\n",
      "Epoch [501/2500], Train Loss: 0.8530, Train Accuracy: 63.87%, Test Loss: 0.8355, Test Accuracy: 69.62%\n",
      "Epoch [502/2500], Train Loss: 0.8231, Train Accuracy: 63.73%, Test Loss: 0.7385, Test Accuracy: 65.82%\n",
      "Epoch [503/2500], Train Loss: 0.8282, Train Accuracy: 64.44%, Test Loss: 0.8302, Test Accuracy: 67.09%\n",
      "Epoch [504/2500], Train Loss: 0.8443, Train Accuracy: 64.30%, Test Loss: 0.8463, Test Accuracy: 68.35%\n",
      "Epoch [505/2500], Train Loss: 0.8406, Train Accuracy: 62.30%, Test Loss: 0.7518, Test Accuracy: 63.29%\n",
      "Epoch [506/2500], Train Loss: 0.8198, Train Accuracy: 64.30%, Test Loss: 0.7733, Test Accuracy: 69.62%\n",
      "Epoch [507/2500], Train Loss: 0.8578, Train Accuracy: 64.15%, Test Loss: 0.8789, Test Accuracy: 64.56%\n",
      "Epoch [508/2500], Train Loss: 0.8646, Train Accuracy: 62.30%, Test Loss: 0.8394, Test Accuracy: 68.35%\n",
      "Epoch [509/2500], Train Loss: 0.8436, Train Accuracy: 63.30%, Test Loss: 0.7321, Test Accuracy: 69.62%\n",
      "Epoch [510/2500], Train Loss: 0.8449, Train Accuracy: 65.15%, Test Loss: 0.7429, Test Accuracy: 68.35%\n",
      "Epoch [511/2500], Train Loss: 0.8261, Train Accuracy: 62.87%, Test Loss: 0.7539, Test Accuracy: 67.09%\n",
      "Epoch [512/2500], Train Loss: 0.8176, Train Accuracy: 65.01%, Test Loss: 0.7950, Test Accuracy: 67.09%\n",
      "Epoch [513/2500], Train Loss: 0.8414, Train Accuracy: 62.73%, Test Loss: 0.8705, Test Accuracy: 62.03%\n",
      "Epoch [514/2500], Train Loss: 0.8046, Train Accuracy: 65.15%, Test Loss: 0.8225, Test Accuracy: 70.89%\n",
      "Epoch [515/2500], Train Loss: 0.8210, Train Accuracy: 65.86%, Test Loss: 0.7552, Test Accuracy: 70.89%\n",
      "Epoch [516/2500], Train Loss: 0.8191, Train Accuracy: 63.73%, Test Loss: 0.7508, Test Accuracy: 63.29%\n",
      "Epoch [517/2500], Train Loss: 0.8771, Train Accuracy: 63.58%, Test Loss: 0.9177, Test Accuracy: 65.82%\n",
      "Epoch [518/2500], Train Loss: 0.8464, Train Accuracy: 63.58%, Test Loss: 0.7715, Test Accuracy: 65.82%\n",
      "Epoch [519/2500], Train Loss: 0.8840, Train Accuracy: 61.74%, Test Loss: 0.8085, Test Accuracy: 70.89%\n",
      "Epoch [520/2500], Train Loss: 0.8542, Train Accuracy: 62.73%, Test Loss: 0.9513, Test Accuracy: 59.49%\n",
      "Epoch [521/2500], Train Loss: 0.8823, Train Accuracy: 62.30%, Test Loss: 0.7500, Test Accuracy: 68.35%\n",
      "Epoch [522/2500], Train Loss: 0.8575, Train Accuracy: 63.30%, Test Loss: 0.8220, Test Accuracy: 68.35%\n",
      "Epoch [523/2500], Train Loss: 0.8375, Train Accuracy: 64.15%, Test Loss: 0.7592, Test Accuracy: 60.76%\n",
      "Epoch [524/2500], Train Loss: 0.8296, Train Accuracy: 64.86%, Test Loss: 0.7666, Test Accuracy: 74.68%\n",
      "Epoch [525/2500], Train Loss: 0.8512, Train Accuracy: 62.73%, Test Loss: 0.8107, Test Accuracy: 65.82%\n",
      "Epoch [526/2500], Train Loss: 0.8272, Train Accuracy: 63.02%, Test Loss: 0.7706, Test Accuracy: 67.09%\n",
      "Epoch [527/2500], Train Loss: 0.8231, Train Accuracy: 64.58%, Test Loss: 0.7749, Test Accuracy: 68.35%\n",
      "Epoch [528/2500], Train Loss: 0.8340, Train Accuracy: 64.58%, Test Loss: 0.7293, Test Accuracy: 67.09%\n",
      "Epoch [529/2500], Train Loss: 0.8527, Train Accuracy: 65.15%, Test Loss: 0.8696, Test Accuracy: 65.82%\n",
      "Epoch [530/2500], Train Loss: 0.8284, Train Accuracy: 63.30%, Test Loss: 0.8544, Test Accuracy: 68.35%\n",
      "Epoch [531/2500], Train Loss: 0.7920, Train Accuracy: 65.58%, Test Loss: 0.9748, Test Accuracy: 62.03%\n",
      "Epoch [532/2500], Train Loss: 0.8256, Train Accuracy: 63.58%, Test Loss: 0.8439, Test Accuracy: 68.35%\n",
      "Epoch [533/2500], Train Loss: 0.8230, Train Accuracy: 65.15%, Test Loss: 0.7543, Test Accuracy: 74.68%\n",
      "Epoch [534/2500], Train Loss: 0.8009, Train Accuracy: 65.01%, Test Loss: 0.8019, Test Accuracy: 68.35%\n",
      "Epoch [535/2500], Train Loss: 0.8493, Train Accuracy: 63.44%, Test Loss: 0.7595, Test Accuracy: 73.42%\n",
      "Epoch [536/2500], Train Loss: 0.8453, Train Accuracy: 63.16%, Test Loss: 0.8311, Test Accuracy: 60.76%\n",
      "Epoch [537/2500], Train Loss: 0.8509, Train Accuracy: 63.02%, Test Loss: 0.9107, Test Accuracy: 64.56%\n",
      "Epoch [538/2500], Train Loss: 0.8405, Train Accuracy: 62.73%, Test Loss: 0.9094, Test Accuracy: 67.09%\n",
      "Epoch [539/2500], Train Loss: 0.8301, Train Accuracy: 64.30%, Test Loss: 0.7931, Test Accuracy: 70.89%\n",
      "Epoch [540/2500], Train Loss: 0.8105, Train Accuracy: 66.57%, Test Loss: 0.7707, Test Accuracy: 68.35%\n",
      "Epoch [541/2500], Train Loss: 0.8240, Train Accuracy: 63.02%, Test Loss: 0.7669, Test Accuracy: 72.15%\n",
      "Epoch [542/2500], Train Loss: 0.8119, Train Accuracy: 63.73%, Test Loss: 0.8401, Test Accuracy: 64.56%\n",
      "Epoch [543/2500], Train Loss: 0.8320, Train Accuracy: 63.87%, Test Loss: 0.7898, Test Accuracy: 65.82%\n",
      "Epoch [544/2500], Train Loss: 0.8337, Train Accuracy: 64.15%, Test Loss: 0.8093, Test Accuracy: 64.56%\n",
      "Epoch [545/2500], Train Loss: 0.8454, Train Accuracy: 64.72%, Test Loss: 0.7747, Test Accuracy: 67.09%\n",
      "Epoch [546/2500], Train Loss: 0.8194, Train Accuracy: 64.72%, Test Loss: 0.7541, Test Accuracy: 72.15%\n",
      "Epoch [547/2500], Train Loss: 0.8265, Train Accuracy: 65.15%, Test Loss: 0.7616, Test Accuracy: 72.15%\n",
      "Epoch [548/2500], Train Loss: 0.8428, Train Accuracy: 63.44%, Test Loss: 0.7994, Test Accuracy: 68.35%\n",
      "Epoch [549/2500], Train Loss: 0.8117, Train Accuracy: 65.72%, Test Loss: 1.0182, Test Accuracy: 59.49%\n",
      "Epoch [550/2500], Train Loss: 0.8260, Train Accuracy: 64.72%, Test Loss: 0.8228, Test Accuracy: 65.82%\n",
      "Epoch [551/2500], Train Loss: 0.8150, Train Accuracy: 63.02%, Test Loss: 0.7526, Test Accuracy: 68.35%\n",
      "Epoch [552/2500], Train Loss: 0.8638, Train Accuracy: 63.16%, Test Loss: 0.7698, Test Accuracy: 70.89%\n",
      "Epoch [553/2500], Train Loss: 0.8300, Train Accuracy: 63.02%, Test Loss: 0.8219, Test Accuracy: 69.62%\n",
      "Epoch [554/2500], Train Loss: 0.8583, Train Accuracy: 64.01%, Test Loss: 0.7962, Test Accuracy: 72.15%\n",
      "Epoch [555/2500], Train Loss: 0.8056, Train Accuracy: 65.43%, Test Loss: 0.7495, Test Accuracy: 73.42%\n",
      "Epoch [556/2500], Train Loss: 0.8263, Train Accuracy: 64.15%, Test Loss: 0.9908, Test Accuracy: 60.76%\n",
      "Epoch [557/2500], Train Loss: 0.8517, Train Accuracy: 62.59%, Test Loss: 0.8096, Test Accuracy: 65.82%\n",
      "Epoch [558/2500], Train Loss: 0.8335, Train Accuracy: 64.01%, Test Loss: 0.7943, Test Accuracy: 67.09%\n",
      "Epoch [559/2500], Train Loss: 0.8372, Train Accuracy: 62.16%, Test Loss: 0.8428, Test Accuracy: 70.89%\n",
      "Epoch [560/2500], Train Loss: 0.8333, Train Accuracy: 62.73%, Test Loss: 0.9328, Test Accuracy: 60.76%\n",
      "Epoch [561/2500], Train Loss: 0.8253, Train Accuracy: 63.58%, Test Loss: 0.7763, Test Accuracy: 65.82%\n",
      "Epoch [562/2500], Train Loss: 0.8509, Train Accuracy: 60.60%, Test Loss: 0.8295, Test Accuracy: 68.35%\n",
      "Epoch [563/2500], Train Loss: 0.8371, Train Accuracy: 62.87%, Test Loss: 0.8308, Test Accuracy: 74.68%\n",
      "Epoch [564/2500], Train Loss: 0.8182, Train Accuracy: 64.15%, Test Loss: 0.7850, Test Accuracy: 74.68%\n",
      "Epoch [565/2500], Train Loss: 0.8334, Train Accuracy: 65.15%, Test Loss: 0.7912, Test Accuracy: 72.15%\n",
      "Epoch [566/2500], Train Loss: 0.8253, Train Accuracy: 64.72%, Test Loss: 0.7695, Test Accuracy: 69.62%\n",
      "Epoch [567/2500], Train Loss: 0.8326, Train Accuracy: 64.01%, Test Loss: 0.7448, Test Accuracy: 70.89%\n",
      "Epoch [568/2500], Train Loss: 0.7982, Train Accuracy: 64.86%, Test Loss: 0.7557, Test Accuracy: 64.56%\n",
      "Epoch [569/2500], Train Loss: 0.8077, Train Accuracy: 65.43%, Test Loss: 0.7336, Test Accuracy: 65.82%\n",
      "Epoch [570/2500], Train Loss: 0.8167, Train Accuracy: 64.30%, Test Loss: 0.7640, Test Accuracy: 63.29%\n",
      "Epoch [571/2500], Train Loss: 0.8096, Train Accuracy: 65.01%, Test Loss: 0.7613, Test Accuracy: 70.89%\n",
      "Epoch [572/2500], Train Loss: 0.8082, Train Accuracy: 65.29%, Test Loss: 0.7654, Test Accuracy: 73.42%\n",
      "Epoch [573/2500], Train Loss: 0.8330, Train Accuracy: 63.16%, Test Loss: 0.7538, Test Accuracy: 59.49%\n",
      "Epoch [574/2500], Train Loss: 0.8461, Train Accuracy: 62.73%, Test Loss: 0.8272, Test Accuracy: 70.89%\n",
      "Epoch [575/2500], Train Loss: 0.8195, Train Accuracy: 65.58%, Test Loss: 0.7914, Test Accuracy: 64.56%\n",
      "Epoch [576/2500], Train Loss: 0.8369, Train Accuracy: 64.30%, Test Loss: 0.7268, Test Accuracy: 63.29%\n",
      "Epoch [577/2500], Train Loss: 0.8162, Train Accuracy: 64.44%, Test Loss: 0.8589, Test Accuracy: 67.09%\n",
      "Epoch [578/2500], Train Loss: 0.8022, Train Accuracy: 65.72%, Test Loss: 0.8093, Test Accuracy: 64.56%\n",
      "Epoch [579/2500], Train Loss: 0.8134, Train Accuracy: 64.15%, Test Loss: 0.8564, Test Accuracy: 64.56%\n",
      "Epoch [580/2500], Train Loss: 0.8320, Train Accuracy: 64.58%, Test Loss: 0.8398, Test Accuracy: 63.29%\n",
      "Epoch [581/2500], Train Loss: 0.8055, Train Accuracy: 65.01%, Test Loss: 0.8544, Test Accuracy: 62.03%\n",
      "Epoch [582/2500], Train Loss: 0.8239, Train Accuracy: 63.58%, Test Loss: 0.7560, Test Accuracy: 73.42%\n",
      "Epoch [583/2500], Train Loss: 0.7789, Train Accuracy: 64.72%, Test Loss: 0.7893, Test Accuracy: 72.15%\n",
      "Epoch [584/2500], Train Loss: 0.7932, Train Accuracy: 64.44%, Test Loss: 0.8988, Test Accuracy: 65.82%\n",
      "Epoch [585/2500], Train Loss: 0.8332, Train Accuracy: 63.73%, Test Loss: 0.9284, Test Accuracy: 60.76%\n",
      "Epoch [586/2500], Train Loss: 0.8324, Train Accuracy: 64.01%, Test Loss: 0.7542, Test Accuracy: 72.15%\n",
      "Epoch [587/2500], Train Loss: 0.8340, Train Accuracy: 64.58%, Test Loss: 0.8497, Test Accuracy: 68.35%\n",
      "Epoch [588/2500], Train Loss: 0.8170, Train Accuracy: 65.15%, Test Loss: 0.7575, Test Accuracy: 59.49%\n",
      "Epoch [589/2500], Train Loss: 0.8208, Train Accuracy: 64.44%, Test Loss: 0.8411, Test Accuracy: 64.56%\n",
      "Epoch [590/2500], Train Loss: 0.8417, Train Accuracy: 64.01%, Test Loss: 0.7777, Test Accuracy: 58.23%\n",
      "Epoch [591/2500], Train Loss: 0.8048, Train Accuracy: 64.72%, Test Loss: 0.8283, Test Accuracy: 64.56%\n",
      "Epoch [592/2500], Train Loss: 0.8237, Train Accuracy: 63.44%, Test Loss: 0.8207, Test Accuracy: 70.89%\n",
      "Epoch [593/2500], Train Loss: 0.8220, Train Accuracy: 63.73%, Test Loss: 0.8111, Test Accuracy: 67.09%\n",
      "Epoch [594/2500], Train Loss: 0.8345, Train Accuracy: 63.73%, Test Loss: 0.7591, Test Accuracy: 72.15%\n",
      "Epoch [595/2500], Train Loss: 0.8132, Train Accuracy: 62.87%, Test Loss: 0.7620, Test Accuracy: 62.03%\n",
      "Epoch [596/2500], Train Loss: 0.8367, Train Accuracy: 63.30%, Test Loss: 0.8362, Test Accuracy: 65.82%\n",
      "Epoch [597/2500], Train Loss: 0.8329, Train Accuracy: 63.16%, Test Loss: 0.7771, Test Accuracy: 73.42%\n",
      "Epoch [598/2500], Train Loss: 0.8207, Train Accuracy: 65.01%, Test Loss: 0.8304, Test Accuracy: 68.35%\n",
      "Epoch [599/2500], Train Loss: 0.8480, Train Accuracy: 63.30%, Test Loss: 0.7626, Test Accuracy: 68.35%\n",
      "Epoch [600/2500], Train Loss: 0.8230, Train Accuracy: 64.01%, Test Loss: 0.8344, Test Accuracy: 65.82%\n",
      "Epoch [601/2500], Train Loss: 0.8087, Train Accuracy: 65.86%, Test Loss: 0.7545, Test Accuracy: 63.29%\n",
      "Epoch [602/2500], Train Loss: 0.8391, Train Accuracy: 64.30%, Test Loss: 0.8488, Test Accuracy: 64.56%\n",
      "Epoch [603/2500], Train Loss: 0.8483, Train Accuracy: 65.86%, Test Loss: 0.7590, Test Accuracy: 68.35%\n",
      "Epoch [604/2500], Train Loss: 0.8322, Train Accuracy: 63.87%, Test Loss: 0.8860, Test Accuracy: 63.29%\n",
      "Epoch [605/2500], Train Loss: 0.8107, Train Accuracy: 64.58%, Test Loss: 0.7976, Test Accuracy: 64.56%\n",
      "Epoch [606/2500], Train Loss: 0.8113, Train Accuracy: 64.44%, Test Loss: 0.7438, Test Accuracy: 63.29%\n",
      "Epoch [607/2500], Train Loss: 0.8374, Train Accuracy: 62.16%, Test Loss: 0.8223, Test Accuracy: 72.15%\n",
      "Epoch [608/2500], Train Loss: 0.8344, Train Accuracy: 64.72%, Test Loss: 0.7716, Test Accuracy: 67.09%\n",
      "Epoch [609/2500], Train Loss: 0.7948, Train Accuracy: 65.29%, Test Loss: 0.8239, Test Accuracy: 64.56%\n",
      "Epoch [610/2500], Train Loss: 0.8481, Train Accuracy: 64.86%, Test Loss: 0.8190, Test Accuracy: 70.89%\n",
      "Epoch [611/2500], Train Loss: 0.8037, Train Accuracy: 65.43%, Test Loss: 0.8254, Test Accuracy: 69.62%\n",
      "Epoch [612/2500], Train Loss: 0.8083, Train Accuracy: 64.44%, Test Loss: 0.8069, Test Accuracy: 67.09%\n",
      "Epoch [613/2500], Train Loss: 0.8057, Train Accuracy: 65.72%, Test Loss: 0.9358, Test Accuracy: 64.56%\n",
      "Epoch [614/2500], Train Loss: 0.8093, Train Accuracy: 66.43%, Test Loss: 0.7620, Test Accuracy: 70.89%\n",
      "Epoch [615/2500], Train Loss: 0.8254, Train Accuracy: 64.72%, Test Loss: 0.7591, Test Accuracy: 68.35%\n",
      "Epoch [616/2500], Train Loss: 0.8127, Train Accuracy: 63.44%, Test Loss: 0.7849, Test Accuracy: 64.56%\n",
      "Epoch [617/2500], Train Loss: 0.8058, Train Accuracy: 64.86%, Test Loss: 0.7728, Test Accuracy: 65.82%\n",
      "Epoch [618/2500], Train Loss: 0.8258, Train Accuracy: 65.01%, Test Loss: 0.8104, Test Accuracy: 69.62%\n",
      "Epoch [619/2500], Train Loss: 0.8101, Train Accuracy: 64.86%, Test Loss: 0.7663, Test Accuracy: 59.49%\n",
      "Epoch [620/2500], Train Loss: 0.8454, Train Accuracy: 62.30%, Test Loss: 0.7428, Test Accuracy: 70.89%\n",
      "Epoch [621/2500], Train Loss: 0.8047, Train Accuracy: 64.44%, Test Loss: 0.7442, Test Accuracy: 62.03%\n",
      "Epoch [622/2500], Train Loss: 0.8524, Train Accuracy: 62.30%, Test Loss: 0.7788, Test Accuracy: 67.09%\n",
      "Epoch [623/2500], Train Loss: 0.8175, Train Accuracy: 63.16%, Test Loss: 0.9302, Test Accuracy: 62.03%\n",
      "Epoch [624/2500], Train Loss: 0.8318, Train Accuracy: 64.01%, Test Loss: 0.8145, Test Accuracy: 67.09%\n",
      "Epoch [625/2500], Train Loss: 0.8046, Train Accuracy: 64.44%, Test Loss: 0.7584, Test Accuracy: 70.89%\n",
      "Epoch [626/2500], Train Loss: 0.8179, Train Accuracy: 63.02%, Test Loss: 0.7771, Test Accuracy: 73.42%\n",
      "Epoch [627/2500], Train Loss: 0.7860, Train Accuracy: 64.58%, Test Loss: 0.7777, Test Accuracy: 69.62%\n",
      "Epoch [628/2500], Train Loss: 0.8327, Train Accuracy: 63.58%, Test Loss: 0.7623, Test Accuracy: 73.42%\n",
      "Epoch [629/2500], Train Loss: 0.8443, Train Accuracy: 65.29%, Test Loss: 0.7732, Test Accuracy: 64.56%\n",
      "Epoch [630/2500], Train Loss: 0.8192, Train Accuracy: 65.01%, Test Loss: 0.7619, Test Accuracy: 70.89%\n",
      "Epoch [631/2500], Train Loss: 0.7974, Train Accuracy: 65.58%, Test Loss: 0.8948, Test Accuracy: 63.29%\n",
      "Epoch [632/2500], Train Loss: 0.8313, Train Accuracy: 64.30%, Test Loss: 0.7621, Test Accuracy: 68.35%\n",
      "Epoch [633/2500], Train Loss: 0.8179, Train Accuracy: 63.30%, Test Loss: 0.7574, Test Accuracy: 64.56%\n",
      "Epoch [634/2500], Train Loss: 0.8285, Train Accuracy: 64.58%, Test Loss: 0.7337, Test Accuracy: 74.68%\n",
      "Epoch [635/2500], Train Loss: 0.8157, Train Accuracy: 64.44%, Test Loss: 0.8430, Test Accuracy: 63.29%\n",
      "Epoch [636/2500], Train Loss: 0.8461, Train Accuracy: 64.72%, Test Loss: 0.7554, Test Accuracy: 67.09%\n",
      "Epoch [637/2500], Train Loss: 0.7991, Train Accuracy: 65.58%, Test Loss: 0.7501, Test Accuracy: 74.68%\n",
      "Epoch [638/2500], Train Loss: 0.8313, Train Accuracy: 64.58%, Test Loss: 0.8061, Test Accuracy: 72.15%\n",
      "Epoch [639/2500], Train Loss: 0.8431, Train Accuracy: 63.02%, Test Loss: 0.8385, Test Accuracy: 68.35%\n",
      "Epoch [640/2500], Train Loss: 0.7897, Train Accuracy: 66.43%, Test Loss: 0.7614, Test Accuracy: 73.42%\n",
      "Epoch [641/2500], Train Loss: 0.8204, Train Accuracy: 64.72%, Test Loss: 0.9438, Test Accuracy: 65.82%\n",
      "Epoch [642/2500], Train Loss: 0.8257, Train Accuracy: 65.15%, Test Loss: 0.8042, Test Accuracy: 67.09%\n",
      "Epoch [643/2500], Train Loss: 0.8298, Train Accuracy: 64.01%, Test Loss: 0.7509, Test Accuracy: 70.89%\n",
      "Epoch [644/2500], Train Loss: 0.7723, Train Accuracy: 66.57%, Test Loss: 0.8575, Test Accuracy: 64.56%\n",
      "Epoch [645/2500], Train Loss: 0.8133, Train Accuracy: 64.30%, Test Loss: 0.7619, Test Accuracy: 73.42%\n",
      "Epoch [646/2500], Train Loss: 0.8063, Train Accuracy: 66.29%, Test Loss: 0.7975, Test Accuracy: 67.09%\n",
      "Epoch [647/2500], Train Loss: 0.8423, Train Accuracy: 63.02%, Test Loss: 0.7371, Test Accuracy: 67.09%\n",
      "Epoch [648/2500], Train Loss: 0.8149, Train Accuracy: 62.30%, Test Loss: 0.7734, Test Accuracy: 68.35%\n",
      "Epoch [649/2500], Train Loss: 0.8085, Train Accuracy: 66.00%, Test Loss: 0.8480, Test Accuracy: 68.35%\n",
      "Epoch [650/2500], Train Loss: 0.8190, Train Accuracy: 63.87%, Test Loss: 0.8609, Test Accuracy: 68.35%\n",
      "Epoch [651/2500], Train Loss: 0.8268, Train Accuracy: 62.59%, Test Loss: 0.8039, Test Accuracy: 68.35%\n",
      "Epoch [652/2500], Train Loss: 0.7978, Train Accuracy: 66.29%, Test Loss: 0.9253, Test Accuracy: 60.76%\n",
      "Epoch [653/2500], Train Loss: 0.8238, Train Accuracy: 66.57%, Test Loss: 0.8412, Test Accuracy: 63.29%\n",
      "Epoch [654/2500], Train Loss: 0.8181, Train Accuracy: 64.01%, Test Loss: 0.7757, Test Accuracy: 65.82%\n",
      "Epoch [655/2500], Train Loss: 0.8013, Train Accuracy: 64.01%, Test Loss: 0.8310, Test Accuracy: 69.62%\n",
      "Epoch [656/2500], Train Loss: 0.8094, Train Accuracy: 66.15%, Test Loss: 0.9269, Test Accuracy: 60.76%\n",
      "Epoch [657/2500], Train Loss: 0.8266, Train Accuracy: 63.58%, Test Loss: 0.7597, Test Accuracy: 70.89%\n",
      "Epoch [658/2500], Train Loss: 0.8018, Train Accuracy: 64.01%, Test Loss: 0.8350, Test Accuracy: 68.35%\n",
      "Epoch [659/2500], Train Loss: 0.8061, Train Accuracy: 65.43%, Test Loss: 0.9953, Test Accuracy: 56.96%\n",
      "Epoch [660/2500], Train Loss: 0.7982, Train Accuracy: 65.43%, Test Loss: 0.8700, Test Accuracy: 67.09%\n",
      "Epoch [661/2500], Train Loss: 0.8031, Train Accuracy: 65.86%, Test Loss: 0.8299, Test Accuracy: 65.82%\n",
      "Epoch [662/2500], Train Loss: 0.8073, Train Accuracy: 65.01%, Test Loss: 0.7436, Test Accuracy: 70.89%\n",
      "Epoch [663/2500], Train Loss: 0.8009, Train Accuracy: 64.86%, Test Loss: 0.9694, Test Accuracy: 62.03%\n",
      "Epoch [664/2500], Train Loss: 0.7930, Train Accuracy: 65.01%, Test Loss: 0.7373, Test Accuracy: 67.09%\n",
      "Epoch [665/2500], Train Loss: 0.8212, Train Accuracy: 64.44%, Test Loss: 0.9224, Test Accuracy: 63.29%\n",
      "Epoch [666/2500], Train Loss: 0.7947, Train Accuracy: 65.72%, Test Loss: 0.8465, Test Accuracy: 65.82%\n",
      "Epoch [667/2500], Train Loss: 0.7987, Train Accuracy: 66.71%, Test Loss: 0.7952, Test Accuracy: 69.62%\n",
      "Epoch [668/2500], Train Loss: 0.7996, Train Accuracy: 65.15%, Test Loss: 0.7962, Test Accuracy: 65.82%\n",
      "Epoch [669/2500], Train Loss: 0.8199, Train Accuracy: 65.01%, Test Loss: 0.7893, Test Accuracy: 67.09%\n",
      "Epoch [670/2500], Train Loss: 0.8102, Train Accuracy: 65.43%, Test Loss: 0.7478, Test Accuracy: 67.09%\n",
      "Epoch [671/2500], Train Loss: 0.8236, Train Accuracy: 66.43%, Test Loss: 0.7412, Test Accuracy: 62.03%\n",
      "Epoch [672/2500], Train Loss: 0.7950, Train Accuracy: 64.30%, Test Loss: 0.7660, Test Accuracy: 70.89%\n",
      "Epoch [673/2500], Train Loss: 0.7915, Train Accuracy: 65.43%, Test Loss: 0.9169, Test Accuracy: 63.29%\n",
      "Epoch [674/2500], Train Loss: 0.8457, Train Accuracy: 63.87%, Test Loss: 0.8358, Test Accuracy: 62.03%\n",
      "Epoch [675/2500], Train Loss: 0.8252, Train Accuracy: 64.15%, Test Loss: 0.7382, Test Accuracy: 60.76%\n",
      "Epoch [676/2500], Train Loss: 0.8077, Train Accuracy: 64.44%, Test Loss: 0.7657, Test Accuracy: 64.56%\n",
      "Epoch [677/2500], Train Loss: 0.8258, Train Accuracy: 63.58%, Test Loss: 0.7501, Test Accuracy: 73.42%\n",
      "Epoch [678/2500], Train Loss: 0.8492, Train Accuracy: 61.02%, Test Loss: 0.7910, Test Accuracy: 72.15%\n",
      "Epoch [679/2500], Train Loss: 0.8216, Train Accuracy: 63.30%, Test Loss: 0.7749, Test Accuracy: 74.68%\n",
      "Epoch [680/2500], Train Loss: 0.8053, Train Accuracy: 64.58%, Test Loss: 0.7710, Test Accuracy: 74.68%\n",
      "Epoch [681/2500], Train Loss: 0.8096, Train Accuracy: 65.86%, Test Loss: 0.7772, Test Accuracy: 73.42%\n",
      "Epoch [682/2500], Train Loss: 0.8100, Train Accuracy: 65.01%, Test Loss: 0.8566, Test Accuracy: 67.09%\n",
      "Epoch [683/2500], Train Loss: 0.7967, Train Accuracy: 65.86%, Test Loss: 0.8485, Test Accuracy: 64.56%\n",
      "Epoch [684/2500], Train Loss: 0.7901, Train Accuracy: 66.43%, Test Loss: 0.7304, Test Accuracy: 62.03%\n",
      "Epoch [685/2500], Train Loss: 0.7876, Train Accuracy: 64.44%, Test Loss: 0.8368, Test Accuracy: 65.82%\n",
      "Epoch [686/2500], Train Loss: 0.8180, Train Accuracy: 66.57%, Test Loss: 0.8003, Test Accuracy: 64.56%\n",
      "Epoch [687/2500], Train Loss: 0.8114, Train Accuracy: 65.43%, Test Loss: 0.7816, Test Accuracy: 68.35%\n",
      "Epoch [688/2500], Train Loss: 0.8020, Train Accuracy: 65.01%, Test Loss: 0.7902, Test Accuracy: 68.35%\n",
      "Epoch [689/2500], Train Loss: 0.8366, Train Accuracy: 63.02%, Test Loss: 0.8432, Test Accuracy: 69.62%\n",
      "Epoch [690/2500], Train Loss: 0.8108, Train Accuracy: 64.15%, Test Loss: 0.8569, Test Accuracy: 62.03%\n",
      "Epoch [691/2500], Train Loss: 0.8242, Train Accuracy: 64.58%, Test Loss: 0.7282, Test Accuracy: 67.09%\n",
      "Epoch [692/2500], Train Loss: 0.8279, Train Accuracy: 62.59%, Test Loss: 0.7751, Test Accuracy: 69.62%\n",
      "Epoch [693/2500], Train Loss: 0.8270, Train Accuracy: 65.29%, Test Loss: 0.7221, Test Accuracy: 64.56%\n",
      "Epoch [694/2500], Train Loss: 0.8413, Train Accuracy: 64.58%, Test Loss: 0.8368, Test Accuracy: 68.35%\n",
      "Epoch [695/2500], Train Loss: 0.8295, Train Accuracy: 65.15%, Test Loss: 0.7536, Test Accuracy: 70.89%\n",
      "Epoch [696/2500], Train Loss: 0.8231, Train Accuracy: 66.29%, Test Loss: 0.8812, Test Accuracy: 62.03%\n",
      "Epoch [697/2500], Train Loss: 0.7916, Train Accuracy: 66.29%, Test Loss: 0.7954, Test Accuracy: 70.89%\n",
      "Epoch [698/2500], Train Loss: 0.8250, Train Accuracy: 64.15%, Test Loss: 0.7507, Test Accuracy: 60.76%\n",
      "Epoch [699/2500], Train Loss: 0.7904, Train Accuracy: 65.29%, Test Loss: 0.8233, Test Accuracy: 69.62%\n",
      "Epoch [700/2500], Train Loss: 0.8219, Train Accuracy: 64.58%, Test Loss: 0.9847, Test Accuracy: 58.23%\n",
      "Epoch [701/2500], Train Loss: 0.8051, Train Accuracy: 63.16%, Test Loss: 0.8715, Test Accuracy: 63.29%\n",
      "Epoch [702/2500], Train Loss: 0.8038, Train Accuracy: 67.28%, Test Loss: 0.8421, Test Accuracy: 67.09%\n",
      "Epoch [703/2500], Train Loss: 0.8050, Train Accuracy: 65.43%, Test Loss: 0.7274, Test Accuracy: 67.09%\n",
      "Epoch [704/2500], Train Loss: 0.7845, Train Accuracy: 66.43%, Test Loss: 0.7537, Test Accuracy: 70.89%\n",
      "Epoch [705/2500], Train Loss: 0.8274, Train Accuracy: 62.45%, Test Loss: 0.8260, Test Accuracy: 69.62%\n",
      "Epoch [706/2500], Train Loss: 0.7914, Train Accuracy: 66.57%, Test Loss: 0.7907, Test Accuracy: 65.82%\n",
      "Epoch [707/2500], Train Loss: 0.8181, Train Accuracy: 66.00%, Test Loss: 0.9601, Test Accuracy: 63.29%\n",
      "Epoch [708/2500], Train Loss: 0.8532, Train Accuracy: 62.73%, Test Loss: 0.8163, Test Accuracy: 69.62%\n",
      "Epoch [709/2500], Train Loss: 0.8221, Train Accuracy: 66.71%, Test Loss: 0.8704, Test Accuracy: 64.56%\n",
      "Epoch [710/2500], Train Loss: 0.8018, Train Accuracy: 66.57%, Test Loss: 0.7641, Test Accuracy: 73.42%\n",
      "Epoch [711/2500], Train Loss: 0.8285, Train Accuracy: 64.15%, Test Loss: 0.8142, Test Accuracy: 65.82%\n",
      "Epoch [712/2500], Train Loss: 0.8160, Train Accuracy: 64.58%, Test Loss: 0.7915, Test Accuracy: 63.29%\n",
      "Epoch [713/2500], Train Loss: 0.8177, Train Accuracy: 64.72%, Test Loss: 0.7558, Test Accuracy: 70.89%\n",
      "Epoch [714/2500], Train Loss: 0.8277, Train Accuracy: 65.58%, Test Loss: 0.7262, Test Accuracy: 67.09%\n",
      "Epoch [715/2500], Train Loss: 0.8169, Train Accuracy: 64.86%, Test Loss: 0.7767, Test Accuracy: 70.89%\n",
      "Epoch [716/2500], Train Loss: 0.8276, Train Accuracy: 65.15%, Test Loss: 0.7580, Test Accuracy: 69.62%\n",
      "Epoch [717/2500], Train Loss: 0.8026, Train Accuracy: 66.15%, Test Loss: 0.8078, Test Accuracy: 67.09%\n",
      "Epoch [718/2500], Train Loss: 0.8339, Train Accuracy: 63.02%, Test Loss: 0.7809, Test Accuracy: 65.82%\n",
      "Epoch [719/2500], Train Loss: 0.8044, Train Accuracy: 65.43%, Test Loss: 0.7736, Test Accuracy: 72.15%\n",
      "Epoch [720/2500], Train Loss: 0.8444, Train Accuracy: 63.44%, Test Loss: 0.7689, Test Accuracy: 70.89%\n",
      "Epoch [721/2500], Train Loss: 0.7908, Train Accuracy: 66.86%, Test Loss: 0.7866, Test Accuracy: 70.89%\n",
      "Epoch [722/2500], Train Loss: 0.8119, Train Accuracy: 64.86%, Test Loss: 0.7416, Test Accuracy: 67.09%\n",
      "Epoch [723/2500], Train Loss: 0.8167, Train Accuracy: 64.30%, Test Loss: 0.7347, Test Accuracy: 67.09%\n",
      "Epoch [724/2500], Train Loss: 0.8150, Train Accuracy: 64.44%, Test Loss: 0.8077, Test Accuracy: 68.35%\n",
      "Epoch [725/2500], Train Loss: 0.7937, Train Accuracy: 65.43%, Test Loss: 0.7514, Test Accuracy: 73.42%\n",
      "Epoch [726/2500], Train Loss: 0.7807, Train Accuracy: 66.00%, Test Loss: 0.7983, Test Accuracy: 67.09%\n",
      "Epoch [727/2500], Train Loss: 0.7982, Train Accuracy: 66.71%, Test Loss: 0.7300, Test Accuracy: 67.09%\n",
      "Epoch [728/2500], Train Loss: 0.8143, Train Accuracy: 65.58%, Test Loss: 0.7679, Test Accuracy: 73.42%\n",
      "Epoch [729/2500], Train Loss: 0.7914, Train Accuracy: 64.58%, Test Loss: 0.7875, Test Accuracy: 68.35%\n",
      "Epoch [730/2500], Train Loss: 0.8126, Train Accuracy: 65.43%, Test Loss: 0.8307, Test Accuracy: 68.35%\n",
      "Epoch [731/2500], Train Loss: 0.8371, Train Accuracy: 64.86%, Test Loss: 0.7254, Test Accuracy: 64.56%\n",
      "Epoch [732/2500], Train Loss: 0.8087, Train Accuracy: 64.72%, Test Loss: 0.8154, Test Accuracy: 73.42%\n",
      "Epoch [733/2500], Train Loss: 0.7857, Train Accuracy: 65.01%, Test Loss: 0.9088, Test Accuracy: 65.82%\n",
      "Epoch [734/2500], Train Loss: 0.8380, Train Accuracy: 62.73%, Test Loss: 0.7527, Test Accuracy: 73.42%\n",
      "Epoch [735/2500], Train Loss: 0.8335, Train Accuracy: 62.30%, Test Loss: 0.8981, Test Accuracy: 64.56%\n",
      "Epoch [736/2500], Train Loss: 0.8137, Train Accuracy: 63.16%, Test Loss: 0.8793, Test Accuracy: 62.03%\n",
      "Epoch [737/2500], Train Loss: 0.8049, Train Accuracy: 64.72%, Test Loss: 0.8114, Test Accuracy: 70.89%\n",
      "Epoch [738/2500], Train Loss: 0.7995, Train Accuracy: 63.16%, Test Loss: 0.7548, Test Accuracy: 69.62%\n",
      "Epoch [739/2500], Train Loss: 0.7835, Train Accuracy: 65.86%, Test Loss: 0.7802, Test Accuracy: 70.89%\n",
      "Epoch [740/2500], Train Loss: 0.8179, Train Accuracy: 64.44%, Test Loss: 0.7966, Test Accuracy: 64.56%\n",
      "Epoch [741/2500], Train Loss: 0.8175, Train Accuracy: 63.44%, Test Loss: 0.7184, Test Accuracy: 68.35%\n",
      "Epoch [742/2500], Train Loss: 0.8134, Train Accuracy: 64.58%, Test Loss: 0.8214, Test Accuracy: 69.62%\n",
      "Epoch [743/2500], Train Loss: 0.7951, Train Accuracy: 67.00%, Test Loss: 0.9141, Test Accuracy: 60.76%\n",
      "Epoch [744/2500], Train Loss: 0.8328, Train Accuracy: 63.44%, Test Loss: 0.7989, Test Accuracy: 65.82%\n",
      "Epoch [745/2500], Train Loss: 0.8235, Train Accuracy: 62.02%, Test Loss: 0.7677, Test Accuracy: 72.15%\n",
      "Epoch [746/2500], Train Loss: 0.8238, Train Accuracy: 64.86%, Test Loss: 0.7366, Test Accuracy: 69.62%\n",
      "Epoch [747/2500], Train Loss: 0.8042, Train Accuracy: 64.30%, Test Loss: 0.7368, Test Accuracy: 62.03%\n",
      "Epoch [748/2500], Train Loss: 0.8296, Train Accuracy: 63.87%, Test Loss: 0.9325, Test Accuracy: 68.35%\n",
      "Epoch [749/2500], Train Loss: 0.7874, Train Accuracy: 66.43%, Test Loss: 0.7439, Test Accuracy: 64.56%\n",
      "Epoch [750/2500], Train Loss: 0.8129, Train Accuracy: 63.58%, Test Loss: 0.7654, Test Accuracy: 74.68%\n",
      "Epoch [751/2500], Train Loss: 0.8062, Train Accuracy: 66.00%, Test Loss: 0.7863, Test Accuracy: 67.09%\n",
      "Epoch [752/2500], Train Loss: 0.8135, Train Accuracy: 65.15%, Test Loss: 0.8002, Test Accuracy: 68.35%\n",
      "Epoch [753/2500], Train Loss: 0.8487, Train Accuracy: 62.73%, Test Loss: 0.7720, Test Accuracy: 64.56%\n",
      "Epoch [754/2500], Train Loss: 0.8289, Train Accuracy: 63.30%, Test Loss: 0.8272, Test Accuracy: 69.62%\n",
      "Epoch [755/2500], Train Loss: 0.8363, Train Accuracy: 63.58%, Test Loss: 0.7814, Test Accuracy: 68.35%\n",
      "Epoch [756/2500], Train Loss: 0.7925, Train Accuracy: 66.15%, Test Loss: 0.7544, Test Accuracy: 63.29%\n",
      "Epoch [757/2500], Train Loss: 0.7805, Train Accuracy: 66.29%, Test Loss: 0.8977, Test Accuracy: 65.82%\n",
      "Epoch [758/2500], Train Loss: 0.8030, Train Accuracy: 65.72%, Test Loss: 0.7665, Test Accuracy: 65.82%\n",
      "Epoch [759/2500], Train Loss: 0.7868, Train Accuracy: 66.57%, Test Loss: 0.8670, Test Accuracy: 69.62%\n",
      "Epoch [760/2500], Train Loss: 0.8372, Train Accuracy: 64.44%, Test Loss: 0.8930, Test Accuracy: 60.76%\n",
      "Epoch [761/2500], Train Loss: 0.8286, Train Accuracy: 65.29%, Test Loss: 0.7595, Test Accuracy: 70.89%\n",
      "Epoch [762/2500], Train Loss: 0.7868, Train Accuracy: 65.29%, Test Loss: 0.7903, Test Accuracy: 68.35%\n",
      "Epoch [763/2500], Train Loss: 0.8015, Train Accuracy: 66.86%, Test Loss: 0.8146, Test Accuracy: 67.09%\n",
      "Epoch [764/2500], Train Loss: 0.8263, Train Accuracy: 65.72%, Test Loss: 0.7533, Test Accuracy: 67.09%\n",
      "Epoch [765/2500], Train Loss: 0.8098, Train Accuracy: 64.44%, Test Loss: 0.8133, Test Accuracy: 63.29%\n",
      "Epoch [766/2500], Train Loss: 0.8125, Train Accuracy: 66.57%, Test Loss: 0.7787, Test Accuracy: 74.68%\n",
      "Epoch [767/2500], Train Loss: 0.8057, Train Accuracy: 64.30%, Test Loss: 0.8247, Test Accuracy: 67.09%\n",
      "Epoch [768/2500], Train Loss: 0.8372, Train Accuracy: 66.00%, Test Loss: 0.8235, Test Accuracy: 69.62%\n",
      "Epoch [769/2500], Train Loss: 0.7914, Train Accuracy: 64.44%, Test Loss: 0.7704, Test Accuracy: 73.42%\n",
      "Epoch [770/2500], Train Loss: 0.7757, Train Accuracy: 67.28%, Test Loss: 0.8303, Test Accuracy: 69.62%\n",
      "Epoch [771/2500], Train Loss: 0.7635, Train Accuracy: 66.29%, Test Loss: 0.8102, Test Accuracy: 65.82%\n",
      "Epoch [772/2500], Train Loss: 0.7998, Train Accuracy: 65.72%, Test Loss: 0.8303, Test Accuracy: 65.82%\n",
      "Epoch [773/2500], Train Loss: 0.8406, Train Accuracy: 64.72%, Test Loss: 0.7317, Test Accuracy: 63.29%\n",
      "Epoch [774/2500], Train Loss: 0.7961, Train Accuracy: 65.86%, Test Loss: 0.7476, Test Accuracy: 74.68%\n",
      "Epoch [775/2500], Train Loss: 0.8237, Train Accuracy: 65.29%, Test Loss: 0.8453, Test Accuracy: 59.49%\n",
      "Epoch [776/2500], Train Loss: 0.7888, Train Accuracy: 65.01%, Test Loss: 0.7372, Test Accuracy: 70.89%\n",
      "Epoch [777/2500], Train Loss: 0.7918, Train Accuracy: 65.43%, Test Loss: 0.8540, Test Accuracy: 67.09%\n",
      "Epoch [778/2500], Train Loss: 0.7988, Train Accuracy: 65.01%, Test Loss: 0.7583, Test Accuracy: 69.62%\n",
      "Epoch [779/2500], Train Loss: 0.8125, Train Accuracy: 65.72%, Test Loss: 0.7378, Test Accuracy: 69.62%\n",
      "Epoch [780/2500], Train Loss: 0.8097, Train Accuracy: 64.15%, Test Loss: 0.7553, Test Accuracy: 74.68%\n",
      "Epoch [781/2500], Train Loss: 0.8188, Train Accuracy: 63.44%, Test Loss: 0.7623, Test Accuracy: 72.15%\n",
      "Epoch [782/2500], Train Loss: 0.8043, Train Accuracy: 64.44%, Test Loss: 0.8478, Test Accuracy: 63.29%\n",
      "Epoch [783/2500], Train Loss: 0.8206, Train Accuracy: 63.87%, Test Loss: 0.7203, Test Accuracy: 65.82%\n",
      "Epoch [784/2500], Train Loss: 0.7788, Train Accuracy: 66.29%, Test Loss: 0.8001, Test Accuracy: 72.15%\n",
      "Epoch [785/2500], Train Loss: 0.8125, Train Accuracy: 64.72%, Test Loss: 0.8035, Test Accuracy: 68.35%\n",
      "Epoch [786/2500], Train Loss: 0.8122, Train Accuracy: 68.28%, Test Loss: 0.7565, Test Accuracy: 63.29%\n",
      "Epoch [787/2500], Train Loss: 0.8197, Train Accuracy: 64.58%, Test Loss: 0.7547, Test Accuracy: 73.42%\n",
      "Epoch [788/2500], Train Loss: 0.8132, Train Accuracy: 65.43%, Test Loss: 0.7421, Test Accuracy: 72.15%\n",
      "Epoch [789/2500], Train Loss: 0.8003, Train Accuracy: 66.71%, Test Loss: 0.8580, Test Accuracy: 63.29%\n",
      "Epoch [790/2500], Train Loss: 0.8466, Train Accuracy: 64.58%, Test Loss: 0.7504, Test Accuracy: 62.03%\n",
      "Epoch [791/2500], Train Loss: 0.8014, Train Accuracy: 65.43%, Test Loss: 0.7970, Test Accuracy: 65.82%\n",
      "Epoch [792/2500], Train Loss: 0.8107, Train Accuracy: 64.72%, Test Loss: 0.8556, Test Accuracy: 63.29%\n",
      "Epoch [793/2500], Train Loss: 0.8031, Train Accuracy: 64.86%, Test Loss: 0.7756, Test Accuracy: 72.15%\n",
      "Epoch [794/2500], Train Loss: 0.8171, Train Accuracy: 65.01%, Test Loss: 0.7660, Test Accuracy: 70.89%\n",
      "Epoch [795/2500], Train Loss: 0.7893, Train Accuracy: 64.58%, Test Loss: 0.8472, Test Accuracy: 64.56%\n",
      "Epoch [796/2500], Train Loss: 0.8183, Train Accuracy: 64.44%, Test Loss: 0.8254, Test Accuracy: 65.82%\n",
      "Epoch [797/2500], Train Loss: 0.8157, Train Accuracy: 65.29%, Test Loss: 0.7410, Test Accuracy: 64.56%\n",
      "Epoch [798/2500], Train Loss: 0.8287, Train Accuracy: 63.73%, Test Loss: 0.7676, Test Accuracy: 68.35%\n",
      "Epoch [799/2500], Train Loss: 0.7888, Train Accuracy: 64.86%, Test Loss: 0.7620, Test Accuracy: 68.35%\n",
      "Epoch [800/2500], Train Loss: 0.8389, Train Accuracy: 63.87%, Test Loss: 0.7583, Test Accuracy: 67.09%\n",
      "Epoch [801/2500], Train Loss: 0.7693, Train Accuracy: 65.15%, Test Loss: 0.7839, Test Accuracy: 68.35%\n",
      "Epoch [802/2500], Train Loss: 0.7929, Train Accuracy: 64.30%, Test Loss: 0.7459, Test Accuracy: 63.29%\n",
      "Epoch [803/2500], Train Loss: 0.8211, Train Accuracy: 65.15%, Test Loss: 0.9052, Test Accuracy: 62.03%\n",
      "Epoch [804/2500], Train Loss: 0.8361, Train Accuracy: 64.15%, Test Loss: 0.7770, Test Accuracy: 73.42%\n",
      "Epoch [805/2500], Train Loss: 0.7976, Train Accuracy: 64.86%, Test Loss: 0.9943, Test Accuracy: 63.29%\n",
      "Epoch [806/2500], Train Loss: 0.7739, Train Accuracy: 66.00%, Test Loss: 0.8426, Test Accuracy: 72.15%\n",
      "Epoch [807/2500], Train Loss: 0.7991, Train Accuracy: 65.86%, Test Loss: 0.7847, Test Accuracy: 68.35%\n",
      "Epoch [808/2500], Train Loss: 0.8198, Train Accuracy: 65.01%, Test Loss: 0.7937, Test Accuracy: 65.82%\n",
      "Epoch [809/2500], Train Loss: 0.7803, Train Accuracy: 65.86%, Test Loss: 0.8093, Test Accuracy: 72.15%\n",
      "Epoch [810/2500], Train Loss: 0.8165, Train Accuracy: 64.30%, Test Loss: 0.8098, Test Accuracy: 70.89%\n",
      "Epoch [811/2500], Train Loss: 0.7984, Train Accuracy: 63.73%, Test Loss: 0.7320, Test Accuracy: 67.09%\n",
      "Epoch [812/2500], Train Loss: 0.7937, Train Accuracy: 65.86%, Test Loss: 0.8963, Test Accuracy: 67.09%\n",
      "Epoch [813/2500], Train Loss: 0.7852, Train Accuracy: 66.57%, Test Loss: 0.7307, Test Accuracy: 69.62%\n",
      "Epoch [814/2500], Train Loss: 0.7985, Train Accuracy: 65.15%, Test Loss: 0.7788, Test Accuracy: 69.62%\n",
      "Epoch [815/2500], Train Loss: 0.8106, Train Accuracy: 64.01%, Test Loss: 0.7673, Test Accuracy: 69.62%\n",
      "Epoch [816/2500], Train Loss: 0.8145, Train Accuracy: 65.72%, Test Loss: 0.7613, Test Accuracy: 72.15%\n",
      "Epoch [817/2500], Train Loss: 0.8187, Train Accuracy: 64.01%, Test Loss: 0.7424, Test Accuracy: 72.15%\n",
      "Epoch [818/2500], Train Loss: 0.8135, Train Accuracy: 65.72%, Test Loss: 0.8201, Test Accuracy: 69.62%\n",
      "Epoch [819/2500], Train Loss: 0.8087, Train Accuracy: 65.43%, Test Loss: 0.8432, Test Accuracy: 64.56%\n",
      "Epoch [820/2500], Train Loss: 0.7830, Train Accuracy: 68.28%, Test Loss: 0.7286, Test Accuracy: 63.29%\n",
      "Epoch [821/2500], Train Loss: 0.8060, Train Accuracy: 65.86%, Test Loss: 0.7521, Test Accuracy: 65.82%\n",
      "Epoch [822/2500], Train Loss: 0.8183, Train Accuracy: 66.15%, Test Loss: 0.7618, Test Accuracy: 64.56%\n",
      "Epoch [823/2500], Train Loss: 0.7985, Train Accuracy: 65.29%, Test Loss: 0.8338, Test Accuracy: 64.56%\n",
      "Epoch [824/2500], Train Loss: 0.8138, Train Accuracy: 65.01%, Test Loss: 0.7533, Test Accuracy: 69.62%\n",
      "Epoch [825/2500], Train Loss: 0.8112, Train Accuracy: 64.15%, Test Loss: 0.8402, Test Accuracy: 69.62%\n",
      "Epoch [826/2500], Train Loss: 0.8208, Train Accuracy: 65.58%, Test Loss: 0.7759, Test Accuracy: 72.15%\n",
      "Epoch [827/2500], Train Loss: 0.8280, Train Accuracy: 63.30%, Test Loss: 0.8613, Test Accuracy: 68.35%\n",
      "Epoch [828/2500], Train Loss: 0.7915, Train Accuracy: 66.57%, Test Loss: 0.8729, Test Accuracy: 67.09%\n",
      "Epoch [829/2500], Train Loss: 0.7933, Train Accuracy: 65.43%, Test Loss: 0.7335, Test Accuracy: 68.35%\n",
      "Epoch [830/2500], Train Loss: 0.8197, Train Accuracy: 63.02%, Test Loss: 0.7848, Test Accuracy: 67.09%\n",
      "Epoch [831/2500], Train Loss: 0.7897, Train Accuracy: 65.86%, Test Loss: 0.8056, Test Accuracy: 64.56%\n",
      "Epoch [832/2500], Train Loss: 0.8204, Train Accuracy: 64.86%, Test Loss: 0.7207, Test Accuracy: 68.35%\n",
      "Epoch [833/2500], Train Loss: 0.8152, Train Accuracy: 64.44%, Test Loss: 0.7904, Test Accuracy: 67.09%\n",
      "Epoch [834/2500], Train Loss: 0.8115, Train Accuracy: 65.29%, Test Loss: 0.8367, Test Accuracy: 67.09%\n",
      "Epoch [835/2500], Train Loss: 0.7819, Train Accuracy: 66.86%, Test Loss: 0.7618, Test Accuracy: 69.62%\n",
      "Epoch [836/2500], Train Loss: 0.8130, Train Accuracy: 64.72%, Test Loss: 0.8129, Test Accuracy: 73.42%\n",
      "Epoch [837/2500], Train Loss: 0.8041, Train Accuracy: 63.30%, Test Loss: 0.7858, Test Accuracy: 70.89%\n",
      "Epoch [838/2500], Train Loss: 0.7938, Train Accuracy: 66.43%, Test Loss: 0.7209, Test Accuracy: 72.15%\n",
      "Epoch [839/2500], Train Loss: 0.8009, Train Accuracy: 64.58%, Test Loss: 0.7273, Test Accuracy: 68.35%\n",
      "Epoch [840/2500], Train Loss: 0.7975, Train Accuracy: 65.43%, Test Loss: 0.7363, Test Accuracy: 72.15%\n",
      "Epoch [841/2500], Train Loss: 0.8112, Train Accuracy: 65.01%, Test Loss: 0.7880, Test Accuracy: 68.35%\n",
      "Epoch [842/2500], Train Loss: 0.7974, Train Accuracy: 65.72%, Test Loss: 0.7508, Test Accuracy: 70.89%\n",
      "Epoch [843/2500], Train Loss: 0.8192, Train Accuracy: 65.58%, Test Loss: 0.7528, Test Accuracy: 72.15%\n",
      "Epoch [844/2500], Train Loss: 0.8165, Train Accuracy: 65.15%, Test Loss: 0.7458, Test Accuracy: 72.15%\n",
      "Epoch [845/2500], Train Loss: 0.8315, Train Accuracy: 64.15%, Test Loss: 0.9820, Test Accuracy: 60.76%\n",
      "Epoch [846/2500], Train Loss: 0.7820, Train Accuracy: 67.14%, Test Loss: 0.7458, Test Accuracy: 63.29%\n",
      "Epoch [847/2500], Train Loss: 0.8033, Train Accuracy: 64.86%, Test Loss: 0.7506, Test Accuracy: 62.03%\n",
      "Epoch [848/2500], Train Loss: 0.8121, Train Accuracy: 66.86%, Test Loss: 0.7276, Test Accuracy: 70.89%\n",
      "Epoch [849/2500], Train Loss: 0.8226, Train Accuracy: 62.87%, Test Loss: 0.7326, Test Accuracy: 74.68%\n",
      "Epoch [850/2500], Train Loss: 0.8126, Train Accuracy: 64.15%, Test Loss: 0.7597, Test Accuracy: 72.15%\n",
      "Epoch [851/2500], Train Loss: 0.8044, Train Accuracy: 64.86%, Test Loss: 0.9320, Test Accuracy: 62.03%\n",
      "Epoch [852/2500], Train Loss: 0.7812, Train Accuracy: 67.00%, Test Loss: 0.7597, Test Accuracy: 67.09%\n",
      "Epoch [853/2500], Train Loss: 0.7782, Train Accuracy: 67.57%, Test Loss: 0.7785, Test Accuracy: 70.89%\n",
      "Epoch [854/2500], Train Loss: 0.8053, Train Accuracy: 65.15%, Test Loss: 0.7498, Test Accuracy: 73.42%\n",
      "Epoch [855/2500], Train Loss: 0.7974, Train Accuracy: 65.86%, Test Loss: 0.7571, Test Accuracy: 69.62%\n",
      "Epoch [856/2500], Train Loss: 0.8006, Train Accuracy: 66.43%, Test Loss: 0.7575, Test Accuracy: 73.42%\n",
      "Epoch [857/2500], Train Loss: 0.7817, Train Accuracy: 65.58%, Test Loss: 0.8634, Test Accuracy: 63.29%\n",
      "Epoch [858/2500], Train Loss: 0.7790, Train Accuracy: 66.29%, Test Loss: 0.7758, Test Accuracy: 73.42%\n",
      "Epoch [859/2500], Train Loss: 0.8075, Train Accuracy: 65.72%, Test Loss: 0.7780, Test Accuracy: 68.35%\n",
      "Epoch [860/2500], Train Loss: 0.8012, Train Accuracy: 64.30%, Test Loss: 0.7768, Test Accuracy: 67.09%\n",
      "Epoch [861/2500], Train Loss: 0.8404, Train Accuracy: 63.44%, Test Loss: 0.8803, Test Accuracy: 64.56%\n",
      "Epoch [862/2500], Train Loss: 0.8149, Train Accuracy: 65.86%, Test Loss: 0.8079, Test Accuracy: 69.62%\n",
      "Epoch [863/2500], Train Loss: 0.7759, Train Accuracy: 65.58%, Test Loss: 0.8460, Test Accuracy: 67.09%\n",
      "Epoch [864/2500], Train Loss: 0.7814, Train Accuracy: 67.14%, Test Loss: 0.7627, Test Accuracy: 68.35%\n",
      "Epoch [865/2500], Train Loss: 0.8031, Train Accuracy: 64.30%, Test Loss: 0.7631, Test Accuracy: 68.35%\n",
      "Epoch [866/2500], Train Loss: 0.7923, Train Accuracy: 66.29%, Test Loss: 0.7995, Test Accuracy: 69.62%\n",
      "Epoch [867/2500], Train Loss: 0.7937, Train Accuracy: 65.15%, Test Loss: 0.8064, Test Accuracy: 69.62%\n",
      "Epoch [868/2500], Train Loss: 0.7974, Train Accuracy: 64.44%, Test Loss: 0.7797, Test Accuracy: 72.15%\n",
      "Epoch [869/2500], Train Loss: 0.8283, Train Accuracy: 62.73%, Test Loss: 0.7589, Test Accuracy: 73.42%\n",
      "Epoch [870/2500], Train Loss: 0.7894, Train Accuracy: 66.00%, Test Loss: 0.8570, Test Accuracy: 63.29%\n",
      "Epoch [871/2500], Train Loss: 0.7814, Train Accuracy: 65.86%, Test Loss: 0.7786, Test Accuracy: 67.09%\n",
      "Epoch [872/2500], Train Loss: 0.8083, Train Accuracy: 65.29%, Test Loss: 0.7782, Test Accuracy: 68.35%\n",
      "Epoch [873/2500], Train Loss: 0.8005, Train Accuracy: 65.43%, Test Loss: 0.7730, Test Accuracy: 72.15%\n",
      "Epoch [874/2500], Train Loss: 0.8060, Train Accuracy: 65.43%, Test Loss: 0.7459, Test Accuracy: 62.03%\n",
      "Epoch [875/2500], Train Loss: 0.7996, Train Accuracy: 65.29%, Test Loss: 0.7487, Test Accuracy: 73.42%\n",
      "Epoch [876/2500], Train Loss: 0.8078, Train Accuracy: 67.43%, Test Loss: 0.7692, Test Accuracy: 67.09%\n",
      "Epoch [877/2500], Train Loss: 0.7956, Train Accuracy: 65.29%, Test Loss: 0.7629, Test Accuracy: 68.35%\n",
      "Epoch [878/2500], Train Loss: 0.7782, Train Accuracy: 65.72%, Test Loss: 0.9109, Test Accuracy: 62.03%\n",
      "Epoch [879/2500], Train Loss: 0.7917, Train Accuracy: 67.99%, Test Loss: 0.7235, Test Accuracy: 73.42%\n",
      "Epoch [880/2500], Train Loss: 0.8121, Train Accuracy: 63.87%, Test Loss: 0.7811, Test Accuracy: 65.82%\n",
      "Epoch [881/2500], Train Loss: 0.7872, Train Accuracy: 66.71%, Test Loss: 0.7062, Test Accuracy: 70.89%\n",
      "Epoch [882/2500], Train Loss: 0.8288, Train Accuracy: 65.72%, Test Loss: 0.7137, Test Accuracy: 65.82%\n",
      "Epoch [883/2500], Train Loss: 0.8267, Train Accuracy: 65.58%, Test Loss: 0.7394, Test Accuracy: 68.35%\n",
      "Epoch [884/2500], Train Loss: 0.8117, Train Accuracy: 65.58%, Test Loss: 0.7356, Test Accuracy: 72.15%\n",
      "Epoch [885/2500], Train Loss: 0.8316, Train Accuracy: 65.01%, Test Loss: 0.7595, Test Accuracy: 72.15%\n",
      "Epoch [886/2500], Train Loss: 0.8016, Train Accuracy: 64.01%, Test Loss: 0.8189, Test Accuracy: 70.89%\n",
      "Epoch [887/2500], Train Loss: 0.7641, Train Accuracy: 66.29%, Test Loss: 0.7284, Test Accuracy: 67.09%\n",
      "Epoch [888/2500], Train Loss: 0.8271, Train Accuracy: 63.02%, Test Loss: 0.8572, Test Accuracy: 67.09%\n",
      "Epoch [889/2500], Train Loss: 0.8120, Train Accuracy: 63.30%, Test Loss: 0.7721, Test Accuracy: 65.82%\n",
      "Epoch [890/2500], Train Loss: 0.8095, Train Accuracy: 65.72%, Test Loss: 0.8904, Test Accuracy: 63.29%\n",
      "Epoch [891/2500], Train Loss: 0.7835, Train Accuracy: 65.43%, Test Loss: 0.8652, Test Accuracy: 63.29%\n",
      "Epoch [892/2500], Train Loss: 0.7990, Train Accuracy: 65.15%, Test Loss: 0.9499, Test Accuracy: 60.76%\n",
      "Epoch [893/2500], Train Loss: 0.7984, Train Accuracy: 66.00%, Test Loss: 0.7534, Test Accuracy: 72.15%\n",
      "Epoch [894/2500], Train Loss: 0.8204, Train Accuracy: 64.01%, Test Loss: 0.8464, Test Accuracy: 62.03%\n",
      "Epoch [895/2500], Train Loss: 0.7998, Train Accuracy: 65.01%, Test Loss: 0.7585, Test Accuracy: 73.42%\n",
      "Epoch [896/2500], Train Loss: 0.7786, Train Accuracy: 65.15%, Test Loss: 0.7636, Test Accuracy: 69.62%\n",
      "Epoch [897/2500], Train Loss: 0.7717, Train Accuracy: 65.15%, Test Loss: 0.8265, Test Accuracy: 72.15%\n",
      "Epoch [898/2500], Train Loss: 0.8084, Train Accuracy: 64.30%, Test Loss: 0.7299, Test Accuracy: 67.09%\n",
      "Epoch [899/2500], Train Loss: 0.8156, Train Accuracy: 63.30%, Test Loss: 0.7199, Test Accuracy: 64.56%\n",
      "Epoch [900/2500], Train Loss: 0.7786, Train Accuracy: 64.72%, Test Loss: 0.7322, Test Accuracy: 72.15%\n",
      "Epoch [901/2500], Train Loss: 0.8114, Train Accuracy: 63.73%, Test Loss: 0.7842, Test Accuracy: 72.15%\n",
      "Epoch [902/2500], Train Loss: 0.8043, Train Accuracy: 64.58%, Test Loss: 0.8749, Test Accuracy: 60.76%\n",
      "Epoch [903/2500], Train Loss: 0.8243, Train Accuracy: 65.01%, Test Loss: 0.7878, Test Accuracy: 68.35%\n",
      "Epoch [904/2500], Train Loss: 0.8173, Train Accuracy: 63.44%, Test Loss: 0.8820, Test Accuracy: 65.82%\n",
      "Epoch [905/2500], Train Loss: 0.7874, Train Accuracy: 66.71%, Test Loss: 0.7489, Test Accuracy: 69.62%\n",
      "Epoch [906/2500], Train Loss: 0.7889, Train Accuracy: 64.86%, Test Loss: 0.8228, Test Accuracy: 64.56%\n",
      "Epoch [907/2500], Train Loss: 0.7960, Train Accuracy: 66.29%, Test Loss: 0.7625, Test Accuracy: 68.35%\n",
      "Epoch [908/2500], Train Loss: 0.7790, Train Accuracy: 64.44%, Test Loss: 0.7678, Test Accuracy: 65.82%\n",
      "Epoch [909/2500], Train Loss: 0.7766, Train Accuracy: 65.72%, Test Loss: 0.7874, Test Accuracy: 69.62%\n",
      "Epoch [910/2500], Train Loss: 0.7816, Train Accuracy: 66.43%, Test Loss: 0.7280, Test Accuracy: 70.89%\n",
      "Epoch [911/2500], Train Loss: 0.8093, Train Accuracy: 66.00%, Test Loss: 0.8461, Test Accuracy: 62.03%\n",
      "Epoch [912/2500], Train Loss: 0.8602, Train Accuracy: 64.15%, Test Loss: 0.7403, Test Accuracy: 70.89%\n",
      "Epoch [913/2500], Train Loss: 0.7828, Train Accuracy: 66.43%, Test Loss: 0.7501, Test Accuracy: 65.82%\n",
      "Epoch [914/2500], Train Loss: 0.7856, Train Accuracy: 65.58%, Test Loss: 0.7379, Test Accuracy: 68.35%\n",
      "Epoch [915/2500], Train Loss: 0.7882, Train Accuracy: 67.00%, Test Loss: 0.8720, Test Accuracy: 63.29%\n",
      "Epoch [916/2500], Train Loss: 0.7832, Train Accuracy: 65.72%, Test Loss: 0.8544, Test Accuracy: 67.09%\n",
      "Epoch [917/2500], Train Loss: 0.8106, Train Accuracy: 64.58%, Test Loss: 0.8963, Test Accuracy: 63.29%\n",
      "Epoch [918/2500], Train Loss: 0.7947, Train Accuracy: 64.72%, Test Loss: 0.8654, Test Accuracy: 64.56%\n",
      "Epoch [919/2500], Train Loss: 0.7857, Train Accuracy: 67.57%, Test Loss: 0.7711, Test Accuracy: 69.62%\n",
      "Epoch [920/2500], Train Loss: 0.8000, Train Accuracy: 65.29%, Test Loss: 0.7275, Test Accuracy: 67.09%\n",
      "Epoch [921/2500], Train Loss: 0.8032, Train Accuracy: 64.72%, Test Loss: 0.7931, Test Accuracy: 74.68%\n",
      "Epoch [922/2500], Train Loss: 0.7903, Train Accuracy: 64.01%, Test Loss: 0.8023, Test Accuracy: 64.56%\n",
      "Epoch [923/2500], Train Loss: 0.7701, Train Accuracy: 64.15%, Test Loss: 0.9436, Test Accuracy: 60.76%\n",
      "Epoch [924/2500], Train Loss: 0.7890, Train Accuracy: 64.15%, Test Loss: 0.8105, Test Accuracy: 67.09%\n",
      "Epoch [925/2500], Train Loss: 0.7971, Train Accuracy: 64.72%, Test Loss: 0.7796, Test Accuracy: 67.09%\n",
      "Epoch [926/2500], Train Loss: 0.7990, Train Accuracy: 65.72%, Test Loss: 0.7477, Test Accuracy: 69.62%\n",
      "Epoch [927/2500], Train Loss: 0.7672, Train Accuracy: 67.99%, Test Loss: 0.7546, Test Accuracy: 68.35%\n",
      "Epoch [928/2500], Train Loss: 0.8023, Train Accuracy: 65.43%, Test Loss: 0.8185, Test Accuracy: 67.09%\n",
      "Epoch [929/2500], Train Loss: 0.7850, Train Accuracy: 64.44%, Test Loss: 0.7322, Test Accuracy: 73.42%\n",
      "Epoch [930/2500], Train Loss: 0.7916, Train Accuracy: 67.14%, Test Loss: 0.7666, Test Accuracy: 69.62%\n",
      "Epoch [931/2500], Train Loss: 0.7894, Train Accuracy: 66.00%, Test Loss: 0.7945, Test Accuracy: 70.89%\n",
      "Epoch [932/2500], Train Loss: 0.7773, Train Accuracy: 67.28%, Test Loss: 0.8803, Test Accuracy: 65.82%\n",
      "Epoch [933/2500], Train Loss: 0.7919, Train Accuracy: 65.86%, Test Loss: 0.8384, Test Accuracy: 68.35%\n",
      "Epoch [934/2500], Train Loss: 0.7904, Train Accuracy: 67.28%, Test Loss: 0.8967, Test Accuracy: 63.29%\n",
      "Epoch [935/2500], Train Loss: 0.7915, Train Accuracy: 65.86%, Test Loss: 0.8609, Test Accuracy: 63.29%\n",
      "Epoch [936/2500], Train Loss: 0.7948, Train Accuracy: 66.71%, Test Loss: 0.8375, Test Accuracy: 69.62%\n",
      "Epoch [937/2500], Train Loss: 0.7917, Train Accuracy: 64.86%, Test Loss: 0.7751, Test Accuracy: 67.09%\n",
      "Epoch [938/2500], Train Loss: 0.7887, Train Accuracy: 65.15%, Test Loss: 0.8084, Test Accuracy: 70.89%\n",
      "Epoch [939/2500], Train Loss: 0.8123, Train Accuracy: 64.72%, Test Loss: 0.7710, Test Accuracy: 70.89%\n",
      "Epoch [940/2500], Train Loss: 0.8335, Train Accuracy: 65.01%, Test Loss: 0.7840, Test Accuracy: 72.15%\n",
      "Epoch [941/2500], Train Loss: 0.7823, Train Accuracy: 66.29%, Test Loss: 0.7592, Test Accuracy: 67.09%\n",
      "Epoch [942/2500], Train Loss: 0.7918, Train Accuracy: 64.72%, Test Loss: 0.7701, Test Accuracy: 73.42%\n",
      "Epoch [943/2500], Train Loss: 0.7758, Train Accuracy: 67.28%, Test Loss: 0.8133, Test Accuracy: 68.35%\n",
      "Epoch [944/2500], Train Loss: 0.8109, Train Accuracy: 65.58%, Test Loss: 0.7432, Test Accuracy: 73.42%\n",
      "Epoch [945/2500], Train Loss: 0.8074, Train Accuracy: 64.72%, Test Loss: 0.8072, Test Accuracy: 65.82%\n",
      "Epoch [946/2500], Train Loss: 0.8083, Train Accuracy: 63.02%, Test Loss: 0.7443, Test Accuracy: 69.62%\n",
      "Epoch [947/2500], Train Loss: 0.8034, Train Accuracy: 66.29%, Test Loss: 0.7761, Test Accuracy: 74.68%\n",
      "Epoch [948/2500], Train Loss: 0.8164, Train Accuracy: 67.14%, Test Loss: 0.7687, Test Accuracy: 69.62%\n",
      "Epoch [949/2500], Train Loss: 0.7796, Train Accuracy: 67.99%, Test Loss: 0.7579, Test Accuracy: 73.42%\n",
      "Epoch [950/2500], Train Loss: 0.7862, Train Accuracy: 66.86%, Test Loss: 0.7574, Test Accuracy: 70.89%\n",
      "Epoch [951/2500], Train Loss: 0.7687, Train Accuracy: 66.57%, Test Loss: 0.8122, Test Accuracy: 67.09%\n",
      "Epoch [952/2500], Train Loss: 0.7758, Train Accuracy: 64.58%, Test Loss: 0.7407, Test Accuracy: 72.15%\n",
      "Epoch [953/2500], Train Loss: 0.7890, Train Accuracy: 66.43%, Test Loss: 0.7397, Test Accuracy: 65.82%\n",
      "Epoch [954/2500], Train Loss: 0.8065, Train Accuracy: 65.72%, Test Loss: 0.7625, Test Accuracy: 67.09%\n",
      "Epoch [955/2500], Train Loss: 0.7813, Train Accuracy: 66.15%, Test Loss: 0.7334, Test Accuracy: 68.35%\n",
      "Epoch [956/2500], Train Loss: 0.7575, Train Accuracy: 65.58%, Test Loss: 0.9506, Test Accuracy: 62.03%\n",
      "Epoch [957/2500], Train Loss: 0.7855, Train Accuracy: 65.43%, Test Loss: 0.7996, Test Accuracy: 69.62%\n",
      "Epoch [958/2500], Train Loss: 0.7790, Train Accuracy: 65.43%, Test Loss: 0.7888, Test Accuracy: 72.15%\n",
      "Epoch [959/2500], Train Loss: 0.8060, Train Accuracy: 66.43%, Test Loss: 0.8073, Test Accuracy: 65.82%\n",
      "Epoch [960/2500], Train Loss: 0.7857, Train Accuracy: 64.01%, Test Loss: 0.7860, Test Accuracy: 68.35%\n",
      "Epoch [961/2500], Train Loss: 0.7838, Train Accuracy: 65.01%, Test Loss: 0.7362, Test Accuracy: 69.62%\n",
      "Epoch [962/2500], Train Loss: 0.8158, Train Accuracy: 65.01%, Test Loss: 0.7976, Test Accuracy: 68.35%\n",
      "Epoch [963/2500], Train Loss: 0.8165, Train Accuracy: 66.29%, Test Loss: 0.7315, Test Accuracy: 65.82%\n",
      "Epoch [964/2500], Train Loss: 0.7609, Train Accuracy: 67.14%, Test Loss: 0.7509, Test Accuracy: 73.42%\n",
      "Epoch [965/2500], Train Loss: 0.7689, Train Accuracy: 68.28%, Test Loss: 0.7322, Test Accuracy: 65.82%\n",
      "Epoch [966/2500], Train Loss: 0.7761, Train Accuracy: 66.86%, Test Loss: 0.8908, Test Accuracy: 67.09%\n",
      "Epoch [967/2500], Train Loss: 0.8010, Train Accuracy: 65.72%, Test Loss: 0.7301, Test Accuracy: 72.15%\n",
      "Epoch [968/2500], Train Loss: 0.7882, Train Accuracy: 66.57%, Test Loss: 0.7559, Test Accuracy: 69.62%\n",
      "Epoch [969/2500], Train Loss: 0.8059, Train Accuracy: 66.29%, Test Loss: 0.8514, Test Accuracy: 65.82%\n",
      "Epoch [970/2500], Train Loss: 0.7729, Train Accuracy: 66.29%, Test Loss: 0.7497, Test Accuracy: 64.56%\n",
      "Epoch [971/2500], Train Loss: 0.8063, Train Accuracy: 64.15%, Test Loss: 0.7356, Test Accuracy: 70.89%\n",
      "Epoch [972/2500], Train Loss: 0.8052, Train Accuracy: 65.01%, Test Loss: 0.7377, Test Accuracy: 70.89%\n",
      "Epoch [973/2500], Train Loss: 0.7795, Train Accuracy: 66.29%, Test Loss: 0.8650, Test Accuracy: 64.56%\n",
      "Epoch [974/2500], Train Loss: 0.7761, Train Accuracy: 65.86%, Test Loss: 0.8107, Test Accuracy: 67.09%\n",
      "Epoch [975/2500], Train Loss: 0.7996, Train Accuracy: 64.72%, Test Loss: 0.7789, Test Accuracy: 70.89%\n",
      "Epoch [976/2500], Train Loss: 0.8143, Train Accuracy: 65.72%, Test Loss: 0.8454, Test Accuracy: 64.56%\n",
      "Epoch [977/2500], Train Loss: 0.7891, Train Accuracy: 65.43%, Test Loss: 0.7742, Test Accuracy: 69.62%\n",
      "Epoch [978/2500], Train Loss: 0.8012, Train Accuracy: 63.87%, Test Loss: 0.7771, Test Accuracy: 70.89%\n",
      "Epoch [979/2500], Train Loss: 0.7753, Train Accuracy: 67.14%, Test Loss: 0.7530, Test Accuracy: 67.09%\n",
      "Epoch [980/2500], Train Loss: 0.7819, Train Accuracy: 66.00%, Test Loss: 0.7547, Test Accuracy: 68.35%\n",
      "Epoch [981/2500], Train Loss: 0.7885, Train Accuracy: 66.00%, Test Loss: 0.7355, Test Accuracy: 73.42%\n",
      "Epoch [982/2500], Train Loss: 0.8132, Train Accuracy: 65.01%, Test Loss: 0.7248, Test Accuracy: 65.82%\n",
      "Epoch [983/2500], Train Loss: 0.8425, Train Accuracy: 63.58%, Test Loss: 0.7307, Test Accuracy: 72.15%\n",
      "Epoch [984/2500], Train Loss: 0.7753, Train Accuracy: 66.71%, Test Loss: 0.8368, Test Accuracy: 64.56%\n",
      "Epoch [985/2500], Train Loss: 0.7950, Train Accuracy: 65.43%, Test Loss: 0.8874, Test Accuracy: 60.76%\n",
      "Epoch [986/2500], Train Loss: 0.7844, Train Accuracy: 64.58%, Test Loss: 0.7959, Test Accuracy: 70.89%\n",
      "Epoch [987/2500], Train Loss: 0.7962, Train Accuracy: 64.30%, Test Loss: 0.7946, Test Accuracy: 72.15%\n",
      "Epoch [988/2500], Train Loss: 0.7725, Train Accuracy: 66.57%, Test Loss: 0.8145, Test Accuracy: 72.15%\n",
      "Epoch [989/2500], Train Loss: 0.8005, Train Accuracy: 67.00%, Test Loss: 0.7405, Test Accuracy: 67.09%\n",
      "Epoch [990/2500], Train Loss: 0.8011, Train Accuracy: 66.00%, Test Loss: 0.7422, Test Accuracy: 67.09%\n",
      "Epoch [991/2500], Train Loss: 0.8106, Train Accuracy: 65.29%, Test Loss: 0.8358, Test Accuracy: 69.62%\n",
      "Epoch [992/2500], Train Loss: 0.7776, Train Accuracy: 66.29%, Test Loss: 0.7303, Test Accuracy: 69.62%\n",
      "Epoch [993/2500], Train Loss: 0.7990, Train Accuracy: 64.58%, Test Loss: 0.7269, Test Accuracy: 64.56%\n",
      "Epoch [994/2500], Train Loss: 0.7775, Train Accuracy: 66.71%, Test Loss: 0.7504, Test Accuracy: 67.09%\n",
      "Epoch [995/2500], Train Loss: 0.7845, Train Accuracy: 64.72%, Test Loss: 0.7464, Test Accuracy: 69.62%\n",
      "Epoch [996/2500], Train Loss: 0.8070, Train Accuracy: 65.15%, Test Loss: 0.7738, Test Accuracy: 73.42%\n",
      "Epoch [997/2500], Train Loss: 0.7823, Train Accuracy: 66.43%, Test Loss: 0.7602, Test Accuracy: 73.42%\n",
      "Epoch [998/2500], Train Loss: 0.7938, Train Accuracy: 66.86%, Test Loss: 0.7384, Test Accuracy: 65.82%\n",
      "Epoch [999/2500], Train Loss: 0.8045, Train Accuracy: 66.57%, Test Loss: 0.7799, Test Accuracy: 68.35%\n",
      "Epoch [1000/2500], Train Loss: 0.8263, Train Accuracy: 64.15%, Test Loss: 0.7974, Test Accuracy: 70.89%\n",
      "Epoch [1001/2500], Train Loss: 0.7772, Train Accuracy: 67.00%, Test Loss: 0.7557, Test Accuracy: 69.62%\n",
      "Epoch [1002/2500], Train Loss: 0.8209, Train Accuracy: 63.16%, Test Loss: 0.7309, Test Accuracy: 62.03%\n",
      "Epoch [1003/2500], Train Loss: 0.8047, Train Accuracy: 66.43%, Test Loss: 0.7259, Test Accuracy: 64.56%\n",
      "Epoch [1004/2500], Train Loss: 0.7744, Train Accuracy: 67.28%, Test Loss: 0.8298, Test Accuracy: 68.35%\n",
      "Epoch [1005/2500], Train Loss: 0.7970, Train Accuracy: 65.01%, Test Loss: 0.7149, Test Accuracy: 67.09%\n",
      "Epoch [1006/2500], Train Loss: 0.7980, Train Accuracy: 66.29%, Test Loss: 0.7233, Test Accuracy: 64.56%\n",
      "Epoch [1007/2500], Train Loss: 0.7732, Train Accuracy: 66.86%, Test Loss: 0.8554, Test Accuracy: 67.09%\n",
      "Epoch [1008/2500], Train Loss: 0.8042, Train Accuracy: 65.58%, Test Loss: 0.7773, Test Accuracy: 67.09%\n",
      "Epoch [1009/2500], Train Loss: 0.8050, Train Accuracy: 65.01%, Test Loss: 0.9566, Test Accuracy: 59.49%\n",
      "Epoch [1010/2500], Train Loss: 0.7825, Train Accuracy: 65.72%, Test Loss: 0.8652, Test Accuracy: 67.09%\n",
      "Epoch [1011/2500], Train Loss: 0.8010, Train Accuracy: 64.72%, Test Loss: 0.9034, Test Accuracy: 64.56%\n",
      "Epoch [1012/2500], Train Loss: 0.8026, Train Accuracy: 65.86%, Test Loss: 0.7278, Test Accuracy: 70.89%\n",
      "Epoch [1013/2500], Train Loss: 0.8131, Train Accuracy: 61.88%, Test Loss: 0.7546, Test Accuracy: 74.68%\n",
      "Epoch [1014/2500], Train Loss: 0.7966, Train Accuracy: 67.43%, Test Loss: 0.8985, Test Accuracy: 60.76%\n",
      "Epoch [1015/2500], Train Loss: 0.7781, Train Accuracy: 66.86%, Test Loss: 0.7556, Test Accuracy: 70.89%\n",
      "Epoch [1016/2500], Train Loss: 0.8011, Train Accuracy: 64.86%, Test Loss: 0.8023, Test Accuracy: 70.89%\n",
      "Epoch [1017/2500], Train Loss: 0.7941, Train Accuracy: 65.01%, Test Loss: 0.7390, Test Accuracy: 72.15%\n",
      "Epoch [1018/2500], Train Loss: 0.7978, Train Accuracy: 64.58%, Test Loss: 0.7906, Test Accuracy: 64.56%\n",
      "Epoch [1019/2500], Train Loss: 0.7953, Train Accuracy: 65.58%, Test Loss: 0.7220, Test Accuracy: 69.62%\n",
      "Epoch [1020/2500], Train Loss: 0.8220, Train Accuracy: 66.43%, Test Loss: 0.7477, Test Accuracy: 70.89%\n",
      "Epoch [1021/2500], Train Loss: 0.8095, Train Accuracy: 65.43%, Test Loss: 0.7231, Test Accuracy: 65.82%\n",
      "Epoch [1022/2500], Train Loss: 0.7827, Train Accuracy: 68.42%, Test Loss: 0.7299, Test Accuracy: 72.15%\n",
      "Epoch [1023/2500], Train Loss: 0.8192, Train Accuracy: 62.45%, Test Loss: 0.7277, Test Accuracy: 69.62%\n",
      "Epoch [1024/2500], Train Loss: 0.7764, Train Accuracy: 64.44%, Test Loss: 0.8070, Test Accuracy: 65.82%\n",
      "Epoch [1025/2500], Train Loss: 0.7713, Train Accuracy: 67.43%, Test Loss: 0.9232, Test Accuracy: 64.56%\n",
      "Epoch [1026/2500], Train Loss: 0.7987, Train Accuracy: 65.01%, Test Loss: 0.7910, Test Accuracy: 68.35%\n",
      "Epoch [1027/2500], Train Loss: 0.7993, Train Accuracy: 66.29%, Test Loss: 0.7999, Test Accuracy: 74.68%\n",
      "Epoch [1028/2500], Train Loss: 0.7924, Train Accuracy: 65.58%, Test Loss: 0.7517, Test Accuracy: 70.89%\n",
      "Epoch [1029/2500], Train Loss: 0.7814, Train Accuracy: 65.58%, Test Loss: 0.8161, Test Accuracy: 68.35%\n",
      "Epoch [1030/2500], Train Loss: 0.7871, Train Accuracy: 64.44%, Test Loss: 0.8466, Test Accuracy: 69.62%\n",
      "Epoch [1031/2500], Train Loss: 0.8001, Train Accuracy: 64.86%, Test Loss: 0.7722, Test Accuracy: 67.09%\n",
      "Epoch [1032/2500], Train Loss: 0.8158, Train Accuracy: 65.72%, Test Loss: 0.8137, Test Accuracy: 70.89%\n",
      "Epoch [1033/2500], Train Loss: 0.7757, Train Accuracy: 67.99%, Test Loss: 0.7374, Test Accuracy: 67.09%\n",
      "Epoch [1034/2500], Train Loss: 0.8115, Train Accuracy: 66.15%, Test Loss: 0.7351, Test Accuracy: 68.35%\n",
      "Epoch [1035/2500], Train Loss: 0.7886, Train Accuracy: 65.72%, Test Loss: 0.7353, Test Accuracy: 70.89%\n",
      "Epoch [1036/2500], Train Loss: 0.7793, Train Accuracy: 64.86%, Test Loss: 0.8400, Test Accuracy: 63.29%\n",
      "Epoch [1037/2500], Train Loss: 0.7935, Train Accuracy: 64.86%, Test Loss: 0.7307, Test Accuracy: 72.15%\n",
      "Epoch [1038/2500], Train Loss: 0.7905, Train Accuracy: 65.29%, Test Loss: 0.7431, Test Accuracy: 69.62%\n",
      "Epoch [1039/2500], Train Loss: 0.7783, Train Accuracy: 67.57%, Test Loss: 0.7261, Test Accuracy: 63.29%\n",
      "Epoch [1040/2500], Train Loss: 0.7932, Train Accuracy: 65.58%, Test Loss: 0.7531, Test Accuracy: 72.15%\n",
      "Epoch [1041/2500], Train Loss: 0.7934, Train Accuracy: 64.15%, Test Loss: 0.7379, Test Accuracy: 63.29%\n",
      "Epoch [1042/2500], Train Loss: 0.7779, Train Accuracy: 67.00%, Test Loss: 0.7759, Test Accuracy: 69.62%\n",
      "Epoch [1043/2500], Train Loss: 0.7933, Train Accuracy: 67.28%, Test Loss: 0.7295, Test Accuracy: 70.89%\n",
      "Epoch [1044/2500], Train Loss: 0.7976, Train Accuracy: 64.72%, Test Loss: 0.7681, Test Accuracy: 72.15%\n",
      "Epoch [1045/2500], Train Loss: 0.7675, Train Accuracy: 66.15%, Test Loss: 0.7719, Test Accuracy: 70.89%\n",
      "Epoch [1046/2500], Train Loss: 0.8148, Train Accuracy: 64.58%, Test Loss: 0.7393, Test Accuracy: 65.82%\n",
      "Epoch [1047/2500], Train Loss: 0.7895, Train Accuracy: 66.00%, Test Loss: 0.7701, Test Accuracy: 67.09%\n",
      "Epoch [1048/2500], Train Loss: 0.7696, Train Accuracy: 68.99%, Test Loss: 0.7435, Test Accuracy: 73.42%\n",
      "Epoch [1049/2500], Train Loss: 0.7891, Train Accuracy: 64.72%, Test Loss: 0.8185, Test Accuracy: 70.89%\n",
      "Epoch [1050/2500], Train Loss: 0.7784, Train Accuracy: 66.15%, Test Loss: 0.7257, Test Accuracy: 64.56%\n",
      "Epoch [1051/2500], Train Loss: 0.7823, Train Accuracy: 65.72%, Test Loss: 0.7894, Test Accuracy: 64.56%\n",
      "Epoch [1052/2500], Train Loss: 0.8032, Train Accuracy: 65.29%, Test Loss: 0.7955, Test Accuracy: 70.89%\n",
      "Epoch [1053/2500], Train Loss: 0.7551, Train Accuracy: 67.57%, Test Loss: 0.7823, Test Accuracy: 62.03%\n",
      "Epoch [1054/2500], Train Loss: 0.7827, Train Accuracy: 67.99%, Test Loss: 0.7848, Test Accuracy: 67.09%\n",
      "Epoch [1055/2500], Train Loss: 0.7817, Train Accuracy: 64.58%, Test Loss: 0.8354, Test Accuracy: 69.62%\n",
      "Epoch [1056/2500], Train Loss: 0.7973, Train Accuracy: 65.86%, Test Loss: 0.9053, Test Accuracy: 60.76%\n",
      "Epoch [1057/2500], Train Loss: 0.7904, Train Accuracy: 66.29%, Test Loss: 1.0336, Test Accuracy: 56.96%\n",
      "Epoch [1058/2500], Train Loss: 0.8062, Train Accuracy: 66.29%, Test Loss: 0.7882, Test Accuracy: 65.82%\n",
      "Epoch [1059/2500], Train Loss: 0.7377, Train Accuracy: 67.28%, Test Loss: 0.9214, Test Accuracy: 62.03%\n",
      "Epoch [1060/2500], Train Loss: 0.7987, Train Accuracy: 65.43%, Test Loss: 0.7515, Test Accuracy: 64.56%\n",
      "Epoch [1061/2500], Train Loss: 0.8157, Train Accuracy: 63.87%, Test Loss: 0.8287, Test Accuracy: 69.62%\n",
      "Epoch [1062/2500], Train Loss: 0.8073, Train Accuracy: 64.72%, Test Loss: 0.8353, Test Accuracy: 67.09%\n",
      "Epoch [1063/2500], Train Loss: 0.7860, Train Accuracy: 67.28%, Test Loss: 0.8495, Test Accuracy: 65.82%\n",
      "Epoch [1064/2500], Train Loss: 0.8106, Train Accuracy: 64.15%, Test Loss: 0.7942, Test Accuracy: 65.82%\n",
      "Epoch [1065/2500], Train Loss: 0.7928, Train Accuracy: 64.86%, Test Loss: 0.7438, Test Accuracy: 69.62%\n",
      "Epoch [1066/2500], Train Loss: 0.7912, Train Accuracy: 66.15%, Test Loss: 0.7230, Test Accuracy: 68.35%\n",
      "Epoch [1067/2500], Train Loss: 0.7934, Train Accuracy: 64.86%, Test Loss: 0.7559, Test Accuracy: 72.15%\n",
      "Epoch [1068/2500], Train Loss: 0.7824, Train Accuracy: 63.58%, Test Loss: 0.7879, Test Accuracy: 67.09%\n",
      "Epoch [1069/2500], Train Loss: 0.7663, Train Accuracy: 67.28%, Test Loss: 0.7613, Test Accuracy: 72.15%\n",
      "Epoch [1070/2500], Train Loss: 0.8251, Train Accuracy: 62.87%, Test Loss: 0.7443, Test Accuracy: 65.82%\n",
      "Epoch [1071/2500], Train Loss: 0.7913, Train Accuracy: 65.15%, Test Loss: 0.7627, Test Accuracy: 70.89%\n",
      "Epoch [1072/2500], Train Loss: 0.7925, Train Accuracy: 67.28%, Test Loss: 0.7357, Test Accuracy: 65.82%\n",
      "Epoch [1073/2500], Train Loss: 0.7955, Train Accuracy: 64.30%, Test Loss: 0.8429, Test Accuracy: 67.09%\n",
      "Epoch [1074/2500], Train Loss: 0.8191, Train Accuracy: 63.30%, Test Loss: 0.7495, Test Accuracy: 70.89%\n",
      "Epoch [1075/2500], Train Loss: 0.7745, Train Accuracy: 65.86%, Test Loss: 0.7720, Test Accuracy: 69.62%\n",
      "Epoch [1076/2500], Train Loss: 0.7505, Train Accuracy: 68.14%, Test Loss: 0.8702, Test Accuracy: 68.35%\n",
      "Epoch [1077/2500], Train Loss: 0.8195, Train Accuracy: 64.30%, Test Loss: 0.7694, Test Accuracy: 64.56%\n",
      "Epoch [1078/2500], Train Loss: 0.7814, Train Accuracy: 66.15%, Test Loss: 0.8596, Test Accuracy: 69.62%\n",
      "Epoch [1079/2500], Train Loss: 0.7680, Train Accuracy: 66.86%, Test Loss: 0.7780, Test Accuracy: 65.82%\n",
      "Epoch [1080/2500], Train Loss: 0.7876, Train Accuracy: 65.01%, Test Loss: 0.8202, Test Accuracy: 65.82%\n",
      "Epoch [1081/2500], Train Loss: 0.7954, Train Accuracy: 63.87%, Test Loss: 0.8164, Test Accuracy: 65.82%\n",
      "Epoch [1082/2500], Train Loss: 0.7896, Train Accuracy: 66.57%, Test Loss: 0.7319, Test Accuracy: 69.62%\n",
      "Epoch [1083/2500], Train Loss: 0.7960, Train Accuracy: 65.43%, Test Loss: 0.8759, Test Accuracy: 63.29%\n",
      "Epoch [1084/2500], Train Loss: 0.7790, Train Accuracy: 66.43%, Test Loss: 0.7834, Test Accuracy: 73.42%\n",
      "Epoch [1085/2500], Train Loss: 0.7710, Train Accuracy: 65.29%, Test Loss: 0.8779, Test Accuracy: 62.03%\n",
      "Epoch [1086/2500], Train Loss: 0.8072, Train Accuracy: 64.44%, Test Loss: 0.7620, Test Accuracy: 75.95%\n",
      "Epoch [1087/2500], Train Loss: 0.7952, Train Accuracy: 64.44%, Test Loss: 0.8459, Test Accuracy: 62.03%\n",
      "Epoch [1088/2500], Train Loss: 0.8085, Train Accuracy: 64.72%, Test Loss: 0.8035, Test Accuracy: 63.29%\n",
      "Epoch [1089/2500], Train Loss: 0.7866, Train Accuracy: 66.29%, Test Loss: 0.7806, Test Accuracy: 68.35%\n",
      "Epoch [1090/2500], Train Loss: 0.7502, Train Accuracy: 67.28%, Test Loss: 0.7794, Test Accuracy: 69.62%\n",
      "Epoch [1091/2500], Train Loss: 0.7697, Train Accuracy: 67.71%, Test Loss: 0.7681, Test Accuracy: 73.42%\n",
      "Epoch [1092/2500], Train Loss: 0.7649, Train Accuracy: 67.99%, Test Loss: 0.8384, Test Accuracy: 64.56%\n",
      "Epoch [1093/2500], Train Loss: 0.7657, Train Accuracy: 66.71%, Test Loss: 0.7507, Test Accuracy: 70.89%\n",
      "Epoch [1094/2500], Train Loss: 0.7678, Train Accuracy: 66.71%, Test Loss: 0.7796, Test Accuracy: 67.09%\n",
      "Epoch [1095/2500], Train Loss: 0.7921, Train Accuracy: 64.01%, Test Loss: 0.7238, Test Accuracy: 65.82%\n",
      "Epoch [1096/2500], Train Loss: 0.8312, Train Accuracy: 63.73%, Test Loss: 0.7519, Test Accuracy: 73.42%\n",
      "Epoch [1097/2500], Train Loss: 0.8094, Train Accuracy: 64.86%, Test Loss: 0.7288, Test Accuracy: 67.09%\n",
      "Epoch [1098/2500], Train Loss: 0.8013, Train Accuracy: 66.00%, Test Loss: 0.7582, Test Accuracy: 72.15%\n",
      "Epoch [1099/2500], Train Loss: 0.8033, Train Accuracy: 67.14%, Test Loss: 0.7372, Test Accuracy: 69.62%\n",
      "Epoch [1100/2500], Train Loss: 0.7673, Train Accuracy: 67.99%, Test Loss: 0.8734, Test Accuracy: 67.09%\n",
      "Epoch [1101/2500], Train Loss: 0.7919, Train Accuracy: 66.15%, Test Loss: 0.8859, Test Accuracy: 62.03%\n",
      "Epoch [1102/2500], Train Loss: 0.8007, Train Accuracy: 66.15%, Test Loss: 0.7477, Test Accuracy: 72.15%\n",
      "Epoch [1103/2500], Train Loss: 0.7997, Train Accuracy: 65.29%, Test Loss: 0.8009, Test Accuracy: 68.35%\n",
      "Epoch [1104/2500], Train Loss: 0.7779, Train Accuracy: 66.00%, Test Loss: 0.7372, Test Accuracy: 67.09%\n",
      "Epoch [1105/2500], Train Loss: 0.7716, Train Accuracy: 66.57%, Test Loss: 0.7690, Test Accuracy: 72.15%\n",
      "Epoch [1106/2500], Train Loss: 0.7823, Train Accuracy: 65.72%, Test Loss: 0.7398, Test Accuracy: 68.35%\n",
      "Epoch [1107/2500], Train Loss: 0.8040, Train Accuracy: 65.86%, Test Loss: 0.8144, Test Accuracy: 70.89%\n",
      "Epoch [1108/2500], Train Loss: 0.7510, Train Accuracy: 68.28%, Test Loss: 0.7794, Test Accuracy: 72.15%\n",
      "Epoch [1109/2500], Train Loss: 0.7879, Train Accuracy: 65.72%, Test Loss: 0.7637, Test Accuracy: 67.09%\n",
      "Epoch [1110/2500], Train Loss: 0.7903, Train Accuracy: 64.86%, Test Loss: 0.7340, Test Accuracy: 69.62%\n",
      "Epoch [1111/2500], Train Loss: 0.7816, Train Accuracy: 66.15%, Test Loss: 0.7488, Test Accuracy: 70.89%\n",
      "Epoch [1112/2500], Train Loss: 0.7804, Train Accuracy: 68.71%, Test Loss: 0.9936, Test Accuracy: 65.82%\n",
      "Epoch [1113/2500], Train Loss: 0.7572, Train Accuracy: 68.14%, Test Loss: 0.7547, Test Accuracy: 69.62%\n",
      "Epoch [1114/2500], Train Loss: 0.7554, Train Accuracy: 68.28%, Test Loss: 0.7618, Test Accuracy: 69.62%\n",
      "Epoch [1115/2500], Train Loss: 0.7833, Train Accuracy: 65.72%, Test Loss: 0.7761, Test Accuracy: 69.62%\n",
      "Epoch [1116/2500], Train Loss: 0.7968, Train Accuracy: 66.57%, Test Loss: 0.7553, Test Accuracy: 72.15%\n",
      "Epoch [1117/2500], Train Loss: 0.7691, Train Accuracy: 66.71%, Test Loss: 0.7298, Test Accuracy: 64.56%\n",
      "Epoch [1118/2500], Train Loss: 0.8380, Train Accuracy: 63.58%, Test Loss: 0.7466, Test Accuracy: 72.15%\n",
      "Epoch [1119/2500], Train Loss: 0.8139, Train Accuracy: 64.58%, Test Loss: 0.7650, Test Accuracy: 70.89%\n",
      "Epoch [1120/2500], Train Loss: 0.7724, Train Accuracy: 66.57%, Test Loss: 0.7456, Test Accuracy: 63.29%\n",
      "Epoch [1121/2500], Train Loss: 0.7863, Train Accuracy: 67.28%, Test Loss: 0.7786, Test Accuracy: 67.09%\n",
      "Epoch [1122/2500], Train Loss: 0.7923, Train Accuracy: 65.01%, Test Loss: 0.8128, Test Accuracy: 67.09%\n",
      "Epoch [1123/2500], Train Loss: 0.7954, Train Accuracy: 65.01%, Test Loss: 0.7540, Test Accuracy: 69.62%\n",
      "Epoch [1124/2500], Train Loss: 0.7993, Train Accuracy: 63.73%, Test Loss: 0.7982, Test Accuracy: 68.35%\n",
      "Epoch [1125/2500], Train Loss: 0.7889, Train Accuracy: 66.86%, Test Loss: 0.7491, Test Accuracy: 65.82%\n",
      "Epoch [1126/2500], Train Loss: 0.8004, Train Accuracy: 65.01%, Test Loss: 0.7690, Test Accuracy: 62.03%\n",
      "Epoch [1127/2500], Train Loss: 0.7994, Train Accuracy: 66.57%, Test Loss: 0.7500, Test Accuracy: 74.68%\n",
      "Epoch [1128/2500], Train Loss: 0.7740, Train Accuracy: 65.58%, Test Loss: 0.7370, Test Accuracy: 70.89%\n",
      "Epoch [1129/2500], Train Loss: 0.7514, Train Accuracy: 66.43%, Test Loss: 0.8281, Test Accuracy: 70.89%\n",
      "Epoch [1130/2500], Train Loss: 0.7659, Train Accuracy: 68.28%, Test Loss: 0.7357, Test Accuracy: 67.09%\n",
      "Epoch [1131/2500], Train Loss: 0.7925, Train Accuracy: 67.99%, Test Loss: 0.8221, Test Accuracy: 68.35%\n",
      "Epoch [1132/2500], Train Loss: 0.7560, Train Accuracy: 67.71%, Test Loss: 0.8313, Test Accuracy: 68.35%\n",
      "Epoch [1133/2500], Train Loss: 0.7816, Train Accuracy: 64.86%, Test Loss: 0.8520, Test Accuracy: 64.56%\n",
      "Epoch [1134/2500], Train Loss: 0.7728, Train Accuracy: 65.58%, Test Loss: 0.7314, Test Accuracy: 67.09%\n",
      "Epoch [1135/2500], Train Loss: 0.8050, Train Accuracy: 66.00%, Test Loss: 0.8046, Test Accuracy: 69.62%\n",
      "Epoch [1136/2500], Train Loss: 0.8018, Train Accuracy: 65.58%, Test Loss: 0.7937, Test Accuracy: 67.09%\n",
      "Epoch [1137/2500], Train Loss: 0.7773, Train Accuracy: 66.86%, Test Loss: 0.7573, Test Accuracy: 69.62%\n",
      "Epoch [1138/2500], Train Loss: 0.7659, Train Accuracy: 66.15%, Test Loss: 0.7385, Test Accuracy: 62.03%\n",
      "Epoch [1139/2500], Train Loss: 0.7813, Train Accuracy: 67.71%, Test Loss: 0.8019, Test Accuracy: 70.89%\n",
      "Epoch [1140/2500], Train Loss: 0.7776, Train Accuracy: 66.57%, Test Loss: 0.7848, Test Accuracy: 67.09%\n",
      "Epoch [1141/2500], Train Loss: 0.7928, Train Accuracy: 65.58%, Test Loss: 0.8567, Test Accuracy: 67.09%\n",
      "Epoch [1142/2500], Train Loss: 0.7823, Train Accuracy: 65.43%, Test Loss: 0.8006, Test Accuracy: 69.62%\n",
      "Epoch [1143/2500], Train Loss: 0.7689, Train Accuracy: 66.29%, Test Loss: 0.7408, Test Accuracy: 72.15%\n",
      "Epoch [1144/2500], Train Loss: 0.7772, Train Accuracy: 66.71%, Test Loss: 0.7634, Test Accuracy: 68.35%\n",
      "Epoch [1145/2500], Train Loss: 0.8174, Train Accuracy: 63.16%, Test Loss: 0.7309, Test Accuracy: 68.35%\n",
      "Epoch [1146/2500], Train Loss: 0.7810, Train Accuracy: 65.58%, Test Loss: 0.7590, Test Accuracy: 63.29%\n",
      "Epoch [1147/2500], Train Loss: 0.7890, Train Accuracy: 65.29%, Test Loss: 0.8322, Test Accuracy: 70.89%\n",
      "Epoch [1148/2500], Train Loss: 0.7708, Train Accuracy: 65.15%, Test Loss: 0.7313, Test Accuracy: 63.29%\n",
      "Epoch [1149/2500], Train Loss: 0.7607, Train Accuracy: 68.42%, Test Loss: 0.7826, Test Accuracy: 70.89%\n",
      "Epoch [1150/2500], Train Loss: 0.7690, Train Accuracy: 67.71%, Test Loss: 0.8313, Test Accuracy: 68.35%\n",
      "Epoch [1151/2500], Train Loss: 0.7845, Train Accuracy: 65.43%, Test Loss: 0.8605, Test Accuracy: 63.29%\n",
      "Epoch [1152/2500], Train Loss: 0.7822, Train Accuracy: 67.00%, Test Loss: 0.7549, Test Accuracy: 69.62%\n",
      "Epoch [1153/2500], Train Loss: 0.7677, Train Accuracy: 68.14%, Test Loss: 0.7490, Test Accuracy: 65.82%\n",
      "Epoch [1154/2500], Train Loss: 0.7912, Train Accuracy: 67.43%, Test Loss: 0.8100, Test Accuracy: 70.89%\n",
      "Epoch [1155/2500], Train Loss: 0.7968, Train Accuracy: 65.86%, Test Loss: 0.7492, Test Accuracy: 65.82%\n",
      "Epoch [1156/2500], Train Loss: 0.7995, Train Accuracy: 64.72%, Test Loss: 0.8055, Test Accuracy: 68.35%\n",
      "Epoch [1157/2500], Train Loss: 0.7995, Train Accuracy: 63.73%, Test Loss: 0.7922, Test Accuracy: 70.89%\n",
      "Epoch [1158/2500], Train Loss: 0.7903, Train Accuracy: 63.58%, Test Loss: 0.7494, Test Accuracy: 74.68%\n",
      "Epoch [1159/2500], Train Loss: 0.7664, Train Accuracy: 67.57%, Test Loss: 0.8906, Test Accuracy: 64.56%\n",
      "Epoch [1160/2500], Train Loss: 0.7813, Train Accuracy: 64.44%, Test Loss: 0.7694, Test Accuracy: 68.35%\n",
      "Epoch [1161/2500], Train Loss: 0.7334, Train Accuracy: 67.57%, Test Loss: 0.7416, Test Accuracy: 63.29%\n",
      "Epoch [1162/2500], Train Loss: 0.7937, Train Accuracy: 64.44%, Test Loss: 0.9574, Test Accuracy: 64.56%\n",
      "Epoch [1163/2500], Train Loss: 0.7676, Train Accuracy: 67.85%, Test Loss: 0.7821, Test Accuracy: 69.62%\n",
      "Epoch [1164/2500], Train Loss: 0.7637, Train Accuracy: 67.99%, Test Loss: 0.7796, Test Accuracy: 73.42%\n",
      "Epoch [1165/2500], Train Loss: 0.7869, Train Accuracy: 64.01%, Test Loss: 0.7499, Test Accuracy: 69.62%\n",
      "Epoch [1166/2500], Train Loss: 0.7713, Train Accuracy: 66.86%, Test Loss: 0.8642, Test Accuracy: 64.56%\n",
      "Epoch [1167/2500], Train Loss: 0.7954, Train Accuracy: 64.58%, Test Loss: 0.8109, Test Accuracy: 70.89%\n",
      "Epoch [1168/2500], Train Loss: 0.7721, Train Accuracy: 67.28%, Test Loss: 0.7611, Test Accuracy: 74.68%\n",
      "Epoch [1169/2500], Train Loss: 0.7975, Train Accuracy: 66.00%, Test Loss: 0.7827, Test Accuracy: 70.89%\n",
      "Epoch [1170/2500], Train Loss: 0.7759, Train Accuracy: 67.99%, Test Loss: 0.7649, Test Accuracy: 69.62%\n",
      "Epoch [1171/2500], Train Loss: 0.7672, Train Accuracy: 67.28%, Test Loss: 0.7724, Test Accuracy: 70.89%\n",
      "Epoch [1172/2500], Train Loss: 0.7797, Train Accuracy: 64.72%, Test Loss: 0.7388, Test Accuracy: 70.89%\n",
      "Epoch [1173/2500], Train Loss: 0.7604, Train Accuracy: 66.43%, Test Loss: 0.8479, Test Accuracy: 69.62%\n",
      "Epoch [1174/2500], Train Loss: 0.7857, Train Accuracy: 66.29%, Test Loss: 0.7936, Test Accuracy: 67.09%\n",
      "Epoch [1175/2500], Train Loss: 0.7754, Train Accuracy: 67.28%, Test Loss: 0.7638, Test Accuracy: 72.15%\n",
      "Epoch [1176/2500], Train Loss: 0.7734, Train Accuracy: 66.86%, Test Loss: 0.7502, Test Accuracy: 72.15%\n",
      "Epoch [1177/2500], Train Loss: 0.8151, Train Accuracy: 65.72%, Test Loss: 0.8103, Test Accuracy: 69.62%\n",
      "Epoch [1178/2500], Train Loss: 0.7934, Train Accuracy: 64.44%, Test Loss: 0.7772, Test Accuracy: 67.09%\n",
      "Epoch [1179/2500], Train Loss: 0.7907, Train Accuracy: 65.72%, Test Loss: 0.8078, Test Accuracy: 72.15%\n",
      "Epoch [1180/2500], Train Loss: 0.7920, Train Accuracy: 66.71%, Test Loss: 0.7788, Test Accuracy: 74.68%\n",
      "Epoch [1181/2500], Train Loss: 0.8072, Train Accuracy: 65.58%, Test Loss: 0.8427, Test Accuracy: 64.56%\n",
      "Epoch [1182/2500], Train Loss: 0.7601, Train Accuracy: 66.43%, Test Loss: 0.8384, Test Accuracy: 63.29%\n",
      "Epoch [1183/2500], Train Loss: 0.7581, Train Accuracy: 67.00%, Test Loss: 0.7482, Test Accuracy: 72.15%\n",
      "Epoch [1184/2500], Train Loss: 0.7789, Train Accuracy: 68.14%, Test Loss: 0.7569, Test Accuracy: 70.89%\n",
      "Epoch [1185/2500], Train Loss: 0.7754, Train Accuracy: 65.29%, Test Loss: 0.7566, Test Accuracy: 69.62%\n",
      "Epoch [1186/2500], Train Loss: 0.7541, Train Accuracy: 67.43%, Test Loss: 0.7349, Test Accuracy: 64.56%\n",
      "Epoch [1187/2500], Train Loss: 0.7855, Train Accuracy: 64.58%, Test Loss: 0.8164, Test Accuracy: 67.09%\n",
      "Epoch [1188/2500], Train Loss: 0.7657, Train Accuracy: 66.00%, Test Loss: 0.8100, Test Accuracy: 70.89%\n",
      "Epoch [1189/2500], Train Loss: 0.7633, Train Accuracy: 66.43%, Test Loss: 0.8736, Test Accuracy: 67.09%\n",
      "Epoch [1190/2500], Train Loss: 0.7673, Train Accuracy: 67.85%, Test Loss: 0.8142, Test Accuracy: 69.62%\n",
      "Epoch [1191/2500], Train Loss: 0.7863, Train Accuracy: 66.86%, Test Loss: 0.7208, Test Accuracy: 67.09%\n",
      "Epoch [1192/2500], Train Loss: 0.7922, Train Accuracy: 64.72%, Test Loss: 0.7843, Test Accuracy: 70.89%\n",
      "Epoch [1193/2500], Train Loss: 0.7567, Train Accuracy: 64.30%, Test Loss: 0.7306, Test Accuracy: 63.29%\n",
      "Epoch [1194/2500], Train Loss: 0.7732, Train Accuracy: 67.00%, Test Loss: 0.7433, Test Accuracy: 73.42%\n",
      "Epoch [1195/2500], Train Loss: 0.7928, Train Accuracy: 65.43%, Test Loss: 0.7593, Test Accuracy: 69.62%\n",
      "Epoch [1196/2500], Train Loss: 0.7846, Train Accuracy: 65.86%, Test Loss: 0.7928, Test Accuracy: 68.35%\n",
      "Epoch [1197/2500], Train Loss: 0.7837, Train Accuracy: 65.72%, Test Loss: 0.7271, Test Accuracy: 68.35%\n",
      "Epoch [1198/2500], Train Loss: 0.7614, Train Accuracy: 67.71%, Test Loss: 0.8017, Test Accuracy: 67.09%\n",
      "Epoch [1199/2500], Train Loss: 0.7878, Train Accuracy: 66.15%, Test Loss: 0.8648, Test Accuracy: 64.56%\n",
      "Epoch [1200/2500], Train Loss: 0.7842, Train Accuracy: 65.86%, Test Loss: 0.7797, Test Accuracy: 63.29%\n",
      "Epoch [1201/2500], Train Loss: 0.7542, Train Accuracy: 66.15%, Test Loss: 0.7558, Test Accuracy: 69.62%\n",
      "Epoch [1202/2500], Train Loss: 0.7858, Train Accuracy: 66.00%, Test Loss: 0.8372, Test Accuracy: 67.09%\n",
      "Epoch [1203/2500], Train Loss: 0.7748, Train Accuracy: 67.28%, Test Loss: 0.8313, Test Accuracy: 63.29%\n",
      "Epoch [1204/2500], Train Loss: 0.7816, Train Accuracy: 67.28%, Test Loss: 0.7923, Test Accuracy: 70.89%\n",
      "Epoch [1205/2500], Train Loss: 0.7874, Train Accuracy: 66.43%, Test Loss: 0.7405, Test Accuracy: 70.89%\n",
      "Epoch [1206/2500], Train Loss: 0.7941, Train Accuracy: 65.01%, Test Loss: 0.7196, Test Accuracy: 63.29%\n",
      "Epoch [1207/2500], Train Loss: 0.7969, Train Accuracy: 66.15%, Test Loss: 0.8078, Test Accuracy: 69.62%\n",
      "Epoch [1208/2500], Train Loss: 0.8006, Train Accuracy: 64.72%, Test Loss: 0.7910, Test Accuracy: 72.15%\n",
      "Epoch [1209/2500], Train Loss: 0.7906, Train Accuracy: 64.44%, Test Loss: 0.7424, Test Accuracy: 72.15%\n",
      "Epoch [1210/2500], Train Loss: 0.7654, Train Accuracy: 66.29%, Test Loss: 0.8217, Test Accuracy: 67.09%\n",
      "Epoch [1211/2500], Train Loss: 0.7731, Train Accuracy: 65.29%, Test Loss: 0.8336, Test Accuracy: 68.35%\n",
      "Epoch [1212/2500], Train Loss: 0.7622, Train Accuracy: 66.43%, Test Loss: 0.8536, Test Accuracy: 67.09%\n",
      "Epoch [1213/2500], Train Loss: 0.7998, Train Accuracy: 65.01%, Test Loss: 0.7482, Test Accuracy: 63.29%\n",
      "Epoch [1214/2500], Train Loss: 0.7764, Train Accuracy: 66.43%, Test Loss: 0.7430, Test Accuracy: 73.42%\n",
      "Epoch [1215/2500], Train Loss: 0.7693, Train Accuracy: 67.85%, Test Loss: 0.7408, Test Accuracy: 73.42%\n",
      "Epoch [1216/2500], Train Loss: 0.7928, Train Accuracy: 66.15%, Test Loss: 0.7293, Test Accuracy: 72.15%\n",
      "Epoch [1217/2500], Train Loss: 0.7895, Train Accuracy: 66.15%, Test Loss: 0.7607, Test Accuracy: 73.42%\n",
      "Epoch [1218/2500], Train Loss: 0.8129, Train Accuracy: 64.72%, Test Loss: 0.7352, Test Accuracy: 72.15%\n",
      "Epoch [1219/2500], Train Loss: 0.7837, Train Accuracy: 65.15%, Test Loss: 0.7655, Test Accuracy: 72.15%\n",
      "Epoch [1220/2500], Train Loss: 0.8075, Train Accuracy: 65.01%, Test Loss: 0.7659, Test Accuracy: 72.15%\n",
      "Epoch [1221/2500], Train Loss: 0.7795, Train Accuracy: 66.15%, Test Loss: 0.8383, Test Accuracy: 65.82%\n",
      "Epoch [1222/2500], Train Loss: 0.7980, Train Accuracy: 66.00%, Test Loss: 0.7478, Test Accuracy: 62.03%\n",
      "Epoch [1223/2500], Train Loss: 0.7785, Train Accuracy: 67.14%, Test Loss: 0.7674, Test Accuracy: 70.89%\n",
      "Epoch [1224/2500], Train Loss: 0.7901, Train Accuracy: 64.01%, Test Loss: 0.8492, Test Accuracy: 69.62%\n",
      "Epoch [1225/2500], Train Loss: 0.7928, Train Accuracy: 65.72%, Test Loss: 0.8070, Test Accuracy: 70.89%\n",
      "Epoch [1226/2500], Train Loss: 0.7736, Train Accuracy: 65.72%, Test Loss: 0.7419, Test Accuracy: 70.89%\n",
      "Epoch [1227/2500], Train Loss: 0.7957, Train Accuracy: 65.86%, Test Loss: 0.7388, Test Accuracy: 72.15%\n",
      "Epoch [1228/2500], Train Loss: 0.7484, Train Accuracy: 68.42%, Test Loss: 0.9615, Test Accuracy: 60.76%\n",
      "Epoch [1229/2500], Train Loss: 0.7842, Train Accuracy: 64.72%, Test Loss: 0.7959, Test Accuracy: 72.15%\n",
      "Epoch [1230/2500], Train Loss: 0.7925, Train Accuracy: 64.58%, Test Loss: 0.7832, Test Accuracy: 69.62%\n",
      "Epoch [1231/2500], Train Loss: 0.7411, Train Accuracy: 68.56%, Test Loss: 0.8439, Test Accuracy: 67.09%\n",
      "Epoch [1232/2500], Train Loss: 0.7839, Train Accuracy: 65.29%, Test Loss: 0.7662, Test Accuracy: 72.15%\n",
      "Epoch [1233/2500], Train Loss: 0.7859, Train Accuracy: 66.15%, Test Loss: 0.7751, Test Accuracy: 69.62%\n",
      "Epoch [1234/2500], Train Loss: 0.7718, Train Accuracy: 66.43%, Test Loss: 0.8812, Test Accuracy: 65.82%\n",
      "Epoch [1235/2500], Train Loss: 0.7646, Train Accuracy: 65.43%, Test Loss: 0.8239, Test Accuracy: 67.09%\n",
      "Epoch [1236/2500], Train Loss: 0.7678, Train Accuracy: 66.29%, Test Loss: 0.8351, Test Accuracy: 68.35%\n",
      "Epoch [1237/2500], Train Loss: 0.7862, Train Accuracy: 65.01%, Test Loss: 0.7449, Test Accuracy: 62.03%\n",
      "Epoch [1238/2500], Train Loss: 0.7872, Train Accuracy: 66.43%, Test Loss: 0.8888, Test Accuracy: 63.29%\n",
      "Epoch [1239/2500], Train Loss: 0.7342, Train Accuracy: 69.42%, Test Loss: 0.7573, Test Accuracy: 65.82%\n",
      "Epoch [1240/2500], Train Loss: 0.7698, Train Accuracy: 66.57%, Test Loss: 0.7285, Test Accuracy: 67.09%\n",
      "Epoch [1241/2500], Train Loss: 0.7863, Train Accuracy: 66.15%, Test Loss: 0.7475, Test Accuracy: 65.82%\n",
      "Epoch [1242/2500], Train Loss: 0.7851, Train Accuracy: 65.29%, Test Loss: 0.7638, Test Accuracy: 67.09%\n",
      "Epoch [1243/2500], Train Loss: 0.7554, Train Accuracy: 67.85%, Test Loss: 1.0875, Test Accuracy: 58.23%\n",
      "Epoch [1244/2500], Train Loss: 0.7842, Train Accuracy: 65.72%, Test Loss: 0.8169, Test Accuracy: 65.82%\n",
      "Epoch [1245/2500], Train Loss: 0.7826, Train Accuracy: 67.00%, Test Loss: 0.7638, Test Accuracy: 64.56%\n",
      "Epoch [1246/2500], Train Loss: 0.8054, Train Accuracy: 66.00%, Test Loss: 0.8226, Test Accuracy: 67.09%\n",
      "Epoch [1247/2500], Train Loss: 0.8030, Train Accuracy: 66.00%, Test Loss: 0.8031, Test Accuracy: 70.89%\n",
      "Epoch [1248/2500], Train Loss: 0.7620, Train Accuracy: 67.43%, Test Loss: 0.7544, Test Accuracy: 67.09%\n",
      "Epoch [1249/2500], Train Loss: 0.7719, Train Accuracy: 66.57%, Test Loss: 0.7802, Test Accuracy: 65.82%\n",
      "Epoch [1250/2500], Train Loss: 0.7376, Train Accuracy: 67.28%, Test Loss: 0.7200, Test Accuracy: 68.35%\n",
      "Epoch [1251/2500], Train Loss: 0.7631, Train Accuracy: 68.56%, Test Loss: 0.8191, Test Accuracy: 69.62%\n",
      "Epoch [1252/2500], Train Loss: 0.7675, Train Accuracy: 66.29%, Test Loss: 0.8500, Test Accuracy: 64.56%\n",
      "Epoch [1253/2500], Train Loss: 0.7588, Train Accuracy: 67.28%, Test Loss: 0.7725, Test Accuracy: 72.15%\n",
      "Epoch [1254/2500], Train Loss: 0.7793, Train Accuracy: 65.72%, Test Loss: 0.7250, Test Accuracy: 65.82%\n",
      "Epoch [1255/2500], Train Loss: 0.7724, Train Accuracy: 67.85%, Test Loss: 0.7925, Test Accuracy: 68.35%\n",
      "Epoch [1256/2500], Train Loss: 0.7470, Train Accuracy: 68.99%, Test Loss: 0.7437, Test Accuracy: 70.89%\n",
      "Epoch [1257/2500], Train Loss: 0.7504, Train Accuracy: 67.57%, Test Loss: 0.8247, Test Accuracy: 68.35%\n",
      "Epoch [1258/2500], Train Loss: 0.7696, Train Accuracy: 66.86%, Test Loss: 0.7962, Test Accuracy: 72.15%\n",
      "Epoch [1259/2500], Train Loss: 0.7596, Train Accuracy: 66.71%, Test Loss: 0.7762, Test Accuracy: 73.42%\n",
      "Epoch [1260/2500], Train Loss: 0.7712, Train Accuracy: 65.58%, Test Loss: 0.7328, Test Accuracy: 68.35%\n",
      "Epoch [1261/2500], Train Loss: 0.7746, Train Accuracy: 66.15%, Test Loss: 0.7847, Test Accuracy: 69.62%\n",
      "Epoch [1262/2500], Train Loss: 0.7918, Train Accuracy: 65.01%, Test Loss: 0.7333, Test Accuracy: 67.09%\n",
      "Epoch [1263/2500], Train Loss: 0.7745, Train Accuracy: 66.00%, Test Loss: 0.7357, Test Accuracy: 67.09%\n",
      "Epoch [1264/2500], Train Loss: 0.7670, Train Accuracy: 65.86%, Test Loss: 0.7944, Test Accuracy: 68.35%\n",
      "Epoch [1265/2500], Train Loss: 0.7759, Train Accuracy: 65.72%, Test Loss: 0.7447, Test Accuracy: 73.42%\n",
      "Epoch [1266/2500], Train Loss: 0.7694, Train Accuracy: 66.71%, Test Loss: 0.7236, Test Accuracy: 68.35%\n",
      "Epoch [1267/2500], Train Loss: 0.7503, Train Accuracy: 66.00%, Test Loss: 0.8074, Test Accuracy: 69.62%\n",
      "Epoch [1268/2500], Train Loss: 0.7819, Train Accuracy: 66.71%, Test Loss: 0.7748, Test Accuracy: 72.15%\n",
      "Epoch [1269/2500], Train Loss: 0.7845, Train Accuracy: 64.58%, Test Loss: 0.8501, Test Accuracy: 69.62%\n",
      "Epoch [1270/2500], Train Loss: 0.7463, Train Accuracy: 68.14%, Test Loss: 0.7569, Test Accuracy: 73.42%\n",
      "Epoch [1271/2500], Train Loss: 0.7841, Train Accuracy: 62.87%, Test Loss: 0.8272, Test Accuracy: 64.56%\n",
      "Epoch [1272/2500], Train Loss: 0.7995, Train Accuracy: 65.15%, Test Loss: 0.7905, Test Accuracy: 70.89%\n",
      "Epoch [1273/2500], Train Loss: 0.7702, Train Accuracy: 67.71%, Test Loss: 0.8982, Test Accuracy: 64.56%\n",
      "Epoch [1274/2500], Train Loss: 0.7708, Train Accuracy: 65.01%, Test Loss: 0.7745, Test Accuracy: 73.42%\n",
      "Epoch [1275/2500], Train Loss: 0.7789, Train Accuracy: 67.85%, Test Loss: 0.7517, Test Accuracy: 72.15%\n",
      "Epoch [1276/2500], Train Loss: 0.7719, Train Accuracy: 66.57%, Test Loss: 0.7362, Test Accuracy: 67.09%\n",
      "Epoch [1277/2500], Train Loss: 0.7797, Train Accuracy: 67.00%, Test Loss: 0.7585, Test Accuracy: 69.62%\n",
      "Epoch [1278/2500], Train Loss: 0.7936, Train Accuracy: 65.43%, Test Loss: 0.7891, Test Accuracy: 70.89%\n",
      "Epoch [1279/2500], Train Loss: 0.7941, Train Accuracy: 65.29%, Test Loss: 0.8172, Test Accuracy: 63.29%\n",
      "Epoch [1280/2500], Train Loss: 0.7697, Train Accuracy: 66.00%, Test Loss: 0.7289, Test Accuracy: 64.56%\n",
      "Epoch [1281/2500], Train Loss: 0.7776, Train Accuracy: 66.15%, Test Loss: 0.7698, Test Accuracy: 70.89%\n",
      "Epoch [1282/2500], Train Loss: 0.7465, Train Accuracy: 67.14%, Test Loss: 0.7260, Test Accuracy: 72.15%\n",
      "Epoch [1283/2500], Train Loss: 0.7720, Train Accuracy: 64.30%, Test Loss: 0.7627, Test Accuracy: 73.42%\n",
      "Epoch [1284/2500], Train Loss: 0.7614, Train Accuracy: 66.00%, Test Loss: 0.9842, Test Accuracy: 64.56%\n",
      "Epoch [1285/2500], Train Loss: 0.7926, Train Accuracy: 66.57%, Test Loss: 0.7237, Test Accuracy: 64.56%\n",
      "Epoch [1286/2500], Train Loss: 0.7845, Train Accuracy: 67.00%, Test Loss: 0.7258, Test Accuracy: 73.42%\n",
      "Epoch [1287/2500], Train Loss: 0.7789, Train Accuracy: 65.86%, Test Loss: 0.8485, Test Accuracy: 65.82%\n",
      "Epoch [1288/2500], Train Loss: 0.7895, Train Accuracy: 65.01%, Test Loss: 0.8550, Test Accuracy: 63.29%\n",
      "Epoch [1289/2500], Train Loss: 0.7650, Train Accuracy: 67.43%, Test Loss: 0.7235, Test Accuracy: 68.35%\n",
      "Epoch [1290/2500], Train Loss: 0.7571, Train Accuracy: 70.13%, Test Loss: 0.8002, Test Accuracy: 70.89%\n",
      "Epoch [1291/2500], Train Loss: 0.7827, Train Accuracy: 66.86%, Test Loss: 0.7983, Test Accuracy: 70.89%\n",
      "Epoch [1292/2500], Train Loss: 0.7802, Train Accuracy: 66.57%, Test Loss: 0.7324, Test Accuracy: 68.35%\n",
      "Epoch [1293/2500], Train Loss: 0.7696, Train Accuracy: 66.86%, Test Loss: 0.7311, Test Accuracy: 69.62%\n",
      "Epoch [1294/2500], Train Loss: 0.7900, Train Accuracy: 66.86%, Test Loss: 0.7581, Test Accuracy: 68.35%\n",
      "Epoch [1295/2500], Train Loss: 0.7820, Train Accuracy: 65.43%, Test Loss: 0.8370, Test Accuracy: 67.09%\n",
      "Epoch [1296/2500], Train Loss: 0.7739, Train Accuracy: 66.86%, Test Loss: 0.7696, Test Accuracy: 69.62%\n",
      "Epoch [1297/2500], Train Loss: 0.7705, Train Accuracy: 66.86%, Test Loss: 0.7359, Test Accuracy: 67.09%\n",
      "Epoch [1298/2500], Train Loss: 0.7609, Train Accuracy: 65.43%, Test Loss: 0.7467, Test Accuracy: 74.68%\n",
      "Epoch [1299/2500], Train Loss: 0.7781, Train Accuracy: 66.15%, Test Loss: 0.8019, Test Accuracy: 69.62%\n",
      "Epoch [1300/2500], Train Loss: 0.7590, Train Accuracy: 65.01%, Test Loss: 0.9546, Test Accuracy: 59.49%\n",
      "Epoch [1301/2500], Train Loss: 0.7801, Train Accuracy: 66.71%, Test Loss: 0.7644, Test Accuracy: 67.09%\n",
      "Epoch [1302/2500], Train Loss: 0.7791, Train Accuracy: 66.43%, Test Loss: 0.7895, Test Accuracy: 72.15%\n",
      "Epoch [1303/2500], Train Loss: 0.7677, Train Accuracy: 66.29%, Test Loss: 0.7719, Test Accuracy: 70.89%\n",
      "Epoch [1304/2500], Train Loss: 0.7900, Train Accuracy: 67.00%, Test Loss: 0.8015, Test Accuracy: 67.09%\n",
      "Epoch [1305/2500], Train Loss: 0.7515, Train Accuracy: 67.28%, Test Loss: 0.8649, Test Accuracy: 62.03%\n",
      "Epoch [1306/2500], Train Loss: 0.7469, Train Accuracy: 66.86%, Test Loss: 0.7310, Test Accuracy: 64.56%\n",
      "Epoch [1307/2500], Train Loss: 0.7652, Train Accuracy: 67.43%, Test Loss: 0.8737, Test Accuracy: 67.09%\n",
      "Epoch [1308/2500], Train Loss: 0.7756, Train Accuracy: 66.29%, Test Loss: 0.7436, Test Accuracy: 63.29%\n",
      "Epoch [1309/2500], Train Loss: 0.7827, Train Accuracy: 66.00%, Test Loss: 0.7670, Test Accuracy: 72.15%\n",
      "Epoch [1310/2500], Train Loss: 0.7909, Train Accuracy: 67.14%, Test Loss: 0.7881, Test Accuracy: 67.09%\n",
      "Epoch [1311/2500], Train Loss: 0.7634, Train Accuracy: 67.28%, Test Loss: 0.7831, Test Accuracy: 67.09%\n",
      "Epoch [1312/2500], Train Loss: 0.7852, Train Accuracy: 66.57%, Test Loss: 0.8091, Test Accuracy: 63.29%\n",
      "Epoch [1313/2500], Train Loss: 0.7757, Train Accuracy: 65.29%, Test Loss: 0.8004, Test Accuracy: 67.09%\n",
      "Epoch [1314/2500], Train Loss: 0.7697, Train Accuracy: 66.57%, Test Loss: 0.7737, Test Accuracy: 67.09%\n",
      "Epoch [1315/2500], Train Loss: 0.7665, Train Accuracy: 67.14%, Test Loss: 0.7411, Test Accuracy: 68.35%\n",
      "Epoch [1316/2500], Train Loss: 0.7907, Train Accuracy: 66.00%, Test Loss: 0.9318, Test Accuracy: 60.76%\n",
      "Epoch [1317/2500], Train Loss: 0.7494, Train Accuracy: 69.56%, Test Loss: 0.7201, Test Accuracy: 72.15%\n",
      "Epoch [1318/2500], Train Loss: 0.7899, Train Accuracy: 65.15%, Test Loss: 0.8870, Test Accuracy: 63.29%\n",
      "Epoch [1319/2500], Train Loss: 0.7903, Train Accuracy: 64.86%, Test Loss: 0.7776, Test Accuracy: 73.42%\n",
      "Epoch [1320/2500], Train Loss: 0.7492, Train Accuracy: 69.56%, Test Loss: 0.7434, Test Accuracy: 65.82%\n",
      "Epoch [1321/2500], Train Loss: 0.7957, Train Accuracy: 64.58%, Test Loss: 0.7987, Test Accuracy: 69.62%\n",
      "Epoch [1322/2500], Train Loss: 0.7847, Train Accuracy: 67.00%, Test Loss: 0.8061, Test Accuracy: 67.09%\n",
      "Epoch [1323/2500], Train Loss: 0.7978, Train Accuracy: 64.58%, Test Loss: 0.9104, Test Accuracy: 68.35%\n",
      "Epoch [1324/2500], Train Loss: 0.7745, Train Accuracy: 67.99%, Test Loss: 0.8267, Test Accuracy: 63.29%\n",
      "Epoch [1325/2500], Train Loss: 0.7753, Train Accuracy: 64.30%, Test Loss: 0.7938, Test Accuracy: 72.15%\n",
      "Epoch [1326/2500], Train Loss: 0.7720, Train Accuracy: 66.15%, Test Loss: 0.8994, Test Accuracy: 62.03%\n",
      "Epoch [1327/2500], Train Loss: 0.7517, Train Accuracy: 68.42%, Test Loss: 0.7771, Test Accuracy: 68.35%\n",
      "Epoch [1328/2500], Train Loss: 0.7642, Train Accuracy: 66.15%, Test Loss: 0.7463, Test Accuracy: 68.35%\n",
      "Epoch [1329/2500], Train Loss: 0.7692, Train Accuracy: 68.42%, Test Loss: 0.7496, Test Accuracy: 60.76%\n",
      "Epoch [1330/2500], Train Loss: 0.7696, Train Accuracy: 66.43%, Test Loss: 0.8296, Test Accuracy: 65.82%\n",
      "Epoch [1331/2500], Train Loss: 0.7535, Train Accuracy: 68.28%, Test Loss: 0.7656, Test Accuracy: 73.42%\n",
      "Epoch [1332/2500], Train Loss: 0.7780, Train Accuracy: 67.00%, Test Loss: 0.7313, Test Accuracy: 69.62%\n",
      "Epoch [1333/2500], Train Loss: 0.7637, Train Accuracy: 68.14%, Test Loss: 0.8380, Test Accuracy: 63.29%\n",
      "Epoch [1334/2500], Train Loss: 0.7631, Train Accuracy: 66.71%, Test Loss: 0.7893, Test Accuracy: 67.09%\n",
      "Epoch [1335/2500], Train Loss: 0.7700, Train Accuracy: 66.00%, Test Loss: 0.7557, Test Accuracy: 70.89%\n",
      "Epoch [1336/2500], Train Loss: 0.7908, Train Accuracy: 66.57%, Test Loss: 0.7244, Test Accuracy: 74.68%\n",
      "Epoch [1337/2500], Train Loss: 0.7888, Train Accuracy: 66.71%, Test Loss: 0.8542, Test Accuracy: 64.56%\n",
      "Epoch [1338/2500], Train Loss: 0.7570, Train Accuracy: 67.43%, Test Loss: 0.7247, Test Accuracy: 69.62%\n",
      "Epoch [1339/2500], Train Loss: 0.7951, Train Accuracy: 66.71%, Test Loss: 0.8090, Test Accuracy: 72.15%\n",
      "Epoch [1340/2500], Train Loss: 0.7576, Train Accuracy: 66.43%, Test Loss: 0.7894, Test Accuracy: 67.09%\n",
      "Epoch [1341/2500], Train Loss: 0.7786, Train Accuracy: 66.86%, Test Loss: 0.8179, Test Accuracy: 65.82%\n",
      "Epoch [1342/2500], Train Loss: 0.7962, Train Accuracy: 63.87%, Test Loss: 0.7563, Test Accuracy: 73.42%\n",
      "Epoch [1343/2500], Train Loss: 0.7518, Train Accuracy: 67.28%, Test Loss: 0.7419, Test Accuracy: 65.82%\n",
      "Epoch [1344/2500], Train Loss: 0.7901, Train Accuracy: 64.86%, Test Loss: 0.7934, Test Accuracy: 69.62%\n",
      "Epoch [1345/2500], Train Loss: 0.7891, Train Accuracy: 65.86%, Test Loss: 0.7496, Test Accuracy: 67.09%\n",
      "Epoch [1346/2500], Train Loss: 0.7655, Train Accuracy: 68.28%, Test Loss: 0.7451, Test Accuracy: 72.15%\n",
      "Epoch [1347/2500], Train Loss: 0.8151, Train Accuracy: 64.44%, Test Loss: 0.8020, Test Accuracy: 67.09%\n",
      "Epoch [1348/2500], Train Loss: 0.7732, Train Accuracy: 67.14%, Test Loss: 0.8663, Test Accuracy: 67.09%\n",
      "Epoch [1349/2500], Train Loss: 0.7873, Train Accuracy: 65.29%, Test Loss: 0.8200, Test Accuracy: 70.89%\n",
      "Epoch [1350/2500], Train Loss: 0.7493, Train Accuracy: 68.99%, Test Loss: 0.7721, Test Accuracy: 70.89%\n",
      "Epoch [1351/2500], Train Loss: 0.7818, Train Accuracy: 65.86%, Test Loss: 0.7330, Test Accuracy: 67.09%\n",
      "Epoch [1352/2500], Train Loss: 0.7734, Train Accuracy: 66.86%, Test Loss: 0.7924, Test Accuracy: 68.35%\n",
      "Epoch [1353/2500], Train Loss: 0.7607, Train Accuracy: 66.43%, Test Loss: 0.8836, Test Accuracy: 60.76%\n",
      "Epoch [1354/2500], Train Loss: 0.7779, Train Accuracy: 65.43%, Test Loss: 1.0162, Test Accuracy: 55.70%\n",
      "Epoch [1355/2500], Train Loss: 0.7863, Train Accuracy: 65.29%, Test Loss: 0.8683, Test Accuracy: 60.76%\n",
      "Epoch [1356/2500], Train Loss: 0.7683, Train Accuracy: 67.28%, Test Loss: 0.7562, Test Accuracy: 65.82%\n",
      "Epoch [1357/2500], Train Loss: 0.7341, Train Accuracy: 67.99%, Test Loss: 0.8120, Test Accuracy: 68.35%\n",
      "Epoch [1358/2500], Train Loss: 0.7678, Train Accuracy: 67.14%, Test Loss: 0.7235, Test Accuracy: 72.15%\n",
      "Epoch [1359/2500], Train Loss: 0.7729, Train Accuracy: 66.86%, Test Loss: 0.7643, Test Accuracy: 70.89%\n",
      "Epoch [1360/2500], Train Loss: 0.7642, Train Accuracy: 67.14%, Test Loss: 0.8038, Test Accuracy: 67.09%\n",
      "Epoch [1361/2500], Train Loss: 0.7564, Train Accuracy: 67.57%, Test Loss: 0.8191, Test Accuracy: 65.82%\n",
      "Epoch [1362/2500], Train Loss: 0.7881, Train Accuracy: 66.00%, Test Loss: 0.7594, Test Accuracy: 68.35%\n",
      "Epoch [1363/2500], Train Loss: 0.7348, Train Accuracy: 68.99%, Test Loss: 0.8012, Test Accuracy: 68.35%\n",
      "Epoch [1364/2500], Train Loss: 0.7810, Train Accuracy: 65.29%, Test Loss: 0.7249, Test Accuracy: 70.89%\n",
      "Epoch [1365/2500], Train Loss: 0.7613, Train Accuracy: 68.56%, Test Loss: 0.7411, Test Accuracy: 73.42%\n",
      "Epoch [1366/2500], Train Loss: 0.7413, Train Accuracy: 67.14%, Test Loss: 0.7635, Test Accuracy: 70.89%\n",
      "Epoch [1367/2500], Train Loss: 0.7781, Train Accuracy: 65.43%, Test Loss: 0.8553, Test Accuracy: 67.09%\n",
      "Epoch [1368/2500], Train Loss: 0.7989, Train Accuracy: 65.72%, Test Loss: 0.7732, Test Accuracy: 70.89%\n",
      "Epoch [1369/2500], Train Loss: 0.7877, Train Accuracy: 64.72%, Test Loss: 0.7492, Test Accuracy: 74.68%\n",
      "Epoch [1370/2500], Train Loss: 0.7738, Train Accuracy: 68.14%, Test Loss: 0.7342, Test Accuracy: 72.15%\n",
      "Epoch [1371/2500], Train Loss: 0.7745, Train Accuracy: 67.14%, Test Loss: 0.7581, Test Accuracy: 73.42%\n",
      "Epoch [1372/2500], Train Loss: 0.7757, Train Accuracy: 66.71%, Test Loss: 0.7608, Test Accuracy: 74.68%\n",
      "Epoch [1373/2500], Train Loss: 0.7810, Train Accuracy: 65.72%, Test Loss: 0.7843, Test Accuracy: 70.89%\n",
      "Epoch [1374/2500], Train Loss: 0.8042, Train Accuracy: 64.58%, Test Loss: 0.7657, Test Accuracy: 70.89%\n",
      "Epoch [1375/2500], Train Loss: 0.7706, Train Accuracy: 65.01%, Test Loss: 0.7711, Test Accuracy: 62.03%\n",
      "Epoch [1376/2500], Train Loss: 0.7733, Train Accuracy: 65.43%, Test Loss: 0.8278, Test Accuracy: 67.09%\n",
      "Epoch [1377/2500], Train Loss: 0.7635, Train Accuracy: 67.57%, Test Loss: 0.7538, Test Accuracy: 65.82%\n",
      "Epoch [1378/2500], Train Loss: 0.7612, Train Accuracy: 66.86%, Test Loss: 0.7590, Test Accuracy: 72.15%\n",
      "Epoch [1379/2500], Train Loss: 0.7662, Train Accuracy: 66.86%, Test Loss: 0.8106, Test Accuracy: 67.09%\n",
      "Epoch [1380/2500], Train Loss: 0.7678, Train Accuracy: 65.58%, Test Loss: 0.7596, Test Accuracy: 72.15%\n",
      "Epoch [1381/2500], Train Loss: 0.7767, Train Accuracy: 64.72%, Test Loss: 0.7537, Test Accuracy: 73.42%\n",
      "Epoch [1382/2500], Train Loss: 0.7863, Train Accuracy: 66.00%, Test Loss: 0.7606, Test Accuracy: 72.15%\n",
      "Epoch [1383/2500], Train Loss: 0.7616, Train Accuracy: 64.86%, Test Loss: 0.7334, Test Accuracy: 67.09%\n",
      "Epoch [1384/2500], Train Loss: 0.7453, Train Accuracy: 69.27%, Test Loss: 0.7748, Test Accuracy: 72.15%\n",
      "Epoch [1385/2500], Train Loss: 0.7577, Train Accuracy: 65.72%, Test Loss: 0.7439, Test Accuracy: 69.62%\n",
      "Epoch [1386/2500], Train Loss: 0.7644, Train Accuracy: 66.15%, Test Loss: 0.7513, Test Accuracy: 72.15%\n",
      "Epoch [1387/2500], Train Loss: 0.7666, Train Accuracy: 67.57%, Test Loss: 0.7228, Test Accuracy: 67.09%\n",
      "Epoch [1388/2500], Train Loss: 0.7406, Train Accuracy: 67.28%, Test Loss: 0.7846, Test Accuracy: 72.15%\n",
      "Epoch [1389/2500], Train Loss: 0.7647, Train Accuracy: 68.85%, Test Loss: 0.8460, Test Accuracy: 68.35%\n",
      "Epoch [1390/2500], Train Loss: 0.7912, Train Accuracy: 65.29%, Test Loss: 0.7822, Test Accuracy: 65.82%\n",
      "Epoch [1391/2500], Train Loss: 0.7626, Train Accuracy: 68.99%, Test Loss: 0.7424, Test Accuracy: 73.42%\n",
      "Epoch [1392/2500], Train Loss: 0.7804, Train Accuracy: 65.15%, Test Loss: 0.8530, Test Accuracy: 64.56%\n",
      "Epoch [1393/2500], Train Loss: 0.7258, Train Accuracy: 68.28%, Test Loss: 0.7609, Test Accuracy: 64.56%\n",
      "Epoch [1394/2500], Train Loss: 0.7607, Train Accuracy: 68.99%, Test Loss: 0.7306, Test Accuracy: 63.29%\n",
      "Epoch [1395/2500], Train Loss: 0.7587, Train Accuracy: 68.56%, Test Loss: 0.7596, Test Accuracy: 68.35%\n",
      "Epoch [1396/2500], Train Loss: 0.7852, Train Accuracy: 65.72%, Test Loss: 0.7393, Test Accuracy: 69.62%\n",
      "Epoch [1397/2500], Train Loss: 0.7874, Train Accuracy: 66.15%, Test Loss: 0.7301, Test Accuracy: 75.95%\n",
      "Epoch [1398/2500], Train Loss: 0.7565, Train Accuracy: 68.85%, Test Loss: 0.7644, Test Accuracy: 68.35%\n",
      "Epoch [1399/2500], Train Loss: 0.7808, Train Accuracy: 66.29%, Test Loss: 0.7688, Test Accuracy: 67.09%\n",
      "Epoch [1400/2500], Train Loss: 0.7401, Train Accuracy: 68.56%, Test Loss: 0.7434, Test Accuracy: 75.95%\n",
      "Epoch [1401/2500], Train Loss: 0.7813, Train Accuracy: 66.57%, Test Loss: 0.7498, Test Accuracy: 68.35%\n",
      "Epoch [1402/2500], Train Loss: 0.7457, Train Accuracy: 68.42%, Test Loss: 0.9055, Test Accuracy: 62.03%\n",
      "Epoch [1403/2500], Train Loss: 0.7985, Train Accuracy: 65.72%, Test Loss: 0.8116, Test Accuracy: 68.35%\n",
      "Epoch [1404/2500], Train Loss: 0.7873, Train Accuracy: 67.43%, Test Loss: 0.7493, Test Accuracy: 63.29%\n",
      "Epoch [1405/2500], Train Loss: 0.7929, Train Accuracy: 65.29%, Test Loss: 0.7929, Test Accuracy: 72.15%\n",
      "Epoch [1406/2500], Train Loss: 0.7747, Train Accuracy: 67.43%, Test Loss: 0.7433, Test Accuracy: 67.09%\n",
      "Epoch [1407/2500], Train Loss: 0.7843, Train Accuracy: 66.71%, Test Loss: 0.7498, Test Accuracy: 67.09%\n",
      "Epoch [1408/2500], Train Loss: 0.7804, Train Accuracy: 65.86%, Test Loss: 0.7836, Test Accuracy: 69.62%\n",
      "Epoch [1409/2500], Train Loss: 0.7742, Train Accuracy: 66.43%, Test Loss: 0.9605, Test Accuracy: 65.82%\n",
      "Epoch [1410/2500], Train Loss: 0.7648, Train Accuracy: 65.58%, Test Loss: 0.7848, Test Accuracy: 73.42%\n",
      "Epoch [1411/2500], Train Loss: 0.7729, Train Accuracy: 66.00%, Test Loss: 0.8127, Test Accuracy: 70.89%\n",
      "Epoch [1412/2500], Train Loss: 0.7488, Train Accuracy: 68.28%, Test Loss: 0.8359, Test Accuracy: 67.09%\n",
      "Epoch [1413/2500], Train Loss: 0.7645, Train Accuracy: 66.86%, Test Loss: 0.8807, Test Accuracy: 62.03%\n",
      "Epoch [1414/2500], Train Loss: 0.7810, Train Accuracy: 67.00%, Test Loss: 0.7136, Test Accuracy: 65.82%\n",
      "Epoch [1415/2500], Train Loss: 0.7628, Train Accuracy: 67.43%, Test Loss: 0.7183, Test Accuracy: 69.62%\n",
      "Epoch [1416/2500], Train Loss: 0.7472, Train Accuracy: 67.00%, Test Loss: 0.8025, Test Accuracy: 68.35%\n",
      "Epoch [1417/2500], Train Loss: 0.7722, Train Accuracy: 66.00%, Test Loss: 0.7551, Test Accuracy: 73.42%\n",
      "Epoch [1418/2500], Train Loss: 0.7687, Train Accuracy: 67.99%, Test Loss: 0.8019, Test Accuracy: 67.09%\n",
      "Epoch [1419/2500], Train Loss: 0.7757, Train Accuracy: 65.29%, Test Loss: 0.8019, Test Accuracy: 70.89%\n",
      "Epoch [1420/2500], Train Loss: 0.7665, Train Accuracy: 65.72%, Test Loss: 0.8372, Test Accuracy: 64.56%\n",
      "Epoch [1421/2500], Train Loss: 0.7688, Train Accuracy: 66.71%, Test Loss: 0.7299, Test Accuracy: 64.56%\n",
      "Epoch [1422/2500], Train Loss: 0.7583, Train Accuracy: 66.15%, Test Loss: 0.8960, Test Accuracy: 64.56%\n",
      "Epoch [1423/2500], Train Loss: 0.7782, Train Accuracy: 65.29%, Test Loss: 0.7259, Test Accuracy: 67.09%\n",
      "Epoch [1424/2500], Train Loss: 0.7639, Train Accuracy: 66.15%, Test Loss: 0.7519, Test Accuracy: 72.15%\n",
      "Epoch [1425/2500], Train Loss: 0.7990, Train Accuracy: 64.44%, Test Loss: 0.7730, Test Accuracy: 69.62%\n",
      "Epoch [1426/2500], Train Loss: 0.7800, Train Accuracy: 65.01%, Test Loss: 0.7595, Test Accuracy: 72.15%\n",
      "Epoch [1427/2500], Train Loss: 0.7860, Train Accuracy: 64.01%, Test Loss: 0.7240, Test Accuracy: 70.89%\n",
      "Epoch [1428/2500], Train Loss: 0.7744, Train Accuracy: 66.71%, Test Loss: 0.7691, Test Accuracy: 68.35%\n",
      "Epoch [1429/2500], Train Loss: 0.7672, Train Accuracy: 66.15%, Test Loss: 0.7124, Test Accuracy: 65.82%\n",
      "Epoch [1430/2500], Train Loss: 0.7906, Train Accuracy: 65.29%, Test Loss: 0.8156, Test Accuracy: 68.35%\n",
      "Epoch [1431/2500], Train Loss: 0.8083, Train Accuracy: 63.30%, Test Loss: 0.7426, Test Accuracy: 72.15%\n",
      "Epoch [1432/2500], Train Loss: 0.7518, Train Accuracy: 67.00%, Test Loss: 0.8091, Test Accuracy: 70.89%\n",
      "Epoch [1433/2500], Train Loss: 0.7802, Train Accuracy: 66.57%, Test Loss: 0.8788, Test Accuracy: 65.82%\n",
      "Epoch [1434/2500], Train Loss: 0.8056, Train Accuracy: 65.58%, Test Loss: 0.7226, Test Accuracy: 67.09%\n",
      "Epoch [1435/2500], Train Loss: 0.7400, Train Accuracy: 68.28%, Test Loss: 0.7566, Test Accuracy: 75.95%\n",
      "Epoch [1436/2500], Train Loss: 0.7682, Train Accuracy: 66.00%, Test Loss: 0.8515, Test Accuracy: 65.82%\n",
      "Epoch [1437/2500], Train Loss: 0.7630, Train Accuracy: 66.43%, Test Loss: 0.8991, Test Accuracy: 63.29%\n",
      "Epoch [1438/2500], Train Loss: 0.7370, Train Accuracy: 70.41%, Test Loss: 0.7426, Test Accuracy: 67.09%\n",
      "Epoch [1439/2500], Train Loss: 0.7576, Train Accuracy: 67.14%, Test Loss: 0.7407, Test Accuracy: 73.42%\n",
      "Epoch [1440/2500], Train Loss: 0.7697, Train Accuracy: 66.43%, Test Loss: 0.8026, Test Accuracy: 70.89%\n",
      "Epoch [1441/2500], Train Loss: 0.7678, Train Accuracy: 65.29%, Test Loss: 0.7603, Test Accuracy: 70.89%\n",
      "Epoch [1442/2500], Train Loss: 0.7637, Train Accuracy: 66.29%, Test Loss: 0.7905, Test Accuracy: 69.62%\n",
      "Epoch [1443/2500], Train Loss: 0.7320, Train Accuracy: 68.85%, Test Loss: 0.8013, Test Accuracy: 67.09%\n",
      "Epoch [1444/2500], Train Loss: 0.7656, Train Accuracy: 65.72%, Test Loss: 0.7316, Test Accuracy: 68.35%\n",
      "Epoch [1445/2500], Train Loss: 0.7533, Train Accuracy: 66.43%, Test Loss: 0.7734, Test Accuracy: 69.62%\n",
      "Epoch [1446/2500], Train Loss: 0.7812, Train Accuracy: 67.71%, Test Loss: 0.7605, Test Accuracy: 70.89%\n",
      "Epoch [1447/2500], Train Loss: 0.7557, Train Accuracy: 68.28%, Test Loss: 0.7327, Test Accuracy: 70.89%\n",
      "Epoch [1448/2500], Train Loss: 0.7826, Train Accuracy: 65.01%, Test Loss: 0.7875, Test Accuracy: 72.15%\n",
      "Epoch [1449/2500], Train Loss: 0.7386, Train Accuracy: 67.99%, Test Loss: 0.7142, Test Accuracy: 72.15%\n",
      "Epoch [1450/2500], Train Loss: 0.7583, Train Accuracy: 68.85%, Test Loss: 0.7542, Test Accuracy: 73.42%\n",
      "Epoch [1451/2500], Train Loss: 0.7667, Train Accuracy: 67.28%, Test Loss: 0.7872, Test Accuracy: 69.62%\n",
      "Epoch [1452/2500], Train Loss: 0.7646, Train Accuracy: 66.71%, Test Loss: 0.7360, Test Accuracy: 70.89%\n",
      "Epoch [1453/2500], Train Loss: 0.7557, Train Accuracy: 67.00%, Test Loss: 0.7364, Test Accuracy: 70.89%\n",
      "Epoch [1454/2500], Train Loss: 0.7787, Train Accuracy: 66.71%, Test Loss: 0.7568, Test Accuracy: 70.89%\n",
      "Epoch [1455/2500], Train Loss: 0.7484, Train Accuracy: 66.57%, Test Loss: 0.8427, Test Accuracy: 69.62%\n",
      "Epoch [1456/2500], Train Loss: 0.7604, Train Accuracy: 66.29%, Test Loss: 0.7263, Test Accuracy: 62.03%\n",
      "Epoch [1457/2500], Train Loss: 0.7708, Train Accuracy: 65.01%, Test Loss: 0.8392, Test Accuracy: 65.82%\n",
      "Epoch [1458/2500], Train Loss: 0.7942, Train Accuracy: 65.72%, Test Loss: 0.7423, Test Accuracy: 72.15%\n",
      "Epoch [1459/2500], Train Loss: 0.7409, Train Accuracy: 67.43%, Test Loss: 0.7840, Test Accuracy: 67.09%\n",
      "Epoch [1460/2500], Train Loss: 0.7738, Train Accuracy: 65.43%, Test Loss: 0.8780, Test Accuracy: 64.56%\n",
      "Epoch [1461/2500], Train Loss: 0.7714, Train Accuracy: 65.43%, Test Loss: 0.9078, Test Accuracy: 64.56%\n",
      "Epoch [1462/2500], Train Loss: 0.7480, Train Accuracy: 67.28%, Test Loss: 0.7456, Test Accuracy: 72.15%\n",
      "Epoch [1463/2500], Train Loss: 0.7470, Train Accuracy: 68.71%, Test Loss: 0.8425, Test Accuracy: 69.62%\n",
      "Epoch [1464/2500], Train Loss: 0.7752, Train Accuracy: 66.43%, Test Loss: 0.7439, Test Accuracy: 67.09%\n",
      "Epoch [1465/2500], Train Loss: 0.7812, Train Accuracy: 67.57%, Test Loss: 0.7360, Test Accuracy: 72.15%\n",
      "Epoch [1466/2500], Train Loss: 0.7554, Train Accuracy: 67.00%, Test Loss: 0.7928, Test Accuracy: 70.89%\n",
      "Epoch [1467/2500], Train Loss: 0.7394, Train Accuracy: 69.42%, Test Loss: 0.7542, Test Accuracy: 65.82%\n",
      "Epoch [1468/2500], Train Loss: 0.8011, Train Accuracy: 66.00%, Test Loss: 0.7284, Test Accuracy: 68.35%\n",
      "Epoch [1469/2500], Train Loss: 0.7996, Train Accuracy: 65.15%, Test Loss: 0.7729, Test Accuracy: 62.03%\n",
      "Epoch [1470/2500], Train Loss: 0.7902, Train Accuracy: 65.58%, Test Loss: 0.7950, Test Accuracy: 70.89%\n",
      "Epoch [1471/2500], Train Loss: 0.7511, Train Accuracy: 67.71%, Test Loss: 0.8019, Test Accuracy: 69.62%\n",
      "Epoch [1472/2500], Train Loss: 0.7771, Train Accuracy: 67.14%, Test Loss: 0.8186, Test Accuracy: 68.35%\n",
      "Epoch [1473/2500], Train Loss: 0.7664, Train Accuracy: 66.15%, Test Loss: 0.7851, Test Accuracy: 69.62%\n",
      "Epoch [1474/2500], Train Loss: 0.7790, Train Accuracy: 66.57%, Test Loss: 0.7340, Test Accuracy: 65.82%\n",
      "Epoch [1475/2500], Train Loss: 0.7889, Train Accuracy: 65.15%, Test Loss: 0.7775, Test Accuracy: 65.82%\n",
      "Epoch [1476/2500], Train Loss: 0.7543, Train Accuracy: 67.43%, Test Loss: 0.7354, Test Accuracy: 68.35%\n",
      "Epoch [1477/2500], Train Loss: 0.7751, Train Accuracy: 66.15%, Test Loss: 0.7502, Test Accuracy: 73.42%\n",
      "Epoch [1478/2500], Train Loss: 0.7744, Train Accuracy: 65.29%, Test Loss: 0.7299, Test Accuracy: 64.56%\n",
      "Epoch [1479/2500], Train Loss: 0.7637, Train Accuracy: 67.14%, Test Loss: 0.9480, Test Accuracy: 64.56%\n",
      "Epoch [1480/2500], Train Loss: 0.7560, Train Accuracy: 67.99%, Test Loss: 0.7478, Test Accuracy: 67.09%\n",
      "Epoch [1481/2500], Train Loss: 0.7928, Train Accuracy: 67.85%, Test Loss: 0.8221, Test Accuracy: 68.35%\n",
      "Epoch [1482/2500], Train Loss: 0.7691, Train Accuracy: 67.99%, Test Loss: 0.8118, Test Accuracy: 67.09%\n",
      "Epoch [1483/2500], Train Loss: 0.7736, Train Accuracy: 68.56%, Test Loss: 0.7825, Test Accuracy: 73.42%\n",
      "Epoch [1484/2500], Train Loss: 0.7785, Train Accuracy: 67.28%, Test Loss: 0.7972, Test Accuracy: 69.62%\n",
      "Epoch [1485/2500], Train Loss: 0.7638, Train Accuracy: 67.00%, Test Loss: 0.7410, Test Accuracy: 72.15%\n",
      "Epoch [1486/2500], Train Loss: 0.7822, Train Accuracy: 67.00%, Test Loss: 0.7535, Test Accuracy: 69.62%\n",
      "Epoch [1487/2500], Train Loss: 0.7745, Train Accuracy: 65.58%, Test Loss: 0.7688, Test Accuracy: 70.89%\n",
      "Epoch [1488/2500], Train Loss: 0.7698, Train Accuracy: 67.99%, Test Loss: 0.8009, Test Accuracy: 65.82%\n",
      "Epoch [1489/2500], Train Loss: 0.7940, Train Accuracy: 66.43%, Test Loss: 0.7292, Test Accuracy: 69.62%\n",
      "Epoch [1490/2500], Train Loss: 0.7788, Train Accuracy: 66.00%, Test Loss: 0.7743, Test Accuracy: 67.09%\n",
      "Epoch [1491/2500], Train Loss: 0.7598, Train Accuracy: 67.57%, Test Loss: 0.7322, Test Accuracy: 73.42%\n",
      "Epoch [1492/2500], Train Loss: 0.7259, Train Accuracy: 68.28%, Test Loss: 0.7665, Test Accuracy: 72.15%\n",
      "Epoch [1493/2500], Train Loss: 0.7655, Train Accuracy: 67.28%, Test Loss: 0.8810, Test Accuracy: 63.29%\n",
      "Epoch [1494/2500], Train Loss: 0.7914, Train Accuracy: 65.15%, Test Loss: 0.7757, Test Accuracy: 70.89%\n",
      "Epoch [1495/2500], Train Loss: 0.7447, Train Accuracy: 67.00%, Test Loss: 0.7176, Test Accuracy: 69.62%\n",
      "Epoch [1496/2500], Train Loss: 0.7835, Train Accuracy: 66.57%, Test Loss: 0.7546, Test Accuracy: 73.42%\n",
      "Epoch [1497/2500], Train Loss: 0.7667, Train Accuracy: 67.00%, Test Loss: 0.7291, Test Accuracy: 68.35%\n",
      "Epoch [1498/2500], Train Loss: 0.7478, Train Accuracy: 68.56%, Test Loss: 0.7762, Test Accuracy: 67.09%\n",
      "Epoch [1499/2500], Train Loss: 0.7340, Train Accuracy: 68.28%, Test Loss: 0.8054, Test Accuracy: 69.62%\n",
      "Epoch [1500/2500], Train Loss: 0.7743, Train Accuracy: 66.00%, Test Loss: 0.8207, Test Accuracy: 68.35%\n",
      "Epoch [1501/2500], Train Loss: 0.7688, Train Accuracy: 67.99%, Test Loss: 0.7344, Test Accuracy: 68.35%\n",
      "Epoch [1502/2500], Train Loss: 0.7562, Train Accuracy: 66.57%, Test Loss: 0.7397, Test Accuracy: 68.35%\n",
      "Epoch [1503/2500], Train Loss: 0.7622, Train Accuracy: 67.57%, Test Loss: 0.7331, Test Accuracy: 73.42%\n",
      "Epoch [1504/2500], Train Loss: 0.7919, Train Accuracy: 67.00%, Test Loss: 0.7571, Test Accuracy: 73.42%\n",
      "Epoch [1505/2500], Train Loss: 0.7883, Train Accuracy: 66.00%, Test Loss: 0.7590, Test Accuracy: 70.89%\n",
      "Epoch [1506/2500], Train Loss: 0.7646, Train Accuracy: 66.71%, Test Loss: 0.7276, Test Accuracy: 73.42%\n",
      "Epoch [1507/2500], Train Loss: 0.7663, Train Accuracy: 67.43%, Test Loss: 0.8633, Test Accuracy: 64.56%\n",
      "Epoch [1508/2500], Train Loss: 0.7758, Train Accuracy: 66.29%, Test Loss: 0.7647, Test Accuracy: 73.42%\n",
      "Epoch [1509/2500], Train Loss: 0.7734, Train Accuracy: 68.28%, Test Loss: 0.7365, Test Accuracy: 64.56%\n",
      "Epoch [1510/2500], Train Loss: 0.7510, Train Accuracy: 65.72%, Test Loss: 0.7604, Test Accuracy: 70.89%\n",
      "Epoch [1511/2500], Train Loss: 0.7289, Train Accuracy: 66.29%, Test Loss: 0.7995, Test Accuracy: 70.89%\n",
      "Epoch [1512/2500], Train Loss: 0.7492, Train Accuracy: 67.85%, Test Loss: 0.7895, Test Accuracy: 69.62%\n",
      "Epoch [1513/2500], Train Loss: 0.7720, Train Accuracy: 66.29%, Test Loss: 0.8367, Test Accuracy: 68.35%\n",
      "Epoch [1514/2500], Train Loss: 0.7618, Train Accuracy: 66.43%, Test Loss: 0.7657, Test Accuracy: 65.82%\n",
      "Epoch [1515/2500], Train Loss: 0.7642, Train Accuracy: 67.14%, Test Loss: 0.7892, Test Accuracy: 68.35%\n",
      "Epoch [1516/2500], Train Loss: 0.7612, Train Accuracy: 67.85%, Test Loss: 0.8177, Test Accuracy: 69.62%\n",
      "Epoch [1517/2500], Train Loss: 0.7481, Train Accuracy: 66.71%, Test Loss: 0.8131, Test Accuracy: 68.35%\n",
      "Epoch [1518/2500], Train Loss: 0.7637, Train Accuracy: 67.00%, Test Loss: 0.7397, Test Accuracy: 68.35%\n",
      "Epoch [1519/2500], Train Loss: 0.7916, Train Accuracy: 66.15%, Test Loss: 0.8191, Test Accuracy: 69.62%\n",
      "Epoch [1520/2500], Train Loss: 0.7728, Train Accuracy: 67.14%, Test Loss: 0.7627, Test Accuracy: 69.62%\n",
      "Epoch [1521/2500], Train Loss: 0.7775, Train Accuracy: 66.57%, Test Loss: 0.7448, Test Accuracy: 73.42%\n",
      "Epoch [1522/2500], Train Loss: 0.7789, Train Accuracy: 65.72%, Test Loss: 0.7623, Test Accuracy: 70.89%\n",
      "Epoch [1523/2500], Train Loss: 0.7929, Train Accuracy: 66.43%, Test Loss: 0.7865, Test Accuracy: 70.89%\n",
      "Epoch [1524/2500], Train Loss: 0.7657, Train Accuracy: 67.43%, Test Loss: 0.7481, Test Accuracy: 70.89%\n",
      "Epoch [1525/2500], Train Loss: 0.7460, Train Accuracy: 68.42%, Test Loss: 0.7737, Test Accuracy: 69.62%\n",
      "Epoch [1526/2500], Train Loss: 0.7538, Train Accuracy: 66.86%, Test Loss: 0.7416, Test Accuracy: 70.89%\n",
      "Epoch [1527/2500], Train Loss: 0.7750, Train Accuracy: 68.71%, Test Loss: 0.7570, Test Accuracy: 73.42%\n",
      "Epoch [1528/2500], Train Loss: 0.7754, Train Accuracy: 65.58%, Test Loss: 0.8570, Test Accuracy: 67.09%\n",
      "Epoch [1529/2500], Train Loss: 0.7636, Train Accuracy: 66.71%, Test Loss: 0.8372, Test Accuracy: 64.56%\n",
      "Epoch [1530/2500], Train Loss: 0.7770, Train Accuracy: 65.86%, Test Loss: 0.7266, Test Accuracy: 64.56%\n",
      "Epoch [1531/2500], Train Loss: 0.7975, Train Accuracy: 67.99%, Test Loss: 0.8013, Test Accuracy: 69.62%\n",
      "Epoch [1532/2500], Train Loss: 0.7709, Train Accuracy: 65.86%, Test Loss: 0.7573, Test Accuracy: 73.42%\n",
      "Epoch [1533/2500], Train Loss: 0.7825, Train Accuracy: 64.86%, Test Loss: 0.7889, Test Accuracy: 69.62%\n",
      "Epoch [1534/2500], Train Loss: 0.7372, Train Accuracy: 67.71%, Test Loss: 0.7666, Test Accuracy: 70.89%\n",
      "Epoch [1535/2500], Train Loss: 0.7999, Train Accuracy: 66.15%, Test Loss: 0.8153, Test Accuracy: 67.09%\n",
      "Epoch [1536/2500], Train Loss: 0.7496, Train Accuracy: 68.28%, Test Loss: 0.7506, Test Accuracy: 65.82%\n",
      "Epoch [1537/2500], Train Loss: 0.7867, Train Accuracy: 65.58%, Test Loss: 0.7319, Test Accuracy: 64.56%\n",
      "Epoch [1538/2500], Train Loss: 0.7914, Train Accuracy: 66.29%, Test Loss: 0.8890, Test Accuracy: 65.82%\n",
      "Epoch [1539/2500], Train Loss: 0.7859, Train Accuracy: 64.58%, Test Loss: 0.8231, Test Accuracy: 69.62%\n",
      "Epoch [1540/2500], Train Loss: 0.7640, Train Accuracy: 68.14%, Test Loss: 0.7746, Test Accuracy: 70.89%\n",
      "Epoch [1541/2500], Train Loss: 0.7733, Train Accuracy: 65.86%, Test Loss: 0.8839, Test Accuracy: 69.62%\n",
      "Epoch [1542/2500], Train Loss: 0.7900, Train Accuracy: 65.86%, Test Loss: 0.8052, Test Accuracy: 67.09%\n",
      "Epoch [1543/2500], Train Loss: 0.7587, Train Accuracy: 66.29%, Test Loss: 0.9427, Test Accuracy: 64.56%\n",
      "Epoch [1544/2500], Train Loss: 0.7279, Train Accuracy: 67.71%, Test Loss: 0.7576, Test Accuracy: 67.09%\n",
      "Epoch [1545/2500], Train Loss: 0.7955, Train Accuracy: 64.72%, Test Loss: 0.7796, Test Accuracy: 70.89%\n",
      "Epoch [1546/2500], Train Loss: 0.7977, Train Accuracy: 64.30%, Test Loss: 0.7588, Test Accuracy: 73.42%\n",
      "Epoch [1547/2500], Train Loss: 0.7455, Train Accuracy: 67.99%, Test Loss: 0.8132, Test Accuracy: 69.62%\n",
      "Epoch [1548/2500], Train Loss: 0.7865, Train Accuracy: 65.29%, Test Loss: 0.7792, Test Accuracy: 68.35%\n",
      "Epoch [1549/2500], Train Loss: 0.7636, Train Accuracy: 67.28%, Test Loss: 0.7487, Test Accuracy: 72.15%\n",
      "Epoch [1550/2500], Train Loss: 0.7752, Train Accuracy: 67.43%, Test Loss: 0.7717, Test Accuracy: 64.56%\n",
      "Epoch [1551/2500], Train Loss: 0.7980, Train Accuracy: 67.57%, Test Loss: 0.7583, Test Accuracy: 72.15%\n",
      "Epoch [1552/2500], Train Loss: 0.7491, Train Accuracy: 67.57%, Test Loss: 0.7364, Test Accuracy: 72.15%\n",
      "Epoch [1553/2500], Train Loss: 0.7776, Train Accuracy: 65.72%, Test Loss: 0.7365, Test Accuracy: 64.56%\n",
      "Epoch [1554/2500], Train Loss: 0.7658, Train Accuracy: 67.57%, Test Loss: 0.7355, Test Accuracy: 67.09%\n",
      "Epoch [1555/2500], Train Loss: 0.7697, Train Accuracy: 65.72%, Test Loss: 0.8049, Test Accuracy: 70.89%\n",
      "Epoch [1556/2500], Train Loss: 0.7745, Train Accuracy: 65.86%, Test Loss: 0.7477, Test Accuracy: 65.82%\n",
      "Epoch [1557/2500], Train Loss: 0.7599, Train Accuracy: 67.99%, Test Loss: 0.7316, Test Accuracy: 73.42%\n",
      "Epoch [1558/2500], Train Loss: 0.7673, Train Accuracy: 63.30%, Test Loss: 0.7935, Test Accuracy: 68.35%\n",
      "Epoch [1559/2500], Train Loss: 0.7422, Train Accuracy: 67.28%, Test Loss: 0.8007, Test Accuracy: 67.09%\n",
      "Epoch [1560/2500], Train Loss: 0.7671, Train Accuracy: 66.00%, Test Loss: 0.7832, Test Accuracy: 68.35%\n",
      "Epoch [1561/2500], Train Loss: 0.7311, Train Accuracy: 67.57%, Test Loss: 0.7636, Test Accuracy: 73.42%\n",
      "Epoch [1562/2500], Train Loss: 0.7472, Train Accuracy: 66.43%, Test Loss: 0.7919, Test Accuracy: 70.89%\n",
      "Epoch [1563/2500], Train Loss: 0.7845, Train Accuracy: 67.14%, Test Loss: 0.7515, Test Accuracy: 69.62%\n",
      "Epoch [1564/2500], Train Loss: 0.7743, Train Accuracy: 65.72%, Test Loss: 0.8810, Test Accuracy: 63.29%\n",
      "Epoch [1565/2500], Train Loss: 0.7550, Train Accuracy: 68.28%, Test Loss: 0.8250, Test Accuracy: 67.09%\n",
      "Epoch [1566/2500], Train Loss: 0.7654, Train Accuracy: 68.42%, Test Loss: 0.8276, Test Accuracy: 69.62%\n",
      "Epoch [1567/2500], Train Loss: 0.7505, Train Accuracy: 67.85%, Test Loss: 0.7307, Test Accuracy: 72.15%\n",
      "Epoch [1568/2500], Train Loss: 0.7659, Train Accuracy: 65.29%, Test Loss: 0.9146, Test Accuracy: 59.49%\n",
      "Epoch [1569/2500], Train Loss: 0.7715, Train Accuracy: 67.14%, Test Loss: 0.7350, Test Accuracy: 67.09%\n",
      "Epoch [1570/2500], Train Loss: 0.7689, Train Accuracy: 65.72%, Test Loss: 0.7509, Test Accuracy: 68.35%\n",
      "Epoch [1571/2500], Train Loss: 0.7479, Train Accuracy: 68.56%, Test Loss: 0.8493, Test Accuracy: 64.56%\n",
      "Epoch [1572/2500], Train Loss: 0.7909, Train Accuracy: 66.29%, Test Loss: 0.7189, Test Accuracy: 70.89%\n",
      "Epoch [1573/2500], Train Loss: 0.7710, Train Accuracy: 65.72%, Test Loss: 0.7724, Test Accuracy: 72.15%\n",
      "Epoch [1574/2500], Train Loss: 0.7478, Train Accuracy: 66.86%, Test Loss: 0.7797, Test Accuracy: 70.89%\n",
      "Epoch [1575/2500], Train Loss: 0.7745, Train Accuracy: 66.57%, Test Loss: 0.7648, Test Accuracy: 70.89%\n",
      "Epoch [1576/2500], Train Loss: 0.7724, Train Accuracy: 65.43%, Test Loss: 0.8092, Test Accuracy: 68.35%\n",
      "Epoch [1577/2500], Train Loss: 0.7505, Train Accuracy: 67.71%, Test Loss: 0.7230, Test Accuracy: 73.42%\n",
      "Epoch [1578/2500], Train Loss: 0.7719, Train Accuracy: 67.57%, Test Loss: 0.8211, Test Accuracy: 67.09%\n",
      "Epoch [1579/2500], Train Loss: 0.7736, Train Accuracy: 66.00%, Test Loss: 0.7507, Test Accuracy: 74.68%\n",
      "Epoch [1580/2500], Train Loss: 0.7785, Train Accuracy: 67.99%, Test Loss: 0.8661, Test Accuracy: 63.29%\n",
      "Epoch [1581/2500], Train Loss: 0.7756, Train Accuracy: 67.14%, Test Loss: 0.7388, Test Accuracy: 65.82%\n",
      "Epoch [1582/2500], Train Loss: 0.7639, Train Accuracy: 65.43%, Test Loss: 0.7738, Test Accuracy: 68.35%\n",
      "Epoch [1583/2500], Train Loss: 0.7981, Train Accuracy: 64.30%, Test Loss: 0.9319, Test Accuracy: 63.29%\n",
      "Epoch [1584/2500], Train Loss: 0.7930, Train Accuracy: 67.57%, Test Loss: 0.7251, Test Accuracy: 72.15%\n",
      "Epoch [1585/2500], Train Loss: 0.7164, Train Accuracy: 68.56%, Test Loss: 0.7567, Test Accuracy: 72.15%\n",
      "Epoch [1586/2500], Train Loss: 0.7711, Train Accuracy: 67.85%, Test Loss: 0.7214, Test Accuracy: 70.89%\n",
      "Epoch [1587/2500], Train Loss: 0.7563, Train Accuracy: 68.28%, Test Loss: 0.8411, Test Accuracy: 69.62%\n",
      "Epoch [1588/2500], Train Loss: 0.7598, Train Accuracy: 67.00%, Test Loss: 0.7573, Test Accuracy: 68.35%\n",
      "Epoch [1589/2500], Train Loss: 0.7519, Train Accuracy: 67.00%, Test Loss: 0.8672, Test Accuracy: 69.62%\n",
      "Epoch [1590/2500], Train Loss: 0.7770, Train Accuracy: 67.57%, Test Loss: 0.7843, Test Accuracy: 69.62%\n",
      "Epoch [1591/2500], Train Loss: 0.7714, Train Accuracy: 66.15%, Test Loss: 0.7520, Test Accuracy: 73.42%\n",
      "Epoch [1592/2500], Train Loss: 0.7579, Train Accuracy: 65.86%, Test Loss: 0.7347, Test Accuracy: 72.15%\n",
      "Epoch [1593/2500], Train Loss: 0.7320, Train Accuracy: 69.56%, Test Loss: 0.7841, Test Accuracy: 72.15%\n",
      "Epoch [1594/2500], Train Loss: 0.7592, Train Accuracy: 64.58%, Test Loss: 0.7380, Test Accuracy: 73.42%\n",
      "Epoch [1595/2500], Train Loss: 0.7609, Train Accuracy: 67.43%, Test Loss: 0.7536, Test Accuracy: 70.89%\n",
      "Epoch [1596/2500], Train Loss: 0.7773, Train Accuracy: 68.28%, Test Loss: 0.8850, Test Accuracy: 67.09%\n",
      "Epoch [1597/2500], Train Loss: 0.7990, Train Accuracy: 66.57%, Test Loss: 0.7514, Test Accuracy: 73.42%\n",
      "Epoch [1598/2500], Train Loss: 0.7276, Train Accuracy: 67.99%, Test Loss: 0.7737, Test Accuracy: 70.89%\n",
      "Epoch [1599/2500], Train Loss: 0.7770, Train Accuracy: 65.72%, Test Loss: 0.7580, Test Accuracy: 70.89%\n",
      "Epoch [1600/2500], Train Loss: 0.7677, Train Accuracy: 65.43%, Test Loss: 0.7846, Test Accuracy: 68.35%\n",
      "Epoch [1601/2500], Train Loss: 0.7542, Train Accuracy: 67.99%, Test Loss: 0.7691, Test Accuracy: 74.68%\n",
      "Epoch [1602/2500], Train Loss: 0.7725, Train Accuracy: 67.14%, Test Loss: 0.7486, Test Accuracy: 73.42%\n",
      "Epoch [1603/2500], Train Loss: 0.7678, Train Accuracy: 65.72%, Test Loss: 0.7269, Test Accuracy: 69.62%\n",
      "Epoch [1604/2500], Train Loss: 0.7659, Train Accuracy: 67.85%, Test Loss: 0.7694, Test Accuracy: 73.42%\n",
      "Epoch [1605/2500], Train Loss: 0.7581, Train Accuracy: 69.42%, Test Loss: 0.7441, Test Accuracy: 68.35%\n",
      "Epoch [1606/2500], Train Loss: 0.7589, Train Accuracy: 66.43%, Test Loss: 0.7616, Test Accuracy: 69.62%\n",
      "Epoch [1607/2500], Train Loss: 0.7566, Train Accuracy: 67.99%, Test Loss: 0.8007, Test Accuracy: 69.62%\n",
      "Epoch [1608/2500], Train Loss: 0.7509, Train Accuracy: 66.86%, Test Loss: 0.7360, Test Accuracy: 63.29%\n",
      "Epoch [1609/2500], Train Loss: 0.7775, Train Accuracy: 67.00%, Test Loss: 0.8424, Test Accuracy: 65.82%\n",
      "Epoch [1610/2500], Train Loss: 0.7622, Train Accuracy: 66.15%, Test Loss: 0.7768, Test Accuracy: 72.15%\n",
      "Epoch [1611/2500], Train Loss: 0.7439, Train Accuracy: 67.28%, Test Loss: 0.8113, Test Accuracy: 70.89%\n",
      "Epoch [1612/2500], Train Loss: 0.7598, Train Accuracy: 65.86%, Test Loss: 0.7396, Test Accuracy: 74.68%\n",
      "Epoch [1613/2500], Train Loss: 0.7523, Train Accuracy: 67.43%, Test Loss: 0.7536, Test Accuracy: 73.42%\n",
      "Epoch [1614/2500], Train Loss: 0.7684, Train Accuracy: 67.85%, Test Loss: 0.8342, Test Accuracy: 67.09%\n",
      "Epoch [1615/2500], Train Loss: 0.7672, Train Accuracy: 65.72%, Test Loss: 0.7512, Test Accuracy: 69.62%\n",
      "Epoch [1616/2500], Train Loss: 0.7561, Train Accuracy: 66.29%, Test Loss: 0.8995, Test Accuracy: 62.03%\n",
      "Epoch [1617/2500], Train Loss: 0.7729, Train Accuracy: 65.86%, Test Loss: 0.8542, Test Accuracy: 64.56%\n",
      "Epoch [1618/2500], Train Loss: 0.7512, Train Accuracy: 66.29%, Test Loss: 0.7337, Test Accuracy: 74.68%\n",
      "Epoch [1619/2500], Train Loss: 0.7727, Train Accuracy: 65.86%, Test Loss: 0.9118, Test Accuracy: 63.29%\n",
      "Epoch [1620/2500], Train Loss: 0.7676, Train Accuracy: 66.43%, Test Loss: 0.7655, Test Accuracy: 72.15%\n",
      "Epoch [1621/2500], Train Loss: 0.7627, Train Accuracy: 67.14%, Test Loss: 0.7298, Test Accuracy: 70.89%\n",
      "Epoch [1622/2500], Train Loss: 0.7609, Train Accuracy: 66.43%, Test Loss: 0.7294, Test Accuracy: 70.89%\n",
      "Epoch [1623/2500], Train Loss: 0.7552, Train Accuracy: 67.43%, Test Loss: 0.7528, Test Accuracy: 72.15%\n",
      "Epoch [1624/2500], Train Loss: 0.7326, Train Accuracy: 67.57%, Test Loss: 0.7335, Test Accuracy: 72.15%\n",
      "Epoch [1625/2500], Train Loss: 0.7544, Train Accuracy: 65.29%, Test Loss: 0.7591, Test Accuracy: 72.15%\n",
      "Epoch [1626/2500], Train Loss: 0.7647, Train Accuracy: 66.29%, Test Loss: 0.8170, Test Accuracy: 63.29%\n",
      "Epoch [1627/2500], Train Loss: 0.7651, Train Accuracy: 67.99%, Test Loss: 0.7272, Test Accuracy: 68.35%\n",
      "Epoch [1628/2500], Train Loss: 0.7833, Train Accuracy: 64.15%, Test Loss: 0.8022, Test Accuracy: 69.62%\n",
      "Epoch [1629/2500], Train Loss: 0.7370, Train Accuracy: 69.56%, Test Loss: 0.8771, Test Accuracy: 64.56%\n",
      "Epoch [1630/2500], Train Loss: 0.7659, Train Accuracy: 67.14%, Test Loss: 0.8517, Test Accuracy: 68.35%\n",
      "Epoch [1631/2500], Train Loss: 0.7623, Train Accuracy: 66.86%, Test Loss: 0.7927, Test Accuracy: 73.42%\n",
      "Epoch [1632/2500], Train Loss: 0.7755, Train Accuracy: 65.86%, Test Loss: 0.7698, Test Accuracy: 67.09%\n",
      "Epoch [1633/2500], Train Loss: 0.7942, Train Accuracy: 64.58%, Test Loss: 0.7266, Test Accuracy: 65.82%\n",
      "Epoch [1634/2500], Train Loss: 0.7488, Train Accuracy: 66.57%, Test Loss: 0.8145, Test Accuracy: 67.09%\n",
      "Epoch [1635/2500], Train Loss: 0.7620, Train Accuracy: 67.00%, Test Loss: 0.7525, Test Accuracy: 73.42%\n",
      "Epoch [1636/2500], Train Loss: 0.7891, Train Accuracy: 64.44%, Test Loss: 0.8222, Test Accuracy: 69.62%\n",
      "Epoch [1637/2500], Train Loss: 0.7508, Train Accuracy: 67.99%, Test Loss: 0.7398, Test Accuracy: 74.68%\n",
      "Epoch [1638/2500], Train Loss: 0.7676, Train Accuracy: 65.43%, Test Loss: 0.8499, Test Accuracy: 65.82%\n",
      "Epoch [1639/2500], Train Loss: 0.7776, Train Accuracy: 66.71%, Test Loss: 0.7553, Test Accuracy: 73.42%\n",
      "Epoch [1640/2500], Train Loss: 0.7838, Train Accuracy: 66.29%, Test Loss: 0.7812, Test Accuracy: 68.35%\n",
      "Epoch [1641/2500], Train Loss: 0.7591, Train Accuracy: 68.85%, Test Loss: 0.7962, Test Accuracy: 70.89%\n",
      "Epoch [1642/2500], Train Loss: 0.7562, Train Accuracy: 67.99%, Test Loss: 0.7571, Test Accuracy: 73.42%\n",
      "Epoch [1643/2500], Train Loss: 0.7454, Train Accuracy: 67.71%, Test Loss: 0.8498, Test Accuracy: 64.56%\n",
      "Epoch [1644/2500], Train Loss: 0.7927, Train Accuracy: 64.15%, Test Loss: 0.7761, Test Accuracy: 70.89%\n",
      "Epoch [1645/2500], Train Loss: 0.7380, Train Accuracy: 67.85%, Test Loss: 0.7584, Test Accuracy: 72.15%\n",
      "Epoch [1646/2500], Train Loss: 0.7467, Train Accuracy: 68.85%, Test Loss: 0.7499, Test Accuracy: 73.42%\n",
      "Epoch [1647/2500], Train Loss: 0.7548, Train Accuracy: 68.99%, Test Loss: 0.9774, Test Accuracy: 60.76%\n",
      "Epoch [1648/2500], Train Loss: 0.8053, Train Accuracy: 65.29%, Test Loss: 0.7792, Test Accuracy: 73.42%\n",
      "Epoch [1649/2500], Train Loss: 0.7498, Train Accuracy: 66.71%, Test Loss: 0.7310, Test Accuracy: 70.89%\n",
      "Epoch [1650/2500], Train Loss: 0.7849, Train Accuracy: 66.71%, Test Loss: 0.7302, Test Accuracy: 68.35%\n",
      "Epoch [1651/2500], Train Loss: 0.7431, Train Accuracy: 66.71%, Test Loss: 0.7187, Test Accuracy: 69.62%\n",
      "Epoch [1652/2500], Train Loss: 0.7742, Train Accuracy: 66.29%, Test Loss: 0.8478, Test Accuracy: 64.56%\n",
      "Epoch [1653/2500], Train Loss: 0.7728, Train Accuracy: 65.15%, Test Loss: 0.7191, Test Accuracy: 60.76%\n",
      "Epoch [1654/2500], Train Loss: 0.7748, Train Accuracy: 65.58%, Test Loss: 0.7486, Test Accuracy: 70.89%\n",
      "Epoch [1655/2500], Train Loss: 0.7678, Train Accuracy: 66.29%, Test Loss: 0.7162, Test Accuracy: 67.09%\n",
      "Epoch [1656/2500], Train Loss: 0.7471, Train Accuracy: 68.14%, Test Loss: 0.7920, Test Accuracy: 70.89%\n",
      "Epoch [1657/2500], Train Loss: 0.7605, Train Accuracy: 65.86%, Test Loss: 0.9104, Test Accuracy: 64.56%\n",
      "Epoch [1658/2500], Train Loss: 0.7482, Train Accuracy: 68.42%, Test Loss: 0.8712, Test Accuracy: 64.56%\n",
      "Epoch [1659/2500], Train Loss: 0.7535, Train Accuracy: 67.99%, Test Loss: 0.7628, Test Accuracy: 74.68%\n",
      "Epoch [1660/2500], Train Loss: 0.7588, Train Accuracy: 66.15%, Test Loss: 0.8150, Test Accuracy: 67.09%\n",
      "Epoch [1661/2500], Train Loss: 0.7679, Train Accuracy: 68.99%, Test Loss: 0.7296, Test Accuracy: 64.56%\n",
      "Epoch [1662/2500], Train Loss: 0.7821, Train Accuracy: 65.58%, Test Loss: 0.7342, Test Accuracy: 68.35%\n",
      "Epoch [1663/2500], Train Loss: 0.7595, Train Accuracy: 66.15%, Test Loss: 0.7586, Test Accuracy: 72.15%\n",
      "Epoch [1664/2500], Train Loss: 0.7538, Train Accuracy: 67.14%, Test Loss: 0.9248, Test Accuracy: 63.29%\n",
      "Epoch [1665/2500], Train Loss: 0.7508, Train Accuracy: 67.28%, Test Loss: 0.8378, Test Accuracy: 64.56%\n",
      "Epoch [1666/2500], Train Loss: 0.7546, Train Accuracy: 67.43%, Test Loss: 0.8851, Test Accuracy: 67.09%\n",
      "Epoch [1667/2500], Train Loss: 0.7977, Train Accuracy: 63.87%, Test Loss: 0.7700, Test Accuracy: 73.42%\n",
      "Epoch [1668/2500], Train Loss: 0.7655, Train Accuracy: 66.29%, Test Loss: 0.9173, Test Accuracy: 59.49%\n",
      "Epoch [1669/2500], Train Loss: 0.7766, Train Accuracy: 66.71%, Test Loss: 0.7525, Test Accuracy: 73.42%\n",
      "Epoch [1670/2500], Train Loss: 0.7743, Train Accuracy: 65.86%, Test Loss: 0.7189, Test Accuracy: 67.09%\n",
      "Epoch [1671/2500], Train Loss: 0.7720, Train Accuracy: 67.28%, Test Loss: 0.8977, Test Accuracy: 62.03%\n",
      "Epoch [1672/2500], Train Loss: 0.7377, Train Accuracy: 68.28%, Test Loss: 0.7257, Test Accuracy: 68.35%\n",
      "Epoch [1673/2500], Train Loss: 0.8111, Train Accuracy: 65.72%, Test Loss: 0.7425, Test Accuracy: 69.62%\n",
      "Epoch [1674/2500], Train Loss: 0.7383, Train Accuracy: 66.00%, Test Loss: 0.7913, Test Accuracy: 65.82%\n",
      "Epoch [1675/2500], Train Loss: 0.7675, Train Accuracy: 65.01%, Test Loss: 0.7240, Test Accuracy: 67.09%\n",
      "Epoch [1676/2500], Train Loss: 0.7640, Train Accuracy: 68.28%, Test Loss: 0.7550, Test Accuracy: 72.15%\n",
      "Epoch [1677/2500], Train Loss: 0.7365, Train Accuracy: 66.29%, Test Loss: 0.8145, Test Accuracy: 67.09%\n",
      "Epoch [1678/2500], Train Loss: 0.7392, Train Accuracy: 69.27%, Test Loss: 0.7729, Test Accuracy: 72.15%\n",
      "Epoch [1679/2500], Train Loss: 0.7448, Train Accuracy: 67.28%, Test Loss: 0.9057, Test Accuracy: 59.49%\n",
      "Epoch [1680/2500], Train Loss: 0.7431, Train Accuracy: 69.13%, Test Loss: 0.7827, Test Accuracy: 67.09%\n",
      "Epoch [1681/2500], Train Loss: 0.7628, Train Accuracy: 65.29%, Test Loss: 0.7627, Test Accuracy: 72.15%\n",
      "Epoch [1682/2500], Train Loss: 0.8142, Train Accuracy: 64.58%, Test Loss: 0.7458, Test Accuracy: 73.42%\n",
      "Epoch [1683/2500], Train Loss: 0.7730, Train Accuracy: 66.57%, Test Loss: 0.8034, Test Accuracy: 68.35%\n",
      "Epoch [1684/2500], Train Loss: 0.7603, Train Accuracy: 65.58%, Test Loss: 0.8156, Test Accuracy: 67.09%\n",
      "Epoch [1685/2500], Train Loss: 0.7628, Train Accuracy: 67.71%, Test Loss: 0.8243, Test Accuracy: 64.56%\n",
      "Epoch [1686/2500], Train Loss: 0.7491, Train Accuracy: 67.71%, Test Loss: 0.7370, Test Accuracy: 73.42%\n",
      "Epoch [1687/2500], Train Loss: 0.7895, Train Accuracy: 65.29%, Test Loss: 0.8252, Test Accuracy: 67.09%\n",
      "Epoch [1688/2500], Train Loss: 0.7583, Train Accuracy: 67.57%, Test Loss: 0.7253, Test Accuracy: 68.35%\n",
      "Epoch [1689/2500], Train Loss: 0.7816, Train Accuracy: 67.14%, Test Loss: 0.7894, Test Accuracy: 67.09%\n",
      "Epoch [1690/2500], Train Loss: 0.7523, Train Accuracy: 68.14%, Test Loss: 0.7421, Test Accuracy: 67.09%\n",
      "Epoch [1691/2500], Train Loss: 0.7524, Train Accuracy: 67.57%, Test Loss: 0.7955, Test Accuracy: 70.89%\n",
      "Epoch [1692/2500], Train Loss: 0.7557, Train Accuracy: 66.71%, Test Loss: 0.7312, Test Accuracy: 70.89%\n",
      "Epoch [1693/2500], Train Loss: 0.7489, Train Accuracy: 67.28%, Test Loss: 0.7547, Test Accuracy: 63.29%\n",
      "Epoch [1694/2500], Train Loss: 0.7510, Train Accuracy: 68.42%, Test Loss: 0.9174, Test Accuracy: 62.03%\n",
      "Epoch [1695/2500], Train Loss: 0.7401, Train Accuracy: 68.28%, Test Loss: 0.7372, Test Accuracy: 68.35%\n",
      "Epoch [1696/2500], Train Loss: 0.7744, Train Accuracy: 66.43%, Test Loss: 0.7257, Test Accuracy: 67.09%\n",
      "Epoch [1697/2500], Train Loss: 0.7580, Train Accuracy: 67.00%, Test Loss: 0.7880, Test Accuracy: 70.89%\n",
      "Epoch [1698/2500], Train Loss: 0.7475, Train Accuracy: 67.99%, Test Loss: 0.8691, Test Accuracy: 65.82%\n",
      "Epoch [1699/2500], Train Loss: 0.7630, Train Accuracy: 68.71%, Test Loss: 0.8328, Test Accuracy: 65.82%\n",
      "Epoch [1700/2500], Train Loss: 0.7720, Train Accuracy: 65.86%, Test Loss: 0.7992, Test Accuracy: 70.89%\n",
      "Epoch [1701/2500], Train Loss: 0.7524, Train Accuracy: 66.57%, Test Loss: 0.7545, Test Accuracy: 69.62%\n",
      "Epoch [1702/2500], Train Loss: 0.7793, Train Accuracy: 65.72%, Test Loss: 0.7574, Test Accuracy: 74.68%\n",
      "Epoch [1703/2500], Train Loss: 0.7875, Train Accuracy: 64.15%, Test Loss: 0.7450, Test Accuracy: 68.35%\n",
      "Epoch [1704/2500], Train Loss: 0.7676, Train Accuracy: 67.00%, Test Loss: 0.9810, Test Accuracy: 59.49%\n",
      "Epoch [1705/2500], Train Loss: 0.7402, Train Accuracy: 68.28%, Test Loss: 0.7593, Test Accuracy: 68.35%\n",
      "Epoch [1706/2500], Train Loss: 0.7527, Train Accuracy: 66.86%, Test Loss: 0.7337, Test Accuracy: 74.68%\n",
      "Epoch [1707/2500], Train Loss: 0.7692, Train Accuracy: 66.71%, Test Loss: 0.7624, Test Accuracy: 69.62%\n",
      "Epoch [1708/2500], Train Loss: 0.7383, Train Accuracy: 68.71%, Test Loss: 0.7869, Test Accuracy: 69.62%\n",
      "Epoch [1709/2500], Train Loss: 0.7602, Train Accuracy: 67.57%, Test Loss: 0.7579, Test Accuracy: 72.15%\n",
      "Epoch [1710/2500], Train Loss: 0.7550, Train Accuracy: 68.71%, Test Loss: 0.7272, Test Accuracy: 68.35%\n",
      "Epoch [1711/2500], Train Loss: 0.8450, Train Accuracy: 63.30%, Test Loss: 0.7431, Test Accuracy: 68.35%\n",
      "Epoch [1712/2500], Train Loss: 0.7495, Train Accuracy: 68.56%, Test Loss: 0.8037, Test Accuracy: 62.03%\n",
      "Epoch [1713/2500], Train Loss: 0.7795, Train Accuracy: 67.43%, Test Loss: 0.7784, Test Accuracy: 70.89%\n",
      "Epoch [1714/2500], Train Loss: 0.7576, Train Accuracy: 68.14%, Test Loss: 0.7247, Test Accuracy: 73.42%\n",
      "Epoch [1715/2500], Train Loss: 0.7384, Train Accuracy: 67.28%, Test Loss: 0.7323, Test Accuracy: 72.15%\n",
      "Epoch [1716/2500], Train Loss: 0.7708, Train Accuracy: 66.71%, Test Loss: 0.7256, Test Accuracy: 74.68%\n",
      "Epoch [1717/2500], Train Loss: 0.7535, Train Accuracy: 67.00%, Test Loss: 0.8083, Test Accuracy: 64.56%\n",
      "Epoch [1718/2500], Train Loss: 0.7669, Train Accuracy: 66.43%, Test Loss: 0.8008, Test Accuracy: 69.62%\n",
      "Epoch [1719/2500], Train Loss: 0.7886, Train Accuracy: 65.58%, Test Loss: 0.7425, Test Accuracy: 73.42%\n",
      "Epoch [1720/2500], Train Loss: 0.7989, Train Accuracy: 66.15%, Test Loss: 0.7731, Test Accuracy: 70.89%\n",
      "Epoch [1721/2500], Train Loss: 0.7751, Train Accuracy: 65.01%, Test Loss: 0.7627, Test Accuracy: 68.35%\n",
      "Epoch [1722/2500], Train Loss: 0.7510, Train Accuracy: 68.14%, Test Loss: 0.8050, Test Accuracy: 70.89%\n",
      "Epoch [1723/2500], Train Loss: 0.7653, Train Accuracy: 67.43%, Test Loss: 0.8556, Test Accuracy: 64.56%\n",
      "Epoch [1724/2500], Train Loss: 0.7766, Train Accuracy: 66.57%, Test Loss: 0.7390, Test Accuracy: 68.35%\n",
      "Epoch [1725/2500], Train Loss: 0.7607, Train Accuracy: 66.00%, Test Loss: 0.8519, Test Accuracy: 63.29%\n",
      "Epoch [1726/2500], Train Loss: 0.7669, Train Accuracy: 66.00%, Test Loss: 0.7720, Test Accuracy: 70.89%\n",
      "Epoch [1727/2500], Train Loss: 0.7744, Train Accuracy: 65.72%, Test Loss: 0.8762, Test Accuracy: 67.09%\n",
      "Epoch [1728/2500], Train Loss: 0.7610, Train Accuracy: 67.99%, Test Loss: 1.0069, Test Accuracy: 59.49%\n",
      "Epoch [1729/2500], Train Loss: 0.7766, Train Accuracy: 67.00%, Test Loss: 0.7273, Test Accuracy: 67.09%\n",
      "Epoch [1730/2500], Train Loss: 0.7744, Train Accuracy: 64.86%, Test Loss: 0.7410, Test Accuracy: 70.89%\n",
      "Epoch [1731/2500], Train Loss: 0.7403, Train Accuracy: 68.14%, Test Loss: 0.7147, Test Accuracy: 65.82%\n",
      "Epoch [1732/2500], Train Loss: 0.7265, Train Accuracy: 69.56%, Test Loss: 0.7375, Test Accuracy: 74.68%\n",
      "Epoch [1733/2500], Train Loss: 0.7768, Train Accuracy: 66.00%, Test Loss: 0.9139, Test Accuracy: 64.56%\n",
      "Epoch [1734/2500], Train Loss: 0.7684, Train Accuracy: 68.56%, Test Loss: 0.7685, Test Accuracy: 72.15%\n",
      "Epoch [1735/2500], Train Loss: 0.7609, Train Accuracy: 65.86%, Test Loss: 0.8018, Test Accuracy: 69.62%\n",
      "Epoch [1736/2500], Train Loss: 0.7611, Train Accuracy: 67.99%, Test Loss: 0.7294, Test Accuracy: 70.89%\n",
      "Epoch [1737/2500], Train Loss: 0.7547, Train Accuracy: 68.71%, Test Loss: 0.8166, Test Accuracy: 69.62%\n",
      "Epoch [1738/2500], Train Loss: 0.7597, Train Accuracy: 68.85%, Test Loss: 0.7210, Test Accuracy: 72.15%\n",
      "Epoch [1739/2500], Train Loss: 0.7553, Train Accuracy: 67.99%, Test Loss: 0.7462, Test Accuracy: 63.29%\n",
      "Epoch [1740/2500], Train Loss: 0.7567, Train Accuracy: 66.57%, Test Loss: 0.8250, Test Accuracy: 67.09%\n",
      "Epoch [1741/2500], Train Loss: 0.7622, Train Accuracy: 65.58%, Test Loss: 0.7841, Test Accuracy: 65.82%\n",
      "Epoch [1742/2500], Train Loss: 0.7724, Train Accuracy: 66.29%, Test Loss: 0.7485, Test Accuracy: 74.68%\n",
      "Epoch [1743/2500], Train Loss: 0.7543, Train Accuracy: 68.71%, Test Loss: 0.8571, Test Accuracy: 65.82%\n",
      "Epoch [1744/2500], Train Loss: 0.7501, Train Accuracy: 68.14%, Test Loss: 0.7405, Test Accuracy: 68.35%\n",
      "Epoch [1745/2500], Train Loss: 0.7730, Train Accuracy: 67.43%, Test Loss: 0.8020, Test Accuracy: 72.15%\n",
      "Epoch [1746/2500], Train Loss: 0.7688, Train Accuracy: 65.43%, Test Loss: 0.7502, Test Accuracy: 72.15%\n",
      "Epoch [1747/2500], Train Loss: 0.7565, Train Accuracy: 68.28%, Test Loss: 0.7862, Test Accuracy: 67.09%\n",
      "Epoch [1748/2500], Train Loss: 0.7392, Train Accuracy: 68.99%, Test Loss: 0.9563, Test Accuracy: 63.29%\n",
      "Epoch [1749/2500], Train Loss: 0.7731, Train Accuracy: 65.58%, Test Loss: 0.7909, Test Accuracy: 70.89%\n",
      "Epoch [1750/2500], Train Loss: 0.7372, Train Accuracy: 66.86%, Test Loss: 0.8216, Test Accuracy: 65.82%\n",
      "Epoch [1751/2500], Train Loss: 0.7713, Train Accuracy: 65.58%, Test Loss: 0.7681, Test Accuracy: 73.42%\n",
      "Epoch [1752/2500], Train Loss: 0.7422, Train Accuracy: 65.43%, Test Loss: 0.7190, Test Accuracy: 69.62%\n",
      "Epoch [1753/2500], Train Loss: 0.7729, Train Accuracy: 66.86%, Test Loss: 0.7054, Test Accuracy: 68.35%\n",
      "Epoch [1754/2500], Train Loss: 0.7582, Train Accuracy: 67.57%, Test Loss: 0.7629, Test Accuracy: 72.15%\n",
      "Epoch [1755/2500], Train Loss: 0.7685, Train Accuracy: 64.15%, Test Loss: 0.7139, Test Accuracy: 67.09%\n",
      "Epoch [1756/2500], Train Loss: 0.7578, Train Accuracy: 67.28%, Test Loss: 0.7798, Test Accuracy: 69.62%\n",
      "Epoch [1757/2500], Train Loss: 0.7625, Train Accuracy: 66.15%, Test Loss: 0.7612, Test Accuracy: 72.15%\n",
      "Epoch [1758/2500], Train Loss: 0.7733, Train Accuracy: 66.86%, Test Loss: 0.7960, Test Accuracy: 70.89%\n",
      "Epoch [1759/2500], Train Loss: 0.7643, Train Accuracy: 66.00%, Test Loss: 0.7260, Test Accuracy: 67.09%\n",
      "Epoch [1760/2500], Train Loss: 0.7591, Train Accuracy: 65.72%, Test Loss: 0.8001, Test Accuracy: 69.62%\n",
      "Epoch [1761/2500], Train Loss: 0.7335, Train Accuracy: 69.70%, Test Loss: 0.7580, Test Accuracy: 68.35%\n",
      "Epoch [1762/2500], Train Loss: 0.7473, Train Accuracy: 65.86%, Test Loss: 0.7676, Test Accuracy: 64.56%\n",
      "Epoch [1763/2500], Train Loss: 0.7356, Train Accuracy: 66.71%, Test Loss: 0.8748, Test Accuracy: 60.76%\n",
      "Epoch [1764/2500], Train Loss: 0.7571, Train Accuracy: 65.58%, Test Loss: 0.7645, Test Accuracy: 72.15%\n",
      "Epoch [1765/2500], Train Loss: 0.7774, Train Accuracy: 67.00%, Test Loss: 0.7592, Test Accuracy: 72.15%\n",
      "Epoch [1766/2500], Train Loss: 0.7637, Train Accuracy: 66.71%, Test Loss: 0.7576, Test Accuracy: 74.68%\n",
      "Epoch [1767/2500], Train Loss: 0.7605, Train Accuracy: 67.00%, Test Loss: 0.8683, Test Accuracy: 60.76%\n",
      "Epoch [1768/2500], Train Loss: 0.7555, Train Accuracy: 67.57%, Test Loss: 0.7355, Test Accuracy: 72.15%\n",
      "Epoch [1769/2500], Train Loss: 0.7559, Train Accuracy: 67.14%, Test Loss: 0.7505, Test Accuracy: 70.89%\n",
      "Epoch [1770/2500], Train Loss: 0.7449, Train Accuracy: 67.99%, Test Loss: 0.8768, Test Accuracy: 65.82%\n",
      "Epoch [1771/2500], Train Loss: 0.7612, Train Accuracy: 66.57%, Test Loss: 0.7570, Test Accuracy: 70.89%\n",
      "Epoch [1772/2500], Train Loss: 0.7905, Train Accuracy: 64.72%, Test Loss: 0.8519, Test Accuracy: 65.82%\n",
      "Epoch [1773/2500], Train Loss: 0.7704, Train Accuracy: 66.86%, Test Loss: 0.7474, Test Accuracy: 72.15%\n",
      "Epoch [1774/2500], Train Loss: 0.7738, Train Accuracy: 67.00%, Test Loss: 0.7354, Test Accuracy: 63.29%\n",
      "Epoch [1775/2500], Train Loss: 0.7727, Train Accuracy: 67.43%, Test Loss: 0.7674, Test Accuracy: 69.62%\n",
      "Epoch [1776/2500], Train Loss: 0.7676, Train Accuracy: 67.28%, Test Loss: 0.8414, Test Accuracy: 64.56%\n",
      "Epoch [1777/2500], Train Loss: 0.7456, Train Accuracy: 69.27%, Test Loss: 0.7482, Test Accuracy: 68.35%\n",
      "Epoch [1778/2500], Train Loss: 0.7648, Train Accuracy: 65.15%, Test Loss: 0.8173, Test Accuracy: 65.82%\n",
      "Epoch [1779/2500], Train Loss: 0.7655, Train Accuracy: 68.14%, Test Loss: 0.7215, Test Accuracy: 62.03%\n",
      "Epoch [1780/2500], Train Loss: 0.7444, Train Accuracy: 67.00%, Test Loss: 0.7127, Test Accuracy: 69.62%\n",
      "Epoch [1781/2500], Train Loss: 0.7727, Train Accuracy: 66.57%, Test Loss: 0.7703, Test Accuracy: 72.15%\n",
      "Epoch [1782/2500], Train Loss: 0.7640, Train Accuracy: 67.85%, Test Loss: 0.7535, Test Accuracy: 73.42%\n",
      "Epoch [1783/2500], Train Loss: 0.7505, Train Accuracy: 68.28%, Test Loss: 0.7880, Test Accuracy: 69.62%\n",
      "Epoch [1784/2500], Train Loss: 0.7663, Train Accuracy: 65.86%, Test Loss: 0.7561, Test Accuracy: 69.62%\n",
      "Epoch [1785/2500], Train Loss: 0.7600, Train Accuracy: 66.43%, Test Loss: 0.7235, Test Accuracy: 73.42%\n",
      "Epoch [1786/2500], Train Loss: 0.7452, Train Accuracy: 68.99%, Test Loss: 0.7399, Test Accuracy: 73.42%\n",
      "Epoch [1787/2500], Train Loss: 0.7695, Train Accuracy: 65.72%, Test Loss: 0.7688, Test Accuracy: 62.03%\n",
      "Epoch [1788/2500], Train Loss: 0.7621, Train Accuracy: 66.71%, Test Loss: 0.7409, Test Accuracy: 64.56%\n",
      "Epoch [1789/2500], Train Loss: 0.7560, Train Accuracy: 66.15%, Test Loss: 0.7482, Test Accuracy: 72.15%\n",
      "Epoch [1790/2500], Train Loss: 0.7195, Train Accuracy: 69.27%, Test Loss: 0.7840, Test Accuracy: 68.35%\n",
      "Epoch [1791/2500], Train Loss: 0.7507, Train Accuracy: 68.28%, Test Loss: 0.8032, Test Accuracy: 67.09%\n",
      "Epoch [1792/2500], Train Loss: 0.7686, Train Accuracy: 65.58%, Test Loss: 0.7162, Test Accuracy: 68.35%\n",
      "Epoch [1793/2500], Train Loss: 0.7443, Train Accuracy: 68.71%, Test Loss: 0.7396, Test Accuracy: 74.68%\n",
      "Epoch [1794/2500], Train Loss: 0.7828, Train Accuracy: 66.57%, Test Loss: 0.7251, Test Accuracy: 67.09%\n",
      "Epoch [1795/2500], Train Loss: 0.7866, Train Accuracy: 66.00%, Test Loss: 0.7808, Test Accuracy: 70.89%\n",
      "Epoch [1796/2500], Train Loss: 0.7529, Train Accuracy: 68.56%, Test Loss: 0.7201, Test Accuracy: 67.09%\n",
      "Epoch [1797/2500], Train Loss: 0.7622, Train Accuracy: 66.15%, Test Loss: 0.8195, Test Accuracy: 67.09%\n",
      "Epoch [1798/2500], Train Loss: 0.7689, Train Accuracy: 67.14%, Test Loss: 0.7590, Test Accuracy: 70.89%\n",
      "Epoch [1799/2500], Train Loss: 0.7745, Train Accuracy: 65.29%, Test Loss: 0.7966, Test Accuracy: 68.35%\n",
      "Epoch [1800/2500], Train Loss: 0.7272, Train Accuracy: 68.42%, Test Loss: 0.8932, Test Accuracy: 63.29%\n",
      "Epoch [1801/2500], Train Loss: 0.7780, Train Accuracy: 65.01%, Test Loss: 0.7700, Test Accuracy: 70.89%\n",
      "Epoch [1802/2500], Train Loss: 0.7412, Train Accuracy: 67.28%, Test Loss: 0.7212, Test Accuracy: 70.89%\n",
      "Epoch [1803/2500], Train Loss: 0.7698, Train Accuracy: 66.29%, Test Loss: 0.7402, Test Accuracy: 67.09%\n",
      "Epoch [1804/2500], Train Loss: 0.7570, Train Accuracy: 67.71%, Test Loss: 0.7990, Test Accuracy: 70.89%\n",
      "Epoch [1805/2500], Train Loss: 0.7648, Train Accuracy: 66.86%, Test Loss: 0.7393, Test Accuracy: 70.89%\n",
      "Epoch [1806/2500], Train Loss: 0.7621, Train Accuracy: 66.29%, Test Loss: 0.7988, Test Accuracy: 69.62%\n",
      "Epoch [1807/2500], Train Loss: 0.7277, Train Accuracy: 68.14%, Test Loss: 0.8057, Test Accuracy: 69.62%\n",
      "Epoch [1808/2500], Train Loss: 0.7545, Train Accuracy: 68.56%, Test Loss: 0.7180, Test Accuracy: 68.35%\n",
      "Epoch [1809/2500], Train Loss: 0.7602, Train Accuracy: 67.14%, Test Loss: 0.7369, Test Accuracy: 70.89%\n",
      "Epoch [1810/2500], Train Loss: 0.7537, Train Accuracy: 69.13%, Test Loss: 0.8131, Test Accuracy: 67.09%\n",
      "Epoch [1811/2500], Train Loss: 0.7778, Train Accuracy: 66.15%, Test Loss: 0.7297, Test Accuracy: 75.95%\n",
      "Epoch [1812/2500], Train Loss: 0.7765, Train Accuracy: 67.00%, Test Loss: 0.7155, Test Accuracy: 74.68%\n",
      "Epoch [1813/2500], Train Loss: 0.8047, Train Accuracy: 67.43%, Test Loss: 0.7154, Test Accuracy: 67.09%\n",
      "Epoch [1814/2500], Train Loss: 0.7739, Train Accuracy: 65.58%, Test Loss: 0.7396, Test Accuracy: 73.42%\n",
      "Epoch [1815/2500], Train Loss: 0.7386, Train Accuracy: 66.86%, Test Loss: 0.7374, Test Accuracy: 67.09%\n",
      "Epoch [1816/2500], Train Loss: 0.7760, Train Accuracy: 65.86%, Test Loss: 0.7442, Test Accuracy: 63.29%\n",
      "Epoch [1817/2500], Train Loss: 0.7750, Train Accuracy: 65.29%, Test Loss: 0.8306, Test Accuracy: 68.35%\n",
      "Epoch [1818/2500], Train Loss: 0.7702, Train Accuracy: 68.42%, Test Loss: 0.8451, Test Accuracy: 65.82%\n",
      "Epoch [1819/2500], Train Loss: 0.7665, Train Accuracy: 68.14%, Test Loss: 0.7352, Test Accuracy: 69.62%\n",
      "Epoch [1820/2500], Train Loss: 0.7219, Train Accuracy: 67.99%, Test Loss: 0.7134, Test Accuracy: 73.42%\n",
      "Epoch [1821/2500], Train Loss: 0.7887, Train Accuracy: 68.56%, Test Loss: 0.7457, Test Accuracy: 72.15%\n",
      "Epoch [1822/2500], Train Loss: 0.7761, Train Accuracy: 65.29%, Test Loss: 0.7193, Test Accuracy: 70.89%\n",
      "Epoch [1823/2500], Train Loss: 0.7531, Train Accuracy: 67.14%, Test Loss: 0.7174, Test Accuracy: 64.56%\n",
      "Epoch [1824/2500], Train Loss: 0.7545, Train Accuracy: 66.86%, Test Loss: 0.7669, Test Accuracy: 70.89%\n",
      "Epoch [1825/2500], Train Loss: 0.7817, Train Accuracy: 65.29%, Test Loss: 0.8220, Test Accuracy: 65.82%\n",
      "Epoch [1826/2500], Train Loss: 0.7457, Train Accuracy: 67.85%, Test Loss: 0.7684, Test Accuracy: 69.62%\n",
      "Epoch [1827/2500], Train Loss: 0.7649, Train Accuracy: 65.29%, Test Loss: 0.7136, Test Accuracy: 68.35%\n",
      "Epoch [1828/2500], Train Loss: 0.7711, Train Accuracy: 67.43%, Test Loss: 0.7289, Test Accuracy: 65.82%\n",
      "Epoch [1829/2500], Train Loss: 0.7426, Train Accuracy: 67.85%, Test Loss: 0.7503, Test Accuracy: 73.42%\n",
      "Epoch [1830/2500], Train Loss: 0.7685, Train Accuracy: 67.99%, Test Loss: 0.7317, Test Accuracy: 74.68%\n",
      "Epoch [1831/2500], Train Loss: 0.7556, Train Accuracy: 67.71%, Test Loss: 0.7782, Test Accuracy: 72.15%\n",
      "Epoch [1832/2500], Train Loss: 0.7365, Train Accuracy: 67.57%, Test Loss: 0.8538, Test Accuracy: 65.82%\n",
      "Epoch [1833/2500], Train Loss: 0.7621, Train Accuracy: 65.43%, Test Loss: 0.7380, Test Accuracy: 62.03%\n",
      "Epoch [1834/2500], Train Loss: 0.7850, Train Accuracy: 66.43%, Test Loss: 0.7715, Test Accuracy: 73.42%\n",
      "Epoch [1835/2500], Train Loss: 0.7815, Train Accuracy: 66.15%, Test Loss: 0.7170, Test Accuracy: 65.82%\n",
      "Epoch [1836/2500], Train Loss: 0.7734, Train Accuracy: 67.43%, Test Loss: 0.7358, Test Accuracy: 72.15%\n",
      "Epoch [1837/2500], Train Loss: 0.7650, Train Accuracy: 65.43%, Test Loss: 0.8549, Test Accuracy: 65.82%\n",
      "Epoch [1838/2500], Train Loss: 0.7594, Train Accuracy: 65.86%, Test Loss: 0.8085, Test Accuracy: 69.62%\n",
      "Epoch [1839/2500], Train Loss: 0.7502, Train Accuracy: 67.57%, Test Loss: 0.8224, Test Accuracy: 68.35%\n",
      "Epoch [1840/2500], Train Loss: 0.7647, Train Accuracy: 66.71%, Test Loss: 0.9016, Test Accuracy: 63.29%\n",
      "Epoch [1841/2500], Train Loss: 0.7843, Train Accuracy: 67.43%, Test Loss: 0.7427, Test Accuracy: 65.82%\n",
      "Epoch [1842/2500], Train Loss: 0.7812, Train Accuracy: 65.43%, Test Loss: 0.7424, Test Accuracy: 72.15%\n",
      "Epoch [1843/2500], Train Loss: 0.7551, Train Accuracy: 67.00%, Test Loss: 0.7508, Test Accuracy: 72.15%\n",
      "Epoch [1844/2500], Train Loss: 0.7851, Train Accuracy: 64.44%, Test Loss: 0.7490, Test Accuracy: 70.89%\n",
      "Epoch [1845/2500], Train Loss: 0.7798, Train Accuracy: 64.01%, Test Loss: 0.7149, Test Accuracy: 73.42%\n",
      "Epoch [1846/2500], Train Loss: 0.7622, Train Accuracy: 66.86%, Test Loss: 0.7152, Test Accuracy: 67.09%\n",
      "Epoch [1847/2500], Train Loss: 0.7596, Train Accuracy: 66.00%, Test Loss: 0.7730, Test Accuracy: 68.35%\n",
      "Epoch [1848/2500], Train Loss: 0.7903, Train Accuracy: 65.72%, Test Loss: 0.7843, Test Accuracy: 72.15%\n",
      "Epoch [1849/2500], Train Loss: 0.7628, Train Accuracy: 68.85%, Test Loss: 0.7205, Test Accuracy: 69.62%\n",
      "Epoch [1850/2500], Train Loss: 0.7507, Train Accuracy: 67.14%, Test Loss: 0.7702, Test Accuracy: 72.15%\n",
      "Epoch [1851/2500], Train Loss: 0.7320, Train Accuracy: 67.57%, Test Loss: 0.7322, Test Accuracy: 72.15%\n",
      "Epoch [1852/2500], Train Loss: 0.7623, Train Accuracy: 66.29%, Test Loss: 0.7905, Test Accuracy: 68.35%\n",
      "Epoch [1853/2500], Train Loss: 0.7591, Train Accuracy: 65.58%, Test Loss: 0.8611, Test Accuracy: 64.56%\n",
      "Epoch [1854/2500], Train Loss: 0.7827, Train Accuracy: 63.73%, Test Loss: 0.7316, Test Accuracy: 68.35%\n",
      "Epoch [1855/2500], Train Loss: 0.7781, Train Accuracy: 65.72%, Test Loss: 0.7092, Test Accuracy: 69.62%\n",
      "Epoch [1856/2500], Train Loss: 0.7510, Train Accuracy: 67.85%, Test Loss: 0.8697, Test Accuracy: 63.29%\n",
      "Epoch [1857/2500], Train Loss: 0.7488, Train Accuracy: 68.14%, Test Loss: 0.7292, Test Accuracy: 72.15%\n",
      "Epoch [1858/2500], Train Loss: 0.7701, Train Accuracy: 67.43%, Test Loss: 0.8439, Test Accuracy: 64.56%\n",
      "Epoch [1859/2500], Train Loss: 0.7652, Train Accuracy: 66.57%, Test Loss: 0.7810, Test Accuracy: 68.35%\n",
      "Epoch [1860/2500], Train Loss: 0.7713, Train Accuracy: 66.71%, Test Loss: 0.8237, Test Accuracy: 67.09%\n",
      "Epoch [1861/2500], Train Loss: 0.7708, Train Accuracy: 65.72%, Test Loss: 0.7233, Test Accuracy: 69.62%\n",
      "Epoch [1862/2500], Train Loss: 0.7733, Train Accuracy: 66.00%, Test Loss: 0.7398, Test Accuracy: 67.09%\n",
      "Epoch [1863/2500], Train Loss: 0.7505, Train Accuracy: 68.14%, Test Loss: 0.7131, Test Accuracy: 70.89%\n",
      "Epoch [1864/2500], Train Loss: 0.7528, Train Accuracy: 68.42%, Test Loss: 0.8129, Test Accuracy: 72.15%\n",
      "Epoch [1865/2500], Train Loss: 0.7325, Train Accuracy: 67.99%, Test Loss: 0.7428, Test Accuracy: 68.35%\n",
      "Epoch [1866/2500], Train Loss: 0.7609, Train Accuracy: 66.86%, Test Loss: 0.7768, Test Accuracy: 69.62%\n",
      "Epoch [1867/2500], Train Loss: 0.7630, Train Accuracy: 65.15%, Test Loss: 0.8320, Test Accuracy: 68.35%\n",
      "Epoch [1868/2500], Train Loss: 0.7316, Train Accuracy: 67.57%, Test Loss: 0.7563, Test Accuracy: 67.09%\n",
      "Epoch [1869/2500], Train Loss: 0.7650, Train Accuracy: 66.29%, Test Loss: 0.8887, Test Accuracy: 63.29%\n",
      "Epoch [1870/2500], Train Loss: 0.7337, Train Accuracy: 68.56%, Test Loss: 0.7364, Test Accuracy: 64.56%\n",
      "Epoch [1871/2500], Train Loss: 0.7558, Train Accuracy: 67.14%, Test Loss: 0.7515, Test Accuracy: 67.09%\n",
      "Epoch [1872/2500], Train Loss: 0.7462, Train Accuracy: 67.28%, Test Loss: 0.7387, Test Accuracy: 73.42%\n",
      "Epoch [1873/2500], Train Loss: 0.7614, Train Accuracy: 67.28%, Test Loss: 0.7413, Test Accuracy: 73.42%\n",
      "Epoch [1874/2500], Train Loss: 0.7368, Train Accuracy: 66.71%, Test Loss: 0.8207, Test Accuracy: 65.82%\n",
      "Epoch [1875/2500], Train Loss: 0.7897, Train Accuracy: 66.43%, Test Loss: 0.7921, Test Accuracy: 65.82%\n",
      "Epoch [1876/2500], Train Loss: 0.7581, Train Accuracy: 67.28%, Test Loss: 0.8136, Test Accuracy: 69.62%\n",
      "Epoch [1877/2500], Train Loss: 0.7482, Train Accuracy: 68.71%, Test Loss: 0.8078, Test Accuracy: 65.82%\n",
      "Epoch [1878/2500], Train Loss: 0.7481, Train Accuracy: 68.56%, Test Loss: 0.7740, Test Accuracy: 70.89%\n",
      "Epoch [1879/2500], Train Loss: 0.7733, Train Accuracy: 66.57%, Test Loss: 0.7431, Test Accuracy: 64.56%\n",
      "Epoch [1880/2500], Train Loss: 0.7621, Train Accuracy: 69.84%, Test Loss: 0.7682, Test Accuracy: 70.89%\n",
      "Epoch [1881/2500], Train Loss: 0.7247, Train Accuracy: 66.86%, Test Loss: 0.7883, Test Accuracy: 68.35%\n",
      "Epoch [1882/2500], Train Loss: 0.7512, Train Accuracy: 66.86%, Test Loss: 0.7594, Test Accuracy: 72.15%\n",
      "Epoch [1883/2500], Train Loss: 0.7657, Train Accuracy: 67.85%, Test Loss: 0.7243, Test Accuracy: 67.09%\n",
      "Epoch [1884/2500], Train Loss: 0.7561, Train Accuracy: 67.00%, Test Loss: 0.7427, Test Accuracy: 70.89%\n",
      "Epoch [1885/2500], Train Loss: 0.7776, Train Accuracy: 66.71%, Test Loss: 0.7257, Test Accuracy: 65.82%\n",
      "Epoch [1886/2500], Train Loss: 0.7638, Train Accuracy: 66.00%, Test Loss: 0.7777, Test Accuracy: 68.35%\n",
      "Epoch [1887/2500], Train Loss: 0.7595, Train Accuracy: 66.00%, Test Loss: 0.7648, Test Accuracy: 74.68%\n",
      "Epoch [1888/2500], Train Loss: 0.7366, Train Accuracy: 69.42%, Test Loss: 0.7275, Test Accuracy: 67.09%\n",
      "Epoch [1889/2500], Train Loss: 0.7243, Train Accuracy: 69.56%, Test Loss: 0.7266, Test Accuracy: 73.42%\n",
      "Epoch [1890/2500], Train Loss: 0.7692, Train Accuracy: 64.44%, Test Loss: 0.7165, Test Accuracy: 67.09%\n",
      "Epoch [1891/2500], Train Loss: 0.7627, Train Accuracy: 67.43%, Test Loss: 0.7877, Test Accuracy: 69.62%\n",
      "Epoch [1892/2500], Train Loss: 0.7666, Train Accuracy: 66.57%, Test Loss: 0.8504, Test Accuracy: 68.35%\n",
      "Epoch [1893/2500], Train Loss: 0.7835, Train Accuracy: 67.57%, Test Loss: 0.7312, Test Accuracy: 74.68%\n",
      "Epoch [1894/2500], Train Loss: 0.7893, Train Accuracy: 65.29%, Test Loss: 0.8421, Test Accuracy: 63.29%\n",
      "Epoch [1895/2500], Train Loss: 0.7415, Train Accuracy: 68.14%, Test Loss: 0.7975, Test Accuracy: 68.35%\n",
      "Epoch [1896/2500], Train Loss: 0.7490, Train Accuracy: 69.56%, Test Loss: 0.7862, Test Accuracy: 69.62%\n",
      "Epoch [1897/2500], Train Loss: 0.7577, Train Accuracy: 67.43%, Test Loss: 0.7919, Test Accuracy: 69.62%\n",
      "Epoch [1898/2500], Train Loss: 0.7487, Train Accuracy: 67.57%, Test Loss: 0.8020, Test Accuracy: 68.35%\n",
      "Epoch [1899/2500], Train Loss: 0.7593, Train Accuracy: 66.00%, Test Loss: 0.9018, Test Accuracy: 64.56%\n",
      "Epoch [1900/2500], Train Loss: 0.7699, Train Accuracy: 67.14%, Test Loss: 0.8667, Test Accuracy: 64.56%\n",
      "Epoch [1901/2500], Train Loss: 0.7492, Train Accuracy: 67.43%, Test Loss: 0.7435, Test Accuracy: 65.82%\n",
      "Epoch [1902/2500], Train Loss: 0.7454, Train Accuracy: 67.28%, Test Loss: 0.7386, Test Accuracy: 67.09%\n",
      "Epoch [1903/2500], Train Loss: 0.7539, Train Accuracy: 67.57%, Test Loss: 0.8535, Test Accuracy: 63.29%\n",
      "Epoch [1904/2500], Train Loss: 0.7370, Train Accuracy: 67.85%, Test Loss: 0.7845, Test Accuracy: 70.89%\n",
      "Epoch [1905/2500], Train Loss: 0.7274, Train Accuracy: 68.56%, Test Loss: 0.8381, Test Accuracy: 64.56%\n",
      "Epoch [1906/2500], Train Loss: 0.7751, Train Accuracy: 67.14%, Test Loss: 0.7837, Test Accuracy: 74.68%\n",
      "Epoch [1907/2500], Train Loss: 0.7590, Train Accuracy: 67.71%, Test Loss: 0.7315, Test Accuracy: 69.62%\n",
      "Epoch [1908/2500], Train Loss: 0.7518, Train Accuracy: 65.72%, Test Loss: 0.7575, Test Accuracy: 72.15%\n",
      "Epoch [1909/2500], Train Loss: 0.7292, Train Accuracy: 69.42%, Test Loss: 0.9194, Test Accuracy: 62.03%\n",
      "Epoch [1910/2500], Train Loss: 0.7526, Train Accuracy: 67.00%, Test Loss: 0.7380, Test Accuracy: 73.42%\n",
      "Epoch [1911/2500], Train Loss: 0.7733, Train Accuracy: 67.85%, Test Loss: 0.9498, Test Accuracy: 65.82%\n",
      "Epoch [1912/2500], Train Loss: 0.7935, Train Accuracy: 66.15%, Test Loss: 0.7442, Test Accuracy: 70.89%\n",
      "Epoch [1913/2500], Train Loss: 0.7502, Train Accuracy: 67.00%, Test Loss: 1.0998, Test Accuracy: 55.70%\n",
      "Epoch [1914/2500], Train Loss: 0.7744, Train Accuracy: 66.15%, Test Loss: 0.8619, Test Accuracy: 65.82%\n",
      "Epoch [1915/2500], Train Loss: 0.7739, Train Accuracy: 66.43%, Test Loss: 0.8379, Test Accuracy: 65.82%\n",
      "Epoch [1916/2500], Train Loss: 0.7665, Train Accuracy: 65.58%, Test Loss: 0.7854, Test Accuracy: 67.09%\n",
      "Epoch [1917/2500], Train Loss: 0.7736, Train Accuracy: 66.15%, Test Loss: 0.7985, Test Accuracy: 69.62%\n",
      "Epoch [1918/2500], Train Loss: 0.7348, Train Accuracy: 67.99%, Test Loss: 0.8062, Test Accuracy: 65.82%\n",
      "Epoch [1919/2500], Train Loss: 0.7432, Train Accuracy: 67.28%, Test Loss: 0.7286, Test Accuracy: 63.29%\n",
      "Epoch [1920/2500], Train Loss: 0.7545, Train Accuracy: 66.71%, Test Loss: 0.7482, Test Accuracy: 70.89%\n",
      "Epoch [1921/2500], Train Loss: 0.7543, Train Accuracy: 67.57%, Test Loss: 0.7732, Test Accuracy: 69.62%\n",
      "Epoch [1922/2500], Train Loss: 0.7347, Train Accuracy: 67.57%, Test Loss: 0.7656, Test Accuracy: 70.89%\n",
      "Epoch [1923/2500], Train Loss: 0.7751, Train Accuracy: 67.43%, Test Loss: 0.8479, Test Accuracy: 68.35%\n",
      "Epoch [1924/2500], Train Loss: 0.7552, Train Accuracy: 67.43%, Test Loss: 0.7898, Test Accuracy: 70.89%\n",
      "Epoch [1925/2500], Train Loss: 0.7573, Train Accuracy: 67.57%, Test Loss: 0.7255, Test Accuracy: 68.35%\n",
      "Epoch [1926/2500], Train Loss: 0.7692, Train Accuracy: 66.29%, Test Loss: 0.7517, Test Accuracy: 72.15%\n",
      "Epoch [1927/2500], Train Loss: 0.7764, Train Accuracy: 66.71%, Test Loss: 0.7297, Test Accuracy: 68.35%\n",
      "Epoch [1928/2500], Train Loss: 0.7212, Train Accuracy: 68.85%, Test Loss: 0.7840, Test Accuracy: 70.89%\n",
      "Epoch [1929/2500], Train Loss: 0.7719, Train Accuracy: 67.00%, Test Loss: 0.7519, Test Accuracy: 73.42%\n",
      "Epoch [1930/2500], Train Loss: 0.7286, Train Accuracy: 68.42%, Test Loss: 0.8072, Test Accuracy: 69.62%\n",
      "Epoch [1931/2500], Train Loss: 0.7241, Train Accuracy: 68.56%, Test Loss: 0.7439, Test Accuracy: 72.15%\n",
      "Epoch [1932/2500], Train Loss: 0.7511, Train Accuracy: 67.14%, Test Loss: 0.8651, Test Accuracy: 63.29%\n",
      "Epoch [1933/2500], Train Loss: 0.7609, Train Accuracy: 66.00%, Test Loss: 0.7896, Test Accuracy: 69.62%\n",
      "Epoch [1934/2500], Train Loss: 0.7516, Train Accuracy: 65.86%, Test Loss: 0.7647, Test Accuracy: 72.15%\n",
      "Epoch [1935/2500], Train Loss: 0.7566, Train Accuracy: 67.57%, Test Loss: 0.8215, Test Accuracy: 70.89%\n",
      "Epoch [1936/2500], Train Loss: 0.7553, Train Accuracy: 68.42%, Test Loss: 0.9331, Test Accuracy: 64.56%\n",
      "Epoch [1937/2500], Train Loss: 0.7398, Train Accuracy: 68.71%, Test Loss: 0.7456, Test Accuracy: 72.15%\n",
      "Epoch [1938/2500], Train Loss: 0.7479, Train Accuracy: 68.71%, Test Loss: 0.7729, Test Accuracy: 67.09%\n",
      "Epoch [1939/2500], Train Loss: 0.7364, Train Accuracy: 68.28%, Test Loss: 0.7414, Test Accuracy: 69.62%\n",
      "Epoch [1940/2500], Train Loss: 0.7775, Train Accuracy: 67.28%, Test Loss: 0.7631, Test Accuracy: 72.15%\n",
      "Epoch [1941/2500], Train Loss: 0.7281, Train Accuracy: 67.28%, Test Loss: 0.7500, Test Accuracy: 72.15%\n",
      "Epoch [1942/2500], Train Loss: 0.7708, Train Accuracy: 66.71%, Test Loss: 0.7165, Test Accuracy: 68.35%\n",
      "Epoch [1943/2500], Train Loss: 0.7551, Train Accuracy: 68.14%, Test Loss: 0.8533, Test Accuracy: 68.35%\n",
      "Epoch [1944/2500], Train Loss: 0.7940, Train Accuracy: 65.15%, Test Loss: 0.7417, Test Accuracy: 70.89%\n",
      "Epoch [1945/2500], Train Loss: 0.7710, Train Accuracy: 64.72%, Test Loss: 0.7658, Test Accuracy: 72.15%\n",
      "Epoch [1946/2500], Train Loss: 0.7538, Train Accuracy: 67.28%, Test Loss: 0.7239, Test Accuracy: 68.35%\n",
      "Epoch [1947/2500], Train Loss: 0.7517, Train Accuracy: 66.00%, Test Loss: 0.7115, Test Accuracy: 64.56%\n",
      "Epoch [1948/2500], Train Loss: 0.7665, Train Accuracy: 68.56%, Test Loss: 0.7343, Test Accuracy: 70.89%\n",
      "Epoch [1949/2500], Train Loss: 0.7323, Train Accuracy: 67.71%, Test Loss: 0.7244, Test Accuracy: 70.89%\n",
      "Epoch [1950/2500], Train Loss: 0.7530, Train Accuracy: 67.71%, Test Loss: 0.7574, Test Accuracy: 69.62%\n",
      "Epoch [1951/2500], Train Loss: 0.7567, Train Accuracy: 66.57%, Test Loss: 0.7656, Test Accuracy: 70.89%\n",
      "Epoch [1952/2500], Train Loss: 0.7516, Train Accuracy: 67.85%, Test Loss: 0.8762, Test Accuracy: 63.29%\n",
      "Epoch [1953/2500], Train Loss: 0.7661, Train Accuracy: 67.85%, Test Loss: 0.8025, Test Accuracy: 70.89%\n",
      "Epoch [1954/2500], Train Loss: 0.7477, Train Accuracy: 68.56%, Test Loss: 0.7663, Test Accuracy: 73.42%\n",
      "Epoch [1955/2500], Train Loss: 0.7793, Train Accuracy: 66.43%, Test Loss: 0.8055, Test Accuracy: 65.82%\n",
      "Epoch [1956/2500], Train Loss: 0.7611, Train Accuracy: 67.43%, Test Loss: 0.7350, Test Accuracy: 72.15%\n",
      "Epoch [1957/2500], Train Loss: 0.7587, Train Accuracy: 66.29%, Test Loss: 0.7327, Test Accuracy: 68.35%\n",
      "Epoch [1958/2500], Train Loss: 0.7332, Train Accuracy: 68.99%, Test Loss: 0.8805, Test Accuracy: 63.29%\n",
      "Epoch [1959/2500], Train Loss: 0.7715, Train Accuracy: 66.57%, Test Loss: 0.7792, Test Accuracy: 70.89%\n",
      "Epoch [1960/2500], Train Loss: 0.7516, Train Accuracy: 67.43%, Test Loss: 0.7718, Test Accuracy: 69.62%\n",
      "Epoch [1961/2500], Train Loss: 0.7364, Train Accuracy: 68.99%, Test Loss: 0.7204, Test Accuracy: 65.82%\n",
      "Epoch [1962/2500], Train Loss: 0.7691, Train Accuracy: 68.14%, Test Loss: 0.8074, Test Accuracy: 64.56%\n",
      "Epoch [1963/2500], Train Loss: 0.7623, Train Accuracy: 66.29%, Test Loss: 0.8197, Test Accuracy: 69.62%\n",
      "Epoch [1964/2500], Train Loss: 0.7375, Train Accuracy: 67.99%, Test Loss: 0.7204, Test Accuracy: 68.35%\n",
      "Epoch [1965/2500], Train Loss: 0.7452, Train Accuracy: 68.28%, Test Loss: 0.7398, Test Accuracy: 68.35%\n",
      "Epoch [1966/2500], Train Loss: 0.7461, Train Accuracy: 67.71%, Test Loss: 0.7242, Test Accuracy: 70.89%\n",
      "Epoch [1967/2500], Train Loss: 0.7208, Train Accuracy: 68.14%, Test Loss: 0.8750, Test Accuracy: 65.82%\n",
      "Epoch [1968/2500], Train Loss: 0.7761, Train Accuracy: 66.00%, Test Loss: 0.8085, Test Accuracy: 68.35%\n",
      "Epoch [1969/2500], Train Loss: 0.7440, Train Accuracy: 68.42%, Test Loss: 0.7440, Test Accuracy: 68.35%\n",
      "Epoch [1970/2500], Train Loss: 0.7669, Train Accuracy: 67.71%, Test Loss: 0.8518, Test Accuracy: 64.56%\n",
      "Epoch [1971/2500], Train Loss: 0.8009, Train Accuracy: 64.15%, Test Loss: 0.8860, Test Accuracy: 67.09%\n",
      "Epoch [1972/2500], Train Loss: 0.7453, Train Accuracy: 67.28%, Test Loss: 0.7341, Test Accuracy: 72.15%\n",
      "Epoch [1973/2500], Train Loss: 0.7380, Train Accuracy: 66.86%, Test Loss: 0.7775, Test Accuracy: 70.89%\n",
      "Epoch [1974/2500], Train Loss: 0.7481, Train Accuracy: 67.99%, Test Loss: 0.7329, Test Accuracy: 69.62%\n",
      "Epoch [1975/2500], Train Loss: 0.7613, Train Accuracy: 68.71%, Test Loss: 0.7275, Test Accuracy: 67.09%\n",
      "Epoch [1976/2500], Train Loss: 0.7593, Train Accuracy: 65.15%, Test Loss: 0.8806, Test Accuracy: 64.56%\n",
      "Epoch [1977/2500], Train Loss: 0.7602, Train Accuracy: 67.28%, Test Loss: 0.8546, Test Accuracy: 62.03%\n",
      "Epoch [1978/2500], Train Loss: 0.7631, Train Accuracy: 67.57%, Test Loss: 0.7185, Test Accuracy: 69.62%\n",
      "Epoch [1979/2500], Train Loss: 0.7296, Train Accuracy: 68.71%, Test Loss: 0.8478, Test Accuracy: 63.29%\n",
      "Epoch [1980/2500], Train Loss: 0.7525, Train Accuracy: 67.14%, Test Loss: 0.7884, Test Accuracy: 67.09%\n",
      "Epoch [1981/2500], Train Loss: 0.7265, Train Accuracy: 66.15%, Test Loss: 0.7299, Test Accuracy: 72.15%\n",
      "Epoch [1982/2500], Train Loss: 0.7728, Train Accuracy: 67.85%, Test Loss: 0.7274, Test Accuracy: 70.89%\n",
      "Epoch [1983/2500], Train Loss: 0.7864, Train Accuracy: 66.86%, Test Loss: 0.8333, Test Accuracy: 67.09%\n",
      "Epoch [1984/2500], Train Loss: 0.7595, Train Accuracy: 67.57%, Test Loss: 0.7493, Test Accuracy: 65.82%\n",
      "Epoch [1985/2500], Train Loss: 0.7386, Train Accuracy: 67.99%, Test Loss: 0.7384, Test Accuracy: 73.42%\n",
      "Epoch [1986/2500], Train Loss: 0.7441, Train Accuracy: 67.71%, Test Loss: 0.7667, Test Accuracy: 67.09%\n",
      "Epoch [1987/2500], Train Loss: 0.7452, Train Accuracy: 66.57%, Test Loss: 0.7256, Test Accuracy: 63.29%\n",
      "Epoch [1988/2500], Train Loss: 0.7724, Train Accuracy: 66.86%, Test Loss: 0.8805, Test Accuracy: 67.09%\n",
      "Epoch [1989/2500], Train Loss: 0.7474, Train Accuracy: 67.57%, Test Loss: 0.7938, Test Accuracy: 65.82%\n",
      "Epoch [1990/2500], Train Loss: 0.7719, Train Accuracy: 66.29%, Test Loss: 0.8160, Test Accuracy: 64.56%\n",
      "Epoch [1991/2500], Train Loss: 0.7668, Train Accuracy: 65.01%, Test Loss: 0.7518, Test Accuracy: 75.95%\n",
      "Epoch [1992/2500], Train Loss: 0.7633, Train Accuracy: 67.99%, Test Loss: 0.7410, Test Accuracy: 68.35%\n",
      "Epoch [1993/2500], Train Loss: 0.7641, Train Accuracy: 65.72%, Test Loss: 0.7717, Test Accuracy: 69.62%\n",
      "Epoch [1994/2500], Train Loss: 0.7558, Train Accuracy: 66.43%, Test Loss: 0.7673, Test Accuracy: 70.89%\n",
      "Epoch [1995/2500], Train Loss: 0.7480, Train Accuracy: 69.42%, Test Loss: 0.8460, Test Accuracy: 67.09%\n",
      "Epoch [1996/2500], Train Loss: 0.7548, Train Accuracy: 67.57%, Test Loss: 0.7459, Test Accuracy: 73.42%\n",
      "Epoch [1997/2500], Train Loss: 0.7645, Train Accuracy: 66.86%, Test Loss: 0.7214, Test Accuracy: 68.35%\n",
      "Epoch [1998/2500], Train Loss: 0.7538, Train Accuracy: 67.57%, Test Loss: 0.7470, Test Accuracy: 73.42%\n",
      "Epoch [1999/2500], Train Loss: 0.7758, Train Accuracy: 65.86%, Test Loss: 0.7482, Test Accuracy: 74.68%\n",
      "Epoch [2000/2500], Train Loss: 0.7551, Train Accuracy: 68.85%, Test Loss: 0.7390, Test Accuracy: 73.42%\n",
      "Epoch [2001/2500], Train Loss: 0.7702, Train Accuracy: 67.71%, Test Loss: 0.8027, Test Accuracy: 69.62%\n",
      "Epoch [2002/2500], Train Loss: 0.7625, Train Accuracy: 65.86%, Test Loss: 0.7369, Test Accuracy: 73.42%\n",
      "Epoch [2003/2500], Train Loss: 0.7847, Train Accuracy: 66.15%, Test Loss: 0.7419, Test Accuracy: 72.15%\n",
      "Epoch [2004/2500], Train Loss: 0.7546, Train Accuracy: 66.29%, Test Loss: 0.8753, Test Accuracy: 63.29%\n",
      "Epoch [2005/2500], Train Loss: 0.7379, Train Accuracy: 66.86%, Test Loss: 0.7446, Test Accuracy: 67.09%\n",
      "Epoch [2006/2500], Train Loss: 0.7672, Train Accuracy: 67.14%, Test Loss: 0.7398, Test Accuracy: 72.15%\n",
      "Epoch [2007/2500], Train Loss: 0.7122, Train Accuracy: 69.70%, Test Loss: 0.7325, Test Accuracy: 70.89%\n",
      "Epoch [2008/2500], Train Loss: 0.7513, Train Accuracy: 67.99%, Test Loss: 0.8436, Test Accuracy: 64.56%\n",
      "Epoch [2009/2500], Train Loss: 0.7831, Train Accuracy: 65.58%, Test Loss: 0.7502, Test Accuracy: 73.42%\n",
      "Epoch [2010/2500], Train Loss: 0.7713, Train Accuracy: 66.71%, Test Loss: 0.8009, Test Accuracy: 70.89%\n",
      "Epoch [2011/2500], Train Loss: 0.7625, Train Accuracy: 64.30%, Test Loss: 0.7631, Test Accuracy: 68.35%\n",
      "Epoch [2012/2500], Train Loss: 0.7370, Train Accuracy: 68.14%, Test Loss: 0.8639, Test Accuracy: 64.56%\n",
      "Epoch [2013/2500], Train Loss: 0.7419, Train Accuracy: 69.70%, Test Loss: 0.7344, Test Accuracy: 67.09%\n",
      "Epoch [2014/2500], Train Loss: 0.7687, Train Accuracy: 65.72%, Test Loss: 0.7420, Test Accuracy: 67.09%\n",
      "Epoch [2015/2500], Train Loss: 0.7659, Train Accuracy: 67.71%, Test Loss: 0.7642, Test Accuracy: 69.62%\n",
      "Epoch [2016/2500], Train Loss: 0.7577, Train Accuracy: 68.14%, Test Loss: 0.8405, Test Accuracy: 65.82%\n",
      "Epoch [2017/2500], Train Loss: 0.7610, Train Accuracy: 67.99%, Test Loss: 0.7354, Test Accuracy: 68.35%\n",
      "Epoch [2018/2500], Train Loss: 0.7490, Train Accuracy: 68.99%, Test Loss: 0.7432, Test Accuracy: 67.09%\n",
      "Epoch [2019/2500], Train Loss: 0.7759, Train Accuracy: 67.57%, Test Loss: 0.8011, Test Accuracy: 68.35%\n",
      "Epoch [2020/2500], Train Loss: 0.7498, Train Accuracy: 67.71%, Test Loss: 0.7571, Test Accuracy: 69.62%\n",
      "Epoch [2021/2500], Train Loss: 0.7548, Train Accuracy: 67.43%, Test Loss: 0.8510, Test Accuracy: 63.29%\n",
      "Epoch [2022/2500], Train Loss: 0.7910, Train Accuracy: 65.86%, Test Loss: 0.8347, Test Accuracy: 65.82%\n",
      "Epoch [2023/2500], Train Loss: 0.7621, Train Accuracy: 67.14%, Test Loss: 0.7493, Test Accuracy: 70.89%\n",
      "Epoch [2024/2500], Train Loss: 0.7795, Train Accuracy: 67.99%, Test Loss: 0.7712, Test Accuracy: 70.89%\n",
      "Epoch [2025/2500], Train Loss: 0.7544, Train Accuracy: 68.42%, Test Loss: 0.8270, Test Accuracy: 63.29%\n",
      "Epoch [2026/2500], Train Loss: 0.7775, Train Accuracy: 65.43%, Test Loss: 0.7346, Test Accuracy: 69.62%\n",
      "Epoch [2027/2500], Train Loss: 0.7677, Train Accuracy: 66.29%, Test Loss: 0.7502, Test Accuracy: 70.89%\n",
      "Epoch [2028/2500], Train Loss: 0.7583, Train Accuracy: 66.15%, Test Loss: 0.7556, Test Accuracy: 72.15%\n",
      "Epoch [2029/2500], Train Loss: 0.7667, Train Accuracy: 68.14%, Test Loss: 0.8145, Test Accuracy: 63.29%\n",
      "Epoch [2030/2500], Train Loss: 0.7813, Train Accuracy: 65.58%, Test Loss: 0.7733, Test Accuracy: 70.89%\n",
      "Epoch [2031/2500], Train Loss: 0.7520, Train Accuracy: 66.86%, Test Loss: 0.7610, Test Accuracy: 69.62%\n",
      "Epoch [2032/2500], Train Loss: 0.7526, Train Accuracy: 67.99%, Test Loss: 0.7332, Test Accuracy: 73.42%\n",
      "Epoch [2033/2500], Train Loss: 0.7443, Train Accuracy: 67.00%, Test Loss: 0.7342, Test Accuracy: 68.35%\n",
      "Epoch [2034/2500], Train Loss: 0.7608, Train Accuracy: 66.71%, Test Loss: 0.7207, Test Accuracy: 67.09%\n",
      "Epoch [2035/2500], Train Loss: 0.7481, Train Accuracy: 68.71%, Test Loss: 0.7486, Test Accuracy: 67.09%\n",
      "Epoch [2036/2500], Train Loss: 0.7639, Train Accuracy: 67.57%, Test Loss: 0.7520, Test Accuracy: 73.42%\n",
      "Epoch [2037/2500], Train Loss: 0.7585, Train Accuracy: 65.72%, Test Loss: 0.7376, Test Accuracy: 72.15%\n",
      "Epoch [2038/2500], Train Loss: 0.7623, Train Accuracy: 66.86%, Test Loss: 0.7287, Test Accuracy: 65.82%\n",
      "Epoch [2039/2500], Train Loss: 0.7646, Train Accuracy: 66.57%, Test Loss: 0.8067, Test Accuracy: 68.35%\n",
      "Epoch [2040/2500], Train Loss: 0.7334, Train Accuracy: 67.85%, Test Loss: 0.7382, Test Accuracy: 73.42%\n",
      "Epoch [2041/2500], Train Loss: 0.7423, Train Accuracy: 68.28%, Test Loss: 0.8798, Test Accuracy: 62.03%\n",
      "Epoch [2042/2500], Train Loss: 0.7432, Train Accuracy: 69.84%, Test Loss: 0.7364, Test Accuracy: 69.62%\n",
      "Epoch [2043/2500], Train Loss: 0.7621, Train Accuracy: 65.29%, Test Loss: 0.7327, Test Accuracy: 70.89%\n",
      "Epoch [2044/2500], Train Loss: 0.7299, Train Accuracy: 68.42%, Test Loss: 0.7870, Test Accuracy: 70.89%\n",
      "Epoch [2045/2500], Train Loss: 0.7544, Train Accuracy: 66.15%, Test Loss: 0.7986, Test Accuracy: 67.09%\n",
      "Epoch [2046/2500], Train Loss: 0.7492, Train Accuracy: 65.86%, Test Loss: 0.7334, Test Accuracy: 73.42%\n",
      "Epoch [2047/2500], Train Loss: 0.7462, Train Accuracy: 67.85%, Test Loss: 0.7501, Test Accuracy: 70.89%\n",
      "Epoch [2048/2500], Train Loss: 0.7743, Train Accuracy: 66.15%, Test Loss: 0.7416, Test Accuracy: 69.62%\n",
      "Epoch [2049/2500], Train Loss: 0.7472, Train Accuracy: 67.85%, Test Loss: 0.9037, Test Accuracy: 62.03%\n",
      "Epoch [2050/2500], Train Loss: 0.7674, Train Accuracy: 67.43%, Test Loss: 0.8350, Test Accuracy: 64.56%\n",
      "Epoch [2051/2500], Train Loss: 0.7408, Train Accuracy: 69.42%, Test Loss: 0.7208, Test Accuracy: 68.35%\n",
      "Epoch [2052/2500], Train Loss: 0.7831, Train Accuracy: 65.43%, Test Loss: 0.8170, Test Accuracy: 69.62%\n",
      "Epoch [2053/2500], Train Loss: 0.7599, Train Accuracy: 66.43%, Test Loss: 0.7408, Test Accuracy: 69.62%\n",
      "Epoch [2054/2500], Train Loss: 0.7859, Train Accuracy: 67.43%, Test Loss: 0.7292, Test Accuracy: 70.89%\n",
      "Epoch [2055/2500], Train Loss: 0.7664, Train Accuracy: 66.57%, Test Loss: 0.7333, Test Accuracy: 73.42%\n",
      "Epoch [2056/2500], Train Loss: 0.7675, Train Accuracy: 67.71%, Test Loss: 0.7376, Test Accuracy: 63.29%\n",
      "Epoch [2057/2500], Train Loss: 0.7500, Train Accuracy: 68.42%, Test Loss: 0.7462, Test Accuracy: 72.15%\n",
      "Epoch [2058/2500], Train Loss: 0.7307, Train Accuracy: 69.84%, Test Loss: 0.9950, Test Accuracy: 59.49%\n",
      "Epoch [2059/2500], Train Loss: 0.7615, Train Accuracy: 67.14%, Test Loss: 0.7741, Test Accuracy: 68.35%\n",
      "Epoch [2060/2500], Train Loss: 0.7429, Train Accuracy: 68.28%, Test Loss: 0.9023, Test Accuracy: 65.82%\n",
      "Epoch [2061/2500], Train Loss: 0.7476, Train Accuracy: 67.00%, Test Loss: 0.8204, Test Accuracy: 67.09%\n",
      "Epoch [2062/2500], Train Loss: 0.7676, Train Accuracy: 67.00%, Test Loss: 0.7333, Test Accuracy: 69.62%\n",
      "Epoch [2063/2500], Train Loss: 0.7478, Train Accuracy: 67.99%, Test Loss: 0.7343, Test Accuracy: 67.09%\n",
      "Epoch [2064/2500], Train Loss: 0.7451, Train Accuracy: 68.42%, Test Loss: 0.8053, Test Accuracy: 72.15%\n",
      "Epoch [2065/2500], Train Loss: 0.7733, Train Accuracy: 67.14%, Test Loss: 0.7628, Test Accuracy: 70.89%\n",
      "Epoch [2066/2500], Train Loss: 0.7531, Train Accuracy: 65.86%, Test Loss: 0.8002, Test Accuracy: 70.89%\n",
      "Epoch [2067/2500], Train Loss: 0.7691, Train Accuracy: 66.71%, Test Loss: 0.7471, Test Accuracy: 68.35%\n",
      "Epoch [2068/2500], Train Loss: 0.7505, Train Accuracy: 67.43%, Test Loss: 0.7895, Test Accuracy: 70.89%\n",
      "Epoch [2069/2500], Train Loss: 0.7496, Train Accuracy: 66.57%, Test Loss: 0.7941, Test Accuracy: 69.62%\n",
      "Epoch [2070/2500], Train Loss: 0.7560, Train Accuracy: 67.85%, Test Loss: 0.7549, Test Accuracy: 67.09%\n",
      "Epoch [2071/2500], Train Loss: 0.7567, Train Accuracy: 67.99%, Test Loss: 0.7974, Test Accuracy: 68.35%\n",
      "Epoch [2072/2500], Train Loss: 0.7478, Train Accuracy: 67.43%, Test Loss: 0.7356, Test Accuracy: 65.82%\n",
      "Epoch [2073/2500], Train Loss: 0.7736, Train Accuracy: 67.28%, Test Loss: 0.7934, Test Accuracy: 68.35%\n",
      "Epoch [2074/2500], Train Loss: 0.7642, Train Accuracy: 67.28%, Test Loss: 0.8303, Test Accuracy: 68.35%\n",
      "Epoch [2075/2500], Train Loss: 0.7546, Train Accuracy: 65.15%, Test Loss: 0.8162, Test Accuracy: 63.29%\n",
      "Epoch [2076/2500], Train Loss: 0.7684, Train Accuracy: 67.99%, Test Loss: 0.7404, Test Accuracy: 69.62%\n",
      "Epoch [2077/2500], Train Loss: 0.7479, Train Accuracy: 67.57%, Test Loss: 0.7455, Test Accuracy: 67.09%\n",
      "Epoch [2078/2500], Train Loss: 0.7271, Train Accuracy: 68.99%, Test Loss: 0.7538, Test Accuracy: 73.42%\n",
      "Epoch [2079/2500], Train Loss: 0.7476, Train Accuracy: 68.42%, Test Loss: 0.8590, Test Accuracy: 65.82%\n",
      "Epoch [2080/2500], Train Loss: 0.7478, Train Accuracy: 68.71%, Test Loss: 0.8051, Test Accuracy: 70.89%\n",
      "Epoch [2081/2500], Train Loss: 0.7450, Train Accuracy: 67.28%, Test Loss: 0.8246, Test Accuracy: 67.09%\n",
      "Epoch [2082/2500], Train Loss: 0.7628, Train Accuracy: 67.00%, Test Loss: 0.8290, Test Accuracy: 69.62%\n",
      "Epoch [2083/2500], Train Loss: 0.7430, Train Accuracy: 67.85%, Test Loss: 0.7154, Test Accuracy: 69.62%\n",
      "Epoch [2084/2500], Train Loss: 0.7588, Train Accuracy: 67.71%, Test Loss: 0.8305, Test Accuracy: 64.56%\n",
      "Epoch [2085/2500], Train Loss: 0.7611, Train Accuracy: 64.86%, Test Loss: 0.7315, Test Accuracy: 70.89%\n",
      "Epoch [2086/2500], Train Loss: 0.7655, Train Accuracy: 67.00%, Test Loss: 0.8571, Test Accuracy: 65.82%\n",
      "Epoch [2087/2500], Train Loss: 0.7615, Train Accuracy: 66.00%, Test Loss: 0.8088, Test Accuracy: 70.89%\n",
      "Epoch [2088/2500], Train Loss: 0.7621, Train Accuracy: 66.57%, Test Loss: 0.7223, Test Accuracy: 65.82%\n",
      "Epoch [2089/2500], Train Loss: 0.7534, Train Accuracy: 67.85%, Test Loss: 0.7340, Test Accuracy: 73.42%\n",
      "Epoch [2090/2500], Train Loss: 0.7603, Train Accuracy: 66.57%, Test Loss: 0.7861, Test Accuracy: 70.89%\n",
      "Epoch [2091/2500], Train Loss: 0.7339, Train Accuracy: 67.85%, Test Loss: 0.7698, Test Accuracy: 67.09%\n",
      "Epoch [2092/2500], Train Loss: 0.7535, Train Accuracy: 67.57%, Test Loss: 0.7995, Test Accuracy: 65.82%\n",
      "Epoch [2093/2500], Train Loss: 0.7548, Train Accuracy: 67.14%, Test Loss: 0.8513, Test Accuracy: 69.62%\n",
      "Epoch [2094/2500], Train Loss: 0.7272, Train Accuracy: 67.71%, Test Loss: 0.7620, Test Accuracy: 72.15%\n",
      "Epoch [2095/2500], Train Loss: 0.7543, Train Accuracy: 68.14%, Test Loss: 0.7224, Test Accuracy: 68.35%\n",
      "Epoch [2096/2500], Train Loss: 0.7522, Train Accuracy: 67.99%, Test Loss: 0.8278, Test Accuracy: 67.09%\n",
      "Epoch [2097/2500], Train Loss: 0.7472, Train Accuracy: 66.43%, Test Loss: 0.8257, Test Accuracy: 65.82%\n",
      "Epoch [2098/2500], Train Loss: 0.7535, Train Accuracy: 66.71%, Test Loss: 0.7418, Test Accuracy: 67.09%\n",
      "Epoch [2099/2500], Train Loss: 0.7416, Train Accuracy: 66.71%, Test Loss: 0.8299, Test Accuracy: 65.82%\n",
      "Epoch [2100/2500], Train Loss: 0.7479, Train Accuracy: 65.86%, Test Loss: 0.7197, Test Accuracy: 65.82%\n",
      "Epoch [2101/2500], Train Loss: 0.7311, Train Accuracy: 66.00%, Test Loss: 0.7325, Test Accuracy: 74.68%\n",
      "Epoch [2102/2500], Train Loss: 0.7669, Train Accuracy: 67.71%, Test Loss: 0.8227, Test Accuracy: 68.35%\n",
      "Epoch [2103/2500], Train Loss: 0.7296, Train Accuracy: 67.99%, Test Loss: 0.7695, Test Accuracy: 72.15%\n",
      "Epoch [2104/2500], Train Loss: 0.7766, Train Accuracy: 67.00%, Test Loss: 0.7610, Test Accuracy: 73.42%\n",
      "Epoch [2105/2500], Train Loss: 0.7572, Train Accuracy: 66.15%, Test Loss: 0.9365, Test Accuracy: 63.29%\n",
      "Epoch [2106/2500], Train Loss: 0.7715, Train Accuracy: 67.85%, Test Loss: 0.7068, Test Accuracy: 68.35%\n",
      "Epoch [2107/2500], Train Loss: 0.7577, Train Accuracy: 67.28%, Test Loss: 0.8401, Test Accuracy: 68.35%\n",
      "Epoch [2108/2500], Train Loss: 0.7401, Train Accuracy: 67.14%, Test Loss: 0.7405, Test Accuracy: 68.35%\n",
      "Epoch [2109/2500], Train Loss: 0.7371, Train Accuracy: 65.29%, Test Loss: 0.7464, Test Accuracy: 73.42%\n",
      "Epoch [2110/2500], Train Loss: 0.7317, Train Accuracy: 67.85%, Test Loss: 0.7386, Test Accuracy: 72.15%\n",
      "Epoch [2111/2500], Train Loss: 0.7558, Train Accuracy: 65.15%, Test Loss: 0.8106, Test Accuracy: 70.89%\n",
      "Epoch [2112/2500], Train Loss: 0.7666, Train Accuracy: 65.43%, Test Loss: 0.7497, Test Accuracy: 69.62%\n",
      "Epoch [2113/2500], Train Loss: 0.7363, Train Accuracy: 69.13%, Test Loss: 0.7689, Test Accuracy: 72.15%\n",
      "Epoch [2114/2500], Train Loss: 0.7535, Train Accuracy: 66.71%, Test Loss: 0.8481, Test Accuracy: 65.82%\n",
      "Epoch [2115/2500], Train Loss: 0.7667, Train Accuracy: 66.86%, Test Loss: 0.7471, Test Accuracy: 70.89%\n",
      "Epoch [2116/2500], Train Loss: 0.7350, Train Accuracy: 67.85%, Test Loss: 0.7412, Test Accuracy: 72.15%\n",
      "Epoch [2117/2500], Train Loss: 0.7613, Train Accuracy: 65.72%, Test Loss: 0.7773, Test Accuracy: 68.35%\n",
      "Epoch [2118/2500], Train Loss: 0.7515, Train Accuracy: 65.58%, Test Loss: 0.7309, Test Accuracy: 72.15%\n",
      "Epoch [2119/2500], Train Loss: 0.7503, Train Accuracy: 67.99%, Test Loss: 0.7537, Test Accuracy: 72.15%\n",
      "Epoch [2120/2500], Train Loss: 0.7573, Train Accuracy: 67.71%, Test Loss: 0.7635, Test Accuracy: 70.89%\n",
      "Epoch [2121/2500], Train Loss: 0.7659, Train Accuracy: 64.01%, Test Loss: 0.7812, Test Accuracy: 68.35%\n",
      "Epoch [2122/2500], Train Loss: 0.7667, Train Accuracy: 67.85%, Test Loss: 0.7361, Test Accuracy: 72.15%\n",
      "Epoch [2123/2500], Train Loss: 0.7511, Train Accuracy: 67.00%, Test Loss: 0.7985, Test Accuracy: 65.82%\n",
      "Epoch [2124/2500], Train Loss: 0.7511, Train Accuracy: 66.71%, Test Loss: 0.7214, Test Accuracy: 63.29%\n",
      "Epoch [2125/2500], Train Loss: 0.7490, Train Accuracy: 66.86%, Test Loss: 0.8994, Test Accuracy: 65.82%\n",
      "Epoch [2126/2500], Train Loss: 0.7385, Train Accuracy: 66.15%, Test Loss: 0.7894, Test Accuracy: 67.09%\n",
      "Epoch [2127/2500], Train Loss: 0.7652, Train Accuracy: 67.71%, Test Loss: 0.7373, Test Accuracy: 73.42%\n",
      "Epoch [2128/2500], Train Loss: 0.7933, Train Accuracy: 64.58%, Test Loss: 0.7732, Test Accuracy: 70.89%\n",
      "Epoch [2129/2500], Train Loss: 0.7459, Train Accuracy: 70.84%, Test Loss: 0.7391, Test Accuracy: 74.68%\n",
      "Epoch [2130/2500], Train Loss: 0.7461, Train Accuracy: 66.86%, Test Loss: 0.7226, Test Accuracy: 69.62%\n",
      "Epoch [2131/2500], Train Loss: 0.7339, Train Accuracy: 66.71%, Test Loss: 0.8056, Test Accuracy: 69.62%\n",
      "Epoch [2132/2500], Train Loss: 0.7549, Train Accuracy: 68.28%, Test Loss: 0.7604, Test Accuracy: 73.42%\n",
      "Epoch [2133/2500], Train Loss: 0.7554, Train Accuracy: 66.57%, Test Loss: 0.7765, Test Accuracy: 73.42%\n",
      "Epoch [2134/2500], Train Loss: 0.7374, Train Accuracy: 67.85%, Test Loss: 0.7390, Test Accuracy: 73.42%\n",
      "Epoch [2135/2500], Train Loss: 0.7449, Train Accuracy: 68.28%, Test Loss: 0.7709, Test Accuracy: 70.89%\n",
      "Epoch [2136/2500], Train Loss: 0.7665, Train Accuracy: 67.28%, Test Loss: 0.7244, Test Accuracy: 64.56%\n",
      "Epoch [2137/2500], Train Loss: 0.7507, Train Accuracy: 67.57%, Test Loss: 0.7268, Test Accuracy: 74.68%\n",
      "Epoch [2138/2500], Train Loss: 0.7591, Train Accuracy: 67.85%, Test Loss: 0.8163, Test Accuracy: 69.62%\n",
      "Epoch [2139/2500], Train Loss: 0.7469, Train Accuracy: 69.42%, Test Loss: 0.8180, Test Accuracy: 67.09%\n",
      "Epoch [2140/2500], Train Loss: 0.7456, Train Accuracy: 67.57%, Test Loss: 0.7200, Test Accuracy: 69.62%\n",
      "Epoch [2141/2500], Train Loss: 0.7609, Train Accuracy: 67.28%, Test Loss: 0.7363, Test Accuracy: 69.62%\n",
      "Epoch [2142/2500], Train Loss: 0.7636, Train Accuracy: 68.42%, Test Loss: 0.8340, Test Accuracy: 67.09%\n",
      "Epoch [2143/2500], Train Loss: 0.7602, Train Accuracy: 67.28%, Test Loss: 0.8648, Test Accuracy: 62.03%\n",
      "Epoch [2144/2500], Train Loss: 0.7622, Train Accuracy: 67.00%, Test Loss: 0.8777, Test Accuracy: 67.09%\n",
      "Epoch [2145/2500], Train Loss: 0.7593, Train Accuracy: 68.71%, Test Loss: 0.7966, Test Accuracy: 68.35%\n",
      "Epoch [2146/2500], Train Loss: 0.7309, Train Accuracy: 69.13%, Test Loss: 0.8663, Test Accuracy: 62.03%\n",
      "Epoch [2147/2500], Train Loss: 0.7531, Train Accuracy: 66.43%, Test Loss: 0.7085, Test Accuracy: 68.35%\n",
      "Epoch [2148/2500], Train Loss: 0.7607, Train Accuracy: 67.14%, Test Loss: 0.7291, Test Accuracy: 73.42%\n",
      "Epoch [2149/2500], Train Loss: 0.7539, Train Accuracy: 67.99%, Test Loss: 0.7931, Test Accuracy: 69.62%\n",
      "Epoch [2150/2500], Train Loss: 0.7344, Train Accuracy: 67.00%, Test Loss: 0.7155, Test Accuracy: 67.09%\n",
      "Epoch [2151/2500], Train Loss: 0.7453, Train Accuracy: 67.28%, Test Loss: 0.7970, Test Accuracy: 70.89%\n",
      "Epoch [2152/2500], Train Loss: 0.7315, Train Accuracy: 67.28%, Test Loss: 0.7715, Test Accuracy: 70.89%\n",
      "Epoch [2153/2500], Train Loss: 0.7284, Train Accuracy: 67.28%, Test Loss: 0.9167, Test Accuracy: 63.29%\n",
      "Epoch [2154/2500], Train Loss: 0.7649, Train Accuracy: 65.15%, Test Loss: 0.7144, Test Accuracy: 67.09%\n",
      "Epoch [2155/2500], Train Loss: 0.7500, Train Accuracy: 69.42%, Test Loss: 0.7484, Test Accuracy: 68.35%\n",
      "Epoch [2156/2500], Train Loss: 0.7481, Train Accuracy: 67.00%, Test Loss: 0.7879, Test Accuracy: 70.89%\n",
      "Epoch [2157/2500], Train Loss: 0.7499, Train Accuracy: 66.71%, Test Loss: 0.7455, Test Accuracy: 74.68%\n",
      "Epoch [2158/2500], Train Loss: 0.7432, Train Accuracy: 67.00%, Test Loss: 0.7444, Test Accuracy: 68.35%\n",
      "Epoch [2159/2500], Train Loss: 0.7352, Train Accuracy: 67.85%, Test Loss: 0.7546, Test Accuracy: 69.62%\n",
      "Epoch [2160/2500], Train Loss: 0.7527, Train Accuracy: 66.71%, Test Loss: 0.7400, Test Accuracy: 70.89%\n",
      "Epoch [2161/2500], Train Loss: 0.7558, Train Accuracy: 67.00%, Test Loss: 0.7738, Test Accuracy: 68.35%\n",
      "Epoch [2162/2500], Train Loss: 0.7661, Train Accuracy: 66.29%, Test Loss: 0.9966, Test Accuracy: 59.49%\n",
      "Epoch [2163/2500], Train Loss: 0.7625, Train Accuracy: 66.29%, Test Loss: 0.7099, Test Accuracy: 67.09%\n",
      "Epoch [2164/2500], Train Loss: 0.7398, Train Accuracy: 69.27%, Test Loss: 0.7909, Test Accuracy: 67.09%\n",
      "Epoch [2165/2500], Train Loss: 0.7673, Train Accuracy: 65.58%, Test Loss: 0.7585, Test Accuracy: 73.42%\n",
      "Epoch [2166/2500], Train Loss: 0.7657, Train Accuracy: 67.28%, Test Loss: 0.8536, Test Accuracy: 64.56%\n",
      "Epoch [2167/2500], Train Loss: 0.7482, Train Accuracy: 67.71%, Test Loss: 0.6998, Test Accuracy: 67.09%\n",
      "Epoch [2168/2500], Train Loss: 0.7587, Train Accuracy: 67.71%, Test Loss: 0.7137, Test Accuracy: 68.35%\n",
      "Epoch [2169/2500], Train Loss: 0.7258, Train Accuracy: 68.99%, Test Loss: 0.8532, Test Accuracy: 63.29%\n",
      "Epoch [2170/2500], Train Loss: 0.7560, Train Accuracy: 66.29%, Test Loss: 0.8640, Test Accuracy: 68.35%\n",
      "Epoch [2171/2500], Train Loss: 0.7362, Train Accuracy: 66.86%, Test Loss: 0.7369, Test Accuracy: 68.35%\n",
      "Epoch [2172/2500], Train Loss: 0.7236, Train Accuracy: 70.13%, Test Loss: 0.7639, Test Accuracy: 73.42%\n",
      "Epoch [2173/2500], Train Loss: 0.7832, Train Accuracy: 67.71%, Test Loss: 0.7330, Test Accuracy: 72.15%\n",
      "Epoch [2174/2500], Train Loss: 0.7737, Train Accuracy: 66.29%, Test Loss: 0.9447, Test Accuracy: 60.76%\n",
      "Epoch [2175/2500], Train Loss: 0.7440, Train Accuracy: 66.57%, Test Loss: 0.8740, Test Accuracy: 68.35%\n",
      "Epoch [2176/2500], Train Loss: 0.7424, Train Accuracy: 68.99%, Test Loss: 0.7412, Test Accuracy: 73.42%\n",
      "Epoch [2177/2500], Train Loss: 0.7567, Train Accuracy: 66.86%, Test Loss: 0.7430, Test Accuracy: 68.35%\n",
      "Epoch [2178/2500], Train Loss: 0.7670, Train Accuracy: 66.86%, Test Loss: 0.7624, Test Accuracy: 70.89%\n",
      "Epoch [2179/2500], Train Loss: 0.7551, Train Accuracy: 65.86%, Test Loss: 0.7399, Test Accuracy: 73.42%\n",
      "Epoch [2180/2500], Train Loss: 0.7490, Train Accuracy: 70.41%, Test Loss: 0.7629, Test Accuracy: 65.82%\n",
      "Epoch [2181/2500], Train Loss: 0.7248, Train Accuracy: 70.13%, Test Loss: 0.8648, Test Accuracy: 68.35%\n",
      "Epoch [2182/2500], Train Loss: 0.7417, Train Accuracy: 67.28%, Test Loss: 0.7549, Test Accuracy: 73.42%\n",
      "Epoch [2183/2500], Train Loss: 0.7378, Train Accuracy: 68.71%, Test Loss: 0.7479, Test Accuracy: 72.15%\n",
      "Epoch [2184/2500], Train Loss: 0.7706, Train Accuracy: 66.71%, Test Loss: 0.8023, Test Accuracy: 69.62%\n",
      "Epoch [2185/2500], Train Loss: 0.7590, Train Accuracy: 65.58%, Test Loss: 0.7276, Test Accuracy: 65.82%\n",
      "Epoch [2186/2500], Train Loss: 0.7715, Train Accuracy: 65.72%, Test Loss: 0.7799, Test Accuracy: 70.89%\n",
      "Epoch [2187/2500], Train Loss: 0.7429, Train Accuracy: 67.99%, Test Loss: 0.8511, Test Accuracy: 64.56%\n",
      "Epoch [2188/2500], Train Loss: 0.7444, Train Accuracy: 68.42%, Test Loss: 0.8274, Test Accuracy: 64.56%\n",
      "Epoch [2189/2500], Train Loss: 0.7488, Train Accuracy: 67.99%, Test Loss: 0.8186, Test Accuracy: 67.09%\n",
      "Epoch [2190/2500], Train Loss: 0.7475, Train Accuracy: 67.57%, Test Loss: 0.8445, Test Accuracy: 63.29%\n",
      "Epoch [2191/2500], Train Loss: 0.7678, Train Accuracy: 66.57%, Test Loss: 0.8647, Test Accuracy: 67.09%\n",
      "Epoch [2192/2500], Train Loss: 0.7347, Train Accuracy: 68.56%, Test Loss: 0.7794, Test Accuracy: 72.15%\n",
      "Epoch [2193/2500], Train Loss: 0.7557, Train Accuracy: 66.43%, Test Loss: 0.7139, Test Accuracy: 65.82%\n",
      "Epoch [2194/2500], Train Loss: 0.7729, Train Accuracy: 66.57%, Test Loss: 0.7573, Test Accuracy: 72.15%\n",
      "Epoch [2195/2500], Train Loss: 0.7479, Train Accuracy: 66.43%, Test Loss: 1.0335, Test Accuracy: 56.96%\n",
      "Epoch [2196/2500], Train Loss: 0.7457, Train Accuracy: 69.42%, Test Loss: 0.8427, Test Accuracy: 67.09%\n",
      "Epoch [2197/2500], Train Loss: 0.7184, Train Accuracy: 68.99%, Test Loss: 0.7332, Test Accuracy: 74.68%\n",
      "Epoch [2198/2500], Train Loss: 0.7409, Train Accuracy: 67.99%, Test Loss: 0.7956, Test Accuracy: 69.62%\n",
      "Epoch [2199/2500], Train Loss: 0.7387, Train Accuracy: 66.86%, Test Loss: 0.7721, Test Accuracy: 70.89%\n",
      "Epoch [2200/2500], Train Loss: 0.7468, Train Accuracy: 68.99%, Test Loss: 0.7491, Test Accuracy: 69.62%\n",
      "Epoch [2201/2500], Train Loss: 0.7903, Train Accuracy: 65.01%, Test Loss: 0.7470, Test Accuracy: 73.42%\n",
      "Epoch [2202/2500], Train Loss: 0.7710, Train Accuracy: 66.86%, Test Loss: 0.7285, Test Accuracy: 68.35%\n",
      "Epoch [2203/2500], Train Loss: 0.7541, Train Accuracy: 66.57%, Test Loss: 0.7785, Test Accuracy: 68.35%\n",
      "Epoch [2204/2500], Train Loss: 0.7340, Train Accuracy: 69.13%, Test Loss: 0.7599, Test Accuracy: 72.15%\n",
      "Epoch [2205/2500], Train Loss: 0.7341, Train Accuracy: 68.99%, Test Loss: 0.7677, Test Accuracy: 70.89%\n",
      "Epoch [2206/2500], Train Loss: 0.7787, Train Accuracy: 66.29%, Test Loss: 0.7514, Test Accuracy: 70.89%\n",
      "Epoch [2207/2500], Train Loss: 0.7432, Train Accuracy: 67.85%, Test Loss: 0.7558, Test Accuracy: 73.42%\n",
      "Epoch [2208/2500], Train Loss: 0.7308, Train Accuracy: 69.42%, Test Loss: 0.7518, Test Accuracy: 73.42%\n",
      "Epoch [2209/2500], Train Loss: 0.7601, Train Accuracy: 66.00%, Test Loss: 0.7706, Test Accuracy: 70.89%\n",
      "Epoch [2210/2500], Train Loss: 0.7579, Train Accuracy: 66.29%, Test Loss: 0.7766, Test Accuracy: 70.89%\n",
      "Epoch [2211/2500], Train Loss: 0.7403, Train Accuracy: 68.99%, Test Loss: 0.8661, Test Accuracy: 60.76%\n",
      "Epoch [2212/2500], Train Loss: 0.7494, Train Accuracy: 68.85%, Test Loss: 0.7593, Test Accuracy: 68.35%\n",
      "Epoch [2213/2500], Train Loss: 0.7439, Train Accuracy: 67.14%, Test Loss: 0.7331, Test Accuracy: 70.89%\n",
      "Epoch [2214/2500], Train Loss: 0.7296, Train Accuracy: 67.28%, Test Loss: 0.7745, Test Accuracy: 72.15%\n",
      "Epoch [2215/2500], Train Loss: 0.7338, Train Accuracy: 68.71%, Test Loss: 0.8043, Test Accuracy: 70.89%\n",
      "Epoch [2216/2500], Train Loss: 0.7717, Train Accuracy: 67.14%, Test Loss: 0.8061, Test Accuracy: 67.09%\n",
      "Epoch [2217/2500], Train Loss: 0.7414, Train Accuracy: 67.28%, Test Loss: 0.7284, Test Accuracy: 72.15%\n",
      "Epoch [2218/2500], Train Loss: 0.7542, Train Accuracy: 66.57%, Test Loss: 0.7933, Test Accuracy: 69.62%\n",
      "Epoch [2219/2500], Train Loss: 0.7678, Train Accuracy: 68.14%, Test Loss: 0.7189, Test Accuracy: 64.56%\n",
      "Epoch [2220/2500], Train Loss: 0.7481, Train Accuracy: 69.27%, Test Loss: 0.8591, Test Accuracy: 65.82%\n",
      "Epoch [2221/2500], Train Loss: 0.7168, Train Accuracy: 68.71%, Test Loss: 0.7722, Test Accuracy: 68.35%\n",
      "Epoch [2222/2500], Train Loss: 0.7460, Train Accuracy: 67.99%, Test Loss: 0.7371, Test Accuracy: 68.35%\n",
      "Epoch [2223/2500], Train Loss: 0.7699, Train Accuracy: 67.71%, Test Loss: 0.7645, Test Accuracy: 69.62%\n",
      "Epoch [2224/2500], Train Loss: 0.7310, Train Accuracy: 67.14%, Test Loss: 0.8762, Test Accuracy: 60.76%\n",
      "Epoch [2225/2500], Train Loss: 0.7339, Train Accuracy: 69.13%, Test Loss: 0.7806, Test Accuracy: 70.89%\n",
      "Epoch [2226/2500], Train Loss: 0.7623, Train Accuracy: 66.57%, Test Loss: 0.7772, Test Accuracy: 70.89%\n",
      "Epoch [2227/2500], Train Loss: 0.7374, Train Accuracy: 68.28%, Test Loss: 0.7500, Test Accuracy: 73.42%\n",
      "Epoch [2228/2500], Train Loss: 0.7495, Train Accuracy: 67.43%, Test Loss: 0.7330, Test Accuracy: 73.42%\n",
      "Epoch [2229/2500], Train Loss: 0.7420, Train Accuracy: 67.00%, Test Loss: 0.7690, Test Accuracy: 70.89%\n",
      "Epoch [2230/2500], Train Loss: 0.7647, Train Accuracy: 67.14%, Test Loss: 0.7660, Test Accuracy: 72.15%\n",
      "Epoch [2231/2500], Train Loss: 0.7470, Train Accuracy: 68.14%, Test Loss: 0.8507, Test Accuracy: 67.09%\n",
      "Epoch [2232/2500], Train Loss: 0.7700, Train Accuracy: 67.28%, Test Loss: 0.7194, Test Accuracy: 74.68%\n",
      "Epoch [2233/2500], Train Loss: 0.7519, Train Accuracy: 66.86%, Test Loss: 0.7619, Test Accuracy: 72.15%\n",
      "Epoch [2234/2500], Train Loss: 0.7690, Train Accuracy: 67.71%, Test Loss: 0.8114, Test Accuracy: 69.62%\n",
      "Epoch [2235/2500], Train Loss: 0.7488, Train Accuracy: 69.70%, Test Loss: 0.7777, Test Accuracy: 70.89%\n",
      "Epoch [2236/2500], Train Loss: 0.7494, Train Accuracy: 67.28%, Test Loss: 0.8723, Test Accuracy: 67.09%\n",
      "Epoch [2237/2500], Train Loss: 0.7274, Train Accuracy: 67.14%, Test Loss: 0.7354, Test Accuracy: 72.15%\n",
      "Epoch [2238/2500], Train Loss: 0.7376, Train Accuracy: 67.57%, Test Loss: 0.7773, Test Accuracy: 72.15%\n",
      "Epoch [2239/2500], Train Loss: 0.7562, Train Accuracy: 68.42%, Test Loss: 0.7307, Test Accuracy: 67.09%\n",
      "Epoch [2240/2500], Train Loss: 0.7527, Train Accuracy: 66.86%, Test Loss: 0.7491, Test Accuracy: 73.42%\n",
      "Epoch [2241/2500], Train Loss: 0.7763, Train Accuracy: 67.85%, Test Loss: 0.8129, Test Accuracy: 69.62%\n",
      "Epoch [2242/2500], Train Loss: 0.7414, Train Accuracy: 66.86%, Test Loss: 0.8249, Test Accuracy: 68.35%\n",
      "Epoch [2243/2500], Train Loss: 0.7230, Train Accuracy: 69.84%, Test Loss: 0.7249, Test Accuracy: 73.42%\n",
      "Epoch [2244/2500], Train Loss: 0.7455, Train Accuracy: 67.99%, Test Loss: 0.7428, Test Accuracy: 72.15%\n",
      "Epoch [2245/2500], Train Loss: 0.7466, Train Accuracy: 68.14%, Test Loss: 0.8388, Test Accuracy: 69.62%\n",
      "Epoch [2246/2500], Train Loss: 0.7534, Train Accuracy: 67.00%, Test Loss: 0.8130, Test Accuracy: 70.89%\n",
      "Epoch [2247/2500], Train Loss: 0.7553, Train Accuracy: 66.15%, Test Loss: 0.7409, Test Accuracy: 69.62%\n",
      "Epoch [2248/2500], Train Loss: 0.7529, Train Accuracy: 66.86%, Test Loss: 0.9056, Test Accuracy: 64.56%\n",
      "Epoch [2249/2500], Train Loss: 0.7662, Train Accuracy: 67.57%, Test Loss: 0.8153, Test Accuracy: 67.09%\n",
      "Epoch [2250/2500], Train Loss: 0.7461, Train Accuracy: 66.43%, Test Loss: 0.7436, Test Accuracy: 68.35%\n",
      "Epoch [2251/2500], Train Loss: 0.7425, Train Accuracy: 66.86%, Test Loss: 0.7966, Test Accuracy: 72.15%\n",
      "Epoch [2252/2500], Train Loss: 0.7830, Train Accuracy: 65.86%, Test Loss: 0.7677, Test Accuracy: 73.42%\n",
      "Epoch [2253/2500], Train Loss: 0.7511, Train Accuracy: 65.86%, Test Loss: 0.7704, Test Accuracy: 69.62%\n",
      "Epoch [2254/2500], Train Loss: 0.7601, Train Accuracy: 67.28%, Test Loss: 0.7217, Test Accuracy: 65.82%\n",
      "Epoch [2255/2500], Train Loss: 0.7446, Train Accuracy: 67.57%, Test Loss: 0.7846, Test Accuracy: 70.89%\n",
      "Epoch [2256/2500], Train Loss: 0.7707, Train Accuracy: 67.43%, Test Loss: 0.7207, Test Accuracy: 69.62%\n",
      "Epoch [2257/2500], Train Loss: 0.7576, Train Accuracy: 67.28%, Test Loss: 0.8306, Test Accuracy: 65.82%\n",
      "Epoch [2258/2500], Train Loss: 0.7672, Train Accuracy: 68.56%, Test Loss: 0.7589, Test Accuracy: 75.95%\n",
      "Epoch [2259/2500], Train Loss: 0.7494, Train Accuracy: 65.72%, Test Loss: 0.7664, Test Accuracy: 74.68%\n",
      "Epoch [2260/2500], Train Loss: 0.7695, Train Accuracy: 66.57%, Test Loss: 1.0484, Test Accuracy: 58.23%\n",
      "Epoch [2261/2500], Train Loss: 0.7994, Train Accuracy: 66.15%, Test Loss: 0.7515, Test Accuracy: 72.15%\n",
      "Epoch [2262/2500], Train Loss: 0.7861, Train Accuracy: 66.00%, Test Loss: 0.7951, Test Accuracy: 70.89%\n",
      "Epoch [2263/2500], Train Loss: 0.7590, Train Accuracy: 65.72%, Test Loss: 0.7818, Test Accuracy: 70.89%\n",
      "Epoch [2264/2500], Train Loss: 0.7583, Train Accuracy: 65.58%, Test Loss: 0.7376, Test Accuracy: 68.35%\n",
      "Epoch [2265/2500], Train Loss: 0.7378, Train Accuracy: 67.99%, Test Loss: 0.8211, Test Accuracy: 69.62%\n",
      "Epoch [2266/2500], Train Loss: 0.7622, Train Accuracy: 66.29%, Test Loss: 0.8167, Test Accuracy: 68.35%\n",
      "Epoch [2267/2500], Train Loss: 0.7770, Train Accuracy: 65.72%, Test Loss: 0.8308, Test Accuracy: 68.35%\n",
      "Epoch [2268/2500], Train Loss: 0.7290, Train Accuracy: 68.85%, Test Loss: 0.8171, Test Accuracy: 67.09%\n",
      "Epoch [2269/2500], Train Loss: 0.7827, Train Accuracy: 65.72%, Test Loss: 0.7460, Test Accuracy: 73.42%\n",
      "Epoch [2270/2500], Train Loss: 0.7441, Train Accuracy: 67.28%, Test Loss: 0.7307, Test Accuracy: 72.15%\n",
      "Epoch [2271/2500], Train Loss: 0.7517, Train Accuracy: 68.14%, Test Loss: 0.7460, Test Accuracy: 68.35%\n",
      "Epoch [2272/2500], Train Loss: 0.7393, Train Accuracy: 67.28%, Test Loss: 0.8352, Test Accuracy: 65.82%\n",
      "Epoch [2273/2500], Train Loss: 0.7527, Train Accuracy: 68.56%, Test Loss: 0.7263, Test Accuracy: 67.09%\n",
      "Epoch [2274/2500], Train Loss: 0.7627, Train Accuracy: 66.43%, Test Loss: 0.9202, Test Accuracy: 62.03%\n",
      "Epoch [2275/2500], Train Loss: 0.7589, Train Accuracy: 65.29%, Test Loss: 0.7583, Test Accuracy: 70.89%\n",
      "Epoch [2276/2500], Train Loss: 0.7403, Train Accuracy: 67.57%, Test Loss: 0.7983, Test Accuracy: 67.09%\n",
      "Epoch [2277/2500], Train Loss: 0.7492, Train Accuracy: 68.85%, Test Loss: 0.7180, Test Accuracy: 67.09%\n",
      "Epoch [2278/2500], Train Loss: 0.7547, Train Accuracy: 66.86%, Test Loss: 0.7982, Test Accuracy: 65.82%\n",
      "Epoch [2279/2500], Train Loss: 0.7434, Train Accuracy: 66.43%, Test Loss: 0.7945, Test Accuracy: 67.09%\n",
      "Epoch [2280/2500], Train Loss: 0.7452, Train Accuracy: 67.85%, Test Loss: 0.7243, Test Accuracy: 67.09%\n",
      "Epoch [2281/2500], Train Loss: 0.7453, Train Accuracy: 68.71%, Test Loss: 0.7655, Test Accuracy: 70.89%\n",
      "Epoch [2282/2500], Train Loss: 0.7441, Train Accuracy: 67.71%, Test Loss: 0.7247, Test Accuracy: 72.15%\n",
      "Epoch [2283/2500], Train Loss: 0.7513, Train Accuracy: 68.14%, Test Loss: 0.7579, Test Accuracy: 60.76%\n",
      "Epoch [2284/2500], Train Loss: 0.7525, Train Accuracy: 66.86%, Test Loss: 0.7350, Test Accuracy: 68.35%\n",
      "Epoch [2285/2500], Train Loss: 0.7468, Train Accuracy: 68.56%, Test Loss: 0.8605, Test Accuracy: 64.56%\n",
      "Epoch [2286/2500], Train Loss: 0.7366, Train Accuracy: 68.14%, Test Loss: 0.7308, Test Accuracy: 73.42%\n",
      "Epoch [2287/2500], Train Loss: 0.7443, Train Accuracy: 68.85%, Test Loss: 0.7715, Test Accuracy: 72.15%\n",
      "Epoch [2288/2500], Train Loss: 0.7296, Train Accuracy: 67.71%, Test Loss: 0.7518, Test Accuracy: 70.89%\n",
      "Epoch [2289/2500], Train Loss: 0.7646, Train Accuracy: 68.14%, Test Loss: 0.7706, Test Accuracy: 68.35%\n",
      "Epoch [2290/2500], Train Loss: 0.7470, Train Accuracy: 68.28%, Test Loss: 0.8561, Test Accuracy: 67.09%\n",
      "Epoch [2291/2500], Train Loss: 0.7426, Train Accuracy: 66.00%, Test Loss: 0.7868, Test Accuracy: 68.35%\n",
      "Epoch [2292/2500], Train Loss: 0.7475, Train Accuracy: 68.99%, Test Loss: 0.8391, Test Accuracy: 64.56%\n",
      "Epoch [2293/2500], Train Loss: 0.7216, Train Accuracy: 67.43%, Test Loss: 0.7913, Test Accuracy: 70.89%\n",
      "Epoch [2294/2500], Train Loss: 0.7473, Train Accuracy: 66.86%, Test Loss: 0.8172, Test Accuracy: 68.35%\n",
      "Epoch [2295/2500], Train Loss: 0.7413, Train Accuracy: 66.57%, Test Loss: 0.7316, Test Accuracy: 72.15%\n",
      "Epoch [2296/2500], Train Loss: 0.7600, Train Accuracy: 67.28%, Test Loss: 0.7778, Test Accuracy: 67.09%\n",
      "Epoch [2297/2500], Train Loss: 0.7548, Train Accuracy: 66.15%, Test Loss: 0.8407, Test Accuracy: 63.29%\n",
      "Epoch [2298/2500], Train Loss: 0.7491, Train Accuracy: 68.28%, Test Loss: 0.7461, Test Accuracy: 72.15%\n",
      "Epoch [2299/2500], Train Loss: 0.7694, Train Accuracy: 66.86%, Test Loss: 0.7102, Test Accuracy: 65.82%\n",
      "Epoch [2300/2500], Train Loss: 0.7390, Train Accuracy: 67.28%, Test Loss: 0.8317, Test Accuracy: 68.35%\n",
      "Epoch [2301/2500], Train Loss: 0.7386, Train Accuracy: 70.27%, Test Loss: 0.8486, Test Accuracy: 67.09%\n",
      "Epoch [2302/2500], Train Loss: 0.7451, Train Accuracy: 68.71%, Test Loss: 0.8329, Test Accuracy: 63.29%\n",
      "Epoch [2303/2500], Train Loss: 0.7581, Train Accuracy: 66.43%, Test Loss: 0.8498, Test Accuracy: 63.29%\n",
      "Epoch [2304/2500], Train Loss: 0.7592, Train Accuracy: 67.85%, Test Loss: 0.7371, Test Accuracy: 73.42%\n",
      "Epoch [2305/2500], Train Loss: 0.7414, Train Accuracy: 68.85%, Test Loss: 0.7288, Test Accuracy: 69.62%\n",
      "Epoch [2306/2500], Train Loss: 0.7490, Train Accuracy: 66.71%, Test Loss: 0.7625, Test Accuracy: 72.15%\n",
      "Epoch [2307/2500], Train Loss: 0.7349, Train Accuracy: 68.71%, Test Loss: 0.7698, Test Accuracy: 70.89%\n",
      "Epoch [2308/2500], Train Loss: 0.7591, Train Accuracy: 67.43%, Test Loss: 0.7228, Test Accuracy: 64.56%\n",
      "Epoch [2309/2500], Train Loss: 0.7485, Train Accuracy: 69.99%, Test Loss: 0.8451, Test Accuracy: 65.82%\n",
      "Epoch [2310/2500], Train Loss: 0.7444, Train Accuracy: 67.85%, Test Loss: 0.8048, Test Accuracy: 69.62%\n",
      "Epoch [2311/2500], Train Loss: 0.7452, Train Accuracy: 67.43%, Test Loss: 0.7599, Test Accuracy: 69.62%\n",
      "Epoch [2312/2500], Train Loss: 0.7501, Train Accuracy: 68.28%, Test Loss: 0.7494, Test Accuracy: 70.89%\n",
      "Epoch [2313/2500], Train Loss: 0.7541, Train Accuracy: 66.57%, Test Loss: 0.7735, Test Accuracy: 67.09%\n",
      "Epoch [2314/2500], Train Loss: 0.7269, Train Accuracy: 69.70%, Test Loss: 0.8619, Test Accuracy: 63.29%\n",
      "Epoch [2315/2500], Train Loss: 0.7170, Train Accuracy: 68.42%, Test Loss: 0.7329, Test Accuracy: 67.09%\n",
      "Epoch [2316/2500], Train Loss: 0.7746, Train Accuracy: 65.58%, Test Loss: 0.7651, Test Accuracy: 72.15%\n",
      "Epoch [2317/2500], Train Loss: 0.7534, Train Accuracy: 66.43%, Test Loss: 0.7445, Test Accuracy: 73.42%\n",
      "Epoch [2318/2500], Train Loss: 0.7357, Train Accuracy: 66.86%, Test Loss: 0.7914, Test Accuracy: 72.15%\n",
      "Epoch [2319/2500], Train Loss: 0.7440, Train Accuracy: 67.71%, Test Loss: 0.7762, Test Accuracy: 73.42%\n",
      "Epoch [2320/2500], Train Loss: 0.7485, Train Accuracy: 68.99%, Test Loss: 0.7540, Test Accuracy: 74.68%\n",
      "Epoch [2321/2500], Train Loss: 0.7395, Train Accuracy: 68.14%, Test Loss: 0.7413, Test Accuracy: 69.62%\n",
      "Epoch [2322/2500], Train Loss: 0.7873, Train Accuracy: 65.01%, Test Loss: 0.7864, Test Accuracy: 68.35%\n",
      "Epoch [2323/2500], Train Loss: 0.7555, Train Accuracy: 67.28%, Test Loss: 0.7767, Test Accuracy: 67.09%\n",
      "Epoch [2324/2500], Train Loss: 0.7427, Train Accuracy: 69.27%, Test Loss: 0.7784, Test Accuracy: 70.89%\n",
      "Epoch [2325/2500], Train Loss: 0.7491, Train Accuracy: 68.71%, Test Loss: 0.8128, Test Accuracy: 68.35%\n",
      "Epoch [2326/2500], Train Loss: 0.7443, Train Accuracy: 67.14%, Test Loss: 0.7374, Test Accuracy: 70.89%\n",
      "Epoch [2327/2500], Train Loss: 0.7680, Train Accuracy: 66.00%, Test Loss: 0.7285, Test Accuracy: 67.09%\n",
      "Epoch [2328/2500], Train Loss: 0.7540, Train Accuracy: 67.00%, Test Loss: 0.7209, Test Accuracy: 69.62%\n",
      "Epoch [2329/2500], Train Loss: 0.7502, Train Accuracy: 67.71%, Test Loss: 0.7219, Test Accuracy: 73.42%\n",
      "Epoch [2330/2500], Train Loss: 0.7469, Train Accuracy: 66.57%, Test Loss: 0.8571, Test Accuracy: 67.09%\n",
      "Epoch [2331/2500], Train Loss: 0.7628, Train Accuracy: 66.86%, Test Loss: 0.7700, Test Accuracy: 68.35%\n",
      "Epoch [2332/2500], Train Loss: 0.7684, Train Accuracy: 66.00%, Test Loss: 0.7230, Test Accuracy: 73.42%\n",
      "Epoch [2333/2500], Train Loss: 0.7207, Train Accuracy: 68.14%, Test Loss: 0.7729, Test Accuracy: 68.35%\n",
      "Epoch [2334/2500], Train Loss: 0.7408, Train Accuracy: 68.99%, Test Loss: 0.7181, Test Accuracy: 68.35%\n",
      "Epoch [2335/2500], Train Loss: 0.7600, Train Accuracy: 68.56%, Test Loss: 0.7465, Test Accuracy: 70.89%\n",
      "Epoch [2336/2500], Train Loss: 0.7541, Train Accuracy: 67.43%, Test Loss: 0.7446, Test Accuracy: 72.15%\n",
      "Epoch [2337/2500], Train Loss: 0.7419, Train Accuracy: 68.28%, Test Loss: 0.7428, Test Accuracy: 67.09%\n",
      "Epoch [2338/2500], Train Loss: 0.7442, Train Accuracy: 67.28%, Test Loss: 0.7350, Test Accuracy: 70.89%\n",
      "Epoch [2339/2500], Train Loss: 0.7593, Train Accuracy: 68.28%, Test Loss: 0.8348, Test Accuracy: 64.56%\n",
      "Epoch [2340/2500], Train Loss: 0.7496, Train Accuracy: 68.28%, Test Loss: 0.7303, Test Accuracy: 72.15%\n",
      "Epoch [2341/2500], Train Loss: 0.7471, Train Accuracy: 69.13%, Test Loss: 0.7445, Test Accuracy: 72.15%\n",
      "Epoch [2342/2500], Train Loss: 0.7546, Train Accuracy: 68.28%, Test Loss: 0.7894, Test Accuracy: 69.62%\n",
      "Epoch [2343/2500], Train Loss: 0.7553, Train Accuracy: 66.71%, Test Loss: 0.7426, Test Accuracy: 73.42%\n",
      "Epoch [2344/2500], Train Loss: 0.7698, Train Accuracy: 66.71%, Test Loss: 0.7484, Test Accuracy: 73.42%\n",
      "Epoch [2345/2500], Train Loss: 0.7296, Train Accuracy: 68.14%, Test Loss: 0.7329, Test Accuracy: 68.35%\n",
      "Epoch [2346/2500], Train Loss: 0.7083, Train Accuracy: 69.27%, Test Loss: 0.7384, Test Accuracy: 67.09%\n",
      "Epoch [2347/2500], Train Loss: 0.7632, Train Accuracy: 65.29%, Test Loss: 0.7979, Test Accuracy: 68.35%\n",
      "Epoch [2348/2500], Train Loss: 0.7593, Train Accuracy: 67.28%, Test Loss: 0.7333, Test Accuracy: 69.62%\n",
      "Epoch [2349/2500], Train Loss: 0.7511, Train Accuracy: 67.28%, Test Loss: 0.7187, Test Accuracy: 65.82%\n",
      "Epoch [2350/2500], Train Loss: 0.7358, Train Accuracy: 66.86%, Test Loss: 0.7143, Test Accuracy: 70.89%\n",
      "Epoch [2351/2500], Train Loss: 0.7365, Train Accuracy: 67.14%, Test Loss: 0.7242, Test Accuracy: 70.89%\n",
      "Epoch [2352/2500], Train Loss: 0.7635, Train Accuracy: 66.57%, Test Loss: 0.7420, Test Accuracy: 70.89%\n",
      "Epoch [2353/2500], Train Loss: 0.7460, Train Accuracy: 65.15%, Test Loss: 0.7338, Test Accuracy: 72.15%\n",
      "Epoch [2354/2500], Train Loss: 0.7390, Train Accuracy: 66.57%, Test Loss: 0.7557, Test Accuracy: 72.15%\n",
      "Epoch [2355/2500], Train Loss: 0.7372, Train Accuracy: 67.99%, Test Loss: 0.8192, Test Accuracy: 69.62%\n",
      "Epoch [2356/2500], Train Loss: 0.7579, Train Accuracy: 66.29%, Test Loss: 0.7248, Test Accuracy: 73.42%\n",
      "Epoch [2357/2500], Train Loss: 0.7707, Train Accuracy: 68.14%, Test Loss: 0.8163, Test Accuracy: 67.09%\n",
      "Epoch [2358/2500], Train Loss: 0.7539, Train Accuracy: 67.28%, Test Loss: 0.7188, Test Accuracy: 67.09%\n",
      "Epoch [2359/2500], Train Loss: 0.7655, Train Accuracy: 67.00%, Test Loss: 0.7424, Test Accuracy: 72.15%\n",
      "Epoch [2360/2500], Train Loss: 0.7254, Train Accuracy: 68.14%, Test Loss: 0.7539, Test Accuracy: 67.09%\n",
      "Epoch [2361/2500], Train Loss: 0.7488, Train Accuracy: 67.57%, Test Loss: 0.7152, Test Accuracy: 65.82%\n",
      "Epoch [2362/2500], Train Loss: 0.7464, Train Accuracy: 66.86%, Test Loss: 0.7393, Test Accuracy: 73.42%\n",
      "Epoch [2363/2500], Train Loss: 0.7644, Train Accuracy: 66.15%, Test Loss: 0.7682, Test Accuracy: 72.15%\n",
      "Epoch [2364/2500], Train Loss: 0.7343, Train Accuracy: 67.28%, Test Loss: 0.8404, Test Accuracy: 69.62%\n",
      "Epoch [2365/2500], Train Loss: 0.7548, Train Accuracy: 66.86%, Test Loss: 0.7378, Test Accuracy: 68.35%\n",
      "Epoch [2366/2500], Train Loss: 0.7350, Train Accuracy: 67.71%, Test Loss: 0.7363, Test Accuracy: 73.42%\n",
      "Epoch [2367/2500], Train Loss: 0.7343, Train Accuracy: 69.84%, Test Loss: 0.8061, Test Accuracy: 68.35%\n",
      "Epoch [2368/2500], Train Loss: 0.7285, Train Accuracy: 68.85%, Test Loss: 0.7617, Test Accuracy: 67.09%\n",
      "Epoch [2369/2500], Train Loss: 0.7581, Train Accuracy: 67.99%, Test Loss: 0.8376, Test Accuracy: 64.56%\n",
      "Epoch [2370/2500], Train Loss: 0.7400, Train Accuracy: 67.00%, Test Loss: 0.7296, Test Accuracy: 68.35%\n",
      "Epoch [2371/2500], Train Loss: 0.7557, Train Accuracy: 67.57%, Test Loss: 0.7402, Test Accuracy: 64.56%\n",
      "Epoch [2372/2500], Train Loss: 0.7602, Train Accuracy: 66.71%, Test Loss: 0.7833, Test Accuracy: 64.56%\n",
      "Epoch [2373/2500], Train Loss: 0.7338, Train Accuracy: 67.85%, Test Loss: 0.8592, Test Accuracy: 63.29%\n",
      "Epoch [2374/2500], Train Loss: 0.7489, Train Accuracy: 65.43%, Test Loss: 0.7412, Test Accuracy: 73.42%\n",
      "Epoch [2375/2500], Train Loss: 0.7389, Train Accuracy: 68.99%, Test Loss: 0.7881, Test Accuracy: 69.62%\n",
      "Epoch [2376/2500], Train Loss: 0.7530, Train Accuracy: 66.29%, Test Loss: 0.7761, Test Accuracy: 70.89%\n",
      "Epoch [2377/2500], Train Loss: 0.7420, Train Accuracy: 68.56%, Test Loss: 0.7164, Test Accuracy: 70.89%\n",
      "Epoch [2378/2500], Train Loss: 0.7521, Train Accuracy: 67.99%, Test Loss: 0.9709, Test Accuracy: 65.82%\n",
      "Epoch [2379/2500], Train Loss: 0.7460, Train Accuracy: 67.14%, Test Loss: 0.7200, Test Accuracy: 73.42%\n",
      "Epoch [2380/2500], Train Loss: 0.7508, Train Accuracy: 66.86%, Test Loss: 0.7464, Test Accuracy: 70.89%\n",
      "Epoch [2381/2500], Train Loss: 0.7707, Train Accuracy: 66.86%, Test Loss: 0.7187, Test Accuracy: 69.62%\n",
      "Epoch [2382/2500], Train Loss: 0.7545, Train Accuracy: 66.15%, Test Loss: 0.7262, Test Accuracy: 69.62%\n",
      "Epoch [2383/2500], Train Loss: 0.7756, Train Accuracy: 67.85%, Test Loss: 0.7542, Test Accuracy: 73.42%\n",
      "Epoch [2384/2500], Train Loss: 0.7482, Train Accuracy: 66.15%, Test Loss: 0.7557, Test Accuracy: 73.42%\n",
      "Epoch [2385/2500], Train Loss: 0.7504, Train Accuracy: 68.28%, Test Loss: 0.7796, Test Accuracy: 69.62%\n",
      "Epoch [2386/2500], Train Loss: 0.7563, Train Accuracy: 67.43%, Test Loss: 0.8235, Test Accuracy: 65.82%\n",
      "Epoch [2387/2500], Train Loss: 0.7263, Train Accuracy: 68.71%, Test Loss: 0.7527, Test Accuracy: 72.15%\n",
      "Epoch [2388/2500], Train Loss: 0.7988, Train Accuracy: 64.86%, Test Loss: 0.8313, Test Accuracy: 63.29%\n",
      "Epoch [2389/2500], Train Loss: 0.7197, Train Accuracy: 68.14%, Test Loss: 0.7219, Test Accuracy: 69.62%\n",
      "Epoch [2390/2500], Train Loss: 0.7487, Train Accuracy: 69.27%, Test Loss: 0.7219, Test Accuracy: 67.09%\n",
      "Epoch [2391/2500], Train Loss: 0.7382, Train Accuracy: 68.42%, Test Loss: 0.7541, Test Accuracy: 70.89%\n",
      "Epoch [2392/2500], Train Loss: 0.7424, Train Accuracy: 68.42%, Test Loss: 0.8489, Test Accuracy: 64.56%\n",
      "Epoch [2393/2500], Train Loss: 0.7185, Train Accuracy: 70.84%, Test Loss: 0.8444, Test Accuracy: 64.56%\n",
      "Epoch [2394/2500], Train Loss: 0.7334, Train Accuracy: 67.28%, Test Loss: 0.8525, Test Accuracy: 67.09%\n",
      "Epoch [2395/2500], Train Loss: 0.7522, Train Accuracy: 66.29%, Test Loss: 0.7964, Test Accuracy: 67.09%\n",
      "Epoch [2396/2500], Train Loss: 0.7604, Train Accuracy: 66.15%, Test Loss: 0.8568, Test Accuracy: 65.82%\n",
      "Epoch [2397/2500], Train Loss: 0.7891, Train Accuracy: 64.30%, Test Loss: 0.9905, Test Accuracy: 60.76%\n",
      "Epoch [2398/2500], Train Loss: 0.7439, Train Accuracy: 68.99%, Test Loss: 0.7941, Test Accuracy: 70.89%\n",
      "Epoch [2399/2500], Train Loss: 0.7544, Train Accuracy: 67.43%, Test Loss: 0.7745, Test Accuracy: 72.15%\n",
      "Epoch [2400/2500], Train Loss: 0.7734, Train Accuracy: 65.01%, Test Loss: 0.8405, Test Accuracy: 68.35%\n",
      "Epoch [2401/2500], Train Loss: 0.7538, Train Accuracy: 68.99%, Test Loss: 0.7213, Test Accuracy: 64.56%\n",
      "Epoch [2402/2500], Train Loss: 0.7317, Train Accuracy: 69.56%, Test Loss: 0.7759, Test Accuracy: 72.15%\n",
      "Epoch [2403/2500], Train Loss: 0.7506, Train Accuracy: 67.00%, Test Loss: 0.7757, Test Accuracy: 68.35%\n",
      "Epoch [2404/2500], Train Loss: 0.7794, Train Accuracy: 66.15%, Test Loss: 0.7550, Test Accuracy: 65.82%\n",
      "Epoch [2405/2500], Train Loss: 0.7476, Train Accuracy: 69.13%, Test Loss: 0.7366, Test Accuracy: 73.42%\n",
      "Epoch [2406/2500], Train Loss: 0.7338, Train Accuracy: 68.71%, Test Loss: 0.7809, Test Accuracy: 70.89%\n",
      "Epoch [2407/2500], Train Loss: 0.7395, Train Accuracy: 67.00%, Test Loss: 0.9527, Test Accuracy: 62.03%\n",
      "Epoch [2408/2500], Train Loss: 0.7653, Train Accuracy: 67.85%, Test Loss: 0.7281, Test Accuracy: 67.09%\n",
      "Epoch [2409/2500], Train Loss: 0.7727, Train Accuracy: 66.71%, Test Loss: 0.7565, Test Accuracy: 70.89%\n",
      "Epoch [2410/2500], Train Loss: 0.7386, Train Accuracy: 68.14%, Test Loss: 0.9293, Test Accuracy: 63.29%\n",
      "Epoch [2411/2500], Train Loss: 0.7481, Train Accuracy: 67.00%, Test Loss: 0.7447, Test Accuracy: 70.89%\n",
      "Epoch [2412/2500], Train Loss: 0.7759, Train Accuracy: 66.29%, Test Loss: 0.7219, Test Accuracy: 73.42%\n",
      "Epoch [2413/2500], Train Loss: 0.7707, Train Accuracy: 66.43%, Test Loss: 0.8427, Test Accuracy: 63.29%\n",
      "Epoch [2414/2500], Train Loss: 0.7412, Train Accuracy: 67.99%, Test Loss: 0.8214, Test Accuracy: 70.89%\n",
      "Epoch [2415/2500], Train Loss: 0.7551, Train Accuracy: 66.00%, Test Loss: 0.7788, Test Accuracy: 65.82%\n",
      "Epoch [2416/2500], Train Loss: 0.7452, Train Accuracy: 67.71%, Test Loss: 0.8030, Test Accuracy: 68.35%\n",
      "Epoch [2417/2500], Train Loss: 0.7605, Train Accuracy: 67.57%, Test Loss: 0.7602, Test Accuracy: 72.15%\n",
      "Epoch [2418/2500], Train Loss: 0.7631, Train Accuracy: 68.28%, Test Loss: 0.7903, Test Accuracy: 68.35%\n",
      "Epoch [2419/2500], Train Loss: 0.7537, Train Accuracy: 67.43%, Test Loss: 0.7406, Test Accuracy: 72.15%\n",
      "Epoch [2420/2500], Train Loss: 0.7438, Train Accuracy: 68.28%, Test Loss: 0.8260, Test Accuracy: 65.82%\n",
      "Epoch [2421/2500], Train Loss: 0.7599, Train Accuracy: 64.72%, Test Loss: 0.8505, Test Accuracy: 68.35%\n",
      "Epoch [2422/2500], Train Loss: 0.7576, Train Accuracy: 67.71%, Test Loss: 0.7827, Test Accuracy: 70.89%\n",
      "Epoch [2423/2500], Train Loss: 0.7999, Train Accuracy: 63.16%, Test Loss: 0.7554, Test Accuracy: 67.09%\n",
      "Epoch [2424/2500], Train Loss: 0.7654, Train Accuracy: 67.57%, Test Loss: 0.7652, Test Accuracy: 73.42%\n",
      "Epoch [2425/2500], Train Loss: 0.7678, Train Accuracy: 67.99%, Test Loss: 0.7776, Test Accuracy: 67.09%\n",
      "Epoch [2426/2500], Train Loss: 0.7591, Train Accuracy: 66.57%, Test Loss: 0.7383, Test Accuracy: 69.62%\n",
      "Epoch [2427/2500], Train Loss: 0.7318, Train Accuracy: 68.42%, Test Loss: 0.7818, Test Accuracy: 73.42%\n",
      "Epoch [2428/2500], Train Loss: 0.7355, Train Accuracy: 68.28%, Test Loss: 0.7467, Test Accuracy: 67.09%\n",
      "Epoch [2429/2500], Train Loss: 0.7499, Train Accuracy: 67.85%, Test Loss: 0.7563, Test Accuracy: 68.35%\n",
      "Epoch [2430/2500], Train Loss: 0.7527, Train Accuracy: 65.86%, Test Loss: 0.7868, Test Accuracy: 68.35%\n",
      "Epoch [2431/2500], Train Loss: 0.7532, Train Accuracy: 66.29%, Test Loss: 0.9398, Test Accuracy: 63.29%\n",
      "Epoch [2432/2500], Train Loss: 0.7575, Train Accuracy: 68.99%, Test Loss: 0.7757, Test Accuracy: 69.62%\n",
      "Epoch [2433/2500], Train Loss: 0.7400, Train Accuracy: 68.56%, Test Loss: 0.8084, Test Accuracy: 65.82%\n",
      "Epoch [2434/2500], Train Loss: 0.7756, Train Accuracy: 65.86%, Test Loss: 0.7624, Test Accuracy: 69.62%\n",
      "Epoch [2435/2500], Train Loss: 0.7310, Train Accuracy: 67.57%, Test Loss: 0.7534, Test Accuracy: 73.42%\n",
      "Epoch [2436/2500], Train Loss: 0.7227, Train Accuracy: 68.85%, Test Loss: 0.7854, Test Accuracy: 69.62%\n",
      "Epoch [2437/2500], Train Loss: 0.7608, Train Accuracy: 66.15%, Test Loss: 0.8510, Test Accuracy: 64.56%\n",
      "Epoch [2438/2500], Train Loss: 0.7523, Train Accuracy: 67.00%, Test Loss: 0.7440, Test Accuracy: 67.09%\n",
      "Epoch [2439/2500], Train Loss: 0.7115, Train Accuracy: 69.70%, Test Loss: 0.8595, Test Accuracy: 65.82%\n",
      "Epoch [2440/2500], Train Loss: 0.7575, Train Accuracy: 65.86%, Test Loss: 0.7292, Test Accuracy: 70.89%\n",
      "Epoch [2441/2500], Train Loss: 0.7444, Train Accuracy: 68.14%, Test Loss: 0.7231, Test Accuracy: 69.62%\n",
      "Epoch [2442/2500], Train Loss: 0.7597, Train Accuracy: 66.86%, Test Loss: 0.8030, Test Accuracy: 70.89%\n",
      "Epoch [2443/2500], Train Loss: 0.7623, Train Accuracy: 66.71%, Test Loss: 0.8651, Test Accuracy: 67.09%\n",
      "Epoch [2444/2500], Train Loss: 0.7218, Train Accuracy: 68.42%, Test Loss: 0.8000, Test Accuracy: 69.62%\n",
      "Epoch [2445/2500], Train Loss: 0.7316, Train Accuracy: 68.42%, Test Loss: 0.7891, Test Accuracy: 72.15%\n",
      "Epoch [2446/2500], Train Loss: 0.7451, Train Accuracy: 67.71%, Test Loss: 0.7339, Test Accuracy: 69.62%\n",
      "Epoch [2447/2500], Train Loss: 0.7490, Train Accuracy: 67.57%, Test Loss: 0.7266, Test Accuracy: 74.68%\n",
      "Epoch [2448/2500], Train Loss: 0.7359, Train Accuracy: 67.57%, Test Loss: 0.7670, Test Accuracy: 70.89%\n",
      "Epoch [2449/2500], Train Loss: 0.7495, Train Accuracy: 68.42%, Test Loss: 0.7276, Test Accuracy: 68.35%\n",
      "Epoch [2450/2500], Train Loss: 0.7455, Train Accuracy: 68.42%, Test Loss: 0.7273, Test Accuracy: 73.42%\n",
      "Epoch [2451/2500], Train Loss: 0.7474, Train Accuracy: 68.42%, Test Loss: 0.8092, Test Accuracy: 68.35%\n",
      "Epoch [2452/2500], Train Loss: 0.7305, Train Accuracy: 68.42%, Test Loss: 0.7964, Test Accuracy: 69.62%\n",
      "Epoch [2453/2500], Train Loss: 0.7434, Train Accuracy: 69.27%, Test Loss: 0.7125, Test Accuracy: 69.62%\n",
      "Epoch [2454/2500], Train Loss: 0.7619, Train Accuracy: 67.00%, Test Loss: 0.8239, Test Accuracy: 67.09%\n",
      "Epoch [2455/2500], Train Loss: 0.7613, Train Accuracy: 67.99%, Test Loss: 0.7616, Test Accuracy: 72.15%\n",
      "Epoch [2456/2500], Train Loss: 0.7386, Train Accuracy: 69.42%, Test Loss: 0.7280, Test Accuracy: 69.62%\n",
      "Epoch [2457/2500], Train Loss: 0.7346, Train Accuracy: 67.14%, Test Loss: 0.8020, Test Accuracy: 67.09%\n",
      "Epoch [2458/2500], Train Loss: 0.7274, Train Accuracy: 67.43%, Test Loss: 0.7723, Test Accuracy: 69.62%\n",
      "Epoch [2459/2500], Train Loss: 0.7402, Train Accuracy: 67.00%, Test Loss: 0.7117, Test Accuracy: 67.09%\n",
      "Epoch [2460/2500], Train Loss: 0.7500, Train Accuracy: 67.28%, Test Loss: 0.7304, Test Accuracy: 74.68%\n",
      "Epoch [2461/2500], Train Loss: 0.7146, Train Accuracy: 69.99%, Test Loss: 0.8187, Test Accuracy: 72.15%\n",
      "Epoch [2462/2500], Train Loss: 0.7768, Train Accuracy: 66.57%, Test Loss: 0.8096, Test Accuracy: 70.89%\n",
      "Epoch [2463/2500], Train Loss: 0.7463, Train Accuracy: 67.00%, Test Loss: 0.7299, Test Accuracy: 67.09%\n",
      "Epoch [2464/2500], Train Loss: 0.7414, Train Accuracy: 67.14%, Test Loss: 0.7741, Test Accuracy: 73.42%\n",
      "Epoch [2465/2500], Train Loss: 0.7250, Train Accuracy: 68.56%, Test Loss: 0.8482, Test Accuracy: 67.09%\n",
      "Epoch [2466/2500], Train Loss: 0.7434, Train Accuracy: 68.99%, Test Loss: 0.8266, Test Accuracy: 69.62%\n",
      "Epoch [2467/2500], Train Loss: 0.7576, Train Accuracy: 67.28%, Test Loss: 0.7306, Test Accuracy: 70.89%\n",
      "Epoch [2468/2500], Train Loss: 0.7593, Train Accuracy: 68.28%, Test Loss: 0.7290, Test Accuracy: 67.09%\n",
      "Epoch [2469/2500], Train Loss: 0.7367, Train Accuracy: 66.29%, Test Loss: 0.7906, Test Accuracy: 70.89%\n",
      "Epoch [2470/2500], Train Loss: 0.7497, Train Accuracy: 67.57%, Test Loss: 0.7215, Test Accuracy: 69.62%\n",
      "Epoch [2471/2500], Train Loss: 0.7625, Train Accuracy: 66.86%, Test Loss: 0.8325, Test Accuracy: 67.09%\n",
      "Epoch [2472/2500], Train Loss: 0.7418, Train Accuracy: 67.57%, Test Loss: 0.7132, Test Accuracy: 70.89%\n",
      "Epoch [2473/2500], Train Loss: 0.7432, Train Accuracy: 68.99%, Test Loss: 0.7377, Test Accuracy: 74.68%\n",
      "Epoch [2474/2500], Train Loss: 0.7445, Train Accuracy: 67.43%, Test Loss: 0.7185, Test Accuracy: 72.15%\n",
      "Epoch [2475/2500], Train Loss: 0.7275, Train Accuracy: 66.57%, Test Loss: 0.8013, Test Accuracy: 68.35%\n",
      "Epoch [2476/2500], Train Loss: 0.7351, Train Accuracy: 67.71%, Test Loss: 0.7231, Test Accuracy: 67.09%\n",
      "Epoch [2477/2500], Train Loss: 0.7583, Train Accuracy: 67.43%, Test Loss: 0.8069, Test Accuracy: 69.62%\n",
      "Epoch [2478/2500], Train Loss: 0.7478, Train Accuracy: 67.14%, Test Loss: 0.7498, Test Accuracy: 70.89%\n",
      "Epoch [2479/2500], Train Loss: 0.7571, Train Accuracy: 67.14%, Test Loss: 0.7307, Test Accuracy: 60.76%\n",
      "Epoch [2480/2500], Train Loss: 0.7654, Train Accuracy: 67.28%, Test Loss: 0.7658, Test Accuracy: 72.15%\n",
      "Epoch [2481/2500], Train Loss: 0.7479, Train Accuracy: 68.99%, Test Loss: 0.8833, Test Accuracy: 68.35%\n",
      "Epoch [2482/2500], Train Loss: 0.7511, Train Accuracy: 67.28%, Test Loss: 0.7581, Test Accuracy: 72.15%\n",
      "Epoch [2483/2500], Train Loss: 0.7212, Train Accuracy: 69.70%, Test Loss: 0.7262, Test Accuracy: 70.89%\n",
      "Epoch [2484/2500], Train Loss: 0.7731, Train Accuracy: 66.00%, Test Loss: 0.8053, Test Accuracy: 69.62%\n",
      "Epoch [2485/2500], Train Loss: 0.7542, Train Accuracy: 67.57%, Test Loss: 0.7369, Test Accuracy: 70.89%\n",
      "Epoch [2486/2500], Train Loss: 0.7797, Train Accuracy: 67.14%, Test Loss: 0.7869, Test Accuracy: 68.35%\n",
      "Epoch [2487/2500], Train Loss: 0.7384, Train Accuracy: 67.14%, Test Loss: 0.7177, Test Accuracy: 70.89%\n",
      "Epoch [2488/2500], Train Loss: 0.7513, Train Accuracy: 66.86%, Test Loss: 0.7255, Test Accuracy: 68.35%\n",
      "Epoch [2489/2500], Train Loss: 0.7352, Train Accuracy: 67.14%, Test Loss: 0.7524, Test Accuracy: 67.09%\n",
      "Epoch [2490/2500], Train Loss: 0.7529, Train Accuracy: 67.00%, Test Loss: 0.7727, Test Accuracy: 70.89%\n",
      "Epoch [2491/2500], Train Loss: 0.7664, Train Accuracy: 67.00%, Test Loss: 0.8699, Test Accuracy: 67.09%\n",
      "Epoch [2492/2500], Train Loss: 0.7587, Train Accuracy: 66.43%, Test Loss: 0.7200, Test Accuracy: 68.35%\n",
      "Epoch [2493/2500], Train Loss: 0.7587, Train Accuracy: 67.43%, Test Loss: 0.9580, Test Accuracy: 60.76%\n",
      "Epoch [2494/2500], Train Loss: 0.7420, Train Accuracy: 69.42%, Test Loss: 0.8311, Test Accuracy: 65.82%\n",
      "Epoch [2495/2500], Train Loss: 0.7412, Train Accuracy: 68.85%, Test Loss: 0.7431, Test Accuracy: 73.42%\n",
      "Epoch [2496/2500], Train Loss: 0.7146, Train Accuracy: 70.27%, Test Loss: 0.7350, Test Accuracy: 74.68%\n",
      "Epoch [2497/2500], Train Loss: 0.7327, Train Accuracy: 68.42%, Test Loss: 0.8327, Test Accuracy: 67.09%\n",
      "Epoch [2498/2500], Train Loss: 0.7069, Train Accuracy: 70.41%, Test Loss: 0.7414, Test Accuracy: 68.35%\n",
      "Epoch [2499/2500], Train Loss: 0.7304, Train Accuracy: 68.85%, Test Loss: 0.7649, Test Accuracy: 67.09%\n",
      "Epoch [2500/2500], Train Loss: 0.7297, Train Accuracy: 67.28%, Test Loss: 0.7634, Test Accuracy: 72.15%\n",
      "model_cnn2d saved as model_cnn2d_4class_best.pth\n",
      "\n",
      "Metrics for model_cnn2d saved as model_cnn2d_metrics_4class.csv\n",
      "\n",
      "Training model_cnn2d_lstm\n",
      "Epoch [1/2500], Train Loss: 1.3650, Train Accuracy: 32.57%, Test Loss: 1.3014, Test Accuracy: 39.24%\n",
      "Epoch [2/2500], Train Loss: 1.3562, Train Accuracy: 34.42%, Test Loss: 1.2931, Test Accuracy: 39.24%\n",
      "Epoch [3/2500], Train Loss: 1.3581, Train Accuracy: 35.14%, Test Loss: 1.2890, Test Accuracy: 39.24%\n",
      "Epoch [4/2500], Train Loss: 1.3444, Train Accuracy: 34.42%, Test Loss: 1.2847, Test Accuracy: 39.24%\n",
      "Epoch [5/2500], Train Loss: 1.3442, Train Accuracy: 34.42%, Test Loss: 1.2822, Test Accuracy: 39.24%\n",
      "Epoch [6/2500], Train Loss: 1.3483, Train Accuracy: 34.14%, Test Loss: 1.2767, Test Accuracy: 39.24%\n",
      "Epoch [7/2500], Train Loss: 1.3393, Train Accuracy: 35.99%, Test Loss: 1.2740, Test Accuracy: 39.24%\n",
      "Epoch [8/2500], Train Loss: 1.3387, Train Accuracy: 36.98%, Test Loss: 1.2718, Test Accuracy: 39.24%\n",
      "Epoch [9/2500], Train Loss: 1.3417, Train Accuracy: 36.13%, Test Loss: 1.2711, Test Accuracy: 39.24%\n",
      "Epoch [10/2500], Train Loss: 1.3372, Train Accuracy: 35.56%, Test Loss: 1.2715, Test Accuracy: 39.24%\n",
      "Epoch [11/2500], Train Loss: 1.3345, Train Accuracy: 36.27%, Test Loss: 1.2678, Test Accuracy: 39.24%\n",
      "Epoch [12/2500], Train Loss: 1.3329, Train Accuracy: 35.70%, Test Loss: 1.2688, Test Accuracy: 39.24%\n",
      "Epoch [13/2500], Train Loss: 1.3332, Train Accuracy: 35.70%, Test Loss: 1.2663, Test Accuracy: 39.24%\n",
      "Epoch [14/2500], Train Loss: 1.3233, Train Accuracy: 38.12%, Test Loss: 1.2619, Test Accuracy: 39.24%\n",
      "Epoch [15/2500], Train Loss: 1.3193, Train Accuracy: 36.70%, Test Loss: 1.2603, Test Accuracy: 39.24%\n",
      "Epoch [16/2500], Train Loss: 1.3232, Train Accuracy: 37.41%, Test Loss: 1.2521, Test Accuracy: 39.24%\n",
      "Epoch [17/2500], Train Loss: 1.3201, Train Accuracy: 37.84%, Test Loss: 1.2492, Test Accuracy: 39.24%\n",
      "Epoch [18/2500], Train Loss: 1.3189, Train Accuracy: 38.12%, Test Loss: 1.2453, Test Accuracy: 39.24%\n",
      "Epoch [19/2500], Train Loss: 1.3223, Train Accuracy: 39.12%, Test Loss: 1.2435, Test Accuracy: 39.24%\n",
      "Epoch [20/2500], Train Loss: 1.3175, Train Accuracy: 39.40%, Test Loss: 1.2444, Test Accuracy: 39.24%\n",
      "Epoch [21/2500], Train Loss: 1.3213, Train Accuracy: 39.69%, Test Loss: 1.2412, Test Accuracy: 39.24%\n",
      "Epoch [22/2500], Train Loss: 1.3149, Train Accuracy: 37.55%, Test Loss: 1.2361, Test Accuracy: 39.24%\n",
      "Epoch [23/2500], Train Loss: 1.3203, Train Accuracy: 38.69%, Test Loss: 1.2344, Test Accuracy: 39.24%\n",
      "Epoch [24/2500], Train Loss: 1.3155, Train Accuracy: 38.98%, Test Loss: 1.2294, Test Accuracy: 39.24%\n",
      "Epoch [25/2500], Train Loss: 1.3077, Train Accuracy: 38.83%, Test Loss: 1.2261, Test Accuracy: 39.24%\n",
      "Epoch [26/2500], Train Loss: 1.3058, Train Accuracy: 39.12%, Test Loss: 1.2226, Test Accuracy: 39.24%\n",
      "Epoch [27/2500], Train Loss: 1.2942, Train Accuracy: 39.97%, Test Loss: 1.2234, Test Accuracy: 39.24%\n",
      "Epoch [28/2500], Train Loss: 1.2997, Train Accuracy: 40.11%, Test Loss: 1.2235, Test Accuracy: 39.24%\n",
      "Epoch [29/2500], Train Loss: 1.3118, Train Accuracy: 39.40%, Test Loss: 1.2197, Test Accuracy: 39.24%\n",
      "Epoch [30/2500], Train Loss: 1.3027, Train Accuracy: 40.40%, Test Loss: 1.2184, Test Accuracy: 39.24%\n",
      "Epoch [31/2500], Train Loss: 1.2983, Train Accuracy: 41.96%, Test Loss: 1.2188, Test Accuracy: 39.24%\n",
      "Epoch [32/2500], Train Loss: 1.3011, Train Accuracy: 40.54%, Test Loss: 1.2159, Test Accuracy: 39.24%\n",
      "Epoch [33/2500], Train Loss: 1.3078, Train Accuracy: 40.54%, Test Loss: 1.2139, Test Accuracy: 39.24%\n",
      "Epoch [34/2500], Train Loss: 1.2917, Train Accuracy: 41.25%, Test Loss: 1.2100, Test Accuracy: 39.24%\n",
      "Epoch [35/2500], Train Loss: 1.2984, Train Accuracy: 39.97%, Test Loss: 1.2070, Test Accuracy: 39.24%\n",
      "Epoch [36/2500], Train Loss: 1.3010, Train Accuracy: 40.54%, Test Loss: 1.2081, Test Accuracy: 39.24%\n",
      "Epoch [37/2500], Train Loss: 1.3019, Train Accuracy: 41.68%, Test Loss: 1.2086, Test Accuracy: 39.24%\n",
      "Epoch [38/2500], Train Loss: 1.2971, Train Accuracy: 41.39%, Test Loss: 1.2049, Test Accuracy: 39.24%\n",
      "Epoch [39/2500], Train Loss: 1.2944, Train Accuracy: 41.96%, Test Loss: 1.2010, Test Accuracy: 40.51%\n",
      "Epoch [40/2500], Train Loss: 1.2927, Train Accuracy: 41.54%, Test Loss: 1.1991, Test Accuracy: 40.51%\n",
      "Epoch [41/2500], Train Loss: 1.2818, Train Accuracy: 44.24%, Test Loss: 1.1950, Test Accuracy: 41.77%\n",
      "Epoch [42/2500], Train Loss: 1.2854, Train Accuracy: 43.53%, Test Loss: 1.1949, Test Accuracy: 43.04%\n",
      "Epoch [43/2500], Train Loss: 1.2864, Train Accuracy: 42.96%, Test Loss: 1.1926, Test Accuracy: 43.04%\n",
      "Epoch [44/2500], Train Loss: 1.2822, Train Accuracy: 43.67%, Test Loss: 1.1922, Test Accuracy: 40.51%\n",
      "Epoch [45/2500], Train Loss: 1.2809, Train Accuracy: 41.96%, Test Loss: 1.1921, Test Accuracy: 40.51%\n",
      "Epoch [46/2500], Train Loss: 1.2804, Train Accuracy: 43.53%, Test Loss: 1.1901, Test Accuracy: 41.77%\n",
      "Epoch [47/2500], Train Loss: 1.2774, Train Accuracy: 42.11%, Test Loss: 1.1872, Test Accuracy: 41.77%\n",
      "Epoch [48/2500], Train Loss: 1.2840, Train Accuracy: 43.39%, Test Loss: 1.1847, Test Accuracy: 41.77%\n",
      "Epoch [49/2500], Train Loss: 1.2791, Train Accuracy: 42.39%, Test Loss: 1.1781, Test Accuracy: 48.10%\n",
      "Epoch [50/2500], Train Loss: 1.2749, Train Accuracy: 45.09%, Test Loss: 1.1710, Test Accuracy: 49.37%\n",
      "Epoch [51/2500], Train Loss: 1.2731, Train Accuracy: 44.52%, Test Loss: 1.1756, Test Accuracy: 49.37%\n",
      "Epoch [52/2500], Train Loss: 1.2636, Train Accuracy: 42.82%, Test Loss: 1.1738, Test Accuracy: 49.37%\n",
      "Epoch [53/2500], Train Loss: 1.2768, Train Accuracy: 43.24%, Test Loss: 1.1655, Test Accuracy: 49.37%\n",
      "Epoch [54/2500], Train Loss: 1.2664, Train Accuracy: 43.81%, Test Loss: 1.1630, Test Accuracy: 48.10%\n",
      "Epoch [55/2500], Train Loss: 1.2694, Train Accuracy: 43.67%, Test Loss: 1.1614, Test Accuracy: 49.37%\n",
      "Epoch [56/2500], Train Loss: 1.2587, Train Accuracy: 45.80%, Test Loss: 1.1627, Test Accuracy: 50.63%\n",
      "Epoch [57/2500], Train Loss: 1.2687, Train Accuracy: 45.52%, Test Loss: 1.1631, Test Accuracy: 50.63%\n",
      "Epoch [58/2500], Train Loss: 1.2724, Train Accuracy: 43.24%, Test Loss: 1.1608, Test Accuracy: 48.10%\n",
      "Epoch [59/2500], Train Loss: 1.2635, Train Accuracy: 45.66%, Test Loss: 1.1610, Test Accuracy: 48.10%\n",
      "Epoch [60/2500], Train Loss: 1.2637, Train Accuracy: 44.10%, Test Loss: 1.1555, Test Accuracy: 48.10%\n",
      "Epoch [61/2500], Train Loss: 1.2573, Train Accuracy: 44.52%, Test Loss: 1.1510, Test Accuracy: 48.10%\n",
      "Epoch [62/2500], Train Loss: 1.2407, Train Accuracy: 46.80%, Test Loss: 1.1475, Test Accuracy: 48.10%\n",
      "Epoch [63/2500], Train Loss: 1.2577, Train Accuracy: 45.66%, Test Loss: 1.1430, Test Accuracy: 48.10%\n",
      "Epoch [64/2500], Train Loss: 1.2550, Train Accuracy: 44.67%, Test Loss: 1.1400, Test Accuracy: 48.10%\n",
      "Epoch [65/2500], Train Loss: 1.2463, Train Accuracy: 45.52%, Test Loss: 1.1395, Test Accuracy: 48.10%\n",
      "Epoch [66/2500], Train Loss: 1.2519, Train Accuracy: 44.52%, Test Loss: 1.1387, Test Accuracy: 48.10%\n",
      "Epoch [67/2500], Train Loss: 1.2441, Train Accuracy: 45.80%, Test Loss: 1.1374, Test Accuracy: 49.37%\n",
      "Epoch [68/2500], Train Loss: 1.2381, Train Accuracy: 46.51%, Test Loss: 1.1331, Test Accuracy: 48.10%\n",
      "Epoch [69/2500], Train Loss: 1.2457, Train Accuracy: 45.38%, Test Loss: 1.1321, Test Accuracy: 48.10%\n",
      "Epoch [70/2500], Train Loss: 1.2388, Train Accuracy: 46.37%, Test Loss: 1.1303, Test Accuracy: 48.10%\n",
      "Epoch [71/2500], Train Loss: 1.2354, Train Accuracy: 47.23%, Test Loss: 1.1268, Test Accuracy: 48.10%\n",
      "Epoch [72/2500], Train Loss: 1.2445, Train Accuracy: 45.52%, Test Loss: 1.1221, Test Accuracy: 48.10%\n",
      "Epoch [73/2500], Train Loss: 1.2448, Train Accuracy: 46.09%, Test Loss: 1.1194, Test Accuracy: 48.10%\n",
      "Epoch [74/2500], Train Loss: 1.2581, Train Accuracy: 44.24%, Test Loss: 1.1181, Test Accuracy: 48.10%\n",
      "Epoch [75/2500], Train Loss: 1.2363, Train Accuracy: 46.37%, Test Loss: 1.1141, Test Accuracy: 48.10%\n",
      "Epoch [76/2500], Train Loss: 1.2232, Train Accuracy: 48.51%, Test Loss: 1.1142, Test Accuracy: 48.10%\n",
      "Epoch [77/2500], Train Loss: 1.2249, Train Accuracy: 46.80%, Test Loss: 1.1113, Test Accuracy: 48.10%\n",
      "Epoch [78/2500], Train Loss: 1.2328, Train Accuracy: 48.08%, Test Loss: 1.1085, Test Accuracy: 48.10%\n",
      "Epoch [79/2500], Train Loss: 1.2307, Train Accuracy: 46.80%, Test Loss: 1.1070, Test Accuracy: 48.10%\n",
      "Epoch [80/2500], Train Loss: 1.2283, Train Accuracy: 45.66%, Test Loss: 1.1035, Test Accuracy: 48.10%\n",
      "Epoch [81/2500], Train Loss: 1.2185, Train Accuracy: 47.08%, Test Loss: 1.1026, Test Accuracy: 48.10%\n",
      "Epoch [82/2500], Train Loss: 1.2047, Train Accuracy: 48.79%, Test Loss: 1.1048, Test Accuracy: 48.10%\n",
      "Epoch [83/2500], Train Loss: 1.2257, Train Accuracy: 47.37%, Test Loss: 1.1016, Test Accuracy: 48.10%\n",
      "Epoch [84/2500], Train Loss: 1.2325, Train Accuracy: 46.09%, Test Loss: 1.0997, Test Accuracy: 48.10%\n",
      "Epoch [85/2500], Train Loss: 1.2173, Train Accuracy: 45.95%, Test Loss: 1.0969, Test Accuracy: 48.10%\n",
      "Epoch [86/2500], Train Loss: 1.2203, Train Accuracy: 47.37%, Test Loss: 1.0978, Test Accuracy: 48.10%\n",
      "Epoch [87/2500], Train Loss: 1.2135, Train Accuracy: 47.80%, Test Loss: 1.0974, Test Accuracy: 48.10%\n",
      "Epoch [88/2500], Train Loss: 1.2102, Train Accuracy: 48.79%, Test Loss: 1.0979, Test Accuracy: 48.10%\n",
      "Epoch [89/2500], Train Loss: 1.2097, Train Accuracy: 47.23%, Test Loss: 1.0973, Test Accuracy: 49.37%\n",
      "Epoch [90/2500], Train Loss: 1.2153, Train Accuracy: 47.23%, Test Loss: 1.0984, Test Accuracy: 49.37%\n",
      "Epoch [91/2500], Train Loss: 1.2242, Train Accuracy: 46.51%, Test Loss: 1.0986, Test Accuracy: 49.37%\n",
      "Epoch [92/2500], Train Loss: 1.2151, Train Accuracy: 47.51%, Test Loss: 1.0968, Test Accuracy: 49.37%\n",
      "Epoch [93/2500], Train Loss: 1.2029, Train Accuracy: 50.07%, Test Loss: 1.0970, Test Accuracy: 49.37%\n",
      "Epoch [94/2500], Train Loss: 1.2070, Train Accuracy: 49.22%, Test Loss: 1.0949, Test Accuracy: 49.37%\n",
      "Epoch [95/2500], Train Loss: 1.2154, Train Accuracy: 47.65%, Test Loss: 1.0983, Test Accuracy: 49.37%\n",
      "Epoch [96/2500], Train Loss: 1.1963, Train Accuracy: 47.94%, Test Loss: 1.1001, Test Accuracy: 49.37%\n",
      "Epoch [97/2500], Train Loss: 1.1943, Train Accuracy: 47.80%, Test Loss: 1.0946, Test Accuracy: 49.37%\n",
      "Epoch [98/2500], Train Loss: 1.1894, Train Accuracy: 49.22%, Test Loss: 1.0940, Test Accuracy: 48.10%\n",
      "Epoch [99/2500], Train Loss: 1.1955, Train Accuracy: 49.64%, Test Loss: 1.0904, Test Accuracy: 49.37%\n",
      "Epoch [100/2500], Train Loss: 1.1972, Train Accuracy: 48.08%, Test Loss: 1.0937, Test Accuracy: 49.37%\n",
      "Epoch [101/2500], Train Loss: 1.2041, Train Accuracy: 46.94%, Test Loss: 1.0912, Test Accuracy: 49.37%\n",
      "Epoch [102/2500], Train Loss: 1.1962, Train Accuracy: 48.22%, Test Loss: 1.0864, Test Accuracy: 48.10%\n",
      "Epoch [103/2500], Train Loss: 1.2055, Train Accuracy: 46.80%, Test Loss: 1.0853, Test Accuracy: 49.37%\n",
      "Epoch [104/2500], Train Loss: 1.1910, Train Accuracy: 48.51%, Test Loss: 1.0834, Test Accuracy: 48.10%\n",
      "Epoch [105/2500], Train Loss: 1.2007, Train Accuracy: 48.22%, Test Loss: 1.0794, Test Accuracy: 49.37%\n",
      "Epoch [106/2500], Train Loss: 1.1752, Train Accuracy: 48.93%, Test Loss: 1.0823, Test Accuracy: 49.37%\n",
      "Epoch [107/2500], Train Loss: 1.1914, Train Accuracy: 49.36%, Test Loss: 1.0792, Test Accuracy: 49.37%\n",
      "Epoch [108/2500], Train Loss: 1.1785, Train Accuracy: 48.93%, Test Loss: 1.0774, Test Accuracy: 48.10%\n",
      "Epoch [109/2500], Train Loss: 1.1934, Train Accuracy: 48.36%, Test Loss: 1.0807, Test Accuracy: 49.37%\n",
      "Epoch [110/2500], Train Loss: 1.1823, Train Accuracy: 49.36%, Test Loss: 1.0749, Test Accuracy: 49.37%\n",
      "Epoch [111/2500], Train Loss: 1.1887, Train Accuracy: 46.80%, Test Loss: 1.0706, Test Accuracy: 49.37%\n",
      "Epoch [112/2500], Train Loss: 1.1803, Train Accuracy: 49.64%, Test Loss: 1.0682, Test Accuracy: 46.84%\n",
      "Epoch [113/2500], Train Loss: 1.1812, Train Accuracy: 50.21%, Test Loss: 1.0663, Test Accuracy: 46.84%\n",
      "Epoch [114/2500], Train Loss: 1.1715, Train Accuracy: 50.21%, Test Loss: 1.0655, Test Accuracy: 48.10%\n",
      "Epoch [115/2500], Train Loss: 1.1725, Train Accuracy: 50.36%, Test Loss: 1.0613, Test Accuracy: 48.10%\n",
      "Epoch [116/2500], Train Loss: 1.1637, Train Accuracy: 50.36%, Test Loss: 1.0611, Test Accuracy: 49.37%\n",
      "Epoch [117/2500], Train Loss: 1.1561, Train Accuracy: 51.21%, Test Loss: 1.0614, Test Accuracy: 49.37%\n",
      "Epoch [118/2500], Train Loss: 1.1781, Train Accuracy: 49.93%, Test Loss: 1.0590, Test Accuracy: 50.63%\n",
      "Epoch [119/2500], Train Loss: 1.1435, Train Accuracy: 52.49%, Test Loss: 1.0628, Test Accuracy: 50.63%\n",
      "Epoch [120/2500], Train Loss: 1.1774, Train Accuracy: 49.22%, Test Loss: 1.0577, Test Accuracy: 50.63%\n",
      "Epoch [121/2500], Train Loss: 1.1729, Train Accuracy: 49.64%, Test Loss: 1.0604, Test Accuracy: 49.37%\n",
      "Epoch [122/2500], Train Loss: 1.1755, Train Accuracy: 50.07%, Test Loss: 1.0575, Test Accuracy: 50.63%\n",
      "Epoch [123/2500], Train Loss: 1.1726, Train Accuracy: 50.36%, Test Loss: 1.0556, Test Accuracy: 51.90%\n",
      "Epoch [124/2500], Train Loss: 1.1617, Train Accuracy: 49.36%, Test Loss: 1.0560, Test Accuracy: 50.63%\n",
      "Epoch [125/2500], Train Loss: 1.1670, Train Accuracy: 50.07%, Test Loss: 1.0530, Test Accuracy: 49.37%\n",
      "Epoch [126/2500], Train Loss: 1.1519, Train Accuracy: 49.79%, Test Loss: 1.0542, Test Accuracy: 50.63%\n",
      "Epoch [127/2500], Train Loss: 1.1636, Train Accuracy: 51.49%, Test Loss: 1.0523, Test Accuracy: 50.63%\n",
      "Epoch [128/2500], Train Loss: 1.1707, Train Accuracy: 50.78%, Test Loss: 1.0490, Test Accuracy: 50.63%\n",
      "Epoch [129/2500], Train Loss: 1.1507, Train Accuracy: 50.78%, Test Loss: 1.0513, Test Accuracy: 49.37%\n",
      "Epoch [130/2500], Train Loss: 1.1607, Train Accuracy: 49.79%, Test Loss: 1.0521, Test Accuracy: 49.37%\n",
      "Epoch [131/2500], Train Loss: 1.1734, Train Accuracy: 49.08%, Test Loss: 1.0498, Test Accuracy: 49.37%\n",
      "Epoch [132/2500], Train Loss: 1.1497, Train Accuracy: 50.36%, Test Loss: 1.0446, Test Accuracy: 50.63%\n",
      "Epoch [133/2500], Train Loss: 1.1396, Train Accuracy: 51.92%, Test Loss: 1.0438, Test Accuracy: 51.90%\n",
      "Epoch [134/2500], Train Loss: 1.1402, Train Accuracy: 52.92%, Test Loss: 1.0472, Test Accuracy: 51.90%\n",
      "Epoch [135/2500], Train Loss: 1.1538, Train Accuracy: 50.92%, Test Loss: 1.0455, Test Accuracy: 51.90%\n",
      "Epoch [136/2500], Train Loss: 1.1592, Train Accuracy: 51.92%, Test Loss: 1.0434, Test Accuracy: 53.16%\n",
      "Epoch [137/2500], Train Loss: 1.1462, Train Accuracy: 53.20%, Test Loss: 1.0460, Test Accuracy: 51.90%\n",
      "Epoch [138/2500], Train Loss: 1.1478, Train Accuracy: 51.35%, Test Loss: 1.0455, Test Accuracy: 51.90%\n",
      "Epoch [139/2500], Train Loss: 1.1409, Train Accuracy: 51.49%, Test Loss: 1.0409, Test Accuracy: 51.90%\n",
      "Epoch [140/2500], Train Loss: 1.1414, Train Accuracy: 52.63%, Test Loss: 1.0420, Test Accuracy: 53.16%\n",
      "Epoch [141/2500], Train Loss: 1.1322, Train Accuracy: 51.92%, Test Loss: 1.0375, Test Accuracy: 54.43%\n",
      "Epoch [142/2500], Train Loss: 1.1322, Train Accuracy: 52.77%, Test Loss: 1.0417, Test Accuracy: 53.16%\n",
      "Epoch [143/2500], Train Loss: 1.1468, Train Accuracy: 52.06%, Test Loss: 1.0391, Test Accuracy: 50.63%\n",
      "Epoch [144/2500], Train Loss: 1.1366, Train Accuracy: 51.78%, Test Loss: 1.0351, Test Accuracy: 50.63%\n",
      "Epoch [145/2500], Train Loss: 1.1437, Train Accuracy: 52.63%, Test Loss: 1.0407, Test Accuracy: 51.90%\n",
      "Epoch [146/2500], Train Loss: 1.1272, Train Accuracy: 52.49%, Test Loss: 1.0348, Test Accuracy: 51.90%\n",
      "Epoch [147/2500], Train Loss: 1.1337, Train Accuracy: 49.93%, Test Loss: 1.0373, Test Accuracy: 53.16%\n",
      "Epoch [148/2500], Train Loss: 1.1204, Train Accuracy: 52.77%, Test Loss: 1.0350, Test Accuracy: 53.16%\n",
      "Epoch [149/2500], Train Loss: 1.1270, Train Accuracy: 52.92%, Test Loss: 1.0306, Test Accuracy: 53.16%\n",
      "Epoch [150/2500], Train Loss: 1.1362, Train Accuracy: 53.20%, Test Loss: 1.0288, Test Accuracy: 53.16%\n",
      "Epoch [151/2500], Train Loss: 1.1098, Train Accuracy: 53.49%, Test Loss: 1.0275, Test Accuracy: 53.16%\n",
      "Epoch [152/2500], Train Loss: 1.1129, Train Accuracy: 52.92%, Test Loss: 1.0330, Test Accuracy: 53.16%\n",
      "Epoch [153/2500], Train Loss: 1.1281, Train Accuracy: 51.35%, Test Loss: 1.0290, Test Accuracy: 53.16%\n",
      "Epoch [154/2500], Train Loss: 1.1261, Train Accuracy: 51.78%, Test Loss: 1.0231, Test Accuracy: 53.16%\n",
      "Epoch [155/2500], Train Loss: 1.1264, Train Accuracy: 53.49%, Test Loss: 1.0230, Test Accuracy: 53.16%\n",
      "Epoch [156/2500], Train Loss: 1.1293, Train Accuracy: 51.49%, Test Loss: 1.0186, Test Accuracy: 53.16%\n",
      "Epoch [157/2500], Train Loss: 1.1200, Train Accuracy: 52.20%, Test Loss: 1.0147, Test Accuracy: 54.43%\n",
      "Epoch [158/2500], Train Loss: 1.1160, Train Accuracy: 53.77%, Test Loss: 1.0157, Test Accuracy: 53.16%\n",
      "Epoch [159/2500], Train Loss: 1.1160, Train Accuracy: 54.20%, Test Loss: 1.0219, Test Accuracy: 53.16%\n",
      "Epoch [160/2500], Train Loss: 1.1001, Train Accuracy: 52.63%, Test Loss: 1.0170, Test Accuracy: 53.16%\n",
      "Epoch [161/2500], Train Loss: 1.1192, Train Accuracy: 53.91%, Test Loss: 1.0176, Test Accuracy: 53.16%\n",
      "Epoch [162/2500], Train Loss: 1.1134, Train Accuracy: 53.20%, Test Loss: 1.0137, Test Accuracy: 53.16%\n",
      "Epoch [163/2500], Train Loss: 1.1149, Train Accuracy: 51.64%, Test Loss: 1.0130, Test Accuracy: 54.43%\n",
      "Epoch [164/2500], Train Loss: 1.1065, Train Accuracy: 53.77%, Test Loss: 1.0116, Test Accuracy: 54.43%\n",
      "Epoch [165/2500], Train Loss: 1.1151, Train Accuracy: 53.49%, Test Loss: 1.0100, Test Accuracy: 55.70%\n",
      "Epoch [166/2500], Train Loss: 1.1055, Train Accuracy: 53.77%, Test Loss: 1.0096, Test Accuracy: 55.70%\n",
      "Epoch [167/2500], Train Loss: 1.1061, Train Accuracy: 54.48%, Test Loss: 1.0047, Test Accuracy: 56.96%\n",
      "Epoch [168/2500], Train Loss: 1.1155, Train Accuracy: 53.20%, Test Loss: 1.0020, Test Accuracy: 56.96%\n",
      "Epoch [169/2500], Train Loss: 1.1265, Train Accuracy: 52.35%, Test Loss: 0.9974, Test Accuracy: 56.96%\n",
      "Epoch [170/2500], Train Loss: 1.1013, Train Accuracy: 53.63%, Test Loss: 0.9986, Test Accuracy: 56.96%\n",
      "Epoch [171/2500], Train Loss: 1.1024, Train Accuracy: 52.92%, Test Loss: 1.0035, Test Accuracy: 56.96%\n",
      "Epoch [172/2500], Train Loss: 1.1015, Train Accuracy: 53.91%, Test Loss: 0.9971, Test Accuracy: 56.96%\n",
      "Epoch [173/2500], Train Loss: 1.1067, Train Accuracy: 52.77%, Test Loss: 0.9920, Test Accuracy: 56.96%\n",
      "Epoch [174/2500], Train Loss: 1.1104, Train Accuracy: 53.06%, Test Loss: 0.9907, Test Accuracy: 56.96%\n",
      "Epoch [175/2500], Train Loss: 1.0951, Train Accuracy: 53.63%, Test Loss: 0.9971, Test Accuracy: 56.96%\n",
      "Epoch [176/2500], Train Loss: 1.0819, Train Accuracy: 54.77%, Test Loss: 1.0003, Test Accuracy: 56.96%\n",
      "Epoch [177/2500], Train Loss: 1.0856, Train Accuracy: 53.91%, Test Loss: 0.9963, Test Accuracy: 56.96%\n",
      "Epoch [178/2500], Train Loss: 1.0914, Train Accuracy: 54.91%, Test Loss: 0.9980, Test Accuracy: 56.96%\n",
      "Epoch [179/2500], Train Loss: 1.0964, Train Accuracy: 53.34%, Test Loss: 0.9933, Test Accuracy: 56.96%\n",
      "Epoch [180/2500], Train Loss: 1.0823, Train Accuracy: 54.77%, Test Loss: 0.9898, Test Accuracy: 58.23%\n",
      "Epoch [181/2500], Train Loss: 1.0920, Train Accuracy: 54.34%, Test Loss: 0.9878, Test Accuracy: 56.96%\n",
      "Epoch [182/2500], Train Loss: 1.0816, Train Accuracy: 54.48%, Test Loss: 0.9851, Test Accuracy: 58.23%\n",
      "Epoch [183/2500], Train Loss: 1.0916, Train Accuracy: 54.20%, Test Loss: 0.9897, Test Accuracy: 58.23%\n",
      "Epoch [184/2500], Train Loss: 1.0792, Train Accuracy: 54.91%, Test Loss: 0.9845, Test Accuracy: 58.23%\n",
      "Epoch [185/2500], Train Loss: 1.0781, Train Accuracy: 54.34%, Test Loss: 0.9816, Test Accuracy: 58.23%\n",
      "Epoch [186/2500], Train Loss: 1.0904, Train Accuracy: 53.34%, Test Loss: 0.9837, Test Accuracy: 56.96%\n",
      "Epoch [187/2500], Train Loss: 1.0692, Train Accuracy: 56.19%, Test Loss: 0.9852, Test Accuracy: 56.96%\n",
      "Epoch [188/2500], Train Loss: 1.0859, Train Accuracy: 55.19%, Test Loss: 0.9799, Test Accuracy: 56.96%\n",
      "Epoch [189/2500], Train Loss: 1.0801, Train Accuracy: 54.20%, Test Loss: 0.9781, Test Accuracy: 56.96%\n",
      "Epoch [190/2500], Train Loss: 1.0784, Train Accuracy: 54.62%, Test Loss: 0.9815, Test Accuracy: 56.96%\n",
      "Epoch [191/2500], Train Loss: 1.0624, Train Accuracy: 55.76%, Test Loss: 0.9747, Test Accuracy: 58.23%\n",
      "Epoch [192/2500], Train Loss: 1.0885, Train Accuracy: 55.76%, Test Loss: 0.9771, Test Accuracy: 58.23%\n",
      "Epoch [193/2500], Train Loss: 1.0878, Train Accuracy: 55.33%, Test Loss: 0.9778, Test Accuracy: 58.23%\n",
      "Epoch [194/2500], Train Loss: 1.0617, Train Accuracy: 55.90%, Test Loss: 0.9835, Test Accuracy: 56.96%\n",
      "Epoch [195/2500], Train Loss: 1.0788, Train Accuracy: 54.62%, Test Loss: 0.9812, Test Accuracy: 56.96%\n",
      "Epoch [196/2500], Train Loss: 1.0869, Train Accuracy: 53.20%, Test Loss: 0.9747, Test Accuracy: 58.23%\n",
      "Epoch [197/2500], Train Loss: 1.0606, Train Accuracy: 53.49%, Test Loss: 0.9770, Test Accuracy: 58.23%\n",
      "Epoch [198/2500], Train Loss: 1.0750, Train Accuracy: 54.20%, Test Loss: 0.9808, Test Accuracy: 56.96%\n",
      "Epoch [199/2500], Train Loss: 1.0799, Train Accuracy: 54.20%, Test Loss: 0.9812, Test Accuracy: 58.23%\n",
      "Epoch [200/2500], Train Loss: 1.0744, Train Accuracy: 54.34%, Test Loss: 0.9759, Test Accuracy: 58.23%\n",
      "Epoch [201/2500], Train Loss: 1.0641, Train Accuracy: 54.05%, Test Loss: 0.9733, Test Accuracy: 58.23%\n",
      "Epoch [202/2500], Train Loss: 1.0676, Train Accuracy: 56.05%, Test Loss: 0.9698, Test Accuracy: 58.23%\n",
      "Epoch [203/2500], Train Loss: 1.0756, Train Accuracy: 54.91%, Test Loss: 0.9711, Test Accuracy: 56.96%\n",
      "Epoch [204/2500], Train Loss: 1.0505, Train Accuracy: 57.61%, Test Loss: 0.9696, Test Accuracy: 58.23%\n",
      "Epoch [205/2500], Train Loss: 1.0640, Train Accuracy: 54.91%, Test Loss: 0.9735, Test Accuracy: 58.23%\n",
      "Epoch [206/2500], Train Loss: 1.0827, Train Accuracy: 54.62%, Test Loss: 0.9698, Test Accuracy: 58.23%\n",
      "Epoch [207/2500], Train Loss: 1.0816, Train Accuracy: 54.34%, Test Loss: 0.9637, Test Accuracy: 58.23%\n",
      "Epoch [208/2500], Train Loss: 1.0734, Train Accuracy: 53.49%, Test Loss: 0.9651, Test Accuracy: 58.23%\n",
      "Epoch [209/2500], Train Loss: 1.0634, Train Accuracy: 55.62%, Test Loss: 0.9645, Test Accuracy: 58.23%\n",
      "Epoch [210/2500], Train Loss: 1.0670, Train Accuracy: 55.19%, Test Loss: 0.9694, Test Accuracy: 58.23%\n",
      "Epoch [211/2500], Train Loss: 1.0572, Train Accuracy: 55.19%, Test Loss: 0.9692, Test Accuracy: 58.23%\n",
      "Epoch [212/2500], Train Loss: 1.0619, Train Accuracy: 53.91%, Test Loss: 0.9686, Test Accuracy: 58.23%\n",
      "Epoch [213/2500], Train Loss: 1.0988, Train Accuracy: 53.49%, Test Loss: 0.9679, Test Accuracy: 58.23%\n",
      "Epoch [214/2500], Train Loss: 1.0682, Train Accuracy: 55.19%, Test Loss: 0.9668, Test Accuracy: 58.23%\n",
      "Epoch [215/2500], Train Loss: 1.0572, Train Accuracy: 55.05%, Test Loss: 0.9612, Test Accuracy: 58.23%\n",
      "Epoch [216/2500], Train Loss: 1.0529, Train Accuracy: 55.90%, Test Loss: 0.9664, Test Accuracy: 58.23%\n",
      "Epoch [217/2500], Train Loss: 1.0583, Train Accuracy: 54.77%, Test Loss: 0.9646, Test Accuracy: 58.23%\n",
      "Epoch [218/2500], Train Loss: 1.0673, Train Accuracy: 54.77%, Test Loss: 0.9590, Test Accuracy: 58.23%\n",
      "Epoch [219/2500], Train Loss: 1.0698, Train Accuracy: 54.48%, Test Loss: 0.9570, Test Accuracy: 58.23%\n",
      "Epoch [220/2500], Train Loss: 1.0562, Train Accuracy: 55.19%, Test Loss: 0.9563, Test Accuracy: 58.23%\n",
      "Epoch [221/2500], Train Loss: 1.0681, Train Accuracy: 55.19%, Test Loss: 0.9572, Test Accuracy: 58.23%\n",
      "Epoch [222/2500], Train Loss: 1.0535, Train Accuracy: 54.48%, Test Loss: 0.9581, Test Accuracy: 58.23%\n",
      "Epoch [223/2500], Train Loss: 1.0624, Train Accuracy: 55.33%, Test Loss: 0.9480, Test Accuracy: 58.23%\n",
      "Epoch [224/2500], Train Loss: 1.0498, Train Accuracy: 55.90%, Test Loss: 0.9616, Test Accuracy: 58.23%\n",
      "Epoch [225/2500], Train Loss: 1.0511, Train Accuracy: 56.19%, Test Loss: 0.9625, Test Accuracy: 58.23%\n",
      "Epoch [226/2500], Train Loss: 1.0592, Train Accuracy: 54.34%, Test Loss: 0.9606, Test Accuracy: 58.23%\n",
      "Epoch [227/2500], Train Loss: 1.0330, Train Accuracy: 56.76%, Test Loss: 0.9582, Test Accuracy: 58.23%\n",
      "Epoch [228/2500], Train Loss: 1.0597, Train Accuracy: 55.19%, Test Loss: 0.9589, Test Accuracy: 58.23%\n",
      "Epoch [229/2500], Train Loss: 1.0559, Train Accuracy: 55.62%, Test Loss: 0.9604, Test Accuracy: 58.23%\n",
      "Epoch [230/2500], Train Loss: 1.0401, Train Accuracy: 57.04%, Test Loss: 0.9678, Test Accuracy: 58.23%\n",
      "Epoch [231/2500], Train Loss: 1.0471, Train Accuracy: 55.33%, Test Loss: 0.9572, Test Accuracy: 58.23%\n",
      "Epoch [232/2500], Train Loss: 1.0446, Train Accuracy: 56.47%, Test Loss: 0.9590, Test Accuracy: 58.23%\n",
      "Epoch [233/2500], Train Loss: 1.0546, Train Accuracy: 55.62%, Test Loss: 0.9589, Test Accuracy: 58.23%\n",
      "Epoch [234/2500], Train Loss: 1.0501, Train Accuracy: 57.18%, Test Loss: 0.9568, Test Accuracy: 58.23%\n",
      "Epoch [235/2500], Train Loss: 1.0325, Train Accuracy: 55.76%, Test Loss: 0.9631, Test Accuracy: 58.23%\n",
      "Epoch [236/2500], Train Loss: 1.0432, Train Accuracy: 56.61%, Test Loss: 0.9638, Test Accuracy: 58.23%\n",
      "Epoch [237/2500], Train Loss: 1.0479, Train Accuracy: 54.91%, Test Loss: 0.9614, Test Accuracy: 58.23%\n",
      "Epoch [238/2500], Train Loss: 1.0491, Train Accuracy: 56.61%, Test Loss: 0.9558, Test Accuracy: 58.23%\n",
      "Epoch [239/2500], Train Loss: 1.0612, Train Accuracy: 53.91%, Test Loss: 0.9498, Test Accuracy: 58.23%\n",
      "Epoch [240/2500], Train Loss: 1.0541, Train Accuracy: 54.48%, Test Loss: 0.9457, Test Accuracy: 58.23%\n",
      "Epoch [241/2500], Train Loss: 1.0526, Train Accuracy: 53.63%, Test Loss: 0.9542, Test Accuracy: 58.23%\n",
      "Epoch [242/2500], Train Loss: 1.0443, Train Accuracy: 56.05%, Test Loss: 0.9502, Test Accuracy: 58.23%\n",
      "Epoch [243/2500], Train Loss: 1.0389, Train Accuracy: 56.90%, Test Loss: 0.9439, Test Accuracy: 58.23%\n",
      "Epoch [244/2500], Train Loss: 1.0410, Train Accuracy: 56.19%, Test Loss: 0.9441, Test Accuracy: 58.23%\n",
      "Epoch [245/2500], Train Loss: 1.0522, Train Accuracy: 55.62%, Test Loss: 0.9437, Test Accuracy: 58.23%\n",
      "Epoch [246/2500], Train Loss: 1.0373, Train Accuracy: 55.90%, Test Loss: 0.9458, Test Accuracy: 58.23%\n",
      "Epoch [247/2500], Train Loss: 1.0398, Train Accuracy: 55.76%, Test Loss: 0.9471, Test Accuracy: 58.23%\n",
      "Epoch [248/2500], Train Loss: 1.0419, Train Accuracy: 56.33%, Test Loss: 0.9448, Test Accuracy: 58.23%\n",
      "Epoch [249/2500], Train Loss: 1.0454, Train Accuracy: 55.19%, Test Loss: 0.9477, Test Accuracy: 58.23%\n",
      "Epoch [250/2500], Train Loss: 1.0570, Train Accuracy: 56.05%, Test Loss: 0.9624, Test Accuracy: 58.23%\n",
      "Epoch [251/2500], Train Loss: 1.0448, Train Accuracy: 56.61%, Test Loss: 0.9651, Test Accuracy: 58.23%\n",
      "Epoch [252/2500], Train Loss: 1.0424, Train Accuracy: 55.19%, Test Loss: 0.9559, Test Accuracy: 58.23%\n",
      "Epoch [253/2500], Train Loss: 1.0483, Train Accuracy: 55.19%, Test Loss: 0.9517, Test Accuracy: 58.23%\n",
      "Epoch [254/2500], Train Loss: 1.0306, Train Accuracy: 57.89%, Test Loss: 0.9507, Test Accuracy: 58.23%\n",
      "Epoch [255/2500], Train Loss: 1.0211, Train Accuracy: 56.19%, Test Loss: 0.9441, Test Accuracy: 58.23%\n",
      "Epoch [256/2500], Train Loss: 1.0289, Train Accuracy: 56.61%, Test Loss: 0.9479, Test Accuracy: 58.23%\n",
      "Epoch [257/2500], Train Loss: 1.0464, Train Accuracy: 56.05%, Test Loss: 0.9428, Test Accuracy: 58.23%\n",
      "Epoch [258/2500], Train Loss: 1.0384, Train Accuracy: 56.90%, Test Loss: 0.9471, Test Accuracy: 58.23%\n",
      "Epoch [259/2500], Train Loss: 1.0429, Train Accuracy: 56.61%, Test Loss: 0.9537, Test Accuracy: 58.23%\n",
      "Epoch [260/2500], Train Loss: 1.0387, Train Accuracy: 56.33%, Test Loss: 0.9599, Test Accuracy: 58.23%\n",
      "Epoch [261/2500], Train Loss: 1.0447, Train Accuracy: 55.90%, Test Loss: 0.9556, Test Accuracy: 58.23%\n",
      "Epoch [262/2500], Train Loss: 1.0368, Train Accuracy: 56.76%, Test Loss: 0.9508, Test Accuracy: 58.23%\n",
      "Epoch [263/2500], Train Loss: 1.0395, Train Accuracy: 55.90%, Test Loss: 0.9568, Test Accuracy: 58.23%\n",
      "Epoch [264/2500], Train Loss: 1.0191, Train Accuracy: 55.90%, Test Loss: 0.9613, Test Accuracy: 58.23%\n",
      "Epoch [265/2500], Train Loss: 1.0415, Train Accuracy: 55.19%, Test Loss: 0.9608, Test Accuracy: 58.23%\n",
      "Epoch [266/2500], Train Loss: 1.0550, Train Accuracy: 54.91%, Test Loss: 0.9614, Test Accuracy: 58.23%\n",
      "Epoch [267/2500], Train Loss: 1.0052, Train Accuracy: 56.47%, Test Loss: 0.9576, Test Accuracy: 58.23%\n",
      "Epoch [268/2500], Train Loss: 1.0194, Train Accuracy: 57.75%, Test Loss: 0.9591, Test Accuracy: 58.23%\n",
      "Epoch [269/2500], Train Loss: 1.0196, Train Accuracy: 57.75%, Test Loss: 0.9640, Test Accuracy: 58.23%\n",
      "Epoch [270/2500], Train Loss: 1.0362, Train Accuracy: 56.90%, Test Loss: 0.9602, Test Accuracy: 58.23%\n",
      "Epoch [271/2500], Train Loss: 1.0294, Train Accuracy: 56.76%, Test Loss: 0.9574, Test Accuracy: 58.23%\n",
      "Epoch [272/2500], Train Loss: 1.0305, Train Accuracy: 56.76%, Test Loss: 0.9598, Test Accuracy: 58.23%\n",
      "Epoch [273/2500], Train Loss: 1.0157, Train Accuracy: 56.33%, Test Loss: 0.9476, Test Accuracy: 58.23%\n",
      "Epoch [274/2500], Train Loss: 1.0389, Train Accuracy: 56.47%, Test Loss: 0.9590, Test Accuracy: 58.23%\n",
      "Epoch [275/2500], Train Loss: 1.0402, Train Accuracy: 55.48%, Test Loss: 0.9592, Test Accuracy: 58.23%\n",
      "Epoch [276/2500], Train Loss: 1.0325, Train Accuracy: 55.62%, Test Loss: 0.9666, Test Accuracy: 58.23%\n",
      "Epoch [277/2500], Train Loss: 1.0229, Train Accuracy: 56.47%, Test Loss: 0.9630, Test Accuracy: 58.23%\n",
      "Epoch [278/2500], Train Loss: 1.0228, Train Accuracy: 55.76%, Test Loss: 0.9592, Test Accuracy: 58.23%\n",
      "Epoch [279/2500], Train Loss: 1.0233, Train Accuracy: 56.61%, Test Loss: 0.9575, Test Accuracy: 58.23%\n",
      "Epoch [280/2500], Train Loss: 1.0194, Train Accuracy: 56.47%, Test Loss: 0.9603, Test Accuracy: 58.23%\n",
      "Epoch [281/2500], Train Loss: 1.0312, Train Accuracy: 55.62%, Test Loss: 0.9539, Test Accuracy: 58.23%\n",
      "Epoch [282/2500], Train Loss: 1.0390, Train Accuracy: 55.48%, Test Loss: 0.9535, Test Accuracy: 58.23%\n",
      "Epoch [283/2500], Train Loss: 1.0179, Train Accuracy: 56.76%, Test Loss: 0.9550, Test Accuracy: 59.49%\n",
      "Epoch [284/2500], Train Loss: 1.0230, Train Accuracy: 55.62%, Test Loss: 0.9484, Test Accuracy: 59.49%\n",
      "Epoch [285/2500], Train Loss: 1.0160, Train Accuracy: 56.47%, Test Loss: 0.9437, Test Accuracy: 59.49%\n",
      "Epoch [286/2500], Train Loss: 1.0176, Train Accuracy: 55.76%, Test Loss: 0.9385, Test Accuracy: 58.23%\n",
      "Epoch [287/2500], Train Loss: 1.0120, Train Accuracy: 55.62%, Test Loss: 0.9319, Test Accuracy: 58.23%\n",
      "Epoch [288/2500], Train Loss: 1.0190, Train Accuracy: 56.05%, Test Loss: 0.9312, Test Accuracy: 58.23%\n",
      "Epoch [289/2500], Train Loss: 1.0132, Train Accuracy: 56.19%, Test Loss: 0.9308, Test Accuracy: 58.23%\n",
      "Epoch [290/2500], Train Loss: 1.0099, Train Accuracy: 56.90%, Test Loss: 0.9339, Test Accuracy: 59.49%\n",
      "Epoch [291/2500], Train Loss: 1.0206, Train Accuracy: 56.47%, Test Loss: 0.9416, Test Accuracy: 59.49%\n",
      "Epoch [292/2500], Train Loss: 1.0279, Train Accuracy: 55.05%, Test Loss: 0.9321, Test Accuracy: 59.49%\n",
      "Epoch [293/2500], Train Loss: 1.0210, Train Accuracy: 56.76%, Test Loss: 0.9296, Test Accuracy: 58.23%\n",
      "Epoch [294/2500], Train Loss: 1.0200, Train Accuracy: 55.62%, Test Loss: 0.9286, Test Accuracy: 59.49%\n",
      "Epoch [295/2500], Train Loss: 1.0331, Train Accuracy: 55.90%, Test Loss: 0.9356, Test Accuracy: 59.49%\n",
      "Epoch [296/2500], Train Loss: 1.0269, Train Accuracy: 56.47%, Test Loss: 0.9417, Test Accuracy: 59.49%\n",
      "Epoch [297/2500], Train Loss: 1.0173, Train Accuracy: 56.76%, Test Loss: 0.9447, Test Accuracy: 58.23%\n",
      "Epoch [298/2500], Train Loss: 1.0322, Train Accuracy: 55.33%, Test Loss: 0.9507, Test Accuracy: 59.49%\n",
      "Epoch [299/2500], Train Loss: 1.0372, Train Accuracy: 55.19%, Test Loss: 0.9528, Test Accuracy: 59.49%\n",
      "Epoch [300/2500], Train Loss: 1.0218, Train Accuracy: 56.61%, Test Loss: 0.9472, Test Accuracy: 59.49%\n",
      "Epoch [301/2500], Train Loss: 1.0235, Train Accuracy: 56.33%, Test Loss: 0.9451, Test Accuracy: 59.49%\n",
      "Epoch [302/2500], Train Loss: 1.0189, Train Accuracy: 56.90%, Test Loss: 0.9421, Test Accuracy: 59.49%\n",
      "Epoch [303/2500], Train Loss: 0.9902, Train Accuracy: 57.04%, Test Loss: 0.9431, Test Accuracy: 59.49%\n",
      "Epoch [304/2500], Train Loss: 1.0036, Train Accuracy: 57.33%, Test Loss: 0.9516, Test Accuracy: 59.49%\n",
      "Epoch [305/2500], Train Loss: 1.0325, Train Accuracy: 55.48%, Test Loss: 0.9439, Test Accuracy: 58.23%\n",
      "Epoch [306/2500], Train Loss: 1.0167, Train Accuracy: 55.90%, Test Loss: 0.9489, Test Accuracy: 58.23%\n",
      "Epoch [307/2500], Train Loss: 1.0262, Train Accuracy: 56.19%, Test Loss: 0.9481, Test Accuracy: 59.49%\n",
      "Epoch [308/2500], Train Loss: 1.0052, Train Accuracy: 55.48%, Test Loss: 0.9442, Test Accuracy: 59.49%\n",
      "Epoch [309/2500], Train Loss: 1.0270, Train Accuracy: 55.62%, Test Loss: 0.9532, Test Accuracy: 59.49%\n",
      "Epoch [310/2500], Train Loss: 1.0119, Train Accuracy: 56.76%, Test Loss: 0.9645, Test Accuracy: 58.23%\n",
      "Epoch [311/2500], Train Loss: 1.0129, Train Accuracy: 56.47%, Test Loss: 0.9578, Test Accuracy: 58.23%\n",
      "Epoch [312/2500], Train Loss: 1.0048, Train Accuracy: 56.61%, Test Loss: 0.9461, Test Accuracy: 58.23%\n",
      "Epoch [313/2500], Train Loss: 1.0199, Train Accuracy: 56.90%, Test Loss: 0.9450, Test Accuracy: 59.49%\n",
      "Epoch [314/2500], Train Loss: 1.0032, Train Accuracy: 56.90%, Test Loss: 0.9498, Test Accuracy: 59.49%\n",
      "Epoch [315/2500], Train Loss: 0.9921, Train Accuracy: 56.61%, Test Loss: 0.9437, Test Accuracy: 59.49%\n",
      "Epoch [316/2500], Train Loss: 1.0183, Train Accuracy: 55.90%, Test Loss: 0.9485, Test Accuracy: 59.49%\n",
      "Epoch [317/2500], Train Loss: 1.0153, Train Accuracy: 56.33%, Test Loss: 0.9546, Test Accuracy: 59.49%\n",
      "Epoch [318/2500], Train Loss: 1.0111, Train Accuracy: 56.76%, Test Loss: 0.9496, Test Accuracy: 59.49%\n",
      "Epoch [319/2500], Train Loss: 1.0097, Train Accuracy: 56.33%, Test Loss: 0.9541, Test Accuracy: 59.49%\n",
      "Epoch [320/2500], Train Loss: 1.0162, Train Accuracy: 56.19%, Test Loss: 0.9375, Test Accuracy: 59.49%\n",
      "Epoch [321/2500], Train Loss: 1.0173, Train Accuracy: 57.18%, Test Loss: 0.9490, Test Accuracy: 59.49%\n",
      "Epoch [322/2500], Train Loss: 1.0055, Train Accuracy: 56.19%, Test Loss: 0.9539, Test Accuracy: 59.49%\n",
      "Epoch [323/2500], Train Loss: 1.0130, Train Accuracy: 56.90%, Test Loss: 0.9666, Test Accuracy: 58.23%\n",
      "Epoch [324/2500], Train Loss: 1.0070, Train Accuracy: 56.33%, Test Loss: 0.9696, Test Accuracy: 59.49%\n",
      "Epoch [325/2500], Train Loss: 1.0238, Train Accuracy: 56.76%, Test Loss: 0.9621, Test Accuracy: 58.23%\n",
      "Epoch [326/2500], Train Loss: 1.0093, Train Accuracy: 56.47%, Test Loss: 0.9609, Test Accuracy: 58.23%\n",
      "Epoch [327/2500], Train Loss: 1.0208, Train Accuracy: 55.19%, Test Loss: 0.9618, Test Accuracy: 58.23%\n",
      "Epoch [328/2500], Train Loss: 1.0033, Train Accuracy: 56.61%, Test Loss: 0.9612, Test Accuracy: 58.23%\n",
      "Epoch [329/2500], Train Loss: 1.0055, Train Accuracy: 57.18%, Test Loss: 0.9607, Test Accuracy: 58.23%\n",
      "Epoch [330/2500], Train Loss: 0.9981, Train Accuracy: 56.61%, Test Loss: 0.9567, Test Accuracy: 58.23%\n",
      "Epoch [331/2500], Train Loss: 1.0039, Train Accuracy: 56.19%, Test Loss: 0.9617, Test Accuracy: 58.23%\n",
      "Epoch [332/2500], Train Loss: 1.0034, Train Accuracy: 57.04%, Test Loss: 0.9569, Test Accuracy: 58.23%\n",
      "Epoch [333/2500], Train Loss: 1.0048, Train Accuracy: 56.33%, Test Loss: 0.9553, Test Accuracy: 59.49%\n",
      "Epoch [334/2500], Train Loss: 1.0084, Train Accuracy: 57.89%, Test Loss: 0.9535, Test Accuracy: 59.49%\n",
      "Epoch [335/2500], Train Loss: 1.0139, Train Accuracy: 57.18%, Test Loss: 0.9604, Test Accuracy: 59.49%\n",
      "Epoch [336/2500], Train Loss: 1.0005, Train Accuracy: 57.61%, Test Loss: 0.9590, Test Accuracy: 59.49%\n",
      "Epoch [337/2500], Train Loss: 0.9925, Train Accuracy: 58.46%, Test Loss: 0.9568, Test Accuracy: 59.49%\n",
      "Epoch [338/2500], Train Loss: 0.9917, Train Accuracy: 57.18%, Test Loss: 0.9455, Test Accuracy: 59.49%\n",
      "Epoch [339/2500], Train Loss: 1.0076, Train Accuracy: 56.90%, Test Loss: 0.9515, Test Accuracy: 59.49%\n",
      "Epoch [340/2500], Train Loss: 1.0066, Train Accuracy: 57.75%, Test Loss: 0.9480, Test Accuracy: 59.49%\n",
      "Epoch [341/2500], Train Loss: 0.9988, Train Accuracy: 57.04%, Test Loss: 0.9360, Test Accuracy: 59.49%\n",
      "Epoch [342/2500], Train Loss: 1.0085, Train Accuracy: 56.05%, Test Loss: 0.9291, Test Accuracy: 59.49%\n",
      "Epoch [343/2500], Train Loss: 0.9950, Train Accuracy: 57.04%, Test Loss: 0.9327, Test Accuracy: 59.49%\n",
      "Epoch [344/2500], Train Loss: 1.0105, Train Accuracy: 55.76%, Test Loss: 0.9390, Test Accuracy: 59.49%\n",
      "Epoch [345/2500], Train Loss: 0.9931, Train Accuracy: 57.75%, Test Loss: 0.9384, Test Accuracy: 59.49%\n",
      "Epoch [346/2500], Train Loss: 1.0035, Train Accuracy: 56.61%, Test Loss: 0.9421, Test Accuracy: 58.23%\n",
      "Epoch [347/2500], Train Loss: 1.0139, Train Accuracy: 56.61%, Test Loss: 0.9453, Test Accuracy: 58.23%\n",
      "Epoch [348/2500], Train Loss: 0.9831, Train Accuracy: 57.18%, Test Loss: 0.9448, Test Accuracy: 58.23%\n",
      "Epoch [349/2500], Train Loss: 0.9810, Train Accuracy: 58.61%, Test Loss: 0.9524, Test Accuracy: 59.49%\n",
      "Epoch [350/2500], Train Loss: 0.9754, Train Accuracy: 57.47%, Test Loss: 0.9444, Test Accuracy: 59.49%\n",
      "Epoch [351/2500], Train Loss: 0.9968, Train Accuracy: 58.18%, Test Loss: 0.9479, Test Accuracy: 59.49%\n",
      "Epoch [352/2500], Train Loss: 0.9880, Train Accuracy: 57.18%, Test Loss: 0.9542, Test Accuracy: 59.49%\n",
      "Epoch [353/2500], Train Loss: 0.9927, Train Accuracy: 56.19%, Test Loss: 0.9565, Test Accuracy: 59.49%\n",
      "Epoch [354/2500], Train Loss: 1.0135, Train Accuracy: 56.76%, Test Loss: 0.9453, Test Accuracy: 59.49%\n",
      "Epoch [355/2500], Train Loss: 0.9919, Train Accuracy: 57.33%, Test Loss: 0.9492, Test Accuracy: 59.49%\n",
      "Epoch [356/2500], Train Loss: 0.9949, Train Accuracy: 56.90%, Test Loss: 0.9502, Test Accuracy: 59.49%\n",
      "Epoch [357/2500], Train Loss: 1.0212, Train Accuracy: 56.33%, Test Loss: 0.9428, Test Accuracy: 59.49%\n",
      "Epoch [358/2500], Train Loss: 0.9963, Train Accuracy: 56.47%, Test Loss: 0.9583, Test Accuracy: 59.49%\n",
      "Epoch [359/2500], Train Loss: 1.0003, Train Accuracy: 57.04%, Test Loss: 0.9591, Test Accuracy: 59.49%\n",
      "Epoch [360/2500], Train Loss: 1.0048, Train Accuracy: 56.90%, Test Loss: 0.9398, Test Accuracy: 59.49%\n",
      "Epoch [361/2500], Train Loss: 0.9985, Train Accuracy: 57.18%, Test Loss: 0.9376, Test Accuracy: 59.49%\n",
      "Epoch [362/2500], Train Loss: 0.9871, Train Accuracy: 57.75%, Test Loss: 0.9461, Test Accuracy: 59.49%\n",
      "Epoch [363/2500], Train Loss: 1.0031, Train Accuracy: 57.61%, Test Loss: 0.9412, Test Accuracy: 59.49%\n",
      "Epoch [364/2500], Train Loss: 1.0013, Train Accuracy: 57.33%, Test Loss: 0.9365, Test Accuracy: 59.49%\n",
      "Epoch [365/2500], Train Loss: 1.0124, Train Accuracy: 57.89%, Test Loss: 0.9349, Test Accuracy: 59.49%\n",
      "Epoch [366/2500], Train Loss: 1.0015, Train Accuracy: 56.61%, Test Loss: 0.9380, Test Accuracy: 59.49%\n",
      "Epoch [367/2500], Train Loss: 1.0127, Train Accuracy: 56.61%, Test Loss: 0.9396, Test Accuracy: 59.49%\n",
      "Epoch [368/2500], Train Loss: 1.0090, Train Accuracy: 56.76%, Test Loss: 0.9361, Test Accuracy: 59.49%\n",
      "Epoch [369/2500], Train Loss: 1.0044, Train Accuracy: 56.76%, Test Loss: 0.9228, Test Accuracy: 59.49%\n",
      "Epoch [370/2500], Train Loss: 1.0085, Train Accuracy: 56.47%, Test Loss: 0.9360, Test Accuracy: 59.49%\n",
      "Epoch [371/2500], Train Loss: 1.0181, Train Accuracy: 56.19%, Test Loss: 0.9326, Test Accuracy: 59.49%\n",
      "Epoch [372/2500], Train Loss: 0.9923, Train Accuracy: 57.18%, Test Loss: 0.9405, Test Accuracy: 59.49%\n",
      "Epoch [373/2500], Train Loss: 0.9978, Train Accuracy: 57.33%, Test Loss: 0.9410, Test Accuracy: 59.49%\n",
      "Epoch [374/2500], Train Loss: 1.0008, Train Accuracy: 57.61%, Test Loss: 0.9457, Test Accuracy: 59.49%\n",
      "Epoch [375/2500], Train Loss: 0.9991, Train Accuracy: 55.62%, Test Loss: 0.9451, Test Accuracy: 59.49%\n",
      "Epoch [376/2500], Train Loss: 0.9867, Train Accuracy: 57.04%, Test Loss: 0.9360, Test Accuracy: 59.49%\n",
      "Epoch [377/2500], Train Loss: 0.9966, Train Accuracy: 57.04%, Test Loss: 0.9357, Test Accuracy: 59.49%\n",
      "Epoch [378/2500], Train Loss: 0.9893, Train Accuracy: 56.61%, Test Loss: 0.9397, Test Accuracy: 59.49%\n",
      "Epoch [379/2500], Train Loss: 1.0056, Train Accuracy: 57.47%, Test Loss: 0.9411, Test Accuracy: 59.49%\n",
      "Epoch [380/2500], Train Loss: 0.9984, Train Accuracy: 57.33%, Test Loss: 0.9341, Test Accuracy: 59.49%\n",
      "Epoch [381/2500], Train Loss: 0.9963, Train Accuracy: 56.90%, Test Loss: 0.9427, Test Accuracy: 59.49%\n",
      "Epoch [382/2500], Train Loss: 0.9759, Train Accuracy: 56.90%, Test Loss: 0.9467, Test Accuracy: 59.49%\n",
      "Epoch [383/2500], Train Loss: 1.0060, Train Accuracy: 57.04%, Test Loss: 0.9490, Test Accuracy: 59.49%\n",
      "Epoch [384/2500], Train Loss: 1.0089, Train Accuracy: 56.33%, Test Loss: 0.9368, Test Accuracy: 59.49%\n",
      "Epoch [385/2500], Train Loss: 0.9905, Train Accuracy: 56.90%, Test Loss: 0.9455, Test Accuracy: 59.49%\n",
      "Epoch [386/2500], Train Loss: 0.9996, Train Accuracy: 56.47%, Test Loss: 0.9365, Test Accuracy: 59.49%\n",
      "Epoch [387/2500], Train Loss: 1.0016, Train Accuracy: 56.61%, Test Loss: 0.9340, Test Accuracy: 59.49%\n",
      "Epoch [388/2500], Train Loss: 0.9869, Train Accuracy: 57.04%, Test Loss: 0.9287, Test Accuracy: 59.49%\n",
      "Epoch [389/2500], Train Loss: 0.9766, Train Accuracy: 58.18%, Test Loss: 0.9326, Test Accuracy: 59.49%\n",
      "Epoch [390/2500], Train Loss: 0.9888, Train Accuracy: 57.04%, Test Loss: 0.9313, Test Accuracy: 59.49%\n",
      "Epoch [391/2500], Train Loss: 0.9947, Train Accuracy: 57.18%, Test Loss: 0.9308, Test Accuracy: 59.49%\n",
      "Epoch [392/2500], Train Loss: 0.9884, Train Accuracy: 57.61%, Test Loss: 0.9297, Test Accuracy: 59.49%\n",
      "Epoch [393/2500], Train Loss: 0.9913, Train Accuracy: 58.04%, Test Loss: 0.9323, Test Accuracy: 59.49%\n",
      "Epoch [394/2500], Train Loss: 0.9877, Train Accuracy: 57.18%, Test Loss: 0.9353, Test Accuracy: 59.49%\n",
      "Epoch [395/2500], Train Loss: 1.0015, Train Accuracy: 57.18%, Test Loss: 0.9393, Test Accuracy: 59.49%\n",
      "Epoch [396/2500], Train Loss: 0.9930, Train Accuracy: 56.47%, Test Loss: 0.9390, Test Accuracy: 59.49%\n",
      "Epoch [397/2500], Train Loss: 0.9851, Train Accuracy: 57.61%, Test Loss: 0.9409, Test Accuracy: 59.49%\n",
      "Epoch [398/2500], Train Loss: 0.9932, Train Accuracy: 57.04%, Test Loss: 0.9334, Test Accuracy: 59.49%\n",
      "Epoch [399/2500], Train Loss: 0.9807, Train Accuracy: 57.75%, Test Loss: 0.9522, Test Accuracy: 59.49%\n",
      "Epoch [400/2500], Train Loss: 0.9945, Train Accuracy: 56.90%, Test Loss: 0.9343, Test Accuracy: 59.49%\n",
      "Epoch [401/2500], Train Loss: 0.9778, Train Accuracy: 57.75%, Test Loss: 0.9345, Test Accuracy: 59.49%\n",
      "Epoch [402/2500], Train Loss: 1.0015, Train Accuracy: 56.61%, Test Loss: 0.9291, Test Accuracy: 59.49%\n",
      "Epoch [403/2500], Train Loss: 0.9966, Train Accuracy: 56.90%, Test Loss: 0.9320, Test Accuracy: 59.49%\n",
      "Epoch [404/2500], Train Loss: 0.9824, Train Accuracy: 57.75%, Test Loss: 0.9348, Test Accuracy: 59.49%\n",
      "Epoch [405/2500], Train Loss: 0.9988, Train Accuracy: 56.05%, Test Loss: 0.9293, Test Accuracy: 59.49%\n",
      "Epoch [406/2500], Train Loss: 0.9782, Train Accuracy: 56.90%, Test Loss: 0.9306, Test Accuracy: 59.49%\n",
      "Epoch [407/2500], Train Loss: 0.9814, Train Accuracy: 56.90%, Test Loss: 0.9374, Test Accuracy: 59.49%\n",
      "Epoch [408/2500], Train Loss: 0.9928, Train Accuracy: 57.61%, Test Loss: 0.9391, Test Accuracy: 59.49%\n",
      "Epoch [409/2500], Train Loss: 0.9829, Train Accuracy: 57.75%, Test Loss: 0.9359, Test Accuracy: 59.49%\n",
      "Epoch [410/2500], Train Loss: 0.9738, Train Accuracy: 57.33%, Test Loss: 0.9406, Test Accuracy: 59.49%\n",
      "Epoch [411/2500], Train Loss: 0.9694, Train Accuracy: 57.18%, Test Loss: 0.9328, Test Accuracy: 59.49%\n",
      "Epoch [412/2500], Train Loss: 1.0064, Train Accuracy: 57.18%, Test Loss: 0.9314, Test Accuracy: 59.49%\n",
      "Epoch [413/2500], Train Loss: 0.9942, Train Accuracy: 57.18%, Test Loss: 0.9357, Test Accuracy: 59.49%\n",
      "Epoch [414/2500], Train Loss: 0.9602, Train Accuracy: 57.61%, Test Loss: 0.9353, Test Accuracy: 59.49%\n",
      "Epoch [415/2500], Train Loss: 0.9812, Train Accuracy: 56.05%, Test Loss: 0.9294, Test Accuracy: 59.49%\n",
      "Epoch [416/2500], Train Loss: 0.9927, Train Accuracy: 56.90%, Test Loss: 0.9352, Test Accuracy: 59.49%\n",
      "Epoch [417/2500], Train Loss: 1.0036, Train Accuracy: 56.05%, Test Loss: 0.9329, Test Accuracy: 59.49%\n",
      "Epoch [418/2500], Train Loss: 0.9830, Train Accuracy: 57.89%, Test Loss: 0.9308, Test Accuracy: 59.49%\n",
      "Epoch [419/2500], Train Loss: 0.9927, Train Accuracy: 58.04%, Test Loss: 0.9316, Test Accuracy: 59.49%\n",
      "Epoch [420/2500], Train Loss: 0.9784, Train Accuracy: 58.04%, Test Loss: 0.9286, Test Accuracy: 59.49%\n",
      "Epoch [421/2500], Train Loss: 0.9950, Train Accuracy: 56.76%, Test Loss: 0.9312, Test Accuracy: 59.49%\n",
      "Epoch [422/2500], Train Loss: 0.9840, Train Accuracy: 57.89%, Test Loss: 0.9303, Test Accuracy: 59.49%\n",
      "Epoch [423/2500], Train Loss: 0.9906, Train Accuracy: 55.90%, Test Loss: 0.9251, Test Accuracy: 59.49%\n",
      "Epoch [424/2500], Train Loss: 0.9923, Train Accuracy: 56.05%, Test Loss: 0.9283, Test Accuracy: 59.49%\n",
      "Epoch [425/2500], Train Loss: 0.9992, Train Accuracy: 56.19%, Test Loss: 0.9350, Test Accuracy: 59.49%\n",
      "Epoch [426/2500], Train Loss: 1.0004, Train Accuracy: 56.47%, Test Loss: 0.9344, Test Accuracy: 59.49%\n",
      "Epoch [427/2500], Train Loss: 0.9941, Train Accuracy: 56.61%, Test Loss: 0.9342, Test Accuracy: 59.49%\n",
      "Epoch [428/2500], Train Loss: 0.9930, Train Accuracy: 57.18%, Test Loss: 0.9303, Test Accuracy: 59.49%\n",
      "Epoch [429/2500], Train Loss: 0.9816, Train Accuracy: 56.76%, Test Loss: 0.9313, Test Accuracy: 59.49%\n",
      "Epoch [430/2500], Train Loss: 0.9658, Train Accuracy: 57.75%, Test Loss: 0.9275, Test Accuracy: 59.49%\n",
      "Epoch [431/2500], Train Loss: 0.9910, Train Accuracy: 57.33%, Test Loss: 0.9324, Test Accuracy: 59.49%\n",
      "Epoch [432/2500], Train Loss: 0.9940, Train Accuracy: 56.76%, Test Loss: 0.9363, Test Accuracy: 59.49%\n",
      "Epoch [433/2500], Train Loss: 0.9929, Train Accuracy: 57.18%, Test Loss: 0.9295, Test Accuracy: 59.49%\n",
      "Epoch [434/2500], Train Loss: 0.9762, Train Accuracy: 57.61%, Test Loss: 0.9370, Test Accuracy: 59.49%\n",
      "Epoch [435/2500], Train Loss: 0.9894, Train Accuracy: 57.61%, Test Loss: 0.9268, Test Accuracy: 59.49%\n",
      "Epoch [436/2500], Train Loss: 0.9877, Train Accuracy: 57.75%, Test Loss: 0.9325, Test Accuracy: 59.49%\n",
      "Epoch [437/2500], Train Loss: 0.9826, Train Accuracy: 56.61%, Test Loss: 0.9305, Test Accuracy: 59.49%\n",
      "Epoch [438/2500], Train Loss: 0.9762, Train Accuracy: 57.18%, Test Loss: 0.9358, Test Accuracy: 59.49%\n",
      "Epoch [439/2500], Train Loss: 0.9903, Train Accuracy: 57.18%, Test Loss: 0.9570, Test Accuracy: 59.49%\n",
      "Epoch [440/2500], Train Loss: 0.9773, Train Accuracy: 56.61%, Test Loss: 0.9413, Test Accuracy: 59.49%\n",
      "Epoch [441/2500], Train Loss: 0.9831, Train Accuracy: 57.75%, Test Loss: 0.9287, Test Accuracy: 59.49%\n",
      "Epoch [442/2500], Train Loss: 0.9767, Train Accuracy: 57.89%, Test Loss: 0.9256, Test Accuracy: 59.49%\n",
      "Epoch [443/2500], Train Loss: 0.9851, Train Accuracy: 58.18%, Test Loss: 0.9246, Test Accuracy: 59.49%\n",
      "Epoch [444/2500], Train Loss: 0.9728, Train Accuracy: 58.18%, Test Loss: 0.9303, Test Accuracy: 59.49%\n",
      "Epoch [445/2500], Train Loss: 0.9947, Train Accuracy: 57.18%, Test Loss: 0.9332, Test Accuracy: 59.49%\n",
      "Epoch [446/2500], Train Loss: 0.9805, Train Accuracy: 57.33%, Test Loss: 0.9372, Test Accuracy: 59.49%\n",
      "Epoch [447/2500], Train Loss: 0.9890, Train Accuracy: 58.18%, Test Loss: 0.9348, Test Accuracy: 59.49%\n",
      "Epoch [448/2500], Train Loss: 0.9892, Train Accuracy: 57.47%, Test Loss: 0.9319, Test Accuracy: 59.49%\n",
      "Epoch [449/2500], Train Loss: 0.9980, Train Accuracy: 57.89%, Test Loss: 0.9303, Test Accuracy: 59.49%\n",
      "Epoch [450/2500], Train Loss: 0.9854, Train Accuracy: 56.61%, Test Loss: 0.9315, Test Accuracy: 59.49%\n",
      "Epoch [451/2500], Train Loss: 0.9694, Train Accuracy: 57.04%, Test Loss: 0.9363, Test Accuracy: 59.49%\n",
      "Epoch [452/2500], Train Loss: 0.9946, Train Accuracy: 57.04%, Test Loss: 0.9364, Test Accuracy: 59.49%\n",
      "Epoch [453/2500], Train Loss: 0.9761, Train Accuracy: 56.90%, Test Loss: 0.9331, Test Accuracy: 59.49%\n",
      "Epoch [454/2500], Train Loss: 0.9910, Train Accuracy: 57.75%, Test Loss: 0.9321, Test Accuracy: 60.76%\n",
      "Epoch [455/2500], Train Loss: 0.9951, Train Accuracy: 57.33%, Test Loss: 0.9252, Test Accuracy: 60.76%\n",
      "Epoch [456/2500], Train Loss: 0.9892, Train Accuracy: 56.90%, Test Loss: 0.9257, Test Accuracy: 60.76%\n",
      "Epoch [457/2500], Train Loss: 0.9698, Train Accuracy: 57.89%, Test Loss: 0.9314, Test Accuracy: 60.76%\n",
      "Epoch [458/2500], Train Loss: 0.9849, Train Accuracy: 57.47%, Test Loss: 0.9390, Test Accuracy: 60.76%\n",
      "Epoch [459/2500], Train Loss: 0.9801, Train Accuracy: 58.46%, Test Loss: 0.9328, Test Accuracy: 59.49%\n",
      "Epoch [460/2500], Train Loss: 0.9625, Train Accuracy: 56.76%, Test Loss: 0.9314, Test Accuracy: 59.49%\n",
      "Epoch [461/2500], Train Loss: 0.9751, Train Accuracy: 56.76%, Test Loss: 0.9324, Test Accuracy: 59.49%\n",
      "Epoch [462/2500], Train Loss: 0.9770, Train Accuracy: 56.61%, Test Loss: 0.9328, Test Accuracy: 59.49%\n",
      "Epoch [463/2500], Train Loss: 0.9789, Train Accuracy: 57.47%, Test Loss: 0.9287, Test Accuracy: 60.76%\n",
      "Epoch [464/2500], Train Loss: 0.9797, Train Accuracy: 57.61%, Test Loss: 0.9304, Test Accuracy: 59.49%\n",
      "Epoch [465/2500], Train Loss: 0.9682, Train Accuracy: 57.18%, Test Loss: 0.9364, Test Accuracy: 59.49%\n",
      "Epoch [466/2500], Train Loss: 0.9701, Train Accuracy: 58.46%, Test Loss: 0.9314, Test Accuracy: 60.76%\n",
      "Epoch [467/2500], Train Loss: 0.9697, Train Accuracy: 57.75%, Test Loss: 0.9250, Test Accuracy: 60.76%\n",
      "Epoch [468/2500], Train Loss: 0.9745, Train Accuracy: 57.18%, Test Loss: 0.9185, Test Accuracy: 60.76%\n",
      "Epoch [469/2500], Train Loss: 0.9936, Train Accuracy: 57.61%, Test Loss: 0.9167, Test Accuracy: 60.76%\n",
      "Epoch [470/2500], Train Loss: 0.9794, Train Accuracy: 57.18%, Test Loss: 0.9209, Test Accuracy: 60.76%\n",
      "Epoch [471/2500], Train Loss: 0.9817, Train Accuracy: 57.61%, Test Loss: 0.9399, Test Accuracy: 60.76%\n",
      "Epoch [472/2500], Train Loss: 0.9840, Train Accuracy: 56.76%, Test Loss: 0.9390, Test Accuracy: 60.76%\n",
      "Epoch [473/2500], Train Loss: 0.9781, Train Accuracy: 57.61%, Test Loss: 0.9318, Test Accuracy: 60.76%\n",
      "Epoch [474/2500], Train Loss: 0.9848, Train Accuracy: 56.76%, Test Loss: 0.9282, Test Accuracy: 60.76%\n",
      "Epoch [475/2500], Train Loss: 0.9791, Train Accuracy: 57.89%, Test Loss: 0.9275, Test Accuracy: 60.76%\n",
      "Epoch [476/2500], Train Loss: 0.9756, Train Accuracy: 57.89%, Test Loss: 0.9288, Test Accuracy: 60.76%\n",
      "Epoch [477/2500], Train Loss: 0.9844, Train Accuracy: 57.04%, Test Loss: 0.9220, Test Accuracy: 60.76%\n",
      "Epoch [478/2500], Train Loss: 0.9656, Train Accuracy: 57.18%, Test Loss: 0.9244, Test Accuracy: 60.76%\n",
      "Epoch [479/2500], Train Loss: 0.9699, Train Accuracy: 57.04%, Test Loss: 0.9273, Test Accuracy: 60.76%\n",
      "Epoch [480/2500], Train Loss: 0.9683, Train Accuracy: 57.18%, Test Loss: 0.9303, Test Accuracy: 60.76%\n",
      "Epoch [481/2500], Train Loss: 0.9785, Train Accuracy: 56.33%, Test Loss: 0.9355, Test Accuracy: 60.76%\n",
      "Epoch [482/2500], Train Loss: 0.9715, Train Accuracy: 57.04%, Test Loss: 0.9417, Test Accuracy: 60.76%\n",
      "Epoch [483/2500], Train Loss: 0.9644, Train Accuracy: 57.47%, Test Loss: 0.9323, Test Accuracy: 60.76%\n",
      "Epoch [484/2500], Train Loss: 0.9735, Train Accuracy: 57.61%, Test Loss: 0.9328, Test Accuracy: 60.76%\n",
      "Epoch [485/2500], Train Loss: 0.9645, Train Accuracy: 57.89%, Test Loss: 0.9296, Test Accuracy: 60.76%\n",
      "Epoch [486/2500], Train Loss: 0.9854, Train Accuracy: 57.18%, Test Loss: 0.9312, Test Accuracy: 60.76%\n",
      "Epoch [487/2500], Train Loss: 0.9869, Train Accuracy: 58.04%, Test Loss: 0.9361, Test Accuracy: 60.76%\n",
      "Epoch [488/2500], Train Loss: 0.9756, Train Accuracy: 58.04%, Test Loss: 0.9374, Test Accuracy: 60.76%\n",
      "Epoch [489/2500], Train Loss: 0.9747, Train Accuracy: 57.04%, Test Loss: 0.9364, Test Accuracy: 60.76%\n",
      "Epoch [490/2500], Train Loss: 0.9837, Train Accuracy: 57.89%, Test Loss: 0.9353, Test Accuracy: 60.76%\n",
      "Epoch [491/2500], Train Loss: 0.9743, Train Accuracy: 58.04%, Test Loss: 0.9325, Test Accuracy: 60.76%\n",
      "Epoch [492/2500], Train Loss: 0.9753, Train Accuracy: 57.04%, Test Loss: 0.9411, Test Accuracy: 60.76%\n",
      "Epoch [493/2500], Train Loss: 0.9706, Train Accuracy: 57.47%, Test Loss: 0.9347, Test Accuracy: 60.76%\n",
      "Epoch [494/2500], Train Loss: 0.9757, Train Accuracy: 57.89%, Test Loss: 0.9308, Test Accuracy: 60.76%\n",
      "Epoch [495/2500], Train Loss: 0.9601, Train Accuracy: 57.47%, Test Loss: 0.9306, Test Accuracy: 60.76%\n",
      "Epoch [496/2500], Train Loss: 0.9585, Train Accuracy: 58.04%, Test Loss: 0.9311, Test Accuracy: 60.76%\n",
      "Epoch [497/2500], Train Loss: 0.9720, Train Accuracy: 57.18%, Test Loss: 0.9371, Test Accuracy: 60.76%\n",
      "Epoch [498/2500], Train Loss: 0.9736, Train Accuracy: 56.05%, Test Loss: 0.9298, Test Accuracy: 60.76%\n",
      "Epoch [499/2500], Train Loss: 0.9606, Train Accuracy: 58.61%, Test Loss: 0.9317, Test Accuracy: 60.76%\n",
      "Epoch [500/2500], Train Loss: 0.9804, Train Accuracy: 56.76%, Test Loss: 0.9366, Test Accuracy: 60.76%\n",
      "Epoch [501/2500], Train Loss: 0.9756, Train Accuracy: 56.61%, Test Loss: 0.9363, Test Accuracy: 60.76%\n",
      "Epoch [502/2500], Train Loss: 0.9855, Train Accuracy: 57.61%, Test Loss: 0.9287, Test Accuracy: 60.76%\n",
      "Epoch [503/2500], Train Loss: 0.9591, Train Accuracy: 57.04%, Test Loss: 0.9262, Test Accuracy: 60.76%\n",
      "Epoch [504/2500], Train Loss: 0.9780, Train Accuracy: 55.90%, Test Loss: 0.9292, Test Accuracy: 60.76%\n",
      "Epoch [505/2500], Train Loss: 0.9662, Train Accuracy: 57.33%, Test Loss: 0.9416, Test Accuracy: 60.76%\n",
      "Epoch [506/2500], Train Loss: 0.9790, Train Accuracy: 57.18%, Test Loss: 0.9344, Test Accuracy: 60.76%\n",
      "Epoch [507/2500], Train Loss: 0.9553, Train Accuracy: 57.33%, Test Loss: 0.9351, Test Accuracy: 60.76%\n",
      "Epoch [508/2500], Train Loss: 0.9773, Train Accuracy: 57.61%, Test Loss: 0.9230, Test Accuracy: 60.76%\n",
      "Epoch [509/2500], Train Loss: 0.9647, Train Accuracy: 57.04%, Test Loss: 0.9225, Test Accuracy: 60.76%\n",
      "Epoch [510/2500], Train Loss: 0.9859, Train Accuracy: 57.18%, Test Loss: 0.9207, Test Accuracy: 59.49%\n",
      "Epoch [511/2500], Train Loss: 0.9734, Train Accuracy: 58.32%, Test Loss: 0.9291, Test Accuracy: 60.76%\n",
      "Epoch [512/2500], Train Loss: 0.9568, Train Accuracy: 57.47%, Test Loss: 0.9240, Test Accuracy: 60.76%\n",
      "Epoch [513/2500], Train Loss: 0.9810, Train Accuracy: 57.61%, Test Loss: 0.9292, Test Accuracy: 59.49%\n",
      "Epoch [514/2500], Train Loss: 0.9827, Train Accuracy: 56.76%, Test Loss: 0.9315, Test Accuracy: 60.76%\n",
      "Epoch [515/2500], Train Loss: 0.9654, Train Accuracy: 57.04%, Test Loss: 0.9281, Test Accuracy: 59.49%\n",
      "Epoch [516/2500], Train Loss: 0.9755, Train Accuracy: 57.61%, Test Loss: 0.9226, Test Accuracy: 60.76%\n",
      "Epoch [517/2500], Train Loss: 0.9708, Train Accuracy: 57.61%, Test Loss: 0.9177, Test Accuracy: 60.76%\n",
      "Epoch [518/2500], Train Loss: 0.9870, Train Accuracy: 56.05%, Test Loss: 0.9217, Test Accuracy: 60.76%\n",
      "Epoch [519/2500], Train Loss: 0.9726, Train Accuracy: 57.04%, Test Loss: 0.9306, Test Accuracy: 60.76%\n",
      "Epoch [520/2500], Train Loss: 0.9588, Train Accuracy: 58.32%, Test Loss: 0.9289, Test Accuracy: 60.76%\n",
      "Epoch [521/2500], Train Loss: 0.9661, Train Accuracy: 57.61%, Test Loss: 0.9302, Test Accuracy: 60.76%\n",
      "Epoch [522/2500], Train Loss: 0.9656, Train Accuracy: 58.75%, Test Loss: 0.9370, Test Accuracy: 60.76%\n",
      "Epoch [523/2500], Train Loss: 0.9684, Train Accuracy: 56.33%, Test Loss: 0.9431, Test Accuracy: 60.76%\n",
      "Epoch [524/2500], Train Loss: 0.9718, Train Accuracy: 57.89%, Test Loss: 0.9361, Test Accuracy: 60.76%\n",
      "Epoch [525/2500], Train Loss: 0.9601, Train Accuracy: 57.18%, Test Loss: 0.9292, Test Accuracy: 60.76%\n",
      "Epoch [526/2500], Train Loss: 0.9743, Train Accuracy: 58.04%, Test Loss: 0.9203, Test Accuracy: 60.76%\n",
      "Epoch [527/2500], Train Loss: 0.9805, Train Accuracy: 57.04%, Test Loss: 0.9184, Test Accuracy: 60.76%\n",
      "Epoch [528/2500], Train Loss: 0.9678, Train Accuracy: 56.61%, Test Loss: 0.9238, Test Accuracy: 60.76%\n",
      "Epoch [529/2500], Train Loss: 0.9549, Train Accuracy: 57.89%, Test Loss: 0.9396, Test Accuracy: 60.76%\n",
      "Epoch [530/2500], Train Loss: 0.9734, Train Accuracy: 57.89%, Test Loss: 0.9242, Test Accuracy: 60.76%\n",
      "Epoch [531/2500], Train Loss: 0.9758, Train Accuracy: 56.90%, Test Loss: 0.9208, Test Accuracy: 60.76%\n",
      "Epoch [532/2500], Train Loss: 0.9741, Train Accuracy: 57.75%, Test Loss: 0.9278, Test Accuracy: 60.76%\n",
      "Epoch [533/2500], Train Loss: 0.9669, Train Accuracy: 56.61%, Test Loss: 0.9283, Test Accuracy: 60.76%\n",
      "Epoch [534/2500], Train Loss: 0.9636, Train Accuracy: 57.33%, Test Loss: 0.9354, Test Accuracy: 60.76%\n",
      "Epoch [535/2500], Train Loss: 0.9585, Train Accuracy: 57.89%, Test Loss: 0.9218, Test Accuracy: 60.76%\n",
      "Epoch [536/2500], Train Loss: 0.9748, Train Accuracy: 57.61%, Test Loss: 0.9265, Test Accuracy: 60.76%\n",
      "Epoch [537/2500], Train Loss: 0.9560, Train Accuracy: 58.04%, Test Loss: 0.9233, Test Accuracy: 60.76%\n",
      "Epoch [538/2500], Train Loss: 0.9758, Train Accuracy: 58.32%, Test Loss: 0.9219, Test Accuracy: 60.76%\n",
      "Epoch [539/2500], Train Loss: 0.9698, Train Accuracy: 57.47%, Test Loss: 0.9218, Test Accuracy: 60.76%\n",
      "Epoch [540/2500], Train Loss: 0.9700, Train Accuracy: 57.61%, Test Loss: 0.9253, Test Accuracy: 60.76%\n",
      "Epoch [541/2500], Train Loss: 0.9563, Train Accuracy: 58.04%, Test Loss: 0.9237, Test Accuracy: 60.76%\n",
      "Epoch [542/2500], Train Loss: 0.9576, Train Accuracy: 56.61%, Test Loss: 0.9292, Test Accuracy: 60.76%\n",
      "Epoch [543/2500], Train Loss: 0.9765, Train Accuracy: 57.04%, Test Loss: 0.9253, Test Accuracy: 60.76%\n",
      "Epoch [544/2500], Train Loss: 0.9635, Train Accuracy: 58.75%, Test Loss: 0.9241, Test Accuracy: 60.76%\n",
      "Epoch [545/2500], Train Loss: 0.9588, Train Accuracy: 58.46%, Test Loss: 0.9150, Test Accuracy: 60.76%\n",
      "Epoch [546/2500], Train Loss: 0.9749, Train Accuracy: 57.47%, Test Loss: 0.9232, Test Accuracy: 60.76%\n",
      "Epoch [547/2500], Train Loss: 0.9612, Train Accuracy: 57.89%, Test Loss: 0.9221, Test Accuracy: 60.76%\n",
      "Epoch [548/2500], Train Loss: 0.9543, Train Accuracy: 57.04%, Test Loss: 0.9142, Test Accuracy: 60.76%\n",
      "Epoch [549/2500], Train Loss: 0.9731, Train Accuracy: 58.18%, Test Loss: 0.9196, Test Accuracy: 60.76%\n",
      "Epoch [550/2500], Train Loss: 0.9728, Train Accuracy: 56.76%, Test Loss: 0.9242, Test Accuracy: 60.76%\n",
      "Epoch [551/2500], Train Loss: 0.9743, Train Accuracy: 58.18%, Test Loss: 0.9180, Test Accuracy: 60.76%\n",
      "Epoch [552/2500], Train Loss: 0.9684, Train Accuracy: 57.18%, Test Loss: 0.9165, Test Accuracy: 60.76%\n",
      "Epoch [553/2500], Train Loss: 0.9619, Train Accuracy: 57.89%, Test Loss: 0.9143, Test Accuracy: 60.76%\n",
      "Epoch [554/2500], Train Loss: 0.9677, Train Accuracy: 58.04%, Test Loss: 0.9206, Test Accuracy: 60.76%\n",
      "Epoch [555/2500], Train Loss: 0.9706, Train Accuracy: 57.04%, Test Loss: 0.9186, Test Accuracy: 60.76%\n",
      "Epoch [556/2500], Train Loss: 0.9458, Train Accuracy: 57.18%, Test Loss: 0.9266, Test Accuracy: 60.76%\n",
      "Epoch [557/2500], Train Loss: 0.9620, Train Accuracy: 57.75%, Test Loss: 0.9257, Test Accuracy: 60.76%\n",
      "Epoch [558/2500], Train Loss: 0.9645, Train Accuracy: 58.32%, Test Loss: 0.9233, Test Accuracy: 60.76%\n",
      "Epoch [559/2500], Train Loss: 0.9570, Train Accuracy: 58.46%, Test Loss: 0.9202, Test Accuracy: 60.76%\n",
      "Epoch [560/2500], Train Loss: 0.9580, Train Accuracy: 58.32%, Test Loss: 0.9193, Test Accuracy: 60.76%\n",
      "Epoch [561/2500], Train Loss: 0.9671, Train Accuracy: 57.33%, Test Loss: 0.9148, Test Accuracy: 60.76%\n",
      "Epoch [562/2500], Train Loss: 0.9532, Train Accuracy: 57.61%, Test Loss: 0.9148, Test Accuracy: 60.76%\n",
      "Epoch [563/2500], Train Loss: 0.9672, Train Accuracy: 56.61%, Test Loss: 0.9203, Test Accuracy: 60.76%\n",
      "Epoch [564/2500], Train Loss: 0.9620, Train Accuracy: 57.47%, Test Loss: 0.9240, Test Accuracy: 60.76%\n",
      "Epoch [565/2500], Train Loss: 0.9680, Train Accuracy: 57.89%, Test Loss: 0.9271, Test Accuracy: 60.76%\n",
      "Epoch [566/2500], Train Loss: 0.9715, Train Accuracy: 57.75%, Test Loss: 0.9222, Test Accuracy: 60.76%\n",
      "Epoch [567/2500], Train Loss: 0.9768, Train Accuracy: 57.04%, Test Loss: 0.9269, Test Accuracy: 60.76%\n",
      "Epoch [568/2500], Train Loss: 0.9525, Train Accuracy: 58.61%, Test Loss: 0.9208, Test Accuracy: 60.76%\n",
      "Epoch [569/2500], Train Loss: 0.9621, Train Accuracy: 57.47%, Test Loss: 0.9203, Test Accuracy: 60.76%\n",
      "Epoch [570/2500], Train Loss: 0.9438, Train Accuracy: 58.61%, Test Loss: 0.9234, Test Accuracy: 60.76%\n",
      "Epoch [571/2500], Train Loss: 0.9579, Train Accuracy: 59.32%, Test Loss: 0.9212, Test Accuracy: 60.76%\n",
      "Epoch [572/2500], Train Loss: 0.9540, Train Accuracy: 57.89%, Test Loss: 0.9283, Test Accuracy: 60.76%\n",
      "Epoch [573/2500], Train Loss: 0.9563, Train Accuracy: 57.33%, Test Loss: 0.9233, Test Accuracy: 60.76%\n",
      "Epoch [574/2500], Train Loss: 0.9709, Train Accuracy: 57.47%, Test Loss: 0.9236, Test Accuracy: 60.76%\n",
      "Epoch [575/2500], Train Loss: 0.9531, Train Accuracy: 58.46%, Test Loss: 0.9219, Test Accuracy: 60.76%\n",
      "Epoch [576/2500], Train Loss: 0.9604, Train Accuracy: 58.32%, Test Loss: 0.9224, Test Accuracy: 60.76%\n",
      "Epoch [577/2500], Train Loss: 0.9538, Train Accuracy: 58.46%, Test Loss: 0.9204, Test Accuracy: 60.76%\n",
      "Epoch [578/2500], Train Loss: 0.9726, Train Accuracy: 57.61%, Test Loss: 0.9212, Test Accuracy: 60.76%\n",
      "Epoch [579/2500], Train Loss: 0.9484, Train Accuracy: 58.75%, Test Loss: 0.9278, Test Accuracy: 60.76%\n",
      "Epoch [580/2500], Train Loss: 0.9498, Train Accuracy: 57.33%, Test Loss: 0.9268, Test Accuracy: 60.76%\n",
      "Epoch [581/2500], Train Loss: 0.9713, Train Accuracy: 56.90%, Test Loss: 0.9232, Test Accuracy: 60.76%\n",
      "Epoch [582/2500], Train Loss: 0.9662, Train Accuracy: 57.18%, Test Loss: 0.9215, Test Accuracy: 60.76%\n",
      "Epoch [583/2500], Train Loss: 0.9541, Train Accuracy: 56.61%, Test Loss: 0.9216, Test Accuracy: 60.76%\n",
      "Epoch [584/2500], Train Loss: 0.9572, Train Accuracy: 58.75%, Test Loss: 0.9212, Test Accuracy: 60.76%\n",
      "Epoch [585/2500], Train Loss: 0.9464, Train Accuracy: 57.75%, Test Loss: 0.9247, Test Accuracy: 60.76%\n",
      "Epoch [586/2500], Train Loss: 0.9485, Train Accuracy: 56.90%, Test Loss: 0.9243, Test Accuracy: 60.76%\n",
      "Epoch [587/2500], Train Loss: 0.9499, Train Accuracy: 58.89%, Test Loss: 0.9227, Test Accuracy: 60.76%\n",
      "Epoch [588/2500], Train Loss: 0.9707, Train Accuracy: 57.18%, Test Loss: 0.9201, Test Accuracy: 60.76%\n",
      "Epoch [589/2500], Train Loss: 0.9490, Train Accuracy: 57.61%, Test Loss: 0.9246, Test Accuracy: 60.76%\n",
      "Epoch [590/2500], Train Loss: 0.9459, Train Accuracy: 58.18%, Test Loss: 0.9249, Test Accuracy: 60.76%\n",
      "Epoch [591/2500], Train Loss: 0.9726, Train Accuracy: 57.47%, Test Loss: 0.9231, Test Accuracy: 60.76%\n",
      "Epoch [592/2500], Train Loss: 0.9588, Train Accuracy: 58.61%, Test Loss: 0.9291, Test Accuracy: 60.76%\n",
      "Epoch [593/2500], Train Loss: 0.9554, Train Accuracy: 58.32%, Test Loss: 0.9279, Test Accuracy: 60.76%\n",
      "Epoch [594/2500], Train Loss: 0.9507, Train Accuracy: 57.75%, Test Loss: 0.9237, Test Accuracy: 60.76%\n",
      "Epoch [595/2500], Train Loss: 0.9688, Train Accuracy: 58.18%, Test Loss: 0.9166, Test Accuracy: 60.76%\n",
      "Epoch [596/2500], Train Loss: 0.9559, Train Accuracy: 57.18%, Test Loss: 0.9211, Test Accuracy: 60.76%\n",
      "Epoch [597/2500], Train Loss: 0.9502, Train Accuracy: 58.46%, Test Loss: 0.9208, Test Accuracy: 60.76%\n",
      "Epoch [598/2500], Train Loss: 0.9506, Train Accuracy: 59.03%, Test Loss: 0.9222, Test Accuracy: 60.76%\n",
      "Epoch [599/2500], Train Loss: 0.9571, Train Accuracy: 58.32%, Test Loss: 0.9193, Test Accuracy: 60.76%\n",
      "Epoch [600/2500], Train Loss: 0.9611, Train Accuracy: 57.75%, Test Loss: 0.9203, Test Accuracy: 60.76%\n",
      "Epoch [601/2500], Train Loss: 0.9447, Train Accuracy: 58.04%, Test Loss: 0.9224, Test Accuracy: 60.76%\n",
      "Epoch [602/2500], Train Loss: 0.9277, Train Accuracy: 58.32%, Test Loss: 0.9181, Test Accuracy: 60.76%\n",
      "Epoch [603/2500], Train Loss: 0.9576, Train Accuracy: 58.32%, Test Loss: 0.9236, Test Accuracy: 60.76%\n",
      "Epoch [604/2500], Train Loss: 0.9609, Train Accuracy: 57.75%, Test Loss: 0.9226, Test Accuracy: 60.76%\n",
      "Epoch [605/2500], Train Loss: 0.9378, Train Accuracy: 59.74%, Test Loss: 0.9225, Test Accuracy: 60.76%\n",
      "Epoch [606/2500], Train Loss: 0.9487, Train Accuracy: 57.75%, Test Loss: 0.9327, Test Accuracy: 60.76%\n",
      "Epoch [607/2500], Train Loss: 0.9500, Train Accuracy: 58.18%, Test Loss: 0.9224, Test Accuracy: 60.76%\n",
      "Epoch [608/2500], Train Loss: 0.9498, Train Accuracy: 57.75%, Test Loss: 0.9274, Test Accuracy: 60.76%\n",
      "Epoch [609/2500], Train Loss: 0.9618, Train Accuracy: 58.04%, Test Loss: 0.9213, Test Accuracy: 60.76%\n",
      "Epoch [610/2500], Train Loss: 0.9497, Train Accuracy: 59.32%, Test Loss: 0.9197, Test Accuracy: 60.76%\n",
      "Epoch [611/2500], Train Loss: 0.9707, Train Accuracy: 57.61%, Test Loss: 0.9231, Test Accuracy: 60.76%\n",
      "Epoch [612/2500], Train Loss: 0.9662, Train Accuracy: 57.75%, Test Loss: 0.9222, Test Accuracy: 60.76%\n",
      "Epoch [613/2500], Train Loss: 0.9414, Train Accuracy: 58.61%, Test Loss: 0.9224, Test Accuracy: 60.76%\n",
      "Epoch [614/2500], Train Loss: 0.9440, Train Accuracy: 58.32%, Test Loss: 0.9251, Test Accuracy: 60.76%\n",
      "Epoch [615/2500], Train Loss: 0.9395, Train Accuracy: 58.46%, Test Loss: 0.9260, Test Accuracy: 60.76%\n",
      "Epoch [616/2500], Train Loss: 0.9479, Train Accuracy: 58.32%, Test Loss: 0.9220, Test Accuracy: 60.76%\n",
      "Epoch [617/2500], Train Loss: 0.9384, Train Accuracy: 58.61%, Test Loss: 0.9217, Test Accuracy: 60.76%\n",
      "Epoch [618/2500], Train Loss: 0.9573, Train Accuracy: 57.33%, Test Loss: 0.9232, Test Accuracy: 60.76%\n",
      "Epoch [619/2500], Train Loss: 0.9339, Train Accuracy: 57.89%, Test Loss: 0.9193, Test Accuracy: 60.76%\n",
      "Epoch [620/2500], Train Loss: 0.9556, Train Accuracy: 57.33%, Test Loss: 0.9245, Test Accuracy: 60.76%\n",
      "Epoch [621/2500], Train Loss: 0.9568, Train Accuracy: 56.76%, Test Loss: 0.9238, Test Accuracy: 60.76%\n",
      "Epoch [622/2500], Train Loss: 0.9564, Train Accuracy: 57.75%, Test Loss: 0.9239, Test Accuracy: 60.76%\n",
      "Epoch [623/2500], Train Loss: 0.9519, Train Accuracy: 58.75%, Test Loss: 0.9257, Test Accuracy: 60.76%\n",
      "Epoch [624/2500], Train Loss: 0.9402, Train Accuracy: 58.18%, Test Loss: 0.9268, Test Accuracy: 60.76%\n",
      "Epoch [625/2500], Train Loss: 0.9456, Train Accuracy: 58.18%, Test Loss: 0.9300, Test Accuracy: 60.76%\n",
      "Epoch [626/2500], Train Loss: 0.9415, Train Accuracy: 57.89%, Test Loss: 0.9324, Test Accuracy: 60.76%\n",
      "Epoch [627/2500], Train Loss: 0.9393, Train Accuracy: 59.17%, Test Loss: 0.9280, Test Accuracy: 60.76%\n",
      "Epoch [628/2500], Train Loss: 0.9462, Train Accuracy: 57.75%, Test Loss: 0.9217, Test Accuracy: 60.76%\n",
      "Epoch [629/2500], Train Loss: 0.9457, Train Accuracy: 58.04%, Test Loss: 0.9176, Test Accuracy: 60.76%\n",
      "Epoch [630/2500], Train Loss: 0.9538, Train Accuracy: 58.32%, Test Loss: 0.9125, Test Accuracy: 59.49%\n",
      "Epoch [631/2500], Train Loss: 0.9517, Train Accuracy: 58.46%, Test Loss: 0.9189, Test Accuracy: 59.49%\n",
      "Epoch [632/2500], Train Loss: 0.9380, Train Accuracy: 57.75%, Test Loss: 0.9167, Test Accuracy: 60.76%\n",
      "Epoch [633/2500], Train Loss: 0.9533, Train Accuracy: 58.18%, Test Loss: 0.9232, Test Accuracy: 60.76%\n",
      "Epoch [634/2500], Train Loss: 0.9626, Train Accuracy: 58.46%, Test Loss: 0.9211, Test Accuracy: 60.76%\n",
      "Epoch [635/2500], Train Loss: 0.9605, Train Accuracy: 58.32%, Test Loss: 0.9220, Test Accuracy: 60.76%\n",
      "Epoch [636/2500], Train Loss: 0.9477, Train Accuracy: 58.75%, Test Loss: 0.9185, Test Accuracy: 60.76%\n",
      "Epoch [637/2500], Train Loss: 0.9614, Train Accuracy: 58.04%, Test Loss: 0.9227, Test Accuracy: 59.49%\n",
      "Epoch [638/2500], Train Loss: 0.9481, Train Accuracy: 58.61%, Test Loss: 0.9240, Test Accuracy: 60.76%\n",
      "Epoch [639/2500], Train Loss: 0.9704, Train Accuracy: 56.47%, Test Loss: 0.9223, Test Accuracy: 60.76%\n",
      "Epoch [640/2500], Train Loss: 0.9590, Train Accuracy: 58.04%, Test Loss: 0.9234, Test Accuracy: 60.76%\n",
      "Epoch [641/2500], Train Loss: 0.9381, Train Accuracy: 58.61%, Test Loss: 0.9256, Test Accuracy: 59.49%\n",
      "Epoch [642/2500], Train Loss: 0.9560, Train Accuracy: 57.75%, Test Loss: 0.9258, Test Accuracy: 59.49%\n",
      "Epoch [643/2500], Train Loss: 0.9487, Train Accuracy: 58.75%, Test Loss: 0.9268, Test Accuracy: 59.49%\n",
      "Epoch [644/2500], Train Loss: 0.9435, Train Accuracy: 59.46%, Test Loss: 0.9240, Test Accuracy: 60.76%\n",
      "Epoch [645/2500], Train Loss: 0.9445, Train Accuracy: 57.61%, Test Loss: 0.9220, Test Accuracy: 60.76%\n",
      "Epoch [646/2500], Train Loss: 0.9400, Train Accuracy: 58.32%, Test Loss: 0.9180, Test Accuracy: 59.49%\n",
      "Epoch [647/2500], Train Loss: 0.9521, Train Accuracy: 58.61%, Test Loss: 0.9164, Test Accuracy: 59.49%\n",
      "Epoch [648/2500], Train Loss: 0.9498, Train Accuracy: 58.04%, Test Loss: 0.9155, Test Accuracy: 60.76%\n",
      "Epoch [649/2500], Train Loss: 0.9561, Train Accuracy: 56.90%, Test Loss: 0.9160, Test Accuracy: 60.76%\n",
      "Epoch [650/2500], Train Loss: 0.9360, Train Accuracy: 58.46%, Test Loss: 0.9169, Test Accuracy: 59.49%\n",
      "Epoch [651/2500], Train Loss: 0.9480, Train Accuracy: 57.89%, Test Loss: 0.9228, Test Accuracy: 58.23%\n",
      "Epoch [652/2500], Train Loss: 0.9598, Train Accuracy: 58.04%, Test Loss: 0.9311, Test Accuracy: 59.49%\n",
      "Epoch [653/2500], Train Loss: 0.9532, Train Accuracy: 57.75%, Test Loss: 0.9291, Test Accuracy: 60.76%\n",
      "Epoch [654/2500], Train Loss: 0.9501, Train Accuracy: 58.18%, Test Loss: 0.9244, Test Accuracy: 60.76%\n",
      "Epoch [655/2500], Train Loss: 0.9467, Train Accuracy: 58.04%, Test Loss: 0.9232, Test Accuracy: 60.76%\n",
      "Epoch [656/2500], Train Loss: 0.9605, Train Accuracy: 58.61%, Test Loss: 0.9214, Test Accuracy: 60.76%\n",
      "Epoch [657/2500], Train Loss: 0.9320, Train Accuracy: 59.17%, Test Loss: 0.9214, Test Accuracy: 59.49%\n",
      "Epoch [658/2500], Train Loss: 0.9520, Train Accuracy: 56.33%, Test Loss: 0.9215, Test Accuracy: 59.49%\n",
      "Epoch [659/2500], Train Loss: 0.9368, Train Accuracy: 58.32%, Test Loss: 0.9233, Test Accuracy: 60.76%\n",
      "Epoch [660/2500], Train Loss: 0.9622, Train Accuracy: 57.04%, Test Loss: 0.9217, Test Accuracy: 59.49%\n",
      "Epoch [661/2500], Train Loss: 0.9504, Train Accuracy: 57.33%, Test Loss: 0.9251, Test Accuracy: 59.49%\n",
      "Epoch [662/2500], Train Loss: 0.9528, Train Accuracy: 58.61%, Test Loss: 0.9286, Test Accuracy: 60.76%\n",
      "Epoch [663/2500], Train Loss: 0.9416, Train Accuracy: 57.18%, Test Loss: 0.9256, Test Accuracy: 60.76%\n",
      "Epoch [664/2500], Train Loss: 0.9656, Train Accuracy: 57.75%, Test Loss: 0.9224, Test Accuracy: 60.76%\n",
      "Epoch [665/2500], Train Loss: 0.9553, Train Accuracy: 58.18%, Test Loss: 0.9308, Test Accuracy: 60.76%\n",
      "Epoch [666/2500], Train Loss: 0.9403, Train Accuracy: 59.03%, Test Loss: 0.9239, Test Accuracy: 59.49%\n",
      "Epoch [667/2500], Train Loss: 0.9346, Train Accuracy: 58.75%, Test Loss: 0.9134, Test Accuracy: 60.76%\n",
      "Epoch [668/2500], Train Loss: 0.9438, Train Accuracy: 58.46%, Test Loss: 0.9185, Test Accuracy: 60.76%\n",
      "Epoch [669/2500], Train Loss: 0.9570, Train Accuracy: 58.46%, Test Loss: 0.9184, Test Accuracy: 60.76%\n",
      "Epoch [670/2500], Train Loss: 0.9446, Train Accuracy: 57.47%, Test Loss: 0.9140, Test Accuracy: 60.76%\n",
      "Epoch [671/2500], Train Loss: 0.9308, Train Accuracy: 58.46%, Test Loss: 0.9185, Test Accuracy: 60.76%\n",
      "Epoch [672/2500], Train Loss: 0.9626, Train Accuracy: 58.61%, Test Loss: 0.9197, Test Accuracy: 60.76%\n",
      "Epoch [673/2500], Train Loss: 0.9539, Train Accuracy: 59.03%, Test Loss: 0.9211, Test Accuracy: 60.76%\n",
      "Epoch [674/2500], Train Loss: 0.9193, Train Accuracy: 59.32%, Test Loss: 0.9119, Test Accuracy: 60.76%\n",
      "Epoch [675/2500], Train Loss: 0.9427, Train Accuracy: 58.04%, Test Loss: 0.9074, Test Accuracy: 59.49%\n",
      "Epoch [676/2500], Train Loss: 0.9482, Train Accuracy: 58.61%, Test Loss: 0.9158, Test Accuracy: 59.49%\n",
      "Epoch [677/2500], Train Loss: 0.9312, Train Accuracy: 58.32%, Test Loss: 0.9174, Test Accuracy: 60.76%\n",
      "Epoch [678/2500], Train Loss: 0.9528, Train Accuracy: 58.04%, Test Loss: 0.9176, Test Accuracy: 60.76%\n",
      "Epoch [679/2500], Train Loss: 0.9429, Train Accuracy: 57.18%, Test Loss: 0.9153, Test Accuracy: 60.76%\n",
      "Epoch [680/2500], Train Loss: 0.9441, Train Accuracy: 57.61%, Test Loss: 0.9166, Test Accuracy: 60.76%\n",
      "Epoch [681/2500], Train Loss: 0.9285, Train Accuracy: 58.04%, Test Loss: 0.9166, Test Accuracy: 60.76%\n",
      "Epoch [682/2500], Train Loss: 0.9506, Train Accuracy: 58.46%, Test Loss: 0.9146, Test Accuracy: 59.49%\n",
      "Epoch [683/2500], Train Loss: 0.9492, Train Accuracy: 58.32%, Test Loss: 0.9143, Test Accuracy: 60.76%\n",
      "Epoch [684/2500], Train Loss: 0.9492, Train Accuracy: 58.04%, Test Loss: 0.9171, Test Accuracy: 60.76%\n",
      "Epoch [685/2500], Train Loss: 0.9624, Train Accuracy: 58.89%, Test Loss: 0.9125, Test Accuracy: 59.49%\n",
      "Epoch [686/2500], Train Loss: 0.9512, Train Accuracy: 58.04%, Test Loss: 0.9149, Test Accuracy: 59.49%\n",
      "Epoch [687/2500], Train Loss: 0.9523, Train Accuracy: 57.47%, Test Loss: 0.9163, Test Accuracy: 59.49%\n",
      "Epoch [688/2500], Train Loss: 0.9410, Train Accuracy: 58.89%, Test Loss: 0.9184, Test Accuracy: 59.49%\n",
      "Epoch [689/2500], Train Loss: 0.9501, Train Accuracy: 58.18%, Test Loss: 0.9158, Test Accuracy: 59.49%\n",
      "Epoch [690/2500], Train Loss: 0.9396, Train Accuracy: 58.75%, Test Loss: 0.9172, Test Accuracy: 58.23%\n",
      "Epoch [691/2500], Train Loss: 0.9481, Train Accuracy: 57.47%, Test Loss: 0.9131, Test Accuracy: 58.23%\n",
      "Epoch [692/2500], Train Loss: 0.9496, Train Accuracy: 57.04%, Test Loss: 0.9107, Test Accuracy: 59.49%\n",
      "Epoch [693/2500], Train Loss: 0.9398, Train Accuracy: 58.32%, Test Loss: 0.9129, Test Accuracy: 58.23%\n",
      "Epoch [694/2500], Train Loss: 0.9455, Train Accuracy: 57.89%, Test Loss: 0.9100, Test Accuracy: 59.49%\n",
      "Epoch [695/2500], Train Loss: 0.9555, Train Accuracy: 58.18%, Test Loss: 0.9072, Test Accuracy: 59.49%\n",
      "Epoch [696/2500], Train Loss: 0.9534, Train Accuracy: 57.18%, Test Loss: 0.8949, Test Accuracy: 59.49%\n",
      "Epoch [697/2500], Train Loss: 0.9436, Train Accuracy: 58.46%, Test Loss: 0.8963, Test Accuracy: 59.49%\n",
      "Epoch [698/2500], Train Loss: 0.9310, Train Accuracy: 60.03%, Test Loss: 0.9026, Test Accuracy: 59.49%\n",
      "Epoch [699/2500], Train Loss: 0.9536, Train Accuracy: 57.89%, Test Loss: 0.9065, Test Accuracy: 59.49%\n",
      "Epoch [700/2500], Train Loss: 0.9468, Train Accuracy: 59.32%, Test Loss: 0.8998, Test Accuracy: 59.49%\n",
      "Epoch [701/2500], Train Loss: 0.9505, Train Accuracy: 59.17%, Test Loss: 0.9060, Test Accuracy: 59.49%\n",
      "Epoch [702/2500], Train Loss: 0.9455, Train Accuracy: 58.75%, Test Loss: 0.9084, Test Accuracy: 59.49%\n",
      "Epoch [703/2500], Train Loss: 0.9348, Train Accuracy: 58.32%, Test Loss: 0.9111, Test Accuracy: 59.49%\n",
      "Epoch [704/2500], Train Loss: 0.9243, Train Accuracy: 58.75%, Test Loss: 0.9171, Test Accuracy: 59.49%\n",
      "Epoch [705/2500], Train Loss: 0.9312, Train Accuracy: 58.46%, Test Loss: 0.9141, Test Accuracy: 60.76%\n",
      "Epoch [706/2500], Train Loss: 0.9377, Train Accuracy: 57.61%, Test Loss: 0.9082, Test Accuracy: 60.76%\n",
      "Epoch [707/2500], Train Loss: 0.9396, Train Accuracy: 58.18%, Test Loss: 0.9100, Test Accuracy: 60.76%\n",
      "Epoch [708/2500], Train Loss: 0.9262, Train Accuracy: 60.17%, Test Loss: 0.9119, Test Accuracy: 60.76%\n",
      "Epoch [709/2500], Train Loss: 0.9385, Train Accuracy: 58.18%, Test Loss: 0.9115, Test Accuracy: 60.76%\n",
      "Epoch [710/2500], Train Loss: 0.9226, Train Accuracy: 59.60%, Test Loss: 0.9107, Test Accuracy: 59.49%\n",
      "Epoch [711/2500], Train Loss: 0.9327, Train Accuracy: 59.60%, Test Loss: 0.9063, Test Accuracy: 59.49%\n",
      "Epoch [712/2500], Train Loss: 0.9367, Train Accuracy: 57.89%, Test Loss: 0.9083, Test Accuracy: 59.49%\n",
      "Epoch [713/2500], Train Loss: 0.9439, Train Accuracy: 57.61%, Test Loss: 0.9051, Test Accuracy: 59.49%\n",
      "Epoch [714/2500], Train Loss: 0.9344, Train Accuracy: 59.74%, Test Loss: 0.9070, Test Accuracy: 59.49%\n",
      "Epoch [715/2500], Train Loss: 0.9587, Train Accuracy: 58.46%, Test Loss: 0.9073, Test Accuracy: 59.49%\n",
      "Epoch [716/2500], Train Loss: 0.9241, Train Accuracy: 58.04%, Test Loss: 0.9020, Test Accuracy: 59.49%\n",
      "Epoch [717/2500], Train Loss: 0.9353, Train Accuracy: 58.32%, Test Loss: 0.9004, Test Accuracy: 59.49%\n",
      "Epoch [718/2500], Train Loss: 0.9284, Train Accuracy: 58.75%, Test Loss: 0.9100, Test Accuracy: 59.49%\n",
      "Epoch [719/2500], Train Loss: 0.9392, Train Accuracy: 58.75%, Test Loss: 0.9031, Test Accuracy: 59.49%\n",
      "Epoch [720/2500], Train Loss: 0.9331, Train Accuracy: 59.03%, Test Loss: 0.9106, Test Accuracy: 59.49%\n",
      "Epoch [721/2500], Train Loss: 0.9454, Train Accuracy: 59.17%, Test Loss: 0.9170, Test Accuracy: 59.49%\n",
      "Epoch [722/2500], Train Loss: 0.9360, Train Accuracy: 58.32%, Test Loss: 0.9085, Test Accuracy: 59.49%\n",
      "Epoch [723/2500], Train Loss: 0.9400, Train Accuracy: 58.61%, Test Loss: 0.9062, Test Accuracy: 59.49%\n",
      "Epoch [724/2500], Train Loss: 0.9410, Train Accuracy: 58.61%, Test Loss: 0.9063, Test Accuracy: 59.49%\n",
      "Epoch [725/2500], Train Loss: 0.9437, Train Accuracy: 58.32%, Test Loss: 0.9022, Test Accuracy: 59.49%\n",
      "Epoch [726/2500], Train Loss: 0.9428, Train Accuracy: 58.04%, Test Loss: 0.9016, Test Accuracy: 59.49%\n",
      "Epoch [727/2500], Train Loss: 0.9468, Train Accuracy: 57.33%, Test Loss: 0.9086, Test Accuracy: 59.49%\n",
      "Epoch [728/2500], Train Loss: 0.9452, Train Accuracy: 58.46%, Test Loss: 0.9051, Test Accuracy: 59.49%\n",
      "Epoch [729/2500], Train Loss: 0.9313, Train Accuracy: 57.75%, Test Loss: 0.9078, Test Accuracy: 59.49%\n",
      "Epoch [730/2500], Train Loss: 0.9549, Train Accuracy: 57.89%, Test Loss: 0.9130, Test Accuracy: 59.49%\n",
      "Epoch [731/2500], Train Loss: 0.9439, Train Accuracy: 57.75%, Test Loss: 0.9118, Test Accuracy: 59.49%\n",
      "Epoch [732/2500], Train Loss: 0.9323, Train Accuracy: 59.03%, Test Loss: 0.9207, Test Accuracy: 59.49%\n",
      "Epoch [733/2500], Train Loss: 0.9319, Train Accuracy: 58.46%, Test Loss: 0.9145, Test Accuracy: 59.49%\n",
      "Epoch [734/2500], Train Loss: 0.9416, Train Accuracy: 58.18%, Test Loss: 0.9167, Test Accuracy: 59.49%\n",
      "Epoch [735/2500], Train Loss: 0.9386, Train Accuracy: 57.18%, Test Loss: 0.9133, Test Accuracy: 59.49%\n",
      "Epoch [736/2500], Train Loss: 0.9352, Train Accuracy: 57.75%, Test Loss: 0.9180, Test Accuracy: 59.49%\n",
      "Epoch [737/2500], Train Loss: 0.9323, Train Accuracy: 58.61%, Test Loss: 0.9135, Test Accuracy: 59.49%\n",
      "Epoch [738/2500], Train Loss: 0.9364, Train Accuracy: 58.32%, Test Loss: 0.9144, Test Accuracy: 59.49%\n",
      "Epoch [739/2500], Train Loss: 0.9219, Train Accuracy: 59.17%, Test Loss: 0.9159, Test Accuracy: 59.49%\n",
      "Epoch [740/2500], Train Loss: 0.9407, Train Accuracy: 58.75%, Test Loss: 0.9163, Test Accuracy: 59.49%\n",
      "Epoch [741/2500], Train Loss: 0.9555, Train Accuracy: 57.04%, Test Loss: 0.9154, Test Accuracy: 59.49%\n",
      "Epoch [742/2500], Train Loss: 0.9418, Train Accuracy: 59.32%, Test Loss: 0.9156, Test Accuracy: 59.49%\n",
      "Epoch [743/2500], Train Loss: 0.9387, Train Accuracy: 58.75%, Test Loss: 0.9117, Test Accuracy: 59.49%\n",
      "Epoch [744/2500], Train Loss: 0.9474, Train Accuracy: 57.47%, Test Loss: 0.9060, Test Accuracy: 59.49%\n",
      "Epoch [745/2500], Train Loss: 0.9289, Train Accuracy: 58.18%, Test Loss: 0.9040, Test Accuracy: 59.49%\n",
      "Epoch [746/2500], Train Loss: 0.9418, Train Accuracy: 59.03%, Test Loss: 0.9067, Test Accuracy: 59.49%\n",
      "Epoch [747/2500], Train Loss: 0.9507, Train Accuracy: 58.04%, Test Loss: 0.9127, Test Accuracy: 58.23%\n",
      "Epoch [748/2500], Train Loss: 0.9367, Train Accuracy: 57.04%, Test Loss: 0.9158, Test Accuracy: 59.49%\n",
      "Epoch [749/2500], Train Loss: 0.9145, Train Accuracy: 59.46%, Test Loss: 0.9136, Test Accuracy: 59.49%\n",
      "Epoch [750/2500], Train Loss: 0.9406, Train Accuracy: 58.04%, Test Loss: 0.9156, Test Accuracy: 59.49%\n",
      "Epoch [751/2500], Train Loss: 0.9512, Train Accuracy: 57.75%, Test Loss: 0.9099, Test Accuracy: 59.49%\n",
      "Epoch [752/2500], Train Loss: 0.9416, Train Accuracy: 58.61%, Test Loss: 0.9161, Test Accuracy: 59.49%\n",
      "Epoch [753/2500], Train Loss: 0.9167, Train Accuracy: 59.32%, Test Loss: 0.9182, Test Accuracy: 58.23%\n",
      "Epoch [754/2500], Train Loss: 0.9311, Train Accuracy: 59.46%, Test Loss: 0.9160, Test Accuracy: 58.23%\n",
      "Epoch [755/2500], Train Loss: 0.9561, Train Accuracy: 57.61%, Test Loss: 0.9157, Test Accuracy: 59.49%\n",
      "Epoch [756/2500], Train Loss: 0.9357, Train Accuracy: 57.04%, Test Loss: 0.9173, Test Accuracy: 59.49%\n",
      "Epoch [757/2500], Train Loss: 0.9459, Train Accuracy: 58.18%, Test Loss: 0.9124, Test Accuracy: 59.49%\n",
      "Epoch [758/2500], Train Loss: 0.9353, Train Accuracy: 58.04%, Test Loss: 0.9102, Test Accuracy: 59.49%\n",
      "Epoch [759/2500], Train Loss: 0.9376, Train Accuracy: 58.61%, Test Loss: 0.9099, Test Accuracy: 59.49%\n",
      "Epoch [760/2500], Train Loss: 0.9210, Train Accuracy: 57.75%, Test Loss: 0.9131, Test Accuracy: 59.49%\n",
      "Epoch [761/2500], Train Loss: 0.9242, Train Accuracy: 59.32%, Test Loss: 0.9168, Test Accuracy: 59.49%\n",
      "Epoch [762/2500], Train Loss: 0.9380, Train Accuracy: 58.89%, Test Loss: 0.9078, Test Accuracy: 58.23%\n",
      "Epoch [763/2500], Train Loss: 0.9285, Train Accuracy: 59.46%, Test Loss: 0.9089, Test Accuracy: 58.23%\n",
      "Epoch [764/2500], Train Loss: 0.9442, Train Accuracy: 57.33%, Test Loss: 0.9083, Test Accuracy: 59.49%\n",
      "Epoch [765/2500], Train Loss: 0.9251, Train Accuracy: 58.04%, Test Loss: 0.9054, Test Accuracy: 59.49%\n",
      "Epoch [766/2500], Train Loss: 0.9518, Train Accuracy: 58.75%, Test Loss: 0.9038, Test Accuracy: 58.23%\n",
      "Epoch [767/2500], Train Loss: 0.9276, Train Accuracy: 58.32%, Test Loss: 0.9012, Test Accuracy: 58.23%\n",
      "Epoch [768/2500], Train Loss: 0.9265, Train Accuracy: 58.75%, Test Loss: 0.9125, Test Accuracy: 59.49%\n",
      "Epoch [769/2500], Train Loss: 0.9375, Train Accuracy: 58.75%, Test Loss: 0.9123, Test Accuracy: 59.49%\n",
      "Epoch [770/2500], Train Loss: 0.9231, Train Accuracy: 58.04%, Test Loss: 0.9177, Test Accuracy: 58.23%\n",
      "Epoch [771/2500], Train Loss: 0.9394, Train Accuracy: 59.03%, Test Loss: 0.9237, Test Accuracy: 59.49%\n",
      "Epoch [772/2500], Train Loss: 0.9414, Train Accuracy: 59.17%, Test Loss: 0.9180, Test Accuracy: 59.49%\n",
      "Epoch [773/2500], Train Loss: 0.9320, Train Accuracy: 57.47%, Test Loss: 0.9186, Test Accuracy: 59.49%\n",
      "Epoch [774/2500], Train Loss: 0.9408, Train Accuracy: 59.17%, Test Loss: 0.9142, Test Accuracy: 59.49%\n",
      "Epoch [775/2500], Train Loss: 0.9268, Train Accuracy: 58.32%, Test Loss: 0.9154, Test Accuracy: 59.49%\n",
      "Epoch [776/2500], Train Loss: 0.9422, Train Accuracy: 58.61%, Test Loss: 0.9082, Test Accuracy: 59.49%\n",
      "Epoch [777/2500], Train Loss: 0.9224, Train Accuracy: 60.46%, Test Loss: 0.9036, Test Accuracy: 59.49%\n",
      "Epoch [778/2500], Train Loss: 0.9450, Train Accuracy: 57.18%, Test Loss: 0.9137, Test Accuracy: 59.49%\n",
      "Epoch [779/2500], Train Loss: 0.9457, Train Accuracy: 58.61%, Test Loss: 0.9209, Test Accuracy: 59.49%\n",
      "Epoch [780/2500], Train Loss: 0.9122, Train Accuracy: 58.89%, Test Loss: 0.9098, Test Accuracy: 59.49%\n",
      "Epoch [781/2500], Train Loss: 0.9296, Train Accuracy: 57.75%, Test Loss: 0.9030, Test Accuracy: 60.76%\n",
      "Epoch [782/2500], Train Loss: 0.9253, Train Accuracy: 59.03%, Test Loss: 0.9122, Test Accuracy: 60.76%\n",
      "Epoch [783/2500], Train Loss: 0.9180, Train Accuracy: 58.61%, Test Loss: 0.9129, Test Accuracy: 60.76%\n",
      "Epoch [784/2500], Train Loss: 0.9504, Train Accuracy: 59.17%, Test Loss: 0.9069, Test Accuracy: 59.49%\n",
      "Epoch [785/2500], Train Loss: 0.9313, Train Accuracy: 58.61%, Test Loss: 0.9119, Test Accuracy: 60.76%\n",
      "Epoch [786/2500], Train Loss: 0.9337, Train Accuracy: 60.03%, Test Loss: 0.9079, Test Accuracy: 60.76%\n",
      "Epoch [787/2500], Train Loss: 0.9363, Train Accuracy: 58.61%, Test Loss: 0.9080, Test Accuracy: 59.49%\n",
      "Epoch [788/2500], Train Loss: 0.9419, Train Accuracy: 57.75%, Test Loss: 0.9088, Test Accuracy: 59.49%\n",
      "Epoch [789/2500], Train Loss: 0.9419, Train Accuracy: 57.75%, Test Loss: 0.9055, Test Accuracy: 59.49%\n",
      "Epoch [790/2500], Train Loss: 0.9392, Train Accuracy: 58.46%, Test Loss: 0.9100, Test Accuracy: 59.49%\n",
      "Epoch [791/2500], Train Loss: 0.9299, Train Accuracy: 58.75%, Test Loss: 0.9142, Test Accuracy: 59.49%\n",
      "Epoch [792/2500], Train Loss: 0.9224, Train Accuracy: 59.17%, Test Loss: 0.9074, Test Accuracy: 59.49%\n",
      "Epoch [793/2500], Train Loss: 0.9465, Train Accuracy: 57.18%, Test Loss: 0.9142, Test Accuracy: 59.49%\n",
      "Epoch [794/2500], Train Loss: 0.9293, Train Accuracy: 58.46%, Test Loss: 0.9171, Test Accuracy: 59.49%\n",
      "Epoch [795/2500], Train Loss: 0.9269, Train Accuracy: 59.46%, Test Loss: 0.9056, Test Accuracy: 59.49%\n",
      "Epoch [796/2500], Train Loss: 0.9301, Train Accuracy: 60.17%, Test Loss: 0.9000, Test Accuracy: 60.76%\n",
      "Epoch [797/2500], Train Loss: 0.9383, Train Accuracy: 57.04%, Test Loss: 0.9029, Test Accuracy: 59.49%\n",
      "Epoch [798/2500], Train Loss: 0.9235, Train Accuracy: 59.17%, Test Loss: 0.9039, Test Accuracy: 60.76%\n",
      "Epoch [799/2500], Train Loss: 0.9396, Train Accuracy: 58.04%, Test Loss: 0.9130, Test Accuracy: 59.49%\n",
      "Epoch [800/2500], Train Loss: 0.9390, Train Accuracy: 59.03%, Test Loss: 0.9117, Test Accuracy: 60.76%\n",
      "Epoch [801/2500], Train Loss: 0.9373, Train Accuracy: 58.18%, Test Loss: 0.9131, Test Accuracy: 62.03%\n",
      "Epoch [802/2500], Train Loss: 0.9300, Train Accuracy: 59.03%, Test Loss: 0.9088, Test Accuracy: 62.03%\n",
      "Epoch [803/2500], Train Loss: 0.9226, Train Accuracy: 59.32%, Test Loss: 0.9069, Test Accuracy: 62.03%\n",
      "Epoch [804/2500], Train Loss: 0.9278, Train Accuracy: 57.75%, Test Loss: 0.9043, Test Accuracy: 62.03%\n",
      "Epoch [805/2500], Train Loss: 0.9251, Train Accuracy: 58.46%, Test Loss: 0.9031, Test Accuracy: 62.03%\n",
      "Epoch [806/2500], Train Loss: 0.9285, Train Accuracy: 58.61%, Test Loss: 0.9009, Test Accuracy: 62.03%\n",
      "Epoch [807/2500], Train Loss: 0.9069, Train Accuracy: 58.89%, Test Loss: 0.9054, Test Accuracy: 62.03%\n",
      "Epoch [808/2500], Train Loss: 0.9406, Train Accuracy: 58.32%, Test Loss: 0.8981, Test Accuracy: 60.76%\n",
      "Epoch [809/2500], Train Loss: 0.9265, Train Accuracy: 58.61%, Test Loss: 0.8946, Test Accuracy: 58.23%\n",
      "Epoch [810/2500], Train Loss: 0.9387, Train Accuracy: 58.04%, Test Loss: 0.9016, Test Accuracy: 60.76%\n",
      "Epoch [811/2500], Train Loss: 0.9458, Train Accuracy: 57.04%, Test Loss: 0.8959, Test Accuracy: 58.23%\n",
      "Epoch [812/2500], Train Loss: 0.9253, Train Accuracy: 59.17%, Test Loss: 0.9009, Test Accuracy: 62.03%\n",
      "Epoch [813/2500], Train Loss: 0.9338, Train Accuracy: 58.61%, Test Loss: 0.9052, Test Accuracy: 62.03%\n",
      "Epoch [814/2500], Train Loss: 0.9262, Train Accuracy: 59.60%, Test Loss: 0.9084, Test Accuracy: 62.03%\n",
      "Epoch [815/2500], Train Loss: 0.9310, Train Accuracy: 58.61%, Test Loss: 0.9092, Test Accuracy: 60.76%\n",
      "Epoch [816/2500], Train Loss: 0.9410, Train Accuracy: 59.32%, Test Loss: 0.9055, Test Accuracy: 60.76%\n",
      "Epoch [817/2500], Train Loss: 0.9541, Train Accuracy: 57.04%, Test Loss: 0.8987, Test Accuracy: 60.76%\n",
      "Epoch [818/2500], Train Loss: 0.9222, Train Accuracy: 59.32%, Test Loss: 0.9054, Test Accuracy: 58.23%\n",
      "Epoch [819/2500], Train Loss: 0.9228, Train Accuracy: 58.04%, Test Loss: 0.9128, Test Accuracy: 58.23%\n",
      "Epoch [820/2500], Train Loss: 0.9309, Train Accuracy: 59.46%, Test Loss: 0.9119, Test Accuracy: 58.23%\n",
      "Epoch [821/2500], Train Loss: 0.9226, Train Accuracy: 59.03%, Test Loss: 0.9103, Test Accuracy: 58.23%\n",
      "Epoch [822/2500], Train Loss: 0.9264, Train Accuracy: 59.03%, Test Loss: 0.9069, Test Accuracy: 59.49%\n",
      "Epoch [823/2500], Train Loss: 0.9243, Train Accuracy: 59.17%, Test Loss: 0.9124, Test Accuracy: 60.76%\n",
      "Epoch [824/2500], Train Loss: 0.9212, Train Accuracy: 58.75%, Test Loss: 0.9139, Test Accuracy: 60.76%\n",
      "Epoch [825/2500], Train Loss: 0.9226, Train Accuracy: 58.61%, Test Loss: 0.9102, Test Accuracy: 59.49%\n",
      "Epoch [826/2500], Train Loss: 0.9242, Train Accuracy: 60.17%, Test Loss: 0.9077, Test Accuracy: 59.49%\n",
      "Epoch [827/2500], Train Loss: 0.9198, Train Accuracy: 58.18%, Test Loss: 0.9094, Test Accuracy: 59.49%\n",
      "Epoch [828/2500], Train Loss: 0.9264, Train Accuracy: 58.32%, Test Loss: 0.9051, Test Accuracy: 59.49%\n",
      "Epoch [829/2500], Train Loss: 0.9231, Train Accuracy: 59.46%, Test Loss: 0.9131, Test Accuracy: 59.49%\n",
      "Epoch [830/2500], Train Loss: 0.9433, Train Accuracy: 59.32%, Test Loss: 0.9086, Test Accuracy: 59.49%\n",
      "Epoch [831/2500], Train Loss: 0.9149, Train Accuracy: 59.74%, Test Loss: 0.9101, Test Accuracy: 59.49%\n",
      "Epoch [832/2500], Train Loss: 0.9171, Train Accuracy: 58.75%, Test Loss: 0.9107, Test Accuracy: 62.03%\n",
      "Epoch [833/2500], Train Loss: 0.9371, Train Accuracy: 59.32%, Test Loss: 0.9087, Test Accuracy: 60.76%\n",
      "Epoch [834/2500], Train Loss: 0.9316, Train Accuracy: 58.32%, Test Loss: 0.9112, Test Accuracy: 59.49%\n",
      "Epoch [835/2500], Train Loss: 0.9259, Train Accuracy: 58.32%, Test Loss: 0.9072, Test Accuracy: 59.49%\n",
      "Epoch [836/2500], Train Loss: 0.9189, Train Accuracy: 58.89%, Test Loss: 0.9019, Test Accuracy: 59.49%\n",
      "Epoch [837/2500], Train Loss: 0.9533, Train Accuracy: 58.32%, Test Loss: 0.9033, Test Accuracy: 59.49%\n",
      "Epoch [838/2500], Train Loss: 0.9382, Train Accuracy: 59.74%, Test Loss: 0.9075, Test Accuracy: 60.76%\n",
      "Epoch [839/2500], Train Loss: 0.9217, Train Accuracy: 59.03%, Test Loss: 0.9153, Test Accuracy: 60.76%\n",
      "Epoch [840/2500], Train Loss: 0.9303, Train Accuracy: 59.03%, Test Loss: 0.9107, Test Accuracy: 58.23%\n",
      "Epoch [841/2500], Train Loss: 0.9310, Train Accuracy: 58.61%, Test Loss: 0.9140, Test Accuracy: 59.49%\n",
      "Epoch [842/2500], Train Loss: 0.9256, Train Accuracy: 59.03%, Test Loss: 0.9137, Test Accuracy: 59.49%\n",
      "Epoch [843/2500], Train Loss: 0.9196, Train Accuracy: 59.89%, Test Loss: 0.9103, Test Accuracy: 60.76%\n",
      "Epoch [844/2500], Train Loss: 0.9103, Train Accuracy: 58.75%, Test Loss: 0.9127, Test Accuracy: 59.49%\n",
      "Epoch [845/2500], Train Loss: 0.9466, Train Accuracy: 58.18%, Test Loss: 0.9098, Test Accuracy: 60.76%\n",
      "Epoch [846/2500], Train Loss: 0.9228, Train Accuracy: 59.74%, Test Loss: 0.9104, Test Accuracy: 60.76%\n",
      "Epoch [847/2500], Train Loss: 0.9411, Train Accuracy: 58.18%, Test Loss: 0.9087, Test Accuracy: 60.76%\n",
      "Epoch [848/2500], Train Loss: 0.9168, Train Accuracy: 58.61%, Test Loss: 0.9037, Test Accuracy: 60.76%\n",
      "Epoch [849/2500], Train Loss: 0.9383, Train Accuracy: 58.75%, Test Loss: 0.9061, Test Accuracy: 60.76%\n",
      "Epoch [850/2500], Train Loss: 0.9153, Train Accuracy: 60.31%, Test Loss: 0.9126, Test Accuracy: 60.76%\n",
      "Epoch [851/2500], Train Loss: 0.9138, Train Accuracy: 59.03%, Test Loss: 0.9151, Test Accuracy: 59.49%\n",
      "Epoch [852/2500], Train Loss: 0.9243, Train Accuracy: 57.47%, Test Loss: 0.9104, Test Accuracy: 59.49%\n",
      "Epoch [853/2500], Train Loss: 0.9234, Train Accuracy: 58.46%, Test Loss: 0.9085, Test Accuracy: 60.76%\n",
      "Epoch [854/2500], Train Loss: 0.9288, Train Accuracy: 58.32%, Test Loss: 0.9072, Test Accuracy: 60.76%\n",
      "Epoch [855/2500], Train Loss: 0.9121, Train Accuracy: 59.46%, Test Loss: 0.9017, Test Accuracy: 62.03%\n",
      "Epoch [856/2500], Train Loss: 0.9410, Train Accuracy: 58.18%, Test Loss: 0.9012, Test Accuracy: 60.76%\n",
      "Epoch [857/2500], Train Loss: 0.9175, Train Accuracy: 60.03%, Test Loss: 0.9055, Test Accuracy: 62.03%\n",
      "Epoch [858/2500], Train Loss: 0.9148, Train Accuracy: 59.17%, Test Loss: 0.9005, Test Accuracy: 62.03%\n",
      "Epoch [859/2500], Train Loss: 0.9082, Train Accuracy: 59.46%, Test Loss: 0.9000, Test Accuracy: 62.03%\n",
      "Epoch [860/2500], Train Loss: 0.9244, Train Accuracy: 58.89%, Test Loss: 0.9108, Test Accuracy: 62.03%\n",
      "Epoch [861/2500], Train Loss: 0.9135, Train Accuracy: 59.74%, Test Loss: 0.9130, Test Accuracy: 62.03%\n",
      "Epoch [862/2500], Train Loss: 0.9389, Train Accuracy: 58.75%, Test Loss: 0.9091, Test Accuracy: 62.03%\n",
      "Epoch [863/2500], Train Loss: 0.9259, Train Accuracy: 58.75%, Test Loss: 0.9034, Test Accuracy: 59.49%\n",
      "Epoch [864/2500], Train Loss: 0.9185, Train Accuracy: 60.03%, Test Loss: 0.9078, Test Accuracy: 60.76%\n",
      "Epoch [865/2500], Train Loss: 0.9177, Train Accuracy: 60.03%, Test Loss: 0.9116, Test Accuracy: 60.76%\n",
      "Epoch [866/2500], Train Loss: 0.9053, Train Accuracy: 60.88%, Test Loss: 0.9124, Test Accuracy: 60.76%\n",
      "Epoch [867/2500], Train Loss: 0.9255, Train Accuracy: 58.89%, Test Loss: 0.9006, Test Accuracy: 59.49%\n",
      "Epoch [868/2500], Train Loss: 0.9171, Train Accuracy: 59.03%, Test Loss: 0.8958, Test Accuracy: 60.76%\n",
      "Epoch [869/2500], Train Loss: 0.9323, Train Accuracy: 58.04%, Test Loss: 0.8966, Test Accuracy: 59.49%\n",
      "Epoch [870/2500], Train Loss: 0.9211, Train Accuracy: 58.75%, Test Loss: 0.9061, Test Accuracy: 60.76%\n",
      "Epoch [871/2500], Train Loss: 0.9254, Train Accuracy: 60.03%, Test Loss: 0.9031, Test Accuracy: 60.76%\n",
      "Epoch [872/2500], Train Loss: 0.9036, Train Accuracy: 59.46%, Test Loss: 0.9111, Test Accuracy: 62.03%\n",
      "Epoch [873/2500], Train Loss: 0.9110, Train Accuracy: 59.32%, Test Loss: 0.9108, Test Accuracy: 62.03%\n",
      "Epoch [874/2500], Train Loss: 0.9094, Train Accuracy: 60.46%, Test Loss: 0.9106, Test Accuracy: 62.03%\n",
      "Epoch [875/2500], Train Loss: 0.9468, Train Accuracy: 58.04%, Test Loss: 0.9010, Test Accuracy: 62.03%\n",
      "Epoch [876/2500], Train Loss: 0.9151, Train Accuracy: 59.60%, Test Loss: 0.9039, Test Accuracy: 60.76%\n",
      "Epoch [877/2500], Train Loss: 0.9286, Train Accuracy: 60.31%, Test Loss: 0.8967, Test Accuracy: 59.49%\n",
      "Epoch [878/2500], Train Loss: 0.9240, Train Accuracy: 58.89%, Test Loss: 0.8934, Test Accuracy: 60.76%\n",
      "Epoch [879/2500], Train Loss: 0.9083, Train Accuracy: 59.32%, Test Loss: 0.8902, Test Accuracy: 60.76%\n",
      "Epoch [880/2500], Train Loss: 0.9405, Train Accuracy: 59.46%, Test Loss: 0.8977, Test Accuracy: 60.76%\n",
      "Epoch [881/2500], Train Loss: 0.9132, Train Accuracy: 59.17%, Test Loss: 0.8900, Test Accuracy: 60.76%\n",
      "Epoch [882/2500], Train Loss: 0.9183, Train Accuracy: 58.61%, Test Loss: 0.8922, Test Accuracy: 60.76%\n",
      "Epoch [883/2500], Train Loss: 0.8969, Train Accuracy: 59.60%, Test Loss: 0.8967, Test Accuracy: 62.03%\n",
      "Epoch [884/2500], Train Loss: 0.9136, Train Accuracy: 60.74%, Test Loss: 0.8966, Test Accuracy: 62.03%\n",
      "Epoch [885/2500], Train Loss: 0.9117, Train Accuracy: 60.17%, Test Loss: 0.8993, Test Accuracy: 62.03%\n",
      "Epoch [886/2500], Train Loss: 0.9247, Train Accuracy: 59.60%, Test Loss: 0.8957, Test Accuracy: 62.03%\n",
      "Epoch [887/2500], Train Loss: 0.9132, Train Accuracy: 59.74%, Test Loss: 0.9000, Test Accuracy: 62.03%\n",
      "Epoch [888/2500], Train Loss: 0.9028, Train Accuracy: 60.03%, Test Loss: 0.8932, Test Accuracy: 62.03%\n",
      "Epoch [889/2500], Train Loss: 0.9074, Train Accuracy: 60.88%, Test Loss: 0.8929, Test Accuracy: 62.03%\n",
      "Epoch [890/2500], Train Loss: 0.9114, Train Accuracy: 60.17%, Test Loss: 0.8915, Test Accuracy: 62.03%\n",
      "Epoch [891/2500], Train Loss: 0.9269, Train Accuracy: 57.89%, Test Loss: 0.8907, Test Accuracy: 62.03%\n",
      "Epoch [892/2500], Train Loss: 0.9225, Train Accuracy: 59.74%, Test Loss: 0.8892, Test Accuracy: 62.03%\n",
      "Epoch [893/2500], Train Loss: 0.9238, Train Accuracy: 58.75%, Test Loss: 0.8940, Test Accuracy: 62.03%\n",
      "Epoch [894/2500], Train Loss: 0.9296, Train Accuracy: 58.61%, Test Loss: 0.9040, Test Accuracy: 62.03%\n",
      "Epoch [895/2500], Train Loss: 0.9174, Train Accuracy: 59.46%, Test Loss: 0.9089, Test Accuracy: 62.03%\n",
      "Epoch [896/2500], Train Loss: 0.9294, Train Accuracy: 59.89%, Test Loss: 0.9115, Test Accuracy: 60.76%\n",
      "Epoch [897/2500], Train Loss: 0.9152, Train Accuracy: 58.89%, Test Loss: 0.8973, Test Accuracy: 60.76%\n",
      "Epoch [898/2500], Train Loss: 0.9198, Train Accuracy: 58.75%, Test Loss: 0.9021, Test Accuracy: 59.49%\n",
      "Epoch [899/2500], Train Loss: 0.9235, Train Accuracy: 57.89%, Test Loss: 0.9067, Test Accuracy: 60.76%\n",
      "Epoch [900/2500], Train Loss: 0.9104, Train Accuracy: 59.03%, Test Loss: 0.9014, Test Accuracy: 60.76%\n",
      "Epoch [901/2500], Train Loss: 0.9271, Train Accuracy: 59.17%, Test Loss: 0.9024, Test Accuracy: 60.76%\n",
      "Epoch [902/2500], Train Loss: 0.9186, Train Accuracy: 59.03%, Test Loss: 0.8985, Test Accuracy: 60.76%\n",
      "Epoch [903/2500], Train Loss: 0.9092, Train Accuracy: 61.17%, Test Loss: 0.9022, Test Accuracy: 62.03%\n",
      "Epoch [904/2500], Train Loss: 0.9108, Train Accuracy: 58.61%, Test Loss: 0.9009, Test Accuracy: 62.03%\n",
      "Epoch [905/2500], Train Loss: 0.9181, Train Accuracy: 59.74%, Test Loss: 0.8978, Test Accuracy: 62.03%\n",
      "Epoch [906/2500], Train Loss: 0.9241, Train Accuracy: 59.17%, Test Loss: 0.8969, Test Accuracy: 62.03%\n",
      "Epoch [907/2500], Train Loss: 0.9238, Train Accuracy: 59.60%, Test Loss: 0.8868, Test Accuracy: 60.76%\n",
      "Epoch [908/2500], Train Loss: 0.9003, Train Accuracy: 59.46%, Test Loss: 0.8844, Test Accuracy: 60.76%\n",
      "Epoch [909/2500], Train Loss: 0.9005, Train Accuracy: 60.17%, Test Loss: 0.8897, Test Accuracy: 62.03%\n",
      "Epoch [910/2500], Train Loss: 0.9212, Train Accuracy: 59.17%, Test Loss: 0.8911, Test Accuracy: 62.03%\n",
      "Epoch [911/2500], Train Loss: 0.9087, Train Accuracy: 58.89%, Test Loss: 0.8907, Test Accuracy: 62.03%\n",
      "Epoch [912/2500], Train Loss: 0.9236, Train Accuracy: 59.74%, Test Loss: 0.8896, Test Accuracy: 62.03%\n",
      "Epoch [913/2500], Train Loss: 0.9272, Train Accuracy: 59.89%, Test Loss: 0.8884, Test Accuracy: 62.03%\n",
      "Epoch [914/2500], Train Loss: 0.9154, Train Accuracy: 59.17%, Test Loss: 0.8855, Test Accuracy: 62.03%\n",
      "Epoch [915/2500], Train Loss: 0.9186, Train Accuracy: 59.32%, Test Loss: 0.8890, Test Accuracy: 62.03%\n",
      "Epoch [916/2500], Train Loss: 0.9094, Train Accuracy: 60.46%, Test Loss: 0.8898, Test Accuracy: 62.03%\n",
      "Epoch [917/2500], Train Loss: 0.9151, Train Accuracy: 60.03%, Test Loss: 0.8962, Test Accuracy: 62.03%\n",
      "Epoch [918/2500], Train Loss: 0.9211, Train Accuracy: 59.46%, Test Loss: 0.8972, Test Accuracy: 62.03%\n",
      "Epoch [919/2500], Train Loss: 0.9129, Train Accuracy: 59.89%, Test Loss: 0.8935, Test Accuracy: 62.03%\n",
      "Epoch [920/2500], Train Loss: 0.9170, Train Accuracy: 58.75%, Test Loss: 0.8873, Test Accuracy: 62.03%\n",
      "Epoch [921/2500], Train Loss: 0.9211, Train Accuracy: 57.33%, Test Loss: 0.8913, Test Accuracy: 62.03%\n",
      "Epoch [922/2500], Train Loss: 0.9230, Train Accuracy: 58.04%, Test Loss: 0.8884, Test Accuracy: 62.03%\n",
      "Epoch [923/2500], Train Loss: 0.9163, Train Accuracy: 58.75%, Test Loss: 0.8911, Test Accuracy: 62.03%\n",
      "Epoch [924/2500], Train Loss: 0.8986, Train Accuracy: 60.74%, Test Loss: 0.8939, Test Accuracy: 62.03%\n",
      "Epoch [925/2500], Train Loss: 0.9114, Train Accuracy: 58.18%, Test Loss: 0.8995, Test Accuracy: 62.03%\n",
      "Epoch [926/2500], Train Loss: 0.9021, Train Accuracy: 59.74%, Test Loss: 0.8948, Test Accuracy: 62.03%\n",
      "Epoch [927/2500], Train Loss: 0.9035, Train Accuracy: 60.17%, Test Loss: 0.8994, Test Accuracy: 62.03%\n",
      "Epoch [928/2500], Train Loss: 0.9120, Train Accuracy: 59.03%, Test Loss: 0.9040, Test Accuracy: 62.03%\n",
      "Epoch [929/2500], Train Loss: 0.9005, Train Accuracy: 59.17%, Test Loss: 0.8950, Test Accuracy: 60.76%\n",
      "Epoch [930/2500], Train Loss: 0.9113, Train Accuracy: 60.88%, Test Loss: 0.9029, Test Accuracy: 60.76%\n",
      "Epoch [931/2500], Train Loss: 0.9200, Train Accuracy: 59.03%, Test Loss: 0.8975, Test Accuracy: 60.76%\n",
      "Epoch [932/2500], Train Loss: 0.9090, Train Accuracy: 59.60%, Test Loss: 0.9045, Test Accuracy: 62.03%\n",
      "Epoch [933/2500], Train Loss: 0.9173, Train Accuracy: 58.61%, Test Loss: 0.9067, Test Accuracy: 62.03%\n",
      "Epoch [934/2500], Train Loss: 0.9077, Train Accuracy: 59.89%, Test Loss: 0.9006, Test Accuracy: 60.76%\n",
      "Epoch [935/2500], Train Loss: 0.9150, Train Accuracy: 60.17%, Test Loss: 0.9115, Test Accuracy: 62.03%\n",
      "Epoch [936/2500], Train Loss: 0.9315, Train Accuracy: 58.61%, Test Loss: 0.9129, Test Accuracy: 62.03%\n",
      "Epoch [937/2500], Train Loss: 0.9182, Train Accuracy: 59.32%, Test Loss: 0.9144, Test Accuracy: 62.03%\n",
      "Epoch [938/2500], Train Loss: 0.9214, Train Accuracy: 58.46%, Test Loss: 0.9128, Test Accuracy: 62.03%\n",
      "Epoch [939/2500], Train Loss: 0.9093, Train Accuracy: 59.89%, Test Loss: 0.9133, Test Accuracy: 62.03%\n",
      "Epoch [940/2500], Train Loss: 0.9177, Train Accuracy: 59.46%, Test Loss: 0.9120, Test Accuracy: 62.03%\n",
      "Epoch [941/2500], Train Loss: 0.9371, Train Accuracy: 58.04%, Test Loss: 0.9078, Test Accuracy: 62.03%\n",
      "Epoch [942/2500], Train Loss: 0.9050, Train Accuracy: 59.89%, Test Loss: 0.9016, Test Accuracy: 62.03%\n",
      "Epoch [943/2500], Train Loss: 0.9084, Train Accuracy: 59.17%, Test Loss: 0.9048, Test Accuracy: 62.03%\n",
      "Epoch [944/2500], Train Loss: 0.8976, Train Accuracy: 59.17%, Test Loss: 0.9068, Test Accuracy: 62.03%\n",
      "Epoch [945/2500], Train Loss: 0.9323, Train Accuracy: 59.32%, Test Loss: 0.9041, Test Accuracy: 62.03%\n",
      "Epoch [946/2500], Train Loss: 0.9018, Train Accuracy: 59.32%, Test Loss: 0.9068, Test Accuracy: 62.03%\n",
      "Epoch [947/2500], Train Loss: 0.9155, Train Accuracy: 58.75%, Test Loss: 0.9079, Test Accuracy: 62.03%\n",
      "Epoch [948/2500], Train Loss: 0.9116, Train Accuracy: 58.46%, Test Loss: 0.9049, Test Accuracy: 62.03%\n",
      "Epoch [949/2500], Train Loss: 0.9243, Train Accuracy: 58.61%, Test Loss: 0.9009, Test Accuracy: 62.03%\n",
      "Epoch [950/2500], Train Loss: 0.9123, Train Accuracy: 60.03%, Test Loss: 0.9012, Test Accuracy: 62.03%\n",
      "Epoch [951/2500], Train Loss: 0.9161, Train Accuracy: 59.46%, Test Loss: 0.8986, Test Accuracy: 62.03%\n",
      "Epoch [952/2500], Train Loss: 0.9242, Train Accuracy: 58.46%, Test Loss: 0.8933, Test Accuracy: 60.76%\n",
      "Epoch [953/2500], Train Loss: 0.8993, Train Accuracy: 60.60%, Test Loss: 0.8970, Test Accuracy: 60.76%\n",
      "Epoch [954/2500], Train Loss: 0.8993, Train Accuracy: 59.46%, Test Loss: 0.9027, Test Accuracy: 60.76%\n",
      "Epoch [955/2500], Train Loss: 0.9156, Train Accuracy: 60.46%, Test Loss: 0.8979, Test Accuracy: 62.03%\n",
      "Epoch [956/2500], Train Loss: 0.9098, Train Accuracy: 58.89%, Test Loss: 0.8918, Test Accuracy: 62.03%\n",
      "Epoch [957/2500], Train Loss: 0.9016, Train Accuracy: 60.46%, Test Loss: 0.8933, Test Accuracy: 60.76%\n",
      "Epoch [958/2500], Train Loss: 0.9008, Train Accuracy: 59.46%, Test Loss: 0.8932, Test Accuracy: 60.76%\n",
      "Epoch [959/2500], Train Loss: 0.8963, Train Accuracy: 59.32%, Test Loss: 0.8883, Test Accuracy: 60.76%\n",
      "Epoch [960/2500], Train Loss: 0.9293, Train Accuracy: 57.33%, Test Loss: 0.8950, Test Accuracy: 60.76%\n",
      "Epoch [961/2500], Train Loss: 0.9170, Train Accuracy: 59.89%, Test Loss: 0.8954, Test Accuracy: 60.76%\n",
      "Epoch [962/2500], Train Loss: 0.9090, Train Accuracy: 60.46%, Test Loss: 0.8974, Test Accuracy: 60.76%\n",
      "Epoch [963/2500], Train Loss: 0.9018, Train Accuracy: 58.89%, Test Loss: 0.8994, Test Accuracy: 60.76%\n",
      "Epoch [964/2500], Train Loss: 0.9073, Train Accuracy: 60.46%, Test Loss: 0.8927, Test Accuracy: 59.49%\n",
      "Epoch [965/2500], Train Loss: 0.9105, Train Accuracy: 58.61%, Test Loss: 0.9019, Test Accuracy: 60.76%\n",
      "Epoch [966/2500], Train Loss: 0.9052, Train Accuracy: 60.60%, Test Loss: 0.8993, Test Accuracy: 60.76%\n",
      "Epoch [967/2500], Train Loss: 0.9159, Train Accuracy: 58.04%, Test Loss: 0.8939, Test Accuracy: 60.76%\n",
      "Epoch [968/2500], Train Loss: 0.8877, Train Accuracy: 60.74%, Test Loss: 0.8940, Test Accuracy: 60.76%\n",
      "Epoch [969/2500], Train Loss: 0.9129, Train Accuracy: 59.46%, Test Loss: 0.8970, Test Accuracy: 60.76%\n",
      "Epoch [970/2500], Train Loss: 0.9027, Train Accuracy: 60.60%, Test Loss: 0.8947, Test Accuracy: 60.76%\n",
      "Epoch [971/2500], Train Loss: 0.9097, Train Accuracy: 58.75%, Test Loss: 0.8978, Test Accuracy: 60.76%\n",
      "Epoch [972/2500], Train Loss: 0.9198, Train Accuracy: 61.31%, Test Loss: 0.8958, Test Accuracy: 62.03%\n",
      "Epoch [973/2500], Train Loss: 0.9036, Train Accuracy: 59.32%, Test Loss: 0.8949, Test Accuracy: 62.03%\n",
      "Epoch [974/2500], Train Loss: 0.9103, Train Accuracy: 58.61%, Test Loss: 0.8879, Test Accuracy: 62.03%\n",
      "Epoch [975/2500], Train Loss: 0.8994, Train Accuracy: 59.17%, Test Loss: 0.8906, Test Accuracy: 62.03%\n",
      "Epoch [976/2500], Train Loss: 0.9105, Train Accuracy: 59.46%, Test Loss: 0.8891, Test Accuracy: 60.76%\n",
      "Epoch [977/2500], Train Loss: 0.9185, Train Accuracy: 59.60%, Test Loss: 0.8941, Test Accuracy: 62.03%\n",
      "Epoch [978/2500], Train Loss: 0.9148, Train Accuracy: 57.61%, Test Loss: 0.8979, Test Accuracy: 62.03%\n",
      "Epoch [979/2500], Train Loss: 0.9112, Train Accuracy: 59.03%, Test Loss: 0.9016, Test Accuracy: 62.03%\n",
      "Epoch [980/2500], Train Loss: 0.9148, Train Accuracy: 59.03%, Test Loss: 0.9013, Test Accuracy: 62.03%\n",
      "Epoch [981/2500], Train Loss: 0.9100, Train Accuracy: 58.32%, Test Loss: 0.9013, Test Accuracy: 60.76%\n",
      "Epoch [982/2500], Train Loss: 0.9000, Train Accuracy: 59.60%, Test Loss: 0.8899, Test Accuracy: 62.03%\n",
      "Epoch [983/2500], Train Loss: 0.9209, Train Accuracy: 61.74%, Test Loss: 0.8948, Test Accuracy: 60.76%\n",
      "Epoch [984/2500], Train Loss: 0.9170, Train Accuracy: 58.46%, Test Loss: 0.9012, Test Accuracy: 62.03%\n",
      "Epoch [985/2500], Train Loss: 0.9109, Train Accuracy: 59.17%, Test Loss: 0.8984, Test Accuracy: 62.03%\n",
      "Epoch [986/2500], Train Loss: 0.9146, Train Accuracy: 58.89%, Test Loss: 0.9049, Test Accuracy: 63.29%\n",
      "Epoch [987/2500], Train Loss: 0.9125, Train Accuracy: 58.18%, Test Loss: 0.9020, Test Accuracy: 63.29%\n",
      "Epoch [988/2500], Train Loss: 0.9172, Train Accuracy: 59.60%, Test Loss: 0.9099, Test Accuracy: 63.29%\n",
      "Epoch [989/2500], Train Loss: 0.8817, Train Accuracy: 59.60%, Test Loss: 0.9143, Test Accuracy: 63.29%\n",
      "Epoch [990/2500], Train Loss: 0.9091, Train Accuracy: 59.32%, Test Loss: 0.9052, Test Accuracy: 63.29%\n",
      "Epoch [991/2500], Train Loss: 0.9118, Train Accuracy: 59.60%, Test Loss: 0.9074, Test Accuracy: 63.29%\n",
      "Epoch [992/2500], Train Loss: 0.8819, Train Accuracy: 60.60%, Test Loss: 0.9129, Test Accuracy: 63.29%\n",
      "Epoch [993/2500], Train Loss: 0.9030, Train Accuracy: 60.88%, Test Loss: 0.9032, Test Accuracy: 63.29%\n",
      "Epoch [994/2500], Train Loss: 0.9033, Train Accuracy: 59.46%, Test Loss: 0.9086, Test Accuracy: 63.29%\n",
      "Epoch [995/2500], Train Loss: 0.9181, Train Accuracy: 59.32%, Test Loss: 0.9020, Test Accuracy: 63.29%\n",
      "Epoch [996/2500], Train Loss: 0.9063, Train Accuracy: 61.02%, Test Loss: 0.8971, Test Accuracy: 63.29%\n",
      "Epoch [997/2500], Train Loss: 0.9064, Train Accuracy: 59.03%, Test Loss: 0.9026, Test Accuracy: 62.03%\n",
      "Epoch [998/2500], Train Loss: 0.9091, Train Accuracy: 59.46%, Test Loss: 0.9033, Test Accuracy: 63.29%\n",
      "Epoch [999/2500], Train Loss: 0.9218, Train Accuracy: 60.03%, Test Loss: 0.9114, Test Accuracy: 62.03%\n",
      "Epoch [1000/2500], Train Loss: 0.9092, Train Accuracy: 59.74%, Test Loss: 0.9018, Test Accuracy: 62.03%\n",
      "Epoch [1001/2500], Train Loss: 0.9136, Train Accuracy: 59.32%, Test Loss: 0.9055, Test Accuracy: 63.29%\n",
      "Epoch [1002/2500], Train Loss: 0.9065, Train Accuracy: 59.03%, Test Loss: 0.9035, Test Accuracy: 62.03%\n",
      "Epoch [1003/2500], Train Loss: 0.9135, Train Accuracy: 59.60%, Test Loss: 0.9041, Test Accuracy: 63.29%\n",
      "Epoch [1004/2500], Train Loss: 0.9113, Train Accuracy: 59.46%, Test Loss: 0.8961, Test Accuracy: 62.03%\n",
      "Epoch [1005/2500], Train Loss: 0.9002, Train Accuracy: 59.17%, Test Loss: 0.8970, Test Accuracy: 62.03%\n",
      "Epoch [1006/2500], Train Loss: 0.9015, Train Accuracy: 59.74%, Test Loss: 0.8992, Test Accuracy: 63.29%\n",
      "Epoch [1007/2500], Train Loss: 0.8980, Train Accuracy: 60.60%, Test Loss: 0.9046, Test Accuracy: 63.29%\n",
      "Epoch [1008/2500], Train Loss: 0.8991, Train Accuracy: 60.60%, Test Loss: 0.8959, Test Accuracy: 63.29%\n",
      "Epoch [1009/2500], Train Loss: 0.8879, Train Accuracy: 60.74%, Test Loss: 0.8950, Test Accuracy: 63.29%\n",
      "Epoch [1010/2500], Train Loss: 0.9089, Train Accuracy: 59.17%, Test Loss: 0.8965, Test Accuracy: 62.03%\n",
      "Epoch [1011/2500], Train Loss: 0.9015, Train Accuracy: 60.74%, Test Loss: 0.9058, Test Accuracy: 60.76%\n",
      "Epoch [1012/2500], Train Loss: 0.9151, Train Accuracy: 58.46%, Test Loss: 0.8985, Test Accuracy: 63.29%\n",
      "Epoch [1013/2500], Train Loss: 0.9014, Train Accuracy: 59.89%, Test Loss: 0.8994, Test Accuracy: 62.03%\n",
      "Epoch [1014/2500], Train Loss: 0.9011, Train Accuracy: 59.89%, Test Loss: 0.9107, Test Accuracy: 63.29%\n",
      "Epoch [1015/2500], Train Loss: 0.9143, Train Accuracy: 59.46%, Test Loss: 0.9006, Test Accuracy: 62.03%\n",
      "Epoch [1016/2500], Train Loss: 0.8971, Train Accuracy: 59.74%, Test Loss: 0.9056, Test Accuracy: 63.29%\n",
      "Epoch [1017/2500], Train Loss: 0.8984, Train Accuracy: 59.74%, Test Loss: 0.9052, Test Accuracy: 63.29%\n",
      "Epoch [1018/2500], Train Loss: 0.9061, Train Accuracy: 59.32%, Test Loss: 0.9053, Test Accuracy: 63.29%\n",
      "Epoch [1019/2500], Train Loss: 0.9104, Train Accuracy: 60.60%, Test Loss: 0.9050, Test Accuracy: 63.29%\n",
      "Epoch [1020/2500], Train Loss: 0.9066, Train Accuracy: 61.02%, Test Loss: 0.9039, Test Accuracy: 59.49%\n",
      "Epoch [1021/2500], Train Loss: 0.9064, Train Accuracy: 60.60%, Test Loss: 0.9039, Test Accuracy: 62.03%\n",
      "Epoch [1022/2500], Train Loss: 0.9087, Train Accuracy: 60.31%, Test Loss: 0.9069, Test Accuracy: 63.29%\n",
      "Epoch [1023/2500], Train Loss: 0.8907, Train Accuracy: 59.46%, Test Loss: 0.9077, Test Accuracy: 63.29%\n",
      "Epoch [1024/2500], Train Loss: 0.9038, Train Accuracy: 59.74%, Test Loss: 0.9031, Test Accuracy: 62.03%\n",
      "Epoch [1025/2500], Train Loss: 0.9053, Train Accuracy: 61.02%, Test Loss: 0.9007, Test Accuracy: 62.03%\n",
      "Epoch [1026/2500], Train Loss: 0.8885, Train Accuracy: 60.46%, Test Loss: 0.9059, Test Accuracy: 63.29%\n",
      "Epoch [1027/2500], Train Loss: 0.8956, Train Accuracy: 60.46%, Test Loss: 0.9008, Test Accuracy: 59.49%\n",
      "Epoch [1028/2500], Train Loss: 0.9233, Train Accuracy: 58.89%, Test Loss: 0.9009, Test Accuracy: 60.76%\n",
      "Epoch [1029/2500], Train Loss: 0.8913, Train Accuracy: 59.60%, Test Loss: 0.8938, Test Accuracy: 59.49%\n",
      "Epoch [1030/2500], Train Loss: 0.9192, Train Accuracy: 58.89%, Test Loss: 0.8841, Test Accuracy: 60.76%\n",
      "Epoch [1031/2500], Train Loss: 0.9192, Train Accuracy: 59.17%, Test Loss: 0.8930, Test Accuracy: 62.03%\n",
      "Epoch [1032/2500], Train Loss: 0.8883, Train Accuracy: 60.88%, Test Loss: 0.8958, Test Accuracy: 62.03%\n",
      "Epoch [1033/2500], Train Loss: 0.9168, Train Accuracy: 59.03%, Test Loss: 0.8820, Test Accuracy: 62.03%\n",
      "Epoch [1034/2500], Train Loss: 0.8983, Train Accuracy: 59.46%, Test Loss: 0.8870, Test Accuracy: 62.03%\n",
      "Epoch [1035/2500], Train Loss: 0.9022, Train Accuracy: 59.74%, Test Loss: 0.8883, Test Accuracy: 62.03%\n",
      "Epoch [1036/2500], Train Loss: 0.9032, Train Accuracy: 59.03%, Test Loss: 0.8878, Test Accuracy: 62.03%\n",
      "Epoch [1037/2500], Train Loss: 0.9068, Train Accuracy: 60.17%, Test Loss: 0.8809, Test Accuracy: 62.03%\n",
      "Epoch [1038/2500], Train Loss: 0.9001, Train Accuracy: 59.89%, Test Loss: 0.8726, Test Accuracy: 60.76%\n",
      "Epoch [1039/2500], Train Loss: 0.8884, Train Accuracy: 60.46%, Test Loss: 0.8763, Test Accuracy: 62.03%\n",
      "Epoch [1040/2500], Train Loss: 0.8990, Train Accuracy: 58.89%, Test Loss: 0.8902, Test Accuracy: 62.03%\n",
      "Epoch [1041/2500], Train Loss: 0.9065, Train Accuracy: 60.17%, Test Loss: 0.8973, Test Accuracy: 62.03%\n",
      "Epoch [1042/2500], Train Loss: 0.9007, Train Accuracy: 60.46%, Test Loss: 0.8949, Test Accuracy: 62.03%\n",
      "Epoch [1043/2500], Train Loss: 0.9116, Train Accuracy: 59.17%, Test Loss: 0.8989, Test Accuracy: 62.03%\n",
      "Epoch [1044/2500], Train Loss: 0.8878, Train Accuracy: 60.74%, Test Loss: 0.8904, Test Accuracy: 62.03%\n",
      "Epoch [1045/2500], Train Loss: 0.8994, Train Accuracy: 61.31%, Test Loss: 0.8732, Test Accuracy: 62.03%\n",
      "Epoch [1046/2500], Train Loss: 0.8892, Train Accuracy: 60.46%, Test Loss: 0.8726, Test Accuracy: 63.29%\n",
      "Epoch [1047/2500], Train Loss: 0.8752, Train Accuracy: 61.31%, Test Loss: 0.8827, Test Accuracy: 63.29%\n",
      "Epoch [1048/2500], Train Loss: 0.9104, Train Accuracy: 59.89%, Test Loss: 0.8918, Test Accuracy: 62.03%\n",
      "Epoch [1049/2500], Train Loss: 0.9010, Train Accuracy: 60.46%, Test Loss: 0.8770, Test Accuracy: 63.29%\n",
      "Epoch [1050/2500], Train Loss: 0.9011, Train Accuracy: 62.45%, Test Loss: 0.8758, Test Accuracy: 63.29%\n",
      "Epoch [1051/2500], Train Loss: 0.8990, Train Accuracy: 61.59%, Test Loss: 0.8882, Test Accuracy: 63.29%\n",
      "Epoch [1052/2500], Train Loss: 0.8993, Train Accuracy: 59.03%, Test Loss: 0.8851, Test Accuracy: 63.29%\n",
      "Epoch [1053/2500], Train Loss: 0.8964, Train Accuracy: 61.59%, Test Loss: 0.8883, Test Accuracy: 63.29%\n",
      "Epoch [1054/2500], Train Loss: 0.9008, Train Accuracy: 59.74%, Test Loss: 0.8907, Test Accuracy: 62.03%\n",
      "Epoch [1055/2500], Train Loss: 0.9075, Train Accuracy: 59.60%, Test Loss: 0.8875, Test Accuracy: 63.29%\n",
      "Epoch [1056/2500], Train Loss: 0.8978, Train Accuracy: 59.03%, Test Loss: 0.9022, Test Accuracy: 63.29%\n",
      "Epoch [1057/2500], Train Loss: 0.9031, Train Accuracy: 60.60%, Test Loss: 0.8914, Test Accuracy: 63.29%\n",
      "Epoch [1058/2500], Train Loss: 0.8954, Train Accuracy: 59.89%, Test Loss: 0.8977, Test Accuracy: 63.29%\n",
      "Epoch [1059/2500], Train Loss: 0.9109, Train Accuracy: 59.60%, Test Loss: 0.8895, Test Accuracy: 63.29%\n",
      "Epoch [1060/2500], Train Loss: 0.9029, Train Accuracy: 58.18%, Test Loss: 0.8889, Test Accuracy: 62.03%\n",
      "Epoch [1061/2500], Train Loss: 0.9033, Train Accuracy: 59.17%, Test Loss: 0.8950, Test Accuracy: 63.29%\n",
      "Epoch [1062/2500], Train Loss: 0.8894, Train Accuracy: 60.74%, Test Loss: 0.8920, Test Accuracy: 63.29%\n",
      "Epoch [1063/2500], Train Loss: 0.8843, Train Accuracy: 61.31%, Test Loss: 0.8884, Test Accuracy: 63.29%\n",
      "Epoch [1064/2500], Train Loss: 0.8923, Train Accuracy: 61.02%, Test Loss: 0.8928, Test Accuracy: 62.03%\n",
      "Epoch [1065/2500], Train Loss: 0.9179, Train Accuracy: 59.60%, Test Loss: 0.8754, Test Accuracy: 62.03%\n",
      "Epoch [1066/2500], Train Loss: 0.8977, Train Accuracy: 60.74%, Test Loss: 0.8645, Test Accuracy: 62.03%\n",
      "Epoch [1067/2500], Train Loss: 0.9173, Train Accuracy: 58.75%, Test Loss: 0.8606, Test Accuracy: 62.03%\n",
      "Epoch [1068/2500], Train Loss: 0.8931, Train Accuracy: 60.17%, Test Loss: 0.8630, Test Accuracy: 62.03%\n",
      "Epoch [1069/2500], Train Loss: 0.8957, Train Accuracy: 59.60%, Test Loss: 0.8698, Test Accuracy: 62.03%\n",
      "Epoch [1070/2500], Train Loss: 0.8942, Train Accuracy: 60.03%, Test Loss: 0.8677, Test Accuracy: 62.03%\n",
      "Epoch [1071/2500], Train Loss: 0.8954, Train Accuracy: 60.46%, Test Loss: 0.8742, Test Accuracy: 62.03%\n",
      "Epoch [1072/2500], Train Loss: 0.9177, Train Accuracy: 60.03%, Test Loss: 0.8806, Test Accuracy: 63.29%\n",
      "Epoch [1073/2500], Train Loss: 0.8899, Train Accuracy: 60.31%, Test Loss: 0.8814, Test Accuracy: 63.29%\n",
      "Epoch [1074/2500], Train Loss: 0.9121, Train Accuracy: 59.60%, Test Loss: 0.8798, Test Accuracy: 62.03%\n",
      "Epoch [1075/2500], Train Loss: 0.9048, Train Accuracy: 58.61%, Test Loss: 0.8905, Test Accuracy: 63.29%\n",
      "Epoch [1076/2500], Train Loss: 0.8911, Train Accuracy: 61.31%, Test Loss: 0.8981, Test Accuracy: 63.29%\n",
      "Epoch [1077/2500], Train Loss: 0.8876, Train Accuracy: 59.89%, Test Loss: 0.8969, Test Accuracy: 63.29%\n",
      "Epoch [1078/2500], Train Loss: 0.8867, Train Accuracy: 59.60%, Test Loss: 0.8911, Test Accuracy: 63.29%\n",
      "Epoch [1079/2500], Train Loss: 0.8821, Train Accuracy: 59.74%, Test Loss: 0.8899, Test Accuracy: 63.29%\n",
      "Epoch [1080/2500], Train Loss: 0.9125, Train Accuracy: 59.74%, Test Loss: 0.8863, Test Accuracy: 62.03%\n",
      "Epoch [1081/2500], Train Loss: 0.9022, Train Accuracy: 59.89%, Test Loss: 0.8847, Test Accuracy: 62.03%\n",
      "Epoch [1082/2500], Train Loss: 0.9021, Train Accuracy: 59.89%, Test Loss: 0.8957, Test Accuracy: 63.29%\n",
      "Epoch [1083/2500], Train Loss: 0.8989, Train Accuracy: 60.60%, Test Loss: 0.8950, Test Accuracy: 63.29%\n",
      "Epoch [1084/2500], Train Loss: 0.9228, Train Accuracy: 59.17%, Test Loss: 0.8922, Test Accuracy: 63.29%\n",
      "Epoch [1085/2500], Train Loss: 0.8939, Train Accuracy: 60.17%, Test Loss: 0.8887, Test Accuracy: 63.29%\n",
      "Epoch [1086/2500], Train Loss: 0.9055, Train Accuracy: 59.46%, Test Loss: 0.8833, Test Accuracy: 63.29%\n",
      "Epoch [1087/2500], Train Loss: 0.9013, Train Accuracy: 59.32%, Test Loss: 0.8897, Test Accuracy: 63.29%\n",
      "Epoch [1088/2500], Train Loss: 0.8994, Train Accuracy: 59.74%, Test Loss: 0.8870, Test Accuracy: 62.03%\n",
      "Epoch [1089/2500], Train Loss: 0.8979, Train Accuracy: 60.03%, Test Loss: 0.8882, Test Accuracy: 62.03%\n",
      "Epoch [1090/2500], Train Loss: 0.8923, Train Accuracy: 60.46%, Test Loss: 0.8955, Test Accuracy: 62.03%\n",
      "Epoch [1091/2500], Train Loss: 0.8912, Train Accuracy: 60.60%, Test Loss: 0.8942, Test Accuracy: 62.03%\n",
      "Epoch [1092/2500], Train Loss: 0.9114, Train Accuracy: 57.89%, Test Loss: 0.8916, Test Accuracy: 62.03%\n",
      "Epoch [1093/2500], Train Loss: 0.9028, Train Accuracy: 60.31%, Test Loss: 0.8876, Test Accuracy: 62.03%\n",
      "Epoch [1094/2500], Train Loss: 0.8911, Train Accuracy: 60.31%, Test Loss: 0.8800, Test Accuracy: 62.03%\n",
      "Epoch [1095/2500], Train Loss: 0.8883, Train Accuracy: 61.74%, Test Loss: 0.8886, Test Accuracy: 62.03%\n",
      "Epoch [1096/2500], Train Loss: 0.8796, Train Accuracy: 60.17%, Test Loss: 0.8918, Test Accuracy: 62.03%\n",
      "Epoch [1097/2500], Train Loss: 0.8944, Train Accuracy: 60.31%, Test Loss: 0.8844, Test Accuracy: 62.03%\n",
      "Epoch [1098/2500], Train Loss: 0.8892, Train Accuracy: 59.32%, Test Loss: 0.8880, Test Accuracy: 63.29%\n",
      "Epoch [1099/2500], Train Loss: 0.8871, Train Accuracy: 60.74%, Test Loss: 0.8819, Test Accuracy: 62.03%\n",
      "Epoch [1100/2500], Train Loss: 0.9078, Train Accuracy: 59.46%, Test Loss: 0.8755, Test Accuracy: 62.03%\n",
      "Epoch [1101/2500], Train Loss: 0.8974, Train Accuracy: 59.74%, Test Loss: 0.8815, Test Accuracy: 60.76%\n",
      "Epoch [1102/2500], Train Loss: 0.8852, Train Accuracy: 59.17%, Test Loss: 0.8903, Test Accuracy: 62.03%\n",
      "Epoch [1103/2500], Train Loss: 0.8865, Train Accuracy: 59.32%, Test Loss: 0.8876, Test Accuracy: 63.29%\n",
      "Epoch [1104/2500], Train Loss: 0.9032, Train Accuracy: 61.02%, Test Loss: 0.8827, Test Accuracy: 62.03%\n",
      "Epoch [1105/2500], Train Loss: 0.8907, Train Accuracy: 60.17%, Test Loss: 0.8892, Test Accuracy: 63.29%\n",
      "Epoch [1106/2500], Train Loss: 0.8846, Train Accuracy: 61.59%, Test Loss: 0.8915, Test Accuracy: 63.29%\n",
      "Epoch [1107/2500], Train Loss: 0.8971, Train Accuracy: 60.03%, Test Loss: 0.8916, Test Accuracy: 63.29%\n",
      "Epoch [1108/2500], Train Loss: 0.8899, Train Accuracy: 60.17%, Test Loss: 0.8912, Test Accuracy: 63.29%\n",
      "Epoch [1109/2500], Train Loss: 0.8974, Train Accuracy: 60.31%, Test Loss: 0.8847, Test Accuracy: 62.03%\n",
      "Epoch [1110/2500], Train Loss: 0.8919, Train Accuracy: 59.32%, Test Loss: 0.8857, Test Accuracy: 63.29%\n",
      "Epoch [1111/2500], Train Loss: 0.8790, Train Accuracy: 59.89%, Test Loss: 0.8861, Test Accuracy: 63.29%\n",
      "Epoch [1112/2500], Train Loss: 0.8964, Train Accuracy: 59.32%, Test Loss: 0.8808, Test Accuracy: 62.03%\n",
      "Epoch [1113/2500], Train Loss: 0.8933, Train Accuracy: 58.61%, Test Loss: 0.8875, Test Accuracy: 63.29%\n",
      "Epoch [1114/2500], Train Loss: 0.8958, Train Accuracy: 60.31%, Test Loss: 0.8958, Test Accuracy: 63.29%\n",
      "Epoch [1115/2500], Train Loss: 0.8914, Train Accuracy: 59.89%, Test Loss: 0.8841, Test Accuracy: 63.29%\n",
      "Epoch [1116/2500], Train Loss: 0.9063, Train Accuracy: 60.60%, Test Loss: 0.8912, Test Accuracy: 63.29%\n",
      "Epoch [1117/2500], Train Loss: 0.8985, Train Accuracy: 59.17%, Test Loss: 0.8974, Test Accuracy: 63.29%\n",
      "Epoch [1118/2500], Train Loss: 0.8935, Train Accuracy: 59.32%, Test Loss: 0.8982, Test Accuracy: 63.29%\n",
      "Epoch [1119/2500], Train Loss: 0.9073, Train Accuracy: 59.89%, Test Loss: 0.8911, Test Accuracy: 63.29%\n",
      "Epoch [1120/2500], Train Loss: 0.8881, Train Accuracy: 59.60%, Test Loss: 0.8854, Test Accuracy: 63.29%\n",
      "Epoch [1121/2500], Train Loss: 0.8943, Train Accuracy: 59.89%, Test Loss: 0.8936, Test Accuracy: 63.29%\n",
      "Epoch [1122/2500], Train Loss: 0.8954, Train Accuracy: 61.31%, Test Loss: 0.9009, Test Accuracy: 63.29%\n",
      "Epoch [1123/2500], Train Loss: 0.8865, Train Accuracy: 60.74%, Test Loss: 0.8943, Test Accuracy: 63.29%\n",
      "Epoch [1124/2500], Train Loss: 0.9009, Train Accuracy: 60.31%, Test Loss: 0.8965, Test Accuracy: 63.29%\n",
      "Epoch [1125/2500], Train Loss: 0.8839, Train Accuracy: 60.60%, Test Loss: 0.8965, Test Accuracy: 63.29%\n",
      "Epoch [1126/2500], Train Loss: 0.8994, Train Accuracy: 59.60%, Test Loss: 0.8886, Test Accuracy: 63.29%\n",
      "Epoch [1127/2500], Train Loss: 0.8899, Train Accuracy: 61.17%, Test Loss: 0.8878, Test Accuracy: 63.29%\n",
      "Epoch [1128/2500], Train Loss: 0.8920, Train Accuracy: 59.60%, Test Loss: 0.8849, Test Accuracy: 63.29%\n",
      "Epoch [1129/2500], Train Loss: 0.8997, Train Accuracy: 60.46%, Test Loss: 0.8970, Test Accuracy: 63.29%\n",
      "Epoch [1130/2500], Train Loss: 0.8771, Train Accuracy: 61.02%, Test Loss: 0.9023, Test Accuracy: 63.29%\n",
      "Epoch [1131/2500], Train Loss: 0.8956, Train Accuracy: 59.74%, Test Loss: 0.9045, Test Accuracy: 63.29%\n",
      "Epoch [1132/2500], Train Loss: 0.8862, Train Accuracy: 59.32%, Test Loss: 0.9080, Test Accuracy: 63.29%\n",
      "Epoch [1133/2500], Train Loss: 0.9017, Train Accuracy: 61.17%, Test Loss: 0.9101, Test Accuracy: 63.29%\n",
      "Epoch [1134/2500], Train Loss: 0.9080, Train Accuracy: 60.74%, Test Loss: 0.8999, Test Accuracy: 63.29%\n",
      "Epoch [1135/2500], Train Loss: 0.8837, Train Accuracy: 60.17%, Test Loss: 0.9080, Test Accuracy: 63.29%\n",
      "Epoch [1136/2500], Train Loss: 0.8951, Train Accuracy: 59.89%, Test Loss: 0.8953, Test Accuracy: 63.29%\n",
      "Epoch [1137/2500], Train Loss: 0.8942, Train Accuracy: 61.02%, Test Loss: 0.8942, Test Accuracy: 63.29%\n",
      "Epoch [1138/2500], Train Loss: 0.9026, Train Accuracy: 60.03%, Test Loss: 0.8893, Test Accuracy: 63.29%\n",
      "Epoch [1139/2500], Train Loss: 0.8988, Train Accuracy: 60.60%, Test Loss: 0.8917, Test Accuracy: 63.29%\n",
      "Epoch [1140/2500], Train Loss: 0.8980, Train Accuracy: 60.17%, Test Loss: 0.8991, Test Accuracy: 63.29%\n",
      "Epoch [1141/2500], Train Loss: 0.9020, Train Accuracy: 59.74%, Test Loss: 0.9014, Test Accuracy: 63.29%\n",
      "Epoch [1142/2500], Train Loss: 0.8884, Train Accuracy: 60.31%, Test Loss: 0.9024, Test Accuracy: 63.29%\n",
      "Epoch [1143/2500], Train Loss: 0.9002, Train Accuracy: 61.02%, Test Loss: 0.9085, Test Accuracy: 63.29%\n",
      "Epoch [1144/2500], Train Loss: 0.8958, Train Accuracy: 60.88%, Test Loss: 0.9061, Test Accuracy: 63.29%\n",
      "Epoch [1145/2500], Train Loss: 0.8798, Train Accuracy: 60.46%, Test Loss: 0.9033, Test Accuracy: 63.29%\n",
      "Epoch [1146/2500], Train Loss: 0.8861, Train Accuracy: 61.17%, Test Loss: 0.8985, Test Accuracy: 63.29%\n",
      "Epoch [1147/2500], Train Loss: 0.8914, Train Accuracy: 60.88%, Test Loss: 0.9003, Test Accuracy: 63.29%\n",
      "Epoch [1148/2500], Train Loss: 0.8963, Train Accuracy: 59.03%, Test Loss: 0.9012, Test Accuracy: 62.03%\n",
      "Epoch [1149/2500], Train Loss: 0.8883, Train Accuracy: 60.03%, Test Loss: 0.8997, Test Accuracy: 62.03%\n",
      "Epoch [1150/2500], Train Loss: 0.8979, Train Accuracy: 61.59%, Test Loss: 0.9073, Test Accuracy: 63.29%\n",
      "Epoch [1151/2500], Train Loss: 0.8889, Train Accuracy: 59.17%, Test Loss: 0.9013, Test Accuracy: 63.29%\n",
      "Epoch [1152/2500], Train Loss: 0.8852, Train Accuracy: 60.03%, Test Loss: 0.8964, Test Accuracy: 63.29%\n",
      "Epoch [1153/2500], Train Loss: 0.8745, Train Accuracy: 59.89%, Test Loss: 0.8928, Test Accuracy: 63.29%\n",
      "Epoch [1154/2500], Train Loss: 0.8927, Train Accuracy: 59.60%, Test Loss: 0.8980, Test Accuracy: 63.29%\n",
      "Epoch [1155/2500], Train Loss: 0.8984, Train Accuracy: 59.60%, Test Loss: 0.8953, Test Accuracy: 62.03%\n",
      "Epoch [1156/2500], Train Loss: 0.9048, Train Accuracy: 60.74%, Test Loss: 0.8969, Test Accuracy: 62.03%\n",
      "Epoch [1157/2500], Train Loss: 0.8788, Train Accuracy: 63.16%, Test Loss: 0.8916, Test Accuracy: 63.29%\n",
      "Epoch [1158/2500], Train Loss: 0.8932, Train Accuracy: 61.74%, Test Loss: 0.8872, Test Accuracy: 62.03%\n",
      "Epoch [1159/2500], Train Loss: 0.9056, Train Accuracy: 59.32%, Test Loss: 0.8903, Test Accuracy: 62.03%\n",
      "Epoch [1160/2500], Train Loss: 0.8812, Train Accuracy: 60.46%, Test Loss: 0.8859, Test Accuracy: 62.03%\n",
      "Epoch [1161/2500], Train Loss: 0.8999, Train Accuracy: 60.31%, Test Loss: 0.8816, Test Accuracy: 64.56%\n",
      "Epoch [1162/2500], Train Loss: 0.8860, Train Accuracy: 59.60%, Test Loss: 0.8853, Test Accuracy: 62.03%\n",
      "Epoch [1163/2500], Train Loss: 0.8819, Train Accuracy: 59.46%, Test Loss: 0.8700, Test Accuracy: 62.03%\n",
      "Epoch [1164/2500], Train Loss: 0.9004, Train Accuracy: 60.03%, Test Loss: 0.8774, Test Accuracy: 62.03%\n",
      "Epoch [1165/2500], Train Loss: 0.8855, Train Accuracy: 60.03%, Test Loss: 0.8837, Test Accuracy: 62.03%\n",
      "Epoch [1166/2500], Train Loss: 0.8838, Train Accuracy: 58.89%, Test Loss: 0.8875, Test Accuracy: 63.29%\n",
      "Epoch [1167/2500], Train Loss: 0.8788, Train Accuracy: 60.88%, Test Loss: 0.8804, Test Accuracy: 64.56%\n",
      "Epoch [1168/2500], Train Loss: 0.8920, Train Accuracy: 59.74%, Test Loss: 0.8826, Test Accuracy: 64.56%\n",
      "Epoch [1169/2500], Train Loss: 0.8825, Train Accuracy: 61.02%, Test Loss: 0.8850, Test Accuracy: 62.03%\n",
      "Epoch [1170/2500], Train Loss: 0.8869, Train Accuracy: 61.31%, Test Loss: 0.8817, Test Accuracy: 63.29%\n",
      "Epoch [1171/2500], Train Loss: 0.8937, Train Accuracy: 59.46%, Test Loss: 0.8789, Test Accuracy: 62.03%\n",
      "Epoch [1172/2500], Train Loss: 0.8963, Train Accuracy: 60.46%, Test Loss: 0.8786, Test Accuracy: 62.03%\n",
      "Epoch [1173/2500], Train Loss: 0.8676, Train Accuracy: 60.88%, Test Loss: 0.8886, Test Accuracy: 62.03%\n",
      "Epoch [1174/2500], Train Loss: 0.8950, Train Accuracy: 59.32%, Test Loss: 0.8872, Test Accuracy: 62.03%\n",
      "Epoch [1175/2500], Train Loss: 0.8843, Train Accuracy: 61.45%, Test Loss: 0.8815, Test Accuracy: 62.03%\n",
      "Epoch [1176/2500], Train Loss: 0.8818, Train Accuracy: 61.17%, Test Loss: 0.8742, Test Accuracy: 63.29%\n",
      "Epoch [1177/2500], Train Loss: 0.8830, Train Accuracy: 59.74%, Test Loss: 0.8801, Test Accuracy: 63.29%\n",
      "Epoch [1178/2500], Train Loss: 0.9087, Train Accuracy: 58.75%, Test Loss: 0.8808, Test Accuracy: 63.29%\n",
      "Epoch [1179/2500], Train Loss: 0.8670, Train Accuracy: 62.45%, Test Loss: 0.8693, Test Accuracy: 62.03%\n",
      "Epoch [1180/2500], Train Loss: 0.8966, Train Accuracy: 59.74%, Test Loss: 0.8704, Test Accuracy: 63.29%\n",
      "Epoch [1181/2500], Train Loss: 0.8890, Train Accuracy: 60.46%, Test Loss: 0.8689, Test Accuracy: 63.29%\n",
      "Epoch [1182/2500], Train Loss: 0.8850, Train Accuracy: 59.74%, Test Loss: 0.8733, Test Accuracy: 63.29%\n",
      "Epoch [1183/2500], Train Loss: 0.8806, Train Accuracy: 61.31%, Test Loss: 0.8776, Test Accuracy: 63.29%\n",
      "Epoch [1184/2500], Train Loss: 0.9045, Train Accuracy: 59.46%, Test Loss: 0.8909, Test Accuracy: 63.29%\n",
      "Epoch [1185/2500], Train Loss: 0.8750, Train Accuracy: 60.03%, Test Loss: 0.8818, Test Accuracy: 63.29%\n",
      "Epoch [1186/2500], Train Loss: 0.8717, Train Accuracy: 60.60%, Test Loss: 0.8807, Test Accuracy: 63.29%\n",
      "Epoch [1187/2500], Train Loss: 0.8745, Train Accuracy: 62.16%, Test Loss: 0.8756, Test Accuracy: 63.29%\n",
      "Epoch [1188/2500], Train Loss: 0.8733, Train Accuracy: 60.31%, Test Loss: 0.8790, Test Accuracy: 63.29%\n",
      "Epoch [1189/2500], Train Loss: 0.8862, Train Accuracy: 60.74%, Test Loss: 0.8809, Test Accuracy: 63.29%\n",
      "Epoch [1190/2500], Train Loss: 0.8966, Train Accuracy: 61.59%, Test Loss: 0.8818, Test Accuracy: 62.03%\n",
      "Epoch [1191/2500], Train Loss: 0.8718, Train Accuracy: 61.02%, Test Loss: 0.8758, Test Accuracy: 63.29%\n",
      "Epoch [1192/2500], Train Loss: 0.9125, Train Accuracy: 58.61%, Test Loss: 0.8801, Test Accuracy: 63.29%\n",
      "Epoch [1193/2500], Train Loss: 0.8804, Train Accuracy: 61.02%, Test Loss: 0.8810, Test Accuracy: 63.29%\n",
      "Epoch [1194/2500], Train Loss: 0.8994, Train Accuracy: 59.74%, Test Loss: 0.8856, Test Accuracy: 63.29%\n",
      "Epoch [1195/2500], Train Loss: 0.8796, Train Accuracy: 60.03%, Test Loss: 0.8823, Test Accuracy: 63.29%\n",
      "Epoch [1196/2500], Train Loss: 0.8769, Train Accuracy: 60.74%, Test Loss: 0.8917, Test Accuracy: 63.29%\n",
      "Epoch [1197/2500], Train Loss: 0.8955, Train Accuracy: 58.75%, Test Loss: 0.8885, Test Accuracy: 63.29%\n",
      "Epoch [1198/2500], Train Loss: 0.8790, Train Accuracy: 61.02%, Test Loss: 0.8781, Test Accuracy: 63.29%\n",
      "Epoch [1199/2500], Train Loss: 0.8813, Train Accuracy: 60.46%, Test Loss: 0.8769, Test Accuracy: 63.29%\n",
      "Epoch [1200/2500], Train Loss: 0.8740, Train Accuracy: 60.60%, Test Loss: 0.8832, Test Accuracy: 63.29%\n",
      "Epoch [1201/2500], Train Loss: 0.8846, Train Accuracy: 60.31%, Test Loss: 0.8704, Test Accuracy: 63.29%\n",
      "Epoch [1202/2500], Train Loss: 0.8856, Train Accuracy: 59.03%, Test Loss: 0.8690, Test Accuracy: 62.03%\n",
      "Epoch [1203/2500], Train Loss: 0.8920, Train Accuracy: 62.30%, Test Loss: 0.8733, Test Accuracy: 63.29%\n",
      "Epoch [1204/2500], Train Loss: 0.8748, Train Accuracy: 61.02%, Test Loss: 0.8743, Test Accuracy: 62.03%\n",
      "Epoch [1205/2500], Train Loss: 0.8742, Train Accuracy: 60.31%, Test Loss: 0.8823, Test Accuracy: 63.29%\n",
      "Epoch [1206/2500], Train Loss: 0.8825, Train Accuracy: 62.16%, Test Loss: 0.8793, Test Accuracy: 63.29%\n",
      "Epoch [1207/2500], Train Loss: 0.8779, Train Accuracy: 61.45%, Test Loss: 0.8744, Test Accuracy: 63.29%\n",
      "Epoch [1208/2500], Train Loss: 0.9072, Train Accuracy: 61.59%, Test Loss: 0.8695, Test Accuracy: 62.03%\n",
      "Epoch [1209/2500], Train Loss: 0.8687, Train Accuracy: 59.89%, Test Loss: 0.8770, Test Accuracy: 62.03%\n",
      "Epoch [1210/2500], Train Loss: 0.8844, Train Accuracy: 59.32%, Test Loss: 0.8672, Test Accuracy: 62.03%\n",
      "Epoch [1211/2500], Train Loss: 0.8993, Train Accuracy: 61.59%, Test Loss: 0.8753, Test Accuracy: 62.03%\n",
      "Epoch [1212/2500], Train Loss: 0.8938, Train Accuracy: 59.03%, Test Loss: 0.8722, Test Accuracy: 63.29%\n",
      "Epoch [1213/2500], Train Loss: 0.8990, Train Accuracy: 62.45%, Test Loss: 0.8741, Test Accuracy: 63.29%\n",
      "Epoch [1214/2500], Train Loss: 0.8758, Train Accuracy: 60.46%, Test Loss: 0.8800, Test Accuracy: 62.03%\n",
      "Epoch [1215/2500], Train Loss: 0.8688, Train Accuracy: 60.17%, Test Loss: 0.8719, Test Accuracy: 62.03%\n",
      "Epoch [1216/2500], Train Loss: 0.9039, Train Accuracy: 60.31%, Test Loss: 0.8776, Test Accuracy: 62.03%\n",
      "Epoch [1217/2500], Train Loss: 0.8689, Train Accuracy: 61.45%, Test Loss: 0.8733, Test Accuracy: 60.76%\n",
      "Epoch [1218/2500], Train Loss: 0.8795, Train Accuracy: 62.30%, Test Loss: 0.8780, Test Accuracy: 60.76%\n",
      "Epoch [1219/2500], Train Loss: 0.8846, Train Accuracy: 59.17%, Test Loss: 0.8823, Test Accuracy: 62.03%\n",
      "Epoch [1220/2500], Train Loss: 0.8903, Train Accuracy: 60.60%, Test Loss: 0.8845, Test Accuracy: 62.03%\n",
      "Epoch [1221/2500], Train Loss: 0.8876, Train Accuracy: 60.17%, Test Loss: 0.8858, Test Accuracy: 62.03%\n",
      "Epoch [1222/2500], Train Loss: 0.8731, Train Accuracy: 60.88%, Test Loss: 0.8719, Test Accuracy: 62.03%\n",
      "Epoch [1223/2500], Train Loss: 0.8968, Train Accuracy: 60.31%, Test Loss: 0.8748, Test Accuracy: 62.03%\n",
      "Epoch [1224/2500], Train Loss: 0.8742, Train Accuracy: 61.02%, Test Loss: 0.8689, Test Accuracy: 60.76%\n",
      "Epoch [1225/2500], Train Loss: 0.8743, Train Accuracy: 60.03%, Test Loss: 0.8842, Test Accuracy: 60.76%\n",
      "Epoch [1226/2500], Train Loss: 0.8916, Train Accuracy: 60.46%, Test Loss: 0.8825, Test Accuracy: 60.76%\n",
      "Epoch [1227/2500], Train Loss: 0.8668, Train Accuracy: 61.59%, Test Loss: 0.8780, Test Accuracy: 60.76%\n",
      "Epoch [1228/2500], Train Loss: 0.8705, Train Accuracy: 62.45%, Test Loss: 0.8709, Test Accuracy: 62.03%\n",
      "Epoch [1229/2500], Train Loss: 0.8876, Train Accuracy: 61.45%, Test Loss: 0.8692, Test Accuracy: 63.29%\n",
      "Epoch [1230/2500], Train Loss: 0.8893, Train Accuracy: 60.46%, Test Loss: 0.8692, Test Accuracy: 62.03%\n",
      "Epoch [1231/2500], Train Loss: 0.8786, Train Accuracy: 62.02%, Test Loss: 0.8702, Test Accuracy: 62.03%\n",
      "Epoch [1232/2500], Train Loss: 0.8919, Train Accuracy: 60.46%, Test Loss: 0.8724, Test Accuracy: 62.03%\n",
      "Epoch [1233/2500], Train Loss: 0.8951, Train Accuracy: 60.88%, Test Loss: 0.8638, Test Accuracy: 63.29%\n",
      "Epoch [1234/2500], Train Loss: 0.8858, Train Accuracy: 61.17%, Test Loss: 0.8605, Test Accuracy: 62.03%\n",
      "Epoch [1235/2500], Train Loss: 0.8809, Train Accuracy: 59.89%, Test Loss: 0.8648, Test Accuracy: 62.03%\n",
      "Epoch [1236/2500], Train Loss: 0.8721, Train Accuracy: 62.45%, Test Loss: 0.8625, Test Accuracy: 63.29%\n",
      "Epoch [1237/2500], Train Loss: 0.8827, Train Accuracy: 60.88%, Test Loss: 0.8627, Test Accuracy: 63.29%\n",
      "Epoch [1238/2500], Train Loss: 0.8791, Train Accuracy: 60.74%, Test Loss: 0.8644, Test Accuracy: 63.29%\n",
      "Epoch [1239/2500], Train Loss: 0.8935, Train Accuracy: 60.46%, Test Loss: 0.8638, Test Accuracy: 62.03%\n",
      "Epoch [1240/2500], Train Loss: 0.8924, Train Accuracy: 59.17%, Test Loss: 0.8721, Test Accuracy: 62.03%\n",
      "Epoch [1241/2500], Train Loss: 0.8608, Train Accuracy: 61.31%, Test Loss: 0.8798, Test Accuracy: 62.03%\n",
      "Epoch [1242/2500], Train Loss: 0.8783, Train Accuracy: 60.31%, Test Loss: 0.8856, Test Accuracy: 62.03%\n",
      "Epoch [1243/2500], Train Loss: 0.8864, Train Accuracy: 60.17%, Test Loss: 0.8727, Test Accuracy: 62.03%\n",
      "Epoch [1244/2500], Train Loss: 0.8721, Train Accuracy: 60.31%, Test Loss: 0.8750, Test Accuracy: 62.03%\n",
      "Epoch [1245/2500], Train Loss: 0.8872, Train Accuracy: 61.17%, Test Loss: 0.8835, Test Accuracy: 62.03%\n",
      "Epoch [1246/2500], Train Loss: 0.8920, Train Accuracy: 61.02%, Test Loss: 0.8920, Test Accuracy: 60.76%\n",
      "Epoch [1247/2500], Train Loss: 0.8698, Train Accuracy: 64.15%, Test Loss: 0.8854, Test Accuracy: 62.03%\n",
      "Epoch [1248/2500], Train Loss: 0.8867, Train Accuracy: 60.60%, Test Loss: 0.8889, Test Accuracy: 60.76%\n",
      "Epoch [1249/2500], Train Loss: 0.8857, Train Accuracy: 60.60%, Test Loss: 0.8815, Test Accuracy: 62.03%\n",
      "Epoch [1250/2500], Train Loss: 0.8798, Train Accuracy: 60.88%, Test Loss: 0.8852, Test Accuracy: 62.03%\n",
      "Epoch [1251/2500], Train Loss: 0.8573, Train Accuracy: 60.60%, Test Loss: 0.8819, Test Accuracy: 60.76%\n",
      "Epoch [1252/2500], Train Loss: 0.8737, Train Accuracy: 61.45%, Test Loss: 0.8745, Test Accuracy: 60.76%\n",
      "Epoch [1253/2500], Train Loss: 0.8737, Train Accuracy: 60.74%, Test Loss: 0.8658, Test Accuracy: 62.03%\n",
      "Epoch [1254/2500], Train Loss: 0.8879, Train Accuracy: 59.74%, Test Loss: 0.8643, Test Accuracy: 62.03%\n",
      "Epoch [1255/2500], Train Loss: 0.8845, Train Accuracy: 60.60%, Test Loss: 0.8701, Test Accuracy: 62.03%\n",
      "Epoch [1256/2500], Train Loss: 0.8857, Train Accuracy: 60.03%, Test Loss: 0.8786, Test Accuracy: 62.03%\n",
      "Epoch [1257/2500], Train Loss: 0.8796, Train Accuracy: 59.60%, Test Loss: 0.8835, Test Accuracy: 60.76%\n",
      "Epoch [1258/2500], Train Loss: 0.8728, Train Accuracy: 60.46%, Test Loss: 0.8769, Test Accuracy: 62.03%\n",
      "Epoch [1259/2500], Train Loss: 0.8768, Train Accuracy: 61.17%, Test Loss: 0.8791, Test Accuracy: 60.76%\n",
      "Epoch [1260/2500], Train Loss: 0.8873, Train Accuracy: 60.46%, Test Loss: 0.8767, Test Accuracy: 62.03%\n",
      "Epoch [1261/2500], Train Loss: 0.8653, Train Accuracy: 61.45%, Test Loss: 0.8780, Test Accuracy: 62.03%\n",
      "Epoch [1262/2500], Train Loss: 0.8702, Train Accuracy: 60.31%, Test Loss: 0.8706, Test Accuracy: 62.03%\n",
      "Epoch [1263/2500], Train Loss: 0.8681, Train Accuracy: 61.17%, Test Loss: 0.8750, Test Accuracy: 62.03%\n",
      "Epoch [1264/2500], Train Loss: 0.8774, Train Accuracy: 61.02%, Test Loss: 0.8756, Test Accuracy: 60.76%\n",
      "Epoch [1265/2500], Train Loss: 0.8795, Train Accuracy: 60.74%, Test Loss: 0.8811, Test Accuracy: 60.76%\n",
      "Epoch [1266/2500], Train Loss: 0.8697, Train Accuracy: 62.16%, Test Loss: 0.8709, Test Accuracy: 63.29%\n",
      "Epoch [1267/2500], Train Loss: 0.8762, Train Accuracy: 61.31%, Test Loss: 0.8764, Test Accuracy: 62.03%\n",
      "Epoch [1268/2500], Train Loss: 0.8952, Train Accuracy: 60.60%, Test Loss: 0.8714, Test Accuracy: 62.03%\n",
      "Epoch [1269/2500], Train Loss: 0.8771, Train Accuracy: 60.03%, Test Loss: 0.8772, Test Accuracy: 64.56%\n",
      "Epoch [1270/2500], Train Loss: 0.8813, Train Accuracy: 60.46%, Test Loss: 0.8797, Test Accuracy: 63.29%\n",
      "Epoch [1271/2500], Train Loss: 0.8970, Train Accuracy: 59.74%, Test Loss: 0.8752, Test Accuracy: 62.03%\n",
      "Epoch [1272/2500], Train Loss: 0.8574, Train Accuracy: 62.59%, Test Loss: 0.8700, Test Accuracy: 60.76%\n",
      "Epoch [1273/2500], Train Loss: 0.8679, Train Accuracy: 61.02%, Test Loss: 0.8663, Test Accuracy: 63.29%\n",
      "Epoch [1274/2500], Train Loss: 0.8722, Train Accuracy: 60.74%, Test Loss: 0.8604, Test Accuracy: 59.49%\n",
      "Epoch [1275/2500], Train Loss: 0.8900, Train Accuracy: 60.31%, Test Loss: 0.8644, Test Accuracy: 60.76%\n",
      "Epoch [1276/2500], Train Loss: 0.8798, Train Accuracy: 59.32%, Test Loss: 0.8760, Test Accuracy: 62.03%\n",
      "Epoch [1277/2500], Train Loss: 0.8839, Train Accuracy: 61.31%, Test Loss: 0.8674, Test Accuracy: 60.76%\n",
      "Epoch [1278/2500], Train Loss: 0.8888, Train Accuracy: 59.89%, Test Loss: 0.8659, Test Accuracy: 62.03%\n",
      "Epoch [1279/2500], Train Loss: 0.8728, Train Accuracy: 61.59%, Test Loss: 0.8715, Test Accuracy: 62.03%\n",
      "Epoch [1280/2500], Train Loss: 0.8921, Train Accuracy: 59.89%, Test Loss: 0.8725, Test Accuracy: 60.76%\n",
      "Epoch [1281/2500], Train Loss: 0.8849, Train Accuracy: 61.45%, Test Loss: 0.8819, Test Accuracy: 63.29%\n",
      "Epoch [1282/2500], Train Loss: 0.8690, Train Accuracy: 61.02%, Test Loss: 0.8816, Test Accuracy: 62.03%\n",
      "Epoch [1283/2500], Train Loss: 0.8740, Train Accuracy: 62.45%, Test Loss: 0.8793, Test Accuracy: 60.76%\n",
      "Epoch [1284/2500], Train Loss: 0.8802, Train Accuracy: 60.17%, Test Loss: 0.8624, Test Accuracy: 59.49%\n",
      "Epoch [1285/2500], Train Loss: 0.8791, Train Accuracy: 61.17%, Test Loss: 0.8659, Test Accuracy: 59.49%\n",
      "Epoch [1286/2500], Train Loss: 0.8814, Train Accuracy: 61.59%, Test Loss: 0.8604, Test Accuracy: 60.76%\n",
      "Epoch [1287/2500], Train Loss: 0.8809, Train Accuracy: 61.45%, Test Loss: 0.8657, Test Accuracy: 58.23%\n",
      "Epoch [1288/2500], Train Loss: 0.8797, Train Accuracy: 60.03%, Test Loss: 0.8614, Test Accuracy: 59.49%\n",
      "Epoch [1289/2500], Train Loss: 0.8725, Train Accuracy: 60.88%, Test Loss: 0.8564, Test Accuracy: 59.49%\n",
      "Epoch [1290/2500], Train Loss: 0.8772, Train Accuracy: 60.74%, Test Loss: 0.8571, Test Accuracy: 59.49%\n",
      "Epoch [1291/2500], Train Loss: 0.8895, Train Accuracy: 60.03%, Test Loss: 0.8570, Test Accuracy: 58.23%\n",
      "Epoch [1292/2500], Train Loss: 0.8622, Train Accuracy: 61.31%, Test Loss: 0.8610, Test Accuracy: 59.49%\n",
      "Epoch [1293/2500], Train Loss: 0.8785, Train Accuracy: 61.88%, Test Loss: 0.8591, Test Accuracy: 59.49%\n",
      "Epoch [1294/2500], Train Loss: 0.8763, Train Accuracy: 60.03%, Test Loss: 0.8729, Test Accuracy: 60.76%\n",
      "Epoch [1295/2500], Train Loss: 0.8867, Train Accuracy: 60.31%, Test Loss: 0.8708, Test Accuracy: 60.76%\n",
      "Epoch [1296/2500], Train Loss: 0.8761, Train Accuracy: 60.31%, Test Loss: 0.8680, Test Accuracy: 59.49%\n",
      "Epoch [1297/2500], Train Loss: 0.8811, Train Accuracy: 59.60%, Test Loss: 0.8613, Test Accuracy: 62.03%\n",
      "Epoch [1298/2500], Train Loss: 0.8902, Train Accuracy: 59.46%, Test Loss: 0.8802, Test Accuracy: 62.03%\n",
      "Epoch [1299/2500], Train Loss: 0.8698, Train Accuracy: 60.60%, Test Loss: 0.8741, Test Accuracy: 63.29%\n",
      "Epoch [1300/2500], Train Loss: 0.8618, Train Accuracy: 61.74%, Test Loss: 0.8578, Test Accuracy: 62.03%\n",
      "Epoch [1301/2500], Train Loss: 0.8695, Train Accuracy: 60.60%, Test Loss: 0.8549, Test Accuracy: 62.03%\n",
      "Epoch [1302/2500], Train Loss: 0.8665, Train Accuracy: 61.31%, Test Loss: 0.8522, Test Accuracy: 62.03%\n",
      "Epoch [1303/2500], Train Loss: 0.8866, Train Accuracy: 60.03%, Test Loss: 0.8626, Test Accuracy: 62.03%\n",
      "Epoch [1304/2500], Train Loss: 0.8629, Train Accuracy: 61.02%, Test Loss: 0.8694, Test Accuracy: 63.29%\n",
      "Epoch [1305/2500], Train Loss: 0.8579, Train Accuracy: 62.30%, Test Loss: 0.8639, Test Accuracy: 63.29%\n",
      "Epoch [1306/2500], Train Loss: 0.8724, Train Accuracy: 60.60%, Test Loss: 0.8616, Test Accuracy: 63.29%\n",
      "Epoch [1307/2500], Train Loss: 0.8778, Train Accuracy: 61.88%, Test Loss: 0.8585, Test Accuracy: 60.76%\n",
      "Epoch [1308/2500], Train Loss: 0.8668, Train Accuracy: 60.60%, Test Loss: 0.8577, Test Accuracy: 62.03%\n",
      "Epoch [1309/2500], Train Loss: 0.8617, Train Accuracy: 61.02%, Test Loss: 0.8593, Test Accuracy: 62.03%\n",
      "Epoch [1310/2500], Train Loss: 0.8544, Train Accuracy: 61.59%, Test Loss: 0.8550, Test Accuracy: 60.76%\n",
      "Epoch [1311/2500], Train Loss: 0.8644, Train Accuracy: 61.88%, Test Loss: 0.8595, Test Accuracy: 60.76%\n",
      "Epoch [1312/2500], Train Loss: 0.8713, Train Accuracy: 61.02%, Test Loss: 0.8683, Test Accuracy: 62.03%\n",
      "Epoch [1313/2500], Train Loss: 0.8883, Train Accuracy: 59.03%, Test Loss: 0.8661, Test Accuracy: 60.76%\n",
      "Epoch [1314/2500], Train Loss: 0.8695, Train Accuracy: 62.02%, Test Loss: 0.8723, Test Accuracy: 62.03%\n",
      "Epoch [1315/2500], Train Loss: 0.8657, Train Accuracy: 61.59%, Test Loss: 0.8700, Test Accuracy: 62.03%\n",
      "Epoch [1316/2500], Train Loss: 0.8727, Train Accuracy: 60.88%, Test Loss: 0.8658, Test Accuracy: 62.03%\n",
      "Epoch [1317/2500], Train Loss: 0.8731, Train Accuracy: 61.74%, Test Loss: 0.8716, Test Accuracy: 62.03%\n",
      "Epoch [1318/2500], Train Loss: 0.8914, Train Accuracy: 61.59%, Test Loss: 0.8692, Test Accuracy: 62.03%\n",
      "Epoch [1319/2500], Train Loss: 0.8795, Train Accuracy: 62.16%, Test Loss: 0.8702, Test Accuracy: 59.49%\n",
      "Epoch [1320/2500], Train Loss: 0.8634, Train Accuracy: 62.16%, Test Loss: 0.8784, Test Accuracy: 63.29%\n",
      "Epoch [1321/2500], Train Loss: 0.8707, Train Accuracy: 61.45%, Test Loss: 0.8625, Test Accuracy: 62.03%\n",
      "Epoch [1322/2500], Train Loss: 0.8690, Train Accuracy: 61.02%, Test Loss: 0.8647, Test Accuracy: 62.03%\n",
      "Epoch [1323/2500], Train Loss: 0.8800, Train Accuracy: 62.02%, Test Loss: 0.8632, Test Accuracy: 62.03%\n",
      "Epoch [1324/2500], Train Loss: 0.8672, Train Accuracy: 63.16%, Test Loss: 0.8662, Test Accuracy: 60.76%\n",
      "Epoch [1325/2500], Train Loss: 0.8602, Train Accuracy: 63.02%, Test Loss: 0.8627, Test Accuracy: 62.03%\n",
      "Epoch [1326/2500], Train Loss: 0.8685, Train Accuracy: 61.59%, Test Loss: 0.8598, Test Accuracy: 62.03%\n",
      "Epoch [1327/2500], Train Loss: 0.8737, Train Accuracy: 61.59%, Test Loss: 0.8703, Test Accuracy: 60.76%\n",
      "Epoch [1328/2500], Train Loss: 0.8722, Train Accuracy: 62.02%, Test Loss: 0.8487, Test Accuracy: 60.76%\n",
      "Epoch [1329/2500], Train Loss: 0.8695, Train Accuracy: 61.31%, Test Loss: 0.8481, Test Accuracy: 59.49%\n",
      "Epoch [1330/2500], Train Loss: 0.8635, Train Accuracy: 61.17%, Test Loss: 0.8512, Test Accuracy: 60.76%\n",
      "Epoch [1331/2500], Train Loss: 0.8659, Train Accuracy: 62.02%, Test Loss: 0.8537, Test Accuracy: 62.03%\n",
      "Epoch [1332/2500], Train Loss: 0.8681, Train Accuracy: 60.46%, Test Loss: 0.8514, Test Accuracy: 59.49%\n",
      "Epoch [1333/2500], Train Loss: 0.8846, Train Accuracy: 61.59%, Test Loss: 0.8526, Test Accuracy: 60.76%\n",
      "Epoch [1334/2500], Train Loss: 0.8625, Train Accuracy: 61.45%, Test Loss: 0.8460, Test Accuracy: 60.76%\n",
      "Epoch [1335/2500], Train Loss: 0.8942, Train Accuracy: 60.60%, Test Loss: 0.8515, Test Accuracy: 62.03%\n",
      "Epoch [1336/2500], Train Loss: 0.8754, Train Accuracy: 59.60%, Test Loss: 0.8489, Test Accuracy: 62.03%\n",
      "Epoch [1337/2500], Train Loss: 0.8677, Train Accuracy: 59.74%, Test Loss: 0.8356, Test Accuracy: 62.03%\n",
      "Epoch [1338/2500], Train Loss: 0.8797, Train Accuracy: 62.16%, Test Loss: 0.8449, Test Accuracy: 62.03%\n",
      "Epoch [1339/2500], Train Loss: 0.8563, Train Accuracy: 62.16%, Test Loss: 0.8479, Test Accuracy: 60.76%\n",
      "Epoch [1340/2500], Train Loss: 0.8752, Train Accuracy: 60.31%, Test Loss: 0.8540, Test Accuracy: 60.76%\n",
      "Epoch [1341/2500], Train Loss: 0.8733, Train Accuracy: 60.31%, Test Loss: 0.8544, Test Accuracy: 62.03%\n",
      "Epoch [1342/2500], Train Loss: 0.8668, Train Accuracy: 61.88%, Test Loss: 0.8569, Test Accuracy: 62.03%\n",
      "Epoch [1343/2500], Train Loss: 0.8701, Train Accuracy: 62.02%, Test Loss: 0.8599, Test Accuracy: 63.29%\n",
      "Epoch [1344/2500], Train Loss: 0.8953, Train Accuracy: 60.31%, Test Loss: 0.8630, Test Accuracy: 59.49%\n",
      "Epoch [1345/2500], Train Loss: 0.8651, Train Accuracy: 61.31%, Test Loss: 0.8724, Test Accuracy: 60.76%\n",
      "Epoch [1346/2500], Train Loss: 0.8606, Train Accuracy: 61.88%, Test Loss: 0.8640, Test Accuracy: 60.76%\n",
      "Epoch [1347/2500], Train Loss: 0.8731, Train Accuracy: 62.87%, Test Loss: 0.8508, Test Accuracy: 60.76%\n",
      "Epoch [1348/2500], Train Loss: 0.8723, Train Accuracy: 59.32%, Test Loss: 0.8581, Test Accuracy: 60.76%\n",
      "Epoch [1349/2500], Train Loss: 0.8497, Train Accuracy: 62.16%, Test Loss: 0.8580, Test Accuracy: 60.76%\n",
      "Epoch [1350/2500], Train Loss: 0.8563, Train Accuracy: 62.02%, Test Loss: 0.8608, Test Accuracy: 60.76%\n",
      "Epoch [1351/2500], Train Loss: 0.8695, Train Accuracy: 59.89%, Test Loss: 0.8436, Test Accuracy: 59.49%\n",
      "Epoch [1352/2500], Train Loss: 0.8747, Train Accuracy: 60.03%, Test Loss: 0.8591, Test Accuracy: 60.76%\n",
      "Epoch [1353/2500], Train Loss: 0.8726, Train Accuracy: 61.17%, Test Loss: 0.8556, Test Accuracy: 60.76%\n",
      "Epoch [1354/2500], Train Loss: 0.8730, Train Accuracy: 62.16%, Test Loss: 0.8467, Test Accuracy: 60.76%\n",
      "Epoch [1355/2500], Train Loss: 0.8723, Train Accuracy: 59.17%, Test Loss: 0.8453, Test Accuracy: 60.76%\n",
      "Epoch [1356/2500], Train Loss: 0.8551, Train Accuracy: 61.59%, Test Loss: 0.8493, Test Accuracy: 62.03%\n",
      "Epoch [1357/2500], Train Loss: 0.8544, Train Accuracy: 62.02%, Test Loss: 0.8536, Test Accuracy: 62.03%\n",
      "Epoch [1358/2500], Train Loss: 0.8593, Train Accuracy: 60.74%, Test Loss: 0.8531, Test Accuracy: 59.49%\n",
      "Epoch [1359/2500], Train Loss: 0.8751, Train Accuracy: 58.89%, Test Loss: 0.8562, Test Accuracy: 59.49%\n",
      "Epoch [1360/2500], Train Loss: 0.8825, Train Accuracy: 61.31%, Test Loss: 0.8505, Test Accuracy: 60.76%\n",
      "Epoch [1361/2500], Train Loss: 0.8729, Train Accuracy: 60.74%, Test Loss: 0.8518, Test Accuracy: 60.76%\n",
      "Epoch [1362/2500], Train Loss: 0.8710, Train Accuracy: 60.03%, Test Loss: 0.8461, Test Accuracy: 60.76%\n",
      "Epoch [1363/2500], Train Loss: 0.8774, Train Accuracy: 60.03%, Test Loss: 0.8504, Test Accuracy: 62.03%\n",
      "Epoch [1364/2500], Train Loss: 0.8782, Train Accuracy: 61.02%, Test Loss: 0.8487, Test Accuracy: 60.76%\n",
      "Epoch [1365/2500], Train Loss: 0.8603, Train Accuracy: 62.45%, Test Loss: 0.8404, Test Accuracy: 60.76%\n",
      "Epoch [1366/2500], Train Loss: 0.8580, Train Accuracy: 62.16%, Test Loss: 0.8475, Test Accuracy: 60.76%\n",
      "Epoch [1367/2500], Train Loss: 0.8593, Train Accuracy: 63.16%, Test Loss: 0.8616, Test Accuracy: 60.76%\n",
      "Epoch [1368/2500], Train Loss: 0.8794, Train Accuracy: 60.17%, Test Loss: 0.8579, Test Accuracy: 60.76%\n",
      "Epoch [1369/2500], Train Loss: 0.8664, Train Accuracy: 59.60%, Test Loss: 0.8473, Test Accuracy: 60.76%\n",
      "Epoch [1370/2500], Train Loss: 0.8641, Train Accuracy: 61.17%, Test Loss: 0.8451, Test Accuracy: 60.76%\n",
      "Epoch [1371/2500], Train Loss: 0.8713, Train Accuracy: 64.30%, Test Loss: 0.8509, Test Accuracy: 60.76%\n",
      "Epoch [1372/2500], Train Loss: 0.8894, Train Accuracy: 59.03%, Test Loss: 0.8447, Test Accuracy: 60.76%\n",
      "Epoch [1373/2500], Train Loss: 0.8574, Train Accuracy: 61.02%, Test Loss: 0.8361, Test Accuracy: 62.03%\n",
      "Epoch [1374/2500], Train Loss: 0.8734, Train Accuracy: 62.16%, Test Loss: 0.8395, Test Accuracy: 62.03%\n",
      "Epoch [1375/2500], Train Loss: 0.8686, Train Accuracy: 61.45%, Test Loss: 0.8444, Test Accuracy: 62.03%\n",
      "Epoch [1376/2500], Train Loss: 0.8749, Train Accuracy: 60.46%, Test Loss: 0.8527, Test Accuracy: 63.29%\n",
      "Epoch [1377/2500], Train Loss: 0.8731, Train Accuracy: 60.46%, Test Loss: 0.8618, Test Accuracy: 63.29%\n",
      "Epoch [1378/2500], Train Loss: 0.8683, Train Accuracy: 61.88%, Test Loss: 0.8554, Test Accuracy: 60.76%\n",
      "Epoch [1379/2500], Train Loss: 0.8711, Train Accuracy: 61.17%, Test Loss: 0.8715, Test Accuracy: 62.03%\n",
      "Epoch [1380/2500], Train Loss: 0.8755, Train Accuracy: 61.88%, Test Loss: 0.8662, Test Accuracy: 62.03%\n",
      "Epoch [1381/2500], Train Loss: 0.8642, Train Accuracy: 60.88%, Test Loss: 0.8631, Test Accuracy: 62.03%\n",
      "Epoch [1382/2500], Train Loss: 0.8828, Train Accuracy: 60.03%, Test Loss: 0.8606, Test Accuracy: 63.29%\n",
      "Epoch [1383/2500], Train Loss: 0.8635, Train Accuracy: 61.74%, Test Loss: 0.8630, Test Accuracy: 62.03%\n",
      "Epoch [1384/2500], Train Loss: 0.8794, Train Accuracy: 61.31%, Test Loss: 0.8533, Test Accuracy: 62.03%\n",
      "Epoch [1385/2500], Train Loss: 0.8688, Train Accuracy: 61.17%, Test Loss: 0.8539, Test Accuracy: 62.03%\n",
      "Epoch [1386/2500], Train Loss: 0.8611, Train Accuracy: 62.02%, Test Loss: 0.8517, Test Accuracy: 62.03%\n",
      "Epoch [1387/2500], Train Loss: 0.8547, Train Accuracy: 61.59%, Test Loss: 0.8420, Test Accuracy: 60.76%\n",
      "Epoch [1388/2500], Train Loss: 0.8780, Train Accuracy: 61.45%, Test Loss: 0.8530, Test Accuracy: 62.03%\n",
      "Epoch [1389/2500], Train Loss: 0.8638, Train Accuracy: 60.60%, Test Loss: 0.8551, Test Accuracy: 63.29%\n",
      "Epoch [1390/2500], Train Loss: 0.8754, Train Accuracy: 61.02%, Test Loss: 0.8486, Test Accuracy: 62.03%\n",
      "Epoch [1391/2500], Train Loss: 0.8782, Train Accuracy: 60.46%, Test Loss: 0.8584, Test Accuracy: 63.29%\n",
      "Epoch [1392/2500], Train Loss: 0.8599, Train Accuracy: 62.87%, Test Loss: 0.8568, Test Accuracy: 63.29%\n",
      "Epoch [1393/2500], Train Loss: 0.8657, Train Accuracy: 61.17%, Test Loss: 0.8537, Test Accuracy: 62.03%\n",
      "Epoch [1394/2500], Train Loss: 0.8578, Train Accuracy: 61.45%, Test Loss: 0.8621, Test Accuracy: 63.29%\n",
      "Epoch [1395/2500], Train Loss: 0.8807, Train Accuracy: 59.32%, Test Loss: 0.8536, Test Accuracy: 62.03%\n",
      "Epoch [1396/2500], Train Loss: 0.8745, Train Accuracy: 61.17%, Test Loss: 0.8638, Test Accuracy: 62.03%\n",
      "Epoch [1397/2500], Train Loss: 0.8713, Train Accuracy: 61.59%, Test Loss: 0.8678, Test Accuracy: 62.03%\n",
      "Epoch [1398/2500], Train Loss: 0.8729, Train Accuracy: 61.31%, Test Loss: 0.8693, Test Accuracy: 63.29%\n",
      "Epoch [1399/2500], Train Loss: 0.8504, Train Accuracy: 62.02%, Test Loss: 0.8701, Test Accuracy: 62.03%\n",
      "Epoch [1400/2500], Train Loss: 0.8562, Train Accuracy: 61.59%, Test Loss: 0.8680, Test Accuracy: 62.03%\n",
      "Epoch [1401/2500], Train Loss: 0.8556, Train Accuracy: 61.17%, Test Loss: 0.8742, Test Accuracy: 62.03%\n",
      "Epoch [1402/2500], Train Loss: 0.8776, Train Accuracy: 60.31%, Test Loss: 0.8679, Test Accuracy: 62.03%\n",
      "Epoch [1403/2500], Train Loss: 0.8861, Train Accuracy: 60.46%, Test Loss: 0.8547, Test Accuracy: 59.49%\n",
      "Epoch [1404/2500], Train Loss: 0.8636, Train Accuracy: 61.59%, Test Loss: 0.8669, Test Accuracy: 60.76%\n",
      "Epoch [1405/2500], Train Loss: 0.8723, Train Accuracy: 61.02%, Test Loss: 0.8792, Test Accuracy: 60.76%\n",
      "Epoch [1406/2500], Train Loss: 0.8625, Train Accuracy: 60.31%, Test Loss: 0.8662, Test Accuracy: 59.49%\n",
      "Epoch [1407/2500], Train Loss: 0.8629, Train Accuracy: 61.45%, Test Loss: 0.8654, Test Accuracy: 60.76%\n",
      "Epoch [1408/2500], Train Loss: 0.8610, Train Accuracy: 61.74%, Test Loss: 0.8713, Test Accuracy: 59.49%\n",
      "Epoch [1409/2500], Train Loss: 0.8842, Train Accuracy: 59.74%, Test Loss: 0.8711, Test Accuracy: 60.76%\n",
      "Epoch [1410/2500], Train Loss: 0.8667, Train Accuracy: 62.16%, Test Loss: 0.8671, Test Accuracy: 60.76%\n",
      "Epoch [1411/2500], Train Loss: 0.8577, Train Accuracy: 61.88%, Test Loss: 0.8626, Test Accuracy: 60.76%\n",
      "Epoch [1412/2500], Train Loss: 0.8632, Train Accuracy: 60.31%, Test Loss: 0.8648, Test Accuracy: 60.76%\n",
      "Epoch [1413/2500], Train Loss: 0.8580, Train Accuracy: 62.02%, Test Loss: 0.8628, Test Accuracy: 62.03%\n",
      "Epoch [1414/2500], Train Loss: 0.8652, Train Accuracy: 61.59%, Test Loss: 0.8645, Test Accuracy: 60.76%\n",
      "Epoch [1415/2500], Train Loss: 0.8518, Train Accuracy: 62.02%, Test Loss: 0.8575, Test Accuracy: 60.76%\n",
      "Epoch [1416/2500], Train Loss: 0.8690, Train Accuracy: 60.74%, Test Loss: 0.8678, Test Accuracy: 60.76%\n",
      "Epoch [1417/2500], Train Loss: 0.8803, Train Accuracy: 60.46%, Test Loss: 0.8699, Test Accuracy: 59.49%\n",
      "Epoch [1418/2500], Train Loss: 0.8670, Train Accuracy: 61.02%, Test Loss: 0.8749, Test Accuracy: 59.49%\n",
      "Epoch [1419/2500], Train Loss: 0.8725, Train Accuracy: 61.02%, Test Loss: 0.8703, Test Accuracy: 60.76%\n",
      "Epoch [1420/2500], Train Loss: 0.8651, Train Accuracy: 61.45%, Test Loss: 0.8796, Test Accuracy: 62.03%\n",
      "Epoch [1421/2500], Train Loss: 0.8636, Train Accuracy: 61.31%, Test Loss: 0.8735, Test Accuracy: 62.03%\n",
      "Epoch [1422/2500], Train Loss: 0.8461, Train Accuracy: 62.16%, Test Loss: 0.8648, Test Accuracy: 62.03%\n",
      "Epoch [1423/2500], Train Loss: 0.8650, Train Accuracy: 61.31%, Test Loss: 0.8675, Test Accuracy: 62.03%\n",
      "Epoch [1424/2500], Train Loss: 0.8607, Train Accuracy: 61.59%, Test Loss: 0.8711, Test Accuracy: 62.03%\n",
      "Epoch [1425/2500], Train Loss: 0.8595, Train Accuracy: 62.73%, Test Loss: 0.8697, Test Accuracy: 60.76%\n",
      "Epoch [1426/2500], Train Loss: 0.8688, Train Accuracy: 61.31%, Test Loss: 0.8804, Test Accuracy: 62.03%\n",
      "Epoch [1427/2500], Train Loss: 0.8635, Train Accuracy: 59.60%, Test Loss: 0.8788, Test Accuracy: 60.76%\n",
      "Epoch [1428/2500], Train Loss: 0.8625, Train Accuracy: 62.30%, Test Loss: 0.8720, Test Accuracy: 62.03%\n",
      "Epoch [1429/2500], Train Loss: 0.8629, Train Accuracy: 61.74%, Test Loss: 0.8683, Test Accuracy: 62.03%\n",
      "Epoch [1430/2500], Train Loss: 0.8763, Train Accuracy: 60.17%, Test Loss: 0.8600, Test Accuracy: 60.76%\n",
      "Epoch [1431/2500], Train Loss: 0.8658, Train Accuracy: 62.30%, Test Loss: 0.8629, Test Accuracy: 62.03%\n",
      "Epoch [1432/2500], Train Loss: 0.8694, Train Accuracy: 60.60%, Test Loss: 0.8717, Test Accuracy: 62.03%\n",
      "Epoch [1433/2500], Train Loss: 0.8613, Train Accuracy: 62.30%, Test Loss: 0.8755, Test Accuracy: 62.03%\n",
      "Epoch [1434/2500], Train Loss: 0.8593, Train Accuracy: 60.46%, Test Loss: 0.8638, Test Accuracy: 60.76%\n",
      "Epoch [1435/2500], Train Loss: 0.8732, Train Accuracy: 62.45%, Test Loss: 0.8654, Test Accuracy: 62.03%\n",
      "Epoch [1436/2500], Train Loss: 0.8709, Train Accuracy: 61.31%, Test Loss: 0.8654, Test Accuracy: 62.03%\n",
      "Epoch [1437/2500], Train Loss: 0.8675, Train Accuracy: 61.31%, Test Loss: 0.8685, Test Accuracy: 62.03%\n",
      "Epoch [1438/2500], Train Loss: 0.8452, Train Accuracy: 62.30%, Test Loss: 0.8652, Test Accuracy: 62.03%\n",
      "Epoch [1439/2500], Train Loss: 0.8497, Train Accuracy: 63.02%, Test Loss: 0.8591, Test Accuracy: 63.29%\n",
      "Epoch [1440/2500], Train Loss: 0.8523, Train Accuracy: 63.16%, Test Loss: 0.8674, Test Accuracy: 62.03%\n",
      "Epoch [1441/2500], Train Loss: 0.8696, Train Accuracy: 62.16%, Test Loss: 0.8629, Test Accuracy: 63.29%\n",
      "Epoch [1442/2500], Train Loss: 0.8717, Train Accuracy: 62.16%, Test Loss: 0.8693, Test Accuracy: 62.03%\n",
      "Epoch [1443/2500], Train Loss: 0.8446, Train Accuracy: 61.74%, Test Loss: 0.8645, Test Accuracy: 62.03%\n",
      "Epoch [1444/2500], Train Loss: 0.8644, Train Accuracy: 62.16%, Test Loss: 0.8765, Test Accuracy: 62.03%\n",
      "Epoch [1445/2500], Train Loss: 0.8653, Train Accuracy: 60.03%, Test Loss: 0.8642, Test Accuracy: 64.56%\n",
      "Epoch [1446/2500], Train Loss: 0.8652, Train Accuracy: 62.45%, Test Loss: 0.8645, Test Accuracy: 63.29%\n",
      "Epoch [1447/2500], Train Loss: 0.8271, Train Accuracy: 62.02%, Test Loss: 0.8644, Test Accuracy: 64.56%\n",
      "Epoch [1448/2500], Train Loss: 0.8548, Train Accuracy: 61.45%, Test Loss: 0.8717, Test Accuracy: 62.03%\n",
      "Epoch [1449/2500], Train Loss: 0.8712, Train Accuracy: 61.59%, Test Loss: 0.8745, Test Accuracy: 63.29%\n",
      "Epoch [1450/2500], Train Loss: 0.8540, Train Accuracy: 60.60%, Test Loss: 0.8747, Test Accuracy: 63.29%\n",
      "Epoch [1451/2500], Train Loss: 0.8523, Train Accuracy: 63.02%, Test Loss: 0.8651, Test Accuracy: 63.29%\n",
      "Epoch [1452/2500], Train Loss: 0.8662, Train Accuracy: 61.74%, Test Loss: 0.8619, Test Accuracy: 63.29%\n",
      "Epoch [1453/2500], Train Loss: 0.8541, Train Accuracy: 61.02%, Test Loss: 0.8623, Test Accuracy: 60.76%\n",
      "Epoch [1454/2500], Train Loss: 0.8514, Train Accuracy: 62.45%, Test Loss: 0.8622, Test Accuracy: 60.76%\n",
      "Epoch [1455/2500], Train Loss: 0.8710, Train Accuracy: 59.89%, Test Loss: 0.8562, Test Accuracy: 62.03%\n",
      "Epoch [1456/2500], Train Loss: 0.8502, Train Accuracy: 62.02%, Test Loss: 0.8511, Test Accuracy: 62.03%\n",
      "Epoch [1457/2500], Train Loss: 0.8494, Train Accuracy: 60.88%, Test Loss: 0.8474, Test Accuracy: 60.76%\n",
      "Epoch [1458/2500], Train Loss: 0.8777, Train Accuracy: 60.03%, Test Loss: 0.8521, Test Accuracy: 62.03%\n",
      "Epoch [1459/2500], Train Loss: 0.8556, Train Accuracy: 61.02%, Test Loss: 0.8534, Test Accuracy: 60.76%\n",
      "Epoch [1460/2500], Train Loss: 0.8549, Train Accuracy: 63.30%, Test Loss: 0.8553, Test Accuracy: 63.29%\n",
      "Epoch [1461/2500], Train Loss: 0.8561, Train Accuracy: 61.31%, Test Loss: 0.8556, Test Accuracy: 62.03%\n",
      "Epoch [1462/2500], Train Loss: 0.8663, Train Accuracy: 63.02%, Test Loss: 0.8543, Test Accuracy: 63.29%\n",
      "Epoch [1463/2500], Train Loss: 0.8699, Train Accuracy: 60.60%, Test Loss: 0.8600, Test Accuracy: 62.03%\n",
      "Epoch [1464/2500], Train Loss: 0.8641, Train Accuracy: 61.17%, Test Loss: 0.8581, Test Accuracy: 59.49%\n",
      "Epoch [1465/2500], Train Loss: 0.8711, Train Accuracy: 60.17%, Test Loss: 0.8596, Test Accuracy: 63.29%\n",
      "Epoch [1466/2500], Train Loss: 0.8433, Train Accuracy: 61.74%, Test Loss: 0.8618, Test Accuracy: 60.76%\n",
      "Epoch [1467/2500], Train Loss: 0.8658, Train Accuracy: 59.74%, Test Loss: 0.8580, Test Accuracy: 59.49%\n",
      "Epoch [1468/2500], Train Loss: 0.8639, Train Accuracy: 61.02%, Test Loss: 0.8594, Test Accuracy: 62.03%\n",
      "Epoch [1469/2500], Train Loss: 0.8611, Train Accuracy: 60.46%, Test Loss: 0.8586, Test Accuracy: 63.29%\n",
      "Epoch [1470/2500], Train Loss: 0.8662, Train Accuracy: 61.17%, Test Loss: 0.8593, Test Accuracy: 60.76%\n",
      "Epoch [1471/2500], Train Loss: 0.8393, Train Accuracy: 62.87%, Test Loss: 0.8609, Test Accuracy: 60.76%\n",
      "Epoch [1472/2500], Train Loss: 0.8641, Train Accuracy: 62.02%, Test Loss: 0.8577, Test Accuracy: 60.76%\n",
      "Epoch [1473/2500], Train Loss: 0.8713, Train Accuracy: 60.60%, Test Loss: 0.8523, Test Accuracy: 62.03%\n",
      "Epoch [1474/2500], Train Loss: 0.8766, Train Accuracy: 60.88%, Test Loss: 0.8575, Test Accuracy: 62.03%\n",
      "Epoch [1475/2500], Train Loss: 0.8716, Train Accuracy: 60.46%, Test Loss: 0.8594, Test Accuracy: 62.03%\n",
      "Epoch [1476/2500], Train Loss: 0.8541, Train Accuracy: 61.31%, Test Loss: 0.8666, Test Accuracy: 62.03%\n",
      "Epoch [1477/2500], Train Loss: 0.8688, Train Accuracy: 59.89%, Test Loss: 0.8569, Test Accuracy: 60.76%\n",
      "Epoch [1478/2500], Train Loss: 0.8607, Train Accuracy: 60.88%, Test Loss: 0.8579, Test Accuracy: 62.03%\n",
      "Epoch [1479/2500], Train Loss: 0.8628, Train Accuracy: 61.59%, Test Loss: 0.8551, Test Accuracy: 60.76%\n",
      "Epoch [1480/2500], Train Loss: 0.8608, Train Accuracy: 60.60%, Test Loss: 0.8650, Test Accuracy: 62.03%\n",
      "Epoch [1481/2500], Train Loss: 0.8446, Train Accuracy: 61.45%, Test Loss: 0.8702, Test Accuracy: 63.29%\n",
      "Epoch [1482/2500], Train Loss: 0.8493, Train Accuracy: 61.31%, Test Loss: 0.8724, Test Accuracy: 63.29%\n",
      "Epoch [1483/2500], Train Loss: 0.8594, Train Accuracy: 62.59%, Test Loss: 0.8562, Test Accuracy: 62.03%\n",
      "Epoch [1484/2500], Train Loss: 0.8632, Train Accuracy: 61.17%, Test Loss: 0.8547, Test Accuracy: 63.29%\n",
      "Epoch [1485/2500], Train Loss: 0.8635, Train Accuracy: 61.74%, Test Loss: 0.8529, Test Accuracy: 63.29%\n",
      "Epoch [1486/2500], Train Loss: 0.8506, Train Accuracy: 62.30%, Test Loss: 0.8532, Test Accuracy: 60.76%\n",
      "Epoch [1487/2500], Train Loss: 0.8640, Train Accuracy: 61.45%, Test Loss: 0.8461, Test Accuracy: 62.03%\n",
      "Epoch [1488/2500], Train Loss: 0.8569, Train Accuracy: 61.17%, Test Loss: 0.8498, Test Accuracy: 62.03%\n",
      "Epoch [1489/2500], Train Loss: 0.8595, Train Accuracy: 60.74%, Test Loss: 0.8539, Test Accuracy: 62.03%\n",
      "Epoch [1490/2500], Train Loss: 0.8743, Train Accuracy: 61.31%, Test Loss: 0.8549, Test Accuracy: 63.29%\n",
      "Epoch [1491/2500], Train Loss: 0.8496, Train Accuracy: 62.30%, Test Loss: 0.8570, Test Accuracy: 60.76%\n",
      "Epoch [1492/2500], Train Loss: 0.8715, Train Accuracy: 60.46%, Test Loss: 0.8471, Test Accuracy: 60.76%\n",
      "Epoch [1493/2500], Train Loss: 0.8701, Train Accuracy: 60.88%, Test Loss: 0.8485, Test Accuracy: 62.03%\n",
      "Epoch [1494/2500], Train Loss: 0.8461, Train Accuracy: 61.59%, Test Loss: 0.8562, Test Accuracy: 63.29%\n",
      "Epoch [1495/2500], Train Loss: 0.8513, Train Accuracy: 60.88%, Test Loss: 0.8624, Test Accuracy: 63.29%\n",
      "Epoch [1496/2500], Train Loss: 0.8575, Train Accuracy: 61.88%, Test Loss: 0.8572, Test Accuracy: 63.29%\n",
      "Epoch [1497/2500], Train Loss: 0.8466, Train Accuracy: 63.58%, Test Loss: 0.8613, Test Accuracy: 63.29%\n",
      "Epoch [1498/2500], Train Loss: 0.8452, Train Accuracy: 60.88%, Test Loss: 0.8556, Test Accuracy: 62.03%\n",
      "Epoch [1499/2500], Train Loss: 0.8504, Train Accuracy: 61.59%, Test Loss: 0.8610, Test Accuracy: 63.29%\n",
      "Epoch [1500/2500], Train Loss: 0.8651, Train Accuracy: 62.30%, Test Loss: 0.8640, Test Accuracy: 63.29%\n",
      "Epoch [1501/2500], Train Loss: 0.8559, Train Accuracy: 61.88%, Test Loss: 0.8561, Test Accuracy: 63.29%\n",
      "Epoch [1502/2500], Train Loss: 0.8473, Train Accuracy: 62.02%, Test Loss: 0.8553, Test Accuracy: 62.03%\n",
      "Epoch [1503/2500], Train Loss: 0.8433, Train Accuracy: 61.74%, Test Loss: 0.8588, Test Accuracy: 62.03%\n",
      "Epoch [1504/2500], Train Loss: 0.8539, Train Accuracy: 61.88%, Test Loss: 0.8503, Test Accuracy: 62.03%\n",
      "Epoch [1505/2500], Train Loss: 0.8596, Train Accuracy: 62.73%, Test Loss: 0.8433, Test Accuracy: 63.29%\n",
      "Epoch [1506/2500], Train Loss: 0.8499, Train Accuracy: 61.17%, Test Loss: 0.8556, Test Accuracy: 62.03%\n",
      "Epoch [1507/2500], Train Loss: 0.8502, Train Accuracy: 62.30%, Test Loss: 0.8536, Test Accuracy: 62.03%\n",
      "Epoch [1508/2500], Train Loss: 0.8498, Train Accuracy: 61.59%, Test Loss: 0.8680, Test Accuracy: 62.03%\n",
      "Epoch [1509/2500], Train Loss: 0.8683, Train Accuracy: 62.02%, Test Loss: 0.8670, Test Accuracy: 62.03%\n",
      "Epoch [1510/2500], Train Loss: 0.8557, Train Accuracy: 60.88%, Test Loss: 0.8617, Test Accuracy: 62.03%\n",
      "Epoch [1511/2500], Train Loss: 0.8489, Train Accuracy: 61.31%, Test Loss: 0.8582, Test Accuracy: 62.03%\n",
      "Epoch [1512/2500], Train Loss: 0.8622, Train Accuracy: 61.02%, Test Loss: 0.8597, Test Accuracy: 62.03%\n",
      "Epoch [1513/2500], Train Loss: 0.8518, Train Accuracy: 62.45%, Test Loss: 0.8564, Test Accuracy: 62.03%\n",
      "Epoch [1514/2500], Train Loss: 0.8593, Train Accuracy: 61.88%, Test Loss: 0.8523, Test Accuracy: 62.03%\n",
      "Epoch [1515/2500], Train Loss: 0.8608, Train Accuracy: 62.02%, Test Loss: 0.8565, Test Accuracy: 62.03%\n",
      "Epoch [1516/2500], Train Loss: 0.8502, Train Accuracy: 62.02%, Test Loss: 0.8621, Test Accuracy: 62.03%\n",
      "Epoch [1517/2500], Train Loss: 0.8581, Train Accuracy: 60.60%, Test Loss: 0.8533, Test Accuracy: 62.03%\n",
      "Epoch [1518/2500], Train Loss: 0.8558, Train Accuracy: 61.88%, Test Loss: 0.8618, Test Accuracy: 62.03%\n",
      "Epoch [1519/2500], Train Loss: 0.8563, Train Accuracy: 61.88%, Test Loss: 0.8674, Test Accuracy: 62.03%\n",
      "Epoch [1520/2500], Train Loss: 0.8476, Train Accuracy: 62.30%, Test Loss: 0.8636, Test Accuracy: 62.03%\n",
      "Epoch [1521/2500], Train Loss: 0.8530, Train Accuracy: 61.45%, Test Loss: 0.8680, Test Accuracy: 62.03%\n",
      "Epoch [1522/2500], Train Loss: 0.8490, Train Accuracy: 63.44%, Test Loss: 0.8747, Test Accuracy: 62.03%\n",
      "Epoch [1523/2500], Train Loss: 0.8615, Train Accuracy: 62.45%, Test Loss: 0.8635, Test Accuracy: 60.76%\n",
      "Epoch [1524/2500], Train Loss: 0.8508, Train Accuracy: 61.88%, Test Loss: 0.8651, Test Accuracy: 62.03%\n",
      "Epoch [1525/2500], Train Loss: 0.8485, Train Accuracy: 60.03%, Test Loss: 0.8603, Test Accuracy: 62.03%\n",
      "Epoch [1526/2500], Train Loss: 0.8707, Train Accuracy: 62.16%, Test Loss: 0.8684, Test Accuracy: 64.56%\n",
      "Epoch [1527/2500], Train Loss: 0.8786, Train Accuracy: 61.02%, Test Loss: 0.8608, Test Accuracy: 64.56%\n",
      "Epoch [1528/2500], Train Loss: 0.8710, Train Accuracy: 61.45%, Test Loss: 0.8625, Test Accuracy: 63.29%\n",
      "Epoch [1529/2500], Train Loss: 0.8566, Train Accuracy: 61.59%, Test Loss: 0.8644, Test Accuracy: 64.56%\n",
      "Epoch [1530/2500], Train Loss: 0.8584, Train Accuracy: 61.45%, Test Loss: 0.8685, Test Accuracy: 63.29%\n",
      "Epoch [1531/2500], Train Loss: 0.8565, Train Accuracy: 59.46%, Test Loss: 0.8617, Test Accuracy: 64.56%\n",
      "Epoch [1532/2500], Train Loss: 0.8667, Train Accuracy: 61.31%, Test Loss: 0.8692, Test Accuracy: 64.56%\n",
      "Epoch [1533/2500], Train Loss: 0.8406, Train Accuracy: 61.74%, Test Loss: 0.8657, Test Accuracy: 62.03%\n",
      "Epoch [1534/2500], Train Loss: 0.8567, Train Accuracy: 59.89%, Test Loss: 0.8624, Test Accuracy: 63.29%\n",
      "Epoch [1535/2500], Train Loss: 0.8595, Train Accuracy: 62.73%, Test Loss: 0.8717, Test Accuracy: 62.03%\n",
      "Epoch [1536/2500], Train Loss: 0.8729, Train Accuracy: 61.17%, Test Loss: 0.8663, Test Accuracy: 62.03%\n",
      "Epoch [1537/2500], Train Loss: 0.8491, Train Accuracy: 61.74%, Test Loss: 0.8672, Test Accuracy: 62.03%\n",
      "Epoch [1538/2500], Train Loss: 0.8641, Train Accuracy: 61.31%, Test Loss: 0.8604, Test Accuracy: 63.29%\n",
      "Epoch [1539/2500], Train Loss: 0.8566, Train Accuracy: 61.74%, Test Loss: 0.8642, Test Accuracy: 63.29%\n",
      "Epoch [1540/2500], Train Loss: 0.8492, Train Accuracy: 61.02%, Test Loss: 0.8536, Test Accuracy: 63.29%\n",
      "Epoch [1541/2500], Train Loss: 0.8773, Train Accuracy: 60.88%, Test Loss: 0.8571, Test Accuracy: 63.29%\n",
      "Epoch [1542/2500], Train Loss: 0.8592, Train Accuracy: 61.74%, Test Loss: 0.8553, Test Accuracy: 63.29%\n",
      "Epoch [1543/2500], Train Loss: 0.8392, Train Accuracy: 60.46%, Test Loss: 0.8528, Test Accuracy: 63.29%\n",
      "Epoch [1544/2500], Train Loss: 0.8543, Train Accuracy: 59.74%, Test Loss: 0.8528, Test Accuracy: 62.03%\n",
      "Epoch [1545/2500], Train Loss: 0.8487, Train Accuracy: 62.45%, Test Loss: 0.8558, Test Accuracy: 62.03%\n",
      "Epoch [1546/2500], Train Loss: 0.8326, Train Accuracy: 63.02%, Test Loss: 0.8564, Test Accuracy: 62.03%\n",
      "Epoch [1547/2500], Train Loss: 0.8394, Train Accuracy: 61.88%, Test Loss: 0.8493, Test Accuracy: 62.03%\n",
      "Epoch [1548/2500], Train Loss: 0.8302, Train Accuracy: 62.16%, Test Loss: 0.8562, Test Accuracy: 63.29%\n",
      "Epoch [1549/2500], Train Loss: 0.8510, Train Accuracy: 61.02%, Test Loss: 0.8638, Test Accuracy: 62.03%\n",
      "Epoch [1550/2500], Train Loss: 0.8630, Train Accuracy: 60.88%, Test Loss: 0.8488, Test Accuracy: 62.03%\n",
      "Epoch [1551/2500], Train Loss: 0.8534, Train Accuracy: 61.17%, Test Loss: 0.8484, Test Accuracy: 60.76%\n",
      "Epoch [1552/2500], Train Loss: 0.8528, Train Accuracy: 61.02%, Test Loss: 0.8505, Test Accuracy: 60.76%\n",
      "Epoch [1553/2500], Train Loss: 0.8604, Train Accuracy: 62.30%, Test Loss: 0.8502, Test Accuracy: 62.03%\n",
      "Epoch [1554/2500], Train Loss: 0.8536, Train Accuracy: 61.59%, Test Loss: 0.8525, Test Accuracy: 63.29%\n",
      "Epoch [1555/2500], Train Loss: 0.8589, Train Accuracy: 62.59%, Test Loss: 0.8447, Test Accuracy: 63.29%\n",
      "Epoch [1556/2500], Train Loss: 0.8570, Train Accuracy: 61.31%, Test Loss: 0.8484, Test Accuracy: 63.29%\n",
      "Epoch [1557/2500], Train Loss: 0.8561, Train Accuracy: 62.87%, Test Loss: 0.8497, Test Accuracy: 63.29%\n",
      "Epoch [1558/2500], Train Loss: 0.8446, Train Accuracy: 60.31%, Test Loss: 0.8437, Test Accuracy: 62.03%\n",
      "Epoch [1559/2500], Train Loss: 0.8567, Train Accuracy: 61.59%, Test Loss: 0.8462, Test Accuracy: 60.76%\n",
      "Epoch [1560/2500], Train Loss: 0.8535, Train Accuracy: 62.02%, Test Loss: 0.8364, Test Accuracy: 62.03%\n",
      "Epoch [1561/2500], Train Loss: 0.8630, Train Accuracy: 61.17%, Test Loss: 0.8439, Test Accuracy: 62.03%\n",
      "Epoch [1562/2500], Train Loss: 0.8583, Train Accuracy: 61.17%, Test Loss: 0.8469, Test Accuracy: 62.03%\n",
      "Epoch [1563/2500], Train Loss: 0.8463, Train Accuracy: 61.17%, Test Loss: 0.8379, Test Accuracy: 62.03%\n",
      "Epoch [1564/2500], Train Loss: 0.8677, Train Accuracy: 61.17%, Test Loss: 0.8449, Test Accuracy: 62.03%\n",
      "Epoch [1565/2500], Train Loss: 0.8564, Train Accuracy: 61.88%, Test Loss: 0.8483, Test Accuracy: 62.03%\n",
      "Epoch [1566/2500], Train Loss: 0.8323, Train Accuracy: 63.58%, Test Loss: 0.8575, Test Accuracy: 63.29%\n",
      "Epoch [1567/2500], Train Loss: 0.8463, Train Accuracy: 61.45%, Test Loss: 0.8603, Test Accuracy: 62.03%\n",
      "Epoch [1568/2500], Train Loss: 0.8347, Train Accuracy: 63.44%, Test Loss: 0.8583, Test Accuracy: 62.03%\n",
      "Epoch [1569/2500], Train Loss: 0.8727, Train Accuracy: 62.16%, Test Loss: 0.8579, Test Accuracy: 62.03%\n",
      "Epoch [1570/2500], Train Loss: 0.8587, Train Accuracy: 60.74%, Test Loss: 0.8525, Test Accuracy: 62.03%\n",
      "Epoch [1571/2500], Train Loss: 0.8608, Train Accuracy: 62.02%, Test Loss: 0.8545, Test Accuracy: 62.03%\n",
      "Epoch [1572/2500], Train Loss: 0.8495, Train Accuracy: 61.02%, Test Loss: 0.8617, Test Accuracy: 62.03%\n",
      "Epoch [1573/2500], Train Loss: 0.8731, Train Accuracy: 62.02%, Test Loss: 0.8534, Test Accuracy: 63.29%\n",
      "Epoch [1574/2500], Train Loss: 0.8434, Train Accuracy: 62.45%, Test Loss: 0.8566, Test Accuracy: 62.03%\n",
      "Epoch [1575/2500], Train Loss: 0.8513, Train Accuracy: 60.60%, Test Loss: 0.8691, Test Accuracy: 62.03%\n",
      "Epoch [1576/2500], Train Loss: 0.8594, Train Accuracy: 62.59%, Test Loss: 0.8750, Test Accuracy: 62.03%\n",
      "Epoch [1577/2500], Train Loss: 0.8552, Train Accuracy: 62.45%, Test Loss: 0.8637, Test Accuracy: 60.76%\n",
      "Epoch [1578/2500], Train Loss: 0.8584, Train Accuracy: 61.17%, Test Loss: 0.8729, Test Accuracy: 62.03%\n",
      "Epoch [1579/2500], Train Loss: 0.8464, Train Accuracy: 62.73%, Test Loss: 0.8563, Test Accuracy: 62.03%\n",
      "Epoch [1580/2500], Train Loss: 0.8589, Train Accuracy: 62.02%, Test Loss: 0.8446, Test Accuracy: 63.29%\n",
      "Epoch [1581/2500], Train Loss: 0.8530, Train Accuracy: 62.59%, Test Loss: 0.8352, Test Accuracy: 63.29%\n",
      "Epoch [1582/2500], Train Loss: 0.8496, Train Accuracy: 62.16%, Test Loss: 0.8340, Test Accuracy: 60.76%\n",
      "Epoch [1583/2500], Train Loss: 0.8553, Train Accuracy: 60.46%, Test Loss: 0.8471, Test Accuracy: 63.29%\n",
      "Epoch [1584/2500], Train Loss: 0.8352, Train Accuracy: 64.15%, Test Loss: 0.8525, Test Accuracy: 62.03%\n",
      "Epoch [1585/2500], Train Loss: 0.8724, Train Accuracy: 60.46%, Test Loss: 0.8573, Test Accuracy: 63.29%\n",
      "Epoch [1586/2500], Train Loss: 0.8375, Train Accuracy: 63.16%, Test Loss: 0.8519, Test Accuracy: 63.29%\n",
      "Epoch [1587/2500], Train Loss: 0.8547, Train Accuracy: 62.73%, Test Loss: 0.8420, Test Accuracy: 62.03%\n",
      "Epoch [1588/2500], Train Loss: 0.8454, Train Accuracy: 61.31%, Test Loss: 0.8342, Test Accuracy: 62.03%\n",
      "Epoch [1589/2500], Train Loss: 0.8623, Train Accuracy: 61.45%, Test Loss: 0.8379, Test Accuracy: 59.49%\n",
      "Epoch [1590/2500], Train Loss: 0.8621, Train Accuracy: 62.02%, Test Loss: 0.8386, Test Accuracy: 59.49%\n",
      "Epoch [1591/2500], Train Loss: 0.8692, Train Accuracy: 61.74%, Test Loss: 0.8373, Test Accuracy: 60.76%\n",
      "Epoch [1592/2500], Train Loss: 0.8433, Train Accuracy: 61.74%, Test Loss: 0.8430, Test Accuracy: 62.03%\n",
      "Epoch [1593/2500], Train Loss: 0.8478, Train Accuracy: 60.88%, Test Loss: 0.8456, Test Accuracy: 62.03%\n",
      "Epoch [1594/2500], Train Loss: 0.8548, Train Accuracy: 62.02%, Test Loss: 0.8492, Test Accuracy: 62.03%\n",
      "Epoch [1595/2500], Train Loss: 0.8556, Train Accuracy: 62.30%, Test Loss: 0.8463, Test Accuracy: 62.03%\n",
      "Epoch [1596/2500], Train Loss: 0.8525, Train Accuracy: 62.16%, Test Loss: 0.8369, Test Accuracy: 62.03%\n",
      "Epoch [1597/2500], Train Loss: 0.8625, Train Accuracy: 60.60%, Test Loss: 0.8362, Test Accuracy: 62.03%\n",
      "Epoch [1598/2500], Train Loss: 0.8402, Train Accuracy: 63.58%, Test Loss: 0.8389, Test Accuracy: 60.76%\n",
      "Epoch [1599/2500], Train Loss: 0.8481, Train Accuracy: 62.73%, Test Loss: 0.8388, Test Accuracy: 60.76%\n",
      "Epoch [1600/2500], Train Loss: 0.8511, Train Accuracy: 62.59%, Test Loss: 0.8394, Test Accuracy: 59.49%\n",
      "Epoch [1601/2500], Train Loss: 0.8489, Train Accuracy: 61.45%, Test Loss: 0.8329, Test Accuracy: 59.49%\n",
      "Epoch [1602/2500], Train Loss: 0.8568, Train Accuracy: 61.17%, Test Loss: 0.8364, Test Accuracy: 62.03%\n",
      "Epoch [1603/2500], Train Loss: 0.8502, Train Accuracy: 61.59%, Test Loss: 0.8418, Test Accuracy: 62.03%\n",
      "Epoch [1604/2500], Train Loss: 0.8518, Train Accuracy: 61.02%, Test Loss: 0.8407, Test Accuracy: 62.03%\n",
      "Epoch [1605/2500], Train Loss: 0.8422, Train Accuracy: 63.02%, Test Loss: 0.8385, Test Accuracy: 62.03%\n",
      "Epoch [1606/2500], Train Loss: 0.8389, Train Accuracy: 61.59%, Test Loss: 0.8392, Test Accuracy: 60.76%\n",
      "Epoch [1607/2500], Train Loss: 0.8405, Train Accuracy: 61.31%, Test Loss: 0.8385, Test Accuracy: 62.03%\n",
      "Epoch [1608/2500], Train Loss: 0.8507, Train Accuracy: 62.02%, Test Loss: 0.8400, Test Accuracy: 62.03%\n",
      "Epoch [1609/2500], Train Loss: 0.8320, Train Accuracy: 63.87%, Test Loss: 0.8475, Test Accuracy: 60.76%\n",
      "Epoch [1610/2500], Train Loss: 0.8633, Train Accuracy: 60.88%, Test Loss: 0.8421, Test Accuracy: 62.03%\n",
      "Epoch [1611/2500], Train Loss: 0.8511, Train Accuracy: 61.31%, Test Loss: 0.8453, Test Accuracy: 62.03%\n",
      "Epoch [1612/2500], Train Loss: 0.8616, Train Accuracy: 61.45%, Test Loss: 0.8542, Test Accuracy: 62.03%\n",
      "Epoch [1613/2500], Train Loss: 0.8531, Train Accuracy: 62.73%, Test Loss: 0.8534, Test Accuracy: 62.03%\n",
      "Epoch [1614/2500], Train Loss: 0.8299, Train Accuracy: 62.73%, Test Loss: 0.8640, Test Accuracy: 62.03%\n",
      "Epoch [1615/2500], Train Loss: 0.8540, Train Accuracy: 60.88%, Test Loss: 0.8486, Test Accuracy: 62.03%\n",
      "Epoch [1616/2500], Train Loss: 0.8526, Train Accuracy: 60.88%, Test Loss: 0.8522, Test Accuracy: 62.03%\n",
      "Epoch [1617/2500], Train Loss: 0.8551, Train Accuracy: 60.88%, Test Loss: 0.8579, Test Accuracy: 62.03%\n",
      "Epoch [1618/2500], Train Loss: 0.8548, Train Accuracy: 61.17%, Test Loss: 0.8579, Test Accuracy: 62.03%\n",
      "Epoch [1619/2500], Train Loss: 0.8512, Train Accuracy: 63.44%, Test Loss: 0.8570, Test Accuracy: 62.03%\n",
      "Epoch [1620/2500], Train Loss: 0.8435, Train Accuracy: 62.87%, Test Loss: 0.8541, Test Accuracy: 62.03%\n",
      "Epoch [1621/2500], Train Loss: 0.8580, Train Accuracy: 62.59%, Test Loss: 0.8562, Test Accuracy: 63.29%\n",
      "Epoch [1622/2500], Train Loss: 0.8407, Train Accuracy: 61.17%, Test Loss: 0.8512, Test Accuracy: 62.03%\n",
      "Epoch [1623/2500], Train Loss: 0.8602, Train Accuracy: 61.45%, Test Loss: 0.8450, Test Accuracy: 62.03%\n",
      "Epoch [1624/2500], Train Loss: 0.8466, Train Accuracy: 62.73%, Test Loss: 0.8413, Test Accuracy: 62.03%\n",
      "Epoch [1625/2500], Train Loss: 0.8561, Train Accuracy: 63.30%, Test Loss: 0.8348, Test Accuracy: 63.29%\n",
      "Epoch [1626/2500], Train Loss: 0.8391, Train Accuracy: 62.30%, Test Loss: 0.8331, Test Accuracy: 60.76%\n",
      "Epoch [1627/2500], Train Loss: 0.8426, Train Accuracy: 61.88%, Test Loss: 0.8441, Test Accuracy: 62.03%\n",
      "Epoch [1628/2500], Train Loss: 0.8457, Train Accuracy: 63.02%, Test Loss: 0.8408, Test Accuracy: 62.03%\n",
      "Epoch [1629/2500], Train Loss: 0.8445, Train Accuracy: 62.59%, Test Loss: 0.8567, Test Accuracy: 63.29%\n",
      "Epoch [1630/2500], Train Loss: 0.8474, Train Accuracy: 63.73%, Test Loss: 0.8533, Test Accuracy: 63.29%\n",
      "Epoch [1631/2500], Train Loss: 0.8527, Train Accuracy: 60.74%, Test Loss: 0.8549, Test Accuracy: 63.29%\n",
      "Epoch [1632/2500], Train Loss: 0.8480, Train Accuracy: 62.59%, Test Loss: 0.8446, Test Accuracy: 63.29%\n",
      "Epoch [1633/2500], Train Loss: 0.8311, Train Accuracy: 62.45%, Test Loss: 0.8486, Test Accuracy: 62.03%\n",
      "Epoch [1634/2500], Train Loss: 0.8640, Train Accuracy: 61.17%, Test Loss: 0.8533, Test Accuracy: 63.29%\n",
      "Epoch [1635/2500], Train Loss: 0.8455, Train Accuracy: 62.02%, Test Loss: 0.8556, Test Accuracy: 62.03%\n",
      "Epoch [1636/2500], Train Loss: 0.8537, Train Accuracy: 61.17%, Test Loss: 0.8603, Test Accuracy: 62.03%\n",
      "Epoch [1637/2500], Train Loss: 0.8396, Train Accuracy: 62.87%, Test Loss: 0.8581, Test Accuracy: 63.29%\n",
      "Epoch [1638/2500], Train Loss: 0.8550, Train Accuracy: 62.73%, Test Loss: 0.8579, Test Accuracy: 63.29%\n",
      "Epoch [1639/2500], Train Loss: 0.8452, Train Accuracy: 63.87%, Test Loss: 0.8525, Test Accuracy: 62.03%\n",
      "Epoch [1640/2500], Train Loss: 0.8478, Train Accuracy: 61.74%, Test Loss: 0.8513, Test Accuracy: 62.03%\n",
      "Epoch [1641/2500], Train Loss: 0.8410, Train Accuracy: 61.31%, Test Loss: 0.8563, Test Accuracy: 62.03%\n",
      "Epoch [1642/2500], Train Loss: 0.8675, Train Accuracy: 61.17%, Test Loss: 0.8478, Test Accuracy: 62.03%\n",
      "Epoch [1643/2500], Train Loss: 0.8405, Train Accuracy: 61.45%, Test Loss: 0.8482, Test Accuracy: 62.03%\n",
      "Epoch [1644/2500], Train Loss: 0.8522, Train Accuracy: 62.02%, Test Loss: 0.8473, Test Accuracy: 62.03%\n",
      "Epoch [1645/2500], Train Loss: 0.8556, Train Accuracy: 61.88%, Test Loss: 0.8432, Test Accuracy: 60.76%\n",
      "Epoch [1646/2500], Train Loss: 0.8455, Train Accuracy: 61.74%, Test Loss: 0.8560, Test Accuracy: 62.03%\n",
      "Epoch [1647/2500], Train Loss: 0.8515, Train Accuracy: 60.46%, Test Loss: 0.8609, Test Accuracy: 63.29%\n",
      "Epoch [1648/2500], Train Loss: 0.8420, Train Accuracy: 62.16%, Test Loss: 0.8590, Test Accuracy: 63.29%\n",
      "Epoch [1649/2500], Train Loss: 0.8590, Train Accuracy: 61.31%, Test Loss: 0.8555, Test Accuracy: 63.29%\n",
      "Epoch [1650/2500], Train Loss: 0.8369, Train Accuracy: 62.73%, Test Loss: 0.8532, Test Accuracy: 63.29%\n",
      "Epoch [1651/2500], Train Loss: 0.8375, Train Accuracy: 62.02%, Test Loss: 0.8521, Test Accuracy: 62.03%\n",
      "Epoch [1652/2500], Train Loss: 0.8520, Train Accuracy: 60.60%, Test Loss: 0.8511, Test Accuracy: 62.03%\n",
      "Epoch [1653/2500], Train Loss: 0.8597, Train Accuracy: 62.02%, Test Loss: 0.8593, Test Accuracy: 62.03%\n",
      "Epoch [1654/2500], Train Loss: 0.8471, Train Accuracy: 62.45%, Test Loss: 0.8551, Test Accuracy: 62.03%\n",
      "Epoch [1655/2500], Train Loss: 0.8369, Train Accuracy: 63.02%, Test Loss: 0.8537, Test Accuracy: 62.03%\n",
      "Epoch [1656/2500], Train Loss: 0.8551, Train Accuracy: 61.31%, Test Loss: 0.8516, Test Accuracy: 62.03%\n",
      "Epoch [1657/2500], Train Loss: 0.8376, Train Accuracy: 64.01%, Test Loss: 0.8554, Test Accuracy: 62.03%\n",
      "Epoch [1658/2500], Train Loss: 0.8269, Train Accuracy: 63.44%, Test Loss: 0.8536, Test Accuracy: 63.29%\n",
      "Epoch [1659/2500], Train Loss: 0.8598, Train Accuracy: 61.31%, Test Loss: 0.8467, Test Accuracy: 64.56%\n",
      "Epoch [1660/2500], Train Loss: 0.8451, Train Accuracy: 61.88%, Test Loss: 0.8481, Test Accuracy: 64.56%\n",
      "Epoch [1661/2500], Train Loss: 0.8444, Train Accuracy: 61.02%, Test Loss: 0.8479, Test Accuracy: 63.29%\n",
      "Epoch [1662/2500], Train Loss: 0.8524, Train Accuracy: 61.88%, Test Loss: 0.8569, Test Accuracy: 63.29%\n",
      "Epoch [1663/2500], Train Loss: 0.8366, Train Accuracy: 62.59%, Test Loss: 0.8483, Test Accuracy: 63.29%\n",
      "Epoch [1664/2500], Train Loss: 0.8366, Train Accuracy: 62.45%, Test Loss: 0.8605, Test Accuracy: 62.03%\n",
      "Epoch [1665/2500], Train Loss: 0.8239, Train Accuracy: 64.15%, Test Loss: 0.8557, Test Accuracy: 62.03%\n",
      "Epoch [1666/2500], Train Loss: 0.8447, Train Accuracy: 62.45%, Test Loss: 0.8597, Test Accuracy: 60.76%\n",
      "Epoch [1667/2500], Train Loss: 0.8360, Train Accuracy: 62.30%, Test Loss: 0.8582, Test Accuracy: 62.03%\n",
      "Epoch [1668/2500], Train Loss: 0.8349, Train Accuracy: 63.44%, Test Loss: 0.8541, Test Accuracy: 62.03%\n",
      "Epoch [1669/2500], Train Loss: 0.8634, Train Accuracy: 61.88%, Test Loss: 0.8496, Test Accuracy: 63.29%\n",
      "Epoch [1670/2500], Train Loss: 0.8430, Train Accuracy: 62.30%, Test Loss: 0.8625, Test Accuracy: 62.03%\n",
      "Epoch [1671/2500], Train Loss: 0.8444, Train Accuracy: 62.59%, Test Loss: 0.8492, Test Accuracy: 62.03%\n",
      "Epoch [1672/2500], Train Loss: 0.8297, Train Accuracy: 63.02%, Test Loss: 0.8451, Test Accuracy: 62.03%\n",
      "Epoch [1673/2500], Train Loss: 0.8524, Train Accuracy: 63.30%, Test Loss: 0.8441, Test Accuracy: 63.29%\n",
      "Epoch [1674/2500], Train Loss: 0.8435, Train Accuracy: 62.73%, Test Loss: 0.8475, Test Accuracy: 62.03%\n",
      "Epoch [1675/2500], Train Loss: 0.8514, Train Accuracy: 60.88%, Test Loss: 0.8444, Test Accuracy: 62.03%\n",
      "Epoch [1676/2500], Train Loss: 0.8208, Train Accuracy: 63.44%, Test Loss: 0.8422, Test Accuracy: 63.29%\n",
      "Epoch [1677/2500], Train Loss: 0.8526, Train Accuracy: 62.30%, Test Loss: 0.8401, Test Accuracy: 63.29%\n",
      "Epoch [1678/2500], Train Loss: 0.8301, Train Accuracy: 62.59%, Test Loss: 0.8355, Test Accuracy: 60.76%\n",
      "Epoch [1679/2500], Train Loss: 0.8292, Train Accuracy: 63.44%, Test Loss: 0.8368, Test Accuracy: 62.03%\n",
      "Epoch [1680/2500], Train Loss: 0.8274, Train Accuracy: 63.44%, Test Loss: 0.8287, Test Accuracy: 64.56%\n",
      "Epoch [1681/2500], Train Loss: 0.8494, Train Accuracy: 60.60%, Test Loss: 0.8300, Test Accuracy: 64.56%\n",
      "Epoch [1682/2500], Train Loss: 0.8603, Train Accuracy: 60.88%, Test Loss: 0.8331, Test Accuracy: 64.56%\n",
      "Epoch [1683/2500], Train Loss: 0.8573, Train Accuracy: 61.74%, Test Loss: 0.8345, Test Accuracy: 65.82%\n",
      "Epoch [1684/2500], Train Loss: 0.8522, Train Accuracy: 61.88%, Test Loss: 0.8401, Test Accuracy: 64.56%\n",
      "Epoch [1685/2500], Train Loss: 0.8381, Train Accuracy: 62.59%, Test Loss: 0.8504, Test Accuracy: 63.29%\n",
      "Epoch [1686/2500], Train Loss: 0.8406, Train Accuracy: 62.30%, Test Loss: 0.8493, Test Accuracy: 63.29%\n",
      "Epoch [1687/2500], Train Loss: 0.8470, Train Accuracy: 61.17%, Test Loss: 0.8468, Test Accuracy: 62.03%\n",
      "Epoch [1688/2500], Train Loss: 0.8530, Train Accuracy: 59.89%, Test Loss: 0.8392, Test Accuracy: 62.03%\n",
      "Epoch [1689/2500], Train Loss: 0.8352, Train Accuracy: 62.02%, Test Loss: 0.8415, Test Accuracy: 62.03%\n",
      "Epoch [1690/2500], Train Loss: 0.8410, Train Accuracy: 62.73%, Test Loss: 0.8407, Test Accuracy: 62.03%\n",
      "Epoch [1691/2500], Train Loss: 0.8521, Train Accuracy: 61.17%, Test Loss: 0.8437, Test Accuracy: 62.03%\n",
      "Epoch [1692/2500], Train Loss: 0.8396, Train Accuracy: 61.45%, Test Loss: 0.8501, Test Accuracy: 62.03%\n",
      "Epoch [1693/2500], Train Loss: 0.8483, Train Accuracy: 60.88%, Test Loss: 0.8384, Test Accuracy: 60.76%\n",
      "Epoch [1694/2500], Train Loss: 0.8446, Train Accuracy: 63.02%, Test Loss: 0.8496, Test Accuracy: 62.03%\n",
      "Epoch [1695/2500], Train Loss: 0.8442, Train Accuracy: 62.02%, Test Loss: 0.8504, Test Accuracy: 63.29%\n",
      "Epoch [1696/2500], Train Loss: 0.8265, Train Accuracy: 65.15%, Test Loss: 0.8416, Test Accuracy: 64.56%\n",
      "Epoch [1697/2500], Train Loss: 0.8302, Train Accuracy: 63.02%, Test Loss: 0.8477, Test Accuracy: 64.56%\n",
      "Epoch [1698/2500], Train Loss: 0.8367, Train Accuracy: 61.59%, Test Loss: 0.8492, Test Accuracy: 63.29%\n",
      "Epoch [1699/2500], Train Loss: 0.8391, Train Accuracy: 62.87%, Test Loss: 0.8442, Test Accuracy: 60.76%\n",
      "Epoch [1700/2500], Train Loss: 0.8781, Train Accuracy: 61.31%, Test Loss: 0.8450, Test Accuracy: 63.29%\n",
      "Epoch [1701/2500], Train Loss: 0.8430, Train Accuracy: 62.30%, Test Loss: 0.8430, Test Accuracy: 63.29%\n",
      "Epoch [1702/2500], Train Loss: 0.8400, Train Accuracy: 61.59%, Test Loss: 0.8364, Test Accuracy: 63.29%\n",
      "Epoch [1703/2500], Train Loss: 0.8305, Train Accuracy: 63.73%, Test Loss: 0.8426, Test Accuracy: 62.03%\n",
      "Epoch [1704/2500], Train Loss: 0.8421, Train Accuracy: 62.45%, Test Loss: 0.8428, Test Accuracy: 60.76%\n",
      "Epoch [1705/2500], Train Loss: 0.8381, Train Accuracy: 62.73%, Test Loss: 0.8407, Test Accuracy: 62.03%\n",
      "Epoch [1706/2500], Train Loss: 0.8446, Train Accuracy: 61.45%, Test Loss: 0.8479, Test Accuracy: 64.56%\n",
      "Epoch [1707/2500], Train Loss: 0.8523, Train Accuracy: 62.02%, Test Loss: 0.8427, Test Accuracy: 64.56%\n",
      "Epoch [1708/2500], Train Loss: 0.8507, Train Accuracy: 61.59%, Test Loss: 0.8451, Test Accuracy: 64.56%\n",
      "Epoch [1709/2500], Train Loss: 0.8378, Train Accuracy: 62.45%, Test Loss: 0.8426, Test Accuracy: 65.82%\n",
      "Epoch [1710/2500], Train Loss: 0.8278, Train Accuracy: 64.44%, Test Loss: 0.8411, Test Accuracy: 64.56%\n",
      "Epoch [1711/2500], Train Loss: 0.8380, Train Accuracy: 62.16%, Test Loss: 0.8438, Test Accuracy: 63.29%\n",
      "Epoch [1712/2500], Train Loss: 0.8365, Train Accuracy: 61.88%, Test Loss: 0.8410, Test Accuracy: 62.03%\n",
      "Epoch [1713/2500], Train Loss: 0.8439, Train Accuracy: 62.16%, Test Loss: 0.8426, Test Accuracy: 60.76%\n",
      "Epoch [1714/2500], Train Loss: 0.8353, Train Accuracy: 61.45%, Test Loss: 0.8429, Test Accuracy: 62.03%\n",
      "Epoch [1715/2500], Train Loss: 0.8344, Train Accuracy: 62.87%, Test Loss: 0.8385, Test Accuracy: 62.03%\n",
      "Epoch [1716/2500], Train Loss: 0.8335, Train Accuracy: 63.30%, Test Loss: 0.8507, Test Accuracy: 60.76%\n",
      "Epoch [1717/2500], Train Loss: 0.8521, Train Accuracy: 60.03%, Test Loss: 0.8542, Test Accuracy: 60.76%\n",
      "Epoch [1718/2500], Train Loss: 0.8436, Train Accuracy: 61.88%, Test Loss: 0.8489, Test Accuracy: 60.76%\n",
      "Epoch [1719/2500], Train Loss: 0.8294, Train Accuracy: 62.73%, Test Loss: 0.8466, Test Accuracy: 62.03%\n",
      "Epoch [1720/2500], Train Loss: 0.8321, Train Accuracy: 62.30%, Test Loss: 0.8449, Test Accuracy: 62.03%\n",
      "Epoch [1721/2500], Train Loss: 0.8539, Train Accuracy: 61.59%, Test Loss: 0.8458, Test Accuracy: 62.03%\n",
      "Epoch [1722/2500], Train Loss: 0.8286, Train Accuracy: 61.17%, Test Loss: 0.8446, Test Accuracy: 62.03%\n",
      "Epoch [1723/2500], Train Loss: 0.8288, Train Accuracy: 61.45%, Test Loss: 0.8481, Test Accuracy: 62.03%\n",
      "Epoch [1724/2500], Train Loss: 0.8397, Train Accuracy: 63.44%, Test Loss: 0.8472, Test Accuracy: 62.03%\n",
      "Epoch [1725/2500], Train Loss: 0.8310, Train Accuracy: 63.02%, Test Loss: 0.8434, Test Accuracy: 63.29%\n",
      "Epoch [1726/2500], Train Loss: 0.8354, Train Accuracy: 62.87%, Test Loss: 0.8423, Test Accuracy: 63.29%\n",
      "Epoch [1727/2500], Train Loss: 0.8330, Train Accuracy: 61.45%, Test Loss: 0.8423, Test Accuracy: 64.56%\n",
      "Epoch [1728/2500], Train Loss: 0.8179, Train Accuracy: 63.58%, Test Loss: 0.8449, Test Accuracy: 60.76%\n",
      "Epoch [1729/2500], Train Loss: 0.8411, Train Accuracy: 62.59%, Test Loss: 0.8503, Test Accuracy: 62.03%\n",
      "Epoch [1730/2500], Train Loss: 0.8444, Train Accuracy: 63.02%, Test Loss: 0.8480, Test Accuracy: 62.03%\n",
      "Epoch [1731/2500], Train Loss: 0.8319, Train Accuracy: 62.87%, Test Loss: 0.8520, Test Accuracy: 62.03%\n",
      "Epoch [1732/2500], Train Loss: 0.8434, Train Accuracy: 63.16%, Test Loss: 0.8516, Test Accuracy: 62.03%\n",
      "Epoch [1733/2500], Train Loss: 0.8489, Train Accuracy: 61.74%, Test Loss: 0.8536, Test Accuracy: 63.29%\n",
      "Epoch [1734/2500], Train Loss: 0.8316, Train Accuracy: 62.73%, Test Loss: 0.8444, Test Accuracy: 64.56%\n",
      "Epoch [1735/2500], Train Loss: 0.8321, Train Accuracy: 60.74%, Test Loss: 0.8459, Test Accuracy: 62.03%\n",
      "Epoch [1736/2500], Train Loss: 0.8400, Train Accuracy: 61.02%, Test Loss: 0.8483, Test Accuracy: 60.76%\n",
      "Epoch [1737/2500], Train Loss: 0.8267, Train Accuracy: 63.58%, Test Loss: 0.8444, Test Accuracy: 60.76%\n",
      "Epoch [1738/2500], Train Loss: 0.8327, Train Accuracy: 61.88%, Test Loss: 0.8531, Test Accuracy: 60.76%\n",
      "Epoch [1739/2500], Train Loss: 0.8326, Train Accuracy: 64.01%, Test Loss: 0.8457, Test Accuracy: 60.76%\n",
      "Epoch [1740/2500], Train Loss: 0.8368, Train Accuracy: 63.02%, Test Loss: 0.8472, Test Accuracy: 59.49%\n",
      "Epoch [1741/2500], Train Loss: 0.8310, Train Accuracy: 63.58%, Test Loss: 0.8438, Test Accuracy: 60.76%\n",
      "Epoch [1742/2500], Train Loss: 0.8356, Train Accuracy: 61.31%, Test Loss: 0.8411, Test Accuracy: 62.03%\n",
      "Epoch [1743/2500], Train Loss: 0.8402, Train Accuracy: 62.30%, Test Loss: 0.8426, Test Accuracy: 60.76%\n",
      "Epoch [1744/2500], Train Loss: 0.8457, Train Accuracy: 61.74%, Test Loss: 0.8441, Test Accuracy: 62.03%\n",
      "Epoch [1745/2500], Train Loss: 0.8392, Train Accuracy: 62.02%, Test Loss: 0.8436, Test Accuracy: 62.03%\n",
      "Epoch [1746/2500], Train Loss: 0.8452, Train Accuracy: 60.60%, Test Loss: 0.8507, Test Accuracy: 60.76%\n",
      "Epoch [1747/2500], Train Loss: 0.8434, Train Accuracy: 61.17%, Test Loss: 0.8436, Test Accuracy: 60.76%\n",
      "Epoch [1748/2500], Train Loss: 0.8315, Train Accuracy: 62.45%, Test Loss: 0.8417, Test Accuracy: 60.76%\n",
      "Epoch [1749/2500], Train Loss: 0.8336, Train Accuracy: 63.02%, Test Loss: 0.8394, Test Accuracy: 62.03%\n",
      "Epoch [1750/2500], Train Loss: 0.8184, Train Accuracy: 63.44%, Test Loss: 0.8424, Test Accuracy: 62.03%\n",
      "Epoch [1751/2500], Train Loss: 0.8323, Train Accuracy: 62.02%, Test Loss: 0.8435, Test Accuracy: 60.76%\n",
      "Epoch [1752/2500], Train Loss: 0.8436, Train Accuracy: 62.02%, Test Loss: 0.8337, Test Accuracy: 62.03%\n",
      "Epoch [1753/2500], Train Loss: 0.8528, Train Accuracy: 61.88%, Test Loss: 0.8345, Test Accuracy: 63.29%\n",
      "Epoch [1754/2500], Train Loss: 0.8289, Train Accuracy: 63.73%, Test Loss: 0.8347, Test Accuracy: 63.29%\n",
      "Epoch [1755/2500], Train Loss: 0.8535, Train Accuracy: 60.17%, Test Loss: 0.8413, Test Accuracy: 63.29%\n",
      "Epoch [1756/2500], Train Loss: 0.8436, Train Accuracy: 61.88%, Test Loss: 0.8386, Test Accuracy: 62.03%\n",
      "Epoch [1757/2500], Train Loss: 0.8285, Train Accuracy: 62.87%, Test Loss: 0.8428, Test Accuracy: 63.29%\n",
      "Epoch [1758/2500], Train Loss: 0.8268, Train Accuracy: 62.30%, Test Loss: 0.8370, Test Accuracy: 62.03%\n",
      "Epoch [1759/2500], Train Loss: 0.8407, Train Accuracy: 62.16%, Test Loss: 0.8503, Test Accuracy: 64.56%\n",
      "Epoch [1760/2500], Train Loss: 0.8455, Train Accuracy: 62.02%, Test Loss: 0.8417, Test Accuracy: 62.03%\n",
      "Epoch [1761/2500], Train Loss: 0.8342, Train Accuracy: 64.15%, Test Loss: 0.8410, Test Accuracy: 62.03%\n",
      "Epoch [1762/2500], Train Loss: 0.8447, Train Accuracy: 64.15%, Test Loss: 0.8460, Test Accuracy: 62.03%\n",
      "Epoch [1763/2500], Train Loss: 0.8531, Train Accuracy: 61.74%, Test Loss: 0.8443, Test Accuracy: 62.03%\n",
      "Epoch [1764/2500], Train Loss: 0.8546, Train Accuracy: 62.02%, Test Loss: 0.8521, Test Accuracy: 62.03%\n",
      "Epoch [1765/2500], Train Loss: 0.8410, Train Accuracy: 61.74%, Test Loss: 0.8438, Test Accuracy: 62.03%\n",
      "Epoch [1766/2500], Train Loss: 0.8325, Train Accuracy: 63.58%, Test Loss: 0.8343, Test Accuracy: 62.03%\n",
      "Epoch [1767/2500], Train Loss: 0.8526, Train Accuracy: 61.45%, Test Loss: 0.8357, Test Accuracy: 60.76%\n",
      "Epoch [1768/2500], Train Loss: 0.8527, Train Accuracy: 62.45%, Test Loss: 0.8401, Test Accuracy: 60.76%\n",
      "Epoch [1769/2500], Train Loss: 0.8346, Train Accuracy: 62.45%, Test Loss: 0.8326, Test Accuracy: 62.03%\n",
      "Epoch [1770/2500], Train Loss: 0.8365, Train Accuracy: 61.74%, Test Loss: 0.8317, Test Accuracy: 62.03%\n",
      "Epoch [1771/2500], Train Loss: 0.8507, Train Accuracy: 60.88%, Test Loss: 0.8367, Test Accuracy: 62.03%\n",
      "Epoch [1772/2500], Train Loss: 0.8456, Train Accuracy: 61.45%, Test Loss: 0.8382, Test Accuracy: 62.03%\n",
      "Epoch [1773/2500], Train Loss: 0.8332, Train Accuracy: 63.16%, Test Loss: 0.8413, Test Accuracy: 62.03%\n",
      "Epoch [1774/2500], Train Loss: 0.8524, Train Accuracy: 62.87%, Test Loss: 0.8372, Test Accuracy: 62.03%\n",
      "Epoch [1775/2500], Train Loss: 0.8430, Train Accuracy: 62.59%, Test Loss: 0.8409, Test Accuracy: 62.03%\n",
      "Epoch [1776/2500], Train Loss: 0.8286, Train Accuracy: 62.73%, Test Loss: 0.8373, Test Accuracy: 63.29%\n",
      "Epoch [1777/2500], Train Loss: 0.8379, Train Accuracy: 60.60%, Test Loss: 0.8280, Test Accuracy: 62.03%\n",
      "Epoch [1778/2500], Train Loss: 0.8338, Train Accuracy: 63.16%, Test Loss: 0.8331, Test Accuracy: 63.29%\n",
      "Epoch [1779/2500], Train Loss: 0.8476, Train Accuracy: 62.87%, Test Loss: 0.8312, Test Accuracy: 62.03%\n",
      "Epoch [1780/2500], Train Loss: 0.8355, Train Accuracy: 63.02%, Test Loss: 0.8316, Test Accuracy: 60.76%\n",
      "Epoch [1781/2500], Train Loss: 0.8527, Train Accuracy: 61.02%, Test Loss: 0.8465, Test Accuracy: 62.03%\n",
      "Epoch [1782/2500], Train Loss: 0.8547, Train Accuracy: 62.30%, Test Loss: 0.8413, Test Accuracy: 62.03%\n",
      "Epoch [1783/2500], Train Loss: 0.8442, Train Accuracy: 61.45%, Test Loss: 0.8508, Test Accuracy: 62.03%\n",
      "Epoch [1784/2500], Train Loss: 0.8343, Train Accuracy: 62.87%, Test Loss: 0.8481, Test Accuracy: 62.03%\n",
      "Epoch [1785/2500], Train Loss: 0.8451, Train Accuracy: 61.88%, Test Loss: 0.8363, Test Accuracy: 60.76%\n",
      "Epoch [1786/2500], Train Loss: 0.8287, Train Accuracy: 63.44%, Test Loss: 0.8333, Test Accuracy: 60.76%\n",
      "Epoch [1787/2500], Train Loss: 0.8231, Train Accuracy: 63.30%, Test Loss: 0.8391, Test Accuracy: 62.03%\n",
      "Epoch [1788/2500], Train Loss: 0.8309, Train Accuracy: 61.59%, Test Loss: 0.8419, Test Accuracy: 60.76%\n",
      "Epoch [1789/2500], Train Loss: 0.8422, Train Accuracy: 63.16%, Test Loss: 0.8318, Test Accuracy: 59.49%\n",
      "Epoch [1790/2500], Train Loss: 0.8426, Train Accuracy: 62.45%, Test Loss: 0.8299, Test Accuracy: 59.49%\n",
      "Epoch [1791/2500], Train Loss: 0.8155, Train Accuracy: 64.58%, Test Loss: 0.8349, Test Accuracy: 62.03%\n",
      "Epoch [1792/2500], Train Loss: 0.8198, Train Accuracy: 63.73%, Test Loss: 0.8379, Test Accuracy: 62.03%\n",
      "Epoch [1793/2500], Train Loss: 0.8413, Train Accuracy: 63.16%, Test Loss: 0.8388, Test Accuracy: 62.03%\n",
      "Epoch [1794/2500], Train Loss: 0.8324, Train Accuracy: 64.44%, Test Loss: 0.8443, Test Accuracy: 62.03%\n",
      "Epoch [1795/2500], Train Loss: 0.8570, Train Accuracy: 60.74%, Test Loss: 0.8532, Test Accuracy: 62.03%\n",
      "Epoch [1796/2500], Train Loss: 0.8413, Train Accuracy: 61.45%, Test Loss: 0.8494, Test Accuracy: 62.03%\n",
      "Epoch [1797/2500], Train Loss: 0.8316, Train Accuracy: 62.45%, Test Loss: 0.8556, Test Accuracy: 62.03%\n",
      "Epoch [1798/2500], Train Loss: 0.8470, Train Accuracy: 62.87%, Test Loss: 0.8545, Test Accuracy: 62.03%\n",
      "Epoch [1799/2500], Train Loss: 0.8310, Train Accuracy: 62.02%, Test Loss: 0.8548, Test Accuracy: 62.03%\n",
      "Epoch [1800/2500], Train Loss: 0.8243, Train Accuracy: 62.73%, Test Loss: 0.8570, Test Accuracy: 62.03%\n",
      "Epoch [1801/2500], Train Loss: 0.8361, Train Accuracy: 64.01%, Test Loss: 0.8519, Test Accuracy: 63.29%\n",
      "Epoch [1802/2500], Train Loss: 0.8274, Train Accuracy: 63.02%, Test Loss: 0.8472, Test Accuracy: 62.03%\n",
      "Epoch [1803/2500], Train Loss: 0.8303, Train Accuracy: 64.44%, Test Loss: 0.8481, Test Accuracy: 63.29%\n",
      "Epoch [1804/2500], Train Loss: 0.8209, Train Accuracy: 64.15%, Test Loss: 0.8443, Test Accuracy: 63.29%\n",
      "Epoch [1805/2500], Train Loss: 0.8325, Train Accuracy: 62.30%, Test Loss: 0.8507, Test Accuracy: 62.03%\n",
      "Epoch [1806/2500], Train Loss: 0.8334, Train Accuracy: 63.87%, Test Loss: 0.8467, Test Accuracy: 60.76%\n",
      "Epoch [1807/2500], Train Loss: 0.8433, Train Accuracy: 64.01%, Test Loss: 0.8468, Test Accuracy: 60.76%\n",
      "Epoch [1808/2500], Train Loss: 0.8294, Train Accuracy: 64.44%, Test Loss: 0.8463, Test Accuracy: 63.29%\n",
      "Epoch [1809/2500], Train Loss: 0.8481, Train Accuracy: 62.16%, Test Loss: 0.8454, Test Accuracy: 63.29%\n",
      "Epoch [1810/2500], Train Loss: 0.8507, Train Accuracy: 61.31%, Test Loss: 0.8509, Test Accuracy: 60.76%\n",
      "Epoch [1811/2500], Train Loss: 0.8233, Train Accuracy: 64.15%, Test Loss: 0.8420, Test Accuracy: 60.76%\n",
      "Epoch [1812/2500], Train Loss: 0.8332, Train Accuracy: 62.59%, Test Loss: 0.8401, Test Accuracy: 60.76%\n",
      "Epoch [1813/2500], Train Loss: 0.8202, Train Accuracy: 63.73%, Test Loss: 0.8424, Test Accuracy: 60.76%\n",
      "Epoch [1814/2500], Train Loss: 0.8455, Train Accuracy: 62.73%, Test Loss: 0.8406, Test Accuracy: 60.76%\n",
      "Epoch [1815/2500], Train Loss: 0.8402, Train Accuracy: 61.59%, Test Loss: 0.8414, Test Accuracy: 62.03%\n",
      "Epoch [1816/2500], Train Loss: 0.8282, Train Accuracy: 64.72%, Test Loss: 0.8367, Test Accuracy: 60.76%\n",
      "Epoch [1817/2500], Train Loss: 0.8403, Train Accuracy: 62.16%, Test Loss: 0.8393, Test Accuracy: 60.76%\n",
      "Epoch [1818/2500], Train Loss: 0.8316, Train Accuracy: 63.73%, Test Loss: 0.8353, Test Accuracy: 60.76%\n",
      "Epoch [1819/2500], Train Loss: 0.8279, Train Accuracy: 63.16%, Test Loss: 0.8353, Test Accuracy: 60.76%\n",
      "Epoch [1820/2500], Train Loss: 0.8366, Train Accuracy: 61.59%, Test Loss: 0.8373, Test Accuracy: 62.03%\n",
      "Epoch [1821/2500], Train Loss: 0.8310, Train Accuracy: 63.02%, Test Loss: 0.8462, Test Accuracy: 62.03%\n",
      "Epoch [1822/2500], Train Loss: 0.8327, Train Accuracy: 62.45%, Test Loss: 0.8331, Test Accuracy: 62.03%\n",
      "Epoch [1823/2500], Train Loss: 0.8431, Train Accuracy: 62.73%, Test Loss: 0.8353, Test Accuracy: 60.76%\n",
      "Epoch [1824/2500], Train Loss: 0.8348, Train Accuracy: 62.30%, Test Loss: 0.8384, Test Accuracy: 63.29%\n",
      "Epoch [1825/2500], Train Loss: 0.8256, Train Accuracy: 62.59%, Test Loss: 0.8349, Test Accuracy: 62.03%\n",
      "Epoch [1826/2500], Train Loss: 0.8390, Train Accuracy: 62.73%, Test Loss: 0.8467, Test Accuracy: 65.82%\n",
      "Epoch [1827/2500], Train Loss: 0.8266, Train Accuracy: 63.30%, Test Loss: 0.8526, Test Accuracy: 63.29%\n",
      "Epoch [1828/2500], Train Loss: 0.8261, Train Accuracy: 63.73%, Test Loss: 0.8438, Test Accuracy: 65.82%\n",
      "Epoch [1829/2500], Train Loss: 0.8424, Train Accuracy: 64.30%, Test Loss: 0.8390, Test Accuracy: 65.82%\n",
      "Epoch [1830/2500], Train Loss: 0.8240, Train Accuracy: 63.30%, Test Loss: 0.8404, Test Accuracy: 65.82%\n",
      "Epoch [1831/2500], Train Loss: 0.8332, Train Accuracy: 62.87%, Test Loss: 0.8434, Test Accuracy: 65.82%\n",
      "Epoch [1832/2500], Train Loss: 0.8345, Train Accuracy: 63.30%, Test Loss: 0.8383, Test Accuracy: 63.29%\n",
      "Epoch [1833/2500], Train Loss: 0.8541, Train Accuracy: 62.02%, Test Loss: 0.8369, Test Accuracy: 65.82%\n",
      "Epoch [1834/2500], Train Loss: 0.8207, Train Accuracy: 63.16%, Test Loss: 0.8399, Test Accuracy: 65.82%\n",
      "Epoch [1835/2500], Train Loss: 0.8406, Train Accuracy: 63.30%, Test Loss: 0.8293, Test Accuracy: 67.09%\n",
      "Epoch [1836/2500], Train Loss: 0.8437, Train Accuracy: 62.73%, Test Loss: 0.8329, Test Accuracy: 67.09%\n",
      "Epoch [1837/2500], Train Loss: 0.8449, Train Accuracy: 61.88%, Test Loss: 0.8360, Test Accuracy: 67.09%\n",
      "Epoch [1838/2500], Train Loss: 0.8492, Train Accuracy: 61.59%, Test Loss: 0.8373, Test Accuracy: 64.56%\n",
      "Epoch [1839/2500], Train Loss: 0.8419, Train Accuracy: 62.30%, Test Loss: 0.8370, Test Accuracy: 65.82%\n",
      "Epoch [1840/2500], Train Loss: 0.8253, Train Accuracy: 63.58%, Test Loss: 0.8432, Test Accuracy: 64.56%\n",
      "Epoch [1841/2500], Train Loss: 0.8257, Train Accuracy: 63.73%, Test Loss: 0.8346, Test Accuracy: 63.29%\n",
      "Epoch [1842/2500], Train Loss: 0.8171, Train Accuracy: 64.58%, Test Loss: 0.8327, Test Accuracy: 63.29%\n",
      "Epoch [1843/2500], Train Loss: 0.8185, Train Accuracy: 63.87%, Test Loss: 0.8327, Test Accuracy: 62.03%\n",
      "Epoch [1844/2500], Train Loss: 0.8387, Train Accuracy: 62.16%, Test Loss: 0.8395, Test Accuracy: 63.29%\n",
      "Epoch [1845/2500], Train Loss: 0.8136, Train Accuracy: 64.44%, Test Loss: 0.8416, Test Accuracy: 63.29%\n",
      "Epoch [1846/2500], Train Loss: 0.8306, Train Accuracy: 62.02%, Test Loss: 0.8384, Test Accuracy: 64.56%\n",
      "Epoch [1847/2500], Train Loss: 0.8517, Train Accuracy: 62.59%, Test Loss: 0.8396, Test Accuracy: 64.56%\n",
      "Epoch [1848/2500], Train Loss: 0.8430, Train Accuracy: 63.44%, Test Loss: 0.8260, Test Accuracy: 63.29%\n",
      "Epoch [1849/2500], Train Loss: 0.8196, Train Accuracy: 62.73%, Test Loss: 0.8277, Test Accuracy: 60.76%\n",
      "Epoch [1850/2500], Train Loss: 0.8221, Train Accuracy: 63.44%, Test Loss: 0.8358, Test Accuracy: 62.03%\n",
      "Epoch [1851/2500], Train Loss: 0.8308, Train Accuracy: 63.16%, Test Loss: 0.8441, Test Accuracy: 62.03%\n",
      "Epoch [1852/2500], Train Loss: 0.8359, Train Accuracy: 62.16%, Test Loss: 0.8317, Test Accuracy: 60.76%\n",
      "Epoch [1853/2500], Train Loss: 0.8236, Train Accuracy: 64.86%, Test Loss: 0.8379, Test Accuracy: 62.03%\n",
      "Epoch [1854/2500], Train Loss: 0.8112, Train Accuracy: 63.87%, Test Loss: 0.8352, Test Accuracy: 60.76%\n",
      "Epoch [1855/2500], Train Loss: 0.8184, Train Accuracy: 62.02%, Test Loss: 0.8397, Test Accuracy: 63.29%\n",
      "Epoch [1856/2500], Train Loss: 0.8222, Train Accuracy: 62.73%, Test Loss: 0.8358, Test Accuracy: 62.03%\n",
      "Epoch [1857/2500], Train Loss: 0.8471, Train Accuracy: 60.60%, Test Loss: 0.8444, Test Accuracy: 63.29%\n",
      "Epoch [1858/2500], Train Loss: 0.8401, Train Accuracy: 62.02%, Test Loss: 0.8406, Test Accuracy: 62.03%\n",
      "Epoch [1859/2500], Train Loss: 0.8300, Train Accuracy: 64.01%, Test Loss: 0.8433, Test Accuracy: 62.03%\n",
      "Epoch [1860/2500], Train Loss: 0.8195, Train Accuracy: 63.44%, Test Loss: 0.8364, Test Accuracy: 62.03%\n",
      "Epoch [1861/2500], Train Loss: 0.8313, Train Accuracy: 63.30%, Test Loss: 0.8363, Test Accuracy: 64.56%\n",
      "Epoch [1862/2500], Train Loss: 0.8285, Train Accuracy: 63.30%, Test Loss: 0.8364, Test Accuracy: 64.56%\n",
      "Epoch [1863/2500], Train Loss: 0.8264, Train Accuracy: 62.59%, Test Loss: 0.8452, Test Accuracy: 64.56%\n",
      "Epoch [1864/2500], Train Loss: 0.8315, Train Accuracy: 64.01%, Test Loss: 0.8448, Test Accuracy: 64.56%\n",
      "Epoch [1865/2500], Train Loss: 0.8351, Train Accuracy: 62.59%, Test Loss: 0.8455, Test Accuracy: 64.56%\n",
      "Epoch [1866/2500], Train Loss: 0.8172, Train Accuracy: 63.58%, Test Loss: 0.8473, Test Accuracy: 64.56%\n",
      "Epoch [1867/2500], Train Loss: 0.8259, Train Accuracy: 62.30%, Test Loss: 0.8449, Test Accuracy: 64.56%\n",
      "Epoch [1868/2500], Train Loss: 0.8520, Train Accuracy: 61.74%, Test Loss: 0.8442, Test Accuracy: 63.29%\n",
      "Epoch [1869/2500], Train Loss: 0.8246, Train Accuracy: 62.59%, Test Loss: 0.8484, Test Accuracy: 62.03%\n",
      "Epoch [1870/2500], Train Loss: 0.8480, Train Accuracy: 63.02%, Test Loss: 0.8432, Test Accuracy: 62.03%\n",
      "Epoch [1871/2500], Train Loss: 0.8067, Train Accuracy: 64.44%, Test Loss: 0.8499, Test Accuracy: 63.29%\n",
      "Epoch [1872/2500], Train Loss: 0.8122, Train Accuracy: 64.01%, Test Loss: 0.8400, Test Accuracy: 63.29%\n",
      "Epoch [1873/2500], Train Loss: 0.8383, Train Accuracy: 64.30%, Test Loss: 0.8460, Test Accuracy: 64.56%\n",
      "Epoch [1874/2500], Train Loss: 0.8369, Train Accuracy: 64.44%, Test Loss: 0.8485, Test Accuracy: 64.56%\n",
      "Epoch [1875/2500], Train Loss: 0.8262, Train Accuracy: 63.58%, Test Loss: 0.8514, Test Accuracy: 63.29%\n",
      "Epoch [1876/2500], Train Loss: 0.8310, Train Accuracy: 65.01%, Test Loss: 0.8499, Test Accuracy: 64.56%\n",
      "Epoch [1877/2500], Train Loss: 0.8199, Train Accuracy: 63.58%, Test Loss: 0.8540, Test Accuracy: 64.56%\n",
      "Epoch [1878/2500], Train Loss: 0.8370, Train Accuracy: 62.45%, Test Loss: 0.8550, Test Accuracy: 64.56%\n",
      "Epoch [1879/2500], Train Loss: 0.8321, Train Accuracy: 62.30%, Test Loss: 0.8521, Test Accuracy: 63.29%\n",
      "Epoch [1880/2500], Train Loss: 0.8470, Train Accuracy: 62.16%, Test Loss: 0.8517, Test Accuracy: 63.29%\n",
      "Epoch [1881/2500], Train Loss: 0.8203, Train Accuracy: 62.87%, Test Loss: 0.8549, Test Accuracy: 63.29%\n",
      "Epoch [1882/2500], Train Loss: 0.8337, Train Accuracy: 64.15%, Test Loss: 0.8450, Test Accuracy: 65.82%\n",
      "Epoch [1883/2500], Train Loss: 0.8424, Train Accuracy: 62.87%, Test Loss: 0.8504, Test Accuracy: 64.56%\n",
      "Epoch [1884/2500], Train Loss: 0.8323, Train Accuracy: 62.45%, Test Loss: 0.8415, Test Accuracy: 67.09%\n",
      "Epoch [1885/2500], Train Loss: 0.8333, Train Accuracy: 63.44%, Test Loss: 0.8417, Test Accuracy: 64.56%\n",
      "Epoch [1886/2500], Train Loss: 0.8451, Train Accuracy: 61.74%, Test Loss: 0.8529, Test Accuracy: 65.82%\n",
      "Epoch [1887/2500], Train Loss: 0.8446, Train Accuracy: 61.59%, Test Loss: 0.8461, Test Accuracy: 65.82%\n",
      "Epoch [1888/2500], Train Loss: 0.8283, Train Accuracy: 62.30%, Test Loss: 0.8502, Test Accuracy: 64.56%\n",
      "Epoch [1889/2500], Train Loss: 0.8074, Train Accuracy: 64.30%, Test Loss: 0.8568, Test Accuracy: 62.03%\n",
      "Epoch [1890/2500], Train Loss: 0.8114, Train Accuracy: 63.44%, Test Loss: 0.8477, Test Accuracy: 63.29%\n",
      "Epoch [1891/2500], Train Loss: 0.8223, Train Accuracy: 64.44%, Test Loss: 0.8450, Test Accuracy: 64.56%\n",
      "Epoch [1892/2500], Train Loss: 0.8177, Train Accuracy: 64.15%, Test Loss: 0.8440, Test Accuracy: 64.56%\n",
      "Epoch [1893/2500], Train Loss: 0.8390, Train Accuracy: 64.44%, Test Loss: 0.8409, Test Accuracy: 65.82%\n",
      "Epoch [1894/2500], Train Loss: 0.8239, Train Accuracy: 65.15%, Test Loss: 0.8388, Test Accuracy: 65.82%\n",
      "Epoch [1895/2500], Train Loss: 0.8333, Train Accuracy: 63.02%, Test Loss: 0.8406, Test Accuracy: 64.56%\n",
      "Epoch [1896/2500], Train Loss: 0.8024, Train Accuracy: 65.15%, Test Loss: 0.8431, Test Accuracy: 64.56%\n",
      "Epoch [1897/2500], Train Loss: 0.8237, Train Accuracy: 63.58%, Test Loss: 0.8491, Test Accuracy: 65.82%\n",
      "Epoch [1898/2500], Train Loss: 0.8386, Train Accuracy: 61.17%, Test Loss: 0.8421, Test Accuracy: 63.29%\n",
      "Epoch [1899/2500], Train Loss: 0.8519, Train Accuracy: 62.73%, Test Loss: 0.8358, Test Accuracy: 64.56%\n",
      "Epoch [1900/2500], Train Loss: 0.8143, Train Accuracy: 64.15%, Test Loss: 0.8324, Test Accuracy: 64.56%\n",
      "Epoch [1901/2500], Train Loss: 0.8162, Train Accuracy: 65.01%, Test Loss: 0.8258, Test Accuracy: 65.82%\n",
      "Epoch [1902/2500], Train Loss: 0.8360, Train Accuracy: 62.87%, Test Loss: 0.8214, Test Accuracy: 64.56%\n",
      "Epoch [1903/2500], Train Loss: 0.8466, Train Accuracy: 62.16%, Test Loss: 0.8211, Test Accuracy: 64.56%\n",
      "Epoch [1904/2500], Train Loss: 0.8160, Train Accuracy: 63.87%, Test Loss: 0.8344, Test Accuracy: 63.29%\n",
      "Epoch [1905/2500], Train Loss: 0.8135, Train Accuracy: 64.72%, Test Loss: 0.8311, Test Accuracy: 63.29%\n",
      "Epoch [1906/2500], Train Loss: 0.8106, Train Accuracy: 64.15%, Test Loss: 0.8383, Test Accuracy: 63.29%\n",
      "Epoch [1907/2500], Train Loss: 0.8151, Train Accuracy: 63.30%, Test Loss: 0.8383, Test Accuracy: 63.29%\n",
      "Epoch [1908/2500], Train Loss: 0.8222, Train Accuracy: 63.44%, Test Loss: 0.8391, Test Accuracy: 63.29%\n",
      "Epoch [1909/2500], Train Loss: 0.8293, Train Accuracy: 63.58%, Test Loss: 0.8359, Test Accuracy: 63.29%\n",
      "Epoch [1910/2500], Train Loss: 0.8168, Train Accuracy: 63.30%, Test Loss: 0.8371, Test Accuracy: 64.56%\n",
      "Epoch [1911/2500], Train Loss: 0.8277, Train Accuracy: 63.87%, Test Loss: 0.8448, Test Accuracy: 64.56%\n",
      "Epoch [1912/2500], Train Loss: 0.8226, Train Accuracy: 63.58%, Test Loss: 0.8399, Test Accuracy: 65.82%\n",
      "Epoch [1913/2500], Train Loss: 0.8203, Train Accuracy: 63.30%, Test Loss: 0.8402, Test Accuracy: 63.29%\n",
      "Epoch [1914/2500], Train Loss: 0.8217, Train Accuracy: 64.44%, Test Loss: 0.8360, Test Accuracy: 63.29%\n",
      "Epoch [1915/2500], Train Loss: 0.8279, Train Accuracy: 62.45%, Test Loss: 0.8387, Test Accuracy: 64.56%\n",
      "Epoch [1916/2500], Train Loss: 0.8152, Train Accuracy: 62.16%, Test Loss: 0.8427, Test Accuracy: 64.56%\n",
      "Epoch [1917/2500], Train Loss: 0.8281, Train Accuracy: 62.45%, Test Loss: 0.8409, Test Accuracy: 64.56%\n",
      "Epoch [1918/2500], Train Loss: 0.8399, Train Accuracy: 61.45%, Test Loss: 0.8401, Test Accuracy: 64.56%\n",
      "Epoch [1919/2500], Train Loss: 0.8192, Train Accuracy: 63.44%, Test Loss: 0.8468, Test Accuracy: 64.56%\n",
      "Epoch [1920/2500], Train Loss: 0.8287, Train Accuracy: 62.87%, Test Loss: 0.8432, Test Accuracy: 63.29%\n",
      "Epoch [1921/2500], Train Loss: 0.8292, Train Accuracy: 63.44%, Test Loss: 0.8416, Test Accuracy: 63.29%\n",
      "Epoch [1922/2500], Train Loss: 0.8279, Train Accuracy: 63.02%, Test Loss: 0.8445, Test Accuracy: 63.29%\n",
      "Epoch [1923/2500], Train Loss: 0.8165, Train Accuracy: 64.15%, Test Loss: 0.8477, Test Accuracy: 63.29%\n",
      "Epoch [1924/2500], Train Loss: 0.8420, Train Accuracy: 63.02%, Test Loss: 0.8528, Test Accuracy: 62.03%\n",
      "Epoch [1925/2500], Train Loss: 0.8297, Train Accuracy: 63.16%, Test Loss: 0.8550, Test Accuracy: 62.03%\n",
      "Epoch [1926/2500], Train Loss: 0.8133, Train Accuracy: 64.44%, Test Loss: 0.8500, Test Accuracy: 60.76%\n",
      "Epoch [1927/2500], Train Loss: 0.8409, Train Accuracy: 61.02%, Test Loss: 0.8504, Test Accuracy: 62.03%\n",
      "Epoch [1928/2500], Train Loss: 0.8279, Train Accuracy: 63.44%, Test Loss: 0.8490, Test Accuracy: 62.03%\n",
      "Epoch [1929/2500], Train Loss: 0.8307, Train Accuracy: 62.02%, Test Loss: 0.8388, Test Accuracy: 62.03%\n",
      "Epoch [1930/2500], Train Loss: 0.8220, Train Accuracy: 61.88%, Test Loss: 0.8350, Test Accuracy: 63.29%\n",
      "Epoch [1931/2500], Train Loss: 0.8260, Train Accuracy: 62.02%, Test Loss: 0.8412, Test Accuracy: 63.29%\n",
      "Epoch [1932/2500], Train Loss: 0.8260, Train Accuracy: 62.73%, Test Loss: 0.8516, Test Accuracy: 63.29%\n",
      "Epoch [1933/2500], Train Loss: 0.8233, Train Accuracy: 63.30%, Test Loss: 0.8421, Test Accuracy: 65.82%\n",
      "Epoch [1934/2500], Train Loss: 0.8475, Train Accuracy: 62.16%, Test Loss: 0.8375, Test Accuracy: 64.56%\n",
      "Epoch [1935/2500], Train Loss: 0.8212, Train Accuracy: 63.44%, Test Loss: 0.8398, Test Accuracy: 64.56%\n",
      "Epoch [1936/2500], Train Loss: 0.8350, Train Accuracy: 61.59%, Test Loss: 0.8353, Test Accuracy: 63.29%\n",
      "Epoch [1937/2500], Train Loss: 0.8316, Train Accuracy: 62.30%, Test Loss: 0.8375, Test Accuracy: 64.56%\n",
      "Epoch [1938/2500], Train Loss: 0.8070, Train Accuracy: 63.30%, Test Loss: 0.8321, Test Accuracy: 63.29%\n",
      "Epoch [1939/2500], Train Loss: 0.8361, Train Accuracy: 62.59%, Test Loss: 0.8330, Test Accuracy: 64.56%\n",
      "Epoch [1940/2500], Train Loss: 0.8082, Train Accuracy: 63.30%, Test Loss: 0.8375, Test Accuracy: 64.56%\n",
      "Epoch [1941/2500], Train Loss: 0.8207, Train Accuracy: 64.15%, Test Loss: 0.8360, Test Accuracy: 63.29%\n",
      "Epoch [1942/2500], Train Loss: 0.8217, Train Accuracy: 64.30%, Test Loss: 0.8359, Test Accuracy: 63.29%\n",
      "Epoch [1943/2500], Train Loss: 0.8158, Train Accuracy: 63.73%, Test Loss: 0.8363, Test Accuracy: 64.56%\n",
      "Epoch [1944/2500], Train Loss: 0.8230, Train Accuracy: 63.44%, Test Loss: 0.8388, Test Accuracy: 62.03%\n",
      "Epoch [1945/2500], Train Loss: 0.8269, Train Accuracy: 63.16%, Test Loss: 0.8309, Test Accuracy: 60.76%\n",
      "Epoch [1946/2500], Train Loss: 0.8269, Train Accuracy: 61.74%, Test Loss: 0.8327, Test Accuracy: 62.03%\n",
      "Epoch [1947/2500], Train Loss: 0.8180, Train Accuracy: 61.88%, Test Loss: 0.8316, Test Accuracy: 62.03%\n",
      "Epoch [1948/2500], Train Loss: 0.8417, Train Accuracy: 61.59%, Test Loss: 0.8326, Test Accuracy: 63.29%\n",
      "Epoch [1949/2500], Train Loss: 0.8370, Train Accuracy: 61.45%, Test Loss: 0.8361, Test Accuracy: 62.03%\n",
      "Epoch [1950/2500], Train Loss: 0.8196, Train Accuracy: 63.16%, Test Loss: 0.8287, Test Accuracy: 60.76%\n",
      "Epoch [1951/2500], Train Loss: 0.8192, Train Accuracy: 63.02%, Test Loss: 0.8301, Test Accuracy: 60.76%\n",
      "Epoch [1952/2500], Train Loss: 0.8148, Train Accuracy: 62.16%, Test Loss: 0.8326, Test Accuracy: 64.56%\n",
      "Epoch [1953/2500], Train Loss: 0.8428, Train Accuracy: 63.16%, Test Loss: 0.8341, Test Accuracy: 63.29%\n",
      "Epoch [1954/2500], Train Loss: 0.8005, Train Accuracy: 65.01%, Test Loss: 0.8363, Test Accuracy: 62.03%\n",
      "Epoch [1955/2500], Train Loss: 0.8370, Train Accuracy: 63.16%, Test Loss: 0.8355, Test Accuracy: 64.56%\n",
      "Epoch [1956/2500], Train Loss: 0.8330, Train Accuracy: 62.30%, Test Loss: 0.8317, Test Accuracy: 64.56%\n",
      "Epoch [1957/2500], Train Loss: 0.8143, Train Accuracy: 64.44%, Test Loss: 0.8339, Test Accuracy: 64.56%\n",
      "Epoch [1958/2500], Train Loss: 0.8299, Train Accuracy: 62.45%, Test Loss: 0.8298, Test Accuracy: 64.56%\n",
      "Epoch [1959/2500], Train Loss: 0.8536, Train Accuracy: 61.88%, Test Loss: 0.8315, Test Accuracy: 62.03%\n",
      "Epoch [1960/2500], Train Loss: 0.8245, Train Accuracy: 64.15%, Test Loss: 0.8345, Test Accuracy: 62.03%\n",
      "Epoch [1961/2500], Train Loss: 0.8378, Train Accuracy: 63.16%, Test Loss: 0.8345, Test Accuracy: 64.56%\n",
      "Epoch [1962/2500], Train Loss: 0.8414, Train Accuracy: 62.02%, Test Loss: 0.8310, Test Accuracy: 62.03%\n",
      "Epoch [1963/2500], Train Loss: 0.8189, Train Accuracy: 63.73%, Test Loss: 0.8300, Test Accuracy: 63.29%\n",
      "Epoch [1964/2500], Train Loss: 0.8472, Train Accuracy: 61.88%, Test Loss: 0.8311, Test Accuracy: 62.03%\n",
      "Epoch [1965/2500], Train Loss: 0.8313, Train Accuracy: 62.30%, Test Loss: 0.8289, Test Accuracy: 62.03%\n",
      "Epoch [1966/2500], Train Loss: 0.8158, Train Accuracy: 63.73%, Test Loss: 0.8289, Test Accuracy: 60.76%\n",
      "Epoch [1967/2500], Train Loss: 0.8312, Train Accuracy: 63.87%, Test Loss: 0.8321, Test Accuracy: 60.76%\n",
      "Epoch [1968/2500], Train Loss: 0.8282, Train Accuracy: 63.30%, Test Loss: 0.8312, Test Accuracy: 60.76%\n",
      "Epoch [1969/2500], Train Loss: 0.8257, Train Accuracy: 63.16%, Test Loss: 0.8325, Test Accuracy: 60.76%\n",
      "Epoch [1970/2500], Train Loss: 0.8109, Train Accuracy: 62.45%, Test Loss: 0.8321, Test Accuracy: 62.03%\n",
      "Epoch [1971/2500], Train Loss: 0.8378, Train Accuracy: 61.59%, Test Loss: 0.8218, Test Accuracy: 62.03%\n",
      "Epoch [1972/2500], Train Loss: 0.8256, Train Accuracy: 62.16%, Test Loss: 0.8308, Test Accuracy: 63.29%\n",
      "Epoch [1973/2500], Train Loss: 0.8149, Train Accuracy: 64.72%, Test Loss: 0.8269, Test Accuracy: 65.82%\n",
      "Epoch [1974/2500], Train Loss: 0.8367, Train Accuracy: 62.73%, Test Loss: 0.8353, Test Accuracy: 64.56%\n",
      "Epoch [1975/2500], Train Loss: 0.8322, Train Accuracy: 63.02%, Test Loss: 0.8291, Test Accuracy: 65.82%\n",
      "Epoch [1976/2500], Train Loss: 0.8375, Train Accuracy: 63.30%, Test Loss: 0.8268, Test Accuracy: 65.82%\n",
      "Epoch [1977/2500], Train Loss: 0.8275, Train Accuracy: 62.73%, Test Loss: 0.8205, Test Accuracy: 65.82%\n",
      "Epoch [1978/2500], Train Loss: 0.8365, Train Accuracy: 62.73%, Test Loss: 0.8219, Test Accuracy: 64.56%\n",
      "Epoch [1979/2500], Train Loss: 0.8366, Train Accuracy: 63.58%, Test Loss: 0.8221, Test Accuracy: 63.29%\n",
      "Epoch [1980/2500], Train Loss: 0.8201, Train Accuracy: 62.87%, Test Loss: 0.8309, Test Accuracy: 63.29%\n",
      "Epoch [1981/2500], Train Loss: 0.8417, Train Accuracy: 61.88%, Test Loss: 0.8315, Test Accuracy: 64.56%\n",
      "Epoch [1982/2500], Train Loss: 0.8296, Train Accuracy: 62.73%, Test Loss: 0.8331, Test Accuracy: 64.56%\n",
      "Epoch [1983/2500], Train Loss: 0.8140, Train Accuracy: 63.44%, Test Loss: 0.8293, Test Accuracy: 63.29%\n",
      "Epoch [1984/2500], Train Loss: 0.8268, Train Accuracy: 64.30%, Test Loss: 0.8320, Test Accuracy: 64.56%\n",
      "Epoch [1985/2500], Train Loss: 0.8362, Train Accuracy: 64.15%, Test Loss: 0.8242, Test Accuracy: 63.29%\n",
      "Epoch [1986/2500], Train Loss: 0.8164, Train Accuracy: 62.16%, Test Loss: 0.8331, Test Accuracy: 64.56%\n",
      "Epoch [1987/2500], Train Loss: 0.8135, Train Accuracy: 64.58%, Test Loss: 0.8325, Test Accuracy: 64.56%\n",
      "Epoch [1988/2500], Train Loss: 0.8164, Train Accuracy: 62.45%, Test Loss: 0.8316, Test Accuracy: 64.56%\n",
      "Epoch [1989/2500], Train Loss: 0.8199, Train Accuracy: 62.45%, Test Loss: 0.8328, Test Accuracy: 62.03%\n",
      "Epoch [1990/2500], Train Loss: 0.8148, Train Accuracy: 64.44%, Test Loss: 0.8365, Test Accuracy: 64.56%\n",
      "Epoch [1991/2500], Train Loss: 0.8189, Train Accuracy: 61.59%, Test Loss: 0.8330, Test Accuracy: 62.03%\n",
      "Epoch [1992/2500], Train Loss: 0.8176, Train Accuracy: 62.16%, Test Loss: 0.8361, Test Accuracy: 63.29%\n",
      "Epoch [1993/2500], Train Loss: 0.8367, Train Accuracy: 61.59%, Test Loss: 0.8382, Test Accuracy: 64.56%\n",
      "Epoch [1994/2500], Train Loss: 0.8112, Train Accuracy: 63.58%, Test Loss: 0.8314, Test Accuracy: 64.56%\n",
      "Epoch [1995/2500], Train Loss: 0.8361, Train Accuracy: 62.30%, Test Loss: 0.8405, Test Accuracy: 64.56%\n",
      "Epoch [1996/2500], Train Loss: 0.8080, Train Accuracy: 64.86%, Test Loss: 0.8342, Test Accuracy: 63.29%\n",
      "Epoch [1997/2500], Train Loss: 0.8241, Train Accuracy: 62.59%, Test Loss: 0.8302, Test Accuracy: 63.29%\n",
      "Epoch [1998/2500], Train Loss: 0.8233, Train Accuracy: 63.30%, Test Loss: 0.8284, Test Accuracy: 60.76%\n",
      "Epoch [1999/2500], Train Loss: 0.8082, Train Accuracy: 63.73%, Test Loss: 0.8344, Test Accuracy: 62.03%\n",
      "Epoch [2000/2500], Train Loss: 0.8206, Train Accuracy: 63.87%, Test Loss: 0.8350, Test Accuracy: 62.03%\n",
      "Epoch [2001/2500], Train Loss: 0.8317, Train Accuracy: 63.73%, Test Loss: 0.8333, Test Accuracy: 63.29%\n",
      "Epoch [2002/2500], Train Loss: 0.8201, Train Accuracy: 62.87%, Test Loss: 0.8411, Test Accuracy: 65.82%\n",
      "Epoch [2003/2500], Train Loss: 0.7999, Train Accuracy: 65.72%, Test Loss: 0.8331, Test Accuracy: 65.82%\n",
      "Epoch [2004/2500], Train Loss: 0.8248, Train Accuracy: 63.73%, Test Loss: 0.8373, Test Accuracy: 63.29%\n",
      "Epoch [2005/2500], Train Loss: 0.8219, Train Accuracy: 63.16%, Test Loss: 0.8381, Test Accuracy: 64.56%\n",
      "Epoch [2006/2500], Train Loss: 0.8245, Train Accuracy: 63.73%, Test Loss: 0.8357, Test Accuracy: 64.56%\n",
      "Epoch [2007/2500], Train Loss: 0.8337, Train Accuracy: 64.15%, Test Loss: 0.8316, Test Accuracy: 63.29%\n",
      "Epoch [2008/2500], Train Loss: 0.8175, Train Accuracy: 62.87%, Test Loss: 0.8305, Test Accuracy: 64.56%\n",
      "Epoch [2009/2500], Train Loss: 0.8198, Train Accuracy: 63.58%, Test Loss: 0.8313, Test Accuracy: 64.56%\n",
      "Epoch [2010/2500], Train Loss: 0.8431, Train Accuracy: 62.73%, Test Loss: 0.8258, Test Accuracy: 64.56%\n",
      "Epoch [2011/2500], Train Loss: 0.8233, Train Accuracy: 63.16%, Test Loss: 0.8292, Test Accuracy: 64.56%\n",
      "Epoch [2012/2500], Train Loss: 0.8333, Train Accuracy: 62.87%, Test Loss: 0.8364, Test Accuracy: 64.56%\n",
      "Epoch [2013/2500], Train Loss: 0.8189, Train Accuracy: 63.02%, Test Loss: 0.8370, Test Accuracy: 64.56%\n",
      "Epoch [2014/2500], Train Loss: 0.8257, Train Accuracy: 63.02%, Test Loss: 0.8347, Test Accuracy: 64.56%\n",
      "Epoch [2015/2500], Train Loss: 0.8277, Train Accuracy: 64.86%, Test Loss: 0.8302, Test Accuracy: 64.56%\n",
      "Epoch [2016/2500], Train Loss: 0.8170, Train Accuracy: 63.58%, Test Loss: 0.8325, Test Accuracy: 64.56%\n",
      "Epoch [2017/2500], Train Loss: 0.8237, Train Accuracy: 62.59%, Test Loss: 0.8356, Test Accuracy: 64.56%\n",
      "Epoch [2018/2500], Train Loss: 0.8087, Train Accuracy: 63.16%, Test Loss: 0.8423, Test Accuracy: 65.82%\n",
      "Epoch [2019/2500], Train Loss: 0.8233, Train Accuracy: 63.87%, Test Loss: 0.8428, Test Accuracy: 62.03%\n",
      "Epoch [2020/2500], Train Loss: 0.8087, Train Accuracy: 64.30%, Test Loss: 0.8397, Test Accuracy: 65.82%\n",
      "Epoch [2021/2500], Train Loss: 0.8256, Train Accuracy: 62.45%, Test Loss: 0.8350, Test Accuracy: 63.29%\n",
      "Epoch [2022/2500], Train Loss: 0.8252, Train Accuracy: 65.29%, Test Loss: 0.8425, Test Accuracy: 65.82%\n",
      "Epoch [2023/2500], Train Loss: 0.8205, Train Accuracy: 63.16%, Test Loss: 0.8337, Test Accuracy: 64.56%\n",
      "Epoch [2024/2500], Train Loss: 0.8054, Train Accuracy: 65.15%, Test Loss: 0.8443, Test Accuracy: 63.29%\n",
      "Epoch [2025/2500], Train Loss: 0.8161, Train Accuracy: 63.16%, Test Loss: 0.8451, Test Accuracy: 65.82%\n",
      "Epoch [2026/2500], Train Loss: 0.8007, Train Accuracy: 64.15%, Test Loss: 0.8506, Test Accuracy: 64.56%\n",
      "Epoch [2027/2500], Train Loss: 0.8228, Train Accuracy: 62.73%, Test Loss: 0.8422, Test Accuracy: 64.56%\n",
      "Epoch [2028/2500], Train Loss: 0.8069, Train Accuracy: 63.58%, Test Loss: 0.8391, Test Accuracy: 64.56%\n",
      "Epoch [2029/2500], Train Loss: 0.8163, Train Accuracy: 61.74%, Test Loss: 0.8504, Test Accuracy: 64.56%\n",
      "Epoch [2030/2500], Train Loss: 0.8291, Train Accuracy: 64.01%, Test Loss: 0.8440, Test Accuracy: 63.29%\n",
      "Epoch [2031/2500], Train Loss: 0.8143, Train Accuracy: 63.87%, Test Loss: 0.8445, Test Accuracy: 63.29%\n",
      "Epoch [2032/2500], Train Loss: 0.8090, Train Accuracy: 64.30%, Test Loss: 0.8405, Test Accuracy: 63.29%\n",
      "Epoch [2033/2500], Train Loss: 0.8120, Train Accuracy: 61.17%, Test Loss: 0.8385, Test Accuracy: 64.56%\n",
      "Epoch [2034/2500], Train Loss: 0.8143, Train Accuracy: 61.74%, Test Loss: 0.8383, Test Accuracy: 64.56%\n",
      "Epoch [2035/2500], Train Loss: 0.8366, Train Accuracy: 61.31%, Test Loss: 0.8372, Test Accuracy: 63.29%\n",
      "Epoch [2036/2500], Train Loss: 0.8321, Train Accuracy: 63.87%, Test Loss: 0.8463, Test Accuracy: 65.82%\n",
      "Epoch [2037/2500], Train Loss: 0.8222, Train Accuracy: 63.73%, Test Loss: 0.8469, Test Accuracy: 64.56%\n",
      "Epoch [2038/2500], Train Loss: 0.8155, Train Accuracy: 64.86%, Test Loss: 0.8355, Test Accuracy: 65.82%\n",
      "Epoch [2039/2500], Train Loss: 0.7947, Train Accuracy: 65.86%, Test Loss: 0.8394, Test Accuracy: 63.29%\n",
      "Epoch [2040/2500], Train Loss: 0.8291, Train Accuracy: 63.16%, Test Loss: 0.8331, Test Accuracy: 65.82%\n",
      "Epoch [2041/2500], Train Loss: 0.8163, Train Accuracy: 63.87%, Test Loss: 0.8325, Test Accuracy: 67.09%\n",
      "Epoch [2042/2500], Train Loss: 0.8245, Train Accuracy: 64.15%, Test Loss: 0.8351, Test Accuracy: 65.82%\n",
      "Epoch [2043/2500], Train Loss: 0.8014, Train Accuracy: 64.58%, Test Loss: 0.8396, Test Accuracy: 64.56%\n",
      "Epoch [2044/2500], Train Loss: 0.8394, Train Accuracy: 62.45%, Test Loss: 0.8385, Test Accuracy: 63.29%\n",
      "Epoch [2045/2500], Train Loss: 0.8184, Train Accuracy: 65.58%, Test Loss: 0.8331, Test Accuracy: 64.56%\n",
      "Epoch [2046/2500], Train Loss: 0.8274, Train Accuracy: 62.30%, Test Loss: 0.8365, Test Accuracy: 64.56%\n",
      "Epoch [2047/2500], Train Loss: 0.8111, Train Accuracy: 63.30%, Test Loss: 0.8374, Test Accuracy: 63.29%\n",
      "Epoch [2048/2500], Train Loss: 0.8038, Train Accuracy: 64.44%, Test Loss: 0.8353, Test Accuracy: 64.56%\n",
      "Epoch [2049/2500], Train Loss: 0.8100, Train Accuracy: 65.01%, Test Loss: 0.8336, Test Accuracy: 64.56%\n",
      "Epoch [2050/2500], Train Loss: 0.8048, Train Accuracy: 65.01%, Test Loss: 0.8370, Test Accuracy: 65.82%\n",
      "Epoch [2051/2500], Train Loss: 0.8468, Train Accuracy: 60.60%, Test Loss: 0.8409, Test Accuracy: 65.82%\n",
      "Epoch [2052/2500], Train Loss: 0.8251, Train Accuracy: 61.88%, Test Loss: 0.8393, Test Accuracy: 67.09%\n",
      "Epoch [2053/2500], Train Loss: 0.8235, Train Accuracy: 64.15%, Test Loss: 0.8368, Test Accuracy: 67.09%\n",
      "Epoch [2054/2500], Train Loss: 0.8211, Train Accuracy: 62.30%, Test Loss: 0.8457, Test Accuracy: 67.09%\n",
      "Epoch [2055/2500], Train Loss: 0.8134, Train Accuracy: 63.73%, Test Loss: 0.8360, Test Accuracy: 67.09%\n",
      "Epoch [2056/2500], Train Loss: 0.8237, Train Accuracy: 63.16%, Test Loss: 0.8334, Test Accuracy: 65.82%\n",
      "Epoch [2057/2500], Train Loss: 0.8223, Train Accuracy: 65.15%, Test Loss: 0.8406, Test Accuracy: 65.82%\n",
      "Epoch [2058/2500], Train Loss: 0.8205, Train Accuracy: 63.58%, Test Loss: 0.8390, Test Accuracy: 65.82%\n",
      "Epoch [2059/2500], Train Loss: 0.8110, Train Accuracy: 65.15%, Test Loss: 0.8427, Test Accuracy: 63.29%\n",
      "Epoch [2060/2500], Train Loss: 0.8142, Train Accuracy: 64.58%, Test Loss: 0.8337, Test Accuracy: 64.56%\n",
      "Epoch [2061/2500], Train Loss: 0.8108, Train Accuracy: 65.29%, Test Loss: 0.8445, Test Accuracy: 64.56%\n",
      "Epoch [2062/2500], Train Loss: 0.8278, Train Accuracy: 61.59%, Test Loss: 0.8376, Test Accuracy: 64.56%\n",
      "Epoch [2063/2500], Train Loss: 0.8108, Train Accuracy: 63.58%, Test Loss: 0.8414, Test Accuracy: 63.29%\n",
      "Epoch [2064/2500], Train Loss: 0.8113, Train Accuracy: 64.44%, Test Loss: 0.8391, Test Accuracy: 64.56%\n",
      "Epoch [2065/2500], Train Loss: 0.8246, Train Accuracy: 64.72%, Test Loss: 0.8413, Test Accuracy: 63.29%\n",
      "Epoch [2066/2500], Train Loss: 0.8154, Train Accuracy: 62.73%, Test Loss: 0.8364, Test Accuracy: 65.82%\n",
      "Epoch [2067/2500], Train Loss: 0.8354, Train Accuracy: 62.30%, Test Loss: 0.8308, Test Accuracy: 64.56%\n",
      "Epoch [2068/2500], Train Loss: 0.8016, Train Accuracy: 64.86%, Test Loss: 0.8196, Test Accuracy: 64.56%\n",
      "Epoch [2069/2500], Train Loss: 0.8327, Train Accuracy: 62.45%, Test Loss: 0.8335, Test Accuracy: 64.56%\n",
      "Epoch [2070/2500], Train Loss: 0.8036, Train Accuracy: 63.44%, Test Loss: 0.8399, Test Accuracy: 67.09%\n",
      "Epoch [2071/2500], Train Loss: 0.8126, Train Accuracy: 64.72%, Test Loss: 0.8350, Test Accuracy: 64.56%\n",
      "Epoch [2072/2500], Train Loss: 0.8205, Train Accuracy: 62.87%, Test Loss: 0.8235, Test Accuracy: 64.56%\n",
      "Epoch [2073/2500], Train Loss: 0.8142, Train Accuracy: 64.01%, Test Loss: 0.8232, Test Accuracy: 64.56%\n",
      "Epoch [2074/2500], Train Loss: 0.8156, Train Accuracy: 64.15%, Test Loss: 0.8395, Test Accuracy: 63.29%\n",
      "Epoch [2075/2500], Train Loss: 0.8166, Train Accuracy: 63.44%, Test Loss: 0.8183, Test Accuracy: 63.29%\n",
      "Epoch [2076/2500], Train Loss: 0.8371, Train Accuracy: 62.73%, Test Loss: 0.8254, Test Accuracy: 62.03%\n",
      "Epoch [2077/2500], Train Loss: 0.8085, Train Accuracy: 61.74%, Test Loss: 0.8216, Test Accuracy: 65.82%\n",
      "Epoch [2078/2500], Train Loss: 0.8144, Train Accuracy: 63.73%, Test Loss: 0.8306, Test Accuracy: 64.56%\n",
      "Epoch [2079/2500], Train Loss: 0.8019, Train Accuracy: 65.15%, Test Loss: 0.8398, Test Accuracy: 65.82%\n",
      "Epoch [2080/2500], Train Loss: 0.8163, Train Accuracy: 62.45%, Test Loss: 0.8289, Test Accuracy: 64.56%\n",
      "Epoch [2081/2500], Train Loss: 0.8282, Train Accuracy: 62.73%, Test Loss: 0.8313, Test Accuracy: 64.56%\n",
      "Epoch [2082/2500], Train Loss: 0.8046, Train Accuracy: 63.44%, Test Loss: 0.8339, Test Accuracy: 64.56%\n",
      "Epoch [2083/2500], Train Loss: 0.8174, Train Accuracy: 63.87%, Test Loss: 0.8343, Test Accuracy: 65.82%\n",
      "Epoch [2084/2500], Train Loss: 0.8201, Train Accuracy: 64.15%, Test Loss: 0.8149, Test Accuracy: 65.82%\n",
      "Epoch [2085/2500], Train Loss: 0.8136, Train Accuracy: 63.87%, Test Loss: 0.8311, Test Accuracy: 67.09%\n",
      "Epoch [2086/2500], Train Loss: 0.8103, Train Accuracy: 66.57%, Test Loss: 0.8356, Test Accuracy: 65.82%\n",
      "Epoch [2087/2500], Train Loss: 0.8217, Train Accuracy: 64.72%, Test Loss: 0.8314, Test Accuracy: 65.82%\n",
      "Epoch [2088/2500], Train Loss: 0.8105, Train Accuracy: 63.16%, Test Loss: 0.8304, Test Accuracy: 65.82%\n",
      "Epoch [2089/2500], Train Loss: 0.8287, Train Accuracy: 63.87%, Test Loss: 0.8189, Test Accuracy: 64.56%\n",
      "Epoch [2090/2500], Train Loss: 0.8088, Train Accuracy: 63.58%, Test Loss: 0.8205, Test Accuracy: 65.82%\n",
      "Epoch [2091/2500], Train Loss: 0.8102, Train Accuracy: 64.72%, Test Loss: 0.8208, Test Accuracy: 65.82%\n",
      "Epoch [2092/2500], Train Loss: 0.8240, Train Accuracy: 65.29%, Test Loss: 0.8325, Test Accuracy: 64.56%\n",
      "Epoch [2093/2500], Train Loss: 0.8271, Train Accuracy: 62.59%, Test Loss: 0.8310, Test Accuracy: 64.56%\n",
      "Epoch [2094/2500], Train Loss: 0.8183, Train Accuracy: 62.16%, Test Loss: 0.8320, Test Accuracy: 65.82%\n",
      "Epoch [2095/2500], Train Loss: 0.8057, Train Accuracy: 63.73%, Test Loss: 0.8265, Test Accuracy: 67.09%\n",
      "Epoch [2096/2500], Train Loss: 0.8012, Train Accuracy: 63.30%, Test Loss: 0.8294, Test Accuracy: 65.82%\n",
      "Epoch [2097/2500], Train Loss: 0.8224, Train Accuracy: 64.30%, Test Loss: 0.8426, Test Accuracy: 67.09%\n",
      "Epoch [2098/2500], Train Loss: 0.8201, Train Accuracy: 63.87%, Test Loss: 0.8417, Test Accuracy: 65.82%\n",
      "Epoch [2099/2500], Train Loss: 0.8123, Train Accuracy: 63.16%, Test Loss: 0.8478, Test Accuracy: 65.82%\n",
      "Epoch [2100/2500], Train Loss: 0.8246, Train Accuracy: 62.87%, Test Loss: 0.8426, Test Accuracy: 67.09%\n",
      "Epoch [2101/2500], Train Loss: 0.8180, Train Accuracy: 64.86%, Test Loss: 0.8383, Test Accuracy: 65.82%\n",
      "Epoch [2102/2500], Train Loss: 0.8107, Train Accuracy: 61.59%, Test Loss: 0.8414, Test Accuracy: 64.56%\n",
      "Epoch [2103/2500], Train Loss: 0.8179, Train Accuracy: 62.45%, Test Loss: 0.8382, Test Accuracy: 67.09%\n",
      "Epoch [2104/2500], Train Loss: 0.8231, Train Accuracy: 64.30%, Test Loss: 0.8266, Test Accuracy: 64.56%\n",
      "Epoch [2105/2500], Train Loss: 0.8116, Train Accuracy: 63.16%, Test Loss: 0.8331, Test Accuracy: 64.56%\n",
      "Epoch [2106/2500], Train Loss: 0.8167, Train Accuracy: 64.30%, Test Loss: 0.8288, Test Accuracy: 63.29%\n",
      "Epoch [2107/2500], Train Loss: 0.8113, Train Accuracy: 63.02%, Test Loss: 0.8357, Test Accuracy: 65.82%\n",
      "Epoch [2108/2500], Train Loss: 0.7950, Train Accuracy: 65.43%, Test Loss: 0.8312, Test Accuracy: 63.29%\n",
      "Epoch [2109/2500], Train Loss: 0.8190, Train Accuracy: 62.87%, Test Loss: 0.8365, Test Accuracy: 63.29%\n",
      "Epoch [2110/2500], Train Loss: 0.8171, Train Accuracy: 63.44%, Test Loss: 0.8321, Test Accuracy: 64.56%\n",
      "Epoch [2111/2500], Train Loss: 0.8068, Train Accuracy: 62.73%, Test Loss: 0.8394, Test Accuracy: 62.03%\n",
      "Epoch [2112/2500], Train Loss: 0.7960, Train Accuracy: 65.43%, Test Loss: 0.8305, Test Accuracy: 63.29%\n",
      "Epoch [2113/2500], Train Loss: 0.8153, Train Accuracy: 64.15%, Test Loss: 0.8378, Test Accuracy: 64.56%\n",
      "Epoch [2114/2500], Train Loss: 0.7969, Train Accuracy: 64.44%, Test Loss: 0.8308, Test Accuracy: 65.82%\n",
      "Epoch [2115/2500], Train Loss: 0.8587, Train Accuracy: 62.30%, Test Loss: 0.8370, Test Accuracy: 65.82%\n",
      "Epoch [2116/2500], Train Loss: 0.8235, Train Accuracy: 61.31%, Test Loss: 0.8265, Test Accuracy: 65.82%\n",
      "Epoch [2117/2500], Train Loss: 0.8067, Train Accuracy: 64.01%, Test Loss: 0.8276, Test Accuracy: 64.56%\n",
      "Epoch [2118/2500], Train Loss: 0.8165, Train Accuracy: 64.58%, Test Loss: 0.8266, Test Accuracy: 65.82%\n",
      "Epoch [2119/2500], Train Loss: 0.8097, Train Accuracy: 64.15%, Test Loss: 0.8300, Test Accuracy: 65.82%\n",
      "Epoch [2120/2500], Train Loss: 0.8042, Train Accuracy: 62.73%, Test Loss: 0.8379, Test Accuracy: 63.29%\n",
      "Epoch [2121/2500], Train Loss: 0.8182, Train Accuracy: 64.15%, Test Loss: 0.8368, Test Accuracy: 65.82%\n",
      "Epoch [2122/2500], Train Loss: 0.8134, Train Accuracy: 64.72%, Test Loss: 0.8346, Test Accuracy: 65.82%\n",
      "Epoch [2123/2500], Train Loss: 0.8026, Train Accuracy: 64.30%, Test Loss: 0.8302, Test Accuracy: 64.56%\n",
      "Epoch [2124/2500], Train Loss: 0.8265, Train Accuracy: 61.88%, Test Loss: 0.8371, Test Accuracy: 65.82%\n",
      "Epoch [2125/2500], Train Loss: 0.8305, Train Accuracy: 61.02%, Test Loss: 0.8297, Test Accuracy: 64.56%\n",
      "Epoch [2126/2500], Train Loss: 0.8229, Train Accuracy: 63.30%, Test Loss: 0.8463, Test Accuracy: 65.82%\n",
      "Epoch [2127/2500], Train Loss: 0.8282, Train Accuracy: 62.59%, Test Loss: 0.8421, Test Accuracy: 64.56%\n",
      "Epoch [2128/2500], Train Loss: 0.8006, Train Accuracy: 64.01%, Test Loss: 0.8438, Test Accuracy: 64.56%\n",
      "Epoch [2129/2500], Train Loss: 0.8205, Train Accuracy: 63.44%, Test Loss: 0.8398, Test Accuracy: 64.56%\n",
      "Epoch [2130/2500], Train Loss: 0.8142, Train Accuracy: 64.30%, Test Loss: 0.8440, Test Accuracy: 65.82%\n",
      "Epoch [2131/2500], Train Loss: 0.8108, Train Accuracy: 64.15%, Test Loss: 0.8501, Test Accuracy: 65.82%\n",
      "Epoch [2132/2500], Train Loss: 0.8264, Train Accuracy: 62.02%, Test Loss: 0.8455, Test Accuracy: 63.29%\n",
      "Epoch [2133/2500], Train Loss: 0.8099, Train Accuracy: 62.73%, Test Loss: 0.8461, Test Accuracy: 64.56%\n",
      "Epoch [2134/2500], Train Loss: 0.8209, Train Accuracy: 63.44%, Test Loss: 0.8455, Test Accuracy: 65.82%\n",
      "Epoch [2135/2500], Train Loss: 0.8056, Train Accuracy: 64.72%, Test Loss: 0.8453, Test Accuracy: 64.56%\n",
      "Epoch [2136/2500], Train Loss: 0.8134, Train Accuracy: 64.44%, Test Loss: 0.8453, Test Accuracy: 64.56%\n",
      "Epoch [2137/2500], Train Loss: 0.7989, Train Accuracy: 65.15%, Test Loss: 0.8491, Test Accuracy: 65.82%\n",
      "Epoch [2138/2500], Train Loss: 0.8065, Train Accuracy: 64.44%, Test Loss: 0.8458, Test Accuracy: 63.29%\n",
      "Epoch [2139/2500], Train Loss: 0.8077, Train Accuracy: 65.58%, Test Loss: 0.8467, Test Accuracy: 63.29%\n",
      "Epoch [2140/2500], Train Loss: 0.8115, Train Accuracy: 64.30%, Test Loss: 0.8460, Test Accuracy: 65.82%\n",
      "Epoch [2141/2500], Train Loss: 0.8204, Train Accuracy: 62.30%, Test Loss: 0.8454, Test Accuracy: 64.56%\n",
      "Epoch [2142/2500], Train Loss: 0.8278, Train Accuracy: 64.01%, Test Loss: 0.8485, Test Accuracy: 64.56%\n",
      "Epoch [2143/2500], Train Loss: 0.7994, Train Accuracy: 64.86%, Test Loss: 0.8479, Test Accuracy: 62.03%\n",
      "Epoch [2144/2500], Train Loss: 0.8149, Train Accuracy: 64.58%, Test Loss: 0.8407, Test Accuracy: 64.56%\n",
      "Epoch [2145/2500], Train Loss: 0.8147, Train Accuracy: 65.01%, Test Loss: 0.8400, Test Accuracy: 64.56%\n",
      "Epoch [2146/2500], Train Loss: 0.8152, Train Accuracy: 62.87%, Test Loss: 0.8457, Test Accuracy: 63.29%\n",
      "Epoch [2147/2500], Train Loss: 0.8141, Train Accuracy: 63.44%, Test Loss: 0.8341, Test Accuracy: 64.56%\n",
      "Epoch [2148/2500], Train Loss: 0.8276, Train Accuracy: 62.73%, Test Loss: 0.8360, Test Accuracy: 63.29%\n",
      "Epoch [2149/2500], Train Loss: 0.8013, Train Accuracy: 63.87%, Test Loss: 0.8410, Test Accuracy: 63.29%\n",
      "Epoch [2150/2500], Train Loss: 0.7928, Train Accuracy: 65.15%, Test Loss: 0.8420, Test Accuracy: 62.03%\n",
      "Epoch [2151/2500], Train Loss: 0.8254, Train Accuracy: 62.45%, Test Loss: 0.8334, Test Accuracy: 62.03%\n",
      "Epoch [2152/2500], Train Loss: 0.8373, Train Accuracy: 62.16%, Test Loss: 0.8385, Test Accuracy: 62.03%\n",
      "Epoch [2153/2500], Train Loss: 0.8096, Train Accuracy: 64.72%, Test Loss: 0.8331, Test Accuracy: 64.56%\n",
      "Epoch [2154/2500], Train Loss: 0.8117, Train Accuracy: 64.72%, Test Loss: 0.8358, Test Accuracy: 65.82%\n",
      "Epoch [2155/2500], Train Loss: 0.8087, Train Accuracy: 63.73%, Test Loss: 0.8312, Test Accuracy: 62.03%\n",
      "Epoch [2156/2500], Train Loss: 0.8132, Train Accuracy: 65.43%, Test Loss: 0.8296, Test Accuracy: 62.03%\n",
      "Epoch [2157/2500], Train Loss: 0.8229, Train Accuracy: 61.59%, Test Loss: 0.8321, Test Accuracy: 62.03%\n",
      "Epoch [2158/2500], Train Loss: 0.8222, Train Accuracy: 63.16%, Test Loss: 0.8319, Test Accuracy: 63.29%\n",
      "Epoch [2159/2500], Train Loss: 0.8088, Train Accuracy: 63.02%, Test Loss: 0.8384, Test Accuracy: 64.56%\n",
      "Epoch [2160/2500], Train Loss: 0.8150, Train Accuracy: 64.01%, Test Loss: 0.8474, Test Accuracy: 63.29%\n",
      "Epoch [2161/2500], Train Loss: 0.8123, Train Accuracy: 63.87%, Test Loss: 0.8446, Test Accuracy: 63.29%\n",
      "Epoch [2162/2500], Train Loss: 0.8115, Train Accuracy: 61.31%, Test Loss: 0.8430, Test Accuracy: 62.03%\n",
      "Epoch [2163/2500], Train Loss: 0.8119, Train Accuracy: 63.02%, Test Loss: 0.8389, Test Accuracy: 64.56%\n",
      "Epoch [2164/2500], Train Loss: 0.8154, Train Accuracy: 64.44%, Test Loss: 0.8508, Test Accuracy: 64.56%\n",
      "Epoch [2165/2500], Train Loss: 0.8135, Train Accuracy: 63.87%, Test Loss: 0.8409, Test Accuracy: 65.82%\n",
      "Epoch [2166/2500], Train Loss: 0.8051, Train Accuracy: 64.44%, Test Loss: 0.8422, Test Accuracy: 64.56%\n",
      "Epoch [2167/2500], Train Loss: 0.8129, Train Accuracy: 63.02%, Test Loss: 0.8440, Test Accuracy: 64.56%\n",
      "Epoch [2168/2500], Train Loss: 0.8064, Train Accuracy: 64.72%, Test Loss: 0.8384, Test Accuracy: 64.56%\n",
      "Epoch [2169/2500], Train Loss: 0.8071, Train Accuracy: 64.44%, Test Loss: 0.8320, Test Accuracy: 63.29%\n",
      "Epoch [2170/2500], Train Loss: 0.8207, Train Accuracy: 63.58%, Test Loss: 0.8363, Test Accuracy: 63.29%\n",
      "Epoch [2171/2500], Train Loss: 0.7999, Train Accuracy: 63.87%, Test Loss: 0.8353, Test Accuracy: 64.56%\n",
      "Epoch [2172/2500], Train Loss: 0.7925, Train Accuracy: 64.72%, Test Loss: 0.8330, Test Accuracy: 64.56%\n",
      "Epoch [2173/2500], Train Loss: 0.8296, Train Accuracy: 63.58%, Test Loss: 0.8227, Test Accuracy: 64.56%\n",
      "Epoch [2174/2500], Train Loss: 0.8100, Train Accuracy: 65.29%, Test Loss: 0.8346, Test Accuracy: 64.56%\n",
      "Epoch [2175/2500], Train Loss: 0.8147, Train Accuracy: 63.87%, Test Loss: 0.8247, Test Accuracy: 63.29%\n",
      "Epoch [2176/2500], Train Loss: 0.8113, Train Accuracy: 65.01%, Test Loss: 0.8285, Test Accuracy: 64.56%\n",
      "Epoch [2177/2500], Train Loss: 0.8151, Train Accuracy: 64.15%, Test Loss: 0.8373, Test Accuracy: 63.29%\n",
      "Epoch [2178/2500], Train Loss: 0.8044, Train Accuracy: 64.01%, Test Loss: 0.8304, Test Accuracy: 64.56%\n",
      "Epoch [2179/2500], Train Loss: 0.8107, Train Accuracy: 63.58%, Test Loss: 0.8381, Test Accuracy: 63.29%\n",
      "Epoch [2180/2500], Train Loss: 0.8048, Train Accuracy: 63.87%, Test Loss: 0.8397, Test Accuracy: 63.29%\n",
      "Epoch [2181/2500], Train Loss: 0.7983, Train Accuracy: 64.72%, Test Loss: 0.8347, Test Accuracy: 62.03%\n",
      "Epoch [2182/2500], Train Loss: 0.8271, Train Accuracy: 61.59%, Test Loss: 0.8340, Test Accuracy: 63.29%\n",
      "Epoch [2183/2500], Train Loss: 0.8233, Train Accuracy: 63.02%, Test Loss: 0.8368, Test Accuracy: 63.29%\n",
      "Epoch [2184/2500], Train Loss: 0.8388, Train Accuracy: 64.15%, Test Loss: 0.8396, Test Accuracy: 64.56%\n",
      "Epoch [2185/2500], Train Loss: 0.8191, Train Accuracy: 63.44%, Test Loss: 0.8360, Test Accuracy: 63.29%\n",
      "Epoch [2186/2500], Train Loss: 0.7880, Train Accuracy: 63.87%, Test Loss: 0.8443, Test Accuracy: 64.56%\n",
      "Epoch [2187/2500], Train Loss: 0.8133, Train Accuracy: 64.15%, Test Loss: 0.8343, Test Accuracy: 65.82%\n",
      "Epoch [2188/2500], Train Loss: 0.8234, Train Accuracy: 63.30%, Test Loss: 0.8353, Test Accuracy: 64.56%\n",
      "Epoch [2189/2500], Train Loss: 0.8168, Train Accuracy: 63.02%, Test Loss: 0.8214, Test Accuracy: 65.82%\n",
      "Epoch [2190/2500], Train Loss: 0.8167, Train Accuracy: 63.30%, Test Loss: 0.8335, Test Accuracy: 64.56%\n",
      "Epoch [2191/2500], Train Loss: 0.8205, Train Accuracy: 63.02%, Test Loss: 0.8281, Test Accuracy: 64.56%\n",
      "Epoch [2192/2500], Train Loss: 0.7992, Train Accuracy: 65.15%, Test Loss: 0.8293, Test Accuracy: 62.03%\n",
      "Epoch [2193/2500], Train Loss: 0.8239, Train Accuracy: 62.73%, Test Loss: 0.8399, Test Accuracy: 63.29%\n",
      "Epoch [2194/2500], Train Loss: 0.8239, Train Accuracy: 63.30%, Test Loss: 0.8354, Test Accuracy: 63.29%\n",
      "Epoch [2195/2500], Train Loss: 0.8209, Train Accuracy: 63.02%, Test Loss: 0.8387, Test Accuracy: 62.03%\n",
      "Epoch [2196/2500], Train Loss: 0.7876, Train Accuracy: 64.72%, Test Loss: 0.8250, Test Accuracy: 63.29%\n",
      "Epoch [2197/2500], Train Loss: 0.8220, Train Accuracy: 63.87%, Test Loss: 0.8500, Test Accuracy: 65.82%\n",
      "Epoch [2198/2500], Train Loss: 0.8083, Train Accuracy: 65.01%, Test Loss: 0.8444, Test Accuracy: 65.82%\n",
      "Epoch [2199/2500], Train Loss: 0.8145, Train Accuracy: 64.15%, Test Loss: 0.8385, Test Accuracy: 65.82%\n",
      "Epoch [2200/2500], Train Loss: 0.8085, Train Accuracy: 62.73%, Test Loss: 0.8374, Test Accuracy: 64.56%\n",
      "Epoch [2201/2500], Train Loss: 0.7971, Train Accuracy: 64.44%, Test Loss: 0.8436, Test Accuracy: 63.29%\n",
      "Epoch [2202/2500], Train Loss: 0.8193, Train Accuracy: 63.16%, Test Loss: 0.8408, Test Accuracy: 65.82%\n",
      "Epoch [2203/2500], Train Loss: 0.7963, Train Accuracy: 64.72%, Test Loss: 0.8462, Test Accuracy: 63.29%\n",
      "Epoch [2204/2500], Train Loss: 0.8012, Train Accuracy: 62.59%, Test Loss: 0.8397, Test Accuracy: 64.56%\n",
      "Epoch [2205/2500], Train Loss: 0.8155, Train Accuracy: 64.86%, Test Loss: 0.8386, Test Accuracy: 64.56%\n",
      "Epoch [2206/2500], Train Loss: 0.8061, Train Accuracy: 64.15%, Test Loss: 0.8363, Test Accuracy: 64.56%\n",
      "Epoch [2207/2500], Train Loss: 0.8272, Train Accuracy: 62.87%, Test Loss: 0.8333, Test Accuracy: 64.56%\n",
      "Epoch [2208/2500], Train Loss: 0.8010, Train Accuracy: 65.01%, Test Loss: 0.8183, Test Accuracy: 64.56%\n",
      "Epoch [2209/2500], Train Loss: 0.8001, Train Accuracy: 64.30%, Test Loss: 0.8170, Test Accuracy: 64.56%\n",
      "Epoch [2210/2500], Train Loss: 0.8105, Train Accuracy: 63.44%, Test Loss: 0.8314, Test Accuracy: 64.56%\n",
      "Epoch [2211/2500], Train Loss: 0.8017, Train Accuracy: 64.86%, Test Loss: 0.8331, Test Accuracy: 64.56%\n",
      "Epoch [2212/2500], Train Loss: 0.7993, Train Accuracy: 62.73%, Test Loss: 0.8266, Test Accuracy: 64.56%\n",
      "Epoch [2213/2500], Train Loss: 0.7984, Train Accuracy: 64.30%, Test Loss: 0.8180, Test Accuracy: 64.56%\n",
      "Epoch [2214/2500], Train Loss: 0.8205, Train Accuracy: 64.30%, Test Loss: 0.8280, Test Accuracy: 63.29%\n",
      "Epoch [2215/2500], Train Loss: 0.8106, Train Accuracy: 64.30%, Test Loss: 0.8248, Test Accuracy: 63.29%\n",
      "Epoch [2216/2500], Train Loss: 0.8179, Train Accuracy: 62.87%, Test Loss: 0.8237, Test Accuracy: 64.56%\n",
      "Epoch [2217/2500], Train Loss: 0.7986, Train Accuracy: 64.44%, Test Loss: 0.8217, Test Accuracy: 64.56%\n",
      "Epoch [2218/2500], Train Loss: 0.7969, Train Accuracy: 65.01%, Test Loss: 0.8213, Test Accuracy: 65.82%\n",
      "Epoch [2219/2500], Train Loss: 0.8193, Train Accuracy: 63.16%, Test Loss: 0.8267, Test Accuracy: 65.82%\n",
      "Epoch [2220/2500], Train Loss: 0.8001, Train Accuracy: 64.30%, Test Loss: 0.8255, Test Accuracy: 65.82%\n",
      "Epoch [2221/2500], Train Loss: 0.8115, Train Accuracy: 63.87%, Test Loss: 0.8266, Test Accuracy: 65.82%\n",
      "Epoch [2222/2500], Train Loss: 0.8014, Train Accuracy: 64.01%, Test Loss: 0.8168, Test Accuracy: 65.82%\n",
      "Epoch [2223/2500], Train Loss: 0.8099, Train Accuracy: 65.15%, Test Loss: 0.8265, Test Accuracy: 65.82%\n",
      "Epoch [2224/2500], Train Loss: 0.8206, Train Accuracy: 63.73%, Test Loss: 0.8261, Test Accuracy: 65.82%\n",
      "Epoch [2225/2500], Train Loss: 0.8200, Train Accuracy: 62.02%, Test Loss: 0.8291, Test Accuracy: 64.56%\n",
      "Epoch [2226/2500], Train Loss: 0.8162, Train Accuracy: 62.73%, Test Loss: 0.8326, Test Accuracy: 65.82%\n",
      "Epoch [2227/2500], Train Loss: 0.8029, Train Accuracy: 63.58%, Test Loss: 0.8419, Test Accuracy: 64.56%\n",
      "Epoch [2228/2500], Train Loss: 0.8040, Train Accuracy: 63.87%, Test Loss: 0.8410, Test Accuracy: 63.29%\n",
      "Epoch [2229/2500], Train Loss: 0.8056, Train Accuracy: 63.30%, Test Loss: 0.8460, Test Accuracy: 64.56%\n",
      "Epoch [2230/2500], Train Loss: 0.8057, Train Accuracy: 63.73%, Test Loss: 0.8429, Test Accuracy: 65.82%\n",
      "Epoch [2231/2500], Train Loss: 0.7874, Train Accuracy: 63.87%, Test Loss: 0.8373, Test Accuracy: 65.82%\n",
      "Epoch [2232/2500], Train Loss: 0.8030, Train Accuracy: 62.30%, Test Loss: 0.8388, Test Accuracy: 65.82%\n",
      "Epoch [2233/2500], Train Loss: 0.8089, Train Accuracy: 63.02%, Test Loss: 0.8426, Test Accuracy: 63.29%\n",
      "Epoch [2234/2500], Train Loss: 0.8055, Train Accuracy: 64.72%, Test Loss: 0.8483, Test Accuracy: 65.82%\n",
      "Epoch [2235/2500], Train Loss: 0.8102, Train Accuracy: 63.87%, Test Loss: 0.8294, Test Accuracy: 65.82%\n",
      "Epoch [2236/2500], Train Loss: 0.8184, Train Accuracy: 63.30%, Test Loss: 0.8372, Test Accuracy: 64.56%\n",
      "Epoch [2237/2500], Train Loss: 0.8053, Train Accuracy: 65.15%, Test Loss: 0.8477, Test Accuracy: 64.56%\n",
      "Epoch [2238/2500], Train Loss: 0.8044, Train Accuracy: 64.86%, Test Loss: 0.8372, Test Accuracy: 64.56%\n",
      "Epoch [2239/2500], Train Loss: 0.8155, Train Accuracy: 62.73%, Test Loss: 0.8389, Test Accuracy: 64.56%\n",
      "Epoch [2240/2500], Train Loss: 0.8035, Train Accuracy: 62.73%, Test Loss: 0.8334, Test Accuracy: 64.56%\n",
      "Epoch [2241/2500], Train Loss: 0.7989, Train Accuracy: 64.30%, Test Loss: 0.8351, Test Accuracy: 64.56%\n",
      "Epoch [2242/2500], Train Loss: 0.8046, Train Accuracy: 64.15%, Test Loss: 0.8503, Test Accuracy: 65.82%\n",
      "Epoch [2243/2500], Train Loss: 0.8038, Train Accuracy: 63.58%, Test Loss: 0.8562, Test Accuracy: 65.82%\n",
      "Epoch [2244/2500], Train Loss: 0.8044, Train Accuracy: 63.87%, Test Loss: 0.8505, Test Accuracy: 65.82%\n",
      "Epoch [2245/2500], Train Loss: 0.8155, Train Accuracy: 63.16%, Test Loss: 0.8492, Test Accuracy: 64.56%\n",
      "Epoch [2246/2500], Train Loss: 0.7986, Train Accuracy: 66.29%, Test Loss: 0.8281, Test Accuracy: 65.82%\n",
      "Epoch [2247/2500], Train Loss: 0.7961, Train Accuracy: 64.86%, Test Loss: 0.8388, Test Accuracy: 64.56%\n",
      "Epoch [2248/2500], Train Loss: 0.8080, Train Accuracy: 64.30%, Test Loss: 0.8356, Test Accuracy: 63.29%\n",
      "Epoch [2249/2500], Train Loss: 0.8137, Train Accuracy: 64.86%, Test Loss: 0.8286, Test Accuracy: 64.56%\n",
      "Epoch [2250/2500], Train Loss: 0.8070, Train Accuracy: 62.87%, Test Loss: 0.8315, Test Accuracy: 63.29%\n",
      "Epoch [2251/2500], Train Loss: 0.8050, Train Accuracy: 63.58%, Test Loss: 0.8191, Test Accuracy: 64.56%\n",
      "Epoch [2252/2500], Train Loss: 0.8082, Train Accuracy: 64.72%, Test Loss: 0.8345, Test Accuracy: 64.56%\n",
      "Epoch [2253/2500], Train Loss: 0.7891, Train Accuracy: 65.72%, Test Loss: 0.8273, Test Accuracy: 64.56%\n",
      "Epoch [2254/2500], Train Loss: 0.8064, Train Accuracy: 64.30%, Test Loss: 0.8318, Test Accuracy: 64.56%\n",
      "Epoch [2255/2500], Train Loss: 0.8063, Train Accuracy: 62.87%, Test Loss: 0.8464, Test Accuracy: 64.56%\n",
      "Epoch [2256/2500], Train Loss: 0.7998, Train Accuracy: 64.44%, Test Loss: 0.8390, Test Accuracy: 64.56%\n",
      "Epoch [2257/2500], Train Loss: 0.8069, Train Accuracy: 65.58%, Test Loss: 0.8378, Test Accuracy: 64.56%\n",
      "Epoch [2258/2500], Train Loss: 0.7989, Train Accuracy: 65.72%, Test Loss: 0.8329, Test Accuracy: 63.29%\n",
      "Epoch [2259/2500], Train Loss: 0.8059, Train Accuracy: 65.15%, Test Loss: 0.8273, Test Accuracy: 64.56%\n",
      "Epoch [2260/2500], Train Loss: 0.8090, Train Accuracy: 62.59%, Test Loss: 0.8310, Test Accuracy: 64.56%\n",
      "Epoch [2261/2500], Train Loss: 0.7969, Train Accuracy: 64.44%, Test Loss: 0.8473, Test Accuracy: 65.82%\n",
      "Epoch [2262/2500], Train Loss: 0.7995, Train Accuracy: 65.29%, Test Loss: 0.8344, Test Accuracy: 64.56%\n",
      "Epoch [2263/2500], Train Loss: 0.8088, Train Accuracy: 62.73%, Test Loss: 0.8216, Test Accuracy: 65.82%\n",
      "Epoch [2264/2500], Train Loss: 0.8013, Train Accuracy: 63.87%, Test Loss: 0.8293, Test Accuracy: 67.09%\n",
      "Epoch [2265/2500], Train Loss: 0.7944, Train Accuracy: 65.72%, Test Loss: 0.8266, Test Accuracy: 64.56%\n",
      "Epoch [2266/2500], Train Loss: 0.7927, Train Accuracy: 65.29%, Test Loss: 0.8313, Test Accuracy: 64.56%\n",
      "Epoch [2267/2500], Train Loss: 0.8180, Train Accuracy: 63.58%, Test Loss: 0.8350, Test Accuracy: 64.56%\n",
      "Epoch [2268/2500], Train Loss: 0.8075, Train Accuracy: 65.43%, Test Loss: 0.8273, Test Accuracy: 64.56%\n",
      "Epoch [2269/2500], Train Loss: 0.8008, Train Accuracy: 64.58%, Test Loss: 0.8331, Test Accuracy: 64.56%\n",
      "Epoch [2270/2500], Train Loss: 0.8212, Train Accuracy: 64.30%, Test Loss: 0.8417, Test Accuracy: 65.82%\n",
      "Epoch [2271/2500], Train Loss: 0.8086, Train Accuracy: 63.44%, Test Loss: 0.8329, Test Accuracy: 63.29%\n",
      "Epoch [2272/2500], Train Loss: 0.8039, Train Accuracy: 64.44%, Test Loss: 0.8287, Test Accuracy: 63.29%\n",
      "Epoch [2273/2500], Train Loss: 0.8167, Train Accuracy: 64.30%, Test Loss: 0.8246, Test Accuracy: 64.56%\n",
      "Epoch [2274/2500], Train Loss: 0.7969, Train Accuracy: 64.30%, Test Loss: 0.8276, Test Accuracy: 64.56%\n",
      "Epoch [2275/2500], Train Loss: 0.8148, Train Accuracy: 63.44%, Test Loss: 0.8265, Test Accuracy: 64.56%\n",
      "Epoch [2276/2500], Train Loss: 0.8286, Train Accuracy: 63.44%, Test Loss: 0.8366, Test Accuracy: 63.29%\n",
      "Epoch [2277/2500], Train Loss: 0.7835, Train Accuracy: 65.58%, Test Loss: 0.8418, Test Accuracy: 64.56%\n",
      "Epoch [2278/2500], Train Loss: 0.8024, Train Accuracy: 64.15%, Test Loss: 0.8346, Test Accuracy: 63.29%\n",
      "Epoch [2279/2500], Train Loss: 0.8200, Train Accuracy: 62.87%, Test Loss: 0.8420, Test Accuracy: 65.82%\n",
      "Epoch [2280/2500], Train Loss: 0.8075, Train Accuracy: 65.29%, Test Loss: 0.8418, Test Accuracy: 64.56%\n",
      "Epoch [2281/2500], Train Loss: 0.8041, Train Accuracy: 64.30%, Test Loss: 0.8465, Test Accuracy: 63.29%\n",
      "Epoch [2282/2500], Train Loss: 0.8263, Train Accuracy: 63.44%, Test Loss: 0.8407, Test Accuracy: 65.82%\n",
      "Epoch [2283/2500], Train Loss: 0.8012, Train Accuracy: 65.15%, Test Loss: 0.8433, Test Accuracy: 65.82%\n",
      "Epoch [2284/2500], Train Loss: 0.8032, Train Accuracy: 63.73%, Test Loss: 0.8337, Test Accuracy: 64.56%\n",
      "Epoch [2285/2500], Train Loss: 0.8036, Train Accuracy: 64.15%, Test Loss: 0.8422, Test Accuracy: 64.56%\n",
      "Epoch [2286/2500], Train Loss: 0.8034, Train Accuracy: 64.44%, Test Loss: 0.8445, Test Accuracy: 65.82%\n",
      "Epoch [2287/2500], Train Loss: 0.8074, Train Accuracy: 62.30%, Test Loss: 0.8381, Test Accuracy: 64.56%\n",
      "Epoch [2288/2500], Train Loss: 0.7978, Train Accuracy: 66.00%, Test Loss: 0.8268, Test Accuracy: 65.82%\n",
      "Epoch [2289/2500], Train Loss: 0.8104, Train Accuracy: 63.44%, Test Loss: 0.8206, Test Accuracy: 64.56%\n",
      "Epoch [2290/2500], Train Loss: 0.8135, Train Accuracy: 64.15%, Test Loss: 0.8186, Test Accuracy: 64.56%\n",
      "Epoch [2291/2500], Train Loss: 0.8013, Train Accuracy: 64.86%, Test Loss: 0.8279, Test Accuracy: 64.56%\n",
      "Epoch [2292/2500], Train Loss: 0.8007, Train Accuracy: 62.59%, Test Loss: 0.8293, Test Accuracy: 64.56%\n",
      "Epoch [2293/2500], Train Loss: 0.8026, Train Accuracy: 65.01%, Test Loss: 0.8310, Test Accuracy: 64.56%\n",
      "Epoch [2294/2500], Train Loss: 0.8088, Train Accuracy: 64.30%, Test Loss: 0.8312, Test Accuracy: 67.09%\n",
      "Epoch [2295/2500], Train Loss: 0.8053, Train Accuracy: 65.58%, Test Loss: 0.8277, Test Accuracy: 64.56%\n",
      "Epoch [2296/2500], Train Loss: 0.8006, Train Accuracy: 66.29%, Test Loss: 0.8211, Test Accuracy: 67.09%\n",
      "Epoch [2297/2500], Train Loss: 0.8151, Train Accuracy: 62.45%, Test Loss: 0.8208, Test Accuracy: 65.82%\n",
      "Epoch [2298/2500], Train Loss: 0.8120, Train Accuracy: 64.30%, Test Loss: 0.8289, Test Accuracy: 67.09%\n",
      "Epoch [2299/2500], Train Loss: 0.8007, Train Accuracy: 65.29%, Test Loss: 0.8361, Test Accuracy: 67.09%\n",
      "Epoch [2300/2500], Train Loss: 0.8166, Train Accuracy: 63.44%, Test Loss: 0.8388, Test Accuracy: 64.56%\n",
      "Epoch [2301/2500], Train Loss: 0.8131, Train Accuracy: 64.15%, Test Loss: 0.8380, Test Accuracy: 65.82%\n",
      "Epoch [2302/2500], Train Loss: 0.8185, Train Accuracy: 63.02%, Test Loss: 0.8344, Test Accuracy: 64.56%\n",
      "Epoch [2303/2500], Train Loss: 0.7817, Train Accuracy: 65.58%, Test Loss: 0.8265, Test Accuracy: 63.29%\n",
      "Epoch [2304/2500], Train Loss: 0.8027, Train Accuracy: 65.86%, Test Loss: 0.8244, Test Accuracy: 64.56%\n",
      "Epoch [2305/2500], Train Loss: 0.7977, Train Accuracy: 64.58%, Test Loss: 0.8198, Test Accuracy: 64.56%\n",
      "Epoch [2306/2500], Train Loss: 0.8039, Train Accuracy: 63.44%, Test Loss: 0.8190, Test Accuracy: 63.29%\n",
      "Epoch [2307/2500], Train Loss: 0.7926, Train Accuracy: 64.01%, Test Loss: 0.8183, Test Accuracy: 64.56%\n",
      "Epoch [2308/2500], Train Loss: 0.8049, Train Accuracy: 65.43%, Test Loss: 0.8209, Test Accuracy: 63.29%\n",
      "Epoch [2309/2500], Train Loss: 0.7949, Train Accuracy: 65.43%, Test Loss: 0.8310, Test Accuracy: 62.03%\n",
      "Epoch [2310/2500], Train Loss: 0.7873, Train Accuracy: 65.01%, Test Loss: 0.8241, Test Accuracy: 64.56%\n",
      "Epoch [2311/2500], Train Loss: 0.8095, Train Accuracy: 64.44%, Test Loss: 0.8358, Test Accuracy: 63.29%\n",
      "Epoch [2312/2500], Train Loss: 0.8067, Train Accuracy: 63.87%, Test Loss: 0.8287, Test Accuracy: 63.29%\n",
      "Epoch [2313/2500], Train Loss: 0.8070, Train Accuracy: 65.15%, Test Loss: 0.8258, Test Accuracy: 62.03%\n",
      "Epoch [2314/2500], Train Loss: 0.8112, Train Accuracy: 65.01%, Test Loss: 0.8171, Test Accuracy: 62.03%\n",
      "Epoch [2315/2500], Train Loss: 0.8048, Train Accuracy: 64.72%, Test Loss: 0.8277, Test Accuracy: 62.03%\n",
      "Epoch [2316/2500], Train Loss: 0.8073, Train Accuracy: 63.30%, Test Loss: 0.8311, Test Accuracy: 63.29%\n",
      "Epoch [2317/2500], Train Loss: 0.8228, Train Accuracy: 62.87%, Test Loss: 0.8315, Test Accuracy: 65.82%\n",
      "Epoch [2318/2500], Train Loss: 0.8099, Train Accuracy: 64.01%, Test Loss: 0.8296, Test Accuracy: 65.82%\n",
      "Epoch [2319/2500], Train Loss: 0.8020, Train Accuracy: 65.01%, Test Loss: 0.8359, Test Accuracy: 65.82%\n",
      "Epoch [2320/2500], Train Loss: 0.8166, Train Accuracy: 64.58%, Test Loss: 0.8334, Test Accuracy: 65.82%\n",
      "Epoch [2321/2500], Train Loss: 0.8131, Train Accuracy: 63.16%, Test Loss: 0.8264, Test Accuracy: 65.82%\n",
      "Epoch [2322/2500], Train Loss: 0.8201, Train Accuracy: 66.29%, Test Loss: 0.8218, Test Accuracy: 65.82%\n",
      "Epoch [2323/2500], Train Loss: 0.8004, Train Accuracy: 63.58%, Test Loss: 0.8244, Test Accuracy: 67.09%\n",
      "Epoch [2324/2500], Train Loss: 0.7947, Train Accuracy: 65.15%, Test Loss: 0.8236, Test Accuracy: 65.82%\n",
      "Epoch [2325/2500], Train Loss: 0.8151, Train Accuracy: 62.16%, Test Loss: 0.8251, Test Accuracy: 65.82%\n",
      "Epoch [2326/2500], Train Loss: 0.8029, Train Accuracy: 65.01%, Test Loss: 0.8121, Test Accuracy: 65.82%\n",
      "Epoch [2327/2500], Train Loss: 0.7970, Train Accuracy: 66.00%, Test Loss: 0.8198, Test Accuracy: 65.82%\n",
      "Epoch [2328/2500], Train Loss: 0.8082, Train Accuracy: 63.44%, Test Loss: 0.8239, Test Accuracy: 65.82%\n",
      "Epoch [2329/2500], Train Loss: 0.8019, Train Accuracy: 64.30%, Test Loss: 0.8373, Test Accuracy: 65.82%\n",
      "Epoch [2330/2500], Train Loss: 0.8106, Train Accuracy: 64.15%, Test Loss: 0.8297, Test Accuracy: 65.82%\n",
      "Epoch [2331/2500], Train Loss: 0.8006, Train Accuracy: 65.29%, Test Loss: 0.8193, Test Accuracy: 65.82%\n",
      "Epoch [2332/2500], Train Loss: 0.8047, Train Accuracy: 63.87%, Test Loss: 0.8389, Test Accuracy: 65.82%\n",
      "Epoch [2333/2500], Train Loss: 0.8014, Train Accuracy: 65.29%, Test Loss: 0.8212, Test Accuracy: 64.56%\n",
      "Epoch [2334/2500], Train Loss: 0.8063, Train Accuracy: 64.86%, Test Loss: 0.8386, Test Accuracy: 65.82%\n",
      "Epoch [2335/2500], Train Loss: 0.8200, Train Accuracy: 63.16%, Test Loss: 0.8258, Test Accuracy: 65.82%\n",
      "Epoch [2336/2500], Train Loss: 0.8045, Train Accuracy: 66.00%, Test Loss: 0.8079, Test Accuracy: 64.56%\n",
      "Epoch [2337/2500], Train Loss: 0.7971, Train Accuracy: 64.30%, Test Loss: 0.8188, Test Accuracy: 62.03%\n",
      "Epoch [2338/2500], Train Loss: 0.8073, Train Accuracy: 63.30%, Test Loss: 0.8310, Test Accuracy: 64.56%\n",
      "Epoch [2339/2500], Train Loss: 0.7887, Train Accuracy: 65.29%, Test Loss: 0.8282, Test Accuracy: 63.29%\n",
      "Epoch [2340/2500], Train Loss: 0.8003, Train Accuracy: 65.15%, Test Loss: 0.8213, Test Accuracy: 63.29%\n",
      "Epoch [2341/2500], Train Loss: 0.7773, Train Accuracy: 66.15%, Test Loss: 0.8303, Test Accuracy: 64.56%\n",
      "Epoch [2342/2500], Train Loss: 0.8109, Train Accuracy: 64.30%, Test Loss: 0.8242, Test Accuracy: 65.82%\n",
      "Epoch [2343/2500], Train Loss: 0.7967, Train Accuracy: 64.44%, Test Loss: 0.8252, Test Accuracy: 65.82%\n",
      "Epoch [2344/2500], Train Loss: 0.7951, Train Accuracy: 65.43%, Test Loss: 0.8210, Test Accuracy: 64.56%\n",
      "Epoch [2345/2500], Train Loss: 0.8252, Train Accuracy: 63.16%, Test Loss: 0.8104, Test Accuracy: 64.56%\n",
      "Epoch [2346/2500], Train Loss: 0.8016, Train Accuracy: 64.01%, Test Loss: 0.8126, Test Accuracy: 64.56%\n",
      "Epoch [2347/2500], Train Loss: 0.8099, Train Accuracy: 64.01%, Test Loss: 0.8259, Test Accuracy: 65.82%\n",
      "Epoch [2348/2500], Train Loss: 0.8090, Train Accuracy: 63.58%, Test Loss: 0.8233, Test Accuracy: 65.82%\n",
      "Epoch [2349/2500], Train Loss: 0.8004, Train Accuracy: 64.86%, Test Loss: 0.8141, Test Accuracy: 65.82%\n",
      "Epoch [2350/2500], Train Loss: 0.8050, Train Accuracy: 66.00%, Test Loss: 0.7988, Test Accuracy: 65.82%\n",
      "Epoch [2351/2500], Train Loss: 0.7877, Train Accuracy: 65.15%, Test Loss: 0.8296, Test Accuracy: 65.82%\n",
      "Epoch [2352/2500], Train Loss: 0.8129, Train Accuracy: 64.15%, Test Loss: 0.8262, Test Accuracy: 65.82%\n",
      "Epoch [2353/2500], Train Loss: 0.7967, Train Accuracy: 65.72%, Test Loss: 0.8232, Test Accuracy: 64.56%\n",
      "Epoch [2354/2500], Train Loss: 0.8019, Train Accuracy: 65.72%, Test Loss: 0.8179, Test Accuracy: 65.82%\n",
      "Epoch [2355/2500], Train Loss: 0.8197, Train Accuracy: 61.74%, Test Loss: 0.8257, Test Accuracy: 65.82%\n",
      "Epoch [2356/2500], Train Loss: 0.8007, Train Accuracy: 65.72%, Test Loss: 0.8340, Test Accuracy: 64.56%\n",
      "Epoch [2357/2500], Train Loss: 0.7849, Train Accuracy: 65.58%, Test Loss: 0.8271, Test Accuracy: 65.82%\n",
      "Epoch [2358/2500], Train Loss: 0.8154, Train Accuracy: 63.16%, Test Loss: 0.8337, Test Accuracy: 63.29%\n",
      "Epoch [2359/2500], Train Loss: 0.7978, Train Accuracy: 64.15%, Test Loss: 0.8390, Test Accuracy: 65.82%\n",
      "Epoch [2360/2500], Train Loss: 0.7932, Train Accuracy: 64.15%, Test Loss: 0.8519, Test Accuracy: 65.82%\n",
      "Epoch [2361/2500], Train Loss: 0.8051, Train Accuracy: 65.01%, Test Loss: 0.8472, Test Accuracy: 65.82%\n",
      "Epoch [2362/2500], Train Loss: 0.7990, Train Accuracy: 64.58%, Test Loss: 0.8415, Test Accuracy: 67.09%\n",
      "Epoch [2363/2500], Train Loss: 0.8089, Train Accuracy: 64.01%, Test Loss: 0.8357, Test Accuracy: 65.82%\n",
      "Epoch [2364/2500], Train Loss: 0.8027, Train Accuracy: 64.72%, Test Loss: 0.8270, Test Accuracy: 65.82%\n",
      "Epoch [2365/2500], Train Loss: 0.7894, Train Accuracy: 64.72%, Test Loss: 0.8353, Test Accuracy: 67.09%\n",
      "Epoch [2366/2500], Train Loss: 0.7992, Train Accuracy: 64.15%, Test Loss: 0.8489, Test Accuracy: 67.09%\n",
      "Epoch [2367/2500], Train Loss: 0.8007, Train Accuracy: 65.58%, Test Loss: 0.8235, Test Accuracy: 64.56%\n",
      "Epoch [2368/2500], Train Loss: 0.7985, Train Accuracy: 66.15%, Test Loss: 0.8377, Test Accuracy: 65.82%\n",
      "Epoch [2369/2500], Train Loss: 0.8002, Train Accuracy: 63.73%, Test Loss: 0.8270, Test Accuracy: 64.56%\n",
      "Epoch [2370/2500], Train Loss: 0.7907, Train Accuracy: 65.29%, Test Loss: 0.8352, Test Accuracy: 65.82%\n",
      "Epoch [2371/2500], Train Loss: 0.7855, Train Accuracy: 66.00%, Test Loss: 0.8393, Test Accuracy: 64.56%\n",
      "Epoch [2372/2500], Train Loss: 0.8037, Train Accuracy: 63.87%, Test Loss: 0.8340, Test Accuracy: 64.56%\n",
      "Epoch [2373/2500], Train Loss: 0.8177, Train Accuracy: 63.44%, Test Loss: 0.8352, Test Accuracy: 64.56%\n",
      "Epoch [2374/2500], Train Loss: 0.7858, Train Accuracy: 65.29%, Test Loss: 0.8468, Test Accuracy: 64.56%\n",
      "Epoch [2375/2500], Train Loss: 0.8093, Train Accuracy: 63.44%, Test Loss: 0.8441, Test Accuracy: 64.56%\n",
      "Epoch [2376/2500], Train Loss: 0.7893, Train Accuracy: 65.01%, Test Loss: 0.8334, Test Accuracy: 64.56%\n",
      "Epoch [2377/2500], Train Loss: 0.7766, Train Accuracy: 65.43%, Test Loss: 0.8454, Test Accuracy: 64.56%\n",
      "Epoch [2378/2500], Train Loss: 0.7880, Train Accuracy: 64.58%, Test Loss: 0.8462, Test Accuracy: 64.56%\n",
      "Epoch [2379/2500], Train Loss: 0.7857, Train Accuracy: 66.15%, Test Loss: 0.8436, Test Accuracy: 64.56%\n",
      "Epoch [2380/2500], Train Loss: 0.7995, Train Accuracy: 65.29%, Test Loss: 0.8428, Test Accuracy: 64.56%\n",
      "Epoch [2381/2500], Train Loss: 0.7987, Train Accuracy: 65.72%, Test Loss: 0.8311, Test Accuracy: 63.29%\n",
      "Epoch [2382/2500], Train Loss: 0.8196, Train Accuracy: 63.44%, Test Loss: 0.8415, Test Accuracy: 63.29%\n",
      "Epoch [2383/2500], Train Loss: 0.7995, Train Accuracy: 64.44%, Test Loss: 0.8309, Test Accuracy: 63.29%\n",
      "Epoch [2384/2500], Train Loss: 0.8236, Train Accuracy: 63.44%, Test Loss: 0.8363, Test Accuracy: 64.56%\n",
      "Epoch [2385/2500], Train Loss: 0.8012, Train Accuracy: 63.87%, Test Loss: 0.8232, Test Accuracy: 64.56%\n",
      "Epoch [2386/2500], Train Loss: 0.7983, Train Accuracy: 64.30%, Test Loss: 0.8240, Test Accuracy: 63.29%\n",
      "Epoch [2387/2500], Train Loss: 0.7983, Train Accuracy: 65.58%, Test Loss: 0.8290, Test Accuracy: 63.29%\n",
      "Epoch [2388/2500], Train Loss: 0.7903, Train Accuracy: 64.58%, Test Loss: 0.8297, Test Accuracy: 63.29%\n",
      "Epoch [2389/2500], Train Loss: 0.8147, Train Accuracy: 64.30%, Test Loss: 0.8234, Test Accuracy: 64.56%\n",
      "Epoch [2390/2500], Train Loss: 0.8095, Train Accuracy: 64.01%, Test Loss: 0.8367, Test Accuracy: 64.56%\n",
      "Epoch [2391/2500], Train Loss: 0.8136, Train Accuracy: 64.44%, Test Loss: 0.8358, Test Accuracy: 64.56%\n",
      "Epoch [2392/2500], Train Loss: 0.7947, Train Accuracy: 65.43%, Test Loss: 0.8254, Test Accuracy: 64.56%\n",
      "Epoch [2393/2500], Train Loss: 0.8224, Train Accuracy: 62.16%, Test Loss: 0.8222, Test Accuracy: 63.29%\n",
      "Epoch [2394/2500], Train Loss: 0.7894, Train Accuracy: 64.58%, Test Loss: 0.8168, Test Accuracy: 64.56%\n",
      "Epoch [2395/2500], Train Loss: 0.8220, Train Accuracy: 64.01%, Test Loss: 0.8262, Test Accuracy: 63.29%\n",
      "Epoch [2396/2500], Train Loss: 0.7826, Train Accuracy: 64.30%, Test Loss: 0.8295, Test Accuracy: 64.56%\n",
      "Epoch [2397/2500], Train Loss: 0.8164, Train Accuracy: 63.87%, Test Loss: 0.8292, Test Accuracy: 63.29%\n",
      "Epoch [2398/2500], Train Loss: 0.7813, Train Accuracy: 65.43%, Test Loss: 0.8239, Test Accuracy: 62.03%\n",
      "Epoch [2399/2500], Train Loss: 0.8003, Train Accuracy: 63.73%, Test Loss: 0.8118, Test Accuracy: 64.56%\n",
      "Epoch [2400/2500], Train Loss: 0.8082, Train Accuracy: 62.73%, Test Loss: 0.8297, Test Accuracy: 64.56%\n",
      "Epoch [2401/2500], Train Loss: 0.7904, Train Accuracy: 64.72%, Test Loss: 0.8246, Test Accuracy: 64.56%\n",
      "Epoch [2402/2500], Train Loss: 0.8070, Train Accuracy: 63.73%, Test Loss: 0.8276, Test Accuracy: 63.29%\n",
      "Epoch [2403/2500], Train Loss: 0.7848, Train Accuracy: 65.58%, Test Loss: 0.8211, Test Accuracy: 62.03%\n",
      "Epoch [2404/2500], Train Loss: 0.7795, Train Accuracy: 65.72%, Test Loss: 0.8160, Test Accuracy: 63.29%\n",
      "Epoch [2405/2500], Train Loss: 0.8026, Train Accuracy: 64.44%, Test Loss: 0.8255, Test Accuracy: 63.29%\n",
      "Epoch [2406/2500], Train Loss: 0.8004, Train Accuracy: 65.01%, Test Loss: 0.8071, Test Accuracy: 62.03%\n",
      "Epoch [2407/2500], Train Loss: 0.7955, Train Accuracy: 64.01%, Test Loss: 0.8265, Test Accuracy: 63.29%\n",
      "Epoch [2408/2500], Train Loss: 0.8069, Train Accuracy: 64.30%, Test Loss: 0.8338, Test Accuracy: 64.56%\n",
      "Epoch [2409/2500], Train Loss: 0.8028, Train Accuracy: 64.58%, Test Loss: 0.8239, Test Accuracy: 63.29%\n",
      "Epoch [2410/2500], Train Loss: 0.8021, Train Accuracy: 63.16%, Test Loss: 0.8352, Test Accuracy: 63.29%\n",
      "Epoch [2411/2500], Train Loss: 0.7934, Train Accuracy: 64.30%, Test Loss: 0.8408, Test Accuracy: 63.29%\n",
      "Epoch [2412/2500], Train Loss: 0.7955, Train Accuracy: 64.15%, Test Loss: 0.8454, Test Accuracy: 63.29%\n",
      "Epoch [2413/2500], Train Loss: 0.8097, Train Accuracy: 63.02%, Test Loss: 0.8300, Test Accuracy: 62.03%\n",
      "Epoch [2414/2500], Train Loss: 0.7855, Train Accuracy: 64.58%, Test Loss: 0.8370, Test Accuracy: 62.03%\n",
      "Epoch [2415/2500], Train Loss: 0.8109, Train Accuracy: 66.43%, Test Loss: 0.8297, Test Accuracy: 63.29%\n",
      "Epoch [2416/2500], Train Loss: 0.7905, Train Accuracy: 63.73%, Test Loss: 0.8367, Test Accuracy: 64.56%\n",
      "Epoch [2417/2500], Train Loss: 0.7895, Train Accuracy: 65.01%, Test Loss: 0.8373, Test Accuracy: 64.56%\n",
      "Epoch [2418/2500], Train Loss: 0.7942, Train Accuracy: 64.86%, Test Loss: 0.8398, Test Accuracy: 62.03%\n",
      "Epoch [2419/2500], Train Loss: 0.8084, Train Accuracy: 64.15%, Test Loss: 0.8433, Test Accuracy: 63.29%\n",
      "Epoch [2420/2500], Train Loss: 0.8249, Train Accuracy: 63.87%, Test Loss: 0.8500, Test Accuracy: 62.03%\n",
      "Epoch [2421/2500], Train Loss: 0.7890, Train Accuracy: 64.30%, Test Loss: 0.8339, Test Accuracy: 63.29%\n",
      "Epoch [2422/2500], Train Loss: 0.8141, Train Accuracy: 62.87%, Test Loss: 0.8424, Test Accuracy: 64.56%\n",
      "Epoch [2423/2500], Train Loss: 0.8019, Train Accuracy: 65.15%, Test Loss: 0.8317, Test Accuracy: 64.56%\n",
      "Epoch [2424/2500], Train Loss: 0.7876, Train Accuracy: 65.86%, Test Loss: 0.8380, Test Accuracy: 64.56%\n",
      "Epoch [2425/2500], Train Loss: 0.7998, Train Accuracy: 64.30%, Test Loss: 0.8364, Test Accuracy: 64.56%\n",
      "Epoch [2426/2500], Train Loss: 0.7921, Train Accuracy: 65.01%, Test Loss: 0.8196, Test Accuracy: 64.56%\n",
      "Epoch [2427/2500], Train Loss: 0.8092, Train Accuracy: 63.87%, Test Loss: 0.8414, Test Accuracy: 65.82%\n",
      "Epoch [2428/2500], Train Loss: 0.7801, Train Accuracy: 65.01%, Test Loss: 0.8412, Test Accuracy: 64.56%\n",
      "Epoch [2429/2500], Train Loss: 0.7949, Train Accuracy: 64.72%, Test Loss: 0.8445, Test Accuracy: 64.56%\n",
      "Epoch [2430/2500], Train Loss: 0.7830, Train Accuracy: 64.58%, Test Loss: 0.8386, Test Accuracy: 64.56%\n",
      "Epoch [2431/2500], Train Loss: 0.7884, Train Accuracy: 66.29%, Test Loss: 0.8345, Test Accuracy: 64.56%\n",
      "Epoch [2432/2500], Train Loss: 0.7980, Train Accuracy: 63.58%, Test Loss: 0.8394, Test Accuracy: 64.56%\n",
      "Epoch [2433/2500], Train Loss: 0.7803, Train Accuracy: 66.29%, Test Loss: 0.8432, Test Accuracy: 63.29%\n",
      "Epoch [2434/2500], Train Loss: 0.8014, Train Accuracy: 64.58%, Test Loss: 0.8323, Test Accuracy: 64.56%\n",
      "Epoch [2435/2500], Train Loss: 0.7938, Train Accuracy: 65.15%, Test Loss: 0.8233, Test Accuracy: 64.56%\n",
      "Epoch [2436/2500], Train Loss: 0.7880, Train Accuracy: 65.43%, Test Loss: 0.8329, Test Accuracy: 65.82%\n",
      "Epoch [2437/2500], Train Loss: 0.8043, Train Accuracy: 63.44%, Test Loss: 0.8384, Test Accuracy: 62.03%\n",
      "Epoch [2438/2500], Train Loss: 0.8152, Train Accuracy: 64.15%, Test Loss: 0.8404, Test Accuracy: 63.29%\n",
      "Epoch [2439/2500], Train Loss: 0.7888, Train Accuracy: 64.86%, Test Loss: 0.8253, Test Accuracy: 64.56%\n",
      "Epoch [2440/2500], Train Loss: 0.8118, Train Accuracy: 64.01%, Test Loss: 0.8257, Test Accuracy: 64.56%\n",
      "Epoch [2441/2500], Train Loss: 0.8003, Train Accuracy: 63.73%, Test Loss: 0.8396, Test Accuracy: 64.56%\n",
      "Epoch [2442/2500], Train Loss: 0.8201, Train Accuracy: 63.30%, Test Loss: 0.8473, Test Accuracy: 64.56%\n",
      "Epoch [2443/2500], Train Loss: 0.8077, Train Accuracy: 64.44%, Test Loss: 0.8466, Test Accuracy: 63.29%\n",
      "Epoch [2444/2500], Train Loss: 0.7964, Train Accuracy: 64.58%, Test Loss: 0.8376, Test Accuracy: 64.56%\n",
      "Epoch [2445/2500], Train Loss: 0.7904, Train Accuracy: 64.01%, Test Loss: 0.8313, Test Accuracy: 63.29%\n",
      "Epoch [2446/2500], Train Loss: 0.8072, Train Accuracy: 64.30%, Test Loss: 0.8368, Test Accuracy: 63.29%\n",
      "Epoch [2447/2500], Train Loss: 0.7874, Train Accuracy: 66.71%, Test Loss: 0.8297, Test Accuracy: 64.56%\n",
      "Epoch [2448/2500], Train Loss: 0.8063, Train Accuracy: 66.00%, Test Loss: 0.8269, Test Accuracy: 64.56%\n",
      "Epoch [2449/2500], Train Loss: 0.7852, Train Accuracy: 64.58%, Test Loss: 0.8267, Test Accuracy: 64.56%\n",
      "Epoch [2450/2500], Train Loss: 0.8051, Train Accuracy: 62.73%, Test Loss: 0.8281, Test Accuracy: 65.82%\n",
      "Epoch [2451/2500], Train Loss: 0.7966, Train Accuracy: 63.87%, Test Loss: 0.8351, Test Accuracy: 62.03%\n",
      "Epoch [2452/2500], Train Loss: 0.7996, Train Accuracy: 63.87%, Test Loss: 0.8276, Test Accuracy: 63.29%\n",
      "Epoch [2453/2500], Train Loss: 0.8099, Train Accuracy: 64.01%, Test Loss: 0.8176, Test Accuracy: 63.29%\n",
      "Epoch [2454/2500], Train Loss: 0.8032, Train Accuracy: 63.02%, Test Loss: 0.8227, Test Accuracy: 63.29%\n",
      "Epoch [2455/2500], Train Loss: 0.7822, Train Accuracy: 64.44%, Test Loss: 0.8278, Test Accuracy: 64.56%\n",
      "Epoch [2456/2500], Train Loss: 0.7752, Train Accuracy: 64.72%, Test Loss: 0.8418, Test Accuracy: 65.82%\n",
      "Epoch [2457/2500], Train Loss: 0.7963, Train Accuracy: 63.58%, Test Loss: 0.8328, Test Accuracy: 63.29%\n",
      "Epoch [2458/2500], Train Loss: 0.8098, Train Accuracy: 63.30%, Test Loss: 0.8444, Test Accuracy: 65.82%\n",
      "Epoch [2459/2500], Train Loss: 0.7950, Train Accuracy: 64.86%, Test Loss: 0.8293, Test Accuracy: 64.56%\n",
      "Epoch [2460/2500], Train Loss: 0.7870, Train Accuracy: 65.29%, Test Loss: 0.8328, Test Accuracy: 64.56%\n",
      "Epoch [2461/2500], Train Loss: 0.8051, Train Accuracy: 63.73%, Test Loss: 0.8375, Test Accuracy: 63.29%\n",
      "Epoch [2462/2500], Train Loss: 0.7902, Train Accuracy: 65.15%, Test Loss: 0.8353, Test Accuracy: 64.56%\n",
      "Epoch [2463/2500], Train Loss: 0.8216, Train Accuracy: 62.45%, Test Loss: 0.8177, Test Accuracy: 64.56%\n",
      "Epoch [2464/2500], Train Loss: 0.7851, Train Accuracy: 64.72%, Test Loss: 0.8327, Test Accuracy: 64.56%\n",
      "Epoch [2465/2500], Train Loss: 0.7899, Train Accuracy: 64.58%, Test Loss: 0.8380, Test Accuracy: 64.56%\n",
      "Epoch [2466/2500], Train Loss: 0.8115, Train Accuracy: 63.73%, Test Loss: 0.8309, Test Accuracy: 65.82%\n",
      "Epoch [2467/2500], Train Loss: 0.7928, Train Accuracy: 65.58%, Test Loss: 0.8264, Test Accuracy: 65.82%\n",
      "Epoch [2468/2500], Train Loss: 0.7809, Train Accuracy: 64.72%, Test Loss: 0.8321, Test Accuracy: 64.56%\n",
      "Epoch [2469/2500], Train Loss: 0.7807, Train Accuracy: 65.29%, Test Loss: 0.8443, Test Accuracy: 65.82%\n",
      "Epoch [2470/2500], Train Loss: 0.7939, Train Accuracy: 64.44%, Test Loss: 0.8314, Test Accuracy: 64.56%\n",
      "Epoch [2471/2500], Train Loss: 0.7943, Train Accuracy: 65.86%, Test Loss: 0.8257, Test Accuracy: 63.29%\n",
      "Epoch [2472/2500], Train Loss: 0.8126, Train Accuracy: 64.72%, Test Loss: 0.8345, Test Accuracy: 64.56%\n",
      "Epoch [2473/2500], Train Loss: 0.8059, Train Accuracy: 62.73%, Test Loss: 0.8443, Test Accuracy: 64.56%\n",
      "Epoch [2474/2500], Train Loss: 0.7923, Train Accuracy: 65.86%, Test Loss: 0.8356, Test Accuracy: 65.82%\n",
      "Epoch [2475/2500], Train Loss: 0.8159, Train Accuracy: 64.72%, Test Loss: 0.8242, Test Accuracy: 64.56%\n",
      "Epoch [2476/2500], Train Loss: 0.7750, Train Accuracy: 65.58%, Test Loss: 0.8359, Test Accuracy: 64.56%\n",
      "Epoch [2477/2500], Train Loss: 0.8001, Train Accuracy: 65.29%, Test Loss: 0.8461, Test Accuracy: 64.56%\n",
      "Epoch [2478/2500], Train Loss: 0.7879, Train Accuracy: 64.86%, Test Loss: 0.8379, Test Accuracy: 63.29%\n",
      "Epoch [2479/2500], Train Loss: 0.7815, Train Accuracy: 64.86%, Test Loss: 0.8124, Test Accuracy: 62.03%\n",
      "Epoch [2480/2500], Train Loss: 0.8038, Train Accuracy: 64.30%, Test Loss: 0.8205, Test Accuracy: 63.29%\n",
      "Epoch [2481/2500], Train Loss: 0.7881, Train Accuracy: 64.86%, Test Loss: 0.8169, Test Accuracy: 63.29%\n",
      "Epoch [2482/2500], Train Loss: 0.7937, Train Accuracy: 65.72%, Test Loss: 0.8220, Test Accuracy: 63.29%\n",
      "Epoch [2483/2500], Train Loss: 0.7940, Train Accuracy: 64.58%, Test Loss: 0.8188, Test Accuracy: 64.56%\n",
      "Epoch [2484/2500], Train Loss: 0.7879, Train Accuracy: 65.72%, Test Loss: 0.8289, Test Accuracy: 64.56%\n",
      "Epoch [2485/2500], Train Loss: 0.7991, Train Accuracy: 65.43%, Test Loss: 0.8298, Test Accuracy: 64.56%\n",
      "Epoch [2486/2500], Train Loss: 0.7924, Train Accuracy: 64.15%, Test Loss: 0.8158, Test Accuracy: 63.29%\n",
      "Epoch [2487/2500], Train Loss: 0.7900, Train Accuracy: 64.86%, Test Loss: 0.8189, Test Accuracy: 63.29%\n",
      "Epoch [2488/2500], Train Loss: 0.7863, Train Accuracy: 66.00%, Test Loss: 0.8325, Test Accuracy: 62.03%\n",
      "Epoch [2489/2500], Train Loss: 0.8024, Train Accuracy: 64.30%, Test Loss: 0.8251, Test Accuracy: 62.03%\n",
      "Epoch [2490/2500], Train Loss: 0.7813, Train Accuracy: 64.01%, Test Loss: 0.8335, Test Accuracy: 62.03%\n",
      "Epoch [2491/2500], Train Loss: 0.8072, Train Accuracy: 64.44%, Test Loss: 0.8289, Test Accuracy: 63.29%\n",
      "Epoch [2492/2500], Train Loss: 0.8083, Train Accuracy: 64.15%, Test Loss: 0.8157, Test Accuracy: 62.03%\n",
      "Epoch [2493/2500], Train Loss: 0.7877, Train Accuracy: 63.30%, Test Loss: 0.8094, Test Accuracy: 62.03%\n",
      "Epoch [2494/2500], Train Loss: 0.7868, Train Accuracy: 65.58%, Test Loss: 0.8215, Test Accuracy: 62.03%\n",
      "Epoch [2495/2500], Train Loss: 0.7883, Train Accuracy: 66.43%, Test Loss: 0.8261, Test Accuracy: 63.29%\n",
      "Epoch [2496/2500], Train Loss: 0.7788, Train Accuracy: 66.43%, Test Loss: 0.8254, Test Accuracy: 63.29%\n",
      "Epoch [2497/2500], Train Loss: 0.7917, Train Accuracy: 63.16%, Test Loss: 0.8303, Test Accuracy: 63.29%\n",
      "Epoch [2498/2500], Train Loss: 0.7941, Train Accuracy: 64.72%, Test Loss: 0.8279, Test Accuracy: 63.29%\n",
      "Epoch [2499/2500], Train Loss: 0.7895, Train Accuracy: 64.58%, Test Loss: 0.8193, Test Accuracy: 64.56%\n",
      "Epoch [2500/2500], Train Loss: 0.7961, Train Accuracy: 65.29%, Test Loss: 0.8316, Test Accuracy: 64.56%\n",
      "model_cnn2d_lstm saved as model_cnn2d_lstm_4class_best.pth\n",
      "\n",
      "Metrics for model_cnn2d_lstm saved as model_cnn2d_lstm_metrics_4class.csv\n",
      "\n",
      "Training model_cnn2d_att\n",
      "Epoch [1/2500], Train Loss: 1.4929, Train Accuracy: 35.70%, Test Loss: 1.1832, Test Accuracy: 64.56%\n",
      "Epoch [2/2500], Train Loss: 1.3037, Train Accuracy: 45.09%, Test Loss: 1.0147, Test Accuracy: 55.70%\n",
      "Epoch [3/2500], Train Loss: 1.2206, Train Accuracy: 49.36%, Test Loss: 1.0138, Test Accuracy: 60.76%\n",
      "Epoch [4/2500], Train Loss: 1.2072, Train Accuracy: 51.07%, Test Loss: 1.2344, Test Accuracy: 51.90%\n",
      "Epoch [5/2500], Train Loss: 1.2100, Train Accuracy: 50.07%, Test Loss: 1.1627, Test Accuracy: 41.77%\n",
      "Epoch [6/2500], Train Loss: 1.1599, Train Accuracy: 53.63%, Test Loss: 1.1618, Test Accuracy: 46.84%\n",
      "Epoch [7/2500], Train Loss: 1.1155, Train Accuracy: 53.91%, Test Loss: 0.9719, Test Accuracy: 59.49%\n",
      "Epoch [8/2500], Train Loss: 1.1395, Train Accuracy: 54.20%, Test Loss: 0.9546, Test Accuracy: 58.23%\n",
      "Epoch [9/2500], Train Loss: 1.1468, Train Accuracy: 52.35%, Test Loss: 1.0355, Test Accuracy: 60.76%\n",
      "Epoch [10/2500], Train Loss: 1.1030, Train Accuracy: 55.76%, Test Loss: 0.9952, Test Accuracy: 62.03%\n",
      "Epoch [11/2500], Train Loss: 1.1204, Train Accuracy: 54.77%, Test Loss: 1.5024, Test Accuracy: 50.63%\n",
      "Epoch [12/2500], Train Loss: 1.1452, Train Accuracy: 51.92%, Test Loss: 0.9191, Test Accuracy: 62.03%\n",
      "Epoch [13/2500], Train Loss: 1.0928, Train Accuracy: 55.48%, Test Loss: 0.9490, Test Accuracy: 60.76%\n",
      "Epoch [14/2500], Train Loss: 1.1424, Train Accuracy: 51.64%, Test Loss: 0.9811, Test Accuracy: 62.03%\n",
      "Epoch [15/2500], Train Loss: 1.0912, Train Accuracy: 53.91%, Test Loss: 1.1371, Test Accuracy: 60.76%\n",
      "Epoch [16/2500], Train Loss: 1.0583, Train Accuracy: 57.18%, Test Loss: 1.1249, Test Accuracy: 56.96%\n",
      "Epoch [17/2500], Train Loss: 1.0947, Train Accuracy: 54.48%, Test Loss: 0.9009, Test Accuracy: 60.76%\n",
      "Epoch [18/2500], Train Loss: 1.1086, Train Accuracy: 54.77%, Test Loss: 1.0772, Test Accuracy: 45.57%\n",
      "Epoch [19/2500], Train Loss: 1.0455, Train Accuracy: 55.19%, Test Loss: 1.1754, Test Accuracy: 54.43%\n",
      "Epoch [20/2500], Train Loss: 1.0765, Train Accuracy: 55.33%, Test Loss: 0.9005, Test Accuracy: 63.29%\n",
      "Epoch [21/2500], Train Loss: 1.0590, Train Accuracy: 55.19%, Test Loss: 0.9345, Test Accuracy: 53.16%\n",
      "Epoch [22/2500], Train Loss: 1.0548, Train Accuracy: 55.62%, Test Loss: 1.0202, Test Accuracy: 60.76%\n",
      "Epoch [23/2500], Train Loss: 1.0280, Train Accuracy: 58.75%, Test Loss: 1.0632, Test Accuracy: 62.03%\n",
      "Epoch [24/2500], Train Loss: 1.1067, Train Accuracy: 55.19%, Test Loss: 0.9077, Test Accuracy: 65.82%\n",
      "Epoch [25/2500], Train Loss: 1.0559, Train Accuracy: 55.48%, Test Loss: 1.0246, Test Accuracy: 62.03%\n",
      "Epoch [26/2500], Train Loss: 1.0842, Train Accuracy: 54.20%, Test Loss: 0.9151, Test Accuracy: 59.49%\n",
      "Epoch [27/2500], Train Loss: 1.0394, Train Accuracy: 58.32%, Test Loss: 1.0200, Test Accuracy: 56.96%\n",
      "Epoch [28/2500], Train Loss: 1.0080, Train Accuracy: 59.32%, Test Loss: 1.0344, Test Accuracy: 64.56%\n",
      "Epoch [29/2500], Train Loss: 1.0762, Train Accuracy: 53.77%, Test Loss: 0.9588, Test Accuracy: 64.56%\n",
      "Epoch [30/2500], Train Loss: 1.0298, Train Accuracy: 59.60%, Test Loss: 0.9697, Test Accuracy: 60.76%\n",
      "Epoch [31/2500], Train Loss: 1.0513, Train Accuracy: 57.18%, Test Loss: 0.9402, Test Accuracy: 60.76%\n",
      "Epoch [32/2500], Train Loss: 1.0019, Train Accuracy: 57.47%, Test Loss: 1.0073, Test Accuracy: 59.49%\n",
      "Epoch [33/2500], Train Loss: 1.0132, Train Accuracy: 60.31%, Test Loss: 0.9054, Test Accuracy: 63.29%\n",
      "Epoch [34/2500], Train Loss: 1.0633, Train Accuracy: 55.48%, Test Loss: 1.0449, Test Accuracy: 59.49%\n",
      "Epoch [35/2500], Train Loss: 1.0306, Train Accuracy: 57.33%, Test Loss: 0.9763, Test Accuracy: 60.76%\n",
      "Epoch [36/2500], Train Loss: 1.0434, Train Accuracy: 57.75%, Test Loss: 0.9697, Test Accuracy: 59.49%\n",
      "Epoch [37/2500], Train Loss: 1.0364, Train Accuracy: 56.61%, Test Loss: 1.1063, Test Accuracy: 60.76%\n",
      "Epoch [38/2500], Train Loss: 1.0197, Train Accuracy: 57.75%, Test Loss: 0.9837, Test Accuracy: 62.03%\n",
      "Epoch [39/2500], Train Loss: 1.0106, Train Accuracy: 58.61%, Test Loss: 1.2782, Test Accuracy: 49.37%\n",
      "Epoch [40/2500], Train Loss: 1.0127, Train Accuracy: 56.19%, Test Loss: 0.9688, Test Accuracy: 60.76%\n",
      "Epoch [41/2500], Train Loss: 1.0189, Train Accuracy: 58.18%, Test Loss: 0.8729, Test Accuracy: 59.49%\n",
      "Epoch [42/2500], Train Loss: 1.0382, Train Accuracy: 58.75%, Test Loss: 0.8893, Test Accuracy: 59.49%\n",
      "Epoch [43/2500], Train Loss: 1.0022, Train Accuracy: 59.46%, Test Loss: 0.9574, Test Accuracy: 60.76%\n",
      "Epoch [44/2500], Train Loss: 1.0354, Train Accuracy: 55.48%, Test Loss: 0.8937, Test Accuracy: 64.56%\n",
      "Epoch [45/2500], Train Loss: 1.0043, Train Accuracy: 58.61%, Test Loss: 1.0217, Test Accuracy: 67.09%\n",
      "Epoch [46/2500], Train Loss: 1.0158, Train Accuracy: 56.76%, Test Loss: 0.8892, Test Accuracy: 62.03%\n",
      "Epoch [47/2500], Train Loss: 1.0088, Train Accuracy: 57.75%, Test Loss: 0.8775, Test Accuracy: 65.82%\n",
      "Epoch [48/2500], Train Loss: 1.0147, Train Accuracy: 58.18%, Test Loss: 0.9874, Test Accuracy: 62.03%\n",
      "Epoch [49/2500], Train Loss: 1.0273, Train Accuracy: 58.61%, Test Loss: 1.0148, Test Accuracy: 65.82%\n",
      "Epoch [50/2500], Train Loss: 0.9863, Train Accuracy: 57.33%, Test Loss: 1.1489, Test Accuracy: 50.63%\n",
      "Epoch [51/2500], Train Loss: 1.0044, Train Accuracy: 58.46%, Test Loss: 1.0099, Test Accuracy: 59.49%\n",
      "Epoch [52/2500], Train Loss: 0.9881, Train Accuracy: 58.04%, Test Loss: 0.9605, Test Accuracy: 62.03%\n",
      "Epoch [53/2500], Train Loss: 1.0030, Train Accuracy: 57.04%, Test Loss: 1.0827, Test Accuracy: 59.49%\n",
      "Epoch [54/2500], Train Loss: 1.0505, Train Accuracy: 57.89%, Test Loss: 0.8672, Test Accuracy: 64.56%\n",
      "Epoch [55/2500], Train Loss: 1.0304, Train Accuracy: 55.48%, Test Loss: 0.8826, Test Accuracy: 62.03%\n",
      "Epoch [56/2500], Train Loss: 1.0220, Train Accuracy: 57.89%, Test Loss: 1.0723, Test Accuracy: 53.16%\n",
      "Epoch [57/2500], Train Loss: 0.9738, Train Accuracy: 58.18%, Test Loss: 0.8587, Test Accuracy: 63.29%\n",
      "Epoch [58/2500], Train Loss: 0.9938, Train Accuracy: 59.46%, Test Loss: 1.1382, Test Accuracy: 63.29%\n",
      "Epoch [59/2500], Train Loss: 0.9871, Train Accuracy: 58.04%, Test Loss: 0.9070, Test Accuracy: 64.56%\n",
      "Epoch [60/2500], Train Loss: 0.9791, Train Accuracy: 60.17%, Test Loss: 1.0692, Test Accuracy: 67.09%\n",
      "Epoch [61/2500], Train Loss: 0.9759, Train Accuracy: 60.60%, Test Loss: 0.8590, Test Accuracy: 62.03%\n",
      "Epoch [62/2500], Train Loss: 0.9872, Train Accuracy: 57.04%, Test Loss: 1.0671, Test Accuracy: 60.76%\n",
      "Epoch [63/2500], Train Loss: 0.9803, Train Accuracy: 57.89%, Test Loss: 0.9131, Test Accuracy: 63.29%\n",
      "Epoch [64/2500], Train Loss: 0.9823, Train Accuracy: 57.47%, Test Loss: 1.0151, Test Accuracy: 64.56%\n",
      "Epoch [65/2500], Train Loss: 1.0130, Train Accuracy: 57.89%, Test Loss: 1.0444, Test Accuracy: 60.76%\n",
      "Epoch [66/2500], Train Loss: 0.9752, Train Accuracy: 59.46%, Test Loss: 0.9838, Test Accuracy: 58.23%\n",
      "Epoch [67/2500], Train Loss: 1.0005, Train Accuracy: 58.61%, Test Loss: 0.9221, Test Accuracy: 62.03%\n",
      "Epoch [68/2500], Train Loss: 0.9693, Train Accuracy: 60.46%, Test Loss: 1.2105, Test Accuracy: 58.23%\n",
      "Epoch [69/2500], Train Loss: 0.9745, Train Accuracy: 59.60%, Test Loss: 0.9260, Test Accuracy: 62.03%\n",
      "Epoch [70/2500], Train Loss: 1.0099, Train Accuracy: 56.19%, Test Loss: 0.8615, Test Accuracy: 65.82%\n",
      "Epoch [71/2500], Train Loss: 0.9921, Train Accuracy: 57.18%, Test Loss: 0.9339, Test Accuracy: 62.03%\n",
      "Epoch [72/2500], Train Loss: 0.9955, Train Accuracy: 58.75%, Test Loss: 0.8965, Test Accuracy: 60.76%\n",
      "Epoch [73/2500], Train Loss: 0.9805, Train Accuracy: 58.46%, Test Loss: 0.9051, Test Accuracy: 63.29%\n",
      "Epoch [74/2500], Train Loss: 0.9863, Train Accuracy: 57.04%, Test Loss: 0.8696, Test Accuracy: 63.29%\n",
      "Epoch [75/2500], Train Loss: 0.9736, Train Accuracy: 57.75%, Test Loss: 0.9716, Test Accuracy: 63.29%\n",
      "Epoch [76/2500], Train Loss: 0.9694, Train Accuracy: 56.61%, Test Loss: 0.9486, Test Accuracy: 62.03%\n",
      "Epoch [77/2500], Train Loss: 1.0054, Train Accuracy: 58.18%, Test Loss: 0.8789, Test Accuracy: 62.03%\n",
      "Epoch [78/2500], Train Loss: 0.9751, Train Accuracy: 58.75%, Test Loss: 0.9800, Test Accuracy: 58.23%\n",
      "Epoch [79/2500], Train Loss: 0.9555, Train Accuracy: 60.03%, Test Loss: 0.8417, Test Accuracy: 59.49%\n",
      "Epoch [80/2500], Train Loss: 0.9852, Train Accuracy: 59.17%, Test Loss: 0.8783, Test Accuracy: 63.29%\n",
      "Epoch [81/2500], Train Loss: 0.9766, Train Accuracy: 58.04%, Test Loss: 0.9655, Test Accuracy: 64.56%\n",
      "Epoch [82/2500], Train Loss: 0.9600, Train Accuracy: 60.03%, Test Loss: 0.8829, Test Accuracy: 72.15%\n",
      "Epoch [83/2500], Train Loss: 0.9692, Train Accuracy: 57.89%, Test Loss: 1.1623, Test Accuracy: 60.76%\n",
      "Epoch [84/2500], Train Loss: 0.9717, Train Accuracy: 60.88%, Test Loss: 0.9342, Test Accuracy: 56.96%\n",
      "Epoch [85/2500], Train Loss: 0.9712, Train Accuracy: 58.32%, Test Loss: 0.9447, Test Accuracy: 62.03%\n",
      "Epoch [86/2500], Train Loss: 0.9965, Train Accuracy: 58.89%, Test Loss: 1.0828, Test Accuracy: 55.70%\n",
      "Epoch [87/2500], Train Loss: 0.9512, Train Accuracy: 58.75%, Test Loss: 0.8322, Test Accuracy: 65.82%\n",
      "Epoch [88/2500], Train Loss: 0.9190, Train Accuracy: 62.45%, Test Loss: 1.0267, Test Accuracy: 62.03%\n",
      "Epoch [89/2500], Train Loss: 0.9666, Train Accuracy: 60.60%, Test Loss: 0.9567, Test Accuracy: 65.82%\n",
      "Epoch [90/2500], Train Loss: 0.9641, Train Accuracy: 59.32%, Test Loss: 0.9357, Test Accuracy: 59.49%\n",
      "Epoch [91/2500], Train Loss: 0.9542, Train Accuracy: 61.17%, Test Loss: 0.9051, Test Accuracy: 62.03%\n",
      "Epoch [92/2500], Train Loss: 1.0016, Train Accuracy: 57.04%, Test Loss: 0.9646, Test Accuracy: 67.09%\n",
      "Epoch [93/2500], Train Loss: 0.9602, Train Accuracy: 58.46%, Test Loss: 1.0773, Test Accuracy: 63.29%\n",
      "Epoch [94/2500], Train Loss: 0.9593, Train Accuracy: 58.04%, Test Loss: 0.9350, Test Accuracy: 63.29%\n",
      "Epoch [95/2500], Train Loss: 0.9514, Train Accuracy: 59.89%, Test Loss: 0.9871, Test Accuracy: 62.03%\n",
      "Epoch [96/2500], Train Loss: 0.9678, Train Accuracy: 58.89%, Test Loss: 1.1225, Test Accuracy: 54.43%\n",
      "Epoch [97/2500], Train Loss: 0.9525, Train Accuracy: 58.18%, Test Loss: 0.8551, Test Accuracy: 65.82%\n",
      "Epoch [98/2500], Train Loss: 0.9387, Train Accuracy: 60.88%, Test Loss: 0.8968, Test Accuracy: 65.82%\n",
      "Epoch [99/2500], Train Loss: 0.9610, Train Accuracy: 58.75%, Test Loss: 0.8989, Test Accuracy: 70.89%\n",
      "Epoch [100/2500], Train Loss: 0.9304, Train Accuracy: 61.17%, Test Loss: 1.0074, Test Accuracy: 58.23%\n",
      "Epoch [101/2500], Train Loss: 0.9483, Train Accuracy: 57.75%, Test Loss: 0.8457, Test Accuracy: 68.35%\n",
      "Epoch [102/2500], Train Loss: 0.9621, Train Accuracy: 60.88%, Test Loss: 1.0216, Test Accuracy: 59.49%\n",
      "Epoch [103/2500], Train Loss: 0.9724, Train Accuracy: 56.90%, Test Loss: 0.9982, Test Accuracy: 60.76%\n",
      "Epoch [104/2500], Train Loss: 0.9711, Train Accuracy: 59.17%, Test Loss: 1.0053, Test Accuracy: 64.56%\n",
      "Epoch [105/2500], Train Loss: 0.9588, Train Accuracy: 60.46%, Test Loss: 0.8310, Test Accuracy: 62.03%\n",
      "Epoch [106/2500], Train Loss: 0.9491, Train Accuracy: 57.89%, Test Loss: 0.9953, Test Accuracy: 55.70%\n",
      "Epoch [107/2500], Train Loss: 0.9650, Train Accuracy: 58.61%, Test Loss: 0.8412, Test Accuracy: 67.09%\n",
      "Epoch [108/2500], Train Loss: 0.9623, Train Accuracy: 60.60%, Test Loss: 0.9390, Test Accuracy: 60.76%\n",
      "Epoch [109/2500], Train Loss: 0.9623, Train Accuracy: 59.89%, Test Loss: 0.8530, Test Accuracy: 64.56%\n",
      "Epoch [110/2500], Train Loss: 0.9562, Train Accuracy: 61.88%, Test Loss: 0.9034, Test Accuracy: 62.03%\n",
      "Epoch [111/2500], Train Loss: 0.9412, Train Accuracy: 59.46%, Test Loss: 0.9927, Test Accuracy: 56.96%\n",
      "Epoch [112/2500], Train Loss: 0.9334, Train Accuracy: 60.74%, Test Loss: 0.8337, Test Accuracy: 64.56%\n",
      "Epoch [113/2500], Train Loss: 0.9375, Train Accuracy: 60.46%, Test Loss: 1.1177, Test Accuracy: 51.90%\n",
      "Epoch [114/2500], Train Loss: 0.9478, Train Accuracy: 60.46%, Test Loss: 0.8883, Test Accuracy: 62.03%\n",
      "Epoch [115/2500], Train Loss: 0.9776, Train Accuracy: 62.02%, Test Loss: 1.0972, Test Accuracy: 55.70%\n",
      "Epoch [116/2500], Train Loss: 0.9473, Train Accuracy: 59.17%, Test Loss: 0.9978, Test Accuracy: 59.49%\n",
      "Epoch [117/2500], Train Loss: 0.9357, Train Accuracy: 61.45%, Test Loss: 0.9932, Test Accuracy: 59.49%\n",
      "Epoch [118/2500], Train Loss: 0.9539, Train Accuracy: 60.17%, Test Loss: 0.8609, Test Accuracy: 62.03%\n",
      "Epoch [119/2500], Train Loss: 0.9500, Train Accuracy: 58.61%, Test Loss: 0.8135, Test Accuracy: 63.29%\n",
      "Epoch [120/2500], Train Loss: 0.9491, Train Accuracy: 61.45%, Test Loss: 0.8902, Test Accuracy: 67.09%\n",
      "Epoch [121/2500], Train Loss: 0.9385, Train Accuracy: 60.17%, Test Loss: 0.8585, Test Accuracy: 65.82%\n",
      "Epoch [122/2500], Train Loss: 0.9160, Train Accuracy: 61.31%, Test Loss: 0.8214, Test Accuracy: 67.09%\n",
      "Epoch [123/2500], Train Loss: 0.9497, Train Accuracy: 60.88%, Test Loss: 0.9820, Test Accuracy: 59.49%\n",
      "Epoch [124/2500], Train Loss: 0.9781, Train Accuracy: 57.89%, Test Loss: 0.9124, Test Accuracy: 65.82%\n",
      "Epoch [125/2500], Train Loss: 0.9365, Train Accuracy: 59.46%, Test Loss: 0.8789, Test Accuracy: 63.29%\n",
      "Epoch [126/2500], Train Loss: 0.9364, Train Accuracy: 61.02%, Test Loss: 0.9691, Test Accuracy: 60.76%\n",
      "Epoch [127/2500], Train Loss: 0.9475, Train Accuracy: 57.75%, Test Loss: 0.9047, Test Accuracy: 60.76%\n",
      "Epoch [128/2500], Train Loss: 0.9553, Train Accuracy: 58.32%, Test Loss: 0.9302, Test Accuracy: 59.49%\n",
      "Epoch [129/2500], Train Loss: 0.9469, Train Accuracy: 58.18%, Test Loss: 0.9053, Test Accuracy: 69.62%\n",
      "Epoch [130/2500], Train Loss: 0.9395, Train Accuracy: 61.31%, Test Loss: 0.8372, Test Accuracy: 64.56%\n",
      "Epoch [131/2500], Train Loss: 0.9553, Train Accuracy: 59.32%, Test Loss: 0.8898, Test Accuracy: 64.56%\n",
      "Epoch [132/2500], Train Loss: 0.9365, Train Accuracy: 60.17%, Test Loss: 1.1588, Test Accuracy: 53.16%\n",
      "Epoch [133/2500], Train Loss: 0.9295, Train Accuracy: 60.46%, Test Loss: 0.9652, Test Accuracy: 54.43%\n",
      "Epoch [134/2500], Train Loss: 0.9223, Train Accuracy: 60.31%, Test Loss: 1.0413, Test Accuracy: 68.35%\n",
      "Epoch [135/2500], Train Loss: 0.9413, Train Accuracy: 59.74%, Test Loss: 0.8527, Test Accuracy: 63.29%\n",
      "Epoch [136/2500], Train Loss: 0.9170, Train Accuracy: 61.31%, Test Loss: 0.8473, Test Accuracy: 65.82%\n",
      "Epoch [137/2500], Train Loss: 0.9420, Train Accuracy: 61.17%, Test Loss: 0.8689, Test Accuracy: 70.89%\n",
      "Epoch [138/2500], Train Loss: 0.9356, Train Accuracy: 59.74%, Test Loss: 0.8390, Test Accuracy: 65.82%\n",
      "Epoch [139/2500], Train Loss: 0.9586, Train Accuracy: 61.02%, Test Loss: 0.9364, Test Accuracy: 68.35%\n",
      "Epoch [140/2500], Train Loss: 0.9199, Train Accuracy: 59.74%, Test Loss: 0.9876, Test Accuracy: 68.35%\n",
      "Epoch [141/2500], Train Loss: 0.9457, Train Accuracy: 61.17%, Test Loss: 0.8503, Test Accuracy: 65.82%\n",
      "Epoch [142/2500], Train Loss: 0.9278, Train Accuracy: 60.74%, Test Loss: 0.9160, Test Accuracy: 68.35%\n",
      "Epoch [143/2500], Train Loss: 0.9260, Train Accuracy: 61.59%, Test Loss: 0.8627, Test Accuracy: 62.03%\n",
      "Epoch [144/2500], Train Loss: 0.9448, Train Accuracy: 59.74%, Test Loss: 0.8648, Test Accuracy: 65.82%\n",
      "Epoch [145/2500], Train Loss: 0.9317, Train Accuracy: 61.45%, Test Loss: 0.8455, Test Accuracy: 65.82%\n",
      "Epoch [146/2500], Train Loss: 0.9045, Train Accuracy: 60.03%, Test Loss: 0.9017, Test Accuracy: 69.62%\n",
      "Epoch [147/2500], Train Loss: 0.9407, Train Accuracy: 58.89%, Test Loss: 0.8788, Test Accuracy: 64.56%\n",
      "Epoch [148/2500], Train Loss: 0.9442, Train Accuracy: 59.03%, Test Loss: 0.8840, Test Accuracy: 60.76%\n",
      "Epoch [149/2500], Train Loss: 0.9267, Train Accuracy: 59.74%, Test Loss: 0.9228, Test Accuracy: 59.49%\n",
      "Epoch [150/2500], Train Loss: 0.9354, Train Accuracy: 58.61%, Test Loss: 0.9198, Test Accuracy: 67.09%\n",
      "Epoch [151/2500], Train Loss: 0.9436, Train Accuracy: 60.46%, Test Loss: 0.8614, Test Accuracy: 64.56%\n",
      "Epoch [152/2500], Train Loss: 0.9329, Train Accuracy: 60.46%, Test Loss: 0.9464, Test Accuracy: 69.62%\n",
      "Epoch [153/2500], Train Loss: 0.9316, Train Accuracy: 61.17%, Test Loss: 0.8482, Test Accuracy: 67.09%\n",
      "Epoch [154/2500], Train Loss: 0.9205, Train Accuracy: 60.74%, Test Loss: 0.8618, Test Accuracy: 62.03%\n",
      "Epoch [155/2500], Train Loss: 0.8949, Train Accuracy: 63.58%, Test Loss: 0.9514, Test Accuracy: 69.62%\n",
      "Epoch [156/2500], Train Loss: 0.9099, Train Accuracy: 62.59%, Test Loss: 0.9492, Test Accuracy: 59.49%\n",
      "Epoch [157/2500], Train Loss: 0.9291, Train Accuracy: 61.45%, Test Loss: 0.8453, Test Accuracy: 64.56%\n",
      "Epoch [158/2500], Train Loss: 0.9350, Train Accuracy: 61.88%, Test Loss: 0.8108, Test Accuracy: 62.03%\n",
      "Epoch [159/2500], Train Loss: 0.9098, Train Accuracy: 61.74%, Test Loss: 0.9999, Test Accuracy: 69.62%\n",
      "Epoch [160/2500], Train Loss: 0.9036, Train Accuracy: 60.46%, Test Loss: 0.8492, Test Accuracy: 63.29%\n",
      "Epoch [161/2500], Train Loss: 0.9333, Train Accuracy: 60.46%, Test Loss: 0.9277, Test Accuracy: 69.62%\n",
      "Epoch [162/2500], Train Loss: 0.9285, Train Accuracy: 61.17%, Test Loss: 0.8819, Test Accuracy: 63.29%\n",
      "Epoch [163/2500], Train Loss: 0.9361, Train Accuracy: 59.46%, Test Loss: 0.8705, Test Accuracy: 64.56%\n",
      "Epoch [164/2500], Train Loss: 0.9179, Train Accuracy: 60.88%, Test Loss: 0.8999, Test Accuracy: 69.62%\n",
      "Epoch [165/2500], Train Loss: 0.9158, Train Accuracy: 60.88%, Test Loss: 0.8996, Test Accuracy: 63.29%\n",
      "Epoch [166/2500], Train Loss: 0.9302, Train Accuracy: 60.60%, Test Loss: 0.8340, Test Accuracy: 70.89%\n",
      "Epoch [167/2500], Train Loss: 0.9137, Train Accuracy: 60.46%, Test Loss: 0.8612, Test Accuracy: 67.09%\n",
      "Epoch [168/2500], Train Loss: 0.9202, Train Accuracy: 62.16%, Test Loss: 0.8126, Test Accuracy: 63.29%\n",
      "Epoch [169/2500], Train Loss: 0.9342, Train Accuracy: 58.75%, Test Loss: 0.9124, Test Accuracy: 69.62%\n",
      "Epoch [170/2500], Train Loss: 0.9386, Train Accuracy: 62.30%, Test Loss: 0.9113, Test Accuracy: 59.49%\n",
      "Epoch [171/2500], Train Loss: 0.9093, Train Accuracy: 59.17%, Test Loss: 0.9283, Test Accuracy: 70.89%\n",
      "Epoch [172/2500], Train Loss: 0.9508, Train Accuracy: 58.89%, Test Loss: 0.8156, Test Accuracy: 65.82%\n",
      "Epoch [173/2500], Train Loss: 0.9064, Train Accuracy: 61.59%, Test Loss: 0.8088, Test Accuracy: 63.29%\n",
      "Epoch [174/2500], Train Loss: 0.9066, Train Accuracy: 61.45%, Test Loss: 0.8199, Test Accuracy: 69.62%\n",
      "Epoch [175/2500], Train Loss: 0.9291, Train Accuracy: 60.74%, Test Loss: 0.9037, Test Accuracy: 59.49%\n",
      "Epoch [176/2500], Train Loss: 0.9203, Train Accuracy: 62.59%, Test Loss: 0.9577, Test Accuracy: 68.35%\n",
      "Epoch [177/2500], Train Loss: 0.9169, Train Accuracy: 60.60%, Test Loss: 0.9513, Test Accuracy: 60.76%\n",
      "Epoch [178/2500], Train Loss: 0.9082, Train Accuracy: 61.59%, Test Loss: 1.0138, Test Accuracy: 62.03%\n",
      "Epoch [179/2500], Train Loss: 0.9255, Train Accuracy: 59.17%, Test Loss: 0.8392, Test Accuracy: 64.56%\n",
      "Epoch [180/2500], Train Loss: 0.9150, Train Accuracy: 60.46%, Test Loss: 0.8941, Test Accuracy: 62.03%\n",
      "Epoch [181/2500], Train Loss: 0.9212, Train Accuracy: 60.31%, Test Loss: 1.1243, Test Accuracy: 58.23%\n",
      "Epoch [182/2500], Train Loss: 0.9091, Train Accuracy: 62.02%, Test Loss: 0.8523, Test Accuracy: 64.56%\n",
      "Epoch [183/2500], Train Loss: 0.9438, Train Accuracy: 57.75%, Test Loss: 1.1838, Test Accuracy: 51.90%\n",
      "Epoch [184/2500], Train Loss: 0.9124, Train Accuracy: 60.46%, Test Loss: 0.8514, Test Accuracy: 64.56%\n",
      "Epoch [185/2500], Train Loss: 0.9398, Train Accuracy: 61.45%, Test Loss: 0.7925, Test Accuracy: 63.29%\n",
      "Epoch [186/2500], Train Loss: 0.9005, Train Accuracy: 62.02%, Test Loss: 0.8280, Test Accuracy: 68.35%\n",
      "Epoch [187/2500], Train Loss: 0.9018, Train Accuracy: 62.45%, Test Loss: 0.8173, Test Accuracy: 67.09%\n",
      "Epoch [188/2500], Train Loss: 0.8806, Train Accuracy: 62.16%, Test Loss: 0.9391, Test Accuracy: 69.62%\n",
      "Epoch [189/2500], Train Loss: 0.8988, Train Accuracy: 61.31%, Test Loss: 0.8599, Test Accuracy: 69.62%\n",
      "Epoch [190/2500], Train Loss: 0.9243, Train Accuracy: 62.30%, Test Loss: 0.8389, Test Accuracy: 69.62%\n",
      "Epoch [191/2500], Train Loss: 0.8995, Train Accuracy: 58.89%, Test Loss: 0.8310, Test Accuracy: 68.35%\n",
      "Epoch [192/2500], Train Loss: 0.8996, Train Accuracy: 59.74%, Test Loss: 0.9367, Test Accuracy: 58.23%\n",
      "Epoch [193/2500], Train Loss: 0.9033, Train Accuracy: 60.46%, Test Loss: 0.8326, Test Accuracy: 64.56%\n",
      "Epoch [194/2500], Train Loss: 0.9126, Train Accuracy: 59.32%, Test Loss: 0.8770, Test Accuracy: 65.82%\n",
      "Epoch [195/2500], Train Loss: 0.9209, Train Accuracy: 60.31%, Test Loss: 0.8481, Test Accuracy: 67.09%\n",
      "Epoch [196/2500], Train Loss: 0.9008, Train Accuracy: 61.74%, Test Loss: 0.9132, Test Accuracy: 68.35%\n",
      "Epoch [197/2500], Train Loss: 0.9187, Train Accuracy: 60.88%, Test Loss: 0.8083, Test Accuracy: 63.29%\n",
      "Epoch [198/2500], Train Loss: 0.9236, Train Accuracy: 60.60%, Test Loss: 0.8668, Test Accuracy: 59.49%\n",
      "Epoch [199/2500], Train Loss: 0.9153, Train Accuracy: 61.88%, Test Loss: 0.9392, Test Accuracy: 67.09%\n",
      "Epoch [200/2500], Train Loss: 0.9400, Train Accuracy: 59.32%, Test Loss: 0.8484, Test Accuracy: 72.15%\n",
      "Epoch [201/2500], Train Loss: 0.9095, Train Accuracy: 61.74%, Test Loss: 0.8676, Test Accuracy: 62.03%\n",
      "Epoch [202/2500], Train Loss: 0.8975, Train Accuracy: 62.59%, Test Loss: 0.8203, Test Accuracy: 70.89%\n",
      "Epoch [203/2500], Train Loss: 0.8985, Train Accuracy: 61.02%, Test Loss: 0.8691, Test Accuracy: 73.42%\n",
      "Epoch [204/2500], Train Loss: 0.8991, Train Accuracy: 62.87%, Test Loss: 0.8435, Test Accuracy: 67.09%\n",
      "Epoch [205/2500], Train Loss: 0.8996, Train Accuracy: 61.31%, Test Loss: 0.7968, Test Accuracy: 70.89%\n",
      "Epoch [206/2500], Train Loss: 0.9069, Train Accuracy: 61.45%, Test Loss: 0.8064, Test Accuracy: 60.76%\n",
      "Epoch [207/2500], Train Loss: 0.8784, Train Accuracy: 62.73%, Test Loss: 0.8457, Test Accuracy: 70.89%\n",
      "Epoch [208/2500], Train Loss: 0.9193, Train Accuracy: 60.60%, Test Loss: 0.8256, Test Accuracy: 62.03%\n",
      "Epoch [209/2500], Train Loss: 0.8739, Train Accuracy: 63.16%, Test Loss: 0.8235, Test Accuracy: 68.35%\n",
      "Epoch [210/2500], Train Loss: 0.9102, Train Accuracy: 60.88%, Test Loss: 0.8312, Test Accuracy: 63.29%\n",
      "Epoch [211/2500], Train Loss: 0.8803, Train Accuracy: 61.88%, Test Loss: 0.9288, Test Accuracy: 59.49%\n",
      "Epoch [212/2500], Train Loss: 0.9352, Train Accuracy: 60.74%, Test Loss: 0.9160, Test Accuracy: 60.76%\n",
      "Epoch [213/2500], Train Loss: 0.9010, Train Accuracy: 60.88%, Test Loss: 0.8061, Test Accuracy: 67.09%\n",
      "Epoch [214/2500], Train Loss: 0.8677, Train Accuracy: 63.73%, Test Loss: 0.8835, Test Accuracy: 63.29%\n",
      "Epoch [215/2500], Train Loss: 0.8798, Train Accuracy: 61.17%, Test Loss: 0.9826, Test Accuracy: 60.76%\n",
      "Epoch [216/2500], Train Loss: 0.8970, Train Accuracy: 60.74%, Test Loss: 0.9253, Test Accuracy: 62.03%\n",
      "Epoch [217/2500], Train Loss: 0.9086, Train Accuracy: 59.89%, Test Loss: 0.8199, Test Accuracy: 69.62%\n",
      "Epoch [218/2500], Train Loss: 0.9121, Train Accuracy: 59.89%, Test Loss: 0.9107, Test Accuracy: 59.49%\n",
      "Epoch [219/2500], Train Loss: 0.9047, Train Accuracy: 60.60%, Test Loss: 0.9717, Test Accuracy: 63.29%\n",
      "Epoch [220/2500], Train Loss: 0.8825, Train Accuracy: 62.02%, Test Loss: 0.8025, Test Accuracy: 65.82%\n",
      "Epoch [221/2500], Train Loss: 0.9092, Train Accuracy: 61.02%, Test Loss: 0.9059, Test Accuracy: 69.62%\n",
      "Epoch [222/2500], Train Loss: 0.8974, Train Accuracy: 62.73%, Test Loss: 0.8773, Test Accuracy: 64.56%\n",
      "Epoch [223/2500], Train Loss: 0.8882, Train Accuracy: 60.88%, Test Loss: 0.8551, Test Accuracy: 65.82%\n",
      "Epoch [224/2500], Train Loss: 0.8990, Train Accuracy: 61.45%, Test Loss: 0.8502, Test Accuracy: 64.56%\n",
      "Epoch [225/2500], Train Loss: 0.9006, Train Accuracy: 61.45%, Test Loss: 0.8337, Test Accuracy: 63.29%\n",
      "Epoch [226/2500], Train Loss: 0.8942, Train Accuracy: 60.46%, Test Loss: 0.8577, Test Accuracy: 67.09%\n",
      "Epoch [227/2500], Train Loss: 0.8860, Train Accuracy: 62.45%, Test Loss: 0.8483, Test Accuracy: 63.29%\n",
      "Epoch [228/2500], Train Loss: 0.8994, Train Accuracy: 61.59%, Test Loss: 0.8045, Test Accuracy: 63.29%\n",
      "Epoch [229/2500], Train Loss: 0.8906, Train Accuracy: 61.59%, Test Loss: 0.8073, Test Accuracy: 59.49%\n",
      "Epoch [230/2500], Train Loss: 0.8447, Train Accuracy: 65.15%, Test Loss: 0.8707, Test Accuracy: 63.29%\n",
      "Epoch [231/2500], Train Loss: 0.9080, Train Accuracy: 61.59%, Test Loss: 0.8484, Test Accuracy: 63.29%\n",
      "Epoch [232/2500], Train Loss: 0.9026, Train Accuracy: 61.88%, Test Loss: 0.9108, Test Accuracy: 60.76%\n",
      "Epoch [233/2500], Train Loss: 0.9068, Train Accuracy: 61.02%, Test Loss: 0.8097, Test Accuracy: 70.89%\n",
      "Epoch [234/2500], Train Loss: 0.8949, Train Accuracy: 61.45%, Test Loss: 0.8561, Test Accuracy: 64.56%\n",
      "Epoch [235/2500], Train Loss: 0.9156, Train Accuracy: 59.32%, Test Loss: 0.8812, Test Accuracy: 67.09%\n",
      "Epoch [236/2500], Train Loss: 0.8754, Train Accuracy: 63.30%, Test Loss: 0.8131, Test Accuracy: 63.29%\n",
      "Epoch [237/2500], Train Loss: 0.8676, Train Accuracy: 62.30%, Test Loss: 0.8234, Test Accuracy: 69.62%\n",
      "Epoch [238/2500], Train Loss: 0.8817, Train Accuracy: 62.45%, Test Loss: 0.7935, Test Accuracy: 63.29%\n",
      "Epoch [239/2500], Train Loss: 0.9206, Train Accuracy: 61.74%, Test Loss: 0.8309, Test Accuracy: 69.62%\n",
      "Epoch [240/2500], Train Loss: 0.8560, Train Accuracy: 62.45%, Test Loss: 0.8454, Test Accuracy: 74.68%\n",
      "Epoch [241/2500], Train Loss: 0.8800, Train Accuracy: 62.59%, Test Loss: 0.9896, Test Accuracy: 59.49%\n",
      "Epoch [242/2500], Train Loss: 0.8866, Train Accuracy: 62.45%, Test Loss: 0.7992, Test Accuracy: 70.89%\n",
      "Epoch [243/2500], Train Loss: 0.8644, Train Accuracy: 62.45%, Test Loss: 1.1767, Test Accuracy: 53.16%\n",
      "Epoch [244/2500], Train Loss: 0.8909, Train Accuracy: 62.45%, Test Loss: 0.7866, Test Accuracy: 62.03%\n",
      "Epoch [245/2500], Train Loss: 0.8826, Train Accuracy: 61.02%, Test Loss: 0.8154, Test Accuracy: 65.82%\n",
      "Epoch [246/2500], Train Loss: 0.8759, Train Accuracy: 62.02%, Test Loss: 0.8396, Test Accuracy: 65.82%\n",
      "Epoch [247/2500], Train Loss: 0.8579, Train Accuracy: 63.58%, Test Loss: 0.8275, Test Accuracy: 67.09%\n",
      "Epoch [248/2500], Train Loss: 0.8985, Train Accuracy: 61.74%, Test Loss: 0.8256, Test Accuracy: 63.29%\n",
      "Epoch [249/2500], Train Loss: 0.8890, Train Accuracy: 62.30%, Test Loss: 0.8518, Test Accuracy: 64.56%\n",
      "Epoch [250/2500], Train Loss: 0.8654, Train Accuracy: 63.87%, Test Loss: 0.8485, Test Accuracy: 64.56%\n",
      "Epoch [251/2500], Train Loss: 0.8723, Train Accuracy: 62.87%, Test Loss: 0.8128, Test Accuracy: 64.56%\n",
      "Epoch [252/2500], Train Loss: 0.8620, Train Accuracy: 64.44%, Test Loss: 0.9520, Test Accuracy: 62.03%\n",
      "Epoch [253/2500], Train Loss: 0.9072, Train Accuracy: 62.02%, Test Loss: 0.7978, Test Accuracy: 67.09%\n",
      "Epoch [254/2500], Train Loss: 0.8635, Train Accuracy: 63.16%, Test Loss: 1.2570, Test Accuracy: 63.29%\n",
      "Epoch [255/2500], Train Loss: 0.8815, Train Accuracy: 62.87%, Test Loss: 0.9421, Test Accuracy: 68.35%\n",
      "Epoch [256/2500], Train Loss: 0.8989, Train Accuracy: 60.17%, Test Loss: 0.8645, Test Accuracy: 67.09%\n",
      "Epoch [257/2500], Train Loss: 0.8846, Train Accuracy: 62.16%, Test Loss: 0.7917, Test Accuracy: 68.35%\n",
      "Epoch [258/2500], Train Loss: 0.8860, Train Accuracy: 63.44%, Test Loss: 0.8071, Test Accuracy: 69.62%\n",
      "Epoch [259/2500], Train Loss: 0.9043, Train Accuracy: 60.46%, Test Loss: 0.9173, Test Accuracy: 63.29%\n",
      "Epoch [260/2500], Train Loss: 0.8909, Train Accuracy: 60.31%, Test Loss: 0.7859, Test Accuracy: 67.09%\n",
      "Epoch [261/2500], Train Loss: 0.8816, Train Accuracy: 62.87%, Test Loss: 0.8743, Test Accuracy: 63.29%\n",
      "Epoch [262/2500], Train Loss: 0.8882, Train Accuracy: 61.59%, Test Loss: 0.8625, Test Accuracy: 62.03%\n",
      "Epoch [263/2500], Train Loss: 0.8673, Train Accuracy: 62.87%, Test Loss: 0.8442, Test Accuracy: 72.15%\n",
      "Epoch [264/2500], Train Loss: 0.8987, Train Accuracy: 62.30%, Test Loss: 0.8714, Test Accuracy: 60.76%\n",
      "Epoch [265/2500], Train Loss: 0.8543, Train Accuracy: 62.73%, Test Loss: 0.9796, Test Accuracy: 64.56%\n",
      "Epoch [266/2500], Train Loss: 0.8757, Train Accuracy: 62.16%, Test Loss: 0.7910, Test Accuracy: 68.35%\n",
      "Epoch [267/2500], Train Loss: 0.8808, Train Accuracy: 62.73%, Test Loss: 0.8311, Test Accuracy: 67.09%\n",
      "Epoch [268/2500], Train Loss: 0.8646, Train Accuracy: 63.30%, Test Loss: 0.7894, Test Accuracy: 64.56%\n",
      "Epoch [269/2500], Train Loss: 0.8841, Train Accuracy: 60.60%, Test Loss: 0.8684, Test Accuracy: 63.29%\n",
      "Epoch [270/2500], Train Loss: 0.8951, Train Accuracy: 63.02%, Test Loss: 0.8796, Test Accuracy: 62.03%\n",
      "Epoch [271/2500], Train Loss: 0.8557, Train Accuracy: 61.59%, Test Loss: 0.8966, Test Accuracy: 62.03%\n",
      "Epoch [272/2500], Train Loss: 0.8595, Train Accuracy: 63.87%, Test Loss: 0.8211, Test Accuracy: 64.56%\n",
      "Epoch [273/2500], Train Loss: 0.8757, Train Accuracy: 59.89%, Test Loss: 0.8234, Test Accuracy: 62.03%\n",
      "Epoch [274/2500], Train Loss: 0.8814, Train Accuracy: 62.59%, Test Loss: 1.0141, Test Accuracy: 58.23%\n",
      "Epoch [275/2500], Train Loss: 0.8686, Train Accuracy: 62.73%, Test Loss: 0.8597, Test Accuracy: 63.29%\n",
      "Epoch [276/2500], Train Loss: 0.8760, Train Accuracy: 61.59%, Test Loss: 0.8511, Test Accuracy: 63.29%\n",
      "Epoch [277/2500], Train Loss: 0.8646, Train Accuracy: 63.58%, Test Loss: 0.8020, Test Accuracy: 70.89%\n",
      "Epoch [278/2500], Train Loss: 0.8662, Train Accuracy: 63.58%, Test Loss: 0.8362, Test Accuracy: 74.68%\n",
      "Epoch [279/2500], Train Loss: 0.8891, Train Accuracy: 63.73%, Test Loss: 0.8355, Test Accuracy: 67.09%\n",
      "Epoch [280/2500], Train Loss: 0.8773, Train Accuracy: 62.02%, Test Loss: 0.8127, Test Accuracy: 64.56%\n",
      "Epoch [281/2500], Train Loss: 0.8527, Train Accuracy: 63.30%, Test Loss: 0.8781, Test Accuracy: 62.03%\n",
      "Epoch [282/2500], Train Loss: 0.8610, Train Accuracy: 63.16%, Test Loss: 0.8427, Test Accuracy: 63.29%\n",
      "Epoch [283/2500], Train Loss: 0.8963, Train Accuracy: 61.17%, Test Loss: 0.7861, Test Accuracy: 70.89%\n",
      "Epoch [284/2500], Train Loss: 0.8626, Train Accuracy: 63.16%, Test Loss: 0.8044, Test Accuracy: 63.29%\n",
      "Epoch [285/2500], Train Loss: 0.8715, Train Accuracy: 63.87%, Test Loss: 0.8411, Test Accuracy: 67.09%\n",
      "Epoch [286/2500], Train Loss: 0.8739, Train Accuracy: 61.59%, Test Loss: 0.8298, Test Accuracy: 67.09%\n",
      "Epoch [287/2500], Train Loss: 0.8540, Train Accuracy: 62.30%, Test Loss: 0.8952, Test Accuracy: 63.29%\n",
      "Epoch [288/2500], Train Loss: 0.8521, Train Accuracy: 64.15%, Test Loss: 0.8173, Test Accuracy: 67.09%\n",
      "Epoch [289/2500], Train Loss: 0.8327, Train Accuracy: 62.02%, Test Loss: 0.8226, Test Accuracy: 65.82%\n",
      "Epoch [290/2500], Train Loss: 0.8318, Train Accuracy: 65.15%, Test Loss: 0.8093, Test Accuracy: 69.62%\n",
      "Epoch [291/2500], Train Loss: 0.8676, Train Accuracy: 63.87%, Test Loss: 0.7973, Test Accuracy: 69.62%\n",
      "Epoch [292/2500], Train Loss: 0.8446, Train Accuracy: 63.16%, Test Loss: 0.8581, Test Accuracy: 65.82%\n",
      "Epoch [293/2500], Train Loss: 0.8741, Train Accuracy: 63.16%, Test Loss: 0.8128, Test Accuracy: 68.35%\n",
      "Epoch [294/2500], Train Loss: 0.8473, Train Accuracy: 63.02%, Test Loss: 0.7890, Test Accuracy: 63.29%\n",
      "Epoch [295/2500], Train Loss: 0.8582, Train Accuracy: 63.44%, Test Loss: 0.8403, Test Accuracy: 63.29%\n",
      "Epoch [296/2500], Train Loss: 0.8783, Train Accuracy: 62.73%, Test Loss: 0.8040, Test Accuracy: 68.35%\n",
      "Epoch [297/2500], Train Loss: 0.8719, Train Accuracy: 63.73%, Test Loss: 0.8203, Test Accuracy: 72.15%\n",
      "Epoch [298/2500], Train Loss: 0.8770, Train Accuracy: 61.88%, Test Loss: 0.8559, Test Accuracy: 70.89%\n",
      "Epoch [299/2500], Train Loss: 0.8672, Train Accuracy: 61.88%, Test Loss: 0.8490, Test Accuracy: 62.03%\n",
      "Epoch [300/2500], Train Loss: 0.8537, Train Accuracy: 62.16%, Test Loss: 0.8115, Test Accuracy: 65.82%\n",
      "Epoch [301/2500], Train Loss: 0.8931, Train Accuracy: 62.73%, Test Loss: 0.8607, Test Accuracy: 67.09%\n",
      "Epoch [302/2500], Train Loss: 0.8761, Train Accuracy: 62.30%, Test Loss: 0.8594, Test Accuracy: 69.62%\n",
      "Epoch [303/2500], Train Loss: 0.8575, Train Accuracy: 64.72%, Test Loss: 0.7898, Test Accuracy: 64.56%\n",
      "Epoch [304/2500], Train Loss: 0.8779, Train Accuracy: 62.87%, Test Loss: 0.7822, Test Accuracy: 69.62%\n",
      "Epoch [305/2500], Train Loss: 0.8553, Train Accuracy: 65.15%, Test Loss: 0.8703, Test Accuracy: 72.15%\n",
      "Epoch [306/2500], Train Loss: 0.8674, Train Accuracy: 63.58%, Test Loss: 0.8069, Test Accuracy: 62.03%\n",
      "Epoch [307/2500], Train Loss: 0.8549, Train Accuracy: 62.59%, Test Loss: 0.8741, Test Accuracy: 60.76%\n",
      "Epoch [308/2500], Train Loss: 0.8701, Train Accuracy: 62.59%, Test Loss: 0.8188, Test Accuracy: 67.09%\n",
      "Epoch [309/2500], Train Loss: 0.8621, Train Accuracy: 62.45%, Test Loss: 0.8602, Test Accuracy: 64.56%\n",
      "Epoch [310/2500], Train Loss: 0.8934, Train Accuracy: 61.02%, Test Loss: 0.9526, Test Accuracy: 58.23%\n",
      "Epoch [311/2500], Train Loss: 0.8567, Train Accuracy: 63.02%, Test Loss: 0.7904, Test Accuracy: 65.82%\n",
      "Epoch [312/2500], Train Loss: 0.8724, Train Accuracy: 63.58%, Test Loss: 0.8174, Test Accuracy: 68.35%\n",
      "Epoch [313/2500], Train Loss: 0.8748, Train Accuracy: 62.16%, Test Loss: 0.8162, Test Accuracy: 68.35%\n",
      "Epoch [314/2500], Train Loss: 0.8644, Train Accuracy: 63.30%, Test Loss: 0.8179, Test Accuracy: 63.29%\n",
      "Epoch [315/2500], Train Loss: 0.8614, Train Accuracy: 62.59%, Test Loss: 0.8056, Test Accuracy: 60.76%\n",
      "Epoch [316/2500], Train Loss: 0.8597, Train Accuracy: 62.30%, Test Loss: 0.8274, Test Accuracy: 70.89%\n",
      "Epoch [317/2500], Train Loss: 0.8808, Train Accuracy: 62.59%, Test Loss: 0.8104, Test Accuracy: 68.35%\n",
      "Epoch [318/2500], Train Loss: 0.8711, Train Accuracy: 63.02%, Test Loss: 0.9221, Test Accuracy: 62.03%\n",
      "Epoch [319/2500], Train Loss: 0.8204, Train Accuracy: 64.44%, Test Loss: 0.8121, Test Accuracy: 69.62%\n",
      "Epoch [320/2500], Train Loss: 0.8635, Train Accuracy: 63.02%, Test Loss: 0.8640, Test Accuracy: 63.29%\n",
      "Epoch [321/2500], Train Loss: 0.8428, Train Accuracy: 64.01%, Test Loss: 0.9182, Test Accuracy: 60.76%\n",
      "Epoch [322/2500], Train Loss: 0.8577, Train Accuracy: 64.30%, Test Loss: 0.8383, Test Accuracy: 70.89%\n",
      "Epoch [323/2500], Train Loss: 0.8620, Train Accuracy: 61.17%, Test Loss: 0.8519, Test Accuracy: 63.29%\n",
      "Epoch [324/2500], Train Loss: 0.8841, Train Accuracy: 62.16%, Test Loss: 0.7799, Test Accuracy: 69.62%\n",
      "Epoch [325/2500], Train Loss: 0.8548, Train Accuracy: 60.60%, Test Loss: 0.9108, Test Accuracy: 63.29%\n",
      "Epoch [326/2500], Train Loss: 0.8699, Train Accuracy: 61.59%, Test Loss: 0.8209, Test Accuracy: 64.56%\n",
      "Epoch [327/2500], Train Loss: 0.8941, Train Accuracy: 62.59%, Test Loss: 0.8727, Test Accuracy: 62.03%\n",
      "Epoch [328/2500], Train Loss: 0.8458, Train Accuracy: 64.15%, Test Loss: 0.8101, Test Accuracy: 67.09%\n",
      "Epoch [329/2500], Train Loss: 0.8500, Train Accuracy: 63.16%, Test Loss: 0.7957, Test Accuracy: 65.82%\n",
      "Epoch [330/2500], Train Loss: 0.8461, Train Accuracy: 63.87%, Test Loss: 0.8668, Test Accuracy: 62.03%\n",
      "Epoch [331/2500], Train Loss: 0.8685, Train Accuracy: 60.60%, Test Loss: 0.8212, Test Accuracy: 74.68%\n",
      "Epoch [332/2500], Train Loss: 0.8578, Train Accuracy: 64.44%, Test Loss: 0.8893, Test Accuracy: 60.76%\n",
      "Epoch [333/2500], Train Loss: 0.8268, Train Accuracy: 63.58%, Test Loss: 0.8516, Test Accuracy: 69.62%\n",
      "Epoch [334/2500], Train Loss: 0.8607, Train Accuracy: 63.44%, Test Loss: 0.7793, Test Accuracy: 70.89%\n",
      "Epoch [335/2500], Train Loss: 0.8946, Train Accuracy: 61.59%, Test Loss: 0.8063, Test Accuracy: 67.09%\n",
      "Epoch [336/2500], Train Loss: 0.8543, Train Accuracy: 63.02%, Test Loss: 0.7975, Test Accuracy: 67.09%\n",
      "Epoch [337/2500], Train Loss: 0.8569, Train Accuracy: 64.58%, Test Loss: 0.7841, Test Accuracy: 64.56%\n",
      "Epoch [338/2500], Train Loss: 0.8427, Train Accuracy: 65.15%, Test Loss: 0.8681, Test Accuracy: 63.29%\n",
      "Epoch [339/2500], Train Loss: 0.8716, Train Accuracy: 61.59%, Test Loss: 0.7784, Test Accuracy: 70.89%\n",
      "Epoch [340/2500], Train Loss: 0.8541, Train Accuracy: 63.87%, Test Loss: 0.8224, Test Accuracy: 67.09%\n",
      "Epoch [341/2500], Train Loss: 0.8529, Train Accuracy: 63.87%, Test Loss: 0.8244, Test Accuracy: 62.03%\n",
      "Epoch [342/2500], Train Loss: 0.8563, Train Accuracy: 63.87%, Test Loss: 0.8021, Test Accuracy: 70.89%\n",
      "Epoch [343/2500], Train Loss: 0.8620, Train Accuracy: 62.59%, Test Loss: 0.7769, Test Accuracy: 68.35%\n",
      "Epoch [344/2500], Train Loss: 0.8454, Train Accuracy: 64.44%, Test Loss: 0.8920, Test Accuracy: 69.62%\n",
      "Epoch [345/2500], Train Loss: 0.8553, Train Accuracy: 61.45%, Test Loss: 0.8735, Test Accuracy: 69.62%\n",
      "Epoch [346/2500], Train Loss: 0.8630, Train Accuracy: 63.02%, Test Loss: 0.9698, Test Accuracy: 63.29%\n",
      "Epoch [347/2500], Train Loss: 0.8293, Train Accuracy: 64.58%, Test Loss: 0.7929, Test Accuracy: 64.56%\n",
      "Epoch [348/2500], Train Loss: 0.8502, Train Accuracy: 63.87%, Test Loss: 0.7832, Test Accuracy: 67.09%\n",
      "Epoch [349/2500], Train Loss: 0.8816, Train Accuracy: 61.88%, Test Loss: 0.7715, Test Accuracy: 69.62%\n",
      "Epoch [350/2500], Train Loss: 0.8627, Train Accuracy: 63.44%, Test Loss: 0.7925, Test Accuracy: 68.35%\n",
      "Epoch [351/2500], Train Loss: 0.8676, Train Accuracy: 63.30%, Test Loss: 0.8711, Test Accuracy: 68.35%\n",
      "Epoch [352/2500], Train Loss: 0.8659, Train Accuracy: 63.73%, Test Loss: 0.8378, Test Accuracy: 65.82%\n",
      "Epoch [353/2500], Train Loss: 0.8778, Train Accuracy: 62.73%, Test Loss: 0.7930, Test Accuracy: 69.62%\n",
      "Epoch [354/2500], Train Loss: 0.8534, Train Accuracy: 65.29%, Test Loss: 0.8078, Test Accuracy: 69.62%\n",
      "Epoch [355/2500], Train Loss: 0.8879, Train Accuracy: 61.02%, Test Loss: 0.9064, Test Accuracy: 65.82%\n",
      "Epoch [356/2500], Train Loss: 0.8533, Train Accuracy: 64.30%, Test Loss: 0.8851, Test Accuracy: 69.62%\n",
      "Epoch [357/2500], Train Loss: 0.8810, Train Accuracy: 61.45%, Test Loss: 0.9795, Test Accuracy: 60.76%\n",
      "Epoch [358/2500], Train Loss: 0.8820, Train Accuracy: 60.60%, Test Loss: 0.8206, Test Accuracy: 67.09%\n",
      "Epoch [359/2500], Train Loss: 0.8530, Train Accuracy: 63.87%, Test Loss: 0.7811, Test Accuracy: 68.35%\n",
      "Epoch [360/2500], Train Loss: 0.8436, Train Accuracy: 65.58%, Test Loss: 0.8140, Test Accuracy: 67.09%\n",
      "Epoch [361/2500], Train Loss: 0.8807, Train Accuracy: 64.30%, Test Loss: 1.0865, Test Accuracy: 54.43%\n",
      "Epoch [362/2500], Train Loss: 0.8847, Train Accuracy: 58.46%, Test Loss: 0.8751, Test Accuracy: 69.62%\n",
      "Epoch [363/2500], Train Loss: 0.8546, Train Accuracy: 62.87%, Test Loss: 0.8376, Test Accuracy: 67.09%\n",
      "Epoch [364/2500], Train Loss: 0.8754, Train Accuracy: 61.74%, Test Loss: 0.7840, Test Accuracy: 67.09%\n",
      "Epoch [365/2500], Train Loss: 0.8795, Train Accuracy: 63.30%, Test Loss: 0.7895, Test Accuracy: 63.29%\n",
      "Epoch [366/2500], Train Loss: 0.8691, Train Accuracy: 63.58%, Test Loss: 0.8342, Test Accuracy: 72.15%\n",
      "Epoch [367/2500], Train Loss: 0.8466, Train Accuracy: 63.16%, Test Loss: 0.8463, Test Accuracy: 63.29%\n",
      "Epoch [368/2500], Train Loss: 0.8365, Train Accuracy: 63.87%, Test Loss: 0.8380, Test Accuracy: 60.76%\n",
      "Epoch [369/2500], Train Loss: 0.8758, Train Accuracy: 62.30%, Test Loss: 0.9174, Test Accuracy: 60.76%\n",
      "Epoch [370/2500], Train Loss: 0.8584, Train Accuracy: 63.30%, Test Loss: 0.9250, Test Accuracy: 60.76%\n",
      "Epoch [371/2500], Train Loss: 0.8331, Train Accuracy: 66.00%, Test Loss: 0.8350, Test Accuracy: 73.42%\n",
      "Epoch [372/2500], Train Loss: 0.8605, Train Accuracy: 63.58%, Test Loss: 0.7969, Test Accuracy: 73.42%\n",
      "Epoch [373/2500], Train Loss: 0.8692, Train Accuracy: 64.72%, Test Loss: 0.8012, Test Accuracy: 67.09%\n",
      "Epoch [374/2500], Train Loss: 0.8315, Train Accuracy: 62.45%, Test Loss: 0.8785, Test Accuracy: 70.89%\n",
      "Epoch [375/2500], Train Loss: 0.8598, Train Accuracy: 61.59%, Test Loss: 0.9185, Test Accuracy: 62.03%\n",
      "Epoch [376/2500], Train Loss: 0.8349, Train Accuracy: 63.58%, Test Loss: 0.8180, Test Accuracy: 62.03%\n",
      "Epoch [377/2500], Train Loss: 0.8565, Train Accuracy: 61.31%, Test Loss: 0.8259, Test Accuracy: 65.82%\n",
      "Epoch [378/2500], Train Loss: 0.8740, Train Accuracy: 62.02%, Test Loss: 0.7905, Test Accuracy: 64.56%\n",
      "Epoch [379/2500], Train Loss: 0.8312, Train Accuracy: 64.86%, Test Loss: 0.8054, Test Accuracy: 65.82%\n",
      "Epoch [380/2500], Train Loss: 0.8275, Train Accuracy: 62.30%, Test Loss: 0.7983, Test Accuracy: 69.62%\n",
      "Epoch [381/2500], Train Loss: 0.8276, Train Accuracy: 61.74%, Test Loss: 0.8747, Test Accuracy: 69.62%\n",
      "Epoch [382/2500], Train Loss: 0.8499, Train Accuracy: 62.16%, Test Loss: 1.0114, Test Accuracy: 56.96%\n",
      "Epoch [383/2500], Train Loss: 0.8649, Train Accuracy: 63.16%, Test Loss: 0.7907, Test Accuracy: 68.35%\n",
      "Epoch [384/2500], Train Loss: 0.8709, Train Accuracy: 62.02%, Test Loss: 0.8831, Test Accuracy: 59.49%\n",
      "Epoch [385/2500], Train Loss: 0.8397, Train Accuracy: 63.16%, Test Loss: 0.7847, Test Accuracy: 68.35%\n",
      "Epoch [386/2500], Train Loss: 0.8705, Train Accuracy: 61.45%, Test Loss: 0.8104, Test Accuracy: 67.09%\n",
      "Epoch [387/2500], Train Loss: 0.8325, Train Accuracy: 64.30%, Test Loss: 0.8032, Test Accuracy: 67.09%\n",
      "Epoch [388/2500], Train Loss: 0.8674, Train Accuracy: 62.73%, Test Loss: 0.8173, Test Accuracy: 67.09%\n",
      "Epoch [389/2500], Train Loss: 0.8294, Train Accuracy: 64.15%, Test Loss: 0.9445, Test Accuracy: 67.09%\n",
      "Epoch [390/2500], Train Loss: 0.8428, Train Accuracy: 64.15%, Test Loss: 0.8654, Test Accuracy: 63.29%\n",
      "Epoch [391/2500], Train Loss: 0.8639, Train Accuracy: 64.44%, Test Loss: 0.9058, Test Accuracy: 62.03%\n",
      "Epoch [392/2500], Train Loss: 0.8521, Train Accuracy: 63.02%, Test Loss: 0.8006, Test Accuracy: 73.42%\n",
      "Epoch [393/2500], Train Loss: 0.8742, Train Accuracy: 62.30%, Test Loss: 0.8710, Test Accuracy: 60.76%\n",
      "Epoch [394/2500], Train Loss: 0.8651, Train Accuracy: 60.31%, Test Loss: 0.8964, Test Accuracy: 63.29%\n",
      "Epoch [395/2500], Train Loss: 0.8442, Train Accuracy: 63.87%, Test Loss: 1.0085, Test Accuracy: 58.23%\n",
      "Epoch [396/2500], Train Loss: 0.8434, Train Accuracy: 65.15%, Test Loss: 0.8815, Test Accuracy: 63.29%\n",
      "Epoch [397/2500], Train Loss: 0.8525, Train Accuracy: 64.01%, Test Loss: 0.8122, Test Accuracy: 63.29%\n",
      "Epoch [398/2500], Train Loss: 0.8313, Train Accuracy: 65.43%, Test Loss: 0.7926, Test Accuracy: 72.15%\n",
      "Epoch [399/2500], Train Loss: 0.8664, Train Accuracy: 62.59%, Test Loss: 0.7698, Test Accuracy: 73.42%\n",
      "Epoch [400/2500], Train Loss: 0.8365, Train Accuracy: 65.01%, Test Loss: 0.8533, Test Accuracy: 62.03%\n",
      "Epoch [401/2500], Train Loss: 0.8658, Train Accuracy: 63.58%, Test Loss: 0.8025, Test Accuracy: 72.15%\n",
      "Epoch [402/2500], Train Loss: 0.8561, Train Accuracy: 63.02%, Test Loss: 0.7844, Test Accuracy: 64.56%\n",
      "Epoch [403/2500], Train Loss: 0.8471, Train Accuracy: 62.87%, Test Loss: 0.8903, Test Accuracy: 63.29%\n",
      "Epoch [404/2500], Train Loss: 0.8772, Train Accuracy: 62.02%, Test Loss: 0.8580, Test Accuracy: 69.62%\n",
      "Epoch [405/2500], Train Loss: 0.8518, Train Accuracy: 62.16%, Test Loss: 0.8120, Test Accuracy: 67.09%\n",
      "Epoch [406/2500], Train Loss: 0.8265, Train Accuracy: 64.01%, Test Loss: 0.8281, Test Accuracy: 65.82%\n",
      "Epoch [407/2500], Train Loss: 0.8343, Train Accuracy: 63.87%, Test Loss: 0.7889, Test Accuracy: 63.29%\n",
      "Epoch [408/2500], Train Loss: 0.8287, Train Accuracy: 64.30%, Test Loss: 0.8254, Test Accuracy: 73.42%\n",
      "Epoch [409/2500], Train Loss: 0.8497, Train Accuracy: 61.88%, Test Loss: 0.7941, Test Accuracy: 63.29%\n",
      "Epoch [410/2500], Train Loss: 0.8364, Train Accuracy: 65.43%, Test Loss: 0.8089, Test Accuracy: 67.09%\n",
      "Epoch [411/2500], Train Loss: 0.8352, Train Accuracy: 62.45%, Test Loss: 0.9153, Test Accuracy: 60.76%\n",
      "Epoch [412/2500], Train Loss: 0.8549, Train Accuracy: 63.30%, Test Loss: 0.8174, Test Accuracy: 64.56%\n",
      "Epoch [413/2500], Train Loss: 0.8665, Train Accuracy: 62.45%, Test Loss: 0.8466, Test Accuracy: 65.82%\n",
      "Epoch [414/2500], Train Loss: 0.8507, Train Accuracy: 62.30%, Test Loss: 0.8059, Test Accuracy: 74.68%\n",
      "Epoch [415/2500], Train Loss: 0.8510, Train Accuracy: 64.72%, Test Loss: 0.8396, Test Accuracy: 72.15%\n",
      "Epoch [416/2500], Train Loss: 0.8712, Train Accuracy: 63.02%, Test Loss: 0.8522, Test Accuracy: 60.76%\n",
      "Epoch [417/2500], Train Loss: 0.8353, Train Accuracy: 63.30%, Test Loss: 0.8348, Test Accuracy: 63.29%\n",
      "Epoch [418/2500], Train Loss: 0.8483, Train Accuracy: 63.30%, Test Loss: 0.7936, Test Accuracy: 74.68%\n",
      "Epoch [419/2500], Train Loss: 0.8548, Train Accuracy: 63.02%, Test Loss: 0.9178, Test Accuracy: 64.56%\n",
      "Epoch [420/2500], Train Loss: 0.8239, Train Accuracy: 64.15%, Test Loss: 0.8357, Test Accuracy: 63.29%\n",
      "Epoch [421/2500], Train Loss: 0.8737, Train Accuracy: 61.88%, Test Loss: 0.8753, Test Accuracy: 62.03%\n",
      "Epoch [422/2500], Train Loss: 0.8513, Train Accuracy: 63.58%, Test Loss: 0.8334, Test Accuracy: 67.09%\n",
      "Epoch [423/2500], Train Loss: 0.8095, Train Accuracy: 65.15%, Test Loss: 0.8193, Test Accuracy: 64.56%\n",
      "Epoch [424/2500], Train Loss: 0.8429, Train Accuracy: 64.86%, Test Loss: 0.8345, Test Accuracy: 63.29%\n",
      "Epoch [425/2500], Train Loss: 0.8478, Train Accuracy: 63.73%, Test Loss: 0.8436, Test Accuracy: 63.29%\n",
      "Epoch [426/2500], Train Loss: 0.8284, Train Accuracy: 65.15%, Test Loss: 0.8555, Test Accuracy: 64.56%\n",
      "Epoch [427/2500], Train Loss: 0.8476, Train Accuracy: 63.02%, Test Loss: 0.7883, Test Accuracy: 67.09%\n",
      "Epoch [428/2500], Train Loss: 0.8190, Train Accuracy: 67.14%, Test Loss: 0.8389, Test Accuracy: 69.62%\n",
      "Epoch [429/2500], Train Loss: 0.8572, Train Accuracy: 62.87%, Test Loss: 0.7945, Test Accuracy: 72.15%\n",
      "Epoch [430/2500], Train Loss: 0.8288, Train Accuracy: 64.44%, Test Loss: 0.7809, Test Accuracy: 65.82%\n",
      "Epoch [431/2500], Train Loss: 0.8189, Train Accuracy: 66.00%, Test Loss: 0.7967, Test Accuracy: 68.35%\n",
      "Epoch [432/2500], Train Loss: 0.8665, Train Accuracy: 63.44%, Test Loss: 0.7944, Test Accuracy: 69.62%\n",
      "Epoch [433/2500], Train Loss: 0.8449, Train Accuracy: 62.02%, Test Loss: 0.7916, Test Accuracy: 63.29%\n",
      "Epoch [434/2500], Train Loss: 0.8459, Train Accuracy: 63.02%, Test Loss: 0.9346, Test Accuracy: 60.76%\n",
      "Epoch [435/2500], Train Loss: 0.8507, Train Accuracy: 61.88%, Test Loss: 0.8184, Test Accuracy: 70.89%\n",
      "Epoch [436/2500], Train Loss: 0.8493, Train Accuracy: 62.73%, Test Loss: 0.8203, Test Accuracy: 64.56%\n",
      "Epoch [437/2500], Train Loss: 0.8538, Train Accuracy: 62.73%, Test Loss: 0.7880, Test Accuracy: 64.56%\n",
      "Epoch [438/2500], Train Loss: 0.8744, Train Accuracy: 62.30%, Test Loss: 0.8070, Test Accuracy: 68.35%\n",
      "Epoch [439/2500], Train Loss: 0.8840, Train Accuracy: 63.30%, Test Loss: 0.8082, Test Accuracy: 69.62%\n",
      "Epoch [440/2500], Train Loss: 0.8462, Train Accuracy: 62.59%, Test Loss: 0.8250, Test Accuracy: 63.29%\n",
      "Epoch [441/2500], Train Loss: 0.8248, Train Accuracy: 64.15%, Test Loss: 0.7934, Test Accuracy: 70.89%\n",
      "Epoch [442/2500], Train Loss: 0.8570, Train Accuracy: 62.45%, Test Loss: 0.8441, Test Accuracy: 62.03%\n",
      "Epoch [443/2500], Train Loss: 0.8419, Train Accuracy: 63.58%, Test Loss: 0.7707, Test Accuracy: 69.62%\n",
      "Epoch [444/2500], Train Loss: 0.8599, Train Accuracy: 64.30%, Test Loss: 0.8005, Test Accuracy: 68.35%\n",
      "Epoch [445/2500], Train Loss: 0.8417, Train Accuracy: 63.44%, Test Loss: 0.7710, Test Accuracy: 65.82%\n",
      "Epoch [446/2500], Train Loss: 0.8409, Train Accuracy: 63.73%, Test Loss: 0.8358, Test Accuracy: 63.29%\n",
      "Epoch [447/2500], Train Loss: 0.8367, Train Accuracy: 63.02%, Test Loss: 0.8097, Test Accuracy: 69.62%\n",
      "Epoch [448/2500], Train Loss: 0.8403, Train Accuracy: 65.29%, Test Loss: 0.8001, Test Accuracy: 67.09%\n",
      "Epoch [449/2500], Train Loss: 0.8405, Train Accuracy: 65.72%, Test Loss: 0.7815, Test Accuracy: 70.89%\n",
      "Epoch [450/2500], Train Loss: 0.8453, Train Accuracy: 64.15%, Test Loss: 0.9841, Test Accuracy: 60.76%\n",
      "Epoch [451/2500], Train Loss: 0.8451, Train Accuracy: 64.86%, Test Loss: 0.8489, Test Accuracy: 63.29%\n",
      "Epoch [452/2500], Train Loss: 0.8322, Train Accuracy: 64.30%, Test Loss: 0.7986, Test Accuracy: 72.15%\n",
      "Epoch [453/2500], Train Loss: 0.8180, Train Accuracy: 65.86%, Test Loss: 0.7856, Test Accuracy: 64.56%\n",
      "Epoch [454/2500], Train Loss: 0.8279, Train Accuracy: 64.58%, Test Loss: 0.8081, Test Accuracy: 65.82%\n",
      "Epoch [455/2500], Train Loss: 0.8488, Train Accuracy: 65.15%, Test Loss: 0.8465, Test Accuracy: 63.29%\n",
      "Epoch [456/2500], Train Loss: 0.8250, Train Accuracy: 65.58%, Test Loss: 0.8681, Test Accuracy: 63.29%\n",
      "Epoch [457/2500], Train Loss: 0.8426, Train Accuracy: 64.15%, Test Loss: 0.8050, Test Accuracy: 74.68%\n",
      "Epoch [458/2500], Train Loss: 0.8069, Train Accuracy: 66.71%, Test Loss: 0.8055, Test Accuracy: 67.09%\n",
      "Epoch [459/2500], Train Loss: 0.8738, Train Accuracy: 63.02%, Test Loss: 0.7713, Test Accuracy: 65.82%\n",
      "Epoch [460/2500], Train Loss: 0.8614, Train Accuracy: 62.02%, Test Loss: 0.7981, Test Accuracy: 65.82%\n",
      "Epoch [461/2500], Train Loss: 0.8180, Train Accuracy: 64.72%, Test Loss: 0.7572, Test Accuracy: 65.82%\n",
      "Epoch [462/2500], Train Loss: 0.8299, Train Accuracy: 65.01%, Test Loss: 0.7768, Test Accuracy: 70.89%\n",
      "Epoch [463/2500], Train Loss: 0.8458, Train Accuracy: 64.72%, Test Loss: 1.1129, Test Accuracy: 53.16%\n",
      "Epoch [464/2500], Train Loss: 0.8481, Train Accuracy: 64.30%, Test Loss: 0.8584, Test Accuracy: 70.89%\n",
      "Epoch [465/2500], Train Loss: 0.8451, Train Accuracy: 65.15%, Test Loss: 0.8666, Test Accuracy: 60.76%\n",
      "Epoch [466/2500], Train Loss: 0.8375, Train Accuracy: 63.30%, Test Loss: 0.7806, Test Accuracy: 69.62%\n",
      "Epoch [467/2500], Train Loss: 0.8462, Train Accuracy: 63.44%, Test Loss: 0.7867, Test Accuracy: 72.15%\n",
      "Epoch [468/2500], Train Loss: 0.8511, Train Accuracy: 63.16%, Test Loss: 0.8301, Test Accuracy: 62.03%\n",
      "Epoch [469/2500], Train Loss: 0.8144, Train Accuracy: 64.01%, Test Loss: 0.8074, Test Accuracy: 64.56%\n",
      "Epoch [470/2500], Train Loss: 0.8690, Train Accuracy: 62.73%, Test Loss: 0.9012, Test Accuracy: 67.09%\n",
      "Epoch [471/2500], Train Loss: 0.8249, Train Accuracy: 64.58%, Test Loss: 0.8278, Test Accuracy: 62.03%\n",
      "Epoch [472/2500], Train Loss: 0.8594, Train Accuracy: 64.15%, Test Loss: 0.8853, Test Accuracy: 63.29%\n",
      "Epoch [473/2500], Train Loss: 0.8569, Train Accuracy: 62.02%, Test Loss: 0.8137, Test Accuracy: 72.15%\n",
      "Epoch [474/2500], Train Loss: 0.8719, Train Accuracy: 63.16%, Test Loss: 0.9180, Test Accuracy: 62.03%\n",
      "Epoch [475/2500], Train Loss: 0.8435, Train Accuracy: 64.30%, Test Loss: 0.8142, Test Accuracy: 64.56%\n",
      "Epoch [476/2500], Train Loss: 0.8200, Train Accuracy: 66.43%, Test Loss: 0.7882, Test Accuracy: 65.82%\n",
      "Epoch [477/2500], Train Loss: 0.8524, Train Accuracy: 61.45%, Test Loss: 0.8017, Test Accuracy: 67.09%\n",
      "Epoch [478/2500], Train Loss: 0.8435, Train Accuracy: 63.16%, Test Loss: 0.7672, Test Accuracy: 67.09%\n",
      "Epoch [479/2500], Train Loss: 0.8224, Train Accuracy: 64.58%, Test Loss: 0.8006, Test Accuracy: 63.29%\n",
      "Epoch [480/2500], Train Loss: 0.8457, Train Accuracy: 64.30%, Test Loss: 0.7694, Test Accuracy: 67.09%\n",
      "Epoch [481/2500], Train Loss: 0.8445, Train Accuracy: 64.15%, Test Loss: 0.7997, Test Accuracy: 67.09%\n",
      "Epoch [482/2500], Train Loss: 0.8424, Train Accuracy: 64.58%, Test Loss: 0.8657, Test Accuracy: 63.29%\n",
      "Epoch [483/2500], Train Loss: 0.8348, Train Accuracy: 64.15%, Test Loss: 0.8175, Test Accuracy: 70.89%\n",
      "Epoch [484/2500], Train Loss: 0.8357, Train Accuracy: 64.86%, Test Loss: 0.8033, Test Accuracy: 72.15%\n",
      "Epoch [485/2500], Train Loss: 0.8085, Train Accuracy: 65.58%, Test Loss: 0.7949, Test Accuracy: 69.62%\n",
      "Epoch [486/2500], Train Loss: 0.8276, Train Accuracy: 64.01%, Test Loss: 0.9049, Test Accuracy: 68.35%\n",
      "Epoch [487/2500], Train Loss: 0.8231, Train Accuracy: 64.86%, Test Loss: 0.7759, Test Accuracy: 64.56%\n",
      "Epoch [488/2500], Train Loss: 0.8269, Train Accuracy: 64.30%, Test Loss: 0.7650, Test Accuracy: 65.82%\n",
      "Epoch [489/2500], Train Loss: 0.8110, Train Accuracy: 67.57%, Test Loss: 0.8064, Test Accuracy: 65.82%\n",
      "Epoch [490/2500], Train Loss: 0.8441, Train Accuracy: 63.87%, Test Loss: 0.7992, Test Accuracy: 65.82%\n",
      "Epoch [491/2500], Train Loss: 0.8348, Train Accuracy: 65.15%, Test Loss: 0.7724, Test Accuracy: 72.15%\n",
      "Epoch [492/2500], Train Loss: 0.8260, Train Accuracy: 64.01%, Test Loss: 0.8057, Test Accuracy: 65.82%\n",
      "Epoch [493/2500], Train Loss: 0.8492, Train Accuracy: 62.02%, Test Loss: 0.7834, Test Accuracy: 68.35%\n",
      "Epoch [494/2500], Train Loss: 0.8419, Train Accuracy: 65.29%, Test Loss: 0.7818, Test Accuracy: 64.56%\n",
      "Epoch [495/2500], Train Loss: 0.8543, Train Accuracy: 64.72%, Test Loss: 0.7659, Test Accuracy: 70.89%\n",
      "Epoch [496/2500], Train Loss: 0.8281, Train Accuracy: 64.86%, Test Loss: 0.7690, Test Accuracy: 64.56%\n",
      "Epoch [497/2500], Train Loss: 0.8130, Train Accuracy: 65.29%, Test Loss: 0.8139, Test Accuracy: 63.29%\n",
      "Epoch [498/2500], Train Loss: 0.8459, Train Accuracy: 63.58%, Test Loss: 0.8932, Test Accuracy: 68.35%\n",
      "Epoch [499/2500], Train Loss: 0.8275, Train Accuracy: 65.43%, Test Loss: 0.7512, Test Accuracy: 64.56%\n",
      "Epoch [500/2500], Train Loss: 0.8449, Train Accuracy: 63.30%, Test Loss: 0.8100, Test Accuracy: 68.35%\n",
      "Epoch [501/2500], Train Loss: 0.8185, Train Accuracy: 64.01%, Test Loss: 0.8058, Test Accuracy: 65.82%\n",
      "Epoch [502/2500], Train Loss: 0.8329, Train Accuracy: 65.01%, Test Loss: 0.7877, Test Accuracy: 65.82%\n",
      "Epoch [503/2500], Train Loss: 0.8230, Train Accuracy: 66.00%, Test Loss: 0.7835, Test Accuracy: 73.42%\n",
      "Epoch [504/2500], Train Loss: 0.8352, Train Accuracy: 64.44%, Test Loss: 0.8381, Test Accuracy: 64.56%\n",
      "Epoch [505/2500], Train Loss: 0.8769, Train Accuracy: 61.45%, Test Loss: 0.7629, Test Accuracy: 68.35%\n",
      "Epoch [506/2500], Train Loss: 0.8298, Train Accuracy: 65.15%, Test Loss: 0.8903, Test Accuracy: 60.76%\n",
      "Epoch [507/2500], Train Loss: 0.8365, Train Accuracy: 64.30%, Test Loss: 0.7659, Test Accuracy: 68.35%\n",
      "Epoch [508/2500], Train Loss: 0.8134, Train Accuracy: 64.01%, Test Loss: 0.8174, Test Accuracy: 69.62%\n",
      "Epoch [509/2500], Train Loss: 0.8092, Train Accuracy: 65.58%, Test Loss: 0.8363, Test Accuracy: 69.62%\n",
      "Epoch [510/2500], Train Loss: 0.8472, Train Accuracy: 64.15%, Test Loss: 0.8637, Test Accuracy: 65.82%\n",
      "Epoch [511/2500], Train Loss: 0.8693, Train Accuracy: 62.73%, Test Loss: 0.8592, Test Accuracy: 67.09%\n",
      "Epoch [512/2500], Train Loss: 0.8176, Train Accuracy: 65.43%, Test Loss: 0.8541, Test Accuracy: 69.62%\n",
      "Epoch [513/2500], Train Loss: 0.8507, Train Accuracy: 63.58%, Test Loss: 0.7933, Test Accuracy: 69.62%\n",
      "Epoch [514/2500], Train Loss: 0.8471, Train Accuracy: 61.74%, Test Loss: 0.7795, Test Accuracy: 70.89%\n",
      "Epoch [515/2500], Train Loss: 0.8428, Train Accuracy: 63.87%, Test Loss: 1.0435, Test Accuracy: 59.49%\n",
      "Epoch [516/2500], Train Loss: 0.8044, Train Accuracy: 63.87%, Test Loss: 0.8528, Test Accuracy: 62.03%\n",
      "Epoch [517/2500], Train Loss: 0.8652, Train Accuracy: 62.16%, Test Loss: 0.8458, Test Accuracy: 63.29%\n",
      "Epoch [518/2500], Train Loss: 0.8328, Train Accuracy: 61.88%, Test Loss: 0.8144, Test Accuracy: 73.42%\n",
      "Epoch [519/2500], Train Loss: 0.8292, Train Accuracy: 63.58%, Test Loss: 0.7757, Test Accuracy: 67.09%\n",
      "Epoch [520/2500], Train Loss: 0.7932, Train Accuracy: 65.43%, Test Loss: 0.9182, Test Accuracy: 60.76%\n",
      "Epoch [521/2500], Train Loss: 0.8101, Train Accuracy: 63.16%, Test Loss: 0.7710, Test Accuracy: 72.15%\n",
      "Epoch [522/2500], Train Loss: 0.8144, Train Accuracy: 64.44%, Test Loss: 0.8530, Test Accuracy: 62.03%\n",
      "Epoch [523/2500], Train Loss: 0.8392, Train Accuracy: 63.30%, Test Loss: 0.8341, Test Accuracy: 63.29%\n",
      "Epoch [524/2500], Train Loss: 0.8268, Train Accuracy: 65.58%, Test Loss: 0.8329, Test Accuracy: 63.29%\n",
      "Epoch [525/2500], Train Loss: 0.8412, Train Accuracy: 65.72%, Test Loss: 0.7881, Test Accuracy: 65.82%\n",
      "Epoch [526/2500], Train Loss: 0.7946, Train Accuracy: 65.43%, Test Loss: 0.7484, Test Accuracy: 68.35%\n",
      "Epoch [527/2500], Train Loss: 0.8070, Train Accuracy: 63.73%, Test Loss: 0.7736, Test Accuracy: 69.62%\n",
      "Epoch [528/2500], Train Loss: 0.8472, Train Accuracy: 64.15%, Test Loss: 0.7994, Test Accuracy: 68.35%\n",
      "Epoch [529/2500], Train Loss: 0.8148, Train Accuracy: 65.01%, Test Loss: 0.8595, Test Accuracy: 60.76%\n",
      "Epoch [530/2500], Train Loss: 0.8539, Train Accuracy: 64.58%, Test Loss: 0.8850, Test Accuracy: 68.35%\n",
      "Epoch [531/2500], Train Loss: 0.8219, Train Accuracy: 64.44%, Test Loss: 0.8775, Test Accuracy: 68.35%\n",
      "Epoch [532/2500], Train Loss: 0.8182, Train Accuracy: 65.15%, Test Loss: 0.7793, Test Accuracy: 73.42%\n",
      "Epoch [533/2500], Train Loss: 0.8286, Train Accuracy: 64.01%, Test Loss: 0.8106, Test Accuracy: 70.89%\n",
      "Epoch [534/2500], Train Loss: 0.8075, Train Accuracy: 63.16%, Test Loss: 0.7712, Test Accuracy: 63.29%\n",
      "Epoch [535/2500], Train Loss: 0.8434, Train Accuracy: 63.30%, Test Loss: 0.7889, Test Accuracy: 65.82%\n",
      "Epoch [536/2500], Train Loss: 0.8235, Train Accuracy: 65.72%, Test Loss: 0.7876, Test Accuracy: 68.35%\n",
      "Epoch [537/2500], Train Loss: 0.8152, Train Accuracy: 65.86%, Test Loss: 0.7771, Test Accuracy: 68.35%\n",
      "Epoch [538/2500], Train Loss: 0.8354, Train Accuracy: 65.15%, Test Loss: 0.8373, Test Accuracy: 63.29%\n",
      "Epoch [539/2500], Train Loss: 0.7979, Train Accuracy: 67.28%, Test Loss: 0.7995, Test Accuracy: 65.82%\n",
      "Epoch [540/2500], Train Loss: 0.8138, Train Accuracy: 66.00%, Test Loss: 0.8078, Test Accuracy: 67.09%\n",
      "Epoch [541/2500], Train Loss: 0.8372, Train Accuracy: 64.30%, Test Loss: 0.7708, Test Accuracy: 72.15%\n",
      "Epoch [542/2500], Train Loss: 0.8296, Train Accuracy: 64.86%, Test Loss: 0.7669, Test Accuracy: 65.82%\n",
      "Epoch [543/2500], Train Loss: 0.8272, Train Accuracy: 64.86%, Test Loss: 0.7686, Test Accuracy: 65.82%\n",
      "Epoch [544/2500], Train Loss: 0.8348, Train Accuracy: 64.01%, Test Loss: 0.8478, Test Accuracy: 72.15%\n",
      "Epoch [545/2500], Train Loss: 0.8263, Train Accuracy: 66.86%, Test Loss: 0.7598, Test Accuracy: 70.89%\n",
      "Epoch [546/2500], Train Loss: 0.8188, Train Accuracy: 65.58%, Test Loss: 0.7569, Test Accuracy: 70.89%\n",
      "Epoch [547/2500], Train Loss: 0.8230, Train Accuracy: 63.02%, Test Loss: 0.9494, Test Accuracy: 60.76%\n",
      "Epoch [548/2500], Train Loss: 0.8249, Train Accuracy: 64.01%, Test Loss: 0.7869, Test Accuracy: 72.15%\n",
      "Epoch [549/2500], Train Loss: 0.8147, Train Accuracy: 67.43%, Test Loss: 0.7776, Test Accuracy: 67.09%\n",
      "Epoch [550/2500], Train Loss: 0.8043, Train Accuracy: 65.86%, Test Loss: 0.8475, Test Accuracy: 63.29%\n",
      "Epoch [551/2500], Train Loss: 0.8328, Train Accuracy: 64.72%, Test Loss: 0.8589, Test Accuracy: 69.62%\n",
      "Epoch [552/2500], Train Loss: 0.8300, Train Accuracy: 63.87%, Test Loss: 0.9707, Test Accuracy: 67.09%\n",
      "Epoch [553/2500], Train Loss: 0.8173, Train Accuracy: 65.72%, Test Loss: 0.8768, Test Accuracy: 63.29%\n",
      "Epoch [554/2500], Train Loss: 0.8196, Train Accuracy: 65.01%, Test Loss: 0.8402, Test Accuracy: 65.82%\n",
      "Epoch [555/2500], Train Loss: 0.8529, Train Accuracy: 62.45%, Test Loss: 0.7958, Test Accuracy: 72.15%\n",
      "Epoch [556/2500], Train Loss: 0.8316, Train Accuracy: 63.73%, Test Loss: 0.8083, Test Accuracy: 68.35%\n",
      "Epoch [557/2500], Train Loss: 0.8307, Train Accuracy: 64.44%, Test Loss: 0.7802, Test Accuracy: 68.35%\n",
      "Epoch [558/2500], Train Loss: 0.7900, Train Accuracy: 67.14%, Test Loss: 0.9266, Test Accuracy: 59.49%\n",
      "Epoch [559/2500], Train Loss: 0.8308, Train Accuracy: 64.15%, Test Loss: 0.8112, Test Accuracy: 65.82%\n",
      "Epoch [560/2500], Train Loss: 0.8220, Train Accuracy: 63.16%, Test Loss: 0.7863, Test Accuracy: 70.89%\n",
      "Epoch [561/2500], Train Loss: 0.8023, Train Accuracy: 64.86%, Test Loss: 0.8101, Test Accuracy: 67.09%\n",
      "Epoch [562/2500], Train Loss: 0.8596, Train Accuracy: 63.02%, Test Loss: 0.7664, Test Accuracy: 68.35%\n",
      "Epoch [563/2500], Train Loss: 0.8101, Train Accuracy: 65.29%, Test Loss: 0.8027, Test Accuracy: 70.89%\n",
      "Epoch [564/2500], Train Loss: 0.8407, Train Accuracy: 62.30%, Test Loss: 0.8251, Test Accuracy: 64.56%\n",
      "Epoch [565/2500], Train Loss: 0.8345, Train Accuracy: 64.01%, Test Loss: 0.8042, Test Accuracy: 69.62%\n",
      "Epoch [566/2500], Train Loss: 0.8245, Train Accuracy: 64.01%, Test Loss: 0.8358, Test Accuracy: 65.82%\n",
      "Epoch [567/2500], Train Loss: 0.8241, Train Accuracy: 64.30%, Test Loss: 0.7918, Test Accuracy: 69.62%\n",
      "Epoch [568/2500], Train Loss: 0.8116, Train Accuracy: 65.15%, Test Loss: 0.7710, Test Accuracy: 72.15%\n",
      "Epoch [569/2500], Train Loss: 0.7948, Train Accuracy: 66.15%, Test Loss: 0.9273, Test Accuracy: 60.76%\n",
      "Epoch [570/2500], Train Loss: 0.8465, Train Accuracy: 64.01%, Test Loss: 0.9976, Test Accuracy: 59.49%\n",
      "Epoch [571/2500], Train Loss: 0.7864, Train Accuracy: 66.43%, Test Loss: 1.0207, Test Accuracy: 58.23%\n",
      "Epoch [572/2500], Train Loss: 0.8174, Train Accuracy: 67.43%, Test Loss: 0.7918, Test Accuracy: 64.56%\n",
      "Epoch [573/2500], Train Loss: 0.7938, Train Accuracy: 65.58%, Test Loss: 0.7744, Test Accuracy: 69.62%\n",
      "Epoch [574/2500], Train Loss: 0.8391, Train Accuracy: 63.02%, Test Loss: 0.8216, Test Accuracy: 65.82%\n",
      "Epoch [575/2500], Train Loss: 0.7818, Train Accuracy: 65.58%, Test Loss: 0.9292, Test Accuracy: 69.62%\n",
      "Epoch [576/2500], Train Loss: 0.8087, Train Accuracy: 64.86%, Test Loss: 0.8745, Test Accuracy: 68.35%\n",
      "Epoch [577/2500], Train Loss: 0.8218, Train Accuracy: 65.58%, Test Loss: 0.8823, Test Accuracy: 65.82%\n",
      "Epoch [578/2500], Train Loss: 0.8296, Train Accuracy: 63.73%, Test Loss: 0.8728, Test Accuracy: 69.62%\n",
      "Epoch [579/2500], Train Loss: 0.7943, Train Accuracy: 66.15%, Test Loss: 0.7712, Test Accuracy: 69.62%\n",
      "Epoch [580/2500], Train Loss: 0.7825, Train Accuracy: 67.28%, Test Loss: 0.7617, Test Accuracy: 70.89%\n",
      "Epoch [581/2500], Train Loss: 0.8184, Train Accuracy: 65.15%, Test Loss: 0.8955, Test Accuracy: 60.76%\n",
      "Epoch [582/2500], Train Loss: 0.7988, Train Accuracy: 65.43%, Test Loss: 0.8659, Test Accuracy: 67.09%\n",
      "Epoch [583/2500], Train Loss: 0.8340, Train Accuracy: 63.02%, Test Loss: 0.7579, Test Accuracy: 69.62%\n",
      "Epoch [584/2500], Train Loss: 0.7955, Train Accuracy: 66.00%, Test Loss: 0.7914, Test Accuracy: 69.62%\n",
      "Epoch [585/2500], Train Loss: 0.8343, Train Accuracy: 63.44%, Test Loss: 0.7617, Test Accuracy: 68.35%\n",
      "Epoch [586/2500], Train Loss: 0.8080, Train Accuracy: 63.02%, Test Loss: 0.9397, Test Accuracy: 59.49%\n",
      "Epoch [587/2500], Train Loss: 0.7882, Train Accuracy: 65.86%, Test Loss: 0.7473, Test Accuracy: 65.82%\n",
      "Epoch [588/2500], Train Loss: 0.8534, Train Accuracy: 61.74%, Test Loss: 0.8745, Test Accuracy: 64.56%\n",
      "Epoch [589/2500], Train Loss: 0.7914, Train Accuracy: 66.15%, Test Loss: 0.7634, Test Accuracy: 69.62%\n",
      "Epoch [590/2500], Train Loss: 0.7900, Train Accuracy: 64.72%, Test Loss: 0.7492, Test Accuracy: 68.35%\n",
      "Epoch [591/2500], Train Loss: 0.7922, Train Accuracy: 66.29%, Test Loss: 0.8166, Test Accuracy: 70.89%\n",
      "Epoch [592/2500], Train Loss: 0.8374, Train Accuracy: 64.01%, Test Loss: 0.8100, Test Accuracy: 73.42%\n",
      "Epoch [593/2500], Train Loss: 0.8052, Train Accuracy: 64.58%, Test Loss: 0.7744, Test Accuracy: 68.35%\n",
      "Epoch [594/2500], Train Loss: 0.8109, Train Accuracy: 64.44%, Test Loss: 0.8684, Test Accuracy: 60.76%\n",
      "Epoch [595/2500], Train Loss: 0.7781, Train Accuracy: 66.29%, Test Loss: 0.7965, Test Accuracy: 67.09%\n",
      "Epoch [596/2500], Train Loss: 0.8218, Train Accuracy: 63.58%, Test Loss: 0.7732, Test Accuracy: 74.68%\n",
      "Epoch [597/2500], Train Loss: 0.8329, Train Accuracy: 63.87%, Test Loss: 0.7427, Test Accuracy: 68.35%\n",
      "Epoch [598/2500], Train Loss: 0.8139, Train Accuracy: 65.58%, Test Loss: 0.7491, Test Accuracy: 64.56%\n",
      "Epoch [599/2500], Train Loss: 0.8332, Train Accuracy: 64.30%, Test Loss: 0.7613, Test Accuracy: 67.09%\n",
      "Epoch [600/2500], Train Loss: 0.8349, Train Accuracy: 65.58%, Test Loss: 0.7699, Test Accuracy: 67.09%\n",
      "Epoch [601/2500], Train Loss: 0.8019, Train Accuracy: 64.86%, Test Loss: 0.8348, Test Accuracy: 72.15%\n",
      "Epoch [602/2500], Train Loss: 0.8130, Train Accuracy: 64.44%, Test Loss: 0.8299, Test Accuracy: 68.35%\n",
      "Epoch [603/2500], Train Loss: 0.7954, Train Accuracy: 66.00%, Test Loss: 0.9108, Test Accuracy: 62.03%\n",
      "Epoch [604/2500], Train Loss: 0.8476, Train Accuracy: 63.16%, Test Loss: 0.8686, Test Accuracy: 63.29%\n",
      "Epoch [605/2500], Train Loss: 0.8150, Train Accuracy: 64.30%, Test Loss: 0.7794, Test Accuracy: 67.09%\n",
      "Epoch [606/2500], Train Loss: 0.8432, Train Accuracy: 62.87%, Test Loss: 0.8297, Test Accuracy: 63.29%\n",
      "Epoch [607/2500], Train Loss: 0.8366, Train Accuracy: 64.01%, Test Loss: 0.7655, Test Accuracy: 68.35%\n",
      "Epoch [608/2500], Train Loss: 0.8243, Train Accuracy: 64.58%, Test Loss: 0.8551, Test Accuracy: 67.09%\n",
      "Epoch [609/2500], Train Loss: 0.8267, Train Accuracy: 64.15%, Test Loss: 0.8403, Test Accuracy: 64.56%\n",
      "Epoch [610/2500], Train Loss: 0.8075, Train Accuracy: 65.86%, Test Loss: 0.8682, Test Accuracy: 65.82%\n",
      "Epoch [611/2500], Train Loss: 0.8033, Train Accuracy: 67.57%, Test Loss: 0.7828, Test Accuracy: 67.09%\n",
      "Epoch [612/2500], Train Loss: 0.8100, Train Accuracy: 66.29%, Test Loss: 0.7918, Test Accuracy: 68.35%\n",
      "Epoch [613/2500], Train Loss: 0.7977, Train Accuracy: 68.28%, Test Loss: 0.8417, Test Accuracy: 63.29%\n",
      "Epoch [614/2500], Train Loss: 0.8253, Train Accuracy: 67.14%, Test Loss: 0.8309, Test Accuracy: 67.09%\n",
      "Epoch [615/2500], Train Loss: 0.7965, Train Accuracy: 66.86%, Test Loss: 0.7826, Test Accuracy: 68.35%\n",
      "Epoch [616/2500], Train Loss: 0.8136, Train Accuracy: 63.30%, Test Loss: 0.8111, Test Accuracy: 65.82%\n",
      "Epoch [617/2500], Train Loss: 0.8121, Train Accuracy: 63.87%, Test Loss: 0.8259, Test Accuracy: 69.62%\n",
      "Epoch [618/2500], Train Loss: 0.8001, Train Accuracy: 65.86%, Test Loss: 0.7932, Test Accuracy: 69.62%\n",
      "Epoch [619/2500], Train Loss: 0.7723, Train Accuracy: 66.29%, Test Loss: 0.7799, Test Accuracy: 70.89%\n",
      "Epoch [620/2500], Train Loss: 0.8178, Train Accuracy: 64.44%, Test Loss: 0.7709, Test Accuracy: 69.62%\n",
      "Epoch [621/2500], Train Loss: 0.8098, Train Accuracy: 65.15%, Test Loss: 0.8839, Test Accuracy: 62.03%\n",
      "Epoch [622/2500], Train Loss: 0.7980, Train Accuracy: 67.71%, Test Loss: 0.8265, Test Accuracy: 65.82%\n",
      "Epoch [623/2500], Train Loss: 0.8238, Train Accuracy: 65.29%, Test Loss: 0.9036, Test Accuracy: 60.76%\n",
      "Epoch [624/2500], Train Loss: 0.8387, Train Accuracy: 64.15%, Test Loss: 0.7965, Test Accuracy: 72.15%\n",
      "Epoch [625/2500], Train Loss: 0.8205, Train Accuracy: 64.15%, Test Loss: 0.7712, Test Accuracy: 67.09%\n",
      "Epoch [626/2500], Train Loss: 0.8133, Train Accuracy: 66.71%, Test Loss: 0.8088, Test Accuracy: 72.15%\n",
      "Epoch [627/2500], Train Loss: 0.8243, Train Accuracy: 65.15%, Test Loss: 0.8577, Test Accuracy: 64.56%\n",
      "Epoch [628/2500], Train Loss: 0.8090, Train Accuracy: 65.29%, Test Loss: 0.7787, Test Accuracy: 63.29%\n",
      "Epoch [629/2500], Train Loss: 0.8059, Train Accuracy: 65.43%, Test Loss: 0.8559, Test Accuracy: 68.35%\n",
      "Epoch [630/2500], Train Loss: 0.7988, Train Accuracy: 65.58%, Test Loss: 0.9397, Test Accuracy: 60.76%\n",
      "Epoch [631/2500], Train Loss: 0.8367, Train Accuracy: 62.87%, Test Loss: 0.7559, Test Accuracy: 70.89%\n",
      "Epoch [632/2500], Train Loss: 0.8123, Train Accuracy: 65.72%, Test Loss: 0.7649, Test Accuracy: 72.15%\n",
      "Epoch [633/2500], Train Loss: 0.8187, Train Accuracy: 64.44%, Test Loss: 0.8002, Test Accuracy: 67.09%\n",
      "Epoch [634/2500], Train Loss: 0.8086, Train Accuracy: 65.15%, Test Loss: 0.7586, Test Accuracy: 70.89%\n",
      "Epoch [635/2500], Train Loss: 0.8286, Train Accuracy: 65.43%, Test Loss: 0.7774, Test Accuracy: 69.62%\n",
      "Epoch [636/2500], Train Loss: 0.8191, Train Accuracy: 65.01%, Test Loss: 0.9156, Test Accuracy: 67.09%\n",
      "Epoch [637/2500], Train Loss: 0.8058, Train Accuracy: 66.15%, Test Loss: 0.8516, Test Accuracy: 60.76%\n",
      "Epoch [638/2500], Train Loss: 0.8142, Train Accuracy: 64.30%, Test Loss: 0.8139, Test Accuracy: 72.15%\n",
      "Epoch [639/2500], Train Loss: 0.8368, Train Accuracy: 64.30%, Test Loss: 0.9237, Test Accuracy: 62.03%\n",
      "Epoch [640/2500], Train Loss: 0.8084, Train Accuracy: 65.58%, Test Loss: 0.7635, Test Accuracy: 70.89%\n",
      "Epoch [641/2500], Train Loss: 0.8194, Train Accuracy: 64.15%, Test Loss: 0.8321, Test Accuracy: 63.29%\n",
      "Epoch [642/2500], Train Loss: 0.8201, Train Accuracy: 64.01%, Test Loss: 0.7973, Test Accuracy: 67.09%\n",
      "Epoch [643/2500], Train Loss: 0.8193, Train Accuracy: 66.71%, Test Loss: 0.7924, Test Accuracy: 70.89%\n",
      "Epoch [644/2500], Train Loss: 0.8084, Train Accuracy: 66.00%, Test Loss: 0.8737, Test Accuracy: 69.62%\n",
      "Epoch [645/2500], Train Loss: 0.8407, Train Accuracy: 63.58%, Test Loss: 0.7774, Test Accuracy: 65.82%\n",
      "Epoch [646/2500], Train Loss: 0.8357, Train Accuracy: 64.15%, Test Loss: 0.7680, Test Accuracy: 72.15%\n",
      "Epoch [647/2500], Train Loss: 0.8229, Train Accuracy: 63.87%, Test Loss: 0.8396, Test Accuracy: 64.56%\n",
      "Epoch [648/2500], Train Loss: 0.8154, Train Accuracy: 66.29%, Test Loss: 0.7618, Test Accuracy: 64.56%\n",
      "Epoch [649/2500], Train Loss: 0.8129, Train Accuracy: 66.57%, Test Loss: 0.8652, Test Accuracy: 68.35%\n",
      "Epoch [650/2500], Train Loss: 0.8331, Train Accuracy: 65.01%, Test Loss: 0.7547, Test Accuracy: 70.89%\n",
      "Epoch [651/2500], Train Loss: 0.8220, Train Accuracy: 63.87%, Test Loss: 0.7951, Test Accuracy: 70.89%\n",
      "Epoch [652/2500], Train Loss: 0.8046, Train Accuracy: 67.00%, Test Loss: 0.8147, Test Accuracy: 67.09%\n",
      "Epoch [653/2500], Train Loss: 0.8202, Train Accuracy: 63.58%, Test Loss: 0.7896, Test Accuracy: 67.09%\n",
      "Epoch [654/2500], Train Loss: 0.8250, Train Accuracy: 63.44%, Test Loss: 0.7896, Test Accuracy: 72.15%\n",
      "Epoch [655/2500], Train Loss: 0.7969, Train Accuracy: 64.86%, Test Loss: 0.7758, Test Accuracy: 70.89%\n",
      "Epoch [656/2500], Train Loss: 0.8291, Train Accuracy: 64.30%, Test Loss: 0.8289, Test Accuracy: 73.42%\n",
      "Epoch [657/2500], Train Loss: 0.8046, Train Accuracy: 63.87%, Test Loss: 0.8709, Test Accuracy: 67.09%\n",
      "Epoch [658/2500], Train Loss: 0.8026, Train Accuracy: 65.43%, Test Loss: 0.8669, Test Accuracy: 63.29%\n",
      "Epoch [659/2500], Train Loss: 0.8099, Train Accuracy: 64.01%, Test Loss: 0.8163, Test Accuracy: 68.35%\n",
      "Epoch [660/2500], Train Loss: 0.7915, Train Accuracy: 65.01%, Test Loss: 0.8291, Test Accuracy: 62.03%\n",
      "Epoch [661/2500], Train Loss: 0.8412, Train Accuracy: 64.58%, Test Loss: 0.9166, Test Accuracy: 63.29%\n",
      "Epoch [662/2500], Train Loss: 0.8144, Train Accuracy: 62.45%, Test Loss: 0.9032, Test Accuracy: 60.76%\n",
      "Epoch [663/2500], Train Loss: 0.8390, Train Accuracy: 64.86%, Test Loss: 0.7657, Test Accuracy: 68.35%\n",
      "Epoch [664/2500], Train Loss: 0.7978, Train Accuracy: 66.15%, Test Loss: 0.7830, Test Accuracy: 64.56%\n",
      "Epoch [665/2500], Train Loss: 0.8058, Train Accuracy: 64.30%, Test Loss: 0.8506, Test Accuracy: 63.29%\n",
      "Epoch [666/2500], Train Loss: 0.8100, Train Accuracy: 64.01%, Test Loss: 0.8649, Test Accuracy: 63.29%\n",
      "Epoch [667/2500], Train Loss: 0.8035, Train Accuracy: 64.86%, Test Loss: 0.8133, Test Accuracy: 69.62%\n",
      "Epoch [668/2500], Train Loss: 0.8138, Train Accuracy: 66.15%, Test Loss: 0.9126, Test Accuracy: 60.76%\n",
      "Epoch [669/2500], Train Loss: 0.8226, Train Accuracy: 66.00%, Test Loss: 0.8490, Test Accuracy: 63.29%\n",
      "Epoch [670/2500], Train Loss: 0.8072, Train Accuracy: 64.58%, Test Loss: 0.8456, Test Accuracy: 64.56%\n",
      "Epoch [671/2500], Train Loss: 0.8261, Train Accuracy: 64.58%, Test Loss: 0.7579, Test Accuracy: 68.35%\n",
      "Epoch [672/2500], Train Loss: 0.8317, Train Accuracy: 63.30%, Test Loss: 0.7528, Test Accuracy: 68.35%\n",
      "Epoch [673/2500], Train Loss: 0.8012, Train Accuracy: 63.58%, Test Loss: 0.8793, Test Accuracy: 67.09%\n",
      "Epoch [674/2500], Train Loss: 0.7985, Train Accuracy: 65.72%, Test Loss: 0.9763, Test Accuracy: 60.76%\n",
      "Epoch [675/2500], Train Loss: 0.8206, Train Accuracy: 66.15%, Test Loss: 0.8090, Test Accuracy: 69.62%\n",
      "Epoch [676/2500], Train Loss: 0.8057, Train Accuracy: 68.14%, Test Loss: 0.8865, Test Accuracy: 65.82%\n",
      "Epoch [677/2500], Train Loss: 0.8110, Train Accuracy: 64.86%, Test Loss: 0.8541, Test Accuracy: 68.35%\n",
      "Epoch [678/2500], Train Loss: 0.7835, Train Accuracy: 67.00%, Test Loss: 0.8101, Test Accuracy: 68.35%\n",
      "Epoch [679/2500], Train Loss: 0.8180, Train Accuracy: 63.02%, Test Loss: 0.8574, Test Accuracy: 67.09%\n",
      "Epoch [680/2500], Train Loss: 0.8072, Train Accuracy: 67.28%, Test Loss: 0.9095, Test Accuracy: 62.03%\n",
      "Epoch [681/2500], Train Loss: 0.7977, Train Accuracy: 67.57%, Test Loss: 0.8350, Test Accuracy: 64.56%\n",
      "Epoch [682/2500], Train Loss: 0.8200, Train Accuracy: 64.86%, Test Loss: 0.8772, Test Accuracy: 65.82%\n",
      "Epoch [683/2500], Train Loss: 0.8117, Train Accuracy: 65.72%, Test Loss: 0.7628, Test Accuracy: 72.15%\n",
      "Epoch [684/2500], Train Loss: 0.8114, Train Accuracy: 64.44%, Test Loss: 0.8728, Test Accuracy: 63.29%\n",
      "Epoch [685/2500], Train Loss: 0.8119, Train Accuracy: 63.73%, Test Loss: 0.7588, Test Accuracy: 72.15%\n",
      "Epoch [686/2500], Train Loss: 0.8328, Train Accuracy: 64.86%, Test Loss: 0.8166, Test Accuracy: 72.15%\n",
      "Epoch [687/2500], Train Loss: 0.8140, Train Accuracy: 64.44%, Test Loss: 0.7759, Test Accuracy: 69.62%\n",
      "Epoch [688/2500], Train Loss: 0.8148, Train Accuracy: 64.15%, Test Loss: 0.9199, Test Accuracy: 59.49%\n",
      "Epoch [689/2500], Train Loss: 0.7907, Train Accuracy: 65.72%, Test Loss: 0.7607, Test Accuracy: 68.35%\n",
      "Epoch [690/2500], Train Loss: 0.8273, Train Accuracy: 63.73%, Test Loss: 0.8166, Test Accuracy: 72.15%\n",
      "Epoch [691/2500], Train Loss: 0.8047, Train Accuracy: 65.58%, Test Loss: 0.8040, Test Accuracy: 70.89%\n",
      "Epoch [692/2500], Train Loss: 0.7895, Train Accuracy: 65.72%, Test Loss: 0.7871, Test Accuracy: 70.89%\n",
      "Epoch [693/2500], Train Loss: 0.8253, Train Accuracy: 64.30%, Test Loss: 0.7851, Test Accuracy: 73.42%\n",
      "Epoch [694/2500], Train Loss: 0.7859, Train Accuracy: 66.57%, Test Loss: 0.7569, Test Accuracy: 69.62%\n",
      "Epoch [695/2500], Train Loss: 0.7999, Train Accuracy: 64.72%, Test Loss: 0.7963, Test Accuracy: 65.82%\n",
      "Epoch [696/2500], Train Loss: 0.8090, Train Accuracy: 64.15%, Test Loss: 0.8201, Test Accuracy: 63.29%\n",
      "Epoch [697/2500], Train Loss: 0.8092, Train Accuracy: 66.15%, Test Loss: 0.8406, Test Accuracy: 68.35%\n",
      "Epoch [698/2500], Train Loss: 0.8166, Train Accuracy: 64.86%, Test Loss: 0.7578, Test Accuracy: 70.89%\n",
      "Epoch [699/2500], Train Loss: 0.8290, Train Accuracy: 61.74%, Test Loss: 0.8361, Test Accuracy: 72.15%\n",
      "Epoch [700/2500], Train Loss: 0.8038, Train Accuracy: 66.43%, Test Loss: 0.8343, Test Accuracy: 72.15%\n",
      "Epoch [701/2500], Train Loss: 0.7909, Train Accuracy: 65.58%, Test Loss: 0.8575, Test Accuracy: 67.09%\n",
      "Epoch [702/2500], Train Loss: 0.8076, Train Accuracy: 65.43%, Test Loss: 0.7759, Test Accuracy: 74.68%\n",
      "Epoch [703/2500], Train Loss: 0.8114, Train Accuracy: 66.00%, Test Loss: 0.7750, Test Accuracy: 72.15%\n",
      "Epoch [704/2500], Train Loss: 0.7973, Train Accuracy: 65.72%, Test Loss: 0.7672, Test Accuracy: 73.42%\n",
      "Epoch [705/2500], Train Loss: 0.8163, Train Accuracy: 64.72%, Test Loss: 0.8480, Test Accuracy: 64.56%\n",
      "Epoch [706/2500], Train Loss: 0.7900, Train Accuracy: 66.29%, Test Loss: 0.7693, Test Accuracy: 70.89%\n",
      "Epoch [707/2500], Train Loss: 0.8123, Train Accuracy: 66.43%, Test Loss: 0.9282, Test Accuracy: 59.49%\n",
      "Epoch [708/2500], Train Loss: 0.8196, Train Accuracy: 63.58%, Test Loss: 0.7981, Test Accuracy: 70.89%\n",
      "Epoch [709/2500], Train Loss: 0.8102, Train Accuracy: 65.43%, Test Loss: 0.8013, Test Accuracy: 73.42%\n",
      "Epoch [710/2500], Train Loss: 0.7961, Train Accuracy: 65.29%, Test Loss: 0.8984, Test Accuracy: 63.29%\n",
      "Epoch [711/2500], Train Loss: 0.7964, Train Accuracy: 64.72%, Test Loss: 0.8809, Test Accuracy: 64.56%\n",
      "Epoch [712/2500], Train Loss: 0.8174, Train Accuracy: 66.86%, Test Loss: 0.8439, Test Accuracy: 65.82%\n",
      "Epoch [713/2500], Train Loss: 0.7978, Train Accuracy: 66.00%, Test Loss: 0.8150, Test Accuracy: 70.89%\n",
      "Epoch [714/2500], Train Loss: 0.7923, Train Accuracy: 64.58%, Test Loss: 0.7667, Test Accuracy: 69.62%\n",
      "Epoch [715/2500], Train Loss: 0.8344, Train Accuracy: 65.29%, Test Loss: 0.8228, Test Accuracy: 67.09%\n",
      "Epoch [716/2500], Train Loss: 0.7912, Train Accuracy: 66.43%, Test Loss: 0.8140, Test Accuracy: 65.82%\n",
      "Epoch [717/2500], Train Loss: 0.7971, Train Accuracy: 64.15%, Test Loss: 0.8398, Test Accuracy: 69.62%\n",
      "Epoch [718/2500], Train Loss: 0.8241, Train Accuracy: 64.86%, Test Loss: 0.7695, Test Accuracy: 68.35%\n",
      "Epoch [719/2500], Train Loss: 0.8154, Train Accuracy: 65.58%, Test Loss: 0.7624, Test Accuracy: 70.89%\n",
      "Epoch [720/2500], Train Loss: 0.8219, Train Accuracy: 65.86%, Test Loss: 0.7736, Test Accuracy: 72.15%\n",
      "Epoch [721/2500], Train Loss: 0.8212, Train Accuracy: 64.58%, Test Loss: 0.8055, Test Accuracy: 67.09%\n",
      "Epoch [722/2500], Train Loss: 0.8215, Train Accuracy: 64.01%, Test Loss: 0.8467, Test Accuracy: 69.62%\n",
      "Epoch [723/2500], Train Loss: 0.7832, Train Accuracy: 64.72%, Test Loss: 0.7751, Test Accuracy: 68.35%\n",
      "Epoch [724/2500], Train Loss: 0.8117, Train Accuracy: 67.14%, Test Loss: 0.7927, Test Accuracy: 64.56%\n",
      "Epoch [725/2500], Train Loss: 0.7918, Train Accuracy: 65.43%, Test Loss: 0.8777, Test Accuracy: 68.35%\n",
      "Epoch [726/2500], Train Loss: 0.7967, Train Accuracy: 65.29%, Test Loss: 0.8510, Test Accuracy: 63.29%\n",
      "Epoch [727/2500], Train Loss: 0.8334, Train Accuracy: 65.01%, Test Loss: 0.9136, Test Accuracy: 62.03%\n",
      "Epoch [728/2500], Train Loss: 0.8081, Train Accuracy: 64.72%, Test Loss: 1.0095, Test Accuracy: 59.49%\n",
      "Epoch [729/2500], Train Loss: 0.8029, Train Accuracy: 66.71%, Test Loss: 0.9426, Test Accuracy: 60.76%\n",
      "Epoch [730/2500], Train Loss: 0.8314, Train Accuracy: 65.01%, Test Loss: 0.9004, Test Accuracy: 62.03%\n",
      "Epoch [731/2500], Train Loss: 0.7823, Train Accuracy: 65.43%, Test Loss: 0.8439, Test Accuracy: 63.29%\n",
      "Epoch [732/2500], Train Loss: 0.7886, Train Accuracy: 64.01%, Test Loss: 0.8376, Test Accuracy: 69.62%\n",
      "Epoch [733/2500], Train Loss: 0.8256, Train Accuracy: 63.16%, Test Loss: 0.7695, Test Accuracy: 67.09%\n",
      "Epoch [734/2500], Train Loss: 0.7746, Train Accuracy: 67.57%, Test Loss: 0.7696, Test Accuracy: 63.29%\n",
      "Epoch [735/2500], Train Loss: 0.8230, Train Accuracy: 64.58%, Test Loss: 0.7463, Test Accuracy: 67.09%\n",
      "Epoch [736/2500], Train Loss: 0.7795, Train Accuracy: 65.58%, Test Loss: 0.8108, Test Accuracy: 67.09%\n",
      "Epoch [737/2500], Train Loss: 0.8241, Train Accuracy: 64.01%, Test Loss: 0.7631, Test Accuracy: 69.62%\n",
      "Epoch [738/2500], Train Loss: 0.8036, Train Accuracy: 65.43%, Test Loss: 0.8899, Test Accuracy: 63.29%\n",
      "Epoch [739/2500], Train Loss: 0.8106, Train Accuracy: 66.29%, Test Loss: 0.8013, Test Accuracy: 65.82%\n",
      "Epoch [740/2500], Train Loss: 0.8044, Train Accuracy: 66.43%, Test Loss: 0.8004, Test Accuracy: 69.62%\n",
      "Epoch [741/2500], Train Loss: 0.8081, Train Accuracy: 65.86%, Test Loss: 0.8140, Test Accuracy: 63.29%\n",
      "Epoch [742/2500], Train Loss: 0.7865, Train Accuracy: 67.43%, Test Loss: 0.7684, Test Accuracy: 68.35%\n",
      "Epoch [743/2500], Train Loss: 0.7979, Train Accuracy: 66.15%, Test Loss: 0.7886, Test Accuracy: 70.89%\n",
      "Epoch [744/2500], Train Loss: 0.8240, Train Accuracy: 65.15%, Test Loss: 0.8236, Test Accuracy: 63.29%\n",
      "Epoch [745/2500], Train Loss: 0.8037, Train Accuracy: 65.29%, Test Loss: 0.7629, Test Accuracy: 70.89%\n",
      "Epoch [746/2500], Train Loss: 0.8088, Train Accuracy: 64.86%, Test Loss: 0.8494, Test Accuracy: 65.82%\n",
      "Epoch [747/2500], Train Loss: 0.7646, Train Accuracy: 66.71%, Test Loss: 0.7916, Test Accuracy: 68.35%\n",
      "Epoch [748/2500], Train Loss: 0.8369, Train Accuracy: 63.73%, Test Loss: 0.7637, Test Accuracy: 69.62%\n",
      "Epoch [749/2500], Train Loss: 0.7994, Train Accuracy: 64.30%, Test Loss: 0.7694, Test Accuracy: 74.68%\n",
      "Epoch [750/2500], Train Loss: 0.8006, Train Accuracy: 65.72%, Test Loss: 0.8103, Test Accuracy: 65.82%\n",
      "Epoch [751/2500], Train Loss: 0.8168, Train Accuracy: 65.43%, Test Loss: 0.7796, Test Accuracy: 69.62%\n",
      "Epoch [752/2500], Train Loss: 0.7991, Train Accuracy: 65.72%, Test Loss: 0.7596, Test Accuracy: 72.15%\n",
      "Epoch [753/2500], Train Loss: 0.8064, Train Accuracy: 61.88%, Test Loss: 0.7939, Test Accuracy: 70.89%\n",
      "Epoch [754/2500], Train Loss: 0.8038, Train Accuracy: 64.15%, Test Loss: 0.7722, Test Accuracy: 69.62%\n",
      "Epoch [755/2500], Train Loss: 0.8175, Train Accuracy: 64.72%, Test Loss: 0.7510, Test Accuracy: 67.09%\n",
      "Epoch [756/2500], Train Loss: 0.8125, Train Accuracy: 66.00%, Test Loss: 0.8415, Test Accuracy: 67.09%\n",
      "Epoch [757/2500], Train Loss: 0.8122, Train Accuracy: 65.01%, Test Loss: 0.8393, Test Accuracy: 65.82%\n",
      "Epoch [758/2500], Train Loss: 0.8158, Train Accuracy: 64.01%, Test Loss: 0.7829, Test Accuracy: 70.89%\n",
      "Epoch [759/2500], Train Loss: 0.7845, Train Accuracy: 64.86%, Test Loss: 0.7466, Test Accuracy: 67.09%\n",
      "Epoch [760/2500], Train Loss: 0.8164, Train Accuracy: 63.87%, Test Loss: 0.7662, Test Accuracy: 64.56%\n",
      "Epoch [761/2500], Train Loss: 0.7951, Train Accuracy: 65.29%, Test Loss: 0.7689, Test Accuracy: 69.62%\n",
      "Epoch [762/2500], Train Loss: 0.8130, Train Accuracy: 67.43%, Test Loss: 0.7803, Test Accuracy: 65.82%\n",
      "Epoch [763/2500], Train Loss: 0.7784, Train Accuracy: 67.57%, Test Loss: 0.8429, Test Accuracy: 63.29%\n",
      "Epoch [764/2500], Train Loss: 0.7964, Train Accuracy: 65.72%, Test Loss: 0.8246, Test Accuracy: 64.56%\n",
      "Epoch [765/2500], Train Loss: 0.8129, Train Accuracy: 65.01%, Test Loss: 0.7561, Test Accuracy: 68.35%\n",
      "Epoch [766/2500], Train Loss: 0.8295, Train Accuracy: 65.58%, Test Loss: 0.7461, Test Accuracy: 68.35%\n",
      "Epoch [767/2500], Train Loss: 0.8122, Train Accuracy: 66.00%, Test Loss: 0.8353, Test Accuracy: 69.62%\n",
      "Epoch [768/2500], Train Loss: 0.8092, Train Accuracy: 66.57%, Test Loss: 0.7939, Test Accuracy: 64.56%\n",
      "Epoch [769/2500], Train Loss: 0.8251, Train Accuracy: 64.44%, Test Loss: 0.8027, Test Accuracy: 67.09%\n",
      "Epoch [770/2500], Train Loss: 0.8109, Train Accuracy: 63.87%, Test Loss: 0.8048, Test Accuracy: 67.09%\n",
      "Epoch [771/2500], Train Loss: 0.8139, Train Accuracy: 65.86%, Test Loss: 0.7392, Test Accuracy: 64.56%\n",
      "Epoch [772/2500], Train Loss: 0.8135, Train Accuracy: 64.72%, Test Loss: 0.7460, Test Accuracy: 70.89%\n",
      "Epoch [773/2500], Train Loss: 0.8108, Train Accuracy: 65.01%, Test Loss: 0.8281, Test Accuracy: 69.62%\n",
      "Epoch [774/2500], Train Loss: 0.7912, Train Accuracy: 64.86%, Test Loss: 0.7444, Test Accuracy: 72.15%\n",
      "Epoch [775/2500], Train Loss: 0.8196, Train Accuracy: 63.73%, Test Loss: 0.7488, Test Accuracy: 70.89%\n",
      "Epoch [776/2500], Train Loss: 0.7913, Train Accuracy: 65.29%, Test Loss: 0.8281, Test Accuracy: 64.56%\n",
      "Epoch [777/2500], Train Loss: 0.8126, Train Accuracy: 64.44%, Test Loss: 0.8430, Test Accuracy: 63.29%\n",
      "Epoch [778/2500], Train Loss: 0.7907, Train Accuracy: 64.30%, Test Loss: 0.7971, Test Accuracy: 74.68%\n",
      "Epoch [779/2500], Train Loss: 0.7843, Train Accuracy: 66.00%, Test Loss: 0.7379, Test Accuracy: 67.09%\n",
      "Epoch [780/2500], Train Loss: 0.7961, Train Accuracy: 64.58%, Test Loss: 0.7473, Test Accuracy: 70.89%\n",
      "Epoch [781/2500], Train Loss: 0.7892, Train Accuracy: 67.57%, Test Loss: 0.7703, Test Accuracy: 67.09%\n",
      "Epoch [782/2500], Train Loss: 0.7940, Train Accuracy: 64.44%, Test Loss: 0.7695, Test Accuracy: 69.62%\n",
      "Epoch [783/2500], Train Loss: 0.8252, Train Accuracy: 64.58%, Test Loss: 0.8472, Test Accuracy: 69.62%\n",
      "Epoch [784/2500], Train Loss: 0.8223, Train Accuracy: 63.02%, Test Loss: 0.7824, Test Accuracy: 68.35%\n",
      "Epoch [785/2500], Train Loss: 0.7868, Train Accuracy: 65.58%, Test Loss: 0.8472, Test Accuracy: 63.29%\n",
      "Epoch [786/2500], Train Loss: 0.7971, Train Accuracy: 63.44%, Test Loss: 0.8708, Test Accuracy: 68.35%\n",
      "Epoch [787/2500], Train Loss: 0.8106, Train Accuracy: 64.86%, Test Loss: 0.7430, Test Accuracy: 65.82%\n",
      "Epoch [788/2500], Train Loss: 0.7977, Train Accuracy: 67.00%, Test Loss: 0.8687, Test Accuracy: 64.56%\n",
      "Epoch [789/2500], Train Loss: 0.8362, Train Accuracy: 64.44%, Test Loss: 0.7650, Test Accuracy: 69.62%\n",
      "Epoch [790/2500], Train Loss: 0.8120, Train Accuracy: 65.29%, Test Loss: 0.7519, Test Accuracy: 72.15%\n",
      "Epoch [791/2500], Train Loss: 0.7992, Train Accuracy: 65.29%, Test Loss: 0.8948, Test Accuracy: 64.56%\n",
      "Epoch [792/2500], Train Loss: 0.8142, Train Accuracy: 64.86%, Test Loss: 0.8076, Test Accuracy: 74.68%\n",
      "Epoch [793/2500], Train Loss: 0.7954, Train Accuracy: 66.00%, Test Loss: 0.7596, Test Accuracy: 68.35%\n",
      "Epoch [794/2500], Train Loss: 0.8053, Train Accuracy: 65.58%, Test Loss: 0.8412, Test Accuracy: 60.76%\n",
      "Epoch [795/2500], Train Loss: 0.8049, Train Accuracy: 64.44%, Test Loss: 0.7565, Test Accuracy: 70.89%\n",
      "Epoch [796/2500], Train Loss: 0.8224, Train Accuracy: 65.43%, Test Loss: 0.7530, Test Accuracy: 67.09%\n",
      "Epoch [797/2500], Train Loss: 0.8155, Train Accuracy: 65.01%, Test Loss: 0.8038, Test Accuracy: 65.82%\n",
      "Epoch [798/2500], Train Loss: 0.7908, Train Accuracy: 65.58%, Test Loss: 0.8148, Test Accuracy: 70.89%\n",
      "Epoch [799/2500], Train Loss: 0.8257, Train Accuracy: 64.86%, Test Loss: 0.8013, Test Accuracy: 68.35%\n",
      "Epoch [800/2500], Train Loss: 0.7989, Train Accuracy: 66.15%, Test Loss: 0.8331, Test Accuracy: 63.29%\n",
      "Epoch [801/2500], Train Loss: 0.7928, Train Accuracy: 66.71%, Test Loss: 0.9303, Test Accuracy: 58.23%\n",
      "Epoch [802/2500], Train Loss: 0.7853, Train Accuracy: 66.43%, Test Loss: 0.7716, Test Accuracy: 69.62%\n",
      "Epoch [803/2500], Train Loss: 0.8185, Train Accuracy: 65.01%, Test Loss: 0.9211, Test Accuracy: 65.82%\n",
      "Epoch [804/2500], Train Loss: 0.8012, Train Accuracy: 65.43%, Test Loss: 0.7608, Test Accuracy: 65.82%\n",
      "Epoch [805/2500], Train Loss: 0.8058, Train Accuracy: 65.01%, Test Loss: 0.8116, Test Accuracy: 70.89%\n",
      "Epoch [806/2500], Train Loss: 0.8032, Train Accuracy: 64.86%, Test Loss: 0.8038, Test Accuracy: 67.09%\n",
      "Epoch [807/2500], Train Loss: 0.7866, Train Accuracy: 64.58%, Test Loss: 0.7565, Test Accuracy: 60.76%\n",
      "Epoch [808/2500], Train Loss: 0.7985, Train Accuracy: 65.01%, Test Loss: 1.1865, Test Accuracy: 53.16%\n",
      "Epoch [809/2500], Train Loss: 0.7702, Train Accuracy: 65.58%, Test Loss: 0.9780, Test Accuracy: 65.82%\n",
      "Epoch [810/2500], Train Loss: 0.7828, Train Accuracy: 65.72%, Test Loss: 0.7511, Test Accuracy: 69.62%\n",
      "Epoch [811/2500], Train Loss: 0.8104, Train Accuracy: 65.29%, Test Loss: 0.8043, Test Accuracy: 67.09%\n",
      "Epoch [812/2500], Train Loss: 0.7906, Train Accuracy: 66.57%, Test Loss: 0.7737, Test Accuracy: 63.29%\n",
      "Epoch [813/2500], Train Loss: 0.7912, Train Accuracy: 65.58%, Test Loss: 0.7872, Test Accuracy: 65.82%\n",
      "Epoch [814/2500], Train Loss: 0.8181, Train Accuracy: 63.87%, Test Loss: 0.8697, Test Accuracy: 67.09%\n",
      "Epoch [815/2500], Train Loss: 0.8100, Train Accuracy: 67.00%, Test Loss: 0.7534, Test Accuracy: 65.82%\n",
      "Epoch [816/2500], Train Loss: 0.8055, Train Accuracy: 66.71%, Test Loss: 0.7816, Test Accuracy: 69.62%\n",
      "Epoch [817/2500], Train Loss: 0.7993, Train Accuracy: 64.86%, Test Loss: 0.7991, Test Accuracy: 64.56%\n",
      "Epoch [818/2500], Train Loss: 0.7901, Train Accuracy: 65.86%, Test Loss: 0.7727, Test Accuracy: 65.82%\n",
      "Epoch [819/2500], Train Loss: 0.7888, Train Accuracy: 65.86%, Test Loss: 0.7715, Test Accuracy: 68.35%\n",
      "Epoch [820/2500], Train Loss: 0.8091, Train Accuracy: 65.58%, Test Loss: 0.9378, Test Accuracy: 63.29%\n",
      "Epoch [821/2500], Train Loss: 0.8006, Train Accuracy: 66.15%, Test Loss: 0.7774, Test Accuracy: 70.89%\n",
      "Epoch [822/2500], Train Loss: 0.7800, Train Accuracy: 65.29%, Test Loss: 0.9378, Test Accuracy: 60.76%\n",
      "Epoch [823/2500], Train Loss: 0.8060, Train Accuracy: 66.00%, Test Loss: 0.7503, Test Accuracy: 65.82%\n",
      "Epoch [824/2500], Train Loss: 0.8036, Train Accuracy: 65.72%, Test Loss: 0.8348, Test Accuracy: 68.35%\n",
      "Epoch [825/2500], Train Loss: 0.7799, Train Accuracy: 65.01%, Test Loss: 0.7923, Test Accuracy: 69.62%\n",
      "Epoch [826/2500], Train Loss: 0.8060, Train Accuracy: 65.01%, Test Loss: 1.1207, Test Accuracy: 55.70%\n",
      "Epoch [827/2500], Train Loss: 0.8183, Train Accuracy: 65.43%, Test Loss: 0.7771, Test Accuracy: 72.15%\n",
      "Epoch [828/2500], Train Loss: 0.8138, Train Accuracy: 65.58%, Test Loss: 0.7645, Test Accuracy: 69.62%\n",
      "Epoch [829/2500], Train Loss: 0.7941, Train Accuracy: 65.01%, Test Loss: 0.7721, Test Accuracy: 69.62%\n",
      "Epoch [830/2500], Train Loss: 0.7619, Train Accuracy: 66.57%, Test Loss: 0.7838, Test Accuracy: 68.35%\n",
      "Epoch [831/2500], Train Loss: 0.7861, Train Accuracy: 67.14%, Test Loss: 0.7543, Test Accuracy: 63.29%\n",
      "Epoch [832/2500], Train Loss: 0.8234, Train Accuracy: 61.88%, Test Loss: 0.8748, Test Accuracy: 60.76%\n",
      "Epoch [833/2500], Train Loss: 0.7772, Train Accuracy: 67.57%, Test Loss: 0.8362, Test Accuracy: 63.29%\n",
      "Epoch [834/2500], Train Loss: 0.7805, Train Accuracy: 67.57%, Test Loss: 0.7776, Test Accuracy: 65.82%\n",
      "Epoch [835/2500], Train Loss: 0.8106, Train Accuracy: 62.87%, Test Loss: 0.8187, Test Accuracy: 64.56%\n",
      "Epoch [836/2500], Train Loss: 0.7776, Train Accuracy: 66.86%, Test Loss: 0.8972, Test Accuracy: 59.49%\n",
      "Epoch [837/2500], Train Loss: 0.8026, Train Accuracy: 64.15%, Test Loss: 0.7784, Test Accuracy: 70.89%\n",
      "Epoch [838/2500], Train Loss: 0.8091, Train Accuracy: 66.57%, Test Loss: 0.8080, Test Accuracy: 68.35%\n",
      "Epoch [839/2500], Train Loss: 0.7932, Train Accuracy: 65.72%, Test Loss: 0.7842, Test Accuracy: 64.56%\n",
      "Epoch [840/2500], Train Loss: 0.7884, Train Accuracy: 64.15%, Test Loss: 0.8240, Test Accuracy: 69.62%\n",
      "Epoch [841/2500], Train Loss: 0.7802, Train Accuracy: 65.43%, Test Loss: 0.7456, Test Accuracy: 69.62%\n",
      "Epoch [842/2500], Train Loss: 0.7987, Train Accuracy: 66.15%, Test Loss: 0.7879, Test Accuracy: 65.82%\n",
      "Epoch [843/2500], Train Loss: 0.8256, Train Accuracy: 67.57%, Test Loss: 0.8263, Test Accuracy: 67.09%\n",
      "Epoch [844/2500], Train Loss: 0.7963, Train Accuracy: 66.29%, Test Loss: 0.7563, Test Accuracy: 67.09%\n",
      "Epoch [845/2500], Train Loss: 0.7858, Train Accuracy: 66.15%, Test Loss: 0.7416, Test Accuracy: 64.56%\n",
      "Epoch [846/2500], Train Loss: 0.7976, Train Accuracy: 65.43%, Test Loss: 0.7557, Test Accuracy: 62.03%\n",
      "Epoch [847/2500], Train Loss: 0.7926, Train Accuracy: 65.43%, Test Loss: 0.7767, Test Accuracy: 69.62%\n",
      "Epoch [848/2500], Train Loss: 0.8066, Train Accuracy: 65.86%, Test Loss: 0.7513, Test Accuracy: 65.82%\n",
      "Epoch [849/2500], Train Loss: 0.7923, Train Accuracy: 65.15%, Test Loss: 0.8439, Test Accuracy: 65.82%\n",
      "Epoch [850/2500], Train Loss: 0.7695, Train Accuracy: 66.43%, Test Loss: 0.8492, Test Accuracy: 67.09%\n",
      "Epoch [851/2500], Train Loss: 0.7759, Train Accuracy: 65.72%, Test Loss: 0.8731, Test Accuracy: 62.03%\n",
      "Epoch [852/2500], Train Loss: 0.8249, Train Accuracy: 64.15%, Test Loss: 0.8030, Test Accuracy: 74.68%\n",
      "Epoch [853/2500], Train Loss: 0.8318, Train Accuracy: 64.44%, Test Loss: 0.7426, Test Accuracy: 67.09%\n",
      "Epoch [854/2500], Train Loss: 0.7963, Train Accuracy: 65.01%, Test Loss: 0.7645, Test Accuracy: 67.09%\n",
      "Epoch [855/2500], Train Loss: 0.7975, Train Accuracy: 65.29%, Test Loss: 0.8594, Test Accuracy: 68.35%\n",
      "Epoch [856/2500], Train Loss: 0.7829, Train Accuracy: 68.42%, Test Loss: 0.7899, Test Accuracy: 68.35%\n",
      "Epoch [857/2500], Train Loss: 0.7749, Train Accuracy: 67.71%, Test Loss: 0.7921, Test Accuracy: 70.89%\n",
      "Epoch [858/2500], Train Loss: 0.7938, Train Accuracy: 65.43%, Test Loss: 0.8140, Test Accuracy: 65.82%\n",
      "Epoch [859/2500], Train Loss: 0.7983, Train Accuracy: 64.44%, Test Loss: 0.8660, Test Accuracy: 62.03%\n",
      "Epoch [860/2500], Train Loss: 0.7997, Train Accuracy: 66.29%, Test Loss: 0.7770, Test Accuracy: 69.62%\n",
      "Epoch [861/2500], Train Loss: 0.7784, Train Accuracy: 65.86%, Test Loss: 0.8657, Test Accuracy: 62.03%\n",
      "Epoch [862/2500], Train Loss: 0.7747, Train Accuracy: 67.14%, Test Loss: 0.7938, Test Accuracy: 67.09%\n",
      "Epoch [863/2500], Train Loss: 0.8002, Train Accuracy: 65.58%, Test Loss: 0.8598, Test Accuracy: 62.03%\n",
      "Epoch [864/2500], Train Loss: 0.7830, Train Accuracy: 66.86%, Test Loss: 0.7500, Test Accuracy: 65.82%\n",
      "Epoch [865/2500], Train Loss: 0.7831, Train Accuracy: 65.15%, Test Loss: 0.8264, Test Accuracy: 62.03%\n",
      "Epoch [866/2500], Train Loss: 0.7819, Train Accuracy: 67.14%, Test Loss: 0.7927, Test Accuracy: 72.15%\n",
      "Epoch [867/2500], Train Loss: 0.7869, Train Accuracy: 66.86%, Test Loss: 0.7585, Test Accuracy: 67.09%\n",
      "Epoch [868/2500], Train Loss: 0.7958, Train Accuracy: 65.72%, Test Loss: 0.7615, Test Accuracy: 72.15%\n",
      "Epoch [869/2500], Train Loss: 0.8006, Train Accuracy: 64.72%, Test Loss: 0.7345, Test Accuracy: 68.35%\n",
      "Epoch [870/2500], Train Loss: 0.8127, Train Accuracy: 65.58%, Test Loss: 0.7360, Test Accuracy: 69.62%\n",
      "Epoch [871/2500], Train Loss: 0.7860, Train Accuracy: 66.00%, Test Loss: 0.7830, Test Accuracy: 72.15%\n",
      "Epoch [872/2500], Train Loss: 0.8219, Train Accuracy: 63.87%, Test Loss: 0.7811, Test Accuracy: 68.35%\n",
      "Epoch [873/2500], Train Loss: 0.7946, Train Accuracy: 64.44%, Test Loss: 0.7569, Test Accuracy: 74.68%\n",
      "Epoch [874/2500], Train Loss: 0.8041, Train Accuracy: 65.01%, Test Loss: 0.8318, Test Accuracy: 69.62%\n",
      "Epoch [875/2500], Train Loss: 0.8162, Train Accuracy: 63.58%, Test Loss: 0.8309, Test Accuracy: 67.09%\n",
      "Epoch [876/2500], Train Loss: 0.7856, Train Accuracy: 64.72%, Test Loss: 0.7785, Test Accuracy: 69.62%\n",
      "Epoch [877/2500], Train Loss: 0.7922, Train Accuracy: 65.29%, Test Loss: 0.8174, Test Accuracy: 64.56%\n",
      "Epoch [878/2500], Train Loss: 0.7666, Train Accuracy: 66.15%, Test Loss: 0.7408, Test Accuracy: 67.09%\n",
      "Epoch [879/2500], Train Loss: 0.7654, Train Accuracy: 67.28%, Test Loss: 0.8038, Test Accuracy: 67.09%\n",
      "Epoch [880/2500], Train Loss: 0.7996, Train Accuracy: 65.15%, Test Loss: 0.8331, Test Accuracy: 69.62%\n",
      "Epoch [881/2500], Train Loss: 0.7907, Train Accuracy: 67.99%, Test Loss: 0.8539, Test Accuracy: 68.35%\n",
      "Epoch [882/2500], Train Loss: 0.8206, Train Accuracy: 64.44%, Test Loss: 0.7988, Test Accuracy: 69.62%\n",
      "Epoch [883/2500], Train Loss: 0.7792, Train Accuracy: 65.15%, Test Loss: 0.8031, Test Accuracy: 64.56%\n",
      "Epoch [884/2500], Train Loss: 0.8002, Train Accuracy: 65.01%, Test Loss: 0.7774, Test Accuracy: 68.35%\n",
      "Epoch [885/2500], Train Loss: 0.7946, Train Accuracy: 66.00%, Test Loss: 0.7592, Test Accuracy: 64.56%\n",
      "Epoch [886/2500], Train Loss: 0.7936, Train Accuracy: 65.15%, Test Loss: 0.7734, Test Accuracy: 69.62%\n",
      "Epoch [887/2500], Train Loss: 0.7473, Train Accuracy: 67.71%, Test Loss: 0.8982, Test Accuracy: 65.82%\n",
      "Epoch [888/2500], Train Loss: 0.7959, Train Accuracy: 64.30%, Test Loss: 0.7729, Test Accuracy: 70.89%\n",
      "Epoch [889/2500], Train Loss: 0.7987, Train Accuracy: 65.01%, Test Loss: 1.0443, Test Accuracy: 59.49%\n",
      "Epoch [890/2500], Train Loss: 0.7922, Train Accuracy: 66.57%, Test Loss: 0.7836, Test Accuracy: 72.15%\n",
      "Epoch [891/2500], Train Loss: 0.7723, Train Accuracy: 68.71%, Test Loss: 0.7623, Test Accuracy: 73.42%\n",
      "Epoch [892/2500], Train Loss: 0.7795, Train Accuracy: 66.86%, Test Loss: 0.7390, Test Accuracy: 67.09%\n",
      "Epoch [893/2500], Train Loss: 0.7854, Train Accuracy: 65.58%, Test Loss: 0.7529, Test Accuracy: 65.82%\n",
      "Epoch [894/2500], Train Loss: 0.8046, Train Accuracy: 64.30%, Test Loss: 0.7832, Test Accuracy: 72.15%\n",
      "Epoch [895/2500], Train Loss: 0.7754, Train Accuracy: 66.57%, Test Loss: 0.9202, Test Accuracy: 60.76%\n",
      "Epoch [896/2500], Train Loss: 0.7745, Train Accuracy: 67.57%, Test Loss: 0.8547, Test Accuracy: 62.03%\n",
      "Epoch [897/2500], Train Loss: 0.7701, Train Accuracy: 65.15%, Test Loss: 0.7407, Test Accuracy: 72.15%\n",
      "Epoch [898/2500], Train Loss: 0.7719, Train Accuracy: 66.57%, Test Loss: 0.8285, Test Accuracy: 67.09%\n",
      "Epoch [899/2500], Train Loss: 0.8092, Train Accuracy: 65.43%, Test Loss: 0.7444, Test Accuracy: 68.35%\n",
      "Epoch [900/2500], Train Loss: 0.7998, Train Accuracy: 67.85%, Test Loss: 0.7453, Test Accuracy: 65.82%\n",
      "Epoch [901/2500], Train Loss: 0.7737, Train Accuracy: 66.00%, Test Loss: 0.8877, Test Accuracy: 59.49%\n",
      "Epoch [902/2500], Train Loss: 0.7912, Train Accuracy: 65.86%, Test Loss: 0.7366, Test Accuracy: 63.29%\n",
      "Epoch [903/2500], Train Loss: 0.8029, Train Accuracy: 66.29%, Test Loss: 0.7584, Test Accuracy: 63.29%\n",
      "Epoch [904/2500], Train Loss: 0.7812, Train Accuracy: 66.71%, Test Loss: 0.7457, Test Accuracy: 67.09%\n",
      "Epoch [905/2500], Train Loss: 0.7964, Train Accuracy: 66.86%, Test Loss: 0.7938, Test Accuracy: 73.42%\n",
      "Epoch [906/2500], Train Loss: 0.7788, Train Accuracy: 64.86%, Test Loss: 0.7680, Test Accuracy: 69.62%\n",
      "Epoch [907/2500], Train Loss: 0.7763, Train Accuracy: 66.86%, Test Loss: 0.7536, Test Accuracy: 68.35%\n",
      "Epoch [908/2500], Train Loss: 0.7920, Train Accuracy: 66.00%, Test Loss: 0.8290, Test Accuracy: 60.76%\n",
      "Epoch [909/2500], Train Loss: 0.7847, Train Accuracy: 65.01%, Test Loss: 0.8130, Test Accuracy: 63.29%\n",
      "Epoch [910/2500], Train Loss: 0.7961, Train Accuracy: 64.58%, Test Loss: 0.7571, Test Accuracy: 68.35%\n",
      "Epoch [911/2500], Train Loss: 0.8042, Train Accuracy: 64.86%, Test Loss: 0.7574, Test Accuracy: 68.35%\n",
      "Epoch [912/2500], Train Loss: 0.7816, Train Accuracy: 64.01%, Test Loss: 0.8153, Test Accuracy: 68.35%\n",
      "Epoch [913/2500], Train Loss: 0.7888, Train Accuracy: 65.43%, Test Loss: 0.7511, Test Accuracy: 70.89%\n",
      "Epoch [914/2500], Train Loss: 0.7745, Train Accuracy: 66.15%, Test Loss: 0.7469, Test Accuracy: 68.35%\n",
      "Epoch [915/2500], Train Loss: 0.7625, Train Accuracy: 67.28%, Test Loss: 0.7618, Test Accuracy: 70.89%\n",
      "Epoch [916/2500], Train Loss: 0.7971, Train Accuracy: 66.15%, Test Loss: 0.9081, Test Accuracy: 62.03%\n",
      "Epoch [917/2500], Train Loss: 0.8026, Train Accuracy: 65.43%, Test Loss: 0.7750, Test Accuracy: 72.15%\n",
      "Epoch [918/2500], Train Loss: 0.7740, Train Accuracy: 66.29%, Test Loss: 0.8334, Test Accuracy: 63.29%\n",
      "Epoch [919/2500], Train Loss: 0.7748, Train Accuracy: 65.72%, Test Loss: 0.7948, Test Accuracy: 69.62%\n",
      "Epoch [920/2500], Train Loss: 0.7670, Train Accuracy: 65.01%, Test Loss: 0.7629, Test Accuracy: 63.29%\n",
      "Epoch [921/2500], Train Loss: 0.7823, Train Accuracy: 65.15%, Test Loss: 0.7946, Test Accuracy: 70.89%\n",
      "Epoch [922/2500], Train Loss: 0.7952, Train Accuracy: 67.71%, Test Loss: 0.7752, Test Accuracy: 68.35%\n",
      "Epoch [923/2500], Train Loss: 0.7874, Train Accuracy: 66.43%, Test Loss: 0.8275, Test Accuracy: 69.62%\n",
      "Epoch [924/2500], Train Loss: 0.7597, Train Accuracy: 67.43%, Test Loss: 0.7612, Test Accuracy: 73.42%\n",
      "Epoch [925/2500], Train Loss: 0.7615, Train Accuracy: 67.99%, Test Loss: 0.8315, Test Accuracy: 63.29%\n",
      "Epoch [926/2500], Train Loss: 0.8054, Train Accuracy: 65.86%, Test Loss: 0.7596, Test Accuracy: 64.56%\n",
      "Epoch [927/2500], Train Loss: 0.7888, Train Accuracy: 64.15%, Test Loss: 0.7915, Test Accuracy: 70.89%\n",
      "Epoch [928/2500], Train Loss: 0.7693, Train Accuracy: 67.14%, Test Loss: 0.7784, Test Accuracy: 72.15%\n",
      "Epoch [929/2500], Train Loss: 0.8129, Train Accuracy: 64.86%, Test Loss: 0.7986, Test Accuracy: 64.56%\n",
      "Epoch [930/2500], Train Loss: 0.7795, Train Accuracy: 66.29%, Test Loss: 0.7397, Test Accuracy: 70.89%\n",
      "Epoch [931/2500], Train Loss: 0.8094, Train Accuracy: 63.87%, Test Loss: 0.8214, Test Accuracy: 63.29%\n",
      "Epoch [932/2500], Train Loss: 0.7912, Train Accuracy: 67.57%, Test Loss: 0.9215, Test Accuracy: 60.76%\n",
      "Epoch [933/2500], Train Loss: 0.7669, Train Accuracy: 67.28%, Test Loss: 0.7377, Test Accuracy: 73.42%\n",
      "Epoch [934/2500], Train Loss: 0.7922, Train Accuracy: 67.00%, Test Loss: 0.8005, Test Accuracy: 63.29%\n",
      "Epoch [935/2500], Train Loss: 0.8155, Train Accuracy: 63.44%, Test Loss: 0.7547, Test Accuracy: 73.42%\n",
      "Epoch [936/2500], Train Loss: 0.7921, Train Accuracy: 65.15%, Test Loss: 0.7432, Test Accuracy: 72.15%\n",
      "Epoch [937/2500], Train Loss: 0.8269, Train Accuracy: 64.58%, Test Loss: 0.7854, Test Accuracy: 73.42%\n",
      "Epoch [938/2500], Train Loss: 0.7821, Train Accuracy: 67.14%, Test Loss: 0.7362, Test Accuracy: 69.62%\n",
      "Epoch [939/2500], Train Loss: 0.7875, Train Accuracy: 65.72%, Test Loss: 0.7882, Test Accuracy: 60.76%\n",
      "Epoch [940/2500], Train Loss: 0.7920, Train Accuracy: 64.44%, Test Loss: 0.8999, Test Accuracy: 62.03%\n",
      "Epoch [941/2500], Train Loss: 0.8057, Train Accuracy: 64.01%, Test Loss: 0.7559, Test Accuracy: 67.09%\n",
      "Epoch [942/2500], Train Loss: 0.7835, Train Accuracy: 65.58%, Test Loss: 0.7841, Test Accuracy: 67.09%\n",
      "Epoch [943/2500], Train Loss: 0.7711, Train Accuracy: 65.86%, Test Loss: 0.7730, Test Accuracy: 67.09%\n",
      "Epoch [944/2500], Train Loss: 0.7822, Train Accuracy: 67.57%, Test Loss: 0.7578, Test Accuracy: 73.42%\n",
      "Epoch [945/2500], Train Loss: 0.7905, Train Accuracy: 65.72%, Test Loss: 0.8694, Test Accuracy: 67.09%\n",
      "Epoch [946/2500], Train Loss: 0.7624, Train Accuracy: 66.71%, Test Loss: 0.7407, Test Accuracy: 64.56%\n",
      "Epoch [947/2500], Train Loss: 0.7743, Train Accuracy: 65.58%, Test Loss: 0.7323, Test Accuracy: 69.62%\n",
      "Epoch [948/2500], Train Loss: 0.7972, Train Accuracy: 65.58%, Test Loss: 0.7667, Test Accuracy: 68.35%\n",
      "Epoch [949/2500], Train Loss: 0.7830, Train Accuracy: 65.72%, Test Loss: 0.8549, Test Accuracy: 60.76%\n",
      "Epoch [950/2500], Train Loss: 0.7781, Train Accuracy: 67.14%, Test Loss: 0.7345, Test Accuracy: 69.62%\n",
      "Epoch [951/2500], Train Loss: 0.7691, Train Accuracy: 66.15%, Test Loss: 0.7851, Test Accuracy: 65.82%\n",
      "Epoch [952/2500], Train Loss: 0.7829, Train Accuracy: 64.01%, Test Loss: 0.7345, Test Accuracy: 69.62%\n",
      "Epoch [953/2500], Train Loss: 0.7757, Train Accuracy: 67.28%, Test Loss: 0.7471, Test Accuracy: 69.62%\n",
      "Epoch [954/2500], Train Loss: 0.7571, Train Accuracy: 67.43%, Test Loss: 0.8150, Test Accuracy: 68.35%\n",
      "Epoch [955/2500], Train Loss: 0.7974, Train Accuracy: 63.87%, Test Loss: 0.7720, Test Accuracy: 70.89%\n",
      "Epoch [956/2500], Train Loss: 0.7763, Train Accuracy: 67.28%, Test Loss: 0.7423, Test Accuracy: 64.56%\n",
      "Epoch [957/2500], Train Loss: 0.7800, Train Accuracy: 66.29%, Test Loss: 0.7932, Test Accuracy: 73.42%\n",
      "Epoch [958/2500], Train Loss: 0.7918, Train Accuracy: 66.86%, Test Loss: 0.7745, Test Accuracy: 72.15%\n",
      "Epoch [959/2500], Train Loss: 0.7763, Train Accuracy: 66.71%, Test Loss: 0.7377, Test Accuracy: 67.09%\n",
      "Epoch [960/2500], Train Loss: 0.7791, Train Accuracy: 67.14%, Test Loss: 0.7887, Test Accuracy: 67.09%\n",
      "Epoch [961/2500], Train Loss: 0.7840, Train Accuracy: 67.00%, Test Loss: 0.7584, Test Accuracy: 70.89%\n",
      "Epoch [962/2500], Train Loss: 0.7708, Train Accuracy: 66.43%, Test Loss: 0.7613, Test Accuracy: 69.62%\n",
      "Epoch [963/2500], Train Loss: 0.7986, Train Accuracy: 66.15%, Test Loss: 0.7924, Test Accuracy: 69.62%\n",
      "Epoch [964/2500], Train Loss: 0.7850, Train Accuracy: 65.58%, Test Loss: 0.7574, Test Accuracy: 69.62%\n",
      "Epoch [965/2500], Train Loss: 0.7783, Train Accuracy: 65.43%, Test Loss: 0.7423, Test Accuracy: 67.09%\n",
      "Epoch [966/2500], Train Loss: 0.7957, Train Accuracy: 66.29%, Test Loss: 0.7569, Test Accuracy: 64.56%\n",
      "Epoch [967/2500], Train Loss: 0.7879, Train Accuracy: 67.85%, Test Loss: 0.7414, Test Accuracy: 67.09%\n",
      "Epoch [968/2500], Train Loss: 0.8014, Train Accuracy: 66.00%, Test Loss: 0.8160, Test Accuracy: 70.89%\n",
      "Epoch [969/2500], Train Loss: 0.8006, Train Accuracy: 64.15%, Test Loss: 0.7620, Test Accuracy: 68.35%\n",
      "Epoch [970/2500], Train Loss: 0.8127, Train Accuracy: 65.86%, Test Loss: 0.7648, Test Accuracy: 68.35%\n",
      "Epoch [971/2500], Train Loss: 0.7568, Train Accuracy: 66.71%, Test Loss: 0.8215, Test Accuracy: 69.62%\n",
      "Epoch [972/2500], Train Loss: 0.7841, Train Accuracy: 66.43%, Test Loss: 0.7635, Test Accuracy: 68.35%\n",
      "Epoch [973/2500], Train Loss: 0.8043, Train Accuracy: 66.57%, Test Loss: 0.8200, Test Accuracy: 67.09%\n",
      "Epoch [974/2500], Train Loss: 0.7777, Train Accuracy: 65.86%, Test Loss: 0.7581, Test Accuracy: 68.35%\n",
      "Epoch [975/2500], Train Loss: 0.7918, Train Accuracy: 66.15%, Test Loss: 1.0525, Test Accuracy: 55.70%\n",
      "Epoch [976/2500], Train Loss: 0.7925, Train Accuracy: 65.15%, Test Loss: 0.8633, Test Accuracy: 64.56%\n",
      "Epoch [977/2500], Train Loss: 0.7709, Train Accuracy: 67.00%, Test Loss: 0.8269, Test Accuracy: 70.89%\n",
      "Epoch [978/2500], Train Loss: 0.7723, Train Accuracy: 66.29%, Test Loss: 0.7429, Test Accuracy: 68.35%\n",
      "Epoch [979/2500], Train Loss: 0.7713, Train Accuracy: 67.43%, Test Loss: 0.7765, Test Accuracy: 68.35%\n",
      "Epoch [980/2500], Train Loss: 0.7638, Train Accuracy: 66.43%, Test Loss: 0.9024, Test Accuracy: 59.49%\n",
      "Epoch [981/2500], Train Loss: 0.7882, Train Accuracy: 67.14%, Test Loss: 0.7335, Test Accuracy: 68.35%\n",
      "Epoch [982/2500], Train Loss: 0.7945, Train Accuracy: 67.28%, Test Loss: 0.7829, Test Accuracy: 68.35%\n",
      "Epoch [983/2500], Train Loss: 0.8069, Train Accuracy: 65.72%, Test Loss: 0.7439, Test Accuracy: 64.56%\n",
      "Epoch [984/2500], Train Loss: 0.7673, Train Accuracy: 68.42%, Test Loss: 0.7702, Test Accuracy: 69.62%\n",
      "Epoch [985/2500], Train Loss: 0.7486, Train Accuracy: 68.71%, Test Loss: 0.8381, Test Accuracy: 68.35%\n",
      "Epoch [986/2500], Train Loss: 0.7858, Train Accuracy: 67.00%, Test Loss: 0.7562, Test Accuracy: 72.15%\n",
      "Epoch [987/2500], Train Loss: 0.7648, Train Accuracy: 65.58%, Test Loss: 0.7616, Test Accuracy: 69.62%\n",
      "Epoch [988/2500], Train Loss: 0.8087, Train Accuracy: 64.58%, Test Loss: 0.7644, Test Accuracy: 70.89%\n",
      "Epoch [989/2500], Train Loss: 0.7904, Train Accuracy: 65.43%, Test Loss: 0.7420, Test Accuracy: 72.15%\n",
      "Epoch [990/2500], Train Loss: 0.7821, Train Accuracy: 67.99%, Test Loss: 0.7445, Test Accuracy: 70.89%\n",
      "Epoch [991/2500], Train Loss: 0.7849, Train Accuracy: 65.86%, Test Loss: 0.8261, Test Accuracy: 69.62%\n",
      "Epoch [992/2500], Train Loss: 0.7729, Train Accuracy: 65.29%, Test Loss: 0.7292, Test Accuracy: 65.82%\n",
      "Epoch [993/2500], Train Loss: 0.7742, Train Accuracy: 66.57%, Test Loss: 0.7344, Test Accuracy: 73.42%\n",
      "Epoch [994/2500], Train Loss: 0.7608, Train Accuracy: 65.01%, Test Loss: 0.8920, Test Accuracy: 64.56%\n",
      "Epoch [995/2500], Train Loss: 0.7846, Train Accuracy: 66.29%, Test Loss: 0.7762, Test Accuracy: 68.35%\n",
      "Epoch [996/2500], Train Loss: 0.7542, Train Accuracy: 67.85%, Test Loss: 0.7490, Test Accuracy: 70.89%\n",
      "Epoch [997/2500], Train Loss: 0.7969, Train Accuracy: 63.73%, Test Loss: 0.8483, Test Accuracy: 64.56%\n",
      "Epoch [998/2500], Train Loss: 0.7833, Train Accuracy: 65.72%, Test Loss: 0.8451, Test Accuracy: 68.35%\n",
      "Epoch [999/2500], Train Loss: 0.8014, Train Accuracy: 65.86%, Test Loss: 0.7685, Test Accuracy: 69.62%\n",
      "Epoch [1000/2500], Train Loss: 0.8056, Train Accuracy: 66.29%, Test Loss: 0.8578, Test Accuracy: 68.35%\n",
      "Epoch [1001/2500], Train Loss: 0.8159, Train Accuracy: 64.58%, Test Loss: 0.8589, Test Accuracy: 63.29%\n",
      "Epoch [1002/2500], Train Loss: 0.7953, Train Accuracy: 66.15%, Test Loss: 0.7670, Test Accuracy: 70.89%\n",
      "Epoch [1003/2500], Train Loss: 0.7891, Train Accuracy: 64.86%, Test Loss: 0.7846, Test Accuracy: 72.15%\n",
      "Epoch [1004/2500], Train Loss: 0.7950, Train Accuracy: 66.15%, Test Loss: 0.7531, Test Accuracy: 68.35%\n",
      "Epoch [1005/2500], Train Loss: 0.7824, Train Accuracy: 65.72%, Test Loss: 0.7386, Test Accuracy: 65.82%\n",
      "Epoch [1006/2500], Train Loss: 0.8073, Train Accuracy: 65.72%, Test Loss: 0.7651, Test Accuracy: 72.15%\n",
      "Epoch [1007/2500], Train Loss: 0.7644, Train Accuracy: 66.43%, Test Loss: 0.7500, Test Accuracy: 69.62%\n",
      "Epoch [1008/2500], Train Loss: 0.7709, Train Accuracy: 67.71%, Test Loss: 0.7742, Test Accuracy: 70.89%\n",
      "Epoch [1009/2500], Train Loss: 0.7709, Train Accuracy: 66.00%, Test Loss: 0.7839, Test Accuracy: 68.35%\n",
      "Epoch [1010/2500], Train Loss: 0.7652, Train Accuracy: 64.44%, Test Loss: 0.7465, Test Accuracy: 64.56%\n",
      "Epoch [1011/2500], Train Loss: 0.8002, Train Accuracy: 65.72%, Test Loss: 0.8449, Test Accuracy: 64.56%\n",
      "Epoch [1012/2500], Train Loss: 0.7983, Train Accuracy: 67.57%, Test Loss: 0.8970, Test Accuracy: 62.03%\n",
      "Epoch [1013/2500], Train Loss: 0.8046, Train Accuracy: 63.73%, Test Loss: 0.7871, Test Accuracy: 70.89%\n",
      "Epoch [1014/2500], Train Loss: 0.7929, Train Accuracy: 65.86%, Test Loss: 0.7956, Test Accuracy: 65.82%\n",
      "Epoch [1015/2500], Train Loss: 0.7497, Train Accuracy: 65.86%, Test Loss: 0.7347, Test Accuracy: 67.09%\n",
      "Epoch [1016/2500], Train Loss: 0.7789, Train Accuracy: 65.58%, Test Loss: 0.8071, Test Accuracy: 64.56%\n",
      "Epoch [1017/2500], Train Loss: 0.7737, Train Accuracy: 66.29%, Test Loss: 0.7973, Test Accuracy: 70.89%\n",
      "Epoch [1018/2500], Train Loss: 0.7834, Train Accuracy: 67.28%, Test Loss: 0.8119, Test Accuracy: 67.09%\n",
      "Epoch [1019/2500], Train Loss: 0.7756, Train Accuracy: 66.29%, Test Loss: 0.8012, Test Accuracy: 68.35%\n",
      "Epoch [1020/2500], Train Loss: 0.7707, Train Accuracy: 66.86%, Test Loss: 0.9117, Test Accuracy: 68.35%\n",
      "Epoch [1021/2500], Train Loss: 0.7820, Train Accuracy: 65.15%, Test Loss: 0.7695, Test Accuracy: 70.89%\n",
      "Epoch [1022/2500], Train Loss: 0.7728, Train Accuracy: 65.86%, Test Loss: 0.8606, Test Accuracy: 62.03%\n",
      "Epoch [1023/2500], Train Loss: 0.7706, Train Accuracy: 66.15%, Test Loss: 0.7999, Test Accuracy: 67.09%\n",
      "Epoch [1024/2500], Train Loss: 0.7889, Train Accuracy: 67.00%, Test Loss: 0.7335, Test Accuracy: 70.89%\n",
      "Epoch [1025/2500], Train Loss: 0.7776, Train Accuracy: 67.14%, Test Loss: 0.7603, Test Accuracy: 70.89%\n",
      "Epoch [1026/2500], Train Loss: 0.8035, Train Accuracy: 66.15%, Test Loss: 0.7877, Test Accuracy: 67.09%\n",
      "Epoch [1027/2500], Train Loss: 0.8041, Train Accuracy: 66.15%, Test Loss: 0.7687, Test Accuracy: 69.62%\n",
      "Epoch [1028/2500], Train Loss: 0.7718, Train Accuracy: 65.43%, Test Loss: 0.7518, Test Accuracy: 63.29%\n",
      "Epoch [1029/2500], Train Loss: 0.7583, Train Accuracy: 68.42%, Test Loss: 0.7558, Test Accuracy: 69.62%\n",
      "Epoch [1030/2500], Train Loss: 0.7899, Train Accuracy: 66.57%, Test Loss: 0.9331, Test Accuracy: 62.03%\n",
      "Epoch [1031/2500], Train Loss: 0.7696, Train Accuracy: 66.29%, Test Loss: 0.8859, Test Accuracy: 62.03%\n",
      "Epoch [1032/2500], Train Loss: 0.7843, Train Accuracy: 67.00%, Test Loss: 0.7645, Test Accuracy: 72.15%\n",
      "Epoch [1033/2500], Train Loss: 0.7600, Train Accuracy: 66.15%, Test Loss: 0.7549, Test Accuracy: 72.15%\n",
      "Epoch [1034/2500], Train Loss: 0.7759, Train Accuracy: 64.58%, Test Loss: 0.7382, Test Accuracy: 69.62%\n",
      "Epoch [1035/2500], Train Loss: 0.7873, Train Accuracy: 66.71%, Test Loss: 0.7638, Test Accuracy: 67.09%\n",
      "Epoch [1036/2500], Train Loss: 0.8068, Train Accuracy: 65.86%, Test Loss: 0.8097, Test Accuracy: 65.82%\n",
      "Epoch [1037/2500], Train Loss: 0.7548, Train Accuracy: 67.43%, Test Loss: 0.9288, Test Accuracy: 59.49%\n",
      "Epoch [1038/2500], Train Loss: 0.7916, Train Accuracy: 65.86%, Test Loss: 0.7918, Test Accuracy: 68.35%\n",
      "Epoch [1039/2500], Train Loss: 0.7783, Train Accuracy: 65.15%, Test Loss: 0.8121, Test Accuracy: 65.82%\n",
      "Epoch [1040/2500], Train Loss: 0.7787, Train Accuracy: 66.57%, Test Loss: 0.7716, Test Accuracy: 73.42%\n",
      "Epoch [1041/2500], Train Loss: 0.7849, Train Accuracy: 66.29%, Test Loss: 0.8851, Test Accuracy: 63.29%\n",
      "Epoch [1042/2500], Train Loss: 0.7703, Train Accuracy: 67.00%, Test Loss: 0.8250, Test Accuracy: 67.09%\n",
      "Epoch [1043/2500], Train Loss: 0.7848, Train Accuracy: 66.15%, Test Loss: 0.8747, Test Accuracy: 69.62%\n",
      "Epoch [1044/2500], Train Loss: 0.7930, Train Accuracy: 63.58%, Test Loss: 0.9700, Test Accuracy: 60.76%\n",
      "Epoch [1045/2500], Train Loss: 0.7970, Train Accuracy: 65.72%, Test Loss: 0.7651, Test Accuracy: 64.56%\n",
      "Epoch [1046/2500], Train Loss: 0.7940, Train Accuracy: 64.86%, Test Loss: 0.8187, Test Accuracy: 69.62%\n",
      "Epoch [1047/2500], Train Loss: 0.8081, Train Accuracy: 66.00%, Test Loss: 0.7845, Test Accuracy: 72.15%\n",
      "Epoch [1048/2500], Train Loss: 0.7861, Train Accuracy: 67.28%, Test Loss: 0.7675, Test Accuracy: 68.35%\n",
      "Epoch [1049/2500], Train Loss: 0.7966, Train Accuracy: 66.57%, Test Loss: 0.7318, Test Accuracy: 65.82%\n",
      "Epoch [1050/2500], Train Loss: 0.7748, Train Accuracy: 66.29%, Test Loss: 0.7570, Test Accuracy: 73.42%\n",
      "Epoch [1051/2500], Train Loss: 0.8003, Train Accuracy: 65.58%, Test Loss: 0.7632, Test Accuracy: 74.68%\n",
      "Epoch [1052/2500], Train Loss: 0.7857, Train Accuracy: 66.29%, Test Loss: 0.7458, Test Accuracy: 75.95%\n",
      "Epoch [1053/2500], Train Loss: 0.7791, Train Accuracy: 66.29%, Test Loss: 0.8161, Test Accuracy: 68.35%\n",
      "Epoch [1054/2500], Train Loss: 0.7759, Train Accuracy: 66.57%, Test Loss: 0.7485, Test Accuracy: 70.89%\n",
      "Epoch [1055/2500], Train Loss: 0.7776, Train Accuracy: 66.86%, Test Loss: 0.7499, Test Accuracy: 70.89%\n",
      "Epoch [1056/2500], Train Loss: 0.7902, Train Accuracy: 64.15%, Test Loss: 0.8170, Test Accuracy: 65.82%\n",
      "Epoch [1057/2500], Train Loss: 0.7893, Train Accuracy: 66.71%, Test Loss: 0.7865, Test Accuracy: 69.62%\n",
      "Epoch [1058/2500], Train Loss: 0.7894, Train Accuracy: 65.86%, Test Loss: 0.7631, Test Accuracy: 74.68%\n",
      "Epoch [1059/2500], Train Loss: 0.7590, Train Accuracy: 66.15%, Test Loss: 0.8084, Test Accuracy: 69.62%\n",
      "Epoch [1060/2500], Train Loss: 0.7723, Train Accuracy: 65.72%, Test Loss: 0.7821, Test Accuracy: 64.56%\n",
      "Epoch [1061/2500], Train Loss: 0.7899, Train Accuracy: 63.73%, Test Loss: 0.8665, Test Accuracy: 64.56%\n",
      "Epoch [1062/2500], Train Loss: 0.7860, Train Accuracy: 67.85%, Test Loss: 0.8015, Test Accuracy: 67.09%\n",
      "Epoch [1063/2500], Train Loss: 0.8088, Train Accuracy: 66.86%, Test Loss: 0.8120, Test Accuracy: 68.35%\n",
      "Epoch [1064/2500], Train Loss: 0.7696, Train Accuracy: 67.99%, Test Loss: 0.7859, Test Accuracy: 69.62%\n",
      "Epoch [1065/2500], Train Loss: 0.7691, Train Accuracy: 66.43%, Test Loss: 0.7311, Test Accuracy: 67.09%\n",
      "Epoch [1066/2500], Train Loss: 0.7739, Train Accuracy: 65.43%, Test Loss: 0.7978, Test Accuracy: 72.15%\n",
      "Epoch [1067/2500], Train Loss: 0.8009, Train Accuracy: 65.58%, Test Loss: 0.7387, Test Accuracy: 70.89%\n",
      "Epoch [1068/2500], Train Loss: 0.7995, Train Accuracy: 63.87%, Test Loss: 0.7874, Test Accuracy: 70.89%\n",
      "Epoch [1069/2500], Train Loss: 0.7856, Train Accuracy: 65.72%, Test Loss: 0.7413, Test Accuracy: 67.09%\n",
      "Epoch [1070/2500], Train Loss: 0.7863, Train Accuracy: 66.43%, Test Loss: 0.7865, Test Accuracy: 67.09%\n",
      "Epoch [1071/2500], Train Loss: 0.7811, Train Accuracy: 67.28%, Test Loss: 0.8189, Test Accuracy: 65.82%\n",
      "Epoch [1072/2500], Train Loss: 0.7513, Train Accuracy: 66.86%, Test Loss: 0.9004, Test Accuracy: 62.03%\n",
      "Epoch [1073/2500], Train Loss: 0.7634, Train Accuracy: 66.71%, Test Loss: 0.7625, Test Accuracy: 69.62%\n",
      "Epoch [1074/2500], Train Loss: 0.7933, Train Accuracy: 65.29%, Test Loss: 0.7546, Test Accuracy: 73.42%\n",
      "Epoch [1075/2500], Train Loss: 0.7956, Train Accuracy: 65.43%, Test Loss: 0.7363, Test Accuracy: 67.09%\n",
      "Epoch [1076/2500], Train Loss: 0.7757, Train Accuracy: 66.43%, Test Loss: 0.7514, Test Accuracy: 73.42%\n",
      "Epoch [1077/2500], Train Loss: 0.7750, Train Accuracy: 65.29%, Test Loss: 0.7644, Test Accuracy: 68.35%\n",
      "Epoch [1078/2500], Train Loss: 0.7960, Train Accuracy: 64.44%, Test Loss: 1.0590, Test Accuracy: 58.23%\n",
      "Epoch [1079/2500], Train Loss: 0.7853, Train Accuracy: 67.57%, Test Loss: 0.7404, Test Accuracy: 67.09%\n",
      "Epoch [1080/2500], Train Loss: 0.7819, Train Accuracy: 67.14%, Test Loss: 0.7520, Test Accuracy: 65.82%\n",
      "Epoch [1081/2500], Train Loss: 0.7439, Train Accuracy: 67.99%, Test Loss: 0.8025, Test Accuracy: 68.35%\n",
      "Epoch [1082/2500], Train Loss: 0.7588, Train Accuracy: 66.15%, Test Loss: 0.8258, Test Accuracy: 68.35%\n",
      "Epoch [1083/2500], Train Loss: 0.7575, Train Accuracy: 67.99%, Test Loss: 0.7785, Test Accuracy: 69.62%\n",
      "Epoch [1084/2500], Train Loss: 0.7936, Train Accuracy: 67.14%, Test Loss: 0.8042, Test Accuracy: 67.09%\n",
      "Epoch [1085/2500], Train Loss: 0.7849, Train Accuracy: 65.86%, Test Loss: 0.8633, Test Accuracy: 65.82%\n",
      "Epoch [1086/2500], Train Loss: 0.7978, Train Accuracy: 66.57%, Test Loss: 0.7663, Test Accuracy: 68.35%\n",
      "Epoch [1087/2500], Train Loss: 0.7956, Train Accuracy: 65.58%, Test Loss: 0.8279, Test Accuracy: 64.56%\n",
      "Epoch [1088/2500], Train Loss: 0.7837, Train Accuracy: 66.86%, Test Loss: 0.7831, Test Accuracy: 67.09%\n",
      "Epoch [1089/2500], Train Loss: 0.7988, Train Accuracy: 64.01%, Test Loss: 0.8100, Test Accuracy: 72.15%\n",
      "Epoch [1090/2500], Train Loss: 0.7702, Train Accuracy: 67.99%, Test Loss: 0.7880, Test Accuracy: 64.56%\n",
      "Epoch [1091/2500], Train Loss: 0.7692, Train Accuracy: 67.71%, Test Loss: 0.7527, Test Accuracy: 70.89%\n",
      "Epoch [1092/2500], Train Loss: 0.7735, Train Accuracy: 65.86%, Test Loss: 0.7879, Test Accuracy: 73.42%\n",
      "Epoch [1093/2500], Train Loss: 0.7769, Train Accuracy: 67.99%, Test Loss: 0.8500, Test Accuracy: 68.35%\n",
      "Epoch [1094/2500], Train Loss: 0.7715, Train Accuracy: 67.43%, Test Loss: 0.7970, Test Accuracy: 73.42%\n",
      "Epoch [1095/2500], Train Loss: 0.7872, Train Accuracy: 66.71%, Test Loss: 0.8101, Test Accuracy: 68.35%\n",
      "Epoch [1096/2500], Train Loss: 0.7756, Train Accuracy: 66.43%, Test Loss: 0.8429, Test Accuracy: 62.03%\n",
      "Epoch [1097/2500], Train Loss: 0.7747, Train Accuracy: 66.43%, Test Loss: 0.8124, Test Accuracy: 67.09%\n",
      "Epoch [1098/2500], Train Loss: 0.7715, Train Accuracy: 67.57%, Test Loss: 0.7507, Test Accuracy: 70.89%\n",
      "Epoch [1099/2500], Train Loss: 0.7621, Train Accuracy: 68.56%, Test Loss: 0.7666, Test Accuracy: 68.35%\n",
      "Epoch [1100/2500], Train Loss: 0.7912, Train Accuracy: 64.72%, Test Loss: 0.7958, Test Accuracy: 72.15%\n",
      "Epoch [1101/2500], Train Loss: 0.7961, Train Accuracy: 66.57%, Test Loss: 0.7679, Test Accuracy: 69.62%\n",
      "Epoch [1102/2500], Train Loss: 0.7524, Train Accuracy: 68.28%, Test Loss: 0.7360, Test Accuracy: 63.29%\n",
      "Epoch [1103/2500], Train Loss: 0.7608, Train Accuracy: 67.57%, Test Loss: 0.7792, Test Accuracy: 73.42%\n",
      "Epoch [1104/2500], Train Loss: 0.8029, Train Accuracy: 65.72%, Test Loss: 0.8152, Test Accuracy: 73.42%\n",
      "Epoch [1105/2500], Train Loss: 0.7815, Train Accuracy: 65.86%, Test Loss: 0.8903, Test Accuracy: 67.09%\n",
      "Epoch [1106/2500], Train Loss: 0.8007, Train Accuracy: 65.86%, Test Loss: 0.8042, Test Accuracy: 65.82%\n",
      "Epoch [1107/2500], Train Loss: 0.7764, Train Accuracy: 66.00%, Test Loss: 0.7385, Test Accuracy: 70.89%\n",
      "Epoch [1108/2500], Train Loss: 0.7784, Train Accuracy: 66.43%, Test Loss: 0.8682, Test Accuracy: 65.82%\n",
      "Epoch [1109/2500], Train Loss: 0.7991, Train Accuracy: 66.71%, Test Loss: 0.8206, Test Accuracy: 69.62%\n",
      "Epoch [1110/2500], Train Loss: 0.7646, Train Accuracy: 65.86%, Test Loss: 0.7829, Test Accuracy: 72.15%\n",
      "Epoch [1111/2500], Train Loss: 0.8029, Train Accuracy: 65.86%, Test Loss: 0.8174, Test Accuracy: 70.89%\n",
      "Epoch [1112/2500], Train Loss: 0.7861, Train Accuracy: 65.01%, Test Loss: 0.7600, Test Accuracy: 65.82%\n",
      "Epoch [1113/2500], Train Loss: 0.7725, Train Accuracy: 65.58%, Test Loss: 0.8632, Test Accuracy: 65.82%\n",
      "Epoch [1114/2500], Train Loss: 0.7588, Train Accuracy: 66.43%, Test Loss: 0.7447, Test Accuracy: 69.62%\n",
      "Epoch [1115/2500], Train Loss: 0.7757, Train Accuracy: 68.85%, Test Loss: 0.7676, Test Accuracy: 68.35%\n",
      "Epoch [1116/2500], Train Loss: 0.7814, Train Accuracy: 65.86%, Test Loss: 0.7388, Test Accuracy: 65.82%\n",
      "Epoch [1117/2500], Train Loss: 0.7836, Train Accuracy: 67.57%, Test Loss: 0.7517, Test Accuracy: 69.62%\n",
      "Epoch [1118/2500], Train Loss: 0.8067, Train Accuracy: 65.15%, Test Loss: 0.7766, Test Accuracy: 70.89%\n",
      "Epoch [1119/2500], Train Loss: 0.7997, Train Accuracy: 65.29%, Test Loss: 0.7680, Test Accuracy: 69.62%\n",
      "Epoch [1120/2500], Train Loss: 0.7963, Train Accuracy: 65.58%, Test Loss: 0.7819, Test Accuracy: 67.09%\n",
      "Epoch [1121/2500], Train Loss: 0.7838, Train Accuracy: 65.43%, Test Loss: 0.7386, Test Accuracy: 68.35%\n",
      "Epoch [1122/2500], Train Loss: 0.7921, Train Accuracy: 63.44%, Test Loss: 0.7637, Test Accuracy: 69.62%\n",
      "Epoch [1123/2500], Train Loss: 0.7862, Train Accuracy: 65.01%, Test Loss: 0.8469, Test Accuracy: 64.56%\n",
      "Epoch [1124/2500], Train Loss: 0.8067, Train Accuracy: 64.44%, Test Loss: 0.7160, Test Accuracy: 72.15%\n",
      "Epoch [1125/2500], Train Loss: 0.7522, Train Accuracy: 67.28%, Test Loss: 0.7972, Test Accuracy: 65.82%\n",
      "Epoch [1126/2500], Train Loss: 0.7681, Train Accuracy: 66.15%, Test Loss: 0.8695, Test Accuracy: 64.56%\n",
      "Epoch [1127/2500], Train Loss: 0.7984, Train Accuracy: 65.58%, Test Loss: 0.7648, Test Accuracy: 65.82%\n",
      "Epoch [1128/2500], Train Loss: 0.7605, Train Accuracy: 67.85%, Test Loss: 0.7764, Test Accuracy: 69.62%\n",
      "Epoch [1129/2500], Train Loss: 0.7595, Train Accuracy: 68.14%, Test Loss: 0.7501, Test Accuracy: 72.15%\n",
      "Epoch [1130/2500], Train Loss: 0.7713, Train Accuracy: 67.71%, Test Loss: 0.7573, Test Accuracy: 67.09%\n",
      "Epoch [1131/2500], Train Loss: 0.7879, Train Accuracy: 65.43%, Test Loss: 0.7378, Test Accuracy: 68.35%\n",
      "Epoch [1132/2500], Train Loss: 0.7755, Train Accuracy: 67.99%, Test Loss: 0.7444, Test Accuracy: 67.09%\n",
      "Epoch [1133/2500], Train Loss: 0.7663, Train Accuracy: 65.86%, Test Loss: 0.7936, Test Accuracy: 65.82%\n",
      "Epoch [1134/2500], Train Loss: 0.7862, Train Accuracy: 67.71%, Test Loss: 0.8311, Test Accuracy: 63.29%\n",
      "Epoch [1135/2500], Train Loss: 0.7709, Train Accuracy: 66.29%, Test Loss: 0.7393, Test Accuracy: 70.89%\n",
      "Epoch [1136/2500], Train Loss: 0.7911, Train Accuracy: 65.15%, Test Loss: 0.7610, Test Accuracy: 72.15%\n",
      "Epoch [1137/2500], Train Loss: 0.7719, Train Accuracy: 67.14%, Test Loss: 0.7741, Test Accuracy: 74.68%\n",
      "Epoch [1138/2500], Train Loss: 0.7521, Train Accuracy: 69.42%, Test Loss: 0.7390, Test Accuracy: 68.35%\n",
      "Epoch [1139/2500], Train Loss: 0.7731, Train Accuracy: 66.57%, Test Loss: 0.9077, Test Accuracy: 65.82%\n",
      "Epoch [1140/2500], Train Loss: 0.7892, Train Accuracy: 67.57%, Test Loss: 0.7603, Test Accuracy: 69.62%\n",
      "Epoch [1141/2500], Train Loss: 0.7837, Train Accuracy: 65.72%, Test Loss: 0.8542, Test Accuracy: 62.03%\n",
      "Epoch [1142/2500], Train Loss: 0.7812, Train Accuracy: 66.57%, Test Loss: 0.8131, Test Accuracy: 65.82%\n",
      "Epoch [1143/2500], Train Loss: 0.7719, Train Accuracy: 66.15%, Test Loss: 0.7783, Test Accuracy: 69.62%\n",
      "Epoch [1144/2500], Train Loss: 0.7731, Train Accuracy: 65.86%, Test Loss: 0.7527, Test Accuracy: 68.35%\n",
      "Epoch [1145/2500], Train Loss: 0.7780, Train Accuracy: 65.72%, Test Loss: 0.7592, Test Accuracy: 70.89%\n",
      "Epoch [1146/2500], Train Loss: 0.7930, Train Accuracy: 66.71%, Test Loss: 0.7359, Test Accuracy: 68.35%\n",
      "Epoch [1147/2500], Train Loss: 0.7919, Train Accuracy: 65.43%, Test Loss: 0.7778, Test Accuracy: 65.82%\n",
      "Epoch [1148/2500], Train Loss: 0.7901, Train Accuracy: 65.72%, Test Loss: 0.7594, Test Accuracy: 73.42%\n",
      "Epoch [1149/2500], Train Loss: 0.7932, Train Accuracy: 64.72%, Test Loss: 0.7938, Test Accuracy: 67.09%\n",
      "Epoch [1150/2500], Train Loss: 0.7821, Train Accuracy: 68.42%, Test Loss: 0.8718, Test Accuracy: 63.29%\n",
      "Epoch [1151/2500], Train Loss: 0.7612, Train Accuracy: 66.29%, Test Loss: 0.8416, Test Accuracy: 63.29%\n",
      "Epoch [1152/2500], Train Loss: 0.7697, Train Accuracy: 66.86%, Test Loss: 0.7663, Test Accuracy: 73.42%\n",
      "Epoch [1153/2500], Train Loss: 0.7674, Train Accuracy: 67.14%, Test Loss: 0.7595, Test Accuracy: 70.89%\n",
      "Epoch [1154/2500], Train Loss: 0.7802, Train Accuracy: 66.71%, Test Loss: 0.7483, Test Accuracy: 67.09%\n",
      "Epoch [1155/2500], Train Loss: 0.7818, Train Accuracy: 67.14%, Test Loss: 0.7828, Test Accuracy: 74.68%\n",
      "Epoch [1156/2500], Train Loss: 0.7650, Train Accuracy: 67.00%, Test Loss: 0.7830, Test Accuracy: 65.82%\n",
      "Epoch [1157/2500], Train Loss: 0.7674, Train Accuracy: 67.14%, Test Loss: 0.7221, Test Accuracy: 68.35%\n",
      "Epoch [1158/2500], Train Loss: 0.7590, Train Accuracy: 67.85%, Test Loss: 0.7358, Test Accuracy: 72.15%\n",
      "Epoch [1159/2500], Train Loss: 0.7752, Train Accuracy: 67.28%, Test Loss: 0.8377, Test Accuracy: 70.89%\n",
      "Epoch [1160/2500], Train Loss: 0.7591, Train Accuracy: 67.57%, Test Loss: 0.7631, Test Accuracy: 73.42%\n",
      "Epoch [1161/2500], Train Loss: 0.8001, Train Accuracy: 65.29%, Test Loss: 0.7979, Test Accuracy: 67.09%\n",
      "Epoch [1162/2500], Train Loss: 0.8035, Train Accuracy: 66.00%, Test Loss: 0.7981, Test Accuracy: 67.09%\n",
      "Epoch [1163/2500], Train Loss: 0.7660, Train Accuracy: 67.57%, Test Loss: 0.7405, Test Accuracy: 69.62%\n",
      "Epoch [1164/2500], Train Loss: 0.7790, Train Accuracy: 65.15%, Test Loss: 0.7847, Test Accuracy: 73.42%\n",
      "Epoch [1165/2500], Train Loss: 0.7577, Train Accuracy: 67.14%, Test Loss: 0.7408, Test Accuracy: 69.62%\n",
      "Epoch [1166/2500], Train Loss: 0.7770, Train Accuracy: 65.43%, Test Loss: 0.8943, Test Accuracy: 65.82%\n",
      "Epoch [1167/2500], Train Loss: 0.7728, Train Accuracy: 67.28%, Test Loss: 0.7739, Test Accuracy: 70.89%\n",
      "Epoch [1168/2500], Train Loss: 0.7489, Train Accuracy: 66.15%, Test Loss: 0.8299, Test Accuracy: 67.09%\n",
      "Epoch [1169/2500], Train Loss: 0.7730, Train Accuracy: 67.14%, Test Loss: 0.7763, Test Accuracy: 69.62%\n",
      "Epoch [1170/2500], Train Loss: 0.7825, Train Accuracy: 67.00%, Test Loss: 0.7516, Test Accuracy: 68.35%\n",
      "Epoch [1171/2500], Train Loss: 0.7936, Train Accuracy: 64.44%, Test Loss: 0.7305, Test Accuracy: 67.09%\n",
      "Epoch [1172/2500], Train Loss: 0.7983, Train Accuracy: 65.29%, Test Loss: 0.7491, Test Accuracy: 72.15%\n",
      "Epoch [1173/2500], Train Loss: 0.7994, Train Accuracy: 64.15%, Test Loss: 0.8366, Test Accuracy: 63.29%\n",
      "Epoch [1174/2500], Train Loss: 0.7794, Train Accuracy: 64.86%, Test Loss: 0.8801, Test Accuracy: 65.82%\n",
      "Epoch [1175/2500], Train Loss: 0.7975, Train Accuracy: 66.29%, Test Loss: 0.8157, Test Accuracy: 68.35%\n",
      "Epoch [1176/2500], Train Loss: 0.7832, Train Accuracy: 65.86%, Test Loss: 0.8027, Test Accuracy: 67.09%\n",
      "Epoch [1177/2500], Train Loss: 0.7980, Train Accuracy: 65.72%, Test Loss: 0.7659, Test Accuracy: 70.89%\n",
      "Epoch [1178/2500], Train Loss: 0.7650, Train Accuracy: 64.01%, Test Loss: 0.7977, Test Accuracy: 64.56%\n",
      "Epoch [1179/2500], Train Loss: 0.7833, Train Accuracy: 66.86%, Test Loss: 0.7639, Test Accuracy: 72.15%\n",
      "Epoch [1180/2500], Train Loss: 0.7892, Train Accuracy: 65.43%, Test Loss: 0.7606, Test Accuracy: 69.62%\n",
      "Epoch [1181/2500], Train Loss: 0.7862, Train Accuracy: 64.30%, Test Loss: 0.7621, Test Accuracy: 74.68%\n",
      "Epoch [1182/2500], Train Loss: 0.7674, Train Accuracy: 66.86%, Test Loss: 0.7441, Test Accuracy: 70.89%\n",
      "Epoch [1183/2500], Train Loss: 0.7582, Train Accuracy: 67.99%, Test Loss: 0.7950, Test Accuracy: 69.62%\n",
      "Epoch [1184/2500], Train Loss: 0.7912, Train Accuracy: 65.29%, Test Loss: 0.7951, Test Accuracy: 69.62%\n",
      "Epoch [1185/2500], Train Loss: 0.7783, Train Accuracy: 66.71%, Test Loss: 0.7540, Test Accuracy: 67.09%\n",
      "Epoch [1186/2500], Train Loss: 0.8019, Train Accuracy: 65.58%, Test Loss: 0.7842, Test Accuracy: 68.35%\n",
      "Epoch [1187/2500], Train Loss: 0.7605, Train Accuracy: 67.43%, Test Loss: 0.7503, Test Accuracy: 68.35%\n",
      "Epoch [1188/2500], Train Loss: 0.7546, Train Accuracy: 65.29%, Test Loss: 0.7629, Test Accuracy: 74.68%\n",
      "Epoch [1189/2500], Train Loss: 0.7724, Train Accuracy: 65.58%, Test Loss: 0.7417, Test Accuracy: 69.62%\n",
      "Epoch [1190/2500], Train Loss: 0.7820, Train Accuracy: 65.29%, Test Loss: 0.7434, Test Accuracy: 72.15%\n",
      "Epoch [1191/2500], Train Loss: 0.7724, Train Accuracy: 67.28%, Test Loss: 0.7366, Test Accuracy: 67.09%\n",
      "Epoch [1192/2500], Train Loss: 0.7374, Train Accuracy: 67.85%, Test Loss: 0.7580, Test Accuracy: 69.62%\n",
      "Epoch [1193/2500], Train Loss: 0.7700, Train Accuracy: 65.72%, Test Loss: 0.7191, Test Accuracy: 67.09%\n",
      "Epoch [1194/2500], Train Loss: 0.7547, Train Accuracy: 67.85%, Test Loss: 0.7744, Test Accuracy: 70.89%\n",
      "Epoch [1195/2500], Train Loss: 0.7656, Train Accuracy: 67.43%, Test Loss: 0.7411, Test Accuracy: 68.35%\n",
      "Epoch [1196/2500], Train Loss: 0.7842, Train Accuracy: 65.86%, Test Loss: 0.7662, Test Accuracy: 65.82%\n",
      "Epoch [1197/2500], Train Loss: 0.7743, Train Accuracy: 66.43%, Test Loss: 0.8435, Test Accuracy: 62.03%\n",
      "Epoch [1198/2500], Train Loss: 0.7708, Train Accuracy: 67.57%, Test Loss: 0.8862, Test Accuracy: 67.09%\n",
      "Epoch [1199/2500], Train Loss: 0.7536, Train Accuracy: 67.57%, Test Loss: 0.8536, Test Accuracy: 60.76%\n",
      "Epoch [1200/2500], Train Loss: 0.8065, Train Accuracy: 64.44%, Test Loss: 0.8212, Test Accuracy: 65.82%\n",
      "Epoch [1201/2500], Train Loss: 0.7805, Train Accuracy: 64.44%, Test Loss: 0.8018, Test Accuracy: 70.89%\n",
      "Epoch [1202/2500], Train Loss: 0.7967, Train Accuracy: 66.15%, Test Loss: 0.8400, Test Accuracy: 67.09%\n",
      "Epoch [1203/2500], Train Loss: 0.7653, Train Accuracy: 66.43%, Test Loss: 0.7910, Test Accuracy: 67.09%\n",
      "Epoch [1204/2500], Train Loss: 0.7824, Train Accuracy: 66.15%, Test Loss: 0.7497, Test Accuracy: 72.15%\n",
      "Epoch [1205/2500], Train Loss: 0.8000, Train Accuracy: 66.43%, Test Loss: 0.7974, Test Accuracy: 70.89%\n",
      "Epoch [1206/2500], Train Loss: 0.7829, Train Accuracy: 65.43%, Test Loss: 0.7320, Test Accuracy: 69.62%\n",
      "Epoch [1207/2500], Train Loss: 0.7762, Train Accuracy: 65.15%, Test Loss: 0.7448, Test Accuracy: 67.09%\n",
      "Epoch [1208/2500], Train Loss: 0.7578, Train Accuracy: 66.00%, Test Loss: 0.7382, Test Accuracy: 69.62%\n",
      "Epoch [1209/2500], Train Loss: 0.7669, Train Accuracy: 65.86%, Test Loss: 0.7748, Test Accuracy: 70.89%\n",
      "Epoch [1210/2500], Train Loss: 0.7840, Train Accuracy: 65.29%, Test Loss: 0.7359, Test Accuracy: 64.56%\n",
      "Epoch [1211/2500], Train Loss: 0.7919, Train Accuracy: 64.44%, Test Loss: 0.8558, Test Accuracy: 65.82%\n",
      "Epoch [1212/2500], Train Loss: 0.7808, Train Accuracy: 66.71%, Test Loss: 0.8785, Test Accuracy: 63.29%\n",
      "Epoch [1213/2500], Train Loss: 0.7775, Train Accuracy: 66.00%, Test Loss: 0.7443, Test Accuracy: 62.03%\n",
      "Epoch [1214/2500], Train Loss: 0.7725, Train Accuracy: 64.01%, Test Loss: 0.7959, Test Accuracy: 72.15%\n",
      "Epoch [1215/2500], Train Loss: 0.7588, Train Accuracy: 66.57%, Test Loss: 0.7355, Test Accuracy: 68.35%\n",
      "Epoch [1216/2500], Train Loss: 0.7636, Train Accuracy: 66.00%, Test Loss: 0.7387, Test Accuracy: 65.82%\n",
      "Epoch [1217/2500], Train Loss: 0.7799, Train Accuracy: 66.43%, Test Loss: 0.8112, Test Accuracy: 68.35%\n",
      "Epoch [1218/2500], Train Loss: 0.7672, Train Accuracy: 67.43%, Test Loss: 0.7352, Test Accuracy: 70.89%\n",
      "Epoch [1219/2500], Train Loss: 0.7624, Train Accuracy: 67.28%, Test Loss: 0.7385, Test Accuracy: 73.42%\n",
      "Epoch [1220/2500], Train Loss: 0.7789, Train Accuracy: 66.43%, Test Loss: 0.7367, Test Accuracy: 68.35%\n",
      "Epoch [1221/2500], Train Loss: 0.7621, Train Accuracy: 67.14%, Test Loss: 0.7384, Test Accuracy: 70.89%\n",
      "Epoch [1222/2500], Train Loss: 0.7766, Train Accuracy: 66.29%, Test Loss: 0.8014, Test Accuracy: 69.62%\n",
      "Epoch [1223/2500], Train Loss: 0.7834, Train Accuracy: 66.43%, Test Loss: 0.7507, Test Accuracy: 67.09%\n",
      "Epoch [1224/2500], Train Loss: 0.7544, Train Accuracy: 68.56%, Test Loss: 0.7580, Test Accuracy: 72.15%\n",
      "Epoch [1225/2500], Train Loss: 0.7607, Train Accuracy: 65.29%, Test Loss: 0.7822, Test Accuracy: 67.09%\n",
      "Epoch [1226/2500], Train Loss: 0.7865, Train Accuracy: 65.72%, Test Loss: 0.7577, Test Accuracy: 73.42%\n",
      "Epoch [1227/2500], Train Loss: 0.7886, Train Accuracy: 66.00%, Test Loss: 0.7428, Test Accuracy: 68.35%\n",
      "Epoch [1228/2500], Train Loss: 0.7781, Train Accuracy: 66.00%, Test Loss: 0.7861, Test Accuracy: 73.42%\n",
      "Epoch [1229/2500], Train Loss: 0.7622, Train Accuracy: 67.00%, Test Loss: 0.7502, Test Accuracy: 70.89%\n",
      "Epoch [1230/2500], Train Loss: 0.7707, Train Accuracy: 67.57%, Test Loss: 0.7956, Test Accuracy: 72.15%\n",
      "Epoch [1231/2500], Train Loss: 0.7752, Train Accuracy: 67.28%, Test Loss: 0.7566, Test Accuracy: 73.42%\n",
      "Epoch [1232/2500], Train Loss: 0.7789, Train Accuracy: 66.00%, Test Loss: 0.7445, Test Accuracy: 68.35%\n",
      "Epoch [1233/2500], Train Loss: 0.7586, Train Accuracy: 67.14%, Test Loss: 0.7881, Test Accuracy: 70.89%\n",
      "Epoch [1234/2500], Train Loss: 0.7726, Train Accuracy: 67.99%, Test Loss: 0.7437, Test Accuracy: 72.15%\n",
      "Epoch [1235/2500], Train Loss: 0.7935, Train Accuracy: 63.87%, Test Loss: 0.7523, Test Accuracy: 68.35%\n",
      "Epoch [1236/2500], Train Loss: 0.7885, Train Accuracy: 65.86%, Test Loss: 0.7978, Test Accuracy: 65.82%\n",
      "Epoch [1237/2500], Train Loss: 0.7593, Train Accuracy: 66.43%, Test Loss: 0.7951, Test Accuracy: 72.15%\n",
      "Epoch [1238/2500], Train Loss: 0.7941, Train Accuracy: 65.72%, Test Loss: 0.8802, Test Accuracy: 62.03%\n",
      "Epoch [1239/2500], Train Loss: 0.7971, Train Accuracy: 64.30%, Test Loss: 0.7781, Test Accuracy: 70.89%\n",
      "Epoch [1240/2500], Train Loss: 0.7854, Train Accuracy: 65.58%, Test Loss: 0.8337, Test Accuracy: 69.62%\n",
      "Epoch [1241/2500], Train Loss: 0.7431, Train Accuracy: 68.71%, Test Loss: 0.8406, Test Accuracy: 69.62%\n",
      "Epoch [1242/2500], Train Loss: 0.7875, Train Accuracy: 63.87%, Test Loss: 0.7376, Test Accuracy: 65.82%\n",
      "Epoch [1243/2500], Train Loss: 0.7713, Train Accuracy: 67.43%, Test Loss: 0.7744, Test Accuracy: 73.42%\n",
      "Epoch [1244/2500], Train Loss: 0.7637, Train Accuracy: 67.43%, Test Loss: 0.7366, Test Accuracy: 70.89%\n",
      "Epoch [1245/2500], Train Loss: 0.7736, Train Accuracy: 66.57%, Test Loss: 0.7453, Test Accuracy: 68.35%\n",
      "Epoch [1246/2500], Train Loss: 0.7591, Train Accuracy: 67.85%, Test Loss: 0.7838, Test Accuracy: 70.89%\n",
      "Epoch [1247/2500], Train Loss: 0.7724, Train Accuracy: 68.28%, Test Loss: 0.7808, Test Accuracy: 68.35%\n",
      "Epoch [1248/2500], Train Loss: 0.7821, Train Accuracy: 66.86%, Test Loss: 0.7994, Test Accuracy: 68.35%\n",
      "Epoch [1249/2500], Train Loss: 0.7499, Train Accuracy: 66.57%, Test Loss: 0.7501, Test Accuracy: 74.68%\n",
      "Epoch [1250/2500], Train Loss: 0.7637, Train Accuracy: 68.42%, Test Loss: 0.7599, Test Accuracy: 69.62%\n",
      "Epoch [1251/2500], Train Loss: 0.7811, Train Accuracy: 67.00%, Test Loss: 0.7629, Test Accuracy: 70.89%\n",
      "Epoch [1252/2500], Train Loss: 0.7759, Train Accuracy: 65.43%, Test Loss: 0.8081, Test Accuracy: 68.35%\n",
      "Epoch [1253/2500], Train Loss: 0.7866, Train Accuracy: 65.29%, Test Loss: 0.7723, Test Accuracy: 70.89%\n",
      "Epoch [1254/2500], Train Loss: 0.7915, Train Accuracy: 67.14%, Test Loss: 0.7945, Test Accuracy: 70.89%\n",
      "Epoch [1255/2500], Train Loss: 0.7578, Train Accuracy: 67.28%, Test Loss: 0.8460, Test Accuracy: 67.09%\n",
      "Epoch [1256/2500], Train Loss: 0.7907, Train Accuracy: 65.29%, Test Loss: 0.7976, Test Accuracy: 64.56%\n",
      "Epoch [1257/2500], Train Loss: 0.7764, Train Accuracy: 66.71%, Test Loss: 0.7468, Test Accuracy: 69.62%\n",
      "Epoch [1258/2500], Train Loss: 0.7986, Train Accuracy: 65.72%, Test Loss: 0.8285, Test Accuracy: 65.82%\n",
      "Epoch [1259/2500], Train Loss: 0.7568, Train Accuracy: 66.43%, Test Loss: 0.7926, Test Accuracy: 72.15%\n",
      "Epoch [1260/2500], Train Loss: 0.7854, Train Accuracy: 66.71%, Test Loss: 0.8847, Test Accuracy: 63.29%\n",
      "Epoch [1261/2500], Train Loss: 0.7609, Train Accuracy: 68.56%, Test Loss: 0.8354, Test Accuracy: 68.35%\n",
      "Epoch [1262/2500], Train Loss: 0.7848, Train Accuracy: 65.29%, Test Loss: 0.7749, Test Accuracy: 69.62%\n",
      "Epoch [1263/2500], Train Loss: 0.7581, Train Accuracy: 66.86%, Test Loss: 0.8202, Test Accuracy: 68.35%\n",
      "Epoch [1264/2500], Train Loss: 0.7981, Train Accuracy: 65.43%, Test Loss: 0.7422, Test Accuracy: 69.62%\n",
      "Epoch [1265/2500], Train Loss: 0.7733, Train Accuracy: 67.14%, Test Loss: 0.8068, Test Accuracy: 60.76%\n",
      "Epoch [1266/2500], Train Loss: 0.7929, Train Accuracy: 64.15%, Test Loss: 0.7515, Test Accuracy: 65.82%\n",
      "Epoch [1267/2500], Train Loss: 0.7963, Train Accuracy: 65.86%, Test Loss: 0.7940, Test Accuracy: 70.89%\n",
      "Epoch [1268/2500], Train Loss: 0.7877, Train Accuracy: 66.71%, Test Loss: 0.7331, Test Accuracy: 68.35%\n",
      "Epoch [1269/2500], Train Loss: 0.7696, Train Accuracy: 67.28%, Test Loss: 0.9220, Test Accuracy: 63.29%\n",
      "Epoch [1270/2500], Train Loss: 0.7542, Train Accuracy: 67.71%, Test Loss: 0.7622, Test Accuracy: 72.15%\n",
      "Epoch [1271/2500], Train Loss: 0.7872, Train Accuracy: 66.86%, Test Loss: 0.7327, Test Accuracy: 70.89%\n",
      "Epoch [1272/2500], Train Loss: 0.7981, Train Accuracy: 66.43%, Test Loss: 0.8880, Test Accuracy: 64.56%\n",
      "Epoch [1273/2500], Train Loss: 0.7780, Train Accuracy: 66.71%, Test Loss: 0.8187, Test Accuracy: 70.89%\n",
      "Epoch [1274/2500], Train Loss: 0.7667, Train Accuracy: 67.57%, Test Loss: 0.8694, Test Accuracy: 64.56%\n",
      "Epoch [1275/2500], Train Loss: 0.7592, Train Accuracy: 67.43%, Test Loss: 0.7407, Test Accuracy: 72.15%\n",
      "Epoch [1276/2500], Train Loss: 0.7664, Train Accuracy: 66.15%, Test Loss: 0.8452, Test Accuracy: 62.03%\n",
      "Epoch [1277/2500], Train Loss: 0.7699, Train Accuracy: 66.15%, Test Loss: 0.8868, Test Accuracy: 62.03%\n",
      "Epoch [1278/2500], Train Loss: 0.7770, Train Accuracy: 66.29%, Test Loss: 0.8368, Test Accuracy: 68.35%\n",
      "Epoch [1279/2500], Train Loss: 0.7651, Train Accuracy: 66.00%, Test Loss: 0.8272, Test Accuracy: 70.89%\n",
      "Epoch [1280/2500], Train Loss: 0.7988, Train Accuracy: 65.01%, Test Loss: 0.7567, Test Accuracy: 72.15%\n",
      "Epoch [1281/2500], Train Loss: 0.8025, Train Accuracy: 67.85%, Test Loss: 0.7348, Test Accuracy: 70.89%\n",
      "Epoch [1282/2500], Train Loss: 0.7614, Train Accuracy: 66.43%, Test Loss: 0.8643, Test Accuracy: 60.76%\n",
      "Epoch [1283/2500], Train Loss: 0.7930, Train Accuracy: 65.72%, Test Loss: 0.7913, Test Accuracy: 73.42%\n",
      "Epoch [1284/2500], Train Loss: 0.7725, Train Accuracy: 67.00%, Test Loss: 0.7427, Test Accuracy: 72.15%\n",
      "Epoch [1285/2500], Train Loss: 0.7682, Train Accuracy: 66.43%, Test Loss: 0.7473, Test Accuracy: 75.95%\n",
      "Epoch [1286/2500], Train Loss: 0.7982, Train Accuracy: 64.58%, Test Loss: 0.7636, Test Accuracy: 67.09%\n",
      "Epoch [1287/2500], Train Loss: 0.7652, Train Accuracy: 66.15%, Test Loss: 0.7941, Test Accuracy: 65.82%\n",
      "Epoch [1288/2500], Train Loss: 0.7762, Train Accuracy: 67.71%, Test Loss: 0.7785, Test Accuracy: 72.15%\n",
      "Epoch [1289/2500], Train Loss: 0.7822, Train Accuracy: 65.01%, Test Loss: 0.8026, Test Accuracy: 70.89%\n",
      "Epoch [1290/2500], Train Loss: 0.7996, Train Accuracy: 66.15%, Test Loss: 0.7570, Test Accuracy: 72.15%\n",
      "Epoch [1291/2500], Train Loss: 0.7626, Train Accuracy: 65.72%, Test Loss: 0.7137, Test Accuracy: 67.09%\n",
      "Epoch [1292/2500], Train Loss: 0.7928, Train Accuracy: 67.00%, Test Loss: 0.8091, Test Accuracy: 65.82%\n",
      "Epoch [1293/2500], Train Loss: 0.7769, Train Accuracy: 66.86%, Test Loss: 0.7884, Test Accuracy: 72.15%\n",
      "Epoch [1294/2500], Train Loss: 0.7488, Train Accuracy: 67.00%, Test Loss: 0.7829, Test Accuracy: 70.89%\n",
      "Epoch [1295/2500], Train Loss: 0.7687, Train Accuracy: 64.86%, Test Loss: 0.8629, Test Accuracy: 63.29%\n",
      "Epoch [1296/2500], Train Loss: 0.7418, Train Accuracy: 68.85%, Test Loss: 0.7399, Test Accuracy: 69.62%\n",
      "Epoch [1297/2500], Train Loss: 0.7479, Train Accuracy: 65.86%, Test Loss: 0.7287, Test Accuracy: 64.56%\n",
      "Epoch [1298/2500], Train Loss: 0.7707, Train Accuracy: 66.15%, Test Loss: 0.7404, Test Accuracy: 72.15%\n",
      "Epoch [1299/2500], Train Loss: 0.7660, Train Accuracy: 65.72%, Test Loss: 0.8730, Test Accuracy: 69.62%\n",
      "Epoch [1300/2500], Train Loss: 0.7757, Train Accuracy: 66.86%, Test Loss: 0.7604, Test Accuracy: 72.15%\n",
      "Epoch [1301/2500], Train Loss: 0.7581, Train Accuracy: 67.14%, Test Loss: 0.8255, Test Accuracy: 65.82%\n",
      "Epoch [1302/2500], Train Loss: 0.7603, Train Accuracy: 65.58%, Test Loss: 0.7507, Test Accuracy: 67.09%\n",
      "Epoch [1303/2500], Train Loss: 0.7570, Train Accuracy: 67.00%, Test Loss: 0.7779, Test Accuracy: 72.15%\n",
      "Epoch [1304/2500], Train Loss: 0.7948, Train Accuracy: 65.15%, Test Loss: 0.7586, Test Accuracy: 70.89%\n",
      "Epoch [1305/2500], Train Loss: 0.7544, Train Accuracy: 66.57%, Test Loss: 0.7431, Test Accuracy: 69.62%\n",
      "Epoch [1306/2500], Train Loss: 0.7688, Train Accuracy: 68.14%, Test Loss: 0.7352, Test Accuracy: 68.35%\n",
      "Epoch [1307/2500], Train Loss: 0.7612, Train Accuracy: 66.15%, Test Loss: 0.7821, Test Accuracy: 70.89%\n",
      "Epoch [1308/2500], Train Loss: 0.7808, Train Accuracy: 66.29%, Test Loss: 0.7188, Test Accuracy: 68.35%\n",
      "Epoch [1309/2500], Train Loss: 0.7697, Train Accuracy: 67.43%, Test Loss: 0.7972, Test Accuracy: 68.35%\n",
      "Epoch [1310/2500], Train Loss: 0.7812, Train Accuracy: 68.28%, Test Loss: 0.8963, Test Accuracy: 62.03%\n",
      "Epoch [1311/2500], Train Loss: 0.7738, Train Accuracy: 66.15%, Test Loss: 0.7732, Test Accuracy: 72.15%\n",
      "Epoch [1312/2500], Train Loss: 0.7454, Train Accuracy: 67.00%, Test Loss: 0.7467, Test Accuracy: 70.89%\n",
      "Epoch [1313/2500], Train Loss: 0.7715, Train Accuracy: 66.71%, Test Loss: 0.9085, Test Accuracy: 60.76%\n",
      "Epoch [1314/2500], Train Loss: 0.8084, Train Accuracy: 65.01%, Test Loss: 0.7897, Test Accuracy: 70.89%\n",
      "Epoch [1315/2500], Train Loss: 0.7612, Train Accuracy: 67.00%, Test Loss: 0.8358, Test Accuracy: 65.82%\n",
      "Epoch [1316/2500], Train Loss: 0.7718, Train Accuracy: 66.15%, Test Loss: 0.7689, Test Accuracy: 69.62%\n",
      "Epoch [1317/2500], Train Loss: 0.7638, Train Accuracy: 69.42%, Test Loss: 0.8483, Test Accuracy: 63.29%\n",
      "Epoch [1318/2500], Train Loss: 0.7593, Train Accuracy: 67.57%, Test Loss: 0.8715, Test Accuracy: 64.56%\n",
      "Epoch [1319/2500], Train Loss: 0.7674, Train Accuracy: 66.29%, Test Loss: 0.7544, Test Accuracy: 67.09%\n",
      "Epoch [1320/2500], Train Loss: 0.7644, Train Accuracy: 64.86%, Test Loss: 0.8158, Test Accuracy: 64.56%\n",
      "Epoch [1321/2500], Train Loss: 0.7524, Train Accuracy: 67.28%, Test Loss: 0.8668, Test Accuracy: 63.29%\n",
      "Epoch [1322/2500], Train Loss: 0.7573, Train Accuracy: 65.01%, Test Loss: 0.7776, Test Accuracy: 68.35%\n",
      "Epoch [1323/2500], Train Loss: 0.7724, Train Accuracy: 65.72%, Test Loss: 0.8046, Test Accuracy: 68.35%\n",
      "Epoch [1324/2500], Train Loss: 0.7577, Train Accuracy: 67.14%, Test Loss: 0.8545, Test Accuracy: 65.82%\n",
      "Epoch [1325/2500], Train Loss: 0.7487, Train Accuracy: 67.00%, Test Loss: 0.8257, Test Accuracy: 64.56%\n",
      "Epoch [1326/2500], Train Loss: 0.7711, Train Accuracy: 65.01%, Test Loss: 0.8216, Test Accuracy: 65.82%\n",
      "Epoch [1327/2500], Train Loss: 0.7945, Train Accuracy: 66.15%, Test Loss: 0.7455, Test Accuracy: 72.15%\n",
      "Epoch [1328/2500], Train Loss: 0.7649, Train Accuracy: 68.14%, Test Loss: 0.8109, Test Accuracy: 72.15%\n",
      "Epoch [1329/2500], Train Loss: 0.7769, Train Accuracy: 67.85%, Test Loss: 0.7622, Test Accuracy: 70.89%\n",
      "Epoch [1330/2500], Train Loss: 0.7619, Train Accuracy: 66.86%, Test Loss: 0.7970, Test Accuracy: 65.82%\n",
      "Epoch [1331/2500], Train Loss: 0.7599, Train Accuracy: 68.42%, Test Loss: 0.7562, Test Accuracy: 70.89%\n",
      "Epoch [1332/2500], Train Loss: 0.7384, Train Accuracy: 67.28%, Test Loss: 0.7500, Test Accuracy: 72.15%\n",
      "Epoch [1333/2500], Train Loss: 0.7726, Train Accuracy: 67.14%, Test Loss: 0.8338, Test Accuracy: 62.03%\n",
      "Epoch [1334/2500], Train Loss: 0.7579, Train Accuracy: 67.85%, Test Loss: 0.7767, Test Accuracy: 69.62%\n",
      "Epoch [1335/2500], Train Loss: 0.7891, Train Accuracy: 64.86%, Test Loss: 0.7930, Test Accuracy: 67.09%\n",
      "Epoch [1336/2500], Train Loss: 0.7622, Train Accuracy: 67.43%, Test Loss: 0.7721, Test Accuracy: 72.15%\n",
      "Epoch [1337/2500], Train Loss: 0.7635, Train Accuracy: 67.14%, Test Loss: 0.8525, Test Accuracy: 64.56%\n",
      "Epoch [1338/2500], Train Loss: 0.7369, Train Accuracy: 66.57%, Test Loss: 0.7397, Test Accuracy: 68.35%\n",
      "Epoch [1339/2500], Train Loss: 0.7450, Train Accuracy: 68.28%, Test Loss: 0.7749, Test Accuracy: 70.89%\n",
      "Epoch [1340/2500], Train Loss: 0.7792, Train Accuracy: 65.72%, Test Loss: 0.7991, Test Accuracy: 67.09%\n",
      "Epoch [1341/2500], Train Loss: 0.7969, Train Accuracy: 63.58%, Test Loss: 0.7772, Test Accuracy: 69.62%\n",
      "Epoch [1342/2500], Train Loss: 0.7862, Train Accuracy: 64.72%, Test Loss: 0.7381, Test Accuracy: 70.89%\n",
      "Epoch [1343/2500], Train Loss: 0.7904, Train Accuracy: 66.57%, Test Loss: 0.8099, Test Accuracy: 68.35%\n",
      "Epoch [1344/2500], Train Loss: 0.7455, Train Accuracy: 67.85%, Test Loss: 0.7770, Test Accuracy: 70.89%\n",
      "Epoch [1345/2500], Train Loss: 0.7766, Train Accuracy: 66.86%, Test Loss: 0.7475, Test Accuracy: 70.89%\n",
      "Epoch [1346/2500], Train Loss: 0.7456, Train Accuracy: 65.15%, Test Loss: 0.8401, Test Accuracy: 69.62%\n",
      "Epoch [1347/2500], Train Loss: 0.7736, Train Accuracy: 66.29%, Test Loss: 0.8798, Test Accuracy: 64.56%\n",
      "Epoch [1348/2500], Train Loss: 0.7585, Train Accuracy: 66.71%, Test Loss: 0.8685, Test Accuracy: 62.03%\n",
      "Epoch [1349/2500], Train Loss: 0.7745, Train Accuracy: 64.58%, Test Loss: 0.7853, Test Accuracy: 69.62%\n",
      "Epoch [1350/2500], Train Loss: 0.7488, Train Accuracy: 67.99%, Test Loss: 0.7689, Test Accuracy: 72.15%\n",
      "Epoch [1351/2500], Train Loss: 0.7668, Train Accuracy: 66.71%, Test Loss: 0.7424, Test Accuracy: 69.62%\n",
      "Epoch [1352/2500], Train Loss: 0.7701, Train Accuracy: 67.14%, Test Loss: 0.7922, Test Accuracy: 70.89%\n",
      "Epoch [1353/2500], Train Loss: 0.7847, Train Accuracy: 67.85%, Test Loss: 0.7607, Test Accuracy: 72.15%\n",
      "Epoch [1354/2500], Train Loss: 0.7770, Train Accuracy: 68.28%, Test Loss: 0.7888, Test Accuracy: 65.82%\n",
      "Epoch [1355/2500], Train Loss: 0.7646, Train Accuracy: 66.71%, Test Loss: 0.7484, Test Accuracy: 69.62%\n",
      "Epoch [1356/2500], Train Loss: 0.7896, Train Accuracy: 67.00%, Test Loss: 0.7384, Test Accuracy: 69.62%\n",
      "Epoch [1357/2500], Train Loss: 0.7551, Train Accuracy: 66.43%, Test Loss: 0.7445, Test Accuracy: 69.62%\n",
      "Epoch [1358/2500], Train Loss: 0.7690, Train Accuracy: 67.99%, Test Loss: 0.9797, Test Accuracy: 60.76%\n",
      "Epoch [1359/2500], Train Loss: 0.7929, Train Accuracy: 65.58%, Test Loss: 0.7477, Test Accuracy: 69.62%\n",
      "Epoch [1360/2500], Train Loss: 0.8023, Train Accuracy: 64.86%, Test Loss: 0.7398, Test Accuracy: 69.62%\n",
      "Epoch [1361/2500], Train Loss: 0.8033, Train Accuracy: 66.15%, Test Loss: 0.7382, Test Accuracy: 69.62%\n",
      "Epoch [1362/2500], Train Loss: 0.7533, Train Accuracy: 67.28%, Test Loss: 0.8261, Test Accuracy: 68.35%\n",
      "Epoch [1363/2500], Train Loss: 0.7589, Train Accuracy: 68.14%, Test Loss: 0.7456, Test Accuracy: 65.82%\n",
      "Epoch [1364/2500], Train Loss: 0.7599, Train Accuracy: 67.43%, Test Loss: 0.8081, Test Accuracy: 65.82%\n",
      "Epoch [1365/2500], Train Loss: 0.7743, Train Accuracy: 66.00%, Test Loss: 0.7560, Test Accuracy: 74.68%\n",
      "Epoch [1366/2500], Train Loss: 0.7662, Train Accuracy: 66.00%, Test Loss: 0.9165, Test Accuracy: 62.03%\n",
      "Epoch [1367/2500], Train Loss: 0.7865, Train Accuracy: 66.43%, Test Loss: 0.7658, Test Accuracy: 70.89%\n",
      "Epoch [1368/2500], Train Loss: 0.7676, Train Accuracy: 66.00%, Test Loss: 0.7932, Test Accuracy: 70.89%\n",
      "Epoch [1369/2500], Train Loss: 0.7508, Train Accuracy: 66.43%, Test Loss: 0.7793, Test Accuracy: 68.35%\n",
      "Epoch [1370/2500], Train Loss: 0.7665, Train Accuracy: 66.86%, Test Loss: 0.7456, Test Accuracy: 74.68%\n",
      "Epoch [1371/2500], Train Loss: 0.7771, Train Accuracy: 66.43%, Test Loss: 0.7282, Test Accuracy: 68.35%\n",
      "Epoch [1372/2500], Train Loss: 0.7767, Train Accuracy: 67.00%, Test Loss: 0.7675, Test Accuracy: 69.62%\n",
      "Epoch [1373/2500], Train Loss: 0.7816, Train Accuracy: 66.00%, Test Loss: 0.7423, Test Accuracy: 72.15%\n",
      "Epoch [1374/2500], Train Loss: 0.7484, Train Accuracy: 67.14%, Test Loss: 0.8398, Test Accuracy: 65.82%\n",
      "Epoch [1375/2500], Train Loss: 0.7557, Train Accuracy: 68.71%, Test Loss: 0.7585, Test Accuracy: 72.15%\n",
      "Epoch [1376/2500], Train Loss: 0.7836, Train Accuracy: 65.01%, Test Loss: 0.7995, Test Accuracy: 65.82%\n",
      "Epoch [1377/2500], Train Loss: 0.7611, Train Accuracy: 65.43%, Test Loss: 0.8281, Test Accuracy: 70.89%\n",
      "Epoch [1378/2500], Train Loss: 0.7740, Train Accuracy: 65.29%, Test Loss: 0.7815, Test Accuracy: 69.62%\n",
      "Epoch [1379/2500], Train Loss: 0.7378, Train Accuracy: 69.27%, Test Loss: 0.7915, Test Accuracy: 72.15%\n",
      "Epoch [1380/2500], Train Loss: 0.7969, Train Accuracy: 65.43%, Test Loss: 0.7418, Test Accuracy: 68.35%\n",
      "Epoch [1381/2500], Train Loss: 0.7616, Train Accuracy: 66.71%, Test Loss: 0.7747, Test Accuracy: 67.09%\n",
      "Epoch [1382/2500], Train Loss: 0.7765, Train Accuracy: 66.43%, Test Loss: 0.7269, Test Accuracy: 73.42%\n",
      "Epoch [1383/2500], Train Loss: 0.7719, Train Accuracy: 66.57%, Test Loss: 0.7126, Test Accuracy: 69.62%\n",
      "Epoch [1384/2500], Train Loss: 0.7775, Train Accuracy: 67.57%, Test Loss: 0.8257, Test Accuracy: 64.56%\n",
      "Epoch [1385/2500], Train Loss: 0.7834, Train Accuracy: 64.72%, Test Loss: 0.8139, Test Accuracy: 69.62%\n",
      "Epoch [1386/2500], Train Loss: 0.7529, Train Accuracy: 67.28%, Test Loss: 0.7433, Test Accuracy: 72.15%\n",
      "Epoch [1387/2500], Train Loss: 0.7905, Train Accuracy: 67.99%, Test Loss: 0.8284, Test Accuracy: 64.56%\n",
      "Epoch [1388/2500], Train Loss: 0.7815, Train Accuracy: 67.43%, Test Loss: 0.7318, Test Accuracy: 69.62%\n",
      "Epoch [1389/2500], Train Loss: 0.7716, Train Accuracy: 67.00%, Test Loss: 0.7807, Test Accuracy: 72.15%\n",
      "Epoch [1390/2500], Train Loss: 0.7745, Train Accuracy: 67.71%, Test Loss: 0.8282, Test Accuracy: 64.56%\n",
      "Epoch [1391/2500], Train Loss: 0.7512, Train Accuracy: 67.43%, Test Loss: 0.7507, Test Accuracy: 69.62%\n",
      "Epoch [1392/2500], Train Loss: 0.7727, Train Accuracy: 66.15%, Test Loss: 0.7357, Test Accuracy: 69.62%\n",
      "Epoch [1393/2500], Train Loss: 0.7395, Train Accuracy: 67.00%, Test Loss: 0.8023, Test Accuracy: 68.35%\n",
      "Epoch [1394/2500], Train Loss: 0.7245, Train Accuracy: 68.56%, Test Loss: 0.8345, Test Accuracy: 68.35%\n",
      "Epoch [1395/2500], Train Loss: 0.7659, Train Accuracy: 66.71%, Test Loss: 0.7483, Test Accuracy: 70.89%\n",
      "Epoch [1396/2500], Train Loss: 0.7759, Train Accuracy: 65.86%, Test Loss: 0.9120, Test Accuracy: 63.29%\n",
      "Epoch [1397/2500], Train Loss: 0.7812, Train Accuracy: 66.43%, Test Loss: 0.7905, Test Accuracy: 65.82%\n",
      "Epoch [1398/2500], Train Loss: 0.7616, Train Accuracy: 67.99%, Test Loss: 0.7575, Test Accuracy: 67.09%\n",
      "Epoch [1399/2500], Train Loss: 0.7492, Train Accuracy: 67.43%, Test Loss: 0.7473, Test Accuracy: 73.42%\n",
      "Epoch [1400/2500], Train Loss: 0.7842, Train Accuracy: 66.43%, Test Loss: 0.7541, Test Accuracy: 73.42%\n",
      "Epoch [1401/2500], Train Loss: 0.7686, Train Accuracy: 65.86%, Test Loss: 0.7202, Test Accuracy: 69.62%\n",
      "Epoch [1402/2500], Train Loss: 0.7694, Train Accuracy: 65.58%, Test Loss: 0.7809, Test Accuracy: 67.09%\n",
      "Epoch [1403/2500], Train Loss: 0.7421, Train Accuracy: 68.28%, Test Loss: 0.8289, Test Accuracy: 63.29%\n",
      "Epoch [1404/2500], Train Loss: 0.7485, Train Accuracy: 66.43%, Test Loss: 0.8438, Test Accuracy: 64.56%\n",
      "Epoch [1405/2500], Train Loss: 0.7593, Train Accuracy: 66.57%, Test Loss: 0.7466, Test Accuracy: 67.09%\n",
      "Epoch [1406/2500], Train Loss: 0.7794, Train Accuracy: 67.28%, Test Loss: 0.7493, Test Accuracy: 69.62%\n",
      "Epoch [1407/2500], Train Loss: 0.7671, Train Accuracy: 66.29%, Test Loss: 0.7505, Test Accuracy: 65.82%\n",
      "Epoch [1408/2500], Train Loss: 0.7683, Train Accuracy: 66.71%, Test Loss: 0.7815, Test Accuracy: 72.15%\n",
      "Epoch [1409/2500], Train Loss: 0.7757, Train Accuracy: 65.86%, Test Loss: 0.7384, Test Accuracy: 67.09%\n",
      "Epoch [1410/2500], Train Loss: 0.7908, Train Accuracy: 67.00%, Test Loss: 0.7298, Test Accuracy: 70.89%\n",
      "Epoch [1411/2500], Train Loss: 0.7646, Train Accuracy: 66.43%, Test Loss: 0.7355, Test Accuracy: 69.62%\n",
      "Epoch [1412/2500], Train Loss: 0.7612, Train Accuracy: 67.57%, Test Loss: 0.7375, Test Accuracy: 72.15%\n",
      "Epoch [1413/2500], Train Loss: 0.7538, Train Accuracy: 68.85%, Test Loss: 0.7881, Test Accuracy: 69.62%\n",
      "Epoch [1414/2500], Train Loss: 0.7921, Train Accuracy: 64.72%, Test Loss: 0.7391, Test Accuracy: 73.42%\n",
      "Epoch [1415/2500], Train Loss: 0.7833, Train Accuracy: 66.29%, Test Loss: 0.8695, Test Accuracy: 64.56%\n",
      "Epoch [1416/2500], Train Loss: 0.7644, Train Accuracy: 66.29%, Test Loss: 0.7374, Test Accuracy: 69.62%\n",
      "Epoch [1417/2500], Train Loss: 0.7767, Train Accuracy: 65.15%, Test Loss: 0.7895, Test Accuracy: 67.09%\n",
      "Epoch [1418/2500], Train Loss: 0.7777, Train Accuracy: 65.29%, Test Loss: 0.7524, Test Accuracy: 74.68%\n",
      "Epoch [1419/2500], Train Loss: 0.7520, Train Accuracy: 67.00%, Test Loss: 0.9840, Test Accuracy: 62.03%\n",
      "Epoch [1420/2500], Train Loss: 0.7824, Train Accuracy: 64.58%, Test Loss: 0.7972, Test Accuracy: 68.35%\n",
      "Epoch [1421/2500], Train Loss: 0.7613, Train Accuracy: 67.28%, Test Loss: 0.8736, Test Accuracy: 63.29%\n",
      "Epoch [1422/2500], Train Loss: 0.7689, Train Accuracy: 67.28%, Test Loss: 0.7558, Test Accuracy: 72.15%\n",
      "Epoch [1423/2500], Train Loss: 0.7725, Train Accuracy: 68.14%, Test Loss: 0.7464, Test Accuracy: 72.15%\n",
      "Epoch [1424/2500], Train Loss: 0.7691, Train Accuracy: 66.43%, Test Loss: 0.7933, Test Accuracy: 67.09%\n",
      "Epoch [1425/2500], Train Loss: 0.7648, Train Accuracy: 67.14%, Test Loss: 0.7501, Test Accuracy: 68.35%\n",
      "Epoch [1426/2500], Train Loss: 0.7645, Train Accuracy: 67.57%, Test Loss: 0.7801, Test Accuracy: 63.29%\n",
      "Epoch [1427/2500], Train Loss: 0.7717, Train Accuracy: 67.85%, Test Loss: 0.7159, Test Accuracy: 72.15%\n",
      "Epoch [1428/2500], Train Loss: 0.7784, Train Accuracy: 64.30%, Test Loss: 0.7522, Test Accuracy: 69.62%\n",
      "Epoch [1429/2500], Train Loss: 0.7764, Train Accuracy: 67.43%, Test Loss: 0.8490, Test Accuracy: 65.82%\n",
      "Epoch [1430/2500], Train Loss: 0.7823, Train Accuracy: 64.72%, Test Loss: 0.9687, Test Accuracy: 59.49%\n",
      "Epoch [1431/2500], Train Loss: 0.7709, Train Accuracy: 66.71%, Test Loss: 0.8287, Test Accuracy: 65.82%\n",
      "Epoch [1432/2500], Train Loss: 0.7740, Train Accuracy: 66.57%, Test Loss: 0.7274, Test Accuracy: 69.62%\n",
      "Epoch [1433/2500], Train Loss: 0.7790, Train Accuracy: 64.44%, Test Loss: 0.7701, Test Accuracy: 74.68%\n",
      "Epoch [1434/2500], Train Loss: 0.7570, Train Accuracy: 68.71%, Test Loss: 0.8098, Test Accuracy: 65.82%\n",
      "Epoch [1435/2500], Train Loss: 0.7350, Train Accuracy: 68.71%, Test Loss: 0.8669, Test Accuracy: 60.76%\n",
      "Epoch [1436/2500], Train Loss: 0.7559, Train Accuracy: 67.00%, Test Loss: 0.8075, Test Accuracy: 69.62%\n",
      "Epoch [1437/2500], Train Loss: 0.7702, Train Accuracy: 67.99%, Test Loss: 0.7442, Test Accuracy: 68.35%\n",
      "Epoch [1438/2500], Train Loss: 0.7663, Train Accuracy: 67.14%, Test Loss: 0.8103, Test Accuracy: 70.89%\n",
      "Epoch [1439/2500], Train Loss: 0.7692, Train Accuracy: 66.00%, Test Loss: 0.7813, Test Accuracy: 70.89%\n",
      "Epoch [1440/2500], Train Loss: 0.7729, Train Accuracy: 67.85%, Test Loss: 0.7346, Test Accuracy: 70.89%\n",
      "Epoch [1441/2500], Train Loss: 0.7432, Train Accuracy: 67.00%, Test Loss: 0.7294, Test Accuracy: 70.89%\n",
      "Epoch [1442/2500], Train Loss: 0.7840, Train Accuracy: 67.00%, Test Loss: 0.8236, Test Accuracy: 68.35%\n",
      "Epoch [1443/2500], Train Loss: 0.7671, Train Accuracy: 67.00%, Test Loss: 0.9420, Test Accuracy: 62.03%\n",
      "Epoch [1444/2500], Train Loss: 0.7883, Train Accuracy: 66.00%, Test Loss: 0.7882, Test Accuracy: 68.35%\n",
      "Epoch [1445/2500], Train Loss: 0.7844, Train Accuracy: 67.14%, Test Loss: 0.7383, Test Accuracy: 72.15%\n",
      "Epoch [1446/2500], Train Loss: 0.7846, Train Accuracy: 65.58%, Test Loss: 0.8048, Test Accuracy: 69.62%\n",
      "Epoch [1447/2500], Train Loss: 0.7858, Train Accuracy: 66.86%, Test Loss: 0.7681, Test Accuracy: 63.29%\n",
      "Epoch [1448/2500], Train Loss: 0.7558, Train Accuracy: 66.43%, Test Loss: 0.8432, Test Accuracy: 67.09%\n",
      "Epoch [1449/2500], Train Loss: 0.7758, Train Accuracy: 65.86%, Test Loss: 0.7505, Test Accuracy: 72.15%\n",
      "Epoch [1450/2500], Train Loss: 0.7609, Train Accuracy: 67.14%, Test Loss: 0.7446, Test Accuracy: 69.62%\n",
      "Epoch [1451/2500], Train Loss: 0.7606, Train Accuracy: 66.15%, Test Loss: 0.7974, Test Accuracy: 64.56%\n",
      "Epoch [1452/2500], Train Loss: 0.7227, Train Accuracy: 68.42%, Test Loss: 0.7290, Test Accuracy: 72.15%\n",
      "Epoch [1453/2500], Train Loss: 0.7650, Train Accuracy: 68.28%, Test Loss: 0.7534, Test Accuracy: 68.35%\n",
      "Epoch [1454/2500], Train Loss: 0.7496, Train Accuracy: 68.85%, Test Loss: 0.7351, Test Accuracy: 72.15%\n",
      "Epoch [1455/2500], Train Loss: 0.7589, Train Accuracy: 67.57%, Test Loss: 0.8259, Test Accuracy: 67.09%\n",
      "Epoch [1456/2500], Train Loss: 0.7698, Train Accuracy: 66.15%, Test Loss: 0.7661, Test Accuracy: 63.29%\n",
      "Epoch [1457/2500], Train Loss: 0.7538, Train Accuracy: 69.56%, Test Loss: 0.8425, Test Accuracy: 65.82%\n",
      "Epoch [1458/2500], Train Loss: 0.7385, Train Accuracy: 66.57%, Test Loss: 0.7204, Test Accuracy: 68.35%\n",
      "Epoch [1459/2500], Train Loss: 0.7700, Train Accuracy: 66.29%, Test Loss: 0.7482, Test Accuracy: 67.09%\n",
      "Epoch [1460/2500], Train Loss: 0.7690, Train Accuracy: 66.29%, Test Loss: 0.7584, Test Accuracy: 68.35%\n",
      "Epoch [1461/2500], Train Loss: 0.7656, Train Accuracy: 65.15%, Test Loss: 0.9032, Test Accuracy: 63.29%\n",
      "Epoch [1462/2500], Train Loss: 0.7646, Train Accuracy: 67.57%, Test Loss: 0.8090, Test Accuracy: 68.35%\n",
      "Epoch [1463/2500], Train Loss: 0.7583, Train Accuracy: 65.58%, Test Loss: 0.9502, Test Accuracy: 63.29%\n",
      "Epoch [1464/2500], Train Loss: 0.7501, Train Accuracy: 66.86%, Test Loss: 0.7568, Test Accuracy: 70.89%\n",
      "Epoch [1465/2500], Train Loss: 0.7842, Train Accuracy: 66.86%, Test Loss: 0.8026, Test Accuracy: 69.62%\n",
      "Epoch [1466/2500], Train Loss: 0.7641, Train Accuracy: 67.28%, Test Loss: 0.8272, Test Accuracy: 62.03%\n",
      "Epoch [1467/2500], Train Loss: 0.7773, Train Accuracy: 66.00%, Test Loss: 0.7393, Test Accuracy: 72.15%\n",
      "Epoch [1468/2500], Train Loss: 0.7400, Train Accuracy: 69.70%, Test Loss: 0.7901, Test Accuracy: 69.62%\n",
      "Epoch [1469/2500], Train Loss: 0.7812, Train Accuracy: 65.72%, Test Loss: 0.7102, Test Accuracy: 72.15%\n",
      "Epoch [1470/2500], Train Loss: 0.7630, Train Accuracy: 66.71%, Test Loss: 0.7417, Test Accuracy: 74.68%\n",
      "Epoch [1471/2500], Train Loss: 0.7317, Train Accuracy: 68.42%, Test Loss: 0.7910, Test Accuracy: 73.42%\n",
      "Epoch [1472/2500], Train Loss: 0.7476, Train Accuracy: 67.14%, Test Loss: 0.8418, Test Accuracy: 69.62%\n",
      "Epoch [1473/2500], Train Loss: 0.7444, Train Accuracy: 68.14%, Test Loss: 0.7346, Test Accuracy: 68.35%\n",
      "Epoch [1474/2500], Train Loss: 0.7752, Train Accuracy: 66.29%, Test Loss: 0.7870, Test Accuracy: 70.89%\n",
      "Epoch [1475/2500], Train Loss: 0.7724, Train Accuracy: 66.15%, Test Loss: 0.8909, Test Accuracy: 62.03%\n",
      "Epoch [1476/2500], Train Loss: 0.7644, Train Accuracy: 66.86%, Test Loss: 0.7585, Test Accuracy: 67.09%\n",
      "Epoch [1477/2500], Train Loss: 0.7746, Train Accuracy: 67.99%, Test Loss: 0.7951, Test Accuracy: 64.56%\n",
      "Epoch [1478/2500], Train Loss: 0.7738, Train Accuracy: 66.57%, Test Loss: 0.7856, Test Accuracy: 73.42%\n",
      "Epoch [1479/2500], Train Loss: 0.7891, Train Accuracy: 64.44%, Test Loss: 0.7347, Test Accuracy: 69.62%\n",
      "Epoch [1480/2500], Train Loss: 0.7596, Train Accuracy: 65.72%, Test Loss: 0.9051, Test Accuracy: 60.76%\n",
      "Epoch [1481/2500], Train Loss: 0.7689, Train Accuracy: 67.14%, Test Loss: 0.8096, Test Accuracy: 69.62%\n",
      "Epoch [1482/2500], Train Loss: 0.7498, Train Accuracy: 66.57%, Test Loss: 0.7685, Test Accuracy: 67.09%\n",
      "Epoch [1483/2500], Train Loss: 0.7617, Train Accuracy: 67.00%, Test Loss: 0.7548, Test Accuracy: 72.15%\n",
      "Epoch [1484/2500], Train Loss: 0.7611, Train Accuracy: 66.43%, Test Loss: 0.7593, Test Accuracy: 70.89%\n",
      "Epoch [1485/2500], Train Loss: 0.7452, Train Accuracy: 67.71%, Test Loss: 0.7425, Test Accuracy: 69.62%\n",
      "Epoch [1486/2500], Train Loss: 0.7666, Train Accuracy: 67.71%, Test Loss: 0.7574, Test Accuracy: 72.15%\n",
      "Epoch [1487/2500], Train Loss: 0.7680, Train Accuracy: 66.86%, Test Loss: 0.7494, Test Accuracy: 70.89%\n",
      "Epoch [1488/2500], Train Loss: 0.7671, Train Accuracy: 66.71%, Test Loss: 0.7298, Test Accuracy: 65.82%\n",
      "Epoch [1489/2500], Train Loss: 0.7585, Train Accuracy: 65.72%, Test Loss: 0.7444, Test Accuracy: 72.15%\n",
      "Epoch [1490/2500], Train Loss: 0.7911, Train Accuracy: 65.29%, Test Loss: 0.7355, Test Accuracy: 69.62%\n",
      "Epoch [1491/2500], Train Loss: 0.7544, Train Accuracy: 67.43%, Test Loss: 0.7556, Test Accuracy: 74.68%\n",
      "Epoch [1492/2500], Train Loss: 0.7587, Train Accuracy: 67.28%, Test Loss: 0.7206, Test Accuracy: 68.35%\n",
      "Epoch [1493/2500], Train Loss: 0.7583, Train Accuracy: 66.57%, Test Loss: 0.7355, Test Accuracy: 73.42%\n",
      "Epoch [1494/2500], Train Loss: 0.7720, Train Accuracy: 67.71%, Test Loss: 0.7390, Test Accuracy: 65.82%\n",
      "Epoch [1495/2500], Train Loss: 0.7646, Train Accuracy: 66.43%, Test Loss: 0.7605, Test Accuracy: 73.42%\n",
      "Epoch [1496/2500], Train Loss: 0.7494, Train Accuracy: 67.14%, Test Loss: 0.8002, Test Accuracy: 67.09%\n",
      "Epoch [1497/2500], Train Loss: 0.7715, Train Accuracy: 66.15%, Test Loss: 0.7228, Test Accuracy: 69.62%\n",
      "Epoch [1498/2500], Train Loss: 0.7448, Train Accuracy: 68.28%, Test Loss: 0.7346, Test Accuracy: 70.89%\n",
      "Epoch [1499/2500], Train Loss: 0.7763, Train Accuracy: 66.00%, Test Loss: 0.8226, Test Accuracy: 68.35%\n",
      "Epoch [1500/2500], Train Loss: 0.7570, Train Accuracy: 66.71%, Test Loss: 0.7504, Test Accuracy: 70.89%\n",
      "Epoch [1501/2500], Train Loss: 0.7365, Train Accuracy: 67.00%, Test Loss: 0.7263, Test Accuracy: 72.15%\n",
      "Epoch [1502/2500], Train Loss: 0.7504, Train Accuracy: 69.42%, Test Loss: 0.8214, Test Accuracy: 67.09%\n",
      "Epoch [1503/2500], Train Loss: 0.7922, Train Accuracy: 63.58%, Test Loss: 0.7404, Test Accuracy: 73.42%\n",
      "Epoch [1504/2500], Train Loss: 0.7517, Train Accuracy: 68.14%, Test Loss: 0.8633, Test Accuracy: 68.35%\n",
      "Epoch [1505/2500], Train Loss: 0.7342, Train Accuracy: 68.71%, Test Loss: 0.7708, Test Accuracy: 70.89%\n",
      "Epoch [1506/2500], Train Loss: 0.7462, Train Accuracy: 68.14%, Test Loss: 0.7970, Test Accuracy: 68.35%\n",
      "Epoch [1507/2500], Train Loss: 0.7800, Train Accuracy: 64.58%, Test Loss: 0.9191, Test Accuracy: 59.49%\n",
      "Epoch [1508/2500], Train Loss: 0.7864, Train Accuracy: 66.86%, Test Loss: 0.7762, Test Accuracy: 73.42%\n",
      "Epoch [1509/2500], Train Loss: 0.7950, Train Accuracy: 64.30%, Test Loss: 0.8052, Test Accuracy: 65.82%\n",
      "Epoch [1510/2500], Train Loss: 0.7232, Train Accuracy: 69.84%, Test Loss: 0.7493, Test Accuracy: 73.42%\n",
      "Epoch [1511/2500], Train Loss: 0.7659, Train Accuracy: 66.43%, Test Loss: 0.8312, Test Accuracy: 65.82%\n",
      "Epoch [1512/2500], Train Loss: 0.7697, Train Accuracy: 65.01%, Test Loss: 0.9304, Test Accuracy: 67.09%\n",
      "Epoch [1513/2500], Train Loss: 0.7515, Train Accuracy: 68.28%, Test Loss: 0.7547, Test Accuracy: 69.62%\n",
      "Epoch [1514/2500], Train Loss: 0.7333, Train Accuracy: 68.14%, Test Loss: 0.7529, Test Accuracy: 67.09%\n",
      "Epoch [1515/2500], Train Loss: 0.7650, Train Accuracy: 67.00%, Test Loss: 0.7912, Test Accuracy: 67.09%\n",
      "Epoch [1516/2500], Train Loss: 0.7629, Train Accuracy: 66.15%, Test Loss: 0.8147, Test Accuracy: 63.29%\n",
      "Epoch [1517/2500], Train Loss: 0.7491, Train Accuracy: 67.99%, Test Loss: 0.8332, Test Accuracy: 64.56%\n",
      "Epoch [1518/2500], Train Loss: 0.7569, Train Accuracy: 67.43%, Test Loss: 0.8197, Test Accuracy: 69.62%\n",
      "Epoch [1519/2500], Train Loss: 0.7471, Train Accuracy: 69.27%, Test Loss: 0.7246, Test Accuracy: 72.15%\n",
      "Epoch [1520/2500], Train Loss: 0.7885, Train Accuracy: 67.00%, Test Loss: 0.8091, Test Accuracy: 69.62%\n",
      "Epoch [1521/2500], Train Loss: 0.7404, Train Accuracy: 67.00%, Test Loss: 0.8131, Test Accuracy: 67.09%\n",
      "Epoch [1522/2500], Train Loss: 0.7901, Train Accuracy: 67.14%, Test Loss: 0.7792, Test Accuracy: 72.15%\n",
      "Epoch [1523/2500], Train Loss: 0.7747, Train Accuracy: 66.29%, Test Loss: 0.7195, Test Accuracy: 73.42%\n",
      "Epoch [1524/2500], Train Loss: 0.7714, Train Accuracy: 66.29%, Test Loss: 0.7489, Test Accuracy: 68.35%\n",
      "Epoch [1525/2500], Train Loss: 0.7544, Train Accuracy: 67.43%, Test Loss: 0.7410, Test Accuracy: 70.89%\n",
      "Epoch [1526/2500], Train Loss: 0.7987, Train Accuracy: 66.15%, Test Loss: 0.7770, Test Accuracy: 73.42%\n",
      "Epoch [1527/2500], Train Loss: 0.7587, Train Accuracy: 69.84%, Test Loss: 0.7472, Test Accuracy: 69.62%\n",
      "Epoch [1528/2500], Train Loss: 0.7616, Train Accuracy: 65.29%, Test Loss: 0.7366, Test Accuracy: 70.89%\n",
      "Epoch [1529/2500], Train Loss: 0.7827, Train Accuracy: 65.58%, Test Loss: 0.7976, Test Accuracy: 70.89%\n",
      "Epoch [1530/2500], Train Loss: 0.7571, Train Accuracy: 67.71%, Test Loss: 0.8035, Test Accuracy: 68.35%\n",
      "Epoch [1531/2500], Train Loss: 0.7780, Train Accuracy: 67.00%, Test Loss: 0.8298, Test Accuracy: 65.82%\n",
      "Epoch [1532/2500], Train Loss: 0.7573, Train Accuracy: 67.85%, Test Loss: 0.8072, Test Accuracy: 69.62%\n",
      "Epoch [1533/2500], Train Loss: 0.7655, Train Accuracy: 67.14%, Test Loss: 0.8248, Test Accuracy: 68.35%\n",
      "Epoch [1534/2500], Train Loss: 0.7625, Train Accuracy: 65.43%, Test Loss: 0.7806, Test Accuracy: 70.89%\n",
      "Epoch [1535/2500], Train Loss: 0.7645, Train Accuracy: 67.71%, Test Loss: 0.7791, Test Accuracy: 73.42%\n",
      "Epoch [1536/2500], Train Loss: 0.7682, Train Accuracy: 65.72%, Test Loss: 0.7940, Test Accuracy: 65.82%\n",
      "Epoch [1537/2500], Train Loss: 0.7498, Train Accuracy: 68.85%, Test Loss: 0.8343, Test Accuracy: 64.56%\n",
      "Epoch [1538/2500], Train Loss: 0.7973, Train Accuracy: 67.00%, Test Loss: 0.8341, Test Accuracy: 65.82%\n",
      "Epoch [1539/2500], Train Loss: 0.7602, Train Accuracy: 66.00%, Test Loss: 0.8270, Test Accuracy: 64.56%\n",
      "Epoch [1540/2500], Train Loss: 0.7688, Train Accuracy: 68.56%, Test Loss: 0.7643, Test Accuracy: 68.35%\n",
      "Epoch [1541/2500], Train Loss: 0.7647, Train Accuracy: 65.58%, Test Loss: 0.8921, Test Accuracy: 63.29%\n",
      "Epoch [1542/2500], Train Loss: 0.7525, Train Accuracy: 66.29%, Test Loss: 0.8994, Test Accuracy: 60.76%\n",
      "Epoch [1543/2500], Train Loss: 0.7636, Train Accuracy: 67.71%, Test Loss: 0.7330, Test Accuracy: 69.62%\n",
      "Epoch [1544/2500], Train Loss: 0.7671, Train Accuracy: 67.00%, Test Loss: 0.7578, Test Accuracy: 72.15%\n",
      "Epoch [1545/2500], Train Loss: 0.7615, Train Accuracy: 63.58%, Test Loss: 0.7907, Test Accuracy: 72.15%\n",
      "Epoch [1546/2500], Train Loss: 0.7509, Train Accuracy: 67.14%, Test Loss: 0.8150, Test Accuracy: 63.29%\n",
      "Epoch [1547/2500], Train Loss: 0.7545, Train Accuracy: 67.28%, Test Loss: 0.7527, Test Accuracy: 70.89%\n",
      "Epoch [1548/2500], Train Loss: 0.7852, Train Accuracy: 67.14%, Test Loss: 0.7609, Test Accuracy: 69.62%\n",
      "Epoch [1549/2500], Train Loss: 0.7588, Train Accuracy: 66.57%, Test Loss: 0.8686, Test Accuracy: 67.09%\n",
      "Epoch [1550/2500], Train Loss: 0.7823, Train Accuracy: 66.15%, Test Loss: 0.7811, Test Accuracy: 69.62%\n",
      "Epoch [1551/2500], Train Loss: 0.7718, Train Accuracy: 67.00%, Test Loss: 0.8394, Test Accuracy: 63.29%\n",
      "Epoch [1552/2500], Train Loss: 0.7643, Train Accuracy: 67.71%, Test Loss: 0.8396, Test Accuracy: 64.56%\n",
      "Epoch [1553/2500], Train Loss: 0.7737, Train Accuracy: 66.71%, Test Loss: 0.7937, Test Accuracy: 68.35%\n",
      "Epoch [1554/2500], Train Loss: 0.7619, Train Accuracy: 66.86%, Test Loss: 0.7356, Test Accuracy: 70.89%\n",
      "Epoch [1555/2500], Train Loss: 0.7319, Train Accuracy: 69.13%, Test Loss: 0.7450, Test Accuracy: 63.29%\n",
      "Epoch [1556/2500], Train Loss: 0.7685, Train Accuracy: 67.57%, Test Loss: 0.7697, Test Accuracy: 65.82%\n",
      "Epoch [1557/2500], Train Loss: 0.7377, Train Accuracy: 66.71%, Test Loss: 0.7879, Test Accuracy: 73.42%\n",
      "Epoch [1558/2500], Train Loss: 0.7721, Train Accuracy: 68.14%, Test Loss: 0.7909, Test Accuracy: 67.09%\n",
      "Epoch [1559/2500], Train Loss: 0.7477, Train Accuracy: 68.14%, Test Loss: 0.8402, Test Accuracy: 68.35%\n",
      "Epoch [1560/2500], Train Loss: 0.7672, Train Accuracy: 67.85%, Test Loss: 0.7736, Test Accuracy: 68.35%\n",
      "Epoch [1561/2500], Train Loss: 0.7163, Train Accuracy: 68.14%, Test Loss: 0.7314, Test Accuracy: 74.68%\n",
      "Epoch [1562/2500], Train Loss: 0.7893, Train Accuracy: 66.29%, Test Loss: 0.8263, Test Accuracy: 69.62%\n",
      "Epoch [1563/2500], Train Loss: 0.7558, Train Accuracy: 68.14%, Test Loss: 0.8544, Test Accuracy: 64.56%\n",
      "Epoch [1564/2500], Train Loss: 0.7530, Train Accuracy: 66.71%, Test Loss: 0.8217, Test Accuracy: 65.82%\n",
      "Epoch [1565/2500], Train Loss: 0.7459, Train Accuracy: 67.00%, Test Loss: 0.8386, Test Accuracy: 67.09%\n",
      "Epoch [1566/2500], Train Loss: 0.7849, Train Accuracy: 66.57%, Test Loss: 0.8053, Test Accuracy: 68.35%\n",
      "Epoch [1567/2500], Train Loss: 0.7602, Train Accuracy: 66.71%, Test Loss: 0.7742, Test Accuracy: 69.62%\n",
      "Epoch [1568/2500], Train Loss: 0.7460, Train Accuracy: 67.14%, Test Loss: 0.7655, Test Accuracy: 70.89%\n",
      "Epoch [1569/2500], Train Loss: 0.7511, Train Accuracy: 66.29%, Test Loss: 0.7436, Test Accuracy: 69.62%\n",
      "Epoch [1570/2500], Train Loss: 0.7617, Train Accuracy: 68.28%, Test Loss: 0.8686, Test Accuracy: 65.82%\n",
      "Epoch [1571/2500], Train Loss: 0.7662, Train Accuracy: 67.71%, Test Loss: 0.8925, Test Accuracy: 65.82%\n",
      "Epoch [1572/2500], Train Loss: 0.7552, Train Accuracy: 66.29%, Test Loss: 0.7425, Test Accuracy: 65.82%\n",
      "Epoch [1573/2500], Train Loss: 0.7684, Train Accuracy: 67.57%, Test Loss: 0.7405, Test Accuracy: 65.82%\n",
      "Epoch [1574/2500], Train Loss: 0.7487, Train Accuracy: 67.43%, Test Loss: 0.7718, Test Accuracy: 69.62%\n",
      "Epoch [1575/2500], Train Loss: 0.7617, Train Accuracy: 67.00%, Test Loss: 0.7877, Test Accuracy: 72.15%\n",
      "Epoch [1576/2500], Train Loss: 0.7909, Train Accuracy: 67.99%, Test Loss: 0.8854, Test Accuracy: 63.29%\n",
      "Epoch [1577/2500], Train Loss: 0.7672, Train Accuracy: 66.57%, Test Loss: 0.7286, Test Accuracy: 73.42%\n",
      "Epoch [1578/2500], Train Loss: 0.7654, Train Accuracy: 66.15%, Test Loss: 0.9058, Test Accuracy: 62.03%\n",
      "Epoch [1579/2500], Train Loss: 0.7429, Train Accuracy: 67.00%, Test Loss: 0.8497, Test Accuracy: 69.62%\n",
      "Epoch [1580/2500], Train Loss: 0.7430, Train Accuracy: 67.43%, Test Loss: 0.7428, Test Accuracy: 74.68%\n",
      "Epoch [1581/2500], Train Loss: 0.7858, Train Accuracy: 65.01%, Test Loss: 0.7702, Test Accuracy: 73.42%\n",
      "Epoch [1582/2500], Train Loss: 0.7497, Train Accuracy: 66.43%, Test Loss: 0.8439, Test Accuracy: 67.09%\n",
      "Epoch [1583/2500], Train Loss: 0.7378, Train Accuracy: 68.99%, Test Loss: 0.7471, Test Accuracy: 67.09%\n",
      "Epoch [1584/2500], Train Loss: 0.7620, Train Accuracy: 64.15%, Test Loss: 0.7385, Test Accuracy: 67.09%\n",
      "Epoch [1585/2500], Train Loss: 0.7560, Train Accuracy: 68.28%, Test Loss: 0.7654, Test Accuracy: 69.62%\n",
      "Epoch [1586/2500], Train Loss: 0.7649, Train Accuracy: 66.57%, Test Loss: 0.7391, Test Accuracy: 70.89%\n",
      "Epoch [1587/2500], Train Loss: 0.7596, Train Accuracy: 69.13%, Test Loss: 0.7763, Test Accuracy: 73.42%\n",
      "Epoch [1588/2500], Train Loss: 0.7449, Train Accuracy: 66.86%, Test Loss: 0.8014, Test Accuracy: 68.35%\n",
      "Epoch [1589/2500], Train Loss: 0.7672, Train Accuracy: 67.85%, Test Loss: 0.7886, Test Accuracy: 70.89%\n",
      "Epoch [1590/2500], Train Loss: 0.7598, Train Accuracy: 67.85%, Test Loss: 0.8381, Test Accuracy: 67.09%\n",
      "Epoch [1591/2500], Train Loss: 0.7749, Train Accuracy: 67.28%, Test Loss: 0.7384, Test Accuracy: 72.15%\n",
      "Epoch [1592/2500], Train Loss: 0.7753, Train Accuracy: 68.99%, Test Loss: 0.7874, Test Accuracy: 68.35%\n",
      "Epoch [1593/2500], Train Loss: 0.7886, Train Accuracy: 65.86%, Test Loss: 0.8139, Test Accuracy: 67.09%\n",
      "Epoch [1594/2500], Train Loss: 0.7130, Train Accuracy: 70.27%, Test Loss: 0.8580, Test Accuracy: 63.29%\n",
      "Epoch [1595/2500], Train Loss: 0.7668, Train Accuracy: 65.72%, Test Loss: 0.7258, Test Accuracy: 68.35%\n",
      "Epoch [1596/2500], Train Loss: 0.7562, Train Accuracy: 66.00%, Test Loss: 0.8866, Test Accuracy: 62.03%\n",
      "Epoch [1597/2500], Train Loss: 0.7657, Train Accuracy: 66.00%, Test Loss: 0.7470, Test Accuracy: 69.62%\n",
      "Epoch [1598/2500], Train Loss: 0.7374, Train Accuracy: 67.28%, Test Loss: 0.8113, Test Accuracy: 68.35%\n",
      "Epoch [1599/2500], Train Loss: 0.7552, Train Accuracy: 67.28%, Test Loss: 0.7961, Test Accuracy: 69.62%\n",
      "Epoch [1600/2500], Train Loss: 0.7610, Train Accuracy: 64.15%, Test Loss: 0.8058, Test Accuracy: 65.82%\n",
      "Epoch [1601/2500], Train Loss: 0.7637, Train Accuracy: 67.85%, Test Loss: 0.7313, Test Accuracy: 69.62%\n",
      "Epoch [1602/2500], Train Loss: 0.7570, Train Accuracy: 68.14%, Test Loss: 0.8328, Test Accuracy: 65.82%\n",
      "Epoch [1603/2500], Train Loss: 0.7407, Train Accuracy: 68.28%, Test Loss: 0.8278, Test Accuracy: 63.29%\n",
      "Epoch [1604/2500], Train Loss: 0.7750, Train Accuracy: 65.86%, Test Loss: 0.7340, Test Accuracy: 67.09%\n",
      "Epoch [1605/2500], Train Loss: 0.7740, Train Accuracy: 67.43%, Test Loss: 0.7995, Test Accuracy: 70.89%\n",
      "Epoch [1606/2500], Train Loss: 0.7669, Train Accuracy: 66.86%, Test Loss: 0.7354, Test Accuracy: 67.09%\n",
      "Epoch [1607/2500], Train Loss: 0.7542, Train Accuracy: 67.00%, Test Loss: 0.7469, Test Accuracy: 68.35%\n",
      "Epoch [1608/2500], Train Loss: 0.7827, Train Accuracy: 65.29%, Test Loss: 0.8472, Test Accuracy: 65.82%\n",
      "Epoch [1609/2500], Train Loss: 0.7605, Train Accuracy: 66.29%, Test Loss: 0.7306, Test Accuracy: 69.62%\n",
      "Epoch [1610/2500], Train Loss: 0.7721, Train Accuracy: 66.15%, Test Loss: 0.7287, Test Accuracy: 72.15%\n",
      "Epoch [1611/2500], Train Loss: 0.7592, Train Accuracy: 66.86%, Test Loss: 0.9144, Test Accuracy: 63.29%\n",
      "Epoch [1612/2500], Train Loss: 0.7680, Train Accuracy: 67.00%, Test Loss: 0.7325, Test Accuracy: 69.62%\n",
      "Epoch [1613/2500], Train Loss: 0.7530, Train Accuracy: 65.86%, Test Loss: 0.7698, Test Accuracy: 68.35%\n",
      "Epoch [1614/2500], Train Loss: 0.7503, Train Accuracy: 69.56%, Test Loss: 0.7694, Test Accuracy: 69.62%\n",
      "Epoch [1615/2500], Train Loss: 0.7828, Train Accuracy: 63.73%, Test Loss: 0.8510, Test Accuracy: 63.29%\n",
      "Epoch [1616/2500], Train Loss: 0.7608, Train Accuracy: 67.43%, Test Loss: 0.7772, Test Accuracy: 72.15%\n",
      "Epoch [1617/2500], Train Loss: 0.7692, Train Accuracy: 65.29%, Test Loss: 0.7890, Test Accuracy: 67.09%\n",
      "Epoch [1618/2500], Train Loss: 0.7800, Train Accuracy: 65.58%, Test Loss: 0.7478, Test Accuracy: 72.15%\n",
      "Epoch [1619/2500], Train Loss: 0.7776, Train Accuracy: 66.00%, Test Loss: 0.8013, Test Accuracy: 67.09%\n",
      "Epoch [1620/2500], Train Loss: 0.7270, Train Accuracy: 68.99%, Test Loss: 0.7479, Test Accuracy: 72.15%\n",
      "Epoch [1621/2500], Train Loss: 0.7498, Train Accuracy: 67.99%, Test Loss: 0.7663, Test Accuracy: 69.62%\n",
      "Epoch [1622/2500], Train Loss: 0.7635, Train Accuracy: 66.00%, Test Loss: 0.7276, Test Accuracy: 72.15%\n",
      "Epoch [1623/2500], Train Loss: 0.7516, Train Accuracy: 67.00%, Test Loss: 0.7898, Test Accuracy: 70.89%\n",
      "Epoch [1624/2500], Train Loss: 0.7783, Train Accuracy: 66.57%, Test Loss: 0.9249, Test Accuracy: 60.76%\n",
      "Epoch [1625/2500], Train Loss: 0.7488, Train Accuracy: 68.56%, Test Loss: 0.7180, Test Accuracy: 65.82%\n",
      "Epoch [1626/2500], Train Loss: 0.7529, Train Accuracy: 68.28%, Test Loss: 0.8334, Test Accuracy: 63.29%\n",
      "Epoch [1627/2500], Train Loss: 0.7694, Train Accuracy: 64.72%, Test Loss: 0.8124, Test Accuracy: 65.82%\n",
      "Epoch [1628/2500], Train Loss: 0.7333, Train Accuracy: 68.56%, Test Loss: 0.8260, Test Accuracy: 67.09%\n",
      "Epoch [1629/2500], Train Loss: 0.7547, Train Accuracy: 68.85%, Test Loss: 0.7330, Test Accuracy: 69.62%\n",
      "Epoch [1630/2500], Train Loss: 0.7428, Train Accuracy: 67.71%, Test Loss: 0.7063, Test Accuracy: 72.15%\n",
      "Epoch [1631/2500], Train Loss: 0.7704, Train Accuracy: 66.29%, Test Loss: 0.7730, Test Accuracy: 68.35%\n",
      "Epoch [1632/2500], Train Loss: 0.7676, Train Accuracy: 67.00%, Test Loss: 0.7323, Test Accuracy: 67.09%\n",
      "Epoch [1633/2500], Train Loss: 0.7869, Train Accuracy: 67.28%, Test Loss: 0.8811, Test Accuracy: 63.29%\n",
      "Epoch [1634/2500], Train Loss: 0.7699, Train Accuracy: 66.57%, Test Loss: 0.7928, Test Accuracy: 67.09%\n",
      "Epoch [1635/2500], Train Loss: 0.7521, Train Accuracy: 67.71%, Test Loss: 0.8360, Test Accuracy: 68.35%\n",
      "Epoch [1636/2500], Train Loss: 0.7452, Train Accuracy: 67.99%, Test Loss: 0.7703, Test Accuracy: 72.15%\n",
      "Epoch [1637/2500], Train Loss: 0.7570, Train Accuracy: 66.43%, Test Loss: 0.7396, Test Accuracy: 73.42%\n",
      "Epoch [1638/2500], Train Loss: 0.7714, Train Accuracy: 65.29%, Test Loss: 0.8703, Test Accuracy: 63.29%\n",
      "Epoch [1639/2500], Train Loss: 0.7497, Train Accuracy: 66.43%, Test Loss: 0.7383, Test Accuracy: 68.35%\n",
      "Epoch [1640/2500], Train Loss: 0.7734, Train Accuracy: 67.99%, Test Loss: 0.8046, Test Accuracy: 69.62%\n",
      "Epoch [1641/2500], Train Loss: 0.8109, Train Accuracy: 65.58%, Test Loss: 0.9247, Test Accuracy: 62.03%\n",
      "Epoch [1642/2500], Train Loss: 0.7512, Train Accuracy: 67.00%, Test Loss: 0.7976, Test Accuracy: 64.56%\n",
      "Epoch [1643/2500], Train Loss: 0.7634, Train Accuracy: 67.85%, Test Loss: 0.7925, Test Accuracy: 69.62%\n",
      "Epoch [1644/2500], Train Loss: 0.7727, Train Accuracy: 65.15%, Test Loss: 0.7301, Test Accuracy: 70.89%\n",
      "Epoch [1645/2500], Train Loss: 0.7856, Train Accuracy: 65.58%, Test Loss: 0.7666, Test Accuracy: 70.89%\n",
      "Epoch [1646/2500], Train Loss: 0.7383, Train Accuracy: 68.56%, Test Loss: 0.8073, Test Accuracy: 67.09%\n",
      "Epoch [1647/2500], Train Loss: 0.7732, Train Accuracy: 66.57%, Test Loss: 0.7185, Test Accuracy: 68.35%\n",
      "Epoch [1648/2500], Train Loss: 0.7664, Train Accuracy: 66.43%, Test Loss: 0.7944, Test Accuracy: 69.62%\n",
      "Epoch [1649/2500], Train Loss: 0.7619, Train Accuracy: 66.00%, Test Loss: 0.8024, Test Accuracy: 67.09%\n",
      "Epoch [1650/2500], Train Loss: 0.7484, Train Accuracy: 69.84%, Test Loss: 0.8792, Test Accuracy: 67.09%\n",
      "Epoch [1651/2500], Train Loss: 0.7592, Train Accuracy: 67.14%, Test Loss: 0.8119, Test Accuracy: 65.82%\n",
      "Epoch [1652/2500], Train Loss: 0.7615, Train Accuracy: 66.15%, Test Loss: 0.7457, Test Accuracy: 72.15%\n",
      "Epoch [1653/2500], Train Loss: 0.7551, Train Accuracy: 66.29%, Test Loss: 0.7319, Test Accuracy: 68.35%\n",
      "Epoch [1654/2500], Train Loss: 0.7745, Train Accuracy: 68.56%, Test Loss: 0.7222, Test Accuracy: 72.15%\n",
      "Epoch [1655/2500], Train Loss: 0.7553, Train Accuracy: 67.28%, Test Loss: 0.7334, Test Accuracy: 68.35%\n",
      "Epoch [1656/2500], Train Loss: 0.7329, Train Accuracy: 69.70%, Test Loss: 0.7369, Test Accuracy: 70.89%\n",
      "Epoch [1657/2500], Train Loss: 0.7489, Train Accuracy: 67.57%, Test Loss: 0.8096, Test Accuracy: 72.15%\n",
      "Epoch [1658/2500], Train Loss: 0.7466, Train Accuracy: 69.99%, Test Loss: 0.7519, Test Accuracy: 69.62%\n",
      "Epoch [1659/2500], Train Loss: 0.7680, Train Accuracy: 66.86%, Test Loss: 0.8206, Test Accuracy: 69.62%\n",
      "Epoch [1660/2500], Train Loss: 0.7469, Train Accuracy: 67.85%, Test Loss: 0.8079, Test Accuracy: 69.62%\n",
      "Epoch [1661/2500], Train Loss: 0.7816, Train Accuracy: 67.00%, Test Loss: 0.7248, Test Accuracy: 67.09%\n",
      "Epoch [1662/2500], Train Loss: 0.7429, Train Accuracy: 67.00%, Test Loss: 0.7860, Test Accuracy: 72.15%\n",
      "Epoch [1663/2500], Train Loss: 0.7554, Train Accuracy: 67.71%, Test Loss: 0.8148, Test Accuracy: 70.89%\n",
      "Epoch [1664/2500], Train Loss: 0.7537, Train Accuracy: 65.86%, Test Loss: 0.8220, Test Accuracy: 69.62%\n",
      "Epoch [1665/2500], Train Loss: 0.7529, Train Accuracy: 67.85%, Test Loss: 0.8585, Test Accuracy: 64.56%\n",
      "Epoch [1666/2500], Train Loss: 0.7687, Train Accuracy: 66.15%, Test Loss: 0.7752, Test Accuracy: 72.15%\n",
      "Epoch [1667/2500], Train Loss: 0.7644, Train Accuracy: 65.01%, Test Loss: 0.7289, Test Accuracy: 70.89%\n",
      "Epoch [1668/2500], Train Loss: 0.7629, Train Accuracy: 66.15%, Test Loss: 0.9008, Test Accuracy: 63.29%\n",
      "Epoch [1669/2500], Train Loss: 0.7958, Train Accuracy: 63.30%, Test Loss: 0.7974, Test Accuracy: 67.09%\n",
      "Epoch [1670/2500], Train Loss: 0.7463, Train Accuracy: 66.29%, Test Loss: 0.7583, Test Accuracy: 73.42%\n",
      "Epoch [1671/2500], Train Loss: 0.7559, Train Accuracy: 67.00%, Test Loss: 0.7849, Test Accuracy: 70.89%\n",
      "Epoch [1672/2500], Train Loss: 0.7663, Train Accuracy: 65.86%, Test Loss: 0.7380, Test Accuracy: 73.42%\n",
      "Epoch [1673/2500], Train Loss: 0.7400, Train Accuracy: 68.42%, Test Loss: 0.7815, Test Accuracy: 70.89%\n",
      "Epoch [1674/2500], Train Loss: 0.7789, Train Accuracy: 64.86%, Test Loss: 0.7332, Test Accuracy: 67.09%\n",
      "Epoch [1675/2500], Train Loss: 0.7981, Train Accuracy: 66.43%, Test Loss: 0.7577, Test Accuracy: 67.09%\n",
      "Epoch [1676/2500], Train Loss: 0.7649, Train Accuracy: 65.15%, Test Loss: 0.8125, Test Accuracy: 69.62%\n",
      "Epoch [1677/2500], Train Loss: 0.7915, Train Accuracy: 67.14%, Test Loss: 0.7806, Test Accuracy: 68.35%\n",
      "Epoch [1678/2500], Train Loss: 0.7540, Train Accuracy: 68.14%, Test Loss: 0.7788, Test Accuracy: 69.62%\n",
      "Epoch [1679/2500], Train Loss: 0.7526, Train Accuracy: 67.85%, Test Loss: 0.7728, Test Accuracy: 69.62%\n",
      "Epoch [1680/2500], Train Loss: 0.7412, Train Accuracy: 67.43%, Test Loss: 0.8068, Test Accuracy: 67.09%\n",
      "Epoch [1681/2500], Train Loss: 0.7601, Train Accuracy: 66.71%, Test Loss: 0.7188, Test Accuracy: 74.68%\n",
      "Epoch [1682/2500], Train Loss: 0.7500, Train Accuracy: 66.43%, Test Loss: 0.7128, Test Accuracy: 70.89%\n",
      "Epoch [1683/2500], Train Loss: 0.7658, Train Accuracy: 66.29%, Test Loss: 0.7672, Test Accuracy: 69.62%\n",
      "Epoch [1684/2500], Train Loss: 0.7652, Train Accuracy: 65.29%, Test Loss: 0.7828, Test Accuracy: 70.89%\n",
      "Epoch [1685/2500], Train Loss: 0.7605, Train Accuracy: 66.43%, Test Loss: 0.7560, Test Accuracy: 72.15%\n",
      "Epoch [1686/2500], Train Loss: 0.7382, Train Accuracy: 68.42%, Test Loss: 0.7820, Test Accuracy: 70.89%\n",
      "Epoch [1687/2500], Train Loss: 0.7771, Train Accuracy: 65.01%, Test Loss: 0.7834, Test Accuracy: 68.35%\n",
      "Epoch [1688/2500], Train Loss: 0.7510, Train Accuracy: 67.85%, Test Loss: 0.7812, Test Accuracy: 72.15%\n",
      "Epoch [1689/2500], Train Loss: 0.7732, Train Accuracy: 66.43%, Test Loss: 0.7838, Test Accuracy: 67.09%\n",
      "Epoch [1690/2500], Train Loss: 0.7604, Train Accuracy: 67.85%, Test Loss: 0.8197, Test Accuracy: 65.82%\n",
      "Epoch [1691/2500], Train Loss: 0.7343, Train Accuracy: 67.00%, Test Loss: 0.8028, Test Accuracy: 65.82%\n",
      "Epoch [1692/2500], Train Loss: 0.7630, Train Accuracy: 68.42%, Test Loss: 0.7843, Test Accuracy: 68.35%\n",
      "Epoch [1693/2500], Train Loss: 0.7900, Train Accuracy: 65.58%, Test Loss: 0.7527, Test Accuracy: 72.15%\n",
      "Epoch [1694/2500], Train Loss: 0.7842, Train Accuracy: 65.58%, Test Loss: 0.9540, Test Accuracy: 65.82%\n",
      "Epoch [1695/2500], Train Loss: 0.7569, Train Accuracy: 67.14%, Test Loss: 0.7413, Test Accuracy: 72.15%\n",
      "Epoch [1696/2500], Train Loss: 0.7398, Train Accuracy: 69.13%, Test Loss: 0.7628, Test Accuracy: 69.62%\n",
      "Epoch [1697/2500], Train Loss: 0.7766, Train Accuracy: 66.86%, Test Loss: 0.7565, Test Accuracy: 65.82%\n",
      "Epoch [1698/2500], Train Loss: 0.7489, Train Accuracy: 65.86%, Test Loss: 0.8393, Test Accuracy: 67.09%\n",
      "Epoch [1699/2500], Train Loss: 0.7326, Train Accuracy: 68.56%, Test Loss: 0.7583, Test Accuracy: 65.82%\n",
      "Epoch [1700/2500], Train Loss: 0.7775, Train Accuracy: 67.71%, Test Loss: 0.7793, Test Accuracy: 67.09%\n",
      "Epoch [1701/2500], Train Loss: 0.7352, Train Accuracy: 68.71%, Test Loss: 0.7408, Test Accuracy: 70.89%\n",
      "Epoch [1702/2500], Train Loss: 0.7563, Train Accuracy: 65.86%, Test Loss: 0.7581, Test Accuracy: 69.62%\n",
      "Epoch [1703/2500], Train Loss: 0.7587, Train Accuracy: 66.43%, Test Loss: 0.7420, Test Accuracy: 70.89%\n",
      "Epoch [1704/2500], Train Loss: 0.7639, Train Accuracy: 68.56%, Test Loss: 0.7365, Test Accuracy: 70.89%\n",
      "Epoch [1705/2500], Train Loss: 0.7855, Train Accuracy: 65.58%, Test Loss: 0.8122, Test Accuracy: 69.62%\n",
      "Epoch [1706/2500], Train Loss: 0.7306, Train Accuracy: 67.57%, Test Loss: 0.7302, Test Accuracy: 69.62%\n",
      "Epoch [1707/2500], Train Loss: 0.7591, Train Accuracy: 66.86%, Test Loss: 0.7564, Test Accuracy: 70.89%\n",
      "Epoch [1708/2500], Train Loss: 0.7355, Train Accuracy: 67.57%, Test Loss: 0.7330, Test Accuracy: 69.62%\n",
      "Epoch [1709/2500], Train Loss: 0.7803, Train Accuracy: 65.58%, Test Loss: 0.7371, Test Accuracy: 68.35%\n",
      "Epoch [1710/2500], Train Loss: 0.7479, Train Accuracy: 67.57%, Test Loss: 0.7609, Test Accuracy: 70.89%\n",
      "Epoch [1711/2500], Train Loss: 0.7438, Train Accuracy: 68.42%, Test Loss: 0.7600, Test Accuracy: 72.15%\n",
      "Epoch [1712/2500], Train Loss: 0.7340, Train Accuracy: 68.28%, Test Loss: 0.7744, Test Accuracy: 69.62%\n",
      "Epoch [1713/2500], Train Loss: 0.7482, Train Accuracy: 68.42%, Test Loss: 0.7210, Test Accuracy: 68.35%\n",
      "Epoch [1714/2500], Train Loss: 0.7867, Train Accuracy: 65.72%, Test Loss: 0.7203, Test Accuracy: 73.42%\n",
      "Epoch [1715/2500], Train Loss: 0.7645, Train Accuracy: 66.15%, Test Loss: 0.7376, Test Accuracy: 68.35%\n",
      "Epoch [1716/2500], Train Loss: 0.7620, Train Accuracy: 66.00%, Test Loss: 0.8753, Test Accuracy: 63.29%\n",
      "Epoch [1717/2500], Train Loss: 0.7667, Train Accuracy: 65.29%, Test Loss: 0.7182, Test Accuracy: 70.89%\n",
      "Epoch [1718/2500], Train Loss: 0.7835, Train Accuracy: 63.73%, Test Loss: 0.7491, Test Accuracy: 72.15%\n",
      "Epoch [1719/2500], Train Loss: 0.7491, Train Accuracy: 68.28%, Test Loss: 0.7424, Test Accuracy: 69.62%\n",
      "Epoch [1720/2500], Train Loss: 0.7446, Train Accuracy: 68.14%, Test Loss: 0.8176, Test Accuracy: 69.62%\n",
      "Epoch [1721/2500], Train Loss: 0.7624, Train Accuracy: 67.28%, Test Loss: 0.7514, Test Accuracy: 70.89%\n",
      "Epoch [1722/2500], Train Loss: 0.7723, Train Accuracy: 66.43%, Test Loss: 0.7972, Test Accuracy: 72.15%\n",
      "Epoch [1723/2500], Train Loss: 0.7650, Train Accuracy: 67.14%, Test Loss: 0.7279, Test Accuracy: 73.42%\n",
      "Epoch [1724/2500], Train Loss: 0.7878, Train Accuracy: 67.14%, Test Loss: 0.7152, Test Accuracy: 67.09%\n",
      "Epoch [1725/2500], Train Loss: 0.7296, Train Accuracy: 68.71%, Test Loss: 0.7704, Test Accuracy: 68.35%\n",
      "Epoch [1726/2500], Train Loss: 0.7501, Train Accuracy: 68.14%, Test Loss: 0.8009, Test Accuracy: 70.89%\n",
      "Epoch [1727/2500], Train Loss: 0.7532, Train Accuracy: 68.28%, Test Loss: 0.7502, Test Accuracy: 69.62%\n",
      "Epoch [1728/2500], Train Loss: 0.7537, Train Accuracy: 67.43%, Test Loss: 0.8675, Test Accuracy: 63.29%\n",
      "Epoch [1729/2500], Train Loss: 0.7615, Train Accuracy: 68.56%, Test Loss: 0.7596, Test Accuracy: 72.15%\n",
      "Epoch [1730/2500], Train Loss: 0.7762, Train Accuracy: 67.00%, Test Loss: 0.7450, Test Accuracy: 68.35%\n",
      "Epoch [1731/2500], Train Loss: 0.7321, Train Accuracy: 67.71%, Test Loss: 0.7600, Test Accuracy: 70.89%\n",
      "Epoch [1732/2500], Train Loss: 0.7617, Train Accuracy: 65.72%, Test Loss: 0.7860, Test Accuracy: 69.62%\n",
      "Epoch [1733/2500], Train Loss: 0.7638, Train Accuracy: 67.43%, Test Loss: 0.7609, Test Accuracy: 73.42%\n",
      "Epoch [1734/2500], Train Loss: 0.7702, Train Accuracy: 68.56%, Test Loss: 0.7275, Test Accuracy: 69.62%\n",
      "Epoch [1735/2500], Train Loss: 0.7403, Train Accuracy: 68.71%, Test Loss: 0.7375, Test Accuracy: 70.89%\n",
      "Epoch [1736/2500], Train Loss: 0.7496, Train Accuracy: 68.28%, Test Loss: 0.7267, Test Accuracy: 70.89%\n",
      "Epoch [1737/2500], Train Loss: 0.7836, Train Accuracy: 65.86%, Test Loss: 0.7731, Test Accuracy: 70.89%\n",
      "Epoch [1738/2500], Train Loss: 0.7898, Train Accuracy: 65.01%, Test Loss: 0.7489, Test Accuracy: 70.89%\n",
      "Epoch [1739/2500], Train Loss: 0.7558, Train Accuracy: 67.28%, Test Loss: 0.7410, Test Accuracy: 72.15%\n",
      "Epoch [1740/2500], Train Loss: 0.7543, Train Accuracy: 67.28%, Test Loss: 0.7304, Test Accuracy: 72.15%\n",
      "Epoch [1741/2500], Train Loss: 0.7450, Train Accuracy: 66.00%, Test Loss: 0.7527, Test Accuracy: 67.09%\n",
      "Epoch [1742/2500], Train Loss: 0.7902, Train Accuracy: 64.72%, Test Loss: 0.7271, Test Accuracy: 67.09%\n",
      "Epoch [1743/2500], Train Loss: 0.7611, Train Accuracy: 68.28%, Test Loss: 0.7943, Test Accuracy: 67.09%\n",
      "Epoch [1744/2500], Train Loss: 0.7455, Train Accuracy: 68.56%, Test Loss: 0.7380, Test Accuracy: 72.15%\n",
      "Epoch [1745/2500], Train Loss: 0.7394, Train Accuracy: 69.13%, Test Loss: 0.8285, Test Accuracy: 63.29%\n",
      "Epoch [1746/2500], Train Loss: 0.7480, Train Accuracy: 68.56%, Test Loss: 0.7618, Test Accuracy: 68.35%\n",
      "Epoch [1747/2500], Train Loss: 0.7900, Train Accuracy: 67.28%, Test Loss: 0.8007, Test Accuracy: 69.62%\n",
      "Epoch [1748/2500], Train Loss: 0.7238, Train Accuracy: 67.57%, Test Loss: 0.8123, Test Accuracy: 68.35%\n",
      "Epoch [1749/2500], Train Loss: 0.7695, Train Accuracy: 65.58%, Test Loss: 0.7355, Test Accuracy: 64.56%\n",
      "Epoch [1750/2500], Train Loss: 0.7516, Train Accuracy: 65.01%, Test Loss: 0.7669, Test Accuracy: 73.42%\n",
      "Epoch [1751/2500], Train Loss: 0.7582, Train Accuracy: 67.57%, Test Loss: 0.7535, Test Accuracy: 69.62%\n",
      "Epoch [1752/2500], Train Loss: 0.7660, Train Accuracy: 66.86%, Test Loss: 0.7518, Test Accuracy: 69.62%\n",
      "Epoch [1753/2500], Train Loss: 0.7757, Train Accuracy: 67.00%, Test Loss: 0.7605, Test Accuracy: 70.89%\n",
      "Epoch [1754/2500], Train Loss: 0.7300, Train Accuracy: 68.56%, Test Loss: 0.7387, Test Accuracy: 68.35%\n",
      "Epoch [1755/2500], Train Loss: 0.7341, Train Accuracy: 67.00%, Test Loss: 0.8429, Test Accuracy: 63.29%\n",
      "Epoch [1756/2500], Train Loss: 0.7574, Train Accuracy: 66.86%, Test Loss: 0.7250, Test Accuracy: 72.15%\n",
      "Epoch [1757/2500], Train Loss: 0.7638, Train Accuracy: 65.86%, Test Loss: 0.7417, Test Accuracy: 72.15%\n",
      "Epoch [1758/2500], Train Loss: 0.7801, Train Accuracy: 67.14%, Test Loss: 0.7586, Test Accuracy: 72.15%\n",
      "Epoch [1759/2500], Train Loss: 0.7248, Train Accuracy: 68.85%, Test Loss: 0.8542, Test Accuracy: 63.29%\n",
      "Epoch [1760/2500], Train Loss: 0.7895, Train Accuracy: 66.57%, Test Loss: 0.8285, Test Accuracy: 68.35%\n",
      "Epoch [1761/2500], Train Loss: 0.7715, Train Accuracy: 66.15%, Test Loss: 0.8254, Test Accuracy: 68.35%\n",
      "Epoch [1762/2500], Train Loss: 0.7410, Train Accuracy: 69.70%, Test Loss: 0.9538, Test Accuracy: 62.03%\n",
      "Epoch [1763/2500], Train Loss: 0.7601, Train Accuracy: 67.99%, Test Loss: 0.7795, Test Accuracy: 68.35%\n",
      "Epoch [1764/2500], Train Loss: 0.7422, Train Accuracy: 68.56%, Test Loss: 0.7728, Test Accuracy: 70.89%\n",
      "Epoch [1765/2500], Train Loss: 0.7486, Train Accuracy: 68.56%, Test Loss: 0.7409, Test Accuracy: 69.62%\n",
      "Epoch [1766/2500], Train Loss: 0.7448, Train Accuracy: 68.14%, Test Loss: 0.7769, Test Accuracy: 69.62%\n",
      "Epoch [1767/2500], Train Loss: 0.7711, Train Accuracy: 67.85%, Test Loss: 0.7908, Test Accuracy: 69.62%\n",
      "Epoch [1768/2500], Train Loss: 0.7616, Train Accuracy: 68.14%, Test Loss: 0.7581, Test Accuracy: 69.62%\n",
      "Epoch [1769/2500], Train Loss: 0.7890, Train Accuracy: 65.01%, Test Loss: 0.8366, Test Accuracy: 65.82%\n",
      "Epoch [1770/2500], Train Loss: 0.7206, Train Accuracy: 70.13%, Test Loss: 0.8151, Test Accuracy: 69.62%\n",
      "Epoch [1771/2500], Train Loss: 0.7564, Train Accuracy: 66.43%, Test Loss: 0.7549, Test Accuracy: 69.62%\n",
      "Epoch [1772/2500], Train Loss: 0.7356, Train Accuracy: 67.85%, Test Loss: 0.8322, Test Accuracy: 67.09%\n",
      "Epoch [1773/2500], Train Loss: 0.7490, Train Accuracy: 67.28%, Test Loss: 0.7388, Test Accuracy: 72.15%\n",
      "Epoch [1774/2500], Train Loss: 0.7563, Train Accuracy: 68.99%, Test Loss: 0.7436, Test Accuracy: 68.35%\n",
      "Epoch [1775/2500], Train Loss: 0.7692, Train Accuracy: 66.71%, Test Loss: 0.7963, Test Accuracy: 65.82%\n",
      "Epoch [1776/2500], Train Loss: 0.7404, Train Accuracy: 67.28%, Test Loss: 0.8795, Test Accuracy: 64.56%\n",
      "Epoch [1777/2500], Train Loss: 0.7434, Train Accuracy: 68.14%, Test Loss: 0.8306, Test Accuracy: 67.09%\n",
      "Epoch [1778/2500], Train Loss: 0.7469, Train Accuracy: 67.00%, Test Loss: 0.7809, Test Accuracy: 69.62%\n",
      "Epoch [1779/2500], Train Loss: 0.7424, Train Accuracy: 67.28%, Test Loss: 0.7982, Test Accuracy: 72.15%\n",
      "Epoch [1780/2500], Train Loss: 0.7641, Train Accuracy: 67.57%, Test Loss: 0.7142, Test Accuracy: 73.42%\n",
      "Epoch [1781/2500], Train Loss: 0.7491, Train Accuracy: 68.56%, Test Loss: 0.7521, Test Accuracy: 68.35%\n",
      "Epoch [1782/2500], Train Loss: 0.7412, Train Accuracy: 67.14%, Test Loss: 0.7205, Test Accuracy: 69.62%\n",
      "Epoch [1783/2500], Train Loss: 0.7414, Train Accuracy: 68.28%, Test Loss: 0.7485, Test Accuracy: 72.15%\n",
      "Epoch [1784/2500], Train Loss: 0.7531, Train Accuracy: 67.71%, Test Loss: 0.7502, Test Accuracy: 73.42%\n",
      "Epoch [1785/2500], Train Loss: 0.7589, Train Accuracy: 68.99%, Test Loss: 0.7513, Test Accuracy: 68.35%\n",
      "Epoch [1786/2500], Train Loss: 0.7456, Train Accuracy: 67.57%, Test Loss: 0.8919, Test Accuracy: 64.56%\n",
      "Epoch [1787/2500], Train Loss: 0.7625, Train Accuracy: 67.43%, Test Loss: 0.7824, Test Accuracy: 68.35%\n",
      "Epoch [1788/2500], Train Loss: 0.7531, Train Accuracy: 67.28%, Test Loss: 0.7364, Test Accuracy: 72.15%\n",
      "Epoch [1789/2500], Train Loss: 0.7655, Train Accuracy: 67.43%, Test Loss: 0.7725, Test Accuracy: 72.15%\n",
      "Epoch [1790/2500], Train Loss: 0.7676, Train Accuracy: 68.28%, Test Loss: 0.7675, Test Accuracy: 72.15%\n",
      "Epoch [1791/2500], Train Loss: 0.7674, Train Accuracy: 65.86%, Test Loss: 0.7555, Test Accuracy: 70.89%\n",
      "Epoch [1792/2500], Train Loss: 0.7809, Train Accuracy: 65.15%, Test Loss: 0.8583, Test Accuracy: 62.03%\n",
      "Epoch [1793/2500], Train Loss: 0.7619, Train Accuracy: 67.43%, Test Loss: 0.8338, Test Accuracy: 63.29%\n",
      "Epoch [1794/2500], Train Loss: 0.7496, Train Accuracy: 67.71%, Test Loss: 0.9101, Test Accuracy: 63.29%\n",
      "Epoch [1795/2500], Train Loss: 0.7466, Train Accuracy: 67.28%, Test Loss: 0.7374, Test Accuracy: 69.62%\n",
      "Epoch [1796/2500], Train Loss: 0.7613, Train Accuracy: 66.15%, Test Loss: 0.7560, Test Accuracy: 72.15%\n",
      "Epoch [1797/2500], Train Loss: 0.7702, Train Accuracy: 67.00%, Test Loss: 0.7145, Test Accuracy: 69.62%\n",
      "Epoch [1798/2500], Train Loss: 0.7733, Train Accuracy: 66.86%, Test Loss: 0.7451, Test Accuracy: 70.89%\n",
      "Epoch [1799/2500], Train Loss: 0.7446, Train Accuracy: 68.99%, Test Loss: 0.8287, Test Accuracy: 67.09%\n",
      "Epoch [1800/2500], Train Loss: 0.7582, Train Accuracy: 67.57%, Test Loss: 0.7278, Test Accuracy: 67.09%\n",
      "Epoch [1801/2500], Train Loss: 0.7422, Train Accuracy: 68.56%, Test Loss: 0.7278, Test Accuracy: 73.42%\n",
      "Epoch [1802/2500], Train Loss: 0.7509, Train Accuracy: 67.85%, Test Loss: 0.8948, Test Accuracy: 65.82%\n",
      "Epoch [1803/2500], Train Loss: 0.7423, Train Accuracy: 68.56%, Test Loss: 0.7740, Test Accuracy: 65.82%\n",
      "Epoch [1804/2500], Train Loss: 0.7481, Train Accuracy: 66.86%, Test Loss: 0.7322, Test Accuracy: 69.62%\n",
      "Epoch [1805/2500], Train Loss: 0.7411, Train Accuracy: 68.28%, Test Loss: 0.7675, Test Accuracy: 68.35%\n",
      "Epoch [1806/2500], Train Loss: 0.7622, Train Accuracy: 66.15%, Test Loss: 0.7942, Test Accuracy: 69.62%\n",
      "Epoch [1807/2500], Train Loss: 0.7398, Train Accuracy: 67.71%, Test Loss: 0.8489, Test Accuracy: 62.03%\n",
      "Epoch [1808/2500], Train Loss: 0.7267, Train Accuracy: 67.28%, Test Loss: 0.7686, Test Accuracy: 69.62%\n",
      "Epoch [1809/2500], Train Loss: 0.7428, Train Accuracy: 68.56%, Test Loss: 0.7558, Test Accuracy: 72.15%\n",
      "Epoch [1810/2500], Train Loss: 0.7499, Train Accuracy: 67.71%, Test Loss: 0.7395, Test Accuracy: 67.09%\n",
      "Epoch [1811/2500], Train Loss: 0.7717, Train Accuracy: 69.13%, Test Loss: 0.8940, Test Accuracy: 63.29%\n",
      "Epoch [1812/2500], Train Loss: 0.7696, Train Accuracy: 66.29%, Test Loss: 0.8831, Test Accuracy: 65.82%\n",
      "Epoch [1813/2500], Train Loss: 0.7362, Train Accuracy: 67.85%, Test Loss: 0.7874, Test Accuracy: 70.89%\n",
      "Epoch [1814/2500], Train Loss: 0.7656, Train Accuracy: 67.14%, Test Loss: 0.7527, Test Accuracy: 68.35%\n",
      "Epoch [1815/2500], Train Loss: 0.7456, Train Accuracy: 68.28%, Test Loss: 0.7337, Test Accuracy: 70.89%\n",
      "Epoch [1816/2500], Train Loss: 0.7588, Train Accuracy: 68.42%, Test Loss: 0.7796, Test Accuracy: 72.15%\n",
      "Epoch [1817/2500], Train Loss: 0.7321, Train Accuracy: 67.43%, Test Loss: 0.7633, Test Accuracy: 70.89%\n",
      "Epoch [1818/2500], Train Loss: 0.7472, Train Accuracy: 67.43%, Test Loss: 0.7972, Test Accuracy: 72.15%\n",
      "Epoch [1819/2500], Train Loss: 0.7428, Train Accuracy: 66.43%, Test Loss: 0.7159, Test Accuracy: 70.89%\n",
      "Epoch [1820/2500], Train Loss: 0.7488, Train Accuracy: 67.43%, Test Loss: 0.7590, Test Accuracy: 70.89%\n",
      "Epoch [1821/2500], Train Loss: 0.7607, Train Accuracy: 65.86%, Test Loss: 0.7970, Test Accuracy: 68.35%\n",
      "Epoch [1822/2500], Train Loss: 0.7532, Train Accuracy: 67.00%, Test Loss: 0.7475, Test Accuracy: 72.15%\n",
      "Epoch [1823/2500], Train Loss: 0.7422, Train Accuracy: 68.28%, Test Loss: 0.7802, Test Accuracy: 69.62%\n",
      "Epoch [1824/2500], Train Loss: 0.7738, Train Accuracy: 67.85%, Test Loss: 0.7167, Test Accuracy: 70.89%\n",
      "Epoch [1825/2500], Train Loss: 0.7478, Train Accuracy: 67.85%, Test Loss: 0.7957, Test Accuracy: 67.09%\n",
      "Epoch [1826/2500], Train Loss: 0.7642, Train Accuracy: 67.43%, Test Loss: 0.7619, Test Accuracy: 69.62%\n",
      "Epoch [1827/2500], Train Loss: 0.7895, Train Accuracy: 66.43%, Test Loss: 0.8371, Test Accuracy: 67.09%\n",
      "Epoch [1828/2500], Train Loss: 0.7578, Train Accuracy: 66.00%, Test Loss: 0.7349, Test Accuracy: 69.62%\n",
      "Epoch [1829/2500], Train Loss: 0.7689, Train Accuracy: 67.57%, Test Loss: 0.7168, Test Accuracy: 67.09%\n",
      "Epoch [1830/2500], Train Loss: 0.7661, Train Accuracy: 66.00%, Test Loss: 0.7427, Test Accuracy: 73.42%\n",
      "Epoch [1831/2500], Train Loss: 0.7496, Train Accuracy: 67.43%, Test Loss: 0.8482, Test Accuracy: 69.62%\n",
      "Epoch [1832/2500], Train Loss: 0.7823, Train Accuracy: 66.15%, Test Loss: 0.9020, Test Accuracy: 62.03%\n",
      "Epoch [1833/2500], Train Loss: 0.7973, Train Accuracy: 66.43%, Test Loss: 0.7731, Test Accuracy: 69.62%\n",
      "Epoch [1834/2500], Train Loss: 0.7461, Train Accuracy: 67.99%, Test Loss: 0.8416, Test Accuracy: 68.35%\n",
      "Epoch [1835/2500], Train Loss: 0.7587, Train Accuracy: 67.43%, Test Loss: 0.7274, Test Accuracy: 70.89%\n",
      "Epoch [1836/2500], Train Loss: 0.7366, Train Accuracy: 67.43%, Test Loss: 0.7680, Test Accuracy: 73.42%\n",
      "Epoch [1837/2500], Train Loss: 0.7439, Train Accuracy: 68.14%, Test Loss: 0.8756, Test Accuracy: 62.03%\n",
      "Epoch [1838/2500], Train Loss: 0.7447, Train Accuracy: 68.28%, Test Loss: 0.7771, Test Accuracy: 70.89%\n",
      "Epoch [1839/2500], Train Loss: 0.7489, Train Accuracy: 67.57%, Test Loss: 0.7226, Test Accuracy: 67.09%\n",
      "Epoch [1840/2500], Train Loss: 0.7414, Train Accuracy: 68.14%, Test Loss: 0.7585, Test Accuracy: 70.89%\n",
      "Epoch [1841/2500], Train Loss: 0.7698, Train Accuracy: 64.72%, Test Loss: 0.7193, Test Accuracy: 69.62%\n",
      "Epoch [1842/2500], Train Loss: 0.7534, Train Accuracy: 65.86%, Test Loss: 0.7306, Test Accuracy: 70.89%\n",
      "Epoch [1843/2500], Train Loss: 0.7574, Train Accuracy: 67.00%, Test Loss: 0.8111, Test Accuracy: 64.56%\n",
      "Epoch [1844/2500], Train Loss: 0.7679, Train Accuracy: 66.29%, Test Loss: 0.7559, Test Accuracy: 70.89%\n",
      "Epoch [1845/2500], Train Loss: 0.7692, Train Accuracy: 66.00%, Test Loss: 0.8285, Test Accuracy: 64.56%\n",
      "Epoch [1846/2500], Train Loss: 0.7466, Train Accuracy: 67.00%, Test Loss: 0.7523, Test Accuracy: 69.62%\n",
      "Epoch [1847/2500], Train Loss: 0.7730, Train Accuracy: 66.86%, Test Loss: 0.7982, Test Accuracy: 62.03%\n",
      "Epoch [1848/2500], Train Loss: 0.7555, Train Accuracy: 66.71%, Test Loss: 0.7552, Test Accuracy: 69.62%\n",
      "Epoch [1849/2500], Train Loss: 0.7467, Train Accuracy: 69.13%, Test Loss: 0.8138, Test Accuracy: 67.09%\n",
      "Epoch [1850/2500], Train Loss: 0.7586, Train Accuracy: 66.86%, Test Loss: 0.7540, Test Accuracy: 70.89%\n",
      "Epoch [1851/2500], Train Loss: 0.7280, Train Accuracy: 68.56%, Test Loss: 0.7716, Test Accuracy: 64.56%\n",
      "Epoch [1852/2500], Train Loss: 0.7574, Train Accuracy: 67.28%, Test Loss: 0.9545, Test Accuracy: 64.56%\n",
      "Epoch [1853/2500], Train Loss: 0.7473, Train Accuracy: 67.00%, Test Loss: 0.7397, Test Accuracy: 65.82%\n",
      "Epoch [1854/2500], Train Loss: 0.7632, Train Accuracy: 66.57%, Test Loss: 0.7347, Test Accuracy: 69.62%\n",
      "Epoch [1855/2500], Train Loss: 0.7441, Train Accuracy: 66.86%, Test Loss: 0.7754, Test Accuracy: 69.62%\n",
      "Epoch [1856/2500], Train Loss: 0.7608, Train Accuracy: 66.86%, Test Loss: 0.7626, Test Accuracy: 72.15%\n",
      "Epoch [1857/2500], Train Loss: 0.7568, Train Accuracy: 68.28%, Test Loss: 0.7669, Test Accuracy: 72.15%\n",
      "Epoch [1858/2500], Train Loss: 0.7779, Train Accuracy: 66.15%, Test Loss: 0.7768, Test Accuracy: 68.35%\n",
      "Epoch [1859/2500], Train Loss: 0.7521, Train Accuracy: 65.86%, Test Loss: 0.7610, Test Accuracy: 70.89%\n",
      "Epoch [1860/2500], Train Loss: 0.7660, Train Accuracy: 66.71%, Test Loss: 0.8895, Test Accuracy: 64.56%\n",
      "Epoch [1861/2500], Train Loss: 0.7394, Train Accuracy: 67.14%, Test Loss: 0.7648, Test Accuracy: 73.42%\n",
      "Epoch [1862/2500], Train Loss: 0.7709, Train Accuracy: 65.43%, Test Loss: 0.7754, Test Accuracy: 69.62%\n",
      "Epoch [1863/2500], Train Loss: 0.7569, Train Accuracy: 67.57%, Test Loss: 0.7566, Test Accuracy: 68.35%\n",
      "Epoch [1864/2500], Train Loss: 0.7551, Train Accuracy: 68.85%, Test Loss: 0.7620, Test Accuracy: 74.68%\n",
      "Epoch [1865/2500], Train Loss: 0.7320, Train Accuracy: 67.71%, Test Loss: 0.8792, Test Accuracy: 67.09%\n",
      "Epoch [1866/2500], Train Loss: 0.7667, Train Accuracy: 67.57%, Test Loss: 0.7543, Test Accuracy: 72.15%\n",
      "Epoch [1867/2500], Train Loss: 0.7843, Train Accuracy: 63.30%, Test Loss: 0.7272, Test Accuracy: 68.35%\n",
      "Epoch [1868/2500], Train Loss: 0.7359, Train Accuracy: 68.14%, Test Loss: 0.9609, Test Accuracy: 63.29%\n",
      "Epoch [1869/2500], Train Loss: 0.7464, Train Accuracy: 68.85%, Test Loss: 0.8323, Test Accuracy: 63.29%\n",
      "Epoch [1870/2500], Train Loss: 0.7406, Train Accuracy: 67.28%, Test Loss: 0.8495, Test Accuracy: 64.56%\n",
      "Epoch [1871/2500], Train Loss: 0.7552, Train Accuracy: 66.15%, Test Loss: 0.8236, Test Accuracy: 65.82%\n",
      "Epoch [1872/2500], Train Loss: 0.7472, Train Accuracy: 67.00%, Test Loss: 0.8029, Test Accuracy: 67.09%\n",
      "Epoch [1873/2500], Train Loss: 0.7564, Train Accuracy: 68.85%, Test Loss: 0.7714, Test Accuracy: 69.62%\n",
      "Epoch [1874/2500], Train Loss: 0.7462, Train Accuracy: 67.14%, Test Loss: 0.7591, Test Accuracy: 73.42%\n",
      "Epoch [1875/2500], Train Loss: 0.7563, Train Accuracy: 67.14%, Test Loss: 0.7313, Test Accuracy: 65.82%\n",
      "Epoch [1876/2500], Train Loss: 0.7519, Train Accuracy: 67.57%, Test Loss: 0.7756, Test Accuracy: 67.09%\n",
      "Epoch [1877/2500], Train Loss: 0.7741, Train Accuracy: 66.43%, Test Loss: 0.9400, Test Accuracy: 63.29%\n",
      "Epoch [1878/2500], Train Loss: 0.7749, Train Accuracy: 67.71%, Test Loss: 0.8866, Test Accuracy: 67.09%\n",
      "Epoch [1879/2500], Train Loss: 0.7434, Train Accuracy: 67.00%, Test Loss: 0.7412, Test Accuracy: 67.09%\n",
      "Epoch [1880/2500], Train Loss: 0.7703, Train Accuracy: 67.14%, Test Loss: 0.7819, Test Accuracy: 67.09%\n",
      "Epoch [1881/2500], Train Loss: 0.7522, Train Accuracy: 67.57%, Test Loss: 0.7258, Test Accuracy: 73.42%\n",
      "Epoch [1882/2500], Train Loss: 0.7618, Train Accuracy: 67.85%, Test Loss: 0.7381, Test Accuracy: 70.89%\n",
      "Epoch [1883/2500], Train Loss: 0.7422, Train Accuracy: 65.58%, Test Loss: 0.8375, Test Accuracy: 68.35%\n",
      "Epoch [1884/2500], Train Loss: 0.7436, Train Accuracy: 68.28%, Test Loss: 0.7684, Test Accuracy: 72.15%\n",
      "Epoch [1885/2500], Train Loss: 0.7273, Train Accuracy: 67.14%, Test Loss: 0.7263, Test Accuracy: 69.62%\n",
      "Epoch [1886/2500], Train Loss: 0.7591, Train Accuracy: 65.86%, Test Loss: 0.7293, Test Accuracy: 70.89%\n",
      "Epoch [1887/2500], Train Loss: 0.7516, Train Accuracy: 66.71%, Test Loss: 0.8099, Test Accuracy: 64.56%\n",
      "Epoch [1888/2500], Train Loss: 0.7599, Train Accuracy: 67.71%, Test Loss: 0.8485, Test Accuracy: 60.76%\n",
      "Epoch [1889/2500], Train Loss: 0.7497, Train Accuracy: 67.14%, Test Loss: 0.7783, Test Accuracy: 64.56%\n",
      "Epoch [1890/2500], Train Loss: 0.7424, Train Accuracy: 67.00%, Test Loss: 0.7818, Test Accuracy: 68.35%\n",
      "Epoch [1891/2500], Train Loss: 0.7337, Train Accuracy: 66.57%, Test Loss: 0.7476, Test Accuracy: 72.15%\n",
      "Epoch [1892/2500], Train Loss: 0.7410, Train Accuracy: 67.43%, Test Loss: 0.8590, Test Accuracy: 64.56%\n",
      "Epoch [1893/2500], Train Loss: 0.7492, Train Accuracy: 66.86%, Test Loss: 0.7427, Test Accuracy: 72.15%\n",
      "Epoch [1894/2500], Train Loss: 0.7519, Train Accuracy: 68.56%, Test Loss: 0.7497, Test Accuracy: 70.89%\n",
      "Epoch [1895/2500], Train Loss: 0.7596, Train Accuracy: 67.85%, Test Loss: 0.7196, Test Accuracy: 68.35%\n",
      "Epoch [1896/2500], Train Loss: 0.7697, Train Accuracy: 66.57%, Test Loss: 0.7770, Test Accuracy: 72.15%\n",
      "Epoch [1897/2500], Train Loss: 0.7451, Train Accuracy: 67.85%, Test Loss: 0.8172, Test Accuracy: 69.62%\n",
      "Epoch [1898/2500], Train Loss: 0.7436, Train Accuracy: 68.56%, Test Loss: 0.8514, Test Accuracy: 60.76%\n",
      "Epoch [1899/2500], Train Loss: 0.7865, Train Accuracy: 65.72%, Test Loss: 0.8668, Test Accuracy: 64.56%\n",
      "Epoch [1900/2500], Train Loss: 0.7581, Train Accuracy: 66.29%, Test Loss: 0.8546, Test Accuracy: 68.35%\n",
      "Epoch [1901/2500], Train Loss: 0.7613, Train Accuracy: 65.58%, Test Loss: 0.7991, Test Accuracy: 67.09%\n",
      "Epoch [1902/2500], Train Loss: 0.7326, Train Accuracy: 69.13%, Test Loss: 0.7670, Test Accuracy: 70.89%\n",
      "Epoch [1903/2500], Train Loss: 0.7602, Train Accuracy: 66.43%, Test Loss: 0.8062, Test Accuracy: 69.62%\n",
      "Epoch [1904/2500], Train Loss: 0.7551, Train Accuracy: 67.57%, Test Loss: 0.7556, Test Accuracy: 72.15%\n",
      "Epoch [1905/2500], Train Loss: 0.7454, Train Accuracy: 67.43%, Test Loss: 0.7307, Test Accuracy: 69.62%\n",
      "Epoch [1906/2500], Train Loss: 0.7565, Train Accuracy: 67.43%, Test Loss: 0.7360, Test Accuracy: 72.15%\n",
      "Epoch [1907/2500], Train Loss: 0.7665, Train Accuracy: 67.71%, Test Loss: 0.7785, Test Accuracy: 70.89%\n",
      "Epoch [1908/2500], Train Loss: 0.7299, Train Accuracy: 68.14%, Test Loss: 0.7826, Test Accuracy: 70.89%\n",
      "Epoch [1909/2500], Train Loss: 0.7793, Train Accuracy: 65.43%, Test Loss: 0.7866, Test Accuracy: 70.89%\n",
      "Epoch [1910/2500], Train Loss: 0.7501, Train Accuracy: 68.14%, Test Loss: 0.8136, Test Accuracy: 68.35%\n",
      "Epoch [1911/2500], Train Loss: 0.7340, Train Accuracy: 67.99%, Test Loss: 0.8124, Test Accuracy: 65.82%\n",
      "Epoch [1912/2500], Train Loss: 0.7597, Train Accuracy: 68.14%, Test Loss: 0.8863, Test Accuracy: 63.29%\n",
      "Epoch [1913/2500], Train Loss: 0.7564, Train Accuracy: 65.58%, Test Loss: 0.7052, Test Accuracy: 73.42%\n",
      "Epoch [1914/2500], Train Loss: 0.7928, Train Accuracy: 66.57%, Test Loss: 0.7550, Test Accuracy: 73.42%\n",
      "Epoch [1915/2500], Train Loss: 0.7831, Train Accuracy: 66.00%, Test Loss: 0.8300, Test Accuracy: 67.09%\n",
      "Epoch [1916/2500], Train Loss: 0.7774, Train Accuracy: 65.15%, Test Loss: 0.7193, Test Accuracy: 69.62%\n",
      "Epoch [1917/2500], Train Loss: 0.7486, Train Accuracy: 65.86%, Test Loss: 0.7069, Test Accuracy: 73.42%\n",
      "Epoch [1918/2500], Train Loss: 0.7522, Train Accuracy: 68.56%, Test Loss: 0.7357, Test Accuracy: 72.15%\n",
      "Epoch [1919/2500], Train Loss: 0.7442, Train Accuracy: 67.71%, Test Loss: 0.7624, Test Accuracy: 69.62%\n",
      "Epoch [1920/2500], Train Loss: 0.7523, Train Accuracy: 67.43%, Test Loss: 0.7731, Test Accuracy: 70.89%\n",
      "Epoch [1921/2500], Train Loss: 0.7639, Train Accuracy: 67.57%, Test Loss: 0.7611, Test Accuracy: 72.15%\n",
      "Epoch [1922/2500], Train Loss: 0.7492, Train Accuracy: 67.00%, Test Loss: 0.9133, Test Accuracy: 65.82%\n",
      "Epoch [1923/2500], Train Loss: 0.7360, Train Accuracy: 69.84%, Test Loss: 0.7651, Test Accuracy: 70.89%\n",
      "Epoch [1924/2500], Train Loss: 0.7414, Train Accuracy: 66.15%, Test Loss: 0.7082, Test Accuracy: 70.89%\n",
      "Epoch [1925/2500], Train Loss: 0.7474, Train Accuracy: 67.43%, Test Loss: 0.7236, Test Accuracy: 73.42%\n",
      "Epoch [1926/2500], Train Loss: 0.7657, Train Accuracy: 67.99%, Test Loss: 0.7869, Test Accuracy: 64.56%\n",
      "Epoch [1927/2500], Train Loss: 0.7358, Train Accuracy: 67.43%, Test Loss: 0.7246, Test Accuracy: 72.15%\n",
      "Epoch [1928/2500], Train Loss: 0.7471, Train Accuracy: 66.86%, Test Loss: 0.7288, Test Accuracy: 72.15%\n",
      "Epoch [1929/2500], Train Loss: 0.7498, Train Accuracy: 66.15%, Test Loss: 0.7206, Test Accuracy: 68.35%\n",
      "Epoch [1930/2500], Train Loss: 0.7712, Train Accuracy: 66.71%, Test Loss: 0.7100, Test Accuracy: 69.62%\n",
      "Epoch [1931/2500], Train Loss: 0.7490, Train Accuracy: 68.42%, Test Loss: 0.7636, Test Accuracy: 72.15%\n",
      "Epoch [1932/2500], Train Loss: 0.7455, Train Accuracy: 68.85%, Test Loss: 0.8928, Test Accuracy: 64.56%\n",
      "Epoch [1933/2500], Train Loss: 0.7555, Train Accuracy: 67.57%, Test Loss: 0.7431, Test Accuracy: 70.89%\n",
      "Epoch [1934/2500], Train Loss: 0.7652, Train Accuracy: 66.29%, Test Loss: 0.7916, Test Accuracy: 67.09%\n",
      "Epoch [1935/2500], Train Loss: 0.7523, Train Accuracy: 68.85%, Test Loss: 0.7913, Test Accuracy: 73.42%\n",
      "Epoch [1936/2500], Train Loss: 0.7492, Train Accuracy: 67.85%, Test Loss: 0.7526, Test Accuracy: 69.62%\n",
      "Epoch [1937/2500], Train Loss: 0.7310, Train Accuracy: 69.42%, Test Loss: 0.8481, Test Accuracy: 63.29%\n",
      "Epoch [1938/2500], Train Loss: 0.7543, Train Accuracy: 67.99%, Test Loss: 0.7510, Test Accuracy: 72.15%\n",
      "Epoch [1939/2500], Train Loss: 0.7479, Train Accuracy: 69.56%, Test Loss: 0.8124, Test Accuracy: 65.82%\n",
      "Epoch [1940/2500], Train Loss: 0.7269, Train Accuracy: 69.13%, Test Loss: 0.7155, Test Accuracy: 70.89%\n",
      "Epoch [1941/2500], Train Loss: 0.7649, Train Accuracy: 67.57%, Test Loss: 0.7382, Test Accuracy: 68.35%\n",
      "Epoch [1942/2500], Train Loss: 0.7572, Train Accuracy: 68.71%, Test Loss: 0.8258, Test Accuracy: 65.82%\n",
      "Epoch [1943/2500], Train Loss: 0.7388, Train Accuracy: 68.56%, Test Loss: 0.7486, Test Accuracy: 73.42%\n",
      "Epoch [1944/2500], Train Loss: 0.7471, Train Accuracy: 67.43%, Test Loss: 0.7714, Test Accuracy: 70.89%\n",
      "Epoch [1945/2500], Train Loss: 0.7462, Train Accuracy: 65.86%, Test Loss: 0.7704, Test Accuracy: 70.89%\n",
      "Epoch [1946/2500], Train Loss: 0.7546, Train Accuracy: 65.29%, Test Loss: 0.7442, Test Accuracy: 73.42%\n",
      "Epoch [1947/2500], Train Loss: 0.7561, Train Accuracy: 67.85%, Test Loss: 0.7370, Test Accuracy: 72.15%\n",
      "Epoch [1948/2500], Train Loss: 0.7501, Train Accuracy: 65.86%, Test Loss: 0.8044, Test Accuracy: 60.76%\n",
      "Epoch [1949/2500], Train Loss: 0.7487, Train Accuracy: 67.14%, Test Loss: 0.9569, Test Accuracy: 63.29%\n",
      "Epoch [1950/2500], Train Loss: 0.7728, Train Accuracy: 65.72%, Test Loss: 0.7367, Test Accuracy: 70.89%\n",
      "Epoch [1951/2500], Train Loss: 0.7592, Train Accuracy: 65.58%, Test Loss: 0.7668, Test Accuracy: 70.89%\n",
      "Epoch [1952/2500], Train Loss: 0.7338, Train Accuracy: 67.00%, Test Loss: 0.7502, Test Accuracy: 74.68%\n",
      "Epoch [1953/2500], Train Loss: 0.7541, Train Accuracy: 68.42%, Test Loss: 0.7818, Test Accuracy: 69.62%\n",
      "Epoch [1954/2500], Train Loss: 0.7432, Train Accuracy: 67.71%, Test Loss: 0.7883, Test Accuracy: 69.62%\n",
      "Epoch [1955/2500], Train Loss: 0.7420, Train Accuracy: 67.71%, Test Loss: 0.8331, Test Accuracy: 65.82%\n",
      "Epoch [1956/2500], Train Loss: 0.7397, Train Accuracy: 68.14%, Test Loss: 0.7328, Test Accuracy: 65.82%\n",
      "Epoch [1957/2500], Train Loss: 0.7672, Train Accuracy: 64.44%, Test Loss: 0.8069, Test Accuracy: 65.82%\n",
      "Epoch [1958/2500], Train Loss: 0.7464, Train Accuracy: 67.14%, Test Loss: 0.7722, Test Accuracy: 69.62%\n",
      "Epoch [1959/2500], Train Loss: 0.7651, Train Accuracy: 66.71%, Test Loss: 0.7689, Test Accuracy: 72.15%\n",
      "Epoch [1960/2500], Train Loss: 0.7323, Train Accuracy: 68.28%, Test Loss: 0.8830, Test Accuracy: 64.56%\n",
      "Epoch [1961/2500], Train Loss: 0.7456, Train Accuracy: 67.57%, Test Loss: 0.8540, Test Accuracy: 64.56%\n",
      "Epoch [1962/2500], Train Loss: 0.7456, Train Accuracy: 67.99%, Test Loss: 0.8211, Test Accuracy: 65.82%\n",
      "Epoch [1963/2500], Train Loss: 0.7601, Train Accuracy: 66.71%, Test Loss: 0.7848, Test Accuracy: 67.09%\n",
      "Epoch [1964/2500], Train Loss: 0.7554, Train Accuracy: 66.71%, Test Loss: 0.8618, Test Accuracy: 63.29%\n",
      "Epoch [1965/2500], Train Loss: 0.7388, Train Accuracy: 68.99%, Test Loss: 0.7251, Test Accuracy: 72.15%\n",
      "Epoch [1966/2500], Train Loss: 0.7546, Train Accuracy: 68.56%, Test Loss: 0.7852, Test Accuracy: 69.62%\n",
      "Epoch [1967/2500], Train Loss: 0.7427, Train Accuracy: 69.13%, Test Loss: 0.7938, Test Accuracy: 68.35%\n",
      "Epoch [1968/2500], Train Loss: 0.7064, Train Accuracy: 69.13%, Test Loss: 0.7689, Test Accuracy: 70.89%\n",
      "Epoch [1969/2500], Train Loss: 0.7460, Train Accuracy: 68.28%, Test Loss: 0.7781, Test Accuracy: 72.15%\n",
      "Epoch [1970/2500], Train Loss: 0.7732, Train Accuracy: 66.00%, Test Loss: 0.8459, Test Accuracy: 67.09%\n",
      "Epoch [1971/2500], Train Loss: 0.7283, Train Accuracy: 66.71%, Test Loss: 0.7304, Test Accuracy: 73.42%\n",
      "Epoch [1972/2500], Train Loss: 0.7452, Train Accuracy: 65.72%, Test Loss: 0.7734, Test Accuracy: 69.62%\n",
      "Epoch [1973/2500], Train Loss: 0.7456, Train Accuracy: 67.00%, Test Loss: 0.7585, Test Accuracy: 65.82%\n",
      "Epoch [1974/2500], Train Loss: 0.7768, Train Accuracy: 65.58%, Test Loss: 0.7969, Test Accuracy: 68.35%\n",
      "Epoch [1975/2500], Train Loss: 0.7267, Train Accuracy: 67.28%, Test Loss: 0.8216, Test Accuracy: 63.29%\n",
      "Epoch [1976/2500], Train Loss: 0.7473, Train Accuracy: 67.57%, Test Loss: 0.7206, Test Accuracy: 72.15%\n",
      "Epoch [1977/2500], Train Loss: 0.7355, Train Accuracy: 67.00%, Test Loss: 0.7252, Test Accuracy: 69.62%\n",
      "Epoch [1978/2500], Train Loss: 0.7830, Train Accuracy: 67.57%, Test Loss: 0.7291, Test Accuracy: 70.89%\n",
      "Epoch [1979/2500], Train Loss: 0.7430, Train Accuracy: 68.28%, Test Loss: 0.7438, Test Accuracy: 70.89%\n",
      "Epoch [1980/2500], Train Loss: 0.7775, Train Accuracy: 66.00%, Test Loss: 0.7806, Test Accuracy: 64.56%\n",
      "Epoch [1981/2500], Train Loss: 0.7464, Train Accuracy: 67.43%, Test Loss: 0.7343, Test Accuracy: 70.89%\n",
      "Epoch [1982/2500], Train Loss: 0.7383, Train Accuracy: 66.15%, Test Loss: 0.7122, Test Accuracy: 69.62%\n",
      "Epoch [1983/2500], Train Loss: 0.7491, Train Accuracy: 67.43%, Test Loss: 0.7416, Test Accuracy: 70.89%\n",
      "Epoch [1984/2500], Train Loss: 0.7237, Train Accuracy: 67.28%, Test Loss: 0.7238, Test Accuracy: 68.35%\n",
      "Epoch [1985/2500], Train Loss: 0.7718, Train Accuracy: 66.57%, Test Loss: 0.7743, Test Accuracy: 68.35%\n",
      "Epoch [1986/2500], Train Loss: 0.7419, Train Accuracy: 67.28%, Test Loss: 0.7780, Test Accuracy: 70.89%\n",
      "Epoch [1987/2500], Train Loss: 0.7382, Train Accuracy: 67.85%, Test Loss: 0.7919, Test Accuracy: 69.62%\n",
      "Epoch [1988/2500], Train Loss: 0.7261, Train Accuracy: 67.28%, Test Loss: 1.0376, Test Accuracy: 58.23%\n",
      "Epoch [1989/2500], Train Loss: 0.7348, Train Accuracy: 69.99%, Test Loss: 0.8849, Test Accuracy: 63.29%\n",
      "Epoch [1990/2500], Train Loss: 0.7442, Train Accuracy: 69.42%, Test Loss: 0.7464, Test Accuracy: 70.89%\n",
      "Epoch [1991/2500], Train Loss: 0.7704, Train Accuracy: 66.86%, Test Loss: 0.7512, Test Accuracy: 72.15%\n",
      "Epoch [1992/2500], Train Loss: 0.7399, Train Accuracy: 68.71%, Test Loss: 0.7684, Test Accuracy: 70.89%\n",
      "Epoch [1993/2500], Train Loss: 0.7494, Train Accuracy: 67.85%, Test Loss: 0.7323, Test Accuracy: 69.62%\n",
      "Epoch [1994/2500], Train Loss: 0.7513, Train Accuracy: 66.86%, Test Loss: 0.7243, Test Accuracy: 70.89%\n",
      "Epoch [1995/2500], Train Loss: 0.7773, Train Accuracy: 66.71%, Test Loss: 0.7390, Test Accuracy: 72.15%\n",
      "Epoch [1996/2500], Train Loss: 0.7610, Train Accuracy: 67.00%, Test Loss: 0.7459, Test Accuracy: 72.15%\n",
      "Epoch [1997/2500], Train Loss: 0.7460, Train Accuracy: 67.28%, Test Loss: 0.8661, Test Accuracy: 63.29%\n",
      "Epoch [1998/2500], Train Loss: 0.7470, Train Accuracy: 67.71%, Test Loss: 0.7653, Test Accuracy: 64.56%\n",
      "Epoch [1999/2500], Train Loss: 0.7415, Train Accuracy: 68.14%, Test Loss: 0.7707, Test Accuracy: 72.15%\n",
      "Epoch [2000/2500], Train Loss: 0.7519, Train Accuracy: 66.86%, Test Loss: 0.7964, Test Accuracy: 68.35%\n",
      "Epoch [2001/2500], Train Loss: 0.7259, Train Accuracy: 68.42%, Test Loss: 0.7823, Test Accuracy: 69.62%\n",
      "Epoch [2002/2500], Train Loss: 0.7482, Train Accuracy: 67.00%, Test Loss: 0.7253, Test Accuracy: 68.35%\n",
      "Epoch [2003/2500], Train Loss: 0.7292, Train Accuracy: 68.99%, Test Loss: 0.7838, Test Accuracy: 69.62%\n",
      "Epoch [2004/2500], Train Loss: 0.7298, Train Accuracy: 67.43%, Test Loss: 0.7950, Test Accuracy: 70.89%\n",
      "Epoch [2005/2500], Train Loss: 0.7521, Train Accuracy: 67.14%, Test Loss: 0.7377, Test Accuracy: 74.68%\n",
      "Epoch [2006/2500], Train Loss: 0.7759, Train Accuracy: 67.14%, Test Loss: 0.7901, Test Accuracy: 68.35%\n",
      "Epoch [2007/2500], Train Loss: 0.7549, Train Accuracy: 65.86%, Test Loss: 0.7442, Test Accuracy: 72.15%\n",
      "Epoch [2008/2500], Train Loss: 0.7363, Train Accuracy: 67.43%, Test Loss: 0.7297, Test Accuracy: 69.62%\n",
      "Epoch [2009/2500], Train Loss: 0.7389, Train Accuracy: 66.86%, Test Loss: 0.7940, Test Accuracy: 68.35%\n",
      "Epoch [2010/2500], Train Loss: 0.7596, Train Accuracy: 67.99%, Test Loss: 0.7729, Test Accuracy: 68.35%\n",
      "Epoch [2011/2500], Train Loss: 0.7685, Train Accuracy: 67.43%, Test Loss: 0.7266, Test Accuracy: 69.62%\n",
      "Epoch [2012/2500], Train Loss: 0.7621, Train Accuracy: 66.00%, Test Loss: 0.7751, Test Accuracy: 70.89%\n",
      "Epoch [2013/2500], Train Loss: 0.7637, Train Accuracy: 66.71%, Test Loss: 0.8019, Test Accuracy: 65.82%\n",
      "Epoch [2014/2500], Train Loss: 0.7404, Train Accuracy: 67.71%, Test Loss: 0.7857, Test Accuracy: 70.89%\n",
      "Epoch [2015/2500], Train Loss: 0.7549, Train Accuracy: 66.57%, Test Loss: 0.7425, Test Accuracy: 72.15%\n",
      "Epoch [2016/2500], Train Loss: 0.7365, Train Accuracy: 69.13%, Test Loss: 0.7636, Test Accuracy: 72.15%\n",
      "Epoch [2017/2500], Train Loss: 0.7688, Train Accuracy: 67.71%, Test Loss: 0.7357, Test Accuracy: 72.15%\n",
      "Epoch [2018/2500], Train Loss: 0.7455, Train Accuracy: 68.56%, Test Loss: 0.8076, Test Accuracy: 69.62%\n",
      "Epoch [2019/2500], Train Loss: 0.7338, Train Accuracy: 68.56%, Test Loss: 0.7506, Test Accuracy: 72.15%\n",
      "Epoch [2020/2500], Train Loss: 0.7597, Train Accuracy: 67.28%, Test Loss: 0.7273, Test Accuracy: 72.15%\n",
      "Epoch [2021/2500], Train Loss: 0.7307, Train Accuracy: 69.84%, Test Loss: 0.8261, Test Accuracy: 68.35%\n",
      "Epoch [2022/2500], Train Loss: 0.7649, Train Accuracy: 65.01%, Test Loss: 0.7643, Test Accuracy: 69.62%\n",
      "Epoch [2023/2500], Train Loss: 0.7757, Train Accuracy: 67.28%, Test Loss: 0.7446, Test Accuracy: 72.15%\n",
      "Epoch [2024/2500], Train Loss: 0.7662, Train Accuracy: 67.14%, Test Loss: 0.7600, Test Accuracy: 72.15%\n",
      "Epoch [2025/2500], Train Loss: 0.7396, Train Accuracy: 68.28%, Test Loss: 0.7568, Test Accuracy: 70.89%\n",
      "Epoch [2026/2500], Train Loss: 0.7303, Train Accuracy: 68.71%, Test Loss: 0.7479, Test Accuracy: 70.89%\n",
      "Epoch [2027/2500], Train Loss: 0.7517, Train Accuracy: 67.71%, Test Loss: 0.7296, Test Accuracy: 69.62%\n",
      "Epoch [2028/2500], Train Loss: 0.7532, Train Accuracy: 66.43%, Test Loss: 0.7280, Test Accuracy: 72.15%\n",
      "Epoch [2029/2500], Train Loss: 0.7519, Train Accuracy: 66.29%, Test Loss: 0.7784, Test Accuracy: 69.62%\n",
      "Epoch [2030/2500], Train Loss: 0.7382, Train Accuracy: 70.27%, Test Loss: 0.8327, Test Accuracy: 65.82%\n",
      "Epoch [2031/2500], Train Loss: 0.7643, Train Accuracy: 65.72%, Test Loss: 0.7850, Test Accuracy: 69.62%\n",
      "Epoch [2032/2500], Train Loss: 0.7569, Train Accuracy: 66.57%, Test Loss: 0.7597, Test Accuracy: 72.15%\n",
      "Epoch [2033/2500], Train Loss: 0.7544, Train Accuracy: 68.71%, Test Loss: 0.7547, Test Accuracy: 74.68%\n",
      "Epoch [2034/2500], Train Loss: 0.7332, Train Accuracy: 68.42%, Test Loss: 0.7582, Test Accuracy: 69.62%\n",
      "Epoch [2035/2500], Train Loss: 0.7670, Train Accuracy: 66.15%, Test Loss: 0.7663, Test Accuracy: 70.89%\n",
      "Epoch [2036/2500], Train Loss: 0.7324, Train Accuracy: 69.70%, Test Loss: 0.8275, Test Accuracy: 69.62%\n",
      "Epoch [2037/2500], Train Loss: 0.7752, Train Accuracy: 67.14%, Test Loss: 0.7361, Test Accuracy: 74.68%\n",
      "Epoch [2038/2500], Train Loss: 0.7351, Train Accuracy: 68.99%, Test Loss: 0.7356, Test Accuracy: 68.35%\n",
      "Epoch [2039/2500], Train Loss: 0.7695, Train Accuracy: 66.15%, Test Loss: 0.7272, Test Accuracy: 74.68%\n",
      "Epoch [2040/2500], Train Loss: 0.7311, Train Accuracy: 66.71%, Test Loss: 0.7181, Test Accuracy: 70.89%\n",
      "Epoch [2041/2500], Train Loss: 0.7400, Train Accuracy: 67.43%, Test Loss: 0.7636, Test Accuracy: 67.09%\n",
      "Epoch [2042/2500], Train Loss: 0.7526, Train Accuracy: 68.28%, Test Loss: 0.8033, Test Accuracy: 67.09%\n",
      "Epoch [2043/2500], Train Loss: 0.7444, Train Accuracy: 69.13%, Test Loss: 0.8333, Test Accuracy: 63.29%\n",
      "Epoch [2044/2500], Train Loss: 0.7740, Train Accuracy: 67.28%, Test Loss: 0.7451, Test Accuracy: 69.62%\n",
      "Epoch [2045/2500], Train Loss: 0.7684, Train Accuracy: 65.15%, Test Loss: 0.7777, Test Accuracy: 69.62%\n",
      "Epoch [2046/2500], Train Loss: 0.7564, Train Accuracy: 66.71%, Test Loss: 0.7811, Test Accuracy: 67.09%\n",
      "Epoch [2047/2500], Train Loss: 0.7408, Train Accuracy: 67.99%, Test Loss: 0.7699, Test Accuracy: 70.89%\n",
      "Epoch [2048/2500], Train Loss: 0.7729, Train Accuracy: 65.86%, Test Loss: 0.7320, Test Accuracy: 74.68%\n",
      "Epoch [2049/2500], Train Loss: 0.7423, Train Accuracy: 67.85%, Test Loss: 0.7540, Test Accuracy: 70.89%\n",
      "Epoch [2050/2500], Train Loss: 0.7459, Train Accuracy: 67.28%, Test Loss: 0.7274, Test Accuracy: 72.15%\n",
      "Epoch [2051/2500], Train Loss: 0.7714, Train Accuracy: 67.71%, Test Loss: 0.7380, Test Accuracy: 72.15%\n",
      "Epoch [2052/2500], Train Loss: 0.7413, Train Accuracy: 68.71%, Test Loss: 0.7799, Test Accuracy: 73.42%\n",
      "Epoch [2053/2500], Train Loss: 0.7501, Train Accuracy: 68.56%, Test Loss: 0.7683, Test Accuracy: 70.89%\n",
      "Epoch [2054/2500], Train Loss: 0.7557, Train Accuracy: 67.14%, Test Loss: 0.7257, Test Accuracy: 72.15%\n",
      "Epoch [2055/2500], Train Loss: 0.7530, Train Accuracy: 68.28%, Test Loss: 0.7670, Test Accuracy: 70.89%\n",
      "Epoch [2056/2500], Train Loss: 0.7298, Train Accuracy: 68.14%, Test Loss: 0.9119, Test Accuracy: 64.56%\n",
      "Epoch [2057/2500], Train Loss: 0.7408, Train Accuracy: 67.14%, Test Loss: 0.9409, Test Accuracy: 62.03%\n",
      "Epoch [2058/2500], Train Loss: 0.7670, Train Accuracy: 65.01%, Test Loss: 0.7576, Test Accuracy: 70.89%\n",
      "Epoch [2059/2500], Train Loss: 0.7567, Train Accuracy: 67.14%, Test Loss: 0.7677, Test Accuracy: 68.35%\n",
      "Epoch [2060/2500], Train Loss: 0.7664, Train Accuracy: 66.57%, Test Loss: 0.7407, Test Accuracy: 68.35%\n",
      "Epoch [2061/2500], Train Loss: 0.7332, Train Accuracy: 67.57%, Test Loss: 0.7699, Test Accuracy: 70.89%\n",
      "Epoch [2062/2500], Train Loss: 0.7363, Train Accuracy: 67.71%, Test Loss: 0.7462, Test Accuracy: 72.15%\n",
      "Epoch [2063/2500], Train Loss: 0.7464, Train Accuracy: 67.57%, Test Loss: 0.8593, Test Accuracy: 67.09%\n",
      "Epoch [2064/2500], Train Loss: 0.7348, Train Accuracy: 68.14%, Test Loss: 0.7647, Test Accuracy: 68.35%\n",
      "Epoch [2065/2500], Train Loss: 0.7522, Train Accuracy: 67.85%, Test Loss: 0.7193, Test Accuracy: 73.42%\n",
      "Epoch [2066/2500], Train Loss: 0.7646, Train Accuracy: 68.28%, Test Loss: 0.7119, Test Accuracy: 72.15%\n",
      "Epoch [2067/2500], Train Loss: 0.7331, Train Accuracy: 67.00%, Test Loss: 0.7177, Test Accuracy: 69.62%\n",
      "Epoch [2068/2500], Train Loss: 0.7306, Train Accuracy: 69.99%, Test Loss: 0.7508, Test Accuracy: 70.89%\n",
      "Epoch [2069/2500], Train Loss: 0.7582, Train Accuracy: 64.58%, Test Loss: 0.8399, Test Accuracy: 64.56%\n",
      "Epoch [2070/2500], Train Loss: 0.7258, Train Accuracy: 67.71%, Test Loss: 0.7372, Test Accuracy: 72.15%\n",
      "Epoch [2071/2500], Train Loss: 0.7591, Train Accuracy: 68.14%, Test Loss: 0.7038, Test Accuracy: 68.35%\n",
      "Epoch [2072/2500], Train Loss: 0.7163, Train Accuracy: 67.14%, Test Loss: 0.7387, Test Accuracy: 73.42%\n",
      "Epoch [2073/2500], Train Loss: 0.7460, Train Accuracy: 67.28%, Test Loss: 0.7806, Test Accuracy: 72.15%\n",
      "Epoch [2074/2500], Train Loss: 0.7618, Train Accuracy: 68.28%, Test Loss: 0.7295, Test Accuracy: 72.15%\n",
      "Epoch [2075/2500], Train Loss: 0.7243, Train Accuracy: 70.70%, Test Loss: 0.7130, Test Accuracy: 67.09%\n",
      "Epoch [2076/2500], Train Loss: 0.7564, Train Accuracy: 67.14%, Test Loss: 0.7376, Test Accuracy: 73.42%\n",
      "Epoch [2077/2500], Train Loss: 0.7307, Train Accuracy: 68.14%, Test Loss: 0.7751, Test Accuracy: 70.89%\n",
      "Epoch [2078/2500], Train Loss: 0.7339, Train Accuracy: 67.57%, Test Loss: 0.7210, Test Accuracy: 65.82%\n",
      "Epoch [2079/2500], Train Loss: 0.7631, Train Accuracy: 66.86%, Test Loss: 0.7913, Test Accuracy: 70.89%\n",
      "Epoch [2080/2500], Train Loss: 0.7598, Train Accuracy: 67.57%, Test Loss: 0.8010, Test Accuracy: 68.35%\n",
      "Epoch [2081/2500], Train Loss: 0.7137, Train Accuracy: 67.43%, Test Loss: 0.7236, Test Accuracy: 75.95%\n",
      "Epoch [2082/2500], Train Loss: 0.7408, Train Accuracy: 67.57%, Test Loss: 0.7369, Test Accuracy: 73.42%\n",
      "Epoch [2083/2500], Train Loss: 0.7846, Train Accuracy: 65.01%, Test Loss: 0.7663, Test Accuracy: 72.15%\n",
      "Epoch [2084/2500], Train Loss: 0.7293, Train Accuracy: 67.99%, Test Loss: 0.8590, Test Accuracy: 67.09%\n",
      "Epoch [2085/2500], Train Loss: 0.7540, Train Accuracy: 65.72%, Test Loss: 0.7352, Test Accuracy: 68.35%\n",
      "Epoch [2086/2500], Train Loss: 0.7573, Train Accuracy: 66.71%, Test Loss: 0.7546, Test Accuracy: 67.09%\n",
      "Epoch [2087/2500], Train Loss: 0.7632, Train Accuracy: 66.71%, Test Loss: 0.7238, Test Accuracy: 73.42%\n",
      "Epoch [2088/2500], Train Loss: 0.7322, Train Accuracy: 69.99%, Test Loss: 0.7325, Test Accuracy: 73.42%\n",
      "Epoch [2089/2500], Train Loss: 0.7285, Train Accuracy: 67.71%, Test Loss: 0.8114, Test Accuracy: 62.03%\n",
      "Epoch [2090/2500], Train Loss: 0.7510, Train Accuracy: 67.99%, Test Loss: 0.7898, Test Accuracy: 68.35%\n",
      "Epoch [2091/2500], Train Loss: 0.7734, Train Accuracy: 66.29%, Test Loss: 0.7393, Test Accuracy: 73.42%\n",
      "Epoch [2092/2500], Train Loss: 0.7432, Train Accuracy: 68.14%, Test Loss: 0.7816, Test Accuracy: 70.89%\n",
      "Epoch [2093/2500], Train Loss: 0.7521, Train Accuracy: 67.99%, Test Loss: 0.7427, Test Accuracy: 73.42%\n",
      "Epoch [2094/2500], Train Loss: 0.7343, Train Accuracy: 66.71%, Test Loss: 0.7499, Test Accuracy: 70.89%\n",
      "Epoch [2095/2500], Train Loss: 0.7230, Train Accuracy: 68.14%, Test Loss: 0.8024, Test Accuracy: 68.35%\n",
      "Epoch [2096/2500], Train Loss: 0.7403, Train Accuracy: 68.42%, Test Loss: 0.7658, Test Accuracy: 69.62%\n",
      "Epoch [2097/2500], Train Loss: 0.7397, Train Accuracy: 67.43%, Test Loss: 0.9329, Test Accuracy: 60.76%\n",
      "Epoch [2098/2500], Train Loss: 0.7609, Train Accuracy: 68.14%, Test Loss: 0.7706, Test Accuracy: 69.62%\n",
      "Epoch [2099/2500], Train Loss: 0.7397, Train Accuracy: 69.70%, Test Loss: 0.7300, Test Accuracy: 68.35%\n",
      "Epoch [2100/2500], Train Loss: 0.7273, Train Accuracy: 68.99%, Test Loss: 0.7413, Test Accuracy: 72.15%\n",
      "Epoch [2101/2500], Train Loss: 0.7415, Train Accuracy: 64.72%, Test Loss: 0.7810, Test Accuracy: 64.56%\n",
      "Epoch [2102/2500], Train Loss: 0.7405, Train Accuracy: 67.85%, Test Loss: 0.7304, Test Accuracy: 69.62%\n",
      "Epoch [2103/2500], Train Loss: 0.7365, Train Accuracy: 67.14%, Test Loss: 0.7632, Test Accuracy: 69.62%\n",
      "Epoch [2104/2500], Train Loss: 0.7839, Train Accuracy: 66.15%, Test Loss: 0.7654, Test Accuracy: 73.42%\n",
      "Epoch [2105/2500], Train Loss: 0.7649, Train Accuracy: 67.85%, Test Loss: 0.7761, Test Accuracy: 67.09%\n",
      "Epoch [2106/2500], Train Loss: 0.7344, Train Accuracy: 68.14%, Test Loss: 0.7905, Test Accuracy: 68.35%\n",
      "Epoch [2107/2500], Train Loss: 0.7301, Train Accuracy: 68.56%, Test Loss: 0.7732, Test Accuracy: 70.89%\n",
      "Epoch [2108/2500], Train Loss: 0.7451, Train Accuracy: 67.14%, Test Loss: 0.7548, Test Accuracy: 70.89%\n",
      "Epoch [2109/2500], Train Loss: 0.7430, Train Accuracy: 67.43%, Test Loss: 0.7766, Test Accuracy: 64.56%\n",
      "Epoch [2110/2500], Train Loss: 0.7444, Train Accuracy: 67.71%, Test Loss: 0.9196, Test Accuracy: 63.29%\n",
      "Epoch [2111/2500], Train Loss: 0.7442, Train Accuracy: 68.56%, Test Loss: 0.7732, Test Accuracy: 67.09%\n",
      "Epoch [2112/2500], Train Loss: 0.7573, Train Accuracy: 66.00%, Test Loss: 0.7464, Test Accuracy: 74.68%\n",
      "Epoch [2113/2500], Train Loss: 0.7578, Train Accuracy: 68.14%, Test Loss: 0.7605, Test Accuracy: 69.62%\n",
      "Epoch [2114/2500], Train Loss: 0.7469, Train Accuracy: 67.99%, Test Loss: 0.8414, Test Accuracy: 64.56%\n",
      "Epoch [2115/2500], Train Loss: 0.7552, Train Accuracy: 67.57%, Test Loss: 0.8171, Test Accuracy: 67.09%\n",
      "Epoch [2116/2500], Train Loss: 0.7568, Train Accuracy: 68.28%, Test Loss: 0.7358, Test Accuracy: 68.35%\n",
      "Epoch [2117/2500], Train Loss: 0.7470, Train Accuracy: 65.43%, Test Loss: 0.8765, Test Accuracy: 65.82%\n",
      "Epoch [2118/2500], Train Loss: 0.7243, Train Accuracy: 68.42%, Test Loss: 0.7586, Test Accuracy: 70.89%\n",
      "Epoch [2119/2500], Train Loss: 0.7514, Train Accuracy: 67.99%, Test Loss: 0.9370, Test Accuracy: 62.03%\n",
      "Epoch [2120/2500], Train Loss: 0.7530, Train Accuracy: 69.56%, Test Loss: 0.7588, Test Accuracy: 68.35%\n",
      "Epoch [2121/2500], Train Loss: 0.7390, Train Accuracy: 68.14%, Test Loss: 0.7378, Test Accuracy: 72.15%\n",
      "Epoch [2122/2500], Train Loss: 0.7669, Train Accuracy: 65.58%, Test Loss: 0.8166, Test Accuracy: 68.35%\n",
      "Epoch [2123/2500], Train Loss: 0.7216, Train Accuracy: 69.27%, Test Loss: 0.8386, Test Accuracy: 64.56%\n",
      "Epoch [2124/2500], Train Loss: 0.7217, Train Accuracy: 66.29%, Test Loss: 0.8226, Test Accuracy: 68.35%\n",
      "Epoch [2125/2500], Train Loss: 0.7389, Train Accuracy: 67.71%, Test Loss: 0.7233, Test Accuracy: 74.68%\n",
      "Epoch [2126/2500], Train Loss: 0.7476, Train Accuracy: 68.42%, Test Loss: 0.7727, Test Accuracy: 67.09%\n",
      "Epoch [2127/2500], Train Loss: 0.7207, Train Accuracy: 68.71%, Test Loss: 0.9529, Test Accuracy: 60.76%\n",
      "Epoch [2128/2500], Train Loss: 0.7425, Train Accuracy: 67.14%, Test Loss: 0.7344, Test Accuracy: 72.15%\n",
      "Epoch [2129/2500], Train Loss: 0.7392, Train Accuracy: 67.85%, Test Loss: 0.7262, Test Accuracy: 70.89%\n",
      "Epoch [2130/2500], Train Loss: 0.7589, Train Accuracy: 67.99%, Test Loss: 0.7837, Test Accuracy: 68.35%\n",
      "Epoch [2131/2500], Train Loss: 0.7560, Train Accuracy: 66.29%, Test Loss: 0.7347, Test Accuracy: 70.89%\n",
      "Epoch [2132/2500], Train Loss: 0.7420, Train Accuracy: 68.71%, Test Loss: 0.7245, Test Accuracy: 72.15%\n",
      "Epoch [2133/2500], Train Loss: 0.7494, Train Accuracy: 68.14%, Test Loss: 0.9360, Test Accuracy: 64.56%\n",
      "Epoch [2134/2500], Train Loss: 0.7716, Train Accuracy: 64.58%, Test Loss: 0.7338, Test Accuracy: 70.89%\n",
      "Epoch [2135/2500], Train Loss: 0.7396, Train Accuracy: 67.99%, Test Loss: 0.8312, Test Accuracy: 67.09%\n",
      "Epoch [2136/2500], Train Loss: 0.7460, Train Accuracy: 68.99%, Test Loss: 0.7701, Test Accuracy: 72.15%\n",
      "Epoch [2137/2500], Train Loss: 0.7577, Train Accuracy: 66.00%, Test Loss: 0.7497, Test Accuracy: 70.89%\n",
      "Epoch [2138/2500], Train Loss: 0.7363, Train Accuracy: 68.14%, Test Loss: 0.7606, Test Accuracy: 70.89%\n",
      "Epoch [2139/2500], Train Loss: 0.7487, Train Accuracy: 69.13%, Test Loss: 0.8085, Test Accuracy: 70.89%\n",
      "Epoch [2140/2500], Train Loss: 0.7629, Train Accuracy: 67.14%, Test Loss: 0.7926, Test Accuracy: 68.35%\n",
      "Epoch [2141/2500], Train Loss: 0.7478, Train Accuracy: 67.57%, Test Loss: 0.7710, Test Accuracy: 69.62%\n",
      "Epoch [2142/2500], Train Loss: 0.7529, Train Accuracy: 66.86%, Test Loss: 0.7977, Test Accuracy: 68.35%\n",
      "Epoch [2143/2500], Train Loss: 0.7604, Train Accuracy: 68.14%, Test Loss: 0.7928, Test Accuracy: 68.35%\n",
      "Epoch [2144/2500], Train Loss: 0.7370, Train Accuracy: 67.99%, Test Loss: 0.8042, Test Accuracy: 67.09%\n",
      "Epoch [2145/2500], Train Loss: 0.7433, Train Accuracy: 67.99%, Test Loss: 0.7859, Test Accuracy: 65.82%\n",
      "Epoch [2146/2500], Train Loss: 0.7283, Train Accuracy: 69.27%, Test Loss: 0.7489, Test Accuracy: 72.15%\n",
      "Epoch [2147/2500], Train Loss: 0.7325, Train Accuracy: 67.14%, Test Loss: 0.7796, Test Accuracy: 69.62%\n",
      "Epoch [2148/2500], Train Loss: 0.7512, Train Accuracy: 66.00%, Test Loss: 0.8033, Test Accuracy: 72.15%\n",
      "Epoch [2149/2500], Train Loss: 0.7251, Train Accuracy: 68.99%, Test Loss: 0.7304, Test Accuracy: 69.62%\n",
      "Epoch [2150/2500], Train Loss: 0.7612, Train Accuracy: 68.14%, Test Loss: 0.7522, Test Accuracy: 70.89%\n",
      "Epoch [2151/2500], Train Loss: 0.7314, Train Accuracy: 66.86%, Test Loss: 0.7630, Test Accuracy: 69.62%\n",
      "Epoch [2152/2500], Train Loss: 0.7546, Train Accuracy: 67.71%, Test Loss: 0.7507, Test Accuracy: 65.82%\n",
      "Epoch [2153/2500], Train Loss: 0.7452, Train Accuracy: 65.15%, Test Loss: 0.7519, Test Accuracy: 68.35%\n",
      "Epoch [2154/2500], Train Loss: 0.7232, Train Accuracy: 69.27%, Test Loss: 0.7607, Test Accuracy: 70.89%\n",
      "Epoch [2155/2500], Train Loss: 0.7276, Train Accuracy: 68.28%, Test Loss: 0.8208, Test Accuracy: 64.56%\n",
      "Epoch [2156/2500], Train Loss: 0.7474, Train Accuracy: 67.00%, Test Loss: 0.8702, Test Accuracy: 63.29%\n",
      "Epoch [2157/2500], Train Loss: 0.7113, Train Accuracy: 69.13%, Test Loss: 0.7466, Test Accuracy: 67.09%\n",
      "Epoch [2158/2500], Train Loss: 0.7366, Train Accuracy: 68.71%, Test Loss: 0.7991, Test Accuracy: 69.62%\n",
      "Epoch [2159/2500], Train Loss: 0.7603, Train Accuracy: 67.14%, Test Loss: 0.7644, Test Accuracy: 70.89%\n",
      "Epoch [2160/2500], Train Loss: 0.7389, Train Accuracy: 69.27%, Test Loss: 0.7541, Test Accuracy: 72.15%\n",
      "Epoch [2161/2500], Train Loss: 0.7735, Train Accuracy: 66.29%, Test Loss: 0.7735, Test Accuracy: 70.89%\n",
      "Epoch [2162/2500], Train Loss: 0.7240, Train Accuracy: 67.99%, Test Loss: 0.7736, Test Accuracy: 72.15%\n",
      "Epoch [2163/2500], Train Loss: 0.7619, Train Accuracy: 67.28%, Test Loss: 0.9125, Test Accuracy: 64.56%\n",
      "Epoch [2164/2500], Train Loss: 0.7561, Train Accuracy: 67.85%, Test Loss: 0.7392, Test Accuracy: 67.09%\n",
      "Epoch [2165/2500], Train Loss: 0.7341, Train Accuracy: 67.57%, Test Loss: 0.7573, Test Accuracy: 72.15%\n",
      "Epoch [2166/2500], Train Loss: 0.7408, Train Accuracy: 67.71%, Test Loss: 0.8420, Test Accuracy: 63.29%\n",
      "Epoch [2167/2500], Train Loss: 0.7351, Train Accuracy: 67.28%, Test Loss: 0.7444, Test Accuracy: 73.42%\n",
      "Epoch [2168/2500], Train Loss: 0.7595, Train Accuracy: 65.58%, Test Loss: 0.8645, Test Accuracy: 64.56%\n",
      "Epoch [2169/2500], Train Loss: 0.7500, Train Accuracy: 68.71%, Test Loss: 0.8333, Test Accuracy: 67.09%\n",
      "Epoch [2170/2500], Train Loss: 0.7582, Train Accuracy: 66.15%, Test Loss: 0.7580, Test Accuracy: 69.62%\n",
      "Epoch [2171/2500], Train Loss: 0.7306, Train Accuracy: 68.56%, Test Loss: 0.7528, Test Accuracy: 70.89%\n",
      "Epoch [2172/2500], Train Loss: 0.7177, Train Accuracy: 68.71%, Test Loss: 0.7597, Test Accuracy: 72.15%\n",
      "Epoch [2173/2500], Train Loss: 0.7545, Train Accuracy: 67.43%, Test Loss: 0.7648, Test Accuracy: 69.62%\n",
      "Epoch [2174/2500], Train Loss: 0.7325, Train Accuracy: 66.71%, Test Loss: 0.7817, Test Accuracy: 72.15%\n",
      "Epoch [2175/2500], Train Loss: 0.7474, Train Accuracy: 67.28%, Test Loss: 0.7471, Test Accuracy: 72.15%\n",
      "Epoch [2176/2500], Train Loss: 0.7420, Train Accuracy: 67.99%, Test Loss: 0.8851, Test Accuracy: 64.56%\n",
      "Epoch [2177/2500], Train Loss: 0.7324, Train Accuracy: 69.84%, Test Loss: 0.7390, Test Accuracy: 74.68%\n",
      "Epoch [2178/2500], Train Loss: 0.7526, Train Accuracy: 67.28%, Test Loss: 0.9266, Test Accuracy: 62.03%\n",
      "Epoch [2179/2500], Train Loss: 0.7391, Train Accuracy: 66.86%, Test Loss: 0.7796, Test Accuracy: 70.89%\n",
      "Epoch [2180/2500], Train Loss: 0.7629, Train Accuracy: 66.00%, Test Loss: 0.7725, Test Accuracy: 69.62%\n",
      "Epoch [2181/2500], Train Loss: 0.7550, Train Accuracy: 66.86%, Test Loss: 0.7322, Test Accuracy: 69.62%\n",
      "Epoch [2182/2500], Train Loss: 0.7352, Train Accuracy: 68.56%, Test Loss: 0.7226, Test Accuracy: 73.42%\n",
      "Epoch [2183/2500], Train Loss: 0.7609, Train Accuracy: 65.29%, Test Loss: 0.7524, Test Accuracy: 69.62%\n",
      "Epoch [2184/2500], Train Loss: 0.7526, Train Accuracy: 66.71%, Test Loss: 0.8653, Test Accuracy: 68.35%\n",
      "Epoch [2185/2500], Train Loss: 0.7404, Train Accuracy: 67.28%, Test Loss: 0.8251, Test Accuracy: 67.09%\n",
      "Epoch [2186/2500], Train Loss: 0.7293, Train Accuracy: 68.56%, Test Loss: 0.8282, Test Accuracy: 67.09%\n",
      "Epoch [2187/2500], Train Loss: 0.7502, Train Accuracy: 67.28%, Test Loss: 0.7608, Test Accuracy: 73.42%\n",
      "Epoch [2188/2500], Train Loss: 0.7588, Train Accuracy: 69.56%, Test Loss: 0.7430, Test Accuracy: 73.42%\n",
      "Epoch [2189/2500], Train Loss: 0.7434, Train Accuracy: 68.85%, Test Loss: 0.7346, Test Accuracy: 73.42%\n",
      "Epoch [2190/2500], Train Loss: 0.7382, Train Accuracy: 67.14%, Test Loss: 0.7523, Test Accuracy: 72.15%\n",
      "Epoch [2191/2500], Train Loss: 0.7530, Train Accuracy: 67.99%, Test Loss: 0.7614, Test Accuracy: 70.89%\n",
      "Epoch [2192/2500], Train Loss: 0.7520, Train Accuracy: 67.43%, Test Loss: 0.7897, Test Accuracy: 64.56%\n",
      "Epoch [2193/2500], Train Loss: 0.7358, Train Accuracy: 68.85%, Test Loss: 0.7453, Test Accuracy: 67.09%\n",
      "Epoch [2194/2500], Train Loss: 0.7638, Train Accuracy: 67.57%, Test Loss: 0.7353, Test Accuracy: 69.62%\n",
      "Epoch [2195/2500], Train Loss: 0.7370, Train Accuracy: 67.99%, Test Loss: 0.7831, Test Accuracy: 68.35%\n",
      "Epoch [2196/2500], Train Loss: 0.7554, Train Accuracy: 68.56%, Test Loss: 0.8432, Test Accuracy: 67.09%\n",
      "Epoch [2197/2500], Train Loss: 0.7550, Train Accuracy: 67.99%, Test Loss: 0.8497, Test Accuracy: 67.09%\n",
      "Epoch [2198/2500], Train Loss: 0.7458, Train Accuracy: 67.43%, Test Loss: 0.9154, Test Accuracy: 62.03%\n",
      "Epoch [2199/2500], Train Loss: 0.7306, Train Accuracy: 68.14%, Test Loss: 0.8079, Test Accuracy: 69.62%\n",
      "Epoch [2200/2500], Train Loss: 0.7633, Train Accuracy: 67.14%, Test Loss: 0.7351, Test Accuracy: 68.35%\n",
      "Epoch [2201/2500], Train Loss: 0.7222, Train Accuracy: 69.99%, Test Loss: 0.8308, Test Accuracy: 68.35%\n",
      "Epoch [2202/2500], Train Loss: 0.7422, Train Accuracy: 69.56%, Test Loss: 0.7385, Test Accuracy: 69.62%\n",
      "Epoch [2203/2500], Train Loss: 0.7360, Train Accuracy: 69.13%, Test Loss: 0.8427, Test Accuracy: 67.09%\n",
      "Epoch [2204/2500], Train Loss: 0.7501, Train Accuracy: 67.00%, Test Loss: 0.7298, Test Accuracy: 70.89%\n",
      "Epoch [2205/2500], Train Loss: 0.7327, Train Accuracy: 67.14%, Test Loss: 0.7540, Test Accuracy: 70.89%\n",
      "Epoch [2206/2500], Train Loss: 0.7376, Train Accuracy: 67.57%, Test Loss: 0.7888, Test Accuracy: 69.62%\n",
      "Epoch [2207/2500], Train Loss: 0.7687, Train Accuracy: 67.43%, Test Loss: 0.7629, Test Accuracy: 70.89%\n",
      "Epoch [2208/2500], Train Loss: 0.7320, Train Accuracy: 65.58%, Test Loss: 0.7992, Test Accuracy: 69.62%\n",
      "Epoch [2209/2500], Train Loss: 0.7444, Train Accuracy: 66.57%, Test Loss: 0.7322, Test Accuracy: 68.35%\n",
      "Epoch [2210/2500], Train Loss: 0.7524, Train Accuracy: 67.43%, Test Loss: 0.7989, Test Accuracy: 69.62%\n",
      "Epoch [2211/2500], Train Loss: 0.7379, Train Accuracy: 67.00%, Test Loss: 0.7706, Test Accuracy: 70.89%\n",
      "Epoch [2212/2500], Train Loss: 0.7443, Train Accuracy: 68.28%, Test Loss: 0.7662, Test Accuracy: 69.62%\n",
      "Epoch [2213/2500], Train Loss: 0.7735, Train Accuracy: 67.57%, Test Loss: 0.8606, Test Accuracy: 63.29%\n",
      "Epoch [2214/2500], Train Loss: 0.7631, Train Accuracy: 66.86%, Test Loss: 0.7466, Test Accuracy: 69.62%\n",
      "Epoch [2215/2500], Train Loss: 0.7490, Train Accuracy: 67.85%, Test Loss: 0.7650, Test Accuracy: 70.89%\n",
      "Epoch [2216/2500], Train Loss: 0.7507, Train Accuracy: 66.86%, Test Loss: 0.7880, Test Accuracy: 68.35%\n",
      "Epoch [2217/2500], Train Loss: 0.7588, Train Accuracy: 66.15%, Test Loss: 0.7295, Test Accuracy: 73.42%\n",
      "Epoch [2218/2500], Train Loss: 0.7381, Train Accuracy: 68.28%, Test Loss: 0.9093, Test Accuracy: 62.03%\n",
      "Epoch [2219/2500], Train Loss: 0.7385, Train Accuracy: 67.00%, Test Loss: 0.7870, Test Accuracy: 65.82%\n",
      "Epoch [2220/2500], Train Loss: 0.7425, Train Accuracy: 67.14%, Test Loss: 0.7156, Test Accuracy: 69.62%\n",
      "Epoch [2221/2500], Train Loss: 0.7259, Train Accuracy: 67.28%, Test Loss: 0.7151, Test Accuracy: 70.89%\n",
      "Epoch [2222/2500], Train Loss: 0.7271, Train Accuracy: 67.85%, Test Loss: 0.8082, Test Accuracy: 65.82%\n",
      "Epoch [2223/2500], Train Loss: 0.7519, Train Accuracy: 69.42%, Test Loss: 0.7171, Test Accuracy: 68.35%\n",
      "Epoch [2224/2500], Train Loss: 0.7515, Train Accuracy: 67.28%, Test Loss: 0.7619, Test Accuracy: 69.62%\n",
      "Epoch [2225/2500], Train Loss: 0.7299, Train Accuracy: 67.85%, Test Loss: 0.7465, Test Accuracy: 72.15%\n",
      "Epoch [2226/2500], Train Loss: 0.7435, Train Accuracy: 67.43%, Test Loss: 0.7379, Test Accuracy: 72.15%\n",
      "Epoch [2227/2500], Train Loss: 0.7381, Train Accuracy: 67.43%, Test Loss: 0.7297, Test Accuracy: 70.89%\n",
      "Epoch [2228/2500], Train Loss: 0.7691, Train Accuracy: 66.57%, Test Loss: 0.7567, Test Accuracy: 72.15%\n",
      "Epoch [2229/2500], Train Loss: 0.7394, Train Accuracy: 69.13%, Test Loss: 0.9469, Test Accuracy: 64.56%\n",
      "Epoch [2230/2500], Train Loss: 0.7288, Train Accuracy: 67.85%, Test Loss: 0.8003, Test Accuracy: 70.89%\n",
      "Epoch [2231/2500], Train Loss: 0.7615, Train Accuracy: 68.85%, Test Loss: 0.7608, Test Accuracy: 70.89%\n",
      "Epoch [2232/2500], Train Loss: 0.7395, Train Accuracy: 68.71%, Test Loss: 0.7592, Test Accuracy: 69.62%\n",
      "Epoch [2233/2500], Train Loss: 0.7336, Train Accuracy: 68.28%, Test Loss: 0.7413, Test Accuracy: 72.15%\n",
      "Epoch [2234/2500], Train Loss: 0.7204, Train Accuracy: 68.14%, Test Loss: 0.8448, Test Accuracy: 67.09%\n",
      "Epoch [2235/2500], Train Loss: 0.7273, Train Accuracy: 68.71%, Test Loss: 0.7754, Test Accuracy: 67.09%\n",
      "Epoch [2236/2500], Train Loss: 0.7269, Train Accuracy: 67.99%, Test Loss: 0.7412, Test Accuracy: 70.89%\n",
      "Epoch [2237/2500], Train Loss: 0.7654, Train Accuracy: 66.86%, Test Loss: 0.8903, Test Accuracy: 62.03%\n",
      "Epoch [2238/2500], Train Loss: 0.7472, Train Accuracy: 68.14%, Test Loss: 0.7660, Test Accuracy: 72.15%\n",
      "Epoch [2239/2500], Train Loss: 0.7609, Train Accuracy: 65.58%, Test Loss: 0.7819, Test Accuracy: 70.89%\n",
      "Epoch [2240/2500], Train Loss: 0.7699, Train Accuracy: 67.28%, Test Loss: 0.7029, Test Accuracy: 73.42%\n",
      "Epoch [2241/2500], Train Loss: 0.7491, Train Accuracy: 67.14%, Test Loss: 0.7241, Test Accuracy: 70.89%\n",
      "Epoch [2242/2500], Train Loss: 0.7176, Train Accuracy: 68.14%, Test Loss: 0.7278, Test Accuracy: 72.15%\n",
      "Epoch [2243/2500], Train Loss: 0.7639, Train Accuracy: 67.00%, Test Loss: 0.7296, Test Accuracy: 69.62%\n",
      "Epoch [2244/2500], Train Loss: 0.7420, Train Accuracy: 68.14%, Test Loss: 0.7955, Test Accuracy: 69.62%\n",
      "Epoch [2245/2500], Train Loss: 0.7278, Train Accuracy: 68.28%, Test Loss: 0.8332, Test Accuracy: 65.82%\n",
      "Epoch [2246/2500], Train Loss: 0.7546, Train Accuracy: 67.85%, Test Loss: 0.7852, Test Accuracy: 69.62%\n",
      "Epoch [2247/2500], Train Loss: 0.7573, Train Accuracy: 69.84%, Test Loss: 0.7527, Test Accuracy: 72.15%\n",
      "Epoch [2248/2500], Train Loss: 0.7373, Train Accuracy: 67.14%, Test Loss: 0.7482, Test Accuracy: 73.42%\n",
      "Epoch [2249/2500], Train Loss: 0.7602, Train Accuracy: 67.00%, Test Loss: 0.7931, Test Accuracy: 67.09%\n",
      "Epoch [2250/2500], Train Loss: 0.7412, Train Accuracy: 67.99%, Test Loss: 0.7511, Test Accuracy: 68.35%\n",
      "Epoch [2251/2500], Train Loss: 0.7327, Train Accuracy: 68.71%, Test Loss: 0.7879, Test Accuracy: 68.35%\n",
      "Epoch [2252/2500], Train Loss: 0.7386, Train Accuracy: 68.56%, Test Loss: 0.7351, Test Accuracy: 72.15%\n",
      "Epoch [2253/2500], Train Loss: 0.7438, Train Accuracy: 68.14%, Test Loss: 0.7420, Test Accuracy: 67.09%\n",
      "Epoch [2254/2500], Train Loss: 0.7733, Train Accuracy: 67.43%, Test Loss: 0.7120, Test Accuracy: 67.09%\n",
      "Epoch [2255/2500], Train Loss: 0.7392, Train Accuracy: 67.71%, Test Loss: 0.7087, Test Accuracy: 68.35%\n",
      "Epoch [2256/2500], Train Loss: 0.7538, Train Accuracy: 67.43%, Test Loss: 0.7582, Test Accuracy: 72.15%\n",
      "Epoch [2257/2500], Train Loss: 0.7304, Train Accuracy: 68.42%, Test Loss: 0.7409, Test Accuracy: 73.42%\n",
      "Epoch [2258/2500], Train Loss: 0.7474, Train Accuracy: 67.85%, Test Loss: 0.7671, Test Accuracy: 72.15%\n",
      "Epoch [2259/2500], Train Loss: 0.7288, Train Accuracy: 67.99%, Test Loss: 0.7548, Test Accuracy: 70.89%\n",
      "Epoch [2260/2500], Train Loss: 0.7452, Train Accuracy: 67.00%, Test Loss: 0.7218, Test Accuracy: 72.15%\n",
      "Epoch [2261/2500], Train Loss: 0.7436, Train Accuracy: 67.71%, Test Loss: 0.7433, Test Accuracy: 68.35%\n",
      "Epoch [2262/2500], Train Loss: 0.7681, Train Accuracy: 67.43%, Test Loss: 0.8720, Test Accuracy: 65.82%\n",
      "Epoch [2263/2500], Train Loss: 0.7609, Train Accuracy: 66.86%, Test Loss: 0.8840, Test Accuracy: 62.03%\n",
      "Epoch [2264/2500], Train Loss: 0.7507, Train Accuracy: 67.85%, Test Loss: 0.7416, Test Accuracy: 73.42%\n",
      "Epoch [2265/2500], Train Loss: 0.7229, Train Accuracy: 69.56%, Test Loss: 0.7929, Test Accuracy: 68.35%\n",
      "Epoch [2266/2500], Train Loss: 0.7232, Train Accuracy: 71.12%, Test Loss: 0.8019, Test Accuracy: 69.62%\n",
      "Epoch [2267/2500], Train Loss: 0.7374, Train Accuracy: 68.99%, Test Loss: 0.7180, Test Accuracy: 68.35%\n",
      "Epoch [2268/2500], Train Loss: 0.7452, Train Accuracy: 67.28%, Test Loss: 0.8621, Test Accuracy: 65.82%\n",
      "Epoch [2269/2500], Train Loss: 0.7507, Train Accuracy: 67.85%, Test Loss: 0.7662, Test Accuracy: 70.89%\n",
      "Epoch [2270/2500], Train Loss: 0.7381, Train Accuracy: 68.99%, Test Loss: 0.7600, Test Accuracy: 68.35%\n",
      "Epoch [2271/2500], Train Loss: 0.7678, Train Accuracy: 66.00%, Test Loss: 0.7318, Test Accuracy: 69.62%\n",
      "Epoch [2272/2500], Train Loss: 0.7285, Train Accuracy: 66.29%, Test Loss: 0.7900, Test Accuracy: 72.15%\n",
      "Epoch [2273/2500], Train Loss: 0.7289, Train Accuracy: 67.57%, Test Loss: 0.7563, Test Accuracy: 69.62%\n",
      "Epoch [2274/2500], Train Loss: 0.7227, Train Accuracy: 69.27%, Test Loss: 0.7321, Test Accuracy: 68.35%\n",
      "Epoch [2275/2500], Train Loss: 0.7482, Train Accuracy: 68.28%, Test Loss: 0.7506, Test Accuracy: 73.42%\n",
      "Epoch [2276/2500], Train Loss: 0.7477, Train Accuracy: 68.14%, Test Loss: 0.7120, Test Accuracy: 69.62%\n",
      "Epoch [2277/2500], Train Loss: 0.7450, Train Accuracy: 66.29%, Test Loss: 0.7989, Test Accuracy: 67.09%\n",
      "Epoch [2278/2500], Train Loss: 0.7599, Train Accuracy: 68.42%, Test Loss: 0.9345, Test Accuracy: 63.29%\n",
      "Epoch [2279/2500], Train Loss: 0.7380, Train Accuracy: 66.57%, Test Loss: 0.7229, Test Accuracy: 70.89%\n",
      "Epoch [2280/2500], Train Loss: 0.7504, Train Accuracy: 67.71%, Test Loss: 0.7402, Test Accuracy: 70.89%\n",
      "Epoch [2281/2500], Train Loss: 0.7276, Train Accuracy: 69.99%, Test Loss: 0.7693, Test Accuracy: 69.62%\n",
      "Epoch [2282/2500], Train Loss: 0.7387, Train Accuracy: 66.86%, Test Loss: 0.7871, Test Accuracy: 69.62%\n",
      "Epoch [2283/2500], Train Loss: 0.7606, Train Accuracy: 68.28%, Test Loss: 0.7859, Test Accuracy: 70.89%\n",
      "Epoch [2284/2500], Train Loss: 0.7254, Train Accuracy: 70.84%, Test Loss: 0.8010, Test Accuracy: 69.62%\n",
      "Epoch [2285/2500], Train Loss: 0.7532, Train Accuracy: 66.43%, Test Loss: 0.7426, Test Accuracy: 73.42%\n",
      "Epoch [2286/2500], Train Loss: 0.7471, Train Accuracy: 67.99%, Test Loss: 0.7237, Test Accuracy: 68.35%\n",
      "Epoch [2287/2500], Train Loss: 0.7054, Train Accuracy: 69.70%, Test Loss: 0.7805, Test Accuracy: 69.62%\n",
      "Epoch [2288/2500], Train Loss: 0.7396, Train Accuracy: 68.28%, Test Loss: 0.7754, Test Accuracy: 70.89%\n",
      "Epoch [2289/2500], Train Loss: 0.7359, Train Accuracy: 69.27%, Test Loss: 0.7646, Test Accuracy: 69.62%\n",
      "Epoch [2290/2500], Train Loss: 0.7560, Train Accuracy: 66.43%, Test Loss: 0.7594, Test Accuracy: 69.62%\n",
      "Epoch [2291/2500], Train Loss: 0.7471, Train Accuracy: 67.71%, Test Loss: 0.7516, Test Accuracy: 70.89%\n",
      "Epoch [2292/2500], Train Loss: 0.7424, Train Accuracy: 68.28%, Test Loss: 0.7922, Test Accuracy: 65.82%\n",
      "Epoch [2293/2500], Train Loss: 0.7187, Train Accuracy: 68.71%, Test Loss: 0.7201, Test Accuracy: 69.62%\n",
      "Epoch [2294/2500], Train Loss: 0.7252, Train Accuracy: 68.28%, Test Loss: 0.7160, Test Accuracy: 74.68%\n",
      "Epoch [2295/2500], Train Loss: 0.7113, Train Accuracy: 70.13%, Test Loss: 0.7534, Test Accuracy: 70.89%\n",
      "Epoch [2296/2500], Train Loss: 0.7384, Train Accuracy: 67.85%, Test Loss: 0.7611, Test Accuracy: 72.15%\n",
      "Epoch [2297/2500], Train Loss: 0.7443, Train Accuracy: 69.13%, Test Loss: 0.7623, Test Accuracy: 73.42%\n",
      "Epoch [2298/2500], Train Loss: 0.7498, Train Accuracy: 67.99%, Test Loss: 0.7277, Test Accuracy: 68.35%\n",
      "Epoch [2299/2500], Train Loss: 0.7193, Train Accuracy: 68.14%, Test Loss: 0.7416, Test Accuracy: 72.15%\n",
      "Epoch [2300/2500], Train Loss: 0.7528, Train Accuracy: 67.85%, Test Loss: 0.8090, Test Accuracy: 70.89%\n",
      "Epoch [2301/2500], Train Loss: 0.7365, Train Accuracy: 67.71%, Test Loss: 0.8900, Test Accuracy: 63.29%\n",
      "Epoch [2302/2500], Train Loss: 0.7475, Train Accuracy: 68.56%, Test Loss: 0.7944, Test Accuracy: 70.89%\n",
      "Epoch [2303/2500], Train Loss: 0.7329, Train Accuracy: 67.71%, Test Loss: 0.8083, Test Accuracy: 67.09%\n",
      "Epoch [2304/2500], Train Loss: 0.7443, Train Accuracy: 65.86%, Test Loss: 0.7777, Test Accuracy: 68.35%\n",
      "Epoch [2305/2500], Train Loss: 0.7594, Train Accuracy: 67.43%, Test Loss: 0.7599, Test Accuracy: 70.89%\n",
      "Epoch [2306/2500], Train Loss: 0.7361, Train Accuracy: 67.57%, Test Loss: 0.7838, Test Accuracy: 68.35%\n",
      "Epoch [2307/2500], Train Loss: 0.7496, Train Accuracy: 67.43%, Test Loss: 0.7175, Test Accuracy: 68.35%\n",
      "Epoch [2308/2500], Train Loss: 0.7137, Train Accuracy: 70.98%, Test Loss: 0.7755, Test Accuracy: 70.89%\n",
      "Epoch [2309/2500], Train Loss: 0.7462, Train Accuracy: 67.14%, Test Loss: 0.7646, Test Accuracy: 68.35%\n",
      "Epoch [2310/2500], Train Loss: 0.7398, Train Accuracy: 68.85%, Test Loss: 0.7374, Test Accuracy: 70.89%\n",
      "Epoch [2311/2500], Train Loss: 0.7341, Train Accuracy: 68.85%, Test Loss: 0.7719, Test Accuracy: 72.15%\n",
      "Epoch [2312/2500], Train Loss: 0.7342, Train Accuracy: 68.56%, Test Loss: 0.7489, Test Accuracy: 70.89%\n",
      "Epoch [2313/2500], Train Loss: 0.7363, Train Accuracy: 68.42%, Test Loss: 0.7474, Test Accuracy: 70.89%\n",
      "Epoch [2314/2500], Train Loss: 0.7174, Train Accuracy: 68.42%, Test Loss: 0.7695, Test Accuracy: 70.89%\n",
      "Epoch [2315/2500], Train Loss: 0.7267, Train Accuracy: 68.71%, Test Loss: 0.8325, Test Accuracy: 63.29%\n",
      "Epoch [2316/2500], Train Loss: 0.7722, Train Accuracy: 66.57%, Test Loss: 0.7619, Test Accuracy: 72.15%\n",
      "Epoch [2317/2500], Train Loss: 0.7400, Train Accuracy: 67.43%, Test Loss: 0.7216, Test Accuracy: 73.42%\n",
      "Epoch [2318/2500], Train Loss: 0.7275, Train Accuracy: 70.70%, Test Loss: 0.7463, Test Accuracy: 68.35%\n",
      "Epoch [2319/2500], Train Loss: 0.7431, Train Accuracy: 69.13%, Test Loss: 0.7707, Test Accuracy: 70.89%\n",
      "Epoch [2320/2500], Train Loss: 0.7648, Train Accuracy: 67.99%, Test Loss: 0.7515, Test Accuracy: 72.15%\n",
      "Epoch [2321/2500], Train Loss: 0.7537, Train Accuracy: 66.86%, Test Loss: 0.7308, Test Accuracy: 69.62%\n",
      "Epoch [2322/2500], Train Loss: 0.7591, Train Accuracy: 67.85%, Test Loss: 0.8040, Test Accuracy: 68.35%\n",
      "Epoch [2323/2500], Train Loss: 0.7561, Train Accuracy: 66.29%, Test Loss: 0.7704, Test Accuracy: 68.35%\n",
      "Epoch [2324/2500], Train Loss: 0.7302, Train Accuracy: 68.28%, Test Loss: 0.7466, Test Accuracy: 70.89%\n",
      "Epoch [2325/2500], Train Loss: 0.7420, Train Accuracy: 67.00%, Test Loss: 0.7644, Test Accuracy: 68.35%\n",
      "Epoch [2326/2500], Train Loss: 0.7430, Train Accuracy: 66.71%, Test Loss: 0.7187, Test Accuracy: 70.89%\n",
      "Epoch [2327/2500], Train Loss: 0.7350, Train Accuracy: 68.99%, Test Loss: 0.8441, Test Accuracy: 64.56%\n",
      "Epoch [2328/2500], Train Loss: 0.7492, Train Accuracy: 68.42%, Test Loss: 0.7400, Test Accuracy: 73.42%\n",
      "Epoch [2329/2500], Train Loss: 0.7563, Train Accuracy: 66.71%, Test Loss: 0.8457, Test Accuracy: 67.09%\n",
      "Epoch [2330/2500], Train Loss: 0.7395, Train Accuracy: 68.14%, Test Loss: 0.7863, Test Accuracy: 68.35%\n",
      "Epoch [2331/2500], Train Loss: 0.7408, Train Accuracy: 66.71%, Test Loss: 0.8602, Test Accuracy: 63.29%\n",
      "Epoch [2332/2500], Train Loss: 0.7254, Train Accuracy: 66.43%, Test Loss: 0.7830, Test Accuracy: 69.62%\n",
      "Epoch [2333/2500], Train Loss: 0.7081, Train Accuracy: 67.85%, Test Loss: 0.7874, Test Accuracy: 68.35%\n",
      "Epoch [2334/2500], Train Loss: 0.7447, Train Accuracy: 67.00%, Test Loss: 0.7441, Test Accuracy: 73.42%\n",
      "Epoch [2335/2500], Train Loss: 0.7578, Train Accuracy: 67.14%, Test Loss: 0.8988, Test Accuracy: 64.56%\n",
      "Epoch [2336/2500], Train Loss: 0.7239, Train Accuracy: 69.13%, Test Loss: 0.8645, Test Accuracy: 62.03%\n",
      "Epoch [2337/2500], Train Loss: 0.7426, Train Accuracy: 68.99%, Test Loss: 0.7780, Test Accuracy: 72.15%\n",
      "Epoch [2338/2500], Train Loss: 0.7482, Train Accuracy: 66.86%, Test Loss: 0.7311, Test Accuracy: 68.35%\n",
      "Epoch [2339/2500], Train Loss: 0.7580, Train Accuracy: 66.29%, Test Loss: 0.7167, Test Accuracy: 68.35%\n",
      "Epoch [2340/2500], Train Loss: 0.7209, Train Accuracy: 67.57%, Test Loss: 0.7294, Test Accuracy: 68.35%\n",
      "Epoch [2341/2500], Train Loss: 0.7253, Train Accuracy: 68.56%, Test Loss: 0.7245, Test Accuracy: 69.62%\n",
      "Epoch [2342/2500], Train Loss: 0.7491, Train Accuracy: 66.86%, Test Loss: 0.8818, Test Accuracy: 63.29%\n",
      "Epoch [2343/2500], Train Loss: 0.7200, Train Accuracy: 68.85%, Test Loss: 0.7202, Test Accuracy: 69.62%\n",
      "Epoch [2344/2500], Train Loss: 0.7576, Train Accuracy: 66.43%, Test Loss: 0.7894, Test Accuracy: 65.82%\n",
      "Epoch [2345/2500], Train Loss: 0.7510, Train Accuracy: 67.85%, Test Loss: 0.7048, Test Accuracy: 72.15%\n",
      "Epoch [2346/2500], Train Loss: 0.7401, Train Accuracy: 68.14%, Test Loss: 0.8228, Test Accuracy: 64.56%\n",
      "Epoch [2347/2500], Train Loss: 0.7382, Train Accuracy: 68.14%, Test Loss: 0.7688, Test Accuracy: 68.35%\n",
      "Epoch [2348/2500], Train Loss: 0.7203, Train Accuracy: 69.84%, Test Loss: 0.8611, Test Accuracy: 67.09%\n",
      "Epoch [2349/2500], Train Loss: 0.7153, Train Accuracy: 69.42%, Test Loss: 0.7796, Test Accuracy: 69.62%\n",
      "Epoch [2350/2500], Train Loss: 0.7446, Train Accuracy: 67.14%, Test Loss: 0.7501, Test Accuracy: 69.62%\n",
      "Epoch [2351/2500], Train Loss: 0.7370, Train Accuracy: 65.86%, Test Loss: 0.7374, Test Accuracy: 68.35%\n",
      "Epoch [2352/2500], Train Loss: 0.7418, Train Accuracy: 68.56%, Test Loss: 0.8203, Test Accuracy: 68.35%\n",
      "Epoch [2353/2500], Train Loss: 0.7423, Train Accuracy: 69.56%, Test Loss: 0.8215, Test Accuracy: 68.35%\n",
      "Epoch [2354/2500], Train Loss: 0.7477, Train Accuracy: 66.86%, Test Loss: 0.7989, Test Accuracy: 65.82%\n",
      "Epoch [2355/2500], Train Loss: 0.7097, Train Accuracy: 67.57%, Test Loss: 0.8254, Test Accuracy: 67.09%\n",
      "Epoch [2356/2500], Train Loss: 0.7532, Train Accuracy: 68.71%, Test Loss: 0.7712, Test Accuracy: 70.89%\n",
      "Epoch [2357/2500], Train Loss: 0.7464, Train Accuracy: 66.71%, Test Loss: 0.7203, Test Accuracy: 72.15%\n",
      "Epoch [2358/2500], Train Loss: 0.7845, Train Accuracy: 67.57%, Test Loss: 0.8512, Test Accuracy: 65.82%\n",
      "Epoch [2359/2500], Train Loss: 0.7317, Train Accuracy: 67.85%, Test Loss: 0.7634, Test Accuracy: 67.09%\n",
      "Epoch [2360/2500], Train Loss: 0.7489, Train Accuracy: 65.58%, Test Loss: 0.7448, Test Accuracy: 72.15%\n",
      "Epoch [2361/2500], Train Loss: 0.7451, Train Accuracy: 68.42%, Test Loss: 0.7332, Test Accuracy: 73.42%\n",
      "Epoch [2362/2500], Train Loss: 0.7516, Train Accuracy: 67.71%, Test Loss: 0.7449, Test Accuracy: 70.89%\n",
      "Epoch [2363/2500], Train Loss: 0.7446, Train Accuracy: 67.00%, Test Loss: 0.7395, Test Accuracy: 70.89%\n",
      "Epoch [2364/2500], Train Loss: 0.7527, Train Accuracy: 68.71%, Test Loss: 0.7803, Test Accuracy: 67.09%\n",
      "Epoch [2365/2500], Train Loss: 0.7501, Train Accuracy: 66.71%, Test Loss: 0.7281, Test Accuracy: 72.15%\n",
      "Epoch [2366/2500], Train Loss: 0.7196, Train Accuracy: 68.14%, Test Loss: 0.7462, Test Accuracy: 72.15%\n",
      "Epoch [2367/2500], Train Loss: 0.7416, Train Accuracy: 68.28%, Test Loss: 0.7568, Test Accuracy: 70.89%\n",
      "Epoch [2368/2500], Train Loss: 0.7799, Train Accuracy: 65.43%, Test Loss: 0.7418, Test Accuracy: 72.15%\n",
      "Epoch [2369/2500], Train Loss: 0.7736, Train Accuracy: 68.28%, Test Loss: 0.8224, Test Accuracy: 64.56%\n",
      "Epoch [2370/2500], Train Loss: 0.7444, Train Accuracy: 69.27%, Test Loss: 0.7381, Test Accuracy: 70.89%\n",
      "Epoch [2371/2500], Train Loss: 0.7389, Train Accuracy: 68.42%, Test Loss: 0.7518, Test Accuracy: 70.89%\n",
      "Epoch [2372/2500], Train Loss: 0.7224, Train Accuracy: 67.43%, Test Loss: 0.7547, Test Accuracy: 72.15%\n",
      "Epoch [2373/2500], Train Loss: 0.7263, Train Accuracy: 67.71%, Test Loss: 0.7654, Test Accuracy: 68.35%\n",
      "Epoch [2374/2500], Train Loss: 0.7303, Train Accuracy: 69.27%, Test Loss: 0.7258, Test Accuracy: 73.42%\n",
      "Epoch [2375/2500], Train Loss: 0.7653, Train Accuracy: 66.57%, Test Loss: 0.7433, Test Accuracy: 69.62%\n",
      "Epoch [2376/2500], Train Loss: 0.7399, Train Accuracy: 68.99%, Test Loss: 0.7667, Test Accuracy: 67.09%\n",
      "Epoch [2377/2500], Train Loss: 0.7597, Train Accuracy: 66.15%, Test Loss: 0.9461, Test Accuracy: 62.03%\n",
      "Epoch [2378/2500], Train Loss: 0.7354, Train Accuracy: 68.56%, Test Loss: 0.7566, Test Accuracy: 73.42%\n",
      "Epoch [2379/2500], Train Loss: 0.7415, Train Accuracy: 67.43%, Test Loss: 0.7679, Test Accuracy: 68.35%\n",
      "Epoch [2380/2500], Train Loss: 0.7500, Train Accuracy: 67.43%, Test Loss: 0.8216, Test Accuracy: 64.56%\n",
      "Epoch [2381/2500], Train Loss: 0.7548, Train Accuracy: 68.28%, Test Loss: 0.7568, Test Accuracy: 72.15%\n",
      "Epoch [2382/2500], Train Loss: 0.7369, Train Accuracy: 68.71%, Test Loss: 0.7256, Test Accuracy: 68.35%\n",
      "Epoch [2383/2500], Train Loss: 0.7375, Train Accuracy: 69.42%, Test Loss: 0.7513, Test Accuracy: 72.15%\n",
      "Epoch [2384/2500], Train Loss: 0.7259, Train Accuracy: 68.42%, Test Loss: 0.7132, Test Accuracy: 72.15%\n",
      "Epoch [2385/2500], Train Loss: 0.7610, Train Accuracy: 67.85%, Test Loss: 0.7403, Test Accuracy: 73.42%\n",
      "Epoch [2386/2500], Train Loss: 0.7472, Train Accuracy: 68.42%, Test Loss: 0.7213, Test Accuracy: 69.62%\n",
      "Epoch [2387/2500], Train Loss: 0.7393, Train Accuracy: 66.43%, Test Loss: 0.7748, Test Accuracy: 68.35%\n",
      "Epoch [2388/2500], Train Loss: 0.7183, Train Accuracy: 69.84%, Test Loss: 0.7259, Test Accuracy: 72.15%\n",
      "Epoch [2389/2500], Train Loss: 0.7353, Train Accuracy: 68.56%, Test Loss: 0.7196, Test Accuracy: 70.89%\n",
      "Epoch [2390/2500], Train Loss: 0.7375, Train Accuracy: 69.84%, Test Loss: 0.9422, Test Accuracy: 59.49%\n",
      "Epoch [2391/2500], Train Loss: 0.7394, Train Accuracy: 67.99%, Test Loss: 0.7389, Test Accuracy: 72.15%\n",
      "Epoch [2392/2500], Train Loss: 0.7471, Train Accuracy: 68.28%, Test Loss: 0.8318, Test Accuracy: 65.82%\n",
      "Epoch [2393/2500], Train Loss: 0.7501, Train Accuracy: 66.71%, Test Loss: 0.7167, Test Accuracy: 72.15%\n",
      "Epoch [2394/2500], Train Loss: 0.7501, Train Accuracy: 67.99%, Test Loss: 0.7554, Test Accuracy: 68.35%\n",
      "Epoch [2395/2500], Train Loss: 0.7390, Train Accuracy: 68.42%, Test Loss: 0.7270, Test Accuracy: 68.35%\n",
      "Epoch [2396/2500], Train Loss: 0.7536, Train Accuracy: 67.28%, Test Loss: 0.7682, Test Accuracy: 70.89%\n",
      "Epoch [2397/2500], Train Loss: 0.7396, Train Accuracy: 68.42%, Test Loss: 0.8261, Test Accuracy: 64.56%\n",
      "Epoch [2398/2500], Train Loss: 0.7294, Train Accuracy: 68.14%, Test Loss: 0.8018, Test Accuracy: 65.82%\n",
      "Epoch [2399/2500], Train Loss: 0.7526, Train Accuracy: 67.71%, Test Loss: 0.7868, Test Accuracy: 69.62%\n",
      "Epoch [2400/2500], Train Loss: 0.7363, Train Accuracy: 68.99%, Test Loss: 0.7591, Test Accuracy: 69.62%\n",
      "Epoch [2401/2500], Train Loss: 0.7274, Train Accuracy: 69.70%, Test Loss: 0.7961, Test Accuracy: 69.62%\n",
      "Epoch [2402/2500], Train Loss: 0.7521, Train Accuracy: 66.15%, Test Loss: 0.7507, Test Accuracy: 73.42%\n",
      "Epoch [2403/2500], Train Loss: 0.7259, Train Accuracy: 70.55%, Test Loss: 0.9407, Test Accuracy: 63.29%\n",
      "Epoch [2404/2500], Train Loss: 0.7501, Train Accuracy: 67.14%, Test Loss: 0.8162, Test Accuracy: 68.35%\n",
      "Epoch [2405/2500], Train Loss: 0.7327, Train Accuracy: 68.28%, Test Loss: 0.7263, Test Accuracy: 70.89%\n",
      "Epoch [2406/2500], Train Loss: 0.7397, Train Accuracy: 67.57%, Test Loss: 0.7744, Test Accuracy: 72.15%\n",
      "Epoch [2407/2500], Train Loss: 0.7486, Train Accuracy: 69.56%, Test Loss: 0.7341, Test Accuracy: 69.62%\n",
      "Epoch [2408/2500], Train Loss: 0.7237, Train Accuracy: 68.14%, Test Loss: 0.7916, Test Accuracy: 68.35%\n",
      "Epoch [2409/2500], Train Loss: 0.7367, Train Accuracy: 66.29%, Test Loss: 0.7454, Test Accuracy: 70.89%\n",
      "Epoch [2410/2500], Train Loss: 0.7440, Train Accuracy: 67.85%, Test Loss: 0.8243, Test Accuracy: 63.29%\n",
      "Epoch [2411/2500], Train Loss: 0.7133, Train Accuracy: 69.27%, Test Loss: 0.8518, Test Accuracy: 67.09%\n",
      "Epoch [2412/2500], Train Loss: 0.7409, Train Accuracy: 69.84%, Test Loss: 0.7714, Test Accuracy: 70.89%\n",
      "Epoch [2413/2500], Train Loss: 0.7490, Train Accuracy: 67.28%, Test Loss: 0.7305, Test Accuracy: 70.89%\n",
      "Epoch [2414/2500], Train Loss: 0.7620, Train Accuracy: 67.71%, Test Loss: 0.8039, Test Accuracy: 64.56%\n",
      "Epoch [2415/2500], Train Loss: 0.7332, Train Accuracy: 68.99%, Test Loss: 0.8930, Test Accuracy: 67.09%\n",
      "Epoch [2416/2500], Train Loss: 0.7494, Train Accuracy: 66.43%, Test Loss: 0.7516, Test Accuracy: 68.35%\n",
      "Epoch [2417/2500], Train Loss: 0.7458, Train Accuracy: 65.86%, Test Loss: 0.7156, Test Accuracy: 70.89%\n",
      "Epoch [2418/2500], Train Loss: 0.7332, Train Accuracy: 68.14%, Test Loss: 0.7916, Test Accuracy: 65.82%\n",
      "Epoch [2419/2500], Train Loss: 0.7136, Train Accuracy: 68.28%, Test Loss: 0.8057, Test Accuracy: 67.09%\n",
      "Epoch [2420/2500], Train Loss: 0.7205, Train Accuracy: 68.28%, Test Loss: 0.7912, Test Accuracy: 69.62%\n",
      "Epoch [2421/2500], Train Loss: 0.7278, Train Accuracy: 68.14%, Test Loss: 0.8259, Test Accuracy: 64.56%\n",
      "Epoch [2422/2500], Train Loss: 0.7441, Train Accuracy: 69.42%, Test Loss: 0.9212, Test Accuracy: 63.29%\n",
      "Epoch [2423/2500], Train Loss: 0.7446, Train Accuracy: 68.42%, Test Loss: 0.7673, Test Accuracy: 69.62%\n",
      "Epoch [2424/2500], Train Loss: 0.7607, Train Accuracy: 67.00%, Test Loss: 0.7376, Test Accuracy: 74.68%\n",
      "Epoch [2425/2500], Train Loss: 0.7452, Train Accuracy: 67.85%, Test Loss: 0.8703, Test Accuracy: 65.82%\n",
      "Epoch [2426/2500], Train Loss: 0.7516, Train Accuracy: 67.14%, Test Loss: 0.7329, Test Accuracy: 70.89%\n",
      "Epoch [2427/2500], Train Loss: 0.7387, Train Accuracy: 68.42%, Test Loss: 0.7704, Test Accuracy: 69.62%\n",
      "Epoch [2428/2500], Train Loss: 0.7485, Train Accuracy: 66.43%, Test Loss: 0.7681, Test Accuracy: 70.89%\n",
      "Epoch [2429/2500], Train Loss: 0.7469, Train Accuracy: 69.27%, Test Loss: 0.7417, Test Accuracy: 69.62%\n",
      "Epoch [2430/2500], Train Loss: 0.7281, Train Accuracy: 68.71%, Test Loss: 0.8350, Test Accuracy: 67.09%\n",
      "Epoch [2431/2500], Train Loss: 0.7456, Train Accuracy: 69.70%, Test Loss: 0.7632, Test Accuracy: 72.15%\n",
      "Epoch [2432/2500], Train Loss: 0.7638, Train Accuracy: 67.43%, Test Loss: 0.7438, Test Accuracy: 65.82%\n",
      "Epoch [2433/2500], Train Loss: 0.7616, Train Accuracy: 67.71%, Test Loss: 0.7156, Test Accuracy: 68.35%\n",
      "Epoch [2434/2500], Train Loss: 0.7645, Train Accuracy: 65.58%, Test Loss: 0.7537, Test Accuracy: 68.35%\n",
      "Epoch [2435/2500], Train Loss: 0.7623, Train Accuracy: 64.44%, Test Loss: 0.7285, Test Accuracy: 70.89%\n",
      "Epoch [2436/2500], Train Loss: 0.7104, Train Accuracy: 67.85%, Test Loss: 0.7413, Test Accuracy: 72.15%\n",
      "Epoch [2437/2500], Train Loss: 0.7393, Train Accuracy: 68.14%, Test Loss: 0.7755, Test Accuracy: 67.09%\n",
      "Epoch [2438/2500], Train Loss: 0.7533, Train Accuracy: 66.71%, Test Loss: 0.7890, Test Accuracy: 67.09%\n",
      "Epoch [2439/2500], Train Loss: 0.7551, Train Accuracy: 67.28%, Test Loss: 0.7383, Test Accuracy: 73.42%\n",
      "Epoch [2440/2500], Train Loss: 0.7329, Train Accuracy: 69.84%, Test Loss: 0.7442, Test Accuracy: 68.35%\n",
      "Epoch [2441/2500], Train Loss: 0.7464, Train Accuracy: 67.00%, Test Loss: 0.8408, Test Accuracy: 67.09%\n",
      "Epoch [2442/2500], Train Loss: 0.7409, Train Accuracy: 69.56%, Test Loss: 0.7196, Test Accuracy: 68.35%\n",
      "Epoch [2443/2500], Train Loss: 0.7226, Train Accuracy: 68.14%, Test Loss: 0.8183, Test Accuracy: 67.09%\n",
      "Epoch [2444/2500], Train Loss: 0.7285, Train Accuracy: 68.42%, Test Loss: 0.7214, Test Accuracy: 69.62%\n",
      "Epoch [2445/2500], Train Loss: 0.7293, Train Accuracy: 67.99%, Test Loss: 0.7571, Test Accuracy: 68.35%\n",
      "Epoch [2446/2500], Train Loss: 0.7311, Train Accuracy: 67.14%, Test Loss: 0.7388, Test Accuracy: 70.89%\n",
      "Epoch [2447/2500], Train Loss: 0.7270, Train Accuracy: 67.85%, Test Loss: 0.8445, Test Accuracy: 63.29%\n",
      "Epoch [2448/2500], Train Loss: 0.7341, Train Accuracy: 67.00%, Test Loss: 0.7609, Test Accuracy: 70.89%\n",
      "Epoch [2449/2500], Train Loss: 0.7586, Train Accuracy: 70.13%, Test Loss: 0.8209, Test Accuracy: 70.89%\n",
      "Epoch [2450/2500], Train Loss: 0.7491, Train Accuracy: 67.14%, Test Loss: 0.8883, Test Accuracy: 64.56%\n",
      "Epoch [2451/2500], Train Loss: 0.7252, Train Accuracy: 70.84%, Test Loss: 0.8221, Test Accuracy: 68.35%\n",
      "Epoch [2452/2500], Train Loss: 0.7396, Train Accuracy: 68.14%, Test Loss: 0.7311, Test Accuracy: 72.15%\n",
      "Epoch [2453/2500], Train Loss: 0.7412, Train Accuracy: 68.42%, Test Loss: 0.7311, Test Accuracy: 69.62%\n",
      "Epoch [2454/2500], Train Loss: 0.7285, Train Accuracy: 67.57%, Test Loss: 0.7440, Test Accuracy: 72.15%\n",
      "Epoch [2455/2500], Train Loss: 0.7307, Train Accuracy: 67.00%, Test Loss: 0.7930, Test Accuracy: 70.89%\n",
      "Epoch [2456/2500], Train Loss: 0.7339, Train Accuracy: 68.28%, Test Loss: 0.7651, Test Accuracy: 67.09%\n",
      "Epoch [2457/2500], Train Loss: 0.7612, Train Accuracy: 66.43%, Test Loss: 0.7355, Test Accuracy: 73.42%\n",
      "Epoch [2458/2500], Train Loss: 0.7181, Train Accuracy: 68.56%, Test Loss: 0.7323, Test Accuracy: 74.68%\n",
      "Epoch [2459/2500], Train Loss: 0.7200, Train Accuracy: 68.71%, Test Loss: 0.7206, Test Accuracy: 73.42%\n",
      "Epoch [2460/2500], Train Loss: 0.7487, Train Accuracy: 65.72%, Test Loss: 0.8246, Test Accuracy: 64.56%\n",
      "Epoch [2461/2500], Train Loss: 0.7606, Train Accuracy: 67.99%, Test Loss: 0.7330, Test Accuracy: 73.42%\n",
      "Epoch [2462/2500], Train Loss: 0.7584, Train Accuracy: 66.15%, Test Loss: 0.7352, Test Accuracy: 72.15%\n",
      "Epoch [2463/2500], Train Loss: 0.7352, Train Accuracy: 68.56%, Test Loss: 0.7336, Test Accuracy: 69.62%\n",
      "Epoch [2464/2500], Train Loss: 0.7390, Train Accuracy: 67.43%, Test Loss: 0.7343, Test Accuracy: 70.89%\n",
      "Epoch [2465/2500], Train Loss: 0.7482, Train Accuracy: 68.56%, Test Loss: 0.7429, Test Accuracy: 68.35%\n",
      "Epoch [2466/2500], Train Loss: 0.7190, Train Accuracy: 68.14%, Test Loss: 0.7282, Test Accuracy: 69.62%\n",
      "Epoch [2467/2500], Train Loss: 0.7313, Train Accuracy: 68.85%, Test Loss: 0.8967, Test Accuracy: 63.29%\n",
      "Epoch [2468/2500], Train Loss: 0.7212, Train Accuracy: 68.99%, Test Loss: 0.7292, Test Accuracy: 70.89%\n",
      "Epoch [2469/2500], Train Loss: 0.7678, Train Accuracy: 66.43%, Test Loss: 0.7986, Test Accuracy: 69.62%\n",
      "Epoch [2470/2500], Train Loss: 0.7181, Train Accuracy: 68.85%, Test Loss: 0.8928, Test Accuracy: 67.09%\n",
      "Epoch [2471/2500], Train Loss: 0.7145, Train Accuracy: 69.70%, Test Loss: 0.7542, Test Accuracy: 72.15%\n",
      "Epoch [2472/2500], Train Loss: 0.7147, Train Accuracy: 67.71%, Test Loss: 0.7749, Test Accuracy: 69.62%\n",
      "Epoch [2473/2500], Train Loss: 0.7461, Train Accuracy: 69.56%, Test Loss: 0.7304, Test Accuracy: 72.15%\n",
      "Epoch [2474/2500], Train Loss: 0.7505, Train Accuracy: 68.14%, Test Loss: 0.8624, Test Accuracy: 67.09%\n",
      "Epoch [2475/2500], Train Loss: 0.7301, Train Accuracy: 67.71%, Test Loss: 0.7672, Test Accuracy: 70.89%\n",
      "Epoch [2476/2500], Train Loss: 0.7432, Train Accuracy: 67.57%, Test Loss: 0.7511, Test Accuracy: 70.89%\n",
      "Epoch [2477/2500], Train Loss: 0.7259, Train Accuracy: 70.13%, Test Loss: 0.7333, Test Accuracy: 74.68%\n",
      "Epoch [2478/2500], Train Loss: 0.7474, Train Accuracy: 67.57%, Test Loss: 0.7324, Test Accuracy: 73.42%\n",
      "Epoch [2479/2500], Train Loss: 0.7329, Train Accuracy: 67.43%, Test Loss: 0.7821, Test Accuracy: 72.15%\n",
      "Epoch [2480/2500], Train Loss: 0.7299, Train Accuracy: 68.85%, Test Loss: 0.8764, Test Accuracy: 63.29%\n",
      "Epoch [2481/2500], Train Loss: 0.7655, Train Accuracy: 67.71%, Test Loss: 0.7049, Test Accuracy: 67.09%\n",
      "Epoch [2482/2500], Train Loss: 0.7400, Train Accuracy: 67.43%, Test Loss: 0.7533, Test Accuracy: 70.89%\n",
      "Epoch [2483/2500], Train Loss: 0.7677, Train Accuracy: 66.15%, Test Loss: 0.7452, Test Accuracy: 72.15%\n",
      "Epoch [2484/2500], Train Loss: 0.7202, Train Accuracy: 69.56%, Test Loss: 0.7735, Test Accuracy: 64.56%\n",
      "Epoch [2485/2500], Train Loss: 0.7488, Train Accuracy: 66.29%, Test Loss: 0.7572, Test Accuracy: 72.15%\n",
      "Epoch [2486/2500], Train Loss: 0.6974, Train Accuracy: 70.84%, Test Loss: 0.7285, Test Accuracy: 65.82%\n",
      "Epoch [2487/2500], Train Loss: 0.7272, Train Accuracy: 68.14%, Test Loss: 0.7422, Test Accuracy: 70.89%\n",
      "Epoch [2488/2500], Train Loss: 0.7284, Train Accuracy: 67.57%, Test Loss: 0.7776, Test Accuracy: 67.09%\n",
      "Epoch [2489/2500], Train Loss: 0.7262, Train Accuracy: 67.57%, Test Loss: 0.8018, Test Accuracy: 68.35%\n",
      "Epoch [2490/2500], Train Loss: 0.7197, Train Accuracy: 69.27%, Test Loss: 0.7676, Test Accuracy: 72.15%\n",
      "Epoch [2491/2500], Train Loss: 0.7419, Train Accuracy: 67.57%, Test Loss: 0.8038, Test Accuracy: 69.62%\n",
      "Epoch [2492/2500], Train Loss: 0.7122, Train Accuracy: 69.99%, Test Loss: 0.7654, Test Accuracy: 72.15%\n",
      "Epoch [2493/2500], Train Loss: 0.7412, Train Accuracy: 67.43%, Test Loss: 0.7351, Test Accuracy: 73.42%\n",
      "Epoch [2494/2500], Train Loss: 0.7306, Train Accuracy: 68.14%, Test Loss: 0.8029, Test Accuracy: 67.09%\n",
      "Epoch [2495/2500], Train Loss: 0.7274, Train Accuracy: 65.86%, Test Loss: 0.7119, Test Accuracy: 69.62%\n",
      "Epoch [2496/2500], Train Loss: 0.7779, Train Accuracy: 65.72%, Test Loss: 0.7608, Test Accuracy: 73.42%\n",
      "Epoch [2497/2500], Train Loss: 0.7465, Train Accuracy: 67.85%, Test Loss: 0.7768, Test Accuracy: 68.35%\n",
      "Epoch [2498/2500], Train Loss: 0.7086, Train Accuracy: 69.42%, Test Loss: 0.8374, Test Accuracy: 65.82%\n",
      "Epoch [2499/2500], Train Loss: 0.7413, Train Accuracy: 66.15%, Test Loss: 0.7262, Test Accuracy: 74.68%\n",
      "Epoch [2500/2500], Train Loss: 0.7158, Train Accuracy: 69.84%, Test Loss: 0.8224, Test Accuracy: 64.56%\n",
      "model_cnn2d_att saved as model_cnn2d_att_4class_best.pth\n",
      "\n",
      "Metrics for model_cnn2d_att saved as model_cnn2d_att_metrics_4class.csv\n",
      "\n",
      "Training model_cnn2dlstm_att\n",
      "Epoch [1/2500], Train Loss: 1.3839, Train Accuracy: 29.02%, Test Loss: 1.3624, Test Accuracy: 39.24%\n",
      "Epoch [2/2500], Train Loss: 1.3589, Train Accuracy: 35.70%, Test Loss: 1.3463, Test Accuracy: 39.24%\n",
      "Epoch [3/2500], Train Loss: 1.3586, Train Accuracy: 35.56%, Test Loss: 1.3167, Test Accuracy: 39.24%\n",
      "Epoch [4/2500], Train Loss: 1.3554, Train Accuracy: 35.42%, Test Loss: 1.3158, Test Accuracy: 39.24%\n",
      "Epoch [5/2500], Train Loss: 1.3586, Train Accuracy: 34.28%, Test Loss: 1.3053, Test Accuracy: 39.24%\n",
      "Epoch [6/2500], Train Loss: 1.3542, Train Accuracy: 35.14%, Test Loss: 1.3024, Test Accuracy: 39.24%\n",
      "Epoch [7/2500], Train Loss: 1.3426, Train Accuracy: 35.85%, Test Loss: 1.2994, Test Accuracy: 39.24%\n",
      "Epoch [8/2500], Train Loss: 1.3453, Train Accuracy: 36.98%, Test Loss: 1.3001, Test Accuracy: 39.24%\n",
      "Epoch [9/2500], Train Loss: 1.3436, Train Accuracy: 35.56%, Test Loss: 1.2997, Test Accuracy: 39.24%\n",
      "Epoch [10/2500], Train Loss: 1.3437, Train Accuracy: 35.99%, Test Loss: 1.2983, Test Accuracy: 39.24%\n",
      "Epoch [11/2500], Train Loss: 1.3374, Train Accuracy: 35.56%, Test Loss: 1.2986, Test Accuracy: 39.24%\n",
      "Epoch [12/2500], Train Loss: 1.3418, Train Accuracy: 35.99%, Test Loss: 1.3025, Test Accuracy: 39.24%\n",
      "Epoch [13/2500], Train Loss: 1.3381, Train Accuracy: 35.85%, Test Loss: 1.2997, Test Accuracy: 39.24%\n",
      "Epoch [14/2500], Train Loss: 1.3344, Train Accuracy: 36.42%, Test Loss: 1.2988, Test Accuracy: 39.24%\n",
      "Epoch [15/2500], Train Loss: 1.3391, Train Accuracy: 34.99%, Test Loss: 1.2908, Test Accuracy: 39.24%\n",
      "Epoch [16/2500], Train Loss: 1.3313, Train Accuracy: 35.42%, Test Loss: 1.2919, Test Accuracy: 39.24%\n",
      "Epoch [17/2500], Train Loss: 1.3305, Train Accuracy: 37.41%, Test Loss: 1.2934, Test Accuracy: 39.24%\n",
      "Epoch [18/2500], Train Loss: 1.3275, Train Accuracy: 37.13%, Test Loss: 1.2890, Test Accuracy: 39.24%\n",
      "Epoch [19/2500], Train Loss: 1.3311, Train Accuracy: 37.55%, Test Loss: 1.2904, Test Accuracy: 39.24%\n",
      "Epoch [20/2500], Train Loss: 1.3206, Train Accuracy: 37.98%, Test Loss: 1.2877, Test Accuracy: 39.24%\n",
      "Epoch [21/2500], Train Loss: 1.3368, Train Accuracy: 36.70%, Test Loss: 1.2844, Test Accuracy: 39.24%\n",
      "Epoch [22/2500], Train Loss: 1.3226, Train Accuracy: 37.41%, Test Loss: 1.2858, Test Accuracy: 39.24%\n",
      "Epoch [23/2500], Train Loss: 1.3192, Train Accuracy: 37.84%, Test Loss: 1.2869, Test Accuracy: 39.24%\n",
      "Epoch [24/2500], Train Loss: 1.3215, Train Accuracy: 35.42%, Test Loss: 1.2845, Test Accuracy: 39.24%\n",
      "Epoch [25/2500], Train Loss: 1.3196, Train Accuracy: 37.98%, Test Loss: 1.2742, Test Accuracy: 39.24%\n",
      "Epoch [26/2500], Train Loss: 1.3175, Train Accuracy: 38.98%, Test Loss: 1.2692, Test Accuracy: 39.24%\n",
      "Epoch [27/2500], Train Loss: 1.3195, Train Accuracy: 37.98%, Test Loss: 1.2661, Test Accuracy: 39.24%\n",
      "Epoch [28/2500], Train Loss: 1.3201, Train Accuracy: 37.70%, Test Loss: 1.2611, Test Accuracy: 39.24%\n",
      "Epoch [29/2500], Train Loss: 1.3130, Train Accuracy: 37.98%, Test Loss: 1.2593, Test Accuracy: 39.24%\n",
      "Epoch [30/2500], Train Loss: 1.3172, Train Accuracy: 36.84%, Test Loss: 1.2611, Test Accuracy: 39.24%\n",
      "Epoch [31/2500], Train Loss: 1.3110, Train Accuracy: 37.98%, Test Loss: 1.2518, Test Accuracy: 39.24%\n",
      "Epoch [32/2500], Train Loss: 1.3113, Train Accuracy: 37.55%, Test Loss: 1.2477, Test Accuracy: 39.24%\n",
      "Epoch [33/2500], Train Loss: 1.3130, Train Accuracy: 38.98%, Test Loss: 1.2456, Test Accuracy: 39.24%\n",
      "Epoch [34/2500], Train Loss: 1.3175, Train Accuracy: 39.97%, Test Loss: 1.2443, Test Accuracy: 39.24%\n",
      "Epoch [35/2500], Train Loss: 1.3074, Train Accuracy: 40.11%, Test Loss: 1.2420, Test Accuracy: 39.24%\n",
      "Epoch [36/2500], Train Loss: 1.3082, Train Accuracy: 39.69%, Test Loss: 1.2405, Test Accuracy: 39.24%\n",
      "Epoch [37/2500], Train Loss: 1.3022, Train Accuracy: 39.97%, Test Loss: 1.2380, Test Accuracy: 41.77%\n",
      "Epoch [38/2500], Train Loss: 1.2994, Train Accuracy: 40.40%, Test Loss: 1.2371, Test Accuracy: 45.57%\n",
      "Epoch [39/2500], Train Loss: 1.2997, Train Accuracy: 41.39%, Test Loss: 1.2341, Test Accuracy: 48.10%\n",
      "Epoch [40/2500], Train Loss: 1.3037, Train Accuracy: 41.96%, Test Loss: 1.2316, Test Accuracy: 49.37%\n",
      "Epoch [41/2500], Train Loss: 1.2982, Train Accuracy: 42.25%, Test Loss: 1.2278, Test Accuracy: 49.37%\n",
      "Epoch [42/2500], Train Loss: 1.2998, Train Accuracy: 39.83%, Test Loss: 1.2271, Test Accuracy: 49.37%\n",
      "Epoch [43/2500], Train Loss: 1.2997, Train Accuracy: 41.25%, Test Loss: 1.2270, Test Accuracy: 48.10%\n",
      "Epoch [44/2500], Train Loss: 1.3006, Train Accuracy: 40.11%, Test Loss: 1.2205, Test Accuracy: 49.37%\n",
      "Epoch [45/2500], Train Loss: 1.3028, Train Accuracy: 40.26%, Test Loss: 1.2211, Test Accuracy: 49.37%\n",
      "Epoch [46/2500], Train Loss: 1.2916, Train Accuracy: 40.40%, Test Loss: 1.2176, Test Accuracy: 49.37%\n",
      "Epoch [47/2500], Train Loss: 1.2974, Train Accuracy: 41.82%, Test Loss: 1.2165, Test Accuracy: 49.37%\n",
      "Epoch [48/2500], Train Loss: 1.3106, Train Accuracy: 38.55%, Test Loss: 1.2108, Test Accuracy: 49.37%\n",
      "Epoch [49/2500], Train Loss: 1.2777, Train Accuracy: 43.10%, Test Loss: 1.2072, Test Accuracy: 49.37%\n",
      "Epoch [50/2500], Train Loss: 1.2796, Train Accuracy: 42.67%, Test Loss: 1.2023, Test Accuracy: 49.37%\n",
      "Epoch [51/2500], Train Loss: 1.2906, Train Accuracy: 42.53%, Test Loss: 1.2026, Test Accuracy: 49.37%\n",
      "Epoch [52/2500], Train Loss: 1.2856, Train Accuracy: 42.39%, Test Loss: 1.1981, Test Accuracy: 49.37%\n",
      "Epoch [53/2500], Train Loss: 1.2816, Train Accuracy: 44.10%, Test Loss: 1.1900, Test Accuracy: 49.37%\n",
      "Epoch [54/2500], Train Loss: 1.2738, Train Accuracy: 43.10%, Test Loss: 1.1893, Test Accuracy: 49.37%\n",
      "Epoch [55/2500], Train Loss: 1.2885, Train Accuracy: 41.68%, Test Loss: 1.1879, Test Accuracy: 49.37%\n",
      "Epoch [56/2500], Train Loss: 1.2888, Train Accuracy: 42.67%, Test Loss: 1.1847, Test Accuracy: 49.37%\n",
      "Epoch [57/2500], Train Loss: 1.2751, Train Accuracy: 43.95%, Test Loss: 1.1830, Test Accuracy: 49.37%\n",
      "Epoch [58/2500], Train Loss: 1.2651, Train Accuracy: 44.10%, Test Loss: 1.1777, Test Accuracy: 50.63%\n",
      "Epoch [59/2500], Train Loss: 1.2739, Train Accuracy: 44.81%, Test Loss: 1.1740, Test Accuracy: 49.37%\n",
      "Epoch [60/2500], Train Loss: 1.2657, Train Accuracy: 44.24%, Test Loss: 1.1721, Test Accuracy: 49.37%\n",
      "Epoch [61/2500], Train Loss: 1.2821, Train Accuracy: 42.96%, Test Loss: 1.1720, Test Accuracy: 50.63%\n",
      "Epoch [62/2500], Train Loss: 1.2640, Train Accuracy: 44.24%, Test Loss: 1.1703, Test Accuracy: 50.63%\n",
      "Epoch [63/2500], Train Loss: 1.2602, Train Accuracy: 45.23%, Test Loss: 1.1693, Test Accuracy: 50.63%\n",
      "Epoch [64/2500], Train Loss: 1.2610, Train Accuracy: 43.53%, Test Loss: 1.1596, Test Accuracy: 50.63%\n",
      "Epoch [65/2500], Train Loss: 1.2699, Train Accuracy: 44.81%, Test Loss: 1.1562, Test Accuracy: 49.37%\n",
      "Epoch [66/2500], Train Loss: 1.2633, Train Accuracy: 43.53%, Test Loss: 1.1539, Test Accuracy: 49.37%\n",
      "Epoch [67/2500], Train Loss: 1.2539, Train Accuracy: 46.51%, Test Loss: 1.1556, Test Accuracy: 49.37%\n",
      "Epoch [68/2500], Train Loss: 1.2579, Train Accuracy: 45.95%, Test Loss: 1.1507, Test Accuracy: 49.37%\n",
      "Epoch [69/2500], Train Loss: 1.2531, Train Accuracy: 45.95%, Test Loss: 1.1465, Test Accuracy: 49.37%\n",
      "Epoch [70/2500], Train Loss: 1.2548, Train Accuracy: 45.09%, Test Loss: 1.1457, Test Accuracy: 49.37%\n",
      "Epoch [71/2500], Train Loss: 1.2425, Train Accuracy: 47.37%, Test Loss: 1.1425, Test Accuracy: 49.37%\n",
      "Epoch [72/2500], Train Loss: 1.2559, Train Accuracy: 45.66%, Test Loss: 1.1359, Test Accuracy: 49.37%\n",
      "Epoch [73/2500], Train Loss: 1.2381, Train Accuracy: 46.80%, Test Loss: 1.1323, Test Accuracy: 49.37%\n",
      "Epoch [74/2500], Train Loss: 1.2408, Train Accuracy: 48.51%, Test Loss: 1.1317, Test Accuracy: 49.37%\n",
      "Epoch [75/2500], Train Loss: 1.2606, Train Accuracy: 44.52%, Test Loss: 1.1315, Test Accuracy: 49.37%\n",
      "Epoch [76/2500], Train Loss: 1.2374, Train Accuracy: 46.37%, Test Loss: 1.1261, Test Accuracy: 49.37%\n",
      "Epoch [77/2500], Train Loss: 1.2379, Train Accuracy: 46.09%, Test Loss: 1.1279, Test Accuracy: 49.37%\n",
      "Epoch [78/2500], Train Loss: 1.2417, Train Accuracy: 45.80%, Test Loss: 1.1232, Test Accuracy: 49.37%\n",
      "Epoch [79/2500], Train Loss: 1.2245, Train Accuracy: 46.51%, Test Loss: 1.1240, Test Accuracy: 49.37%\n",
      "Epoch [80/2500], Train Loss: 1.2432, Train Accuracy: 46.09%, Test Loss: 1.1167, Test Accuracy: 49.37%\n",
      "Epoch [81/2500], Train Loss: 1.2329, Train Accuracy: 47.80%, Test Loss: 1.1183, Test Accuracy: 49.37%\n",
      "Epoch [82/2500], Train Loss: 1.2241, Train Accuracy: 46.23%, Test Loss: 1.1168, Test Accuracy: 49.37%\n",
      "Epoch [83/2500], Train Loss: 1.2271, Train Accuracy: 47.37%, Test Loss: 1.1138, Test Accuracy: 50.63%\n",
      "Epoch [84/2500], Train Loss: 1.2338, Train Accuracy: 45.09%, Test Loss: 1.1131, Test Accuracy: 49.37%\n",
      "Epoch [85/2500], Train Loss: 1.2353, Train Accuracy: 47.08%, Test Loss: 1.1081, Test Accuracy: 49.37%\n",
      "Epoch [86/2500], Train Loss: 1.2269, Train Accuracy: 47.08%, Test Loss: 1.1109, Test Accuracy: 50.63%\n",
      "Epoch [87/2500], Train Loss: 1.2176, Train Accuracy: 47.51%, Test Loss: 1.1052, Test Accuracy: 49.37%\n",
      "Epoch [88/2500], Train Loss: 1.2103, Train Accuracy: 49.93%, Test Loss: 1.1085, Test Accuracy: 49.37%\n",
      "Epoch [89/2500], Train Loss: 1.2181, Train Accuracy: 47.23%, Test Loss: 1.1061, Test Accuracy: 50.63%\n",
      "Epoch [90/2500], Train Loss: 1.2180, Train Accuracy: 46.09%, Test Loss: 1.0997, Test Accuracy: 50.63%\n",
      "Epoch [91/2500], Train Loss: 1.2132, Train Accuracy: 48.93%, Test Loss: 1.1032, Test Accuracy: 50.63%\n",
      "Epoch [92/2500], Train Loss: 1.2162, Train Accuracy: 47.23%, Test Loss: 1.0976, Test Accuracy: 49.37%\n",
      "Epoch [93/2500], Train Loss: 1.2056, Train Accuracy: 47.51%, Test Loss: 1.0971, Test Accuracy: 49.37%\n",
      "Epoch [94/2500], Train Loss: 1.1908, Train Accuracy: 49.50%, Test Loss: 1.0982, Test Accuracy: 49.37%\n",
      "Epoch [95/2500], Train Loss: 1.2069, Train Accuracy: 48.51%, Test Loss: 1.0997, Test Accuracy: 49.37%\n",
      "Epoch [96/2500], Train Loss: 1.2116, Train Accuracy: 47.65%, Test Loss: 1.0941, Test Accuracy: 49.37%\n",
      "Epoch [97/2500], Train Loss: 1.2053, Train Accuracy: 49.22%, Test Loss: 1.0834, Test Accuracy: 49.37%\n",
      "Epoch [98/2500], Train Loss: 1.1969, Train Accuracy: 49.93%, Test Loss: 1.0825, Test Accuracy: 49.37%\n",
      "Epoch [99/2500], Train Loss: 1.2063, Train Accuracy: 47.94%, Test Loss: 1.0693, Test Accuracy: 50.63%\n",
      "Epoch [100/2500], Train Loss: 1.1951, Train Accuracy: 49.36%, Test Loss: 1.0717, Test Accuracy: 49.37%\n",
      "Epoch [101/2500], Train Loss: 1.1936, Train Accuracy: 49.08%, Test Loss: 1.0754, Test Accuracy: 49.37%\n",
      "Epoch [102/2500], Train Loss: 1.1807, Train Accuracy: 49.64%, Test Loss: 1.0722, Test Accuracy: 49.37%\n",
      "Epoch [103/2500], Train Loss: 1.2238, Train Accuracy: 47.23%, Test Loss: 1.0618, Test Accuracy: 49.37%\n",
      "Epoch [104/2500], Train Loss: 1.1940, Train Accuracy: 47.94%, Test Loss: 1.0630, Test Accuracy: 49.37%\n",
      "Epoch [105/2500], Train Loss: 1.1920, Train Accuracy: 49.08%, Test Loss: 1.0639, Test Accuracy: 50.63%\n",
      "Epoch [106/2500], Train Loss: 1.1945, Train Accuracy: 49.79%, Test Loss: 1.0593, Test Accuracy: 50.63%\n",
      "Epoch [107/2500], Train Loss: 1.1793, Train Accuracy: 49.93%, Test Loss: 1.0601, Test Accuracy: 50.63%\n",
      "Epoch [108/2500], Train Loss: 1.1771, Train Accuracy: 50.07%, Test Loss: 1.0619, Test Accuracy: 50.63%\n",
      "Epoch [109/2500], Train Loss: 1.1804, Train Accuracy: 49.79%, Test Loss: 1.0554, Test Accuracy: 49.37%\n",
      "Epoch [110/2500], Train Loss: 1.1834, Train Accuracy: 49.93%, Test Loss: 1.0538, Test Accuracy: 50.63%\n",
      "Epoch [111/2500], Train Loss: 1.1659, Train Accuracy: 50.21%, Test Loss: 1.0547, Test Accuracy: 50.63%\n",
      "Epoch [112/2500], Train Loss: 1.1687, Train Accuracy: 50.21%, Test Loss: 1.0513, Test Accuracy: 50.63%\n",
      "Epoch [113/2500], Train Loss: 1.1772, Train Accuracy: 49.64%, Test Loss: 1.0495, Test Accuracy: 50.63%\n",
      "Epoch [114/2500], Train Loss: 1.1797, Train Accuracy: 48.65%, Test Loss: 1.0496, Test Accuracy: 50.63%\n",
      "Epoch [115/2500], Train Loss: 1.1719, Train Accuracy: 49.08%, Test Loss: 1.0489, Test Accuracy: 50.63%\n",
      "Epoch [116/2500], Train Loss: 1.1504, Train Accuracy: 51.21%, Test Loss: 1.0362, Test Accuracy: 51.90%\n",
      "Epoch [117/2500], Train Loss: 1.1787, Train Accuracy: 49.50%, Test Loss: 1.0402, Test Accuracy: 50.63%\n",
      "Epoch [118/2500], Train Loss: 1.1606, Train Accuracy: 49.79%, Test Loss: 1.0406, Test Accuracy: 53.16%\n",
      "Epoch [119/2500], Train Loss: 1.1497, Train Accuracy: 51.64%, Test Loss: 1.0341, Test Accuracy: 51.90%\n",
      "Epoch [120/2500], Train Loss: 1.1593, Train Accuracy: 49.93%, Test Loss: 1.0363, Test Accuracy: 51.90%\n",
      "Epoch [121/2500], Train Loss: 1.1673, Train Accuracy: 50.64%, Test Loss: 1.0374, Test Accuracy: 51.90%\n",
      "Epoch [122/2500], Train Loss: 1.1586, Train Accuracy: 49.64%, Test Loss: 1.0362, Test Accuracy: 53.16%\n",
      "Epoch [123/2500], Train Loss: 1.1565, Train Accuracy: 50.78%, Test Loss: 1.0192, Test Accuracy: 54.43%\n",
      "Epoch [124/2500], Train Loss: 1.1694, Train Accuracy: 52.35%, Test Loss: 1.0273, Test Accuracy: 53.16%\n",
      "Epoch [125/2500], Train Loss: 1.1471, Train Accuracy: 53.20%, Test Loss: 1.0205, Test Accuracy: 53.16%\n",
      "Epoch [126/2500], Train Loss: 1.1510, Train Accuracy: 51.35%, Test Loss: 1.0141, Test Accuracy: 54.43%\n",
      "Epoch [127/2500], Train Loss: 1.1542, Train Accuracy: 49.79%, Test Loss: 1.0108, Test Accuracy: 54.43%\n",
      "Epoch [128/2500], Train Loss: 1.1513, Train Accuracy: 52.63%, Test Loss: 1.0224, Test Accuracy: 54.43%\n",
      "Epoch [129/2500], Train Loss: 1.1373, Train Accuracy: 51.78%, Test Loss: 1.0245, Test Accuracy: 53.16%\n",
      "Epoch [130/2500], Train Loss: 1.1427, Train Accuracy: 50.78%, Test Loss: 1.0173, Test Accuracy: 54.43%\n",
      "Epoch [131/2500], Train Loss: 1.1568, Train Accuracy: 51.21%, Test Loss: 1.0205, Test Accuracy: 55.70%\n",
      "Epoch [132/2500], Train Loss: 1.1453, Train Accuracy: 50.64%, Test Loss: 1.0134, Test Accuracy: 55.70%\n",
      "Epoch [133/2500], Train Loss: 1.1274, Train Accuracy: 53.34%, Test Loss: 1.0109, Test Accuracy: 54.43%\n",
      "Epoch [134/2500], Train Loss: 1.1374, Train Accuracy: 52.63%, Test Loss: 1.0263, Test Accuracy: 54.43%\n",
      "Epoch [135/2500], Train Loss: 1.1441, Train Accuracy: 50.78%, Test Loss: 1.0161, Test Accuracy: 55.70%\n",
      "Epoch [136/2500], Train Loss: 1.1339, Train Accuracy: 51.49%, Test Loss: 1.0257, Test Accuracy: 54.43%\n",
      "Epoch [137/2500], Train Loss: 1.1389, Train Accuracy: 51.64%, Test Loss: 1.0025, Test Accuracy: 55.70%\n",
      "Epoch [138/2500], Train Loss: 1.1423, Train Accuracy: 50.07%, Test Loss: 0.9989, Test Accuracy: 55.70%\n",
      "Epoch [139/2500], Train Loss: 1.1071, Train Accuracy: 53.91%, Test Loss: 1.0015, Test Accuracy: 55.70%\n",
      "Epoch [140/2500], Train Loss: 1.1291, Train Accuracy: 52.35%, Test Loss: 1.0030, Test Accuracy: 55.70%\n",
      "Epoch [141/2500], Train Loss: 1.1320, Train Accuracy: 52.77%, Test Loss: 1.0064, Test Accuracy: 55.70%\n",
      "Epoch [142/2500], Train Loss: 1.1188, Train Accuracy: 51.92%, Test Loss: 1.0105, Test Accuracy: 54.43%\n",
      "Epoch [143/2500], Train Loss: 1.1318, Train Accuracy: 52.20%, Test Loss: 1.0056, Test Accuracy: 55.70%\n",
      "Epoch [144/2500], Train Loss: 1.1344, Train Accuracy: 52.63%, Test Loss: 0.9955, Test Accuracy: 55.70%\n",
      "Epoch [145/2500], Train Loss: 1.0928, Train Accuracy: 54.77%, Test Loss: 1.0082, Test Accuracy: 55.70%\n",
      "Epoch [146/2500], Train Loss: 1.1287, Train Accuracy: 54.20%, Test Loss: 1.0020, Test Accuracy: 55.70%\n",
      "Epoch [147/2500], Train Loss: 1.1265, Train Accuracy: 52.63%, Test Loss: 0.9926, Test Accuracy: 55.70%\n",
      "Epoch [148/2500], Train Loss: 1.1049, Train Accuracy: 53.63%, Test Loss: 0.9958, Test Accuracy: 56.96%\n",
      "Epoch [149/2500], Train Loss: 1.1167, Train Accuracy: 52.35%, Test Loss: 0.9898, Test Accuracy: 55.70%\n",
      "Epoch [150/2500], Train Loss: 1.1182, Train Accuracy: 51.78%, Test Loss: 1.0050, Test Accuracy: 55.70%\n",
      "Epoch [151/2500], Train Loss: 1.1138, Train Accuracy: 51.92%, Test Loss: 0.9923, Test Accuracy: 55.70%\n",
      "Epoch [152/2500], Train Loss: 1.1201, Train Accuracy: 52.63%, Test Loss: 0.9916, Test Accuracy: 55.70%\n",
      "Epoch [153/2500], Train Loss: 1.1182, Train Accuracy: 52.77%, Test Loss: 0.9952, Test Accuracy: 55.70%\n",
      "Epoch [154/2500], Train Loss: 1.1125, Train Accuracy: 53.77%, Test Loss: 0.9896, Test Accuracy: 55.70%\n",
      "Epoch [155/2500], Train Loss: 1.1190, Train Accuracy: 52.92%, Test Loss: 0.9891, Test Accuracy: 55.70%\n",
      "Epoch [156/2500], Train Loss: 1.1020, Train Accuracy: 52.77%, Test Loss: 0.9914, Test Accuracy: 55.70%\n",
      "Epoch [157/2500], Train Loss: 1.1033, Train Accuracy: 53.63%, Test Loss: 0.9897, Test Accuracy: 55.70%\n",
      "Epoch [158/2500], Train Loss: 1.1007, Train Accuracy: 52.35%, Test Loss: 1.0119, Test Accuracy: 55.70%\n",
      "Epoch [159/2500], Train Loss: 1.0962, Train Accuracy: 53.91%, Test Loss: 0.9891, Test Accuracy: 56.96%\n",
      "Epoch [160/2500], Train Loss: 1.1110, Train Accuracy: 52.92%, Test Loss: 0.9878, Test Accuracy: 56.96%\n",
      "Epoch [161/2500], Train Loss: 1.1021, Train Accuracy: 55.05%, Test Loss: 0.9842, Test Accuracy: 56.96%\n",
      "Epoch [162/2500], Train Loss: 1.0874, Train Accuracy: 54.20%, Test Loss: 0.9788, Test Accuracy: 58.23%\n",
      "Epoch [163/2500], Train Loss: 1.0975, Train Accuracy: 54.62%, Test Loss: 0.9715, Test Accuracy: 56.96%\n",
      "Epoch [164/2500], Train Loss: 1.0811, Train Accuracy: 54.62%, Test Loss: 0.9741, Test Accuracy: 58.23%\n",
      "Epoch [165/2500], Train Loss: 1.1234, Train Accuracy: 52.92%, Test Loss: 0.9864, Test Accuracy: 56.96%\n",
      "Epoch [166/2500], Train Loss: 1.0929, Train Accuracy: 54.20%, Test Loss: 0.9924, Test Accuracy: 58.23%\n",
      "Epoch [167/2500], Train Loss: 1.0896, Train Accuracy: 55.19%, Test Loss: 0.9878, Test Accuracy: 56.96%\n",
      "Epoch [168/2500], Train Loss: 1.0855, Train Accuracy: 53.63%, Test Loss: 0.9931, Test Accuracy: 58.23%\n",
      "Epoch [169/2500], Train Loss: 1.0905, Train Accuracy: 53.06%, Test Loss: 0.9912, Test Accuracy: 58.23%\n",
      "Epoch [170/2500], Train Loss: 1.0800, Train Accuracy: 55.05%, Test Loss: 0.9933, Test Accuracy: 58.23%\n",
      "Epoch [171/2500], Train Loss: 1.0916, Train Accuracy: 53.49%, Test Loss: 0.9986, Test Accuracy: 56.96%\n",
      "Epoch [172/2500], Train Loss: 1.0782, Train Accuracy: 54.48%, Test Loss: 0.9877, Test Accuracy: 58.23%\n",
      "Epoch [173/2500], Train Loss: 1.0955, Train Accuracy: 53.49%, Test Loss: 0.9795, Test Accuracy: 58.23%\n",
      "Epoch [174/2500], Train Loss: 1.0889, Train Accuracy: 54.77%, Test Loss: 0.9874, Test Accuracy: 58.23%\n",
      "Epoch [175/2500], Train Loss: 1.0875, Train Accuracy: 54.34%, Test Loss: 0.9805, Test Accuracy: 58.23%\n",
      "Epoch [176/2500], Train Loss: 1.0788, Train Accuracy: 53.63%, Test Loss: 0.9832, Test Accuracy: 58.23%\n",
      "Epoch [177/2500], Train Loss: 1.0903, Train Accuracy: 53.63%, Test Loss: 0.9838, Test Accuracy: 58.23%\n",
      "Epoch [178/2500], Train Loss: 1.0816, Train Accuracy: 55.19%, Test Loss: 0.9865, Test Accuracy: 58.23%\n",
      "Epoch [179/2500], Train Loss: 1.0739, Train Accuracy: 53.91%, Test Loss: 1.0106, Test Accuracy: 56.96%\n",
      "Epoch [180/2500], Train Loss: 1.0727, Train Accuracy: 54.62%, Test Loss: 1.0040, Test Accuracy: 58.23%\n",
      "Epoch [181/2500], Train Loss: 1.0699, Train Accuracy: 55.19%, Test Loss: 0.9863, Test Accuracy: 58.23%\n",
      "Epoch [182/2500], Train Loss: 1.0770, Train Accuracy: 54.77%, Test Loss: 0.9809, Test Accuracy: 59.49%\n",
      "Epoch [183/2500], Train Loss: 1.0731, Train Accuracy: 54.20%, Test Loss: 0.9851, Test Accuracy: 58.23%\n",
      "Epoch [184/2500], Train Loss: 1.0679, Train Accuracy: 53.91%, Test Loss: 0.9894, Test Accuracy: 58.23%\n",
      "Epoch [185/2500], Train Loss: 1.1004, Train Accuracy: 53.77%, Test Loss: 0.9919, Test Accuracy: 58.23%\n",
      "Epoch [186/2500], Train Loss: 1.0691, Train Accuracy: 55.05%, Test Loss: 0.9896, Test Accuracy: 59.49%\n",
      "Epoch [187/2500], Train Loss: 1.0696, Train Accuracy: 54.05%, Test Loss: 0.9844, Test Accuracy: 59.49%\n",
      "Epoch [188/2500], Train Loss: 1.0793, Train Accuracy: 54.91%, Test Loss: 0.9828, Test Accuracy: 59.49%\n",
      "Epoch [189/2500], Train Loss: 1.0658, Train Accuracy: 54.48%, Test Loss: 0.9973, Test Accuracy: 58.23%\n",
      "Epoch [190/2500], Train Loss: 1.0918, Train Accuracy: 52.35%, Test Loss: 0.9907, Test Accuracy: 58.23%\n",
      "Epoch [191/2500], Train Loss: 1.0783, Train Accuracy: 54.48%, Test Loss: 0.9857, Test Accuracy: 58.23%\n",
      "Epoch [192/2500], Train Loss: 1.0712, Train Accuracy: 53.63%, Test Loss: 0.9816, Test Accuracy: 59.49%\n",
      "Epoch [193/2500], Train Loss: 1.0808, Train Accuracy: 55.33%, Test Loss: 0.9778, Test Accuracy: 59.49%\n",
      "Epoch [194/2500], Train Loss: 1.0765, Train Accuracy: 53.77%, Test Loss: 0.9832, Test Accuracy: 59.49%\n",
      "Epoch [195/2500], Train Loss: 1.0721, Train Accuracy: 54.34%, Test Loss: 0.9787, Test Accuracy: 59.49%\n",
      "Epoch [196/2500], Train Loss: 1.0465, Train Accuracy: 56.47%, Test Loss: 0.9943, Test Accuracy: 59.49%\n",
      "Epoch [197/2500], Train Loss: 1.0692, Train Accuracy: 55.33%, Test Loss: 0.9846, Test Accuracy: 59.49%\n",
      "Epoch [198/2500], Train Loss: 1.0776, Train Accuracy: 53.77%, Test Loss: 0.9839, Test Accuracy: 59.49%\n",
      "Epoch [199/2500], Train Loss: 1.0838, Train Accuracy: 53.49%, Test Loss: 0.9778, Test Accuracy: 59.49%\n",
      "Epoch [200/2500], Train Loss: 1.0689, Train Accuracy: 54.77%, Test Loss: 0.9785, Test Accuracy: 59.49%\n",
      "Epoch [201/2500], Train Loss: 1.0647, Train Accuracy: 54.77%, Test Loss: 0.9784, Test Accuracy: 58.23%\n",
      "Epoch [202/2500], Train Loss: 1.0594, Train Accuracy: 53.77%, Test Loss: 0.9784, Test Accuracy: 58.23%\n",
      "Epoch [203/2500], Train Loss: 1.0626, Train Accuracy: 54.77%, Test Loss: 0.9820, Test Accuracy: 59.49%\n",
      "Epoch [204/2500], Train Loss: 1.0480, Train Accuracy: 56.05%, Test Loss: 0.9893, Test Accuracy: 59.49%\n",
      "Epoch [205/2500], Train Loss: 1.0598, Train Accuracy: 54.77%, Test Loss: 0.9913, Test Accuracy: 59.49%\n",
      "Epoch [206/2500], Train Loss: 1.0683, Train Accuracy: 55.48%, Test Loss: 0.9819, Test Accuracy: 59.49%\n",
      "Epoch [207/2500], Train Loss: 1.0544, Train Accuracy: 55.48%, Test Loss: 0.9841, Test Accuracy: 59.49%\n",
      "Epoch [208/2500], Train Loss: 1.0735, Train Accuracy: 55.33%, Test Loss: 0.9830, Test Accuracy: 58.23%\n",
      "Epoch [209/2500], Train Loss: 1.0717, Train Accuracy: 54.48%, Test Loss: 0.9728, Test Accuracy: 58.23%\n",
      "Epoch [210/2500], Train Loss: 1.0466, Train Accuracy: 55.76%, Test Loss: 0.9806, Test Accuracy: 59.49%\n",
      "Epoch [211/2500], Train Loss: 1.0542, Train Accuracy: 55.62%, Test Loss: 0.9721, Test Accuracy: 58.23%\n",
      "Epoch [212/2500], Train Loss: 1.0774, Train Accuracy: 54.91%, Test Loss: 0.9732, Test Accuracy: 60.76%\n",
      "Epoch [213/2500], Train Loss: 1.0529, Train Accuracy: 56.47%, Test Loss: 0.9782, Test Accuracy: 59.49%\n",
      "Epoch [214/2500], Train Loss: 1.0475, Train Accuracy: 55.90%, Test Loss: 0.9763, Test Accuracy: 62.03%\n",
      "Epoch [215/2500], Train Loss: 1.0520, Train Accuracy: 55.19%, Test Loss: 0.9712, Test Accuracy: 59.49%\n",
      "Epoch [216/2500], Train Loss: 1.0556, Train Accuracy: 55.76%, Test Loss: 0.9703, Test Accuracy: 59.49%\n",
      "Epoch [217/2500], Train Loss: 1.0615, Train Accuracy: 55.62%, Test Loss: 0.9735, Test Accuracy: 59.49%\n",
      "Epoch [218/2500], Train Loss: 1.0496, Train Accuracy: 54.62%, Test Loss: 0.9706, Test Accuracy: 59.49%\n",
      "Epoch [219/2500], Train Loss: 1.0449, Train Accuracy: 55.33%, Test Loss: 0.9695, Test Accuracy: 59.49%\n",
      "Epoch [220/2500], Train Loss: 1.0510, Train Accuracy: 54.77%, Test Loss: 0.9854, Test Accuracy: 59.49%\n",
      "Epoch [221/2500], Train Loss: 1.0565, Train Accuracy: 56.33%, Test Loss: 0.9657, Test Accuracy: 59.49%\n",
      "Epoch [222/2500], Train Loss: 1.0611, Train Accuracy: 54.77%, Test Loss: 0.9650, Test Accuracy: 59.49%\n",
      "Epoch [223/2500], Train Loss: 1.0450, Train Accuracy: 56.33%, Test Loss: 0.9636, Test Accuracy: 59.49%\n",
      "Epoch [224/2500], Train Loss: 1.0452, Train Accuracy: 55.62%, Test Loss: 0.9648, Test Accuracy: 59.49%\n",
      "Epoch [225/2500], Train Loss: 1.0539, Train Accuracy: 56.61%, Test Loss: 0.9623, Test Accuracy: 59.49%\n",
      "Epoch [226/2500], Train Loss: 1.0351, Train Accuracy: 56.05%, Test Loss: 0.9647, Test Accuracy: 59.49%\n",
      "Epoch [227/2500], Train Loss: 1.0426, Train Accuracy: 56.61%, Test Loss: 0.9607, Test Accuracy: 59.49%\n",
      "Epoch [228/2500], Train Loss: 1.0285, Train Accuracy: 56.76%, Test Loss: 0.9646, Test Accuracy: 59.49%\n",
      "Epoch [229/2500], Train Loss: 1.0448, Train Accuracy: 54.77%, Test Loss: 0.9619, Test Accuracy: 59.49%\n",
      "Epoch [230/2500], Train Loss: 1.0474, Train Accuracy: 56.33%, Test Loss: 0.9672, Test Accuracy: 59.49%\n",
      "Epoch [231/2500], Train Loss: 1.0526, Train Accuracy: 54.91%, Test Loss: 0.9630, Test Accuracy: 59.49%\n",
      "Epoch [232/2500], Train Loss: 1.0444, Train Accuracy: 55.05%, Test Loss: 0.9645, Test Accuracy: 59.49%\n",
      "Epoch [233/2500], Train Loss: 1.0355, Train Accuracy: 56.47%, Test Loss: 0.9605, Test Accuracy: 62.03%\n",
      "Epoch [234/2500], Train Loss: 1.0537, Train Accuracy: 55.62%, Test Loss: 0.9636, Test Accuracy: 59.49%\n",
      "Epoch [235/2500], Train Loss: 1.0326, Train Accuracy: 54.62%, Test Loss: 0.9667, Test Accuracy: 59.49%\n",
      "Epoch [236/2500], Train Loss: 1.0521, Train Accuracy: 56.19%, Test Loss: 0.9701, Test Accuracy: 58.23%\n",
      "Epoch [237/2500], Train Loss: 1.0499, Train Accuracy: 55.48%, Test Loss: 0.9663, Test Accuracy: 59.49%\n",
      "Epoch [238/2500], Train Loss: 1.0352, Train Accuracy: 55.76%, Test Loss: 0.9650, Test Accuracy: 58.23%\n",
      "Epoch [239/2500], Train Loss: 1.0416, Train Accuracy: 54.62%, Test Loss: 0.9639, Test Accuracy: 59.49%\n",
      "Epoch [240/2500], Train Loss: 1.0372, Train Accuracy: 56.61%, Test Loss: 0.9613, Test Accuracy: 59.49%\n",
      "Epoch [241/2500], Train Loss: 1.0349, Train Accuracy: 55.33%, Test Loss: 0.9625, Test Accuracy: 59.49%\n",
      "Epoch [242/2500], Train Loss: 1.0402, Train Accuracy: 56.33%, Test Loss: 0.9624, Test Accuracy: 59.49%\n",
      "Epoch [243/2500], Train Loss: 1.0312, Train Accuracy: 56.47%, Test Loss: 0.9619, Test Accuracy: 59.49%\n",
      "Epoch [244/2500], Train Loss: 1.0258, Train Accuracy: 56.47%, Test Loss: 0.9656, Test Accuracy: 59.49%\n",
      "Epoch [245/2500], Train Loss: 1.0429, Train Accuracy: 55.62%, Test Loss: 0.9614, Test Accuracy: 59.49%\n",
      "Epoch [246/2500], Train Loss: 1.0195, Train Accuracy: 56.33%, Test Loss: 0.9630, Test Accuracy: 59.49%\n",
      "Epoch [247/2500], Train Loss: 1.0424, Train Accuracy: 56.19%, Test Loss: 0.9623, Test Accuracy: 59.49%\n",
      "Epoch [248/2500], Train Loss: 1.0462, Train Accuracy: 55.62%, Test Loss: 0.9579, Test Accuracy: 59.49%\n",
      "Epoch [249/2500], Train Loss: 1.0493, Train Accuracy: 55.05%, Test Loss: 0.9576, Test Accuracy: 59.49%\n",
      "Epoch [250/2500], Train Loss: 1.0384, Train Accuracy: 55.48%, Test Loss: 0.9583, Test Accuracy: 59.49%\n",
      "Epoch [251/2500], Train Loss: 1.0373, Train Accuracy: 55.90%, Test Loss: 0.9547, Test Accuracy: 60.76%\n",
      "Epoch [252/2500], Train Loss: 1.0289, Train Accuracy: 56.05%, Test Loss: 0.9606, Test Accuracy: 59.49%\n",
      "Epoch [253/2500], Train Loss: 1.0184, Train Accuracy: 56.19%, Test Loss: 0.9563, Test Accuracy: 60.76%\n",
      "Epoch [254/2500], Train Loss: 1.0375, Train Accuracy: 56.19%, Test Loss: 0.9611, Test Accuracy: 59.49%\n",
      "Epoch [255/2500], Train Loss: 1.0334, Train Accuracy: 57.33%, Test Loss: 0.9628, Test Accuracy: 60.76%\n",
      "Epoch [256/2500], Train Loss: 1.0302, Train Accuracy: 55.48%, Test Loss: 0.9652, Test Accuracy: 59.49%\n",
      "Epoch [257/2500], Train Loss: 1.0326, Train Accuracy: 56.19%, Test Loss: 0.9551, Test Accuracy: 59.49%\n",
      "Epoch [258/2500], Train Loss: 1.0227, Train Accuracy: 56.05%, Test Loss: 0.9603, Test Accuracy: 59.49%\n",
      "Epoch [259/2500], Train Loss: 1.0200, Train Accuracy: 56.33%, Test Loss: 0.9577, Test Accuracy: 59.49%\n",
      "Epoch [260/2500], Train Loss: 1.0082, Train Accuracy: 57.75%, Test Loss: 0.9593, Test Accuracy: 59.49%\n",
      "Epoch [261/2500], Train Loss: 1.0387, Train Accuracy: 55.62%, Test Loss: 0.9622, Test Accuracy: 59.49%\n",
      "Epoch [262/2500], Train Loss: 1.0369, Train Accuracy: 54.62%, Test Loss: 0.9570, Test Accuracy: 60.76%\n",
      "Epoch [263/2500], Train Loss: 1.0325, Train Accuracy: 56.05%, Test Loss: 0.9569, Test Accuracy: 63.29%\n",
      "Epoch [264/2500], Train Loss: 1.0265, Train Accuracy: 57.04%, Test Loss: 0.9613, Test Accuracy: 60.76%\n",
      "Epoch [265/2500], Train Loss: 1.0222, Train Accuracy: 57.18%, Test Loss: 0.9646, Test Accuracy: 60.76%\n",
      "Epoch [266/2500], Train Loss: 1.0482, Train Accuracy: 54.77%, Test Loss: 0.9616, Test Accuracy: 60.76%\n",
      "Epoch [267/2500], Train Loss: 1.0233, Train Accuracy: 56.33%, Test Loss: 0.9639, Test Accuracy: 59.49%\n",
      "Epoch [268/2500], Train Loss: 1.0305, Train Accuracy: 56.90%, Test Loss: 0.9641, Test Accuracy: 59.49%\n",
      "Epoch [269/2500], Train Loss: 1.0301, Train Accuracy: 55.90%, Test Loss: 0.9608, Test Accuracy: 59.49%\n",
      "Epoch [270/2500], Train Loss: 1.0173, Train Accuracy: 55.33%, Test Loss: 0.9606, Test Accuracy: 60.76%\n",
      "Epoch [271/2500], Train Loss: 1.0336, Train Accuracy: 56.19%, Test Loss: 0.9583, Test Accuracy: 59.49%\n",
      "Epoch [272/2500], Train Loss: 1.0146, Train Accuracy: 57.18%, Test Loss: 0.9602, Test Accuracy: 59.49%\n",
      "Epoch [273/2500], Train Loss: 1.0385, Train Accuracy: 56.61%, Test Loss: 0.9578, Test Accuracy: 59.49%\n",
      "Epoch [274/2500], Train Loss: 1.0310, Train Accuracy: 56.05%, Test Loss: 0.9566, Test Accuracy: 59.49%\n",
      "Epoch [275/2500], Train Loss: 1.0217, Train Accuracy: 56.19%, Test Loss: 0.9489, Test Accuracy: 59.49%\n",
      "Epoch [276/2500], Train Loss: 1.0328, Train Accuracy: 56.76%, Test Loss: 0.9573, Test Accuracy: 59.49%\n",
      "Epoch [277/2500], Train Loss: 1.0257, Train Accuracy: 56.61%, Test Loss: 0.9619, Test Accuracy: 59.49%\n",
      "Epoch [278/2500], Train Loss: 1.0081, Train Accuracy: 56.47%, Test Loss: 0.9579, Test Accuracy: 59.49%\n",
      "Epoch [279/2500], Train Loss: 1.0035, Train Accuracy: 57.47%, Test Loss: 0.9611, Test Accuracy: 59.49%\n",
      "Epoch [280/2500], Train Loss: 1.0209, Train Accuracy: 55.62%, Test Loss: 0.9663, Test Accuracy: 59.49%\n",
      "Epoch [281/2500], Train Loss: 1.0164, Train Accuracy: 56.19%, Test Loss: 0.9624, Test Accuracy: 59.49%\n",
      "Epoch [282/2500], Train Loss: 1.0185, Train Accuracy: 57.18%, Test Loss: 0.9676, Test Accuracy: 59.49%\n",
      "Epoch [283/2500], Train Loss: 1.0215, Train Accuracy: 57.33%, Test Loss: 0.9724, Test Accuracy: 59.49%\n",
      "Epoch [284/2500], Train Loss: 1.0256, Train Accuracy: 56.90%, Test Loss: 0.9687, Test Accuracy: 59.49%\n",
      "Epoch [285/2500], Train Loss: 1.0145, Train Accuracy: 56.33%, Test Loss: 0.9747, Test Accuracy: 59.49%\n",
      "Epoch [286/2500], Train Loss: 1.0143, Train Accuracy: 57.33%, Test Loss: 0.9604, Test Accuracy: 59.49%\n",
      "Epoch [287/2500], Train Loss: 1.0235, Train Accuracy: 56.19%, Test Loss: 0.9590, Test Accuracy: 59.49%\n",
      "Epoch [288/2500], Train Loss: 1.0057, Train Accuracy: 57.89%, Test Loss: 0.9593, Test Accuracy: 60.76%\n",
      "Epoch [289/2500], Train Loss: 1.0228, Train Accuracy: 55.76%, Test Loss: 0.9581, Test Accuracy: 60.76%\n",
      "Epoch [290/2500], Train Loss: 1.0233, Train Accuracy: 56.05%, Test Loss: 0.9614, Test Accuracy: 60.76%\n",
      "Epoch [291/2500], Train Loss: 1.0306, Train Accuracy: 55.62%, Test Loss: 0.9604, Test Accuracy: 59.49%\n",
      "Epoch [292/2500], Train Loss: 1.0138, Train Accuracy: 56.76%, Test Loss: 0.9626, Test Accuracy: 59.49%\n",
      "Epoch [293/2500], Train Loss: 1.0042, Train Accuracy: 57.75%, Test Loss: 0.9650, Test Accuracy: 60.76%\n",
      "Epoch [294/2500], Train Loss: 1.0162, Train Accuracy: 56.05%, Test Loss: 0.9601, Test Accuracy: 59.49%\n",
      "Epoch [295/2500], Train Loss: 1.0247, Train Accuracy: 55.90%, Test Loss: 0.9553, Test Accuracy: 60.76%\n",
      "Epoch [296/2500], Train Loss: 1.0148, Train Accuracy: 56.76%, Test Loss: 0.9606, Test Accuracy: 59.49%\n",
      "Epoch [297/2500], Train Loss: 1.0169, Train Accuracy: 56.19%, Test Loss: 0.9642, Test Accuracy: 59.49%\n",
      "Epoch [298/2500], Train Loss: 1.0155, Train Accuracy: 56.76%, Test Loss: 0.9678, Test Accuracy: 58.23%\n",
      "Epoch [299/2500], Train Loss: 1.0290, Train Accuracy: 56.76%, Test Loss: 0.9570, Test Accuracy: 62.03%\n",
      "Epoch [300/2500], Train Loss: 1.0125, Train Accuracy: 57.47%, Test Loss: 0.9559, Test Accuracy: 60.76%\n",
      "Epoch [301/2500], Train Loss: 1.0060, Train Accuracy: 56.19%, Test Loss: 0.9628, Test Accuracy: 60.76%\n",
      "Epoch [302/2500], Train Loss: 0.9917, Train Accuracy: 57.18%, Test Loss: 0.9637, Test Accuracy: 60.76%\n",
      "Epoch [303/2500], Train Loss: 1.0204, Train Accuracy: 57.33%, Test Loss: 0.9600, Test Accuracy: 60.76%\n",
      "Epoch [304/2500], Train Loss: 1.0084, Train Accuracy: 56.33%, Test Loss: 0.9585, Test Accuracy: 60.76%\n",
      "Epoch [305/2500], Train Loss: 1.0047, Train Accuracy: 56.47%, Test Loss: 0.9617, Test Accuracy: 60.76%\n",
      "Epoch [306/2500], Train Loss: 1.0275, Train Accuracy: 55.33%, Test Loss: 0.9583, Test Accuracy: 59.49%\n",
      "Epoch [307/2500], Train Loss: 1.0085, Train Accuracy: 58.04%, Test Loss: 0.9600, Test Accuracy: 60.76%\n",
      "Epoch [308/2500], Train Loss: 1.0001, Train Accuracy: 55.90%, Test Loss: 0.9623, Test Accuracy: 60.76%\n",
      "Epoch [309/2500], Train Loss: 1.0090, Train Accuracy: 57.18%, Test Loss: 0.9619, Test Accuracy: 59.49%\n",
      "Epoch [310/2500], Train Loss: 1.0030, Train Accuracy: 57.18%, Test Loss: 0.9610, Test Accuracy: 59.49%\n",
      "Epoch [311/2500], Train Loss: 1.0305, Train Accuracy: 57.04%, Test Loss: 0.9635, Test Accuracy: 60.76%\n",
      "Epoch [312/2500], Train Loss: 1.0077, Train Accuracy: 56.61%, Test Loss: 0.9627, Test Accuracy: 59.49%\n",
      "Epoch [313/2500], Train Loss: 1.0009, Train Accuracy: 58.46%, Test Loss: 0.9681, Test Accuracy: 59.49%\n",
      "Epoch [314/2500], Train Loss: 1.0043, Train Accuracy: 57.61%, Test Loss: 0.9663, Test Accuracy: 59.49%\n",
      "Epoch [315/2500], Train Loss: 1.0023, Train Accuracy: 57.75%, Test Loss: 0.9625, Test Accuracy: 60.76%\n",
      "Epoch [316/2500], Train Loss: 1.0038, Train Accuracy: 56.47%, Test Loss: 0.9637, Test Accuracy: 59.49%\n",
      "Epoch [317/2500], Train Loss: 0.9976, Train Accuracy: 57.89%, Test Loss: 0.9574, Test Accuracy: 59.49%\n",
      "Epoch [318/2500], Train Loss: 1.0078, Train Accuracy: 57.04%, Test Loss: 0.9571, Test Accuracy: 60.76%\n",
      "Epoch [319/2500], Train Loss: 1.0054, Train Accuracy: 57.47%, Test Loss: 0.9533, Test Accuracy: 59.49%\n",
      "Epoch [320/2500], Train Loss: 1.0253, Train Accuracy: 56.47%, Test Loss: 0.9533, Test Accuracy: 60.76%\n",
      "Epoch [321/2500], Train Loss: 1.0026, Train Accuracy: 56.47%, Test Loss: 0.9559, Test Accuracy: 60.76%\n",
      "Epoch [322/2500], Train Loss: 1.0026, Train Accuracy: 56.76%, Test Loss: 0.9582, Test Accuracy: 59.49%\n",
      "Epoch [323/2500], Train Loss: 1.0104, Train Accuracy: 58.04%, Test Loss: 0.9649, Test Accuracy: 60.76%\n",
      "Epoch [324/2500], Train Loss: 1.0209, Train Accuracy: 56.61%, Test Loss: 0.9622, Test Accuracy: 60.76%\n",
      "Epoch [325/2500], Train Loss: 1.0005, Train Accuracy: 56.90%, Test Loss: 0.9593, Test Accuracy: 59.49%\n",
      "Epoch [326/2500], Train Loss: 0.9941, Train Accuracy: 56.76%, Test Loss: 0.9593, Test Accuracy: 60.76%\n",
      "Epoch [327/2500], Train Loss: 0.9854, Train Accuracy: 57.04%, Test Loss: 0.9562, Test Accuracy: 59.49%\n",
      "Epoch [328/2500], Train Loss: 1.0082, Train Accuracy: 56.05%, Test Loss: 0.9571, Test Accuracy: 59.49%\n",
      "Epoch [329/2500], Train Loss: 1.0144, Train Accuracy: 56.33%, Test Loss: 0.9598, Test Accuracy: 59.49%\n",
      "Epoch [330/2500], Train Loss: 0.9945, Train Accuracy: 57.04%, Test Loss: 0.9659, Test Accuracy: 59.49%\n",
      "Epoch [331/2500], Train Loss: 1.0049, Train Accuracy: 57.04%, Test Loss: 0.9639, Test Accuracy: 59.49%\n",
      "Epoch [332/2500], Train Loss: 0.9938, Train Accuracy: 57.18%, Test Loss: 0.9612, Test Accuracy: 59.49%\n",
      "Epoch [333/2500], Train Loss: 0.9902, Train Accuracy: 57.61%, Test Loss: 0.9576, Test Accuracy: 59.49%\n",
      "Epoch [334/2500], Train Loss: 0.9984, Train Accuracy: 56.76%, Test Loss: 0.9611, Test Accuracy: 59.49%\n",
      "Epoch [335/2500], Train Loss: 1.0107, Train Accuracy: 56.47%, Test Loss: 0.9572, Test Accuracy: 60.76%\n",
      "Epoch [336/2500], Train Loss: 0.9960, Train Accuracy: 57.18%, Test Loss: 0.9620, Test Accuracy: 60.76%\n",
      "Epoch [337/2500], Train Loss: 0.9932, Train Accuracy: 57.33%, Test Loss: 0.9576, Test Accuracy: 59.49%\n",
      "Epoch [338/2500], Train Loss: 1.0207, Train Accuracy: 57.89%, Test Loss: 0.9472, Test Accuracy: 60.76%\n",
      "Epoch [339/2500], Train Loss: 1.0145, Train Accuracy: 55.90%, Test Loss: 0.9476, Test Accuracy: 62.03%\n",
      "Epoch [340/2500], Train Loss: 1.0192, Train Accuracy: 56.76%, Test Loss: 0.9537, Test Accuracy: 62.03%\n",
      "Epoch [341/2500], Train Loss: 0.9988, Train Accuracy: 56.76%, Test Loss: 0.9542, Test Accuracy: 62.03%\n",
      "Epoch [342/2500], Train Loss: 1.0098, Train Accuracy: 57.33%, Test Loss: 0.9624, Test Accuracy: 60.76%\n",
      "Epoch [343/2500], Train Loss: 0.9900, Train Accuracy: 57.18%, Test Loss: 0.9591, Test Accuracy: 60.76%\n",
      "Epoch [344/2500], Train Loss: 1.0047, Train Accuracy: 57.04%, Test Loss: 0.9539, Test Accuracy: 60.76%\n",
      "Epoch [345/2500], Train Loss: 1.0041, Train Accuracy: 56.61%, Test Loss: 0.9607, Test Accuracy: 60.76%\n",
      "Epoch [346/2500], Train Loss: 1.0005, Train Accuracy: 57.04%, Test Loss: 0.9559, Test Accuracy: 62.03%\n",
      "Epoch [347/2500], Train Loss: 1.0036, Train Accuracy: 57.04%, Test Loss: 0.9569, Test Accuracy: 60.76%\n",
      "Epoch [348/2500], Train Loss: 0.9916, Train Accuracy: 56.90%, Test Loss: 0.9568, Test Accuracy: 59.49%\n",
      "Epoch [349/2500], Train Loss: 1.0083, Train Accuracy: 56.90%, Test Loss: 0.9591, Test Accuracy: 60.76%\n",
      "Epoch [350/2500], Train Loss: 1.0017, Train Accuracy: 56.61%, Test Loss: 0.9613, Test Accuracy: 60.76%\n",
      "Epoch [351/2500], Train Loss: 0.9876, Train Accuracy: 56.61%, Test Loss: 0.9608, Test Accuracy: 62.03%\n",
      "Epoch [352/2500], Train Loss: 1.0190, Train Accuracy: 57.04%, Test Loss: 0.9519, Test Accuracy: 62.03%\n",
      "Epoch [353/2500], Train Loss: 0.9985, Train Accuracy: 57.47%, Test Loss: 0.9574, Test Accuracy: 62.03%\n",
      "Epoch [354/2500], Train Loss: 1.0082, Train Accuracy: 56.19%, Test Loss: 0.9564, Test Accuracy: 60.76%\n",
      "Epoch [355/2500], Train Loss: 0.9818, Train Accuracy: 57.75%, Test Loss: 0.9642, Test Accuracy: 60.76%\n",
      "Epoch [356/2500], Train Loss: 0.9998, Train Accuracy: 56.61%, Test Loss: 0.9639, Test Accuracy: 60.76%\n",
      "Epoch [357/2500], Train Loss: 0.9962, Train Accuracy: 56.33%, Test Loss: 0.9632, Test Accuracy: 59.49%\n",
      "Epoch [358/2500], Train Loss: 0.9914, Train Accuracy: 57.04%, Test Loss: 0.9626, Test Accuracy: 60.76%\n",
      "Epoch [359/2500], Train Loss: 0.9977, Train Accuracy: 56.05%, Test Loss: 0.9595, Test Accuracy: 59.49%\n",
      "Epoch [360/2500], Train Loss: 0.9703, Train Accuracy: 58.32%, Test Loss: 0.9524, Test Accuracy: 62.03%\n",
      "Epoch [361/2500], Train Loss: 1.0186, Train Accuracy: 56.90%, Test Loss: 0.9516, Test Accuracy: 60.76%\n",
      "Epoch [362/2500], Train Loss: 1.0081, Train Accuracy: 57.61%, Test Loss: 0.9607, Test Accuracy: 62.03%\n",
      "Epoch [363/2500], Train Loss: 0.9846, Train Accuracy: 58.04%, Test Loss: 0.9623, Test Accuracy: 59.49%\n",
      "Epoch [364/2500], Train Loss: 1.0162, Train Accuracy: 56.33%, Test Loss: 0.9599, Test Accuracy: 60.76%\n",
      "Epoch [365/2500], Train Loss: 0.9925, Train Accuracy: 58.04%, Test Loss: 0.9616, Test Accuracy: 60.76%\n",
      "Epoch [366/2500], Train Loss: 0.9760, Train Accuracy: 57.75%, Test Loss: 0.9599, Test Accuracy: 62.03%\n",
      "Epoch [367/2500], Train Loss: 0.9995, Train Accuracy: 56.76%, Test Loss: 0.9581, Test Accuracy: 62.03%\n",
      "Epoch [368/2500], Train Loss: 0.9992, Train Accuracy: 56.90%, Test Loss: 0.9622, Test Accuracy: 59.49%\n",
      "Epoch [369/2500], Train Loss: 0.9981, Train Accuracy: 56.90%, Test Loss: 0.9627, Test Accuracy: 60.76%\n",
      "Epoch [370/2500], Train Loss: 1.0028, Train Accuracy: 56.47%, Test Loss: 0.9663, Test Accuracy: 59.49%\n",
      "Epoch [371/2500], Train Loss: 0.9995, Train Accuracy: 56.19%, Test Loss: 0.9675, Test Accuracy: 59.49%\n",
      "Epoch [372/2500], Train Loss: 0.9865, Train Accuracy: 57.47%, Test Loss: 0.9665, Test Accuracy: 60.76%\n",
      "Epoch [373/2500], Train Loss: 0.9978, Train Accuracy: 56.05%, Test Loss: 0.9674, Test Accuracy: 60.76%\n",
      "Epoch [374/2500], Train Loss: 0.9936, Train Accuracy: 58.75%, Test Loss: 0.9689, Test Accuracy: 60.76%\n",
      "Epoch [375/2500], Train Loss: 0.9984, Train Accuracy: 56.76%, Test Loss: 0.9684, Test Accuracy: 60.76%\n",
      "Epoch [376/2500], Train Loss: 0.9847, Train Accuracy: 56.76%, Test Loss: 0.9674, Test Accuracy: 59.49%\n",
      "Epoch [377/2500], Train Loss: 0.9859, Train Accuracy: 56.90%, Test Loss: 0.9673, Test Accuracy: 59.49%\n",
      "Epoch [378/2500], Train Loss: 1.0003, Train Accuracy: 57.47%, Test Loss: 0.9693, Test Accuracy: 60.76%\n",
      "Epoch [379/2500], Train Loss: 0.9834, Train Accuracy: 57.18%, Test Loss: 0.9697, Test Accuracy: 60.76%\n",
      "Epoch [380/2500], Train Loss: 0.9937, Train Accuracy: 58.18%, Test Loss: 0.9642, Test Accuracy: 59.49%\n",
      "Epoch [381/2500], Train Loss: 1.0058, Train Accuracy: 56.90%, Test Loss: 0.9629, Test Accuracy: 60.76%\n",
      "Epoch [382/2500], Train Loss: 0.9925, Train Accuracy: 57.61%, Test Loss: 0.9650, Test Accuracy: 60.76%\n",
      "Epoch [383/2500], Train Loss: 1.0051, Train Accuracy: 56.47%, Test Loss: 0.9662, Test Accuracy: 60.76%\n",
      "Epoch [384/2500], Train Loss: 0.9920, Train Accuracy: 57.75%, Test Loss: 0.9594, Test Accuracy: 60.76%\n",
      "Epoch [385/2500], Train Loss: 1.0015, Train Accuracy: 56.76%, Test Loss: 0.9556, Test Accuracy: 60.76%\n",
      "Epoch [386/2500], Train Loss: 0.9941, Train Accuracy: 57.04%, Test Loss: 0.9515, Test Accuracy: 60.76%\n",
      "Epoch [387/2500], Train Loss: 0.9841, Train Accuracy: 58.32%, Test Loss: 0.9639, Test Accuracy: 60.76%\n",
      "Epoch [388/2500], Train Loss: 0.9875, Train Accuracy: 57.04%, Test Loss: 0.9569, Test Accuracy: 60.76%\n",
      "Epoch [389/2500], Train Loss: 1.0066, Train Accuracy: 58.04%, Test Loss: 0.9728, Test Accuracy: 60.76%\n",
      "Epoch [390/2500], Train Loss: 0.9833, Train Accuracy: 57.75%, Test Loss: 0.9483, Test Accuracy: 62.03%\n",
      "Epoch [391/2500], Train Loss: 0.9924, Train Accuracy: 57.61%, Test Loss: 0.9528, Test Accuracy: 62.03%\n",
      "Epoch [392/2500], Train Loss: 1.0064, Train Accuracy: 57.18%, Test Loss: 0.9405, Test Accuracy: 62.03%\n",
      "Epoch [393/2500], Train Loss: 0.9968, Train Accuracy: 56.47%, Test Loss: 0.9473, Test Accuracy: 62.03%\n",
      "Epoch [394/2500], Train Loss: 0.9784, Train Accuracy: 57.75%, Test Loss: 0.9479, Test Accuracy: 62.03%\n",
      "Epoch [395/2500], Train Loss: 0.9747, Train Accuracy: 58.61%, Test Loss: 0.9532, Test Accuracy: 62.03%\n",
      "Epoch [396/2500], Train Loss: 1.0019, Train Accuracy: 56.61%, Test Loss: 0.9526, Test Accuracy: 62.03%\n",
      "Epoch [397/2500], Train Loss: 0.9699, Train Accuracy: 58.04%, Test Loss: 0.9498, Test Accuracy: 62.03%\n",
      "Epoch [398/2500], Train Loss: 0.9916, Train Accuracy: 57.75%, Test Loss: 0.9418, Test Accuracy: 60.76%\n",
      "Epoch [399/2500], Train Loss: 0.9986, Train Accuracy: 58.18%, Test Loss: 0.9417, Test Accuracy: 60.76%\n",
      "Epoch [400/2500], Train Loss: 0.9623, Train Accuracy: 59.17%, Test Loss: 0.9423, Test Accuracy: 62.03%\n",
      "Epoch [401/2500], Train Loss: 0.9995, Train Accuracy: 57.33%, Test Loss: 0.9441, Test Accuracy: 60.76%\n",
      "Epoch [402/2500], Train Loss: 0.9776, Train Accuracy: 58.46%, Test Loss: 0.9540, Test Accuracy: 62.03%\n",
      "Epoch [403/2500], Train Loss: 0.9844, Train Accuracy: 57.61%, Test Loss: 0.9566, Test Accuracy: 59.49%\n",
      "Epoch [404/2500], Train Loss: 0.9896, Train Accuracy: 57.18%, Test Loss: 0.9580, Test Accuracy: 60.76%\n",
      "Epoch [405/2500], Train Loss: 0.9836, Train Accuracy: 57.89%, Test Loss: 0.9579, Test Accuracy: 60.76%\n",
      "Epoch [406/2500], Train Loss: 0.9776, Train Accuracy: 57.75%, Test Loss: 0.9555, Test Accuracy: 60.76%\n",
      "Epoch [407/2500], Train Loss: 0.9883, Train Accuracy: 57.47%, Test Loss: 0.9547, Test Accuracy: 62.03%\n",
      "Epoch [408/2500], Train Loss: 0.9901, Train Accuracy: 56.76%, Test Loss: 0.9590, Test Accuracy: 60.76%\n",
      "Epoch [409/2500], Train Loss: 0.9823, Train Accuracy: 57.89%, Test Loss: 0.9614, Test Accuracy: 60.76%\n",
      "Epoch [410/2500], Train Loss: 0.9960, Train Accuracy: 58.18%, Test Loss: 0.9600, Test Accuracy: 60.76%\n",
      "Epoch [411/2500], Train Loss: 0.9820, Train Accuracy: 58.46%, Test Loss: 0.9597, Test Accuracy: 60.76%\n",
      "Epoch [412/2500], Train Loss: 0.9764, Train Accuracy: 58.32%, Test Loss: 0.9574, Test Accuracy: 60.76%\n",
      "Epoch [413/2500], Train Loss: 0.9868, Train Accuracy: 57.89%, Test Loss: 0.9574, Test Accuracy: 59.49%\n",
      "Epoch [414/2500], Train Loss: 0.9733, Train Accuracy: 57.33%, Test Loss: 0.9522, Test Accuracy: 60.76%\n",
      "Epoch [415/2500], Train Loss: 0.9674, Train Accuracy: 57.18%, Test Loss: 0.9470, Test Accuracy: 60.76%\n",
      "Epoch [416/2500], Train Loss: 0.9765, Train Accuracy: 56.76%, Test Loss: 0.9396, Test Accuracy: 62.03%\n",
      "Epoch [417/2500], Train Loss: 0.9870, Train Accuracy: 56.19%, Test Loss: 0.9403, Test Accuracy: 62.03%\n",
      "Epoch [418/2500], Train Loss: 0.9945, Train Accuracy: 57.89%, Test Loss: 0.9479, Test Accuracy: 60.76%\n",
      "Epoch [419/2500], Train Loss: 0.9766, Train Accuracy: 56.61%, Test Loss: 0.9461, Test Accuracy: 60.76%\n",
      "Epoch [420/2500], Train Loss: 0.9884, Train Accuracy: 57.47%, Test Loss: 0.9410, Test Accuracy: 59.49%\n",
      "Epoch [421/2500], Train Loss: 0.9919, Train Accuracy: 57.33%, Test Loss: 0.9431, Test Accuracy: 59.49%\n",
      "Epoch [422/2500], Train Loss: 0.9822, Train Accuracy: 57.47%, Test Loss: 0.9409, Test Accuracy: 59.49%\n",
      "Epoch [423/2500], Train Loss: 0.9731, Train Accuracy: 58.18%, Test Loss: 0.9456, Test Accuracy: 59.49%\n",
      "Epoch [424/2500], Train Loss: 0.9846, Train Accuracy: 57.75%, Test Loss: 0.9460, Test Accuracy: 59.49%\n",
      "Epoch [425/2500], Train Loss: 0.9717, Train Accuracy: 58.04%, Test Loss: 0.9470, Test Accuracy: 59.49%\n",
      "Epoch [426/2500], Train Loss: 1.0028, Train Accuracy: 55.90%, Test Loss: 0.9468, Test Accuracy: 59.49%\n",
      "Epoch [427/2500], Train Loss: 0.9788, Train Accuracy: 57.18%, Test Loss: 0.9375, Test Accuracy: 59.49%\n",
      "Epoch [428/2500], Train Loss: 0.9894, Train Accuracy: 57.04%, Test Loss: 0.9379, Test Accuracy: 59.49%\n",
      "Epoch [429/2500], Train Loss: 0.9966, Train Accuracy: 57.61%, Test Loss: 0.9425, Test Accuracy: 59.49%\n",
      "Epoch [430/2500], Train Loss: 0.9868, Train Accuracy: 57.61%, Test Loss: 0.9473, Test Accuracy: 60.76%\n",
      "Epoch [431/2500], Train Loss: 0.9888, Train Accuracy: 56.47%, Test Loss: 0.9502, Test Accuracy: 59.49%\n",
      "Epoch [432/2500], Train Loss: 0.9965, Train Accuracy: 57.75%, Test Loss: 0.9532, Test Accuracy: 60.76%\n",
      "Epoch [433/2500], Train Loss: 0.9792, Train Accuracy: 57.75%, Test Loss: 0.9571, Test Accuracy: 60.76%\n",
      "Epoch [434/2500], Train Loss: 0.9737, Train Accuracy: 56.90%, Test Loss: 0.9534, Test Accuracy: 59.49%\n",
      "Epoch [435/2500], Train Loss: 1.0022, Train Accuracy: 57.04%, Test Loss: 0.9517, Test Accuracy: 59.49%\n",
      "Epoch [436/2500], Train Loss: 0.9752, Train Accuracy: 58.61%, Test Loss: 0.9526, Test Accuracy: 60.76%\n",
      "Epoch [437/2500], Train Loss: 0.9819, Train Accuracy: 57.75%, Test Loss: 0.9499, Test Accuracy: 60.76%\n",
      "Epoch [438/2500], Train Loss: 0.9993, Train Accuracy: 57.18%, Test Loss: 0.9493, Test Accuracy: 60.76%\n",
      "Epoch [439/2500], Train Loss: 0.9657, Train Accuracy: 56.61%, Test Loss: 0.9594, Test Accuracy: 60.76%\n",
      "Epoch [440/2500], Train Loss: 0.9847, Train Accuracy: 57.47%, Test Loss: 0.9522, Test Accuracy: 60.76%\n",
      "Epoch [441/2500], Train Loss: 0.9852, Train Accuracy: 57.18%, Test Loss: 0.9489, Test Accuracy: 60.76%\n",
      "Epoch [442/2500], Train Loss: 0.9830, Train Accuracy: 58.46%, Test Loss: 0.9547, Test Accuracy: 59.49%\n",
      "Epoch [443/2500], Train Loss: 0.9808, Train Accuracy: 59.17%, Test Loss: 0.9524, Test Accuracy: 60.76%\n",
      "Epoch [444/2500], Train Loss: 0.9720, Train Accuracy: 57.04%, Test Loss: 0.9502, Test Accuracy: 60.76%\n",
      "Epoch [445/2500], Train Loss: 0.9913, Train Accuracy: 57.61%, Test Loss: 0.9416, Test Accuracy: 60.76%\n",
      "Epoch [446/2500], Train Loss: 0.9767, Train Accuracy: 58.32%, Test Loss: 0.9450, Test Accuracy: 60.76%\n",
      "Epoch [447/2500], Train Loss: 0.9881, Train Accuracy: 57.61%, Test Loss: 0.9502, Test Accuracy: 59.49%\n",
      "Epoch [448/2500], Train Loss: 0.9809, Train Accuracy: 56.61%, Test Loss: 0.9501, Test Accuracy: 59.49%\n",
      "Epoch [449/2500], Train Loss: 0.9866, Train Accuracy: 57.33%, Test Loss: 0.9518, Test Accuracy: 59.49%\n",
      "Epoch [450/2500], Train Loss: 0.9813, Train Accuracy: 57.75%, Test Loss: 0.9542, Test Accuracy: 58.23%\n",
      "Epoch [451/2500], Train Loss: 0.9843, Train Accuracy: 57.04%, Test Loss: 0.9544, Test Accuracy: 58.23%\n",
      "Epoch [452/2500], Train Loss: 0.9919, Train Accuracy: 57.18%, Test Loss: 0.9585, Test Accuracy: 59.49%\n",
      "Epoch [453/2500], Train Loss: 0.9611, Train Accuracy: 59.03%, Test Loss: 0.9582, Test Accuracy: 59.49%\n",
      "Epoch [454/2500], Train Loss: 0.9692, Train Accuracy: 57.33%, Test Loss: 0.9564, Test Accuracy: 60.76%\n",
      "Epoch [455/2500], Train Loss: 0.9927, Train Accuracy: 58.18%, Test Loss: 0.9529, Test Accuracy: 59.49%\n",
      "Epoch [456/2500], Train Loss: 0.9743, Train Accuracy: 57.75%, Test Loss: 0.9524, Test Accuracy: 59.49%\n",
      "Epoch [457/2500], Train Loss: 0.9776, Train Accuracy: 57.33%, Test Loss: 0.9535, Test Accuracy: 59.49%\n",
      "Epoch [458/2500], Train Loss: 0.9823, Train Accuracy: 57.04%, Test Loss: 0.9518, Test Accuracy: 59.49%\n",
      "Epoch [459/2500], Train Loss: 0.9911, Train Accuracy: 58.18%, Test Loss: 0.9439, Test Accuracy: 59.49%\n",
      "Epoch [460/2500], Train Loss: 0.9813, Train Accuracy: 58.18%, Test Loss: 0.9457, Test Accuracy: 60.76%\n",
      "Epoch [461/2500], Train Loss: 0.9735, Train Accuracy: 57.47%, Test Loss: 0.9480, Test Accuracy: 59.49%\n",
      "Epoch [462/2500], Train Loss: 0.9714, Train Accuracy: 58.18%, Test Loss: 0.9566, Test Accuracy: 59.49%\n",
      "Epoch [463/2500], Train Loss: 0.9875, Train Accuracy: 58.46%, Test Loss: 0.9573, Test Accuracy: 60.76%\n",
      "Epoch [464/2500], Train Loss: 0.9761, Train Accuracy: 57.61%, Test Loss: 0.9567, Test Accuracy: 60.76%\n",
      "Epoch [465/2500], Train Loss: 0.9790, Train Accuracy: 58.61%, Test Loss: 0.9564, Test Accuracy: 60.76%\n",
      "Epoch [466/2500], Train Loss: 0.9740, Train Accuracy: 56.47%, Test Loss: 0.9569, Test Accuracy: 60.76%\n",
      "Epoch [467/2500], Train Loss: 0.9875, Train Accuracy: 58.04%, Test Loss: 0.9554, Test Accuracy: 60.76%\n",
      "Epoch [468/2500], Train Loss: 0.9745, Train Accuracy: 57.33%, Test Loss: 0.9343, Test Accuracy: 60.76%\n",
      "Epoch [469/2500], Train Loss: 0.9796, Train Accuracy: 58.18%, Test Loss: 0.9554, Test Accuracy: 60.76%\n",
      "Epoch [470/2500], Train Loss: 0.9785, Train Accuracy: 56.90%, Test Loss: 0.9505, Test Accuracy: 60.76%\n",
      "Epoch [471/2500], Train Loss: 0.9761, Train Accuracy: 57.75%, Test Loss: 0.9564, Test Accuracy: 60.76%\n",
      "Epoch [472/2500], Train Loss: 0.9792, Train Accuracy: 57.61%, Test Loss: 0.9545, Test Accuracy: 60.76%\n",
      "Epoch [473/2500], Train Loss: 0.9653, Train Accuracy: 57.47%, Test Loss: 0.9569, Test Accuracy: 60.76%\n",
      "Epoch [474/2500], Train Loss: 0.9809, Train Accuracy: 57.75%, Test Loss: 0.9513, Test Accuracy: 60.76%\n",
      "Epoch [475/2500], Train Loss: 0.9764, Train Accuracy: 57.33%, Test Loss: 0.9525, Test Accuracy: 59.49%\n",
      "Epoch [476/2500], Train Loss: 0.9643, Train Accuracy: 58.18%, Test Loss: 0.9518, Test Accuracy: 60.76%\n",
      "Epoch [477/2500], Train Loss: 0.9674, Train Accuracy: 57.18%, Test Loss: 0.9534, Test Accuracy: 60.76%\n",
      "Epoch [478/2500], Train Loss: 0.9819, Train Accuracy: 58.46%, Test Loss: 0.9536, Test Accuracy: 60.76%\n",
      "Epoch [479/2500], Train Loss: 0.9680, Train Accuracy: 59.17%, Test Loss: 0.9472, Test Accuracy: 60.76%\n",
      "Epoch [480/2500], Train Loss: 0.9738, Train Accuracy: 56.61%, Test Loss: 0.9492, Test Accuracy: 60.76%\n",
      "Epoch [481/2500], Train Loss: 0.9765, Train Accuracy: 56.90%, Test Loss: 0.9525, Test Accuracy: 60.76%\n",
      "Epoch [482/2500], Train Loss: 0.9746, Train Accuracy: 58.46%, Test Loss: 0.9478, Test Accuracy: 60.76%\n",
      "Epoch [483/2500], Train Loss: 0.9863, Train Accuracy: 58.04%, Test Loss: 0.9541, Test Accuracy: 60.76%\n",
      "Epoch [484/2500], Train Loss: 0.9783, Train Accuracy: 56.61%, Test Loss: 0.9573, Test Accuracy: 60.76%\n",
      "Epoch [485/2500], Train Loss: 0.9811, Train Accuracy: 56.76%, Test Loss: 0.9450, Test Accuracy: 60.76%\n",
      "Epoch [486/2500], Train Loss: 0.9723, Train Accuracy: 58.04%, Test Loss: 0.9454, Test Accuracy: 60.76%\n",
      "Epoch [487/2500], Train Loss: 0.9681, Train Accuracy: 57.18%, Test Loss: 0.9477, Test Accuracy: 60.76%\n",
      "Epoch [488/2500], Train Loss: 0.9651, Train Accuracy: 57.33%, Test Loss: 0.9434, Test Accuracy: 60.76%\n",
      "Epoch [489/2500], Train Loss: 0.9702, Train Accuracy: 56.76%, Test Loss: 0.9410, Test Accuracy: 60.76%\n",
      "Epoch [490/2500], Train Loss: 0.9839, Train Accuracy: 57.47%, Test Loss: 0.9423, Test Accuracy: 60.76%\n",
      "Epoch [491/2500], Train Loss: 0.9563, Train Accuracy: 58.46%, Test Loss: 0.9500, Test Accuracy: 60.76%\n",
      "Epoch [492/2500], Train Loss: 0.9677, Train Accuracy: 58.18%, Test Loss: 0.9499, Test Accuracy: 60.76%\n",
      "Epoch [493/2500], Train Loss: 0.9603, Train Accuracy: 57.89%, Test Loss: 0.9515, Test Accuracy: 60.76%\n",
      "Epoch [494/2500], Train Loss: 0.9731, Train Accuracy: 58.61%, Test Loss: 0.9545, Test Accuracy: 60.76%\n",
      "Epoch [495/2500], Train Loss: 0.9646, Train Accuracy: 58.04%, Test Loss: 0.9501, Test Accuracy: 60.76%\n",
      "Epoch [496/2500], Train Loss: 0.9734, Train Accuracy: 57.18%, Test Loss: 0.9544, Test Accuracy: 60.76%\n",
      "Epoch [497/2500], Train Loss: 0.9731, Train Accuracy: 57.04%, Test Loss: 0.9527, Test Accuracy: 60.76%\n",
      "Epoch [498/2500], Train Loss: 0.9694, Train Accuracy: 56.05%, Test Loss: 0.9376, Test Accuracy: 60.76%\n",
      "Epoch [499/2500], Train Loss: 0.9574, Train Accuracy: 58.61%, Test Loss: 0.9472, Test Accuracy: 59.49%\n",
      "Epoch [500/2500], Train Loss: 0.9835, Train Accuracy: 58.04%, Test Loss: 0.9499, Test Accuracy: 59.49%\n",
      "Epoch [501/2500], Train Loss: 0.9691, Train Accuracy: 57.04%, Test Loss: 0.9436, Test Accuracy: 60.76%\n",
      "Epoch [502/2500], Train Loss: 0.9910, Train Accuracy: 57.18%, Test Loss: 0.9380, Test Accuracy: 60.76%\n",
      "Epoch [503/2500], Train Loss: 0.9814, Train Accuracy: 58.04%, Test Loss: 0.9452, Test Accuracy: 60.76%\n",
      "Epoch [504/2500], Train Loss: 0.9732, Train Accuracy: 57.89%, Test Loss: 0.9474, Test Accuracy: 60.76%\n",
      "Epoch [505/2500], Train Loss: 0.9670, Train Accuracy: 57.75%, Test Loss: 0.9439, Test Accuracy: 60.76%\n",
      "Epoch [506/2500], Train Loss: 0.9710, Train Accuracy: 57.04%, Test Loss: 0.9434, Test Accuracy: 59.49%\n",
      "Epoch [507/2500], Train Loss: 0.9864, Train Accuracy: 58.46%, Test Loss: 0.9346, Test Accuracy: 60.76%\n",
      "Epoch [508/2500], Train Loss: 0.9784, Train Accuracy: 57.75%, Test Loss: 0.9356, Test Accuracy: 60.76%\n",
      "Epoch [509/2500], Train Loss: 0.9718, Train Accuracy: 58.18%, Test Loss: 0.9458, Test Accuracy: 59.49%\n",
      "Epoch [510/2500], Train Loss: 0.9873, Train Accuracy: 57.61%, Test Loss: 0.9438, Test Accuracy: 59.49%\n",
      "Epoch [511/2500], Train Loss: 0.9715, Train Accuracy: 58.18%, Test Loss: 0.9435, Test Accuracy: 60.76%\n",
      "Epoch [512/2500], Train Loss: 0.9538, Train Accuracy: 58.04%, Test Loss: 0.9362, Test Accuracy: 60.76%\n",
      "Epoch [513/2500], Train Loss: 0.9538, Train Accuracy: 59.89%, Test Loss: 0.9465, Test Accuracy: 59.49%\n",
      "Epoch [514/2500], Train Loss: 0.9607, Train Accuracy: 57.89%, Test Loss: 0.9407, Test Accuracy: 59.49%\n",
      "Epoch [515/2500], Train Loss: 0.9740, Train Accuracy: 57.18%, Test Loss: 0.9375, Test Accuracy: 59.49%\n",
      "Epoch [516/2500], Train Loss: 0.9748, Train Accuracy: 57.61%, Test Loss: 0.9402, Test Accuracy: 59.49%\n",
      "Epoch [517/2500], Train Loss: 0.9601, Train Accuracy: 57.89%, Test Loss: 0.9488, Test Accuracy: 60.76%\n",
      "Epoch [518/2500], Train Loss: 0.9655, Train Accuracy: 57.89%, Test Loss: 0.9541, Test Accuracy: 60.76%\n",
      "Epoch [519/2500], Train Loss: 0.9644, Train Accuracy: 57.47%, Test Loss: 0.9540, Test Accuracy: 60.76%\n",
      "Epoch [520/2500], Train Loss: 0.9739, Train Accuracy: 57.04%, Test Loss: 0.9592, Test Accuracy: 60.76%\n",
      "Epoch [521/2500], Train Loss: 0.9693, Train Accuracy: 58.04%, Test Loss: 0.9552, Test Accuracy: 60.76%\n",
      "Epoch [522/2500], Train Loss: 0.9545, Train Accuracy: 58.04%, Test Loss: 0.9429, Test Accuracy: 60.76%\n",
      "Epoch [523/2500], Train Loss: 0.9601, Train Accuracy: 57.75%, Test Loss: 0.9411, Test Accuracy: 59.49%\n",
      "Epoch [524/2500], Train Loss: 0.9735, Train Accuracy: 57.04%, Test Loss: 0.9362, Test Accuracy: 59.49%\n",
      "Epoch [525/2500], Train Loss: 0.9714, Train Accuracy: 58.46%, Test Loss: 0.9356, Test Accuracy: 59.49%\n",
      "Epoch [526/2500], Train Loss: 0.9487, Train Accuracy: 58.75%, Test Loss: 0.9365, Test Accuracy: 60.76%\n",
      "Epoch [527/2500], Train Loss: 0.9625, Train Accuracy: 58.04%, Test Loss: 0.9411, Test Accuracy: 60.76%\n",
      "Epoch [528/2500], Train Loss: 0.9765, Train Accuracy: 57.18%, Test Loss: 0.9405, Test Accuracy: 60.76%\n",
      "Epoch [529/2500], Train Loss: 0.9680, Train Accuracy: 59.46%, Test Loss: 0.9400, Test Accuracy: 60.76%\n",
      "Epoch [530/2500], Train Loss: 0.9742, Train Accuracy: 57.75%, Test Loss: 0.9427, Test Accuracy: 60.76%\n",
      "Epoch [531/2500], Train Loss: 0.9569, Train Accuracy: 58.32%, Test Loss: 0.9387, Test Accuracy: 60.76%\n",
      "Epoch [532/2500], Train Loss: 0.9439, Train Accuracy: 58.46%, Test Loss: 0.9451, Test Accuracy: 60.76%\n",
      "Epoch [533/2500], Train Loss: 0.9709, Train Accuracy: 58.61%, Test Loss: 0.9446, Test Accuracy: 59.49%\n",
      "Epoch [534/2500], Train Loss: 0.9793, Train Accuracy: 57.18%, Test Loss: 0.9389, Test Accuracy: 60.76%\n",
      "Epoch [535/2500], Train Loss: 0.9862, Train Accuracy: 57.89%, Test Loss: 0.9393, Test Accuracy: 60.76%\n",
      "Epoch [536/2500], Train Loss: 0.9642, Train Accuracy: 58.89%, Test Loss: 0.9391, Test Accuracy: 60.76%\n",
      "Epoch [537/2500], Train Loss: 0.9683, Train Accuracy: 57.75%, Test Loss: 0.9374, Test Accuracy: 60.76%\n",
      "Epoch [538/2500], Train Loss: 0.9692, Train Accuracy: 57.47%, Test Loss: 0.9384, Test Accuracy: 60.76%\n",
      "Epoch [539/2500], Train Loss: 0.9666, Train Accuracy: 58.32%, Test Loss: 0.9389, Test Accuracy: 60.76%\n",
      "Epoch [540/2500], Train Loss: 0.9638, Train Accuracy: 58.04%, Test Loss: 0.9379, Test Accuracy: 60.76%\n",
      "Epoch [541/2500], Train Loss: 0.9780, Train Accuracy: 57.18%, Test Loss: 0.9351, Test Accuracy: 60.76%\n",
      "Epoch [542/2500], Train Loss: 0.9647, Train Accuracy: 58.75%, Test Loss: 0.9391, Test Accuracy: 60.76%\n",
      "Epoch [543/2500], Train Loss: 0.9514, Train Accuracy: 57.61%, Test Loss: 0.9330, Test Accuracy: 60.76%\n",
      "Epoch [544/2500], Train Loss: 0.9722, Train Accuracy: 58.89%, Test Loss: 0.9284, Test Accuracy: 59.49%\n",
      "Epoch [545/2500], Train Loss: 0.9632, Train Accuracy: 58.32%, Test Loss: 0.9325, Test Accuracy: 60.76%\n",
      "Epoch [546/2500], Train Loss: 0.9632, Train Accuracy: 58.04%, Test Loss: 0.9354, Test Accuracy: 60.76%\n",
      "Epoch [547/2500], Train Loss: 0.9519, Train Accuracy: 59.46%, Test Loss: 0.9343, Test Accuracy: 60.76%\n",
      "Epoch [548/2500], Train Loss: 0.9712, Train Accuracy: 57.89%, Test Loss: 0.9382, Test Accuracy: 60.76%\n",
      "Epoch [549/2500], Train Loss: 0.9666, Train Accuracy: 57.33%, Test Loss: 0.9408, Test Accuracy: 59.49%\n",
      "Epoch [550/2500], Train Loss: 0.9706, Train Accuracy: 57.47%, Test Loss: 0.9373, Test Accuracy: 60.76%\n",
      "Epoch [551/2500], Train Loss: 0.9541, Train Accuracy: 57.61%, Test Loss: 0.9407, Test Accuracy: 60.76%\n",
      "Epoch [552/2500], Train Loss: 0.9611, Train Accuracy: 57.89%, Test Loss: 0.9343, Test Accuracy: 59.49%\n",
      "Epoch [553/2500], Train Loss: 0.9764, Train Accuracy: 56.61%, Test Loss: 0.9342, Test Accuracy: 59.49%\n",
      "Epoch [554/2500], Train Loss: 0.9738, Train Accuracy: 57.18%, Test Loss: 0.9327, Test Accuracy: 59.49%\n",
      "Epoch [555/2500], Train Loss: 0.9667, Train Accuracy: 58.04%, Test Loss: 0.9270, Test Accuracy: 59.49%\n",
      "Epoch [556/2500], Train Loss: 0.9556, Train Accuracy: 57.75%, Test Loss: 0.9335, Test Accuracy: 60.76%\n",
      "Epoch [557/2500], Train Loss: 0.9502, Train Accuracy: 58.61%, Test Loss: 0.9194, Test Accuracy: 60.76%\n",
      "Epoch [558/2500], Train Loss: 0.9781, Train Accuracy: 58.75%, Test Loss: 0.9180, Test Accuracy: 60.76%\n",
      "Epoch [559/2500], Train Loss: 0.9758, Train Accuracy: 57.04%, Test Loss: 0.9217, Test Accuracy: 60.76%\n",
      "Epoch [560/2500], Train Loss: 0.9610, Train Accuracy: 57.89%, Test Loss: 0.9253, Test Accuracy: 60.76%\n",
      "Epoch [561/2500], Train Loss: 0.9462, Train Accuracy: 58.32%, Test Loss: 0.9253, Test Accuracy: 60.76%\n",
      "Epoch [562/2500], Train Loss: 0.9443, Train Accuracy: 59.03%, Test Loss: 0.9245, Test Accuracy: 60.76%\n",
      "Epoch [563/2500], Train Loss: 0.9560, Train Accuracy: 57.33%, Test Loss: 0.9216, Test Accuracy: 60.76%\n",
      "Epoch [564/2500], Train Loss: 0.9706, Train Accuracy: 58.61%, Test Loss: 0.9305, Test Accuracy: 60.76%\n",
      "Epoch [565/2500], Train Loss: 0.9620, Train Accuracy: 56.47%, Test Loss: 0.9314, Test Accuracy: 60.76%\n",
      "Epoch [566/2500], Train Loss: 0.9722, Train Accuracy: 57.33%, Test Loss: 0.9353, Test Accuracy: 60.76%\n",
      "Epoch [567/2500], Train Loss: 0.9701, Train Accuracy: 57.75%, Test Loss: 0.9414, Test Accuracy: 60.76%\n",
      "Epoch [568/2500], Train Loss: 0.9718, Train Accuracy: 57.61%, Test Loss: 0.9389, Test Accuracy: 60.76%\n",
      "Epoch [569/2500], Train Loss: 0.9559, Train Accuracy: 56.76%, Test Loss: 0.9337, Test Accuracy: 60.76%\n",
      "Epoch [570/2500], Train Loss: 0.9642, Train Accuracy: 57.47%, Test Loss: 0.9402, Test Accuracy: 60.76%\n",
      "Epoch [571/2500], Train Loss: 0.9626, Train Accuracy: 58.32%, Test Loss: 0.9454, Test Accuracy: 60.76%\n",
      "Epoch [572/2500], Train Loss: 0.9704, Train Accuracy: 58.61%, Test Loss: 0.9371, Test Accuracy: 60.76%\n",
      "Epoch [573/2500], Train Loss: 0.9715, Train Accuracy: 57.61%, Test Loss: 0.9388, Test Accuracy: 60.76%\n",
      "Epoch [574/2500], Train Loss: 0.9613, Train Accuracy: 58.18%, Test Loss: 0.9240, Test Accuracy: 60.76%\n",
      "Epoch [575/2500], Train Loss: 0.9591, Train Accuracy: 58.46%, Test Loss: 0.9256, Test Accuracy: 60.76%\n",
      "Epoch [576/2500], Train Loss: 0.9431, Train Accuracy: 57.89%, Test Loss: 0.9313, Test Accuracy: 59.49%\n",
      "Epoch [577/2500], Train Loss: 0.9551, Train Accuracy: 57.04%, Test Loss: 0.9324, Test Accuracy: 59.49%\n",
      "Epoch [578/2500], Train Loss: 0.9688, Train Accuracy: 58.32%, Test Loss: 0.9297, Test Accuracy: 59.49%\n",
      "Epoch [579/2500], Train Loss: 0.9637, Train Accuracy: 58.89%, Test Loss: 0.9220, Test Accuracy: 58.23%\n",
      "Epoch [580/2500], Train Loss: 0.9579, Train Accuracy: 59.32%, Test Loss: 0.9153, Test Accuracy: 58.23%\n",
      "Epoch [581/2500], Train Loss: 0.9629, Train Accuracy: 57.47%, Test Loss: 0.9216, Test Accuracy: 59.49%\n",
      "Epoch [582/2500], Train Loss: 0.9405, Train Accuracy: 59.46%, Test Loss: 0.9223, Test Accuracy: 58.23%\n",
      "Epoch [583/2500], Train Loss: 0.9608, Train Accuracy: 58.18%, Test Loss: 0.9311, Test Accuracy: 58.23%\n",
      "Epoch [584/2500], Train Loss: 0.9594, Train Accuracy: 57.89%, Test Loss: 0.9222, Test Accuracy: 58.23%\n",
      "Epoch [585/2500], Train Loss: 0.9720, Train Accuracy: 58.46%, Test Loss: 0.9243, Test Accuracy: 60.76%\n",
      "Epoch [586/2500], Train Loss: 0.9695, Train Accuracy: 58.89%, Test Loss: 0.9201, Test Accuracy: 60.76%\n",
      "Epoch [587/2500], Train Loss: 0.9518, Train Accuracy: 57.75%, Test Loss: 0.9215, Test Accuracy: 58.23%\n",
      "Epoch [588/2500], Train Loss: 0.9652, Train Accuracy: 59.60%, Test Loss: 0.9130, Test Accuracy: 59.49%\n",
      "Epoch [589/2500], Train Loss: 0.9504, Train Accuracy: 59.03%, Test Loss: 0.9182, Test Accuracy: 60.76%\n",
      "Epoch [590/2500], Train Loss: 0.9544, Train Accuracy: 58.18%, Test Loss: 0.9144, Test Accuracy: 60.76%\n",
      "Epoch [591/2500], Train Loss: 0.9448, Train Accuracy: 58.61%, Test Loss: 0.9184, Test Accuracy: 60.76%\n",
      "Epoch [592/2500], Train Loss: 0.9649, Train Accuracy: 57.75%, Test Loss: 0.9189, Test Accuracy: 60.76%\n",
      "Epoch [593/2500], Train Loss: 0.9728, Train Accuracy: 57.75%, Test Loss: 0.9164, Test Accuracy: 60.76%\n",
      "Epoch [594/2500], Train Loss: 0.9588, Train Accuracy: 58.18%, Test Loss: 0.9274, Test Accuracy: 60.76%\n",
      "Epoch [595/2500], Train Loss: 0.9395, Train Accuracy: 59.03%, Test Loss: 0.9258, Test Accuracy: 60.76%\n",
      "Epoch [596/2500], Train Loss: 0.9467, Train Accuracy: 58.61%, Test Loss: 0.9318, Test Accuracy: 60.76%\n",
      "Epoch [597/2500], Train Loss: 0.9583, Train Accuracy: 58.89%, Test Loss: 0.9291, Test Accuracy: 60.76%\n",
      "Epoch [598/2500], Train Loss: 0.9601, Train Accuracy: 58.32%, Test Loss: 0.9380, Test Accuracy: 60.76%\n",
      "Epoch [599/2500], Train Loss: 0.9656, Train Accuracy: 58.89%, Test Loss: 0.9259, Test Accuracy: 59.49%\n",
      "Epoch [600/2500], Train Loss: 0.9454, Train Accuracy: 57.75%, Test Loss: 0.9396, Test Accuracy: 59.49%\n",
      "Epoch [601/2500], Train Loss: 0.9761, Train Accuracy: 58.89%, Test Loss: 0.9303, Test Accuracy: 59.49%\n",
      "Epoch [602/2500], Train Loss: 0.9659, Train Accuracy: 57.75%, Test Loss: 0.9340, Test Accuracy: 59.49%\n",
      "Epoch [603/2500], Train Loss: 0.9590, Train Accuracy: 59.03%, Test Loss: 0.9377, Test Accuracy: 59.49%\n",
      "Epoch [604/2500], Train Loss: 0.9492, Train Accuracy: 58.18%, Test Loss: 0.9310, Test Accuracy: 59.49%\n",
      "Epoch [605/2500], Train Loss: 0.9757, Train Accuracy: 58.32%, Test Loss: 0.9272, Test Accuracy: 60.76%\n",
      "Epoch [606/2500], Train Loss: 0.9593, Train Accuracy: 59.32%, Test Loss: 0.9290, Test Accuracy: 60.76%\n",
      "Epoch [607/2500], Train Loss: 0.9504, Train Accuracy: 58.46%, Test Loss: 0.9202, Test Accuracy: 60.76%\n",
      "Epoch [608/2500], Train Loss: 0.9519, Train Accuracy: 58.61%, Test Loss: 0.9265, Test Accuracy: 59.49%\n",
      "Epoch [609/2500], Train Loss: 0.9610, Train Accuracy: 58.18%, Test Loss: 0.9276, Test Accuracy: 59.49%\n",
      "Epoch [610/2500], Train Loss: 0.9232, Train Accuracy: 59.03%, Test Loss: 0.9302, Test Accuracy: 60.76%\n",
      "Epoch [611/2500], Train Loss: 0.9519, Train Accuracy: 58.61%, Test Loss: 0.9196, Test Accuracy: 59.49%\n",
      "Epoch [612/2500], Train Loss: 0.9539, Train Accuracy: 58.46%, Test Loss: 0.9241, Test Accuracy: 60.76%\n",
      "Epoch [613/2500], Train Loss: 0.9594, Train Accuracy: 57.89%, Test Loss: 0.9300, Test Accuracy: 60.76%\n",
      "Epoch [614/2500], Train Loss: 0.9454, Train Accuracy: 59.32%, Test Loss: 0.9276, Test Accuracy: 60.76%\n",
      "Epoch [615/2500], Train Loss: 0.9544, Train Accuracy: 58.32%, Test Loss: 0.9252, Test Accuracy: 59.49%\n",
      "Epoch [616/2500], Train Loss: 0.9590, Train Accuracy: 58.18%, Test Loss: 0.9234, Test Accuracy: 59.49%\n",
      "Epoch [617/2500], Train Loss: 0.9588, Train Accuracy: 58.46%, Test Loss: 0.9223, Test Accuracy: 60.76%\n",
      "Epoch [618/2500], Train Loss: 0.9611, Train Accuracy: 57.61%, Test Loss: 0.9210, Test Accuracy: 60.76%\n",
      "Epoch [619/2500], Train Loss: 0.9575, Train Accuracy: 57.75%, Test Loss: 0.9264, Test Accuracy: 58.23%\n",
      "Epoch [620/2500], Train Loss: 0.9481, Train Accuracy: 58.46%, Test Loss: 0.9267, Test Accuracy: 59.49%\n",
      "Epoch [621/2500], Train Loss: 0.9612, Train Accuracy: 57.89%, Test Loss: 0.9305, Test Accuracy: 59.49%\n",
      "Epoch [622/2500], Train Loss: 0.9657, Train Accuracy: 57.89%, Test Loss: 0.9224, Test Accuracy: 59.49%\n",
      "Epoch [623/2500], Train Loss: 0.9633, Train Accuracy: 58.46%, Test Loss: 0.9221, Test Accuracy: 58.23%\n",
      "Epoch [624/2500], Train Loss: 0.9501, Train Accuracy: 58.04%, Test Loss: 0.9223, Test Accuracy: 59.49%\n",
      "Epoch [625/2500], Train Loss: 0.9619, Train Accuracy: 58.04%, Test Loss: 0.9275, Test Accuracy: 58.23%\n",
      "Epoch [626/2500], Train Loss: 0.9589, Train Accuracy: 58.61%, Test Loss: 0.9263, Test Accuracy: 59.49%\n",
      "Epoch [627/2500], Train Loss: 0.9635, Train Accuracy: 57.89%, Test Loss: 0.9273, Test Accuracy: 59.49%\n",
      "Epoch [628/2500], Train Loss: 0.9774, Train Accuracy: 58.32%, Test Loss: 0.9289, Test Accuracy: 60.76%\n",
      "Epoch [629/2500], Train Loss: 0.9441, Train Accuracy: 59.17%, Test Loss: 0.9120, Test Accuracy: 58.23%\n",
      "Epoch [630/2500], Train Loss: 0.9473, Train Accuracy: 58.89%, Test Loss: 0.9266, Test Accuracy: 58.23%\n",
      "Epoch [631/2500], Train Loss: 0.9564, Train Accuracy: 58.32%, Test Loss: 0.9338, Test Accuracy: 59.49%\n",
      "Epoch [632/2500], Train Loss: 0.9434, Train Accuracy: 59.46%, Test Loss: 0.9273, Test Accuracy: 59.49%\n",
      "Epoch [633/2500], Train Loss: 0.9529, Train Accuracy: 58.04%, Test Loss: 0.9246, Test Accuracy: 58.23%\n",
      "Epoch [634/2500], Train Loss: 0.9672, Train Accuracy: 58.46%, Test Loss: 0.9276, Test Accuracy: 59.49%\n",
      "Epoch [635/2500], Train Loss: 0.9544, Train Accuracy: 58.75%, Test Loss: 0.9329, Test Accuracy: 60.76%\n",
      "Epoch [636/2500], Train Loss: 0.9532, Train Accuracy: 58.61%, Test Loss: 0.9352, Test Accuracy: 59.49%\n",
      "Epoch [637/2500], Train Loss: 0.9545, Train Accuracy: 57.75%, Test Loss: 0.9345, Test Accuracy: 60.76%\n",
      "Epoch [638/2500], Train Loss: 0.9413, Train Accuracy: 58.46%, Test Loss: 0.9332, Test Accuracy: 60.76%\n",
      "Epoch [639/2500], Train Loss: 0.9504, Train Accuracy: 59.32%, Test Loss: 0.9307, Test Accuracy: 60.76%\n",
      "Epoch [640/2500], Train Loss: 0.9466, Train Accuracy: 59.03%, Test Loss: 0.9279, Test Accuracy: 59.49%\n",
      "Epoch [641/2500], Train Loss: 0.9431, Train Accuracy: 58.89%, Test Loss: 0.9420, Test Accuracy: 62.03%\n",
      "Epoch [642/2500], Train Loss: 0.9642, Train Accuracy: 58.04%, Test Loss: 0.9329, Test Accuracy: 60.76%\n",
      "Epoch [643/2500], Train Loss: 0.9533, Train Accuracy: 58.18%, Test Loss: 0.9236, Test Accuracy: 60.76%\n",
      "Epoch [644/2500], Train Loss: 0.9550, Train Accuracy: 57.33%, Test Loss: 0.9219, Test Accuracy: 62.03%\n",
      "Epoch [645/2500], Train Loss: 0.9630, Train Accuracy: 57.75%, Test Loss: 0.9364, Test Accuracy: 62.03%\n",
      "Epoch [646/2500], Train Loss: 0.9546, Train Accuracy: 59.03%, Test Loss: 0.9370, Test Accuracy: 60.76%\n",
      "Epoch [647/2500], Train Loss: 0.9556, Train Accuracy: 56.47%, Test Loss: 0.9330, Test Accuracy: 59.49%\n",
      "Epoch [648/2500], Train Loss: 0.9659, Train Accuracy: 58.18%, Test Loss: 0.9267, Test Accuracy: 60.76%\n",
      "Epoch [649/2500], Train Loss: 0.9420, Train Accuracy: 58.61%, Test Loss: 0.9284, Test Accuracy: 60.76%\n",
      "Epoch [650/2500], Train Loss: 0.9365, Train Accuracy: 58.04%, Test Loss: 0.9327, Test Accuracy: 58.23%\n",
      "Epoch [651/2500], Train Loss: 0.9573, Train Accuracy: 57.75%, Test Loss: 0.9367, Test Accuracy: 59.49%\n",
      "Epoch [652/2500], Train Loss: 0.9676, Train Accuracy: 58.18%, Test Loss: 0.9219, Test Accuracy: 58.23%\n",
      "Epoch [653/2500], Train Loss: 0.9424, Train Accuracy: 56.90%, Test Loss: 0.9226, Test Accuracy: 58.23%\n",
      "Epoch [654/2500], Train Loss: 0.9424, Train Accuracy: 58.61%, Test Loss: 0.9335, Test Accuracy: 58.23%\n",
      "Epoch [655/2500], Train Loss: 0.9584, Train Accuracy: 57.89%, Test Loss: 0.9357, Test Accuracy: 58.23%\n",
      "Epoch [656/2500], Train Loss: 0.9593, Train Accuracy: 59.46%, Test Loss: 0.9346, Test Accuracy: 59.49%\n",
      "Epoch [657/2500], Train Loss: 0.9352, Train Accuracy: 59.46%, Test Loss: 0.9372, Test Accuracy: 58.23%\n",
      "Epoch [658/2500], Train Loss: 0.9553, Train Accuracy: 57.89%, Test Loss: 0.9359, Test Accuracy: 62.03%\n",
      "Epoch [659/2500], Train Loss: 0.9321, Train Accuracy: 58.89%, Test Loss: 0.9410, Test Accuracy: 62.03%\n",
      "Epoch [660/2500], Train Loss: 0.9299, Train Accuracy: 59.89%, Test Loss: 0.9298, Test Accuracy: 59.49%\n",
      "Epoch [661/2500], Train Loss: 0.9507, Train Accuracy: 58.75%, Test Loss: 0.9412, Test Accuracy: 60.76%\n",
      "Epoch [662/2500], Train Loss: 0.9614, Train Accuracy: 57.89%, Test Loss: 0.9392, Test Accuracy: 59.49%\n",
      "Epoch [663/2500], Train Loss: 0.9249, Train Accuracy: 59.32%, Test Loss: 0.9361, Test Accuracy: 59.49%\n",
      "Epoch [664/2500], Train Loss: 0.9527, Train Accuracy: 58.04%, Test Loss: 0.9377, Test Accuracy: 59.49%\n",
      "Epoch [665/2500], Train Loss: 0.9417, Train Accuracy: 58.89%, Test Loss: 0.9345, Test Accuracy: 59.49%\n",
      "Epoch [666/2500], Train Loss: 0.9578, Train Accuracy: 57.89%, Test Loss: 0.9308, Test Accuracy: 58.23%\n",
      "Epoch [667/2500], Train Loss: 0.9440, Train Accuracy: 59.17%, Test Loss: 0.9336, Test Accuracy: 58.23%\n",
      "Epoch [668/2500], Train Loss: 0.9447, Train Accuracy: 58.89%, Test Loss: 0.9325, Test Accuracy: 60.76%\n",
      "Epoch [669/2500], Train Loss: 0.9433, Train Accuracy: 59.32%, Test Loss: 0.9291, Test Accuracy: 58.23%\n",
      "Epoch [670/2500], Train Loss: 0.9437, Train Accuracy: 58.04%, Test Loss: 0.9311, Test Accuracy: 58.23%\n",
      "Epoch [671/2500], Train Loss: 0.9507, Train Accuracy: 58.46%, Test Loss: 0.9283, Test Accuracy: 59.49%\n",
      "Epoch [672/2500], Train Loss: 0.9661, Train Accuracy: 57.75%, Test Loss: 0.9241, Test Accuracy: 59.49%\n",
      "Epoch [673/2500], Train Loss: 0.9470, Train Accuracy: 57.89%, Test Loss: 0.9144, Test Accuracy: 59.49%\n",
      "Epoch [674/2500], Train Loss: 0.9336, Train Accuracy: 58.18%, Test Loss: 0.9193, Test Accuracy: 59.49%\n",
      "Epoch [675/2500], Train Loss: 0.9468, Train Accuracy: 57.18%, Test Loss: 0.9296, Test Accuracy: 58.23%\n",
      "Epoch [676/2500], Train Loss: 0.9486, Train Accuracy: 57.61%, Test Loss: 0.9178, Test Accuracy: 60.76%\n",
      "Epoch [677/2500], Train Loss: 0.9593, Train Accuracy: 58.04%, Test Loss: 0.9204, Test Accuracy: 58.23%\n",
      "Epoch [678/2500], Train Loss: 0.9458, Train Accuracy: 57.18%, Test Loss: 0.9346, Test Accuracy: 58.23%\n",
      "Epoch [679/2500], Train Loss: 0.9662, Train Accuracy: 57.89%, Test Loss: 0.9326, Test Accuracy: 58.23%\n",
      "Epoch [680/2500], Train Loss: 0.9516, Train Accuracy: 58.61%, Test Loss: 0.9308, Test Accuracy: 60.76%\n",
      "Epoch [681/2500], Train Loss: 0.9643, Train Accuracy: 57.47%, Test Loss: 0.9278, Test Accuracy: 60.76%\n",
      "Epoch [682/2500], Train Loss: 0.9414, Train Accuracy: 58.18%, Test Loss: 0.9318, Test Accuracy: 60.76%\n",
      "Epoch [683/2500], Train Loss: 0.9398, Train Accuracy: 58.32%, Test Loss: 0.9300, Test Accuracy: 60.76%\n",
      "Epoch [684/2500], Train Loss: 0.9495, Train Accuracy: 57.75%, Test Loss: 0.9315, Test Accuracy: 60.76%\n",
      "Epoch [685/2500], Train Loss: 0.9442, Train Accuracy: 58.04%, Test Loss: 0.9316, Test Accuracy: 60.76%\n",
      "Epoch [686/2500], Train Loss: 0.9435, Train Accuracy: 59.32%, Test Loss: 0.9303, Test Accuracy: 60.76%\n",
      "Epoch [687/2500], Train Loss: 0.9502, Train Accuracy: 59.03%, Test Loss: 0.9201, Test Accuracy: 60.76%\n",
      "Epoch [688/2500], Train Loss: 0.9638, Train Accuracy: 57.89%, Test Loss: 0.9262, Test Accuracy: 59.49%\n",
      "Epoch [689/2500], Train Loss: 0.9344, Train Accuracy: 59.03%, Test Loss: 0.9283, Test Accuracy: 59.49%\n",
      "Epoch [690/2500], Train Loss: 0.9566, Train Accuracy: 58.61%, Test Loss: 0.9302, Test Accuracy: 60.76%\n",
      "Epoch [691/2500], Train Loss: 0.9380, Train Accuracy: 58.04%, Test Loss: 0.9448, Test Accuracy: 59.49%\n",
      "Epoch [692/2500], Train Loss: 0.9623, Train Accuracy: 57.61%, Test Loss: 0.9288, Test Accuracy: 59.49%\n",
      "Epoch [693/2500], Train Loss: 0.9312, Train Accuracy: 59.60%, Test Loss: 0.9277, Test Accuracy: 59.49%\n",
      "Epoch [694/2500], Train Loss: 0.9378, Train Accuracy: 58.04%, Test Loss: 0.9296, Test Accuracy: 59.49%\n",
      "Epoch [695/2500], Train Loss: 0.9367, Train Accuracy: 57.89%, Test Loss: 0.9279, Test Accuracy: 59.49%\n",
      "Epoch [696/2500], Train Loss: 0.9515, Train Accuracy: 58.89%, Test Loss: 0.9346, Test Accuracy: 59.49%\n",
      "Epoch [697/2500], Train Loss: 0.9455, Train Accuracy: 59.46%, Test Loss: 0.9342, Test Accuracy: 59.49%\n",
      "Epoch [698/2500], Train Loss: 0.9404, Train Accuracy: 58.61%, Test Loss: 0.9293, Test Accuracy: 59.49%\n",
      "Epoch [699/2500], Train Loss: 0.9430, Train Accuracy: 57.89%, Test Loss: 0.9271, Test Accuracy: 59.49%\n",
      "Epoch [700/2500], Train Loss: 0.9427, Train Accuracy: 58.18%, Test Loss: 0.9323, Test Accuracy: 59.49%\n",
      "Epoch [701/2500], Train Loss: 0.9470, Train Accuracy: 58.75%, Test Loss: 0.9304, Test Accuracy: 59.49%\n",
      "Epoch [702/2500], Train Loss: 0.9513, Train Accuracy: 59.03%, Test Loss: 0.9312, Test Accuracy: 59.49%\n",
      "Epoch [703/2500], Train Loss: 0.9635, Train Accuracy: 59.60%, Test Loss: 0.9249, Test Accuracy: 59.49%\n",
      "Epoch [704/2500], Train Loss: 0.9410, Train Accuracy: 58.32%, Test Loss: 0.9132, Test Accuracy: 59.49%\n",
      "Epoch [705/2500], Train Loss: 0.9508, Train Accuracy: 58.61%, Test Loss: 0.9211, Test Accuracy: 59.49%\n",
      "Epoch [706/2500], Train Loss: 0.9264, Train Accuracy: 58.61%, Test Loss: 0.9189, Test Accuracy: 59.49%\n",
      "Epoch [707/2500], Train Loss: 0.9575, Train Accuracy: 58.18%, Test Loss: 0.9279, Test Accuracy: 59.49%\n",
      "Epoch [708/2500], Train Loss: 0.9388, Train Accuracy: 59.74%, Test Loss: 0.9274, Test Accuracy: 59.49%\n",
      "Epoch [709/2500], Train Loss: 0.9537, Train Accuracy: 57.47%, Test Loss: 0.9407, Test Accuracy: 59.49%\n",
      "Epoch [710/2500], Train Loss: 0.9512, Train Accuracy: 58.46%, Test Loss: 0.9202, Test Accuracy: 59.49%\n",
      "Epoch [711/2500], Train Loss: 0.9421, Train Accuracy: 58.89%, Test Loss: 0.9168, Test Accuracy: 59.49%\n",
      "Epoch [712/2500], Train Loss: 0.9476, Train Accuracy: 59.32%, Test Loss: 0.9207, Test Accuracy: 59.49%\n",
      "Epoch [713/2500], Train Loss: 0.9416, Train Accuracy: 58.61%, Test Loss: 0.9184, Test Accuracy: 59.49%\n",
      "Epoch [714/2500], Train Loss: 0.9498, Train Accuracy: 58.61%, Test Loss: 0.9149, Test Accuracy: 59.49%\n",
      "Epoch [715/2500], Train Loss: 0.9445, Train Accuracy: 58.75%, Test Loss: 0.9170, Test Accuracy: 60.76%\n",
      "Epoch [716/2500], Train Loss: 0.9362, Train Accuracy: 57.75%, Test Loss: 0.9171, Test Accuracy: 58.23%\n",
      "Epoch [717/2500], Train Loss: 0.9491, Train Accuracy: 57.89%, Test Loss: 0.9226, Test Accuracy: 59.49%\n",
      "Epoch [718/2500], Train Loss: 0.9539, Train Accuracy: 58.46%, Test Loss: 0.9197, Test Accuracy: 59.49%\n",
      "Epoch [719/2500], Train Loss: 0.9444, Train Accuracy: 58.18%, Test Loss: 0.9200, Test Accuracy: 59.49%\n",
      "Epoch [720/2500], Train Loss: 0.9480, Train Accuracy: 57.89%, Test Loss: 0.9212, Test Accuracy: 59.49%\n",
      "Epoch [721/2500], Train Loss: 0.9486, Train Accuracy: 58.61%, Test Loss: 0.9256, Test Accuracy: 59.49%\n",
      "Epoch [722/2500], Train Loss: 0.9445, Train Accuracy: 58.75%, Test Loss: 0.9179, Test Accuracy: 59.49%\n",
      "Epoch [723/2500], Train Loss: 0.9545, Train Accuracy: 57.89%, Test Loss: 0.9211, Test Accuracy: 62.03%\n",
      "Epoch [724/2500], Train Loss: 0.9374, Train Accuracy: 58.75%, Test Loss: 0.9178, Test Accuracy: 60.76%\n",
      "Epoch [725/2500], Train Loss: 0.9382, Train Accuracy: 58.18%, Test Loss: 0.9191, Test Accuracy: 62.03%\n",
      "Epoch [726/2500], Train Loss: 0.9353, Train Accuracy: 58.61%, Test Loss: 0.9200, Test Accuracy: 59.49%\n",
      "Epoch [727/2500], Train Loss: 0.9447, Train Accuracy: 59.03%, Test Loss: 0.9267, Test Accuracy: 59.49%\n",
      "Epoch [728/2500], Train Loss: 0.9564, Train Accuracy: 58.75%, Test Loss: 0.9243, Test Accuracy: 60.76%\n",
      "Epoch [729/2500], Train Loss: 0.9247, Train Accuracy: 59.03%, Test Loss: 0.9168, Test Accuracy: 60.76%\n",
      "Epoch [730/2500], Train Loss: 0.9483, Train Accuracy: 59.32%, Test Loss: 0.9172, Test Accuracy: 60.76%\n",
      "Epoch [731/2500], Train Loss: 0.9488, Train Accuracy: 59.32%, Test Loss: 0.9122, Test Accuracy: 62.03%\n",
      "Epoch [732/2500], Train Loss: 0.9567, Train Accuracy: 58.46%, Test Loss: 0.9257, Test Accuracy: 60.76%\n",
      "Epoch [733/2500], Train Loss: 0.9416, Train Accuracy: 58.75%, Test Loss: 0.9084, Test Accuracy: 59.49%\n",
      "Epoch [734/2500], Train Loss: 0.9437, Train Accuracy: 57.61%, Test Loss: 0.9172, Test Accuracy: 60.76%\n",
      "Epoch [735/2500], Train Loss: 0.9257, Train Accuracy: 60.17%, Test Loss: 0.9225, Test Accuracy: 60.76%\n",
      "Epoch [736/2500], Train Loss: 0.9417, Train Accuracy: 59.17%, Test Loss: 0.9215, Test Accuracy: 60.76%\n",
      "Epoch [737/2500], Train Loss: 0.9356, Train Accuracy: 58.89%, Test Loss: 0.9405, Test Accuracy: 62.03%\n",
      "Epoch [738/2500], Train Loss: 0.9449, Train Accuracy: 58.04%, Test Loss: 0.9340, Test Accuracy: 60.76%\n",
      "Epoch [739/2500], Train Loss: 0.9457, Train Accuracy: 59.46%, Test Loss: 0.9109, Test Accuracy: 60.76%\n",
      "Epoch [740/2500], Train Loss: 0.9488, Train Accuracy: 57.75%, Test Loss: 0.9197, Test Accuracy: 60.76%\n",
      "Epoch [741/2500], Train Loss: 0.9559, Train Accuracy: 58.46%, Test Loss: 0.9204, Test Accuracy: 62.03%\n",
      "Epoch [742/2500], Train Loss: 0.9275, Train Accuracy: 58.89%, Test Loss: 0.9157, Test Accuracy: 60.76%\n",
      "Epoch [743/2500], Train Loss: 0.9316, Train Accuracy: 59.60%, Test Loss: 0.9218, Test Accuracy: 60.76%\n",
      "Epoch [744/2500], Train Loss: 0.9462, Train Accuracy: 58.04%, Test Loss: 0.9159, Test Accuracy: 62.03%\n",
      "Epoch [745/2500], Train Loss: 0.9192, Train Accuracy: 58.89%, Test Loss: 0.9219, Test Accuracy: 64.56%\n",
      "Epoch [746/2500], Train Loss: 0.9335, Train Accuracy: 59.03%, Test Loss: 0.9094, Test Accuracy: 62.03%\n",
      "Epoch [747/2500], Train Loss: 0.9465, Train Accuracy: 58.75%, Test Loss: 0.9153, Test Accuracy: 63.29%\n",
      "Epoch [748/2500], Train Loss: 0.9535, Train Accuracy: 58.32%, Test Loss: 0.9260, Test Accuracy: 59.49%\n",
      "Epoch [749/2500], Train Loss: 0.9538, Train Accuracy: 58.32%, Test Loss: 0.9212, Test Accuracy: 59.49%\n",
      "Epoch [750/2500], Train Loss: 0.9421, Train Accuracy: 59.17%, Test Loss: 0.9168, Test Accuracy: 60.76%\n",
      "Epoch [751/2500], Train Loss: 0.9356, Train Accuracy: 59.32%, Test Loss: 0.9159, Test Accuracy: 59.49%\n",
      "Epoch [752/2500], Train Loss: 0.9235, Train Accuracy: 59.32%, Test Loss: 0.9202, Test Accuracy: 59.49%\n",
      "Epoch [753/2500], Train Loss: 0.9375, Train Accuracy: 58.75%, Test Loss: 0.9227, Test Accuracy: 58.23%\n",
      "Epoch [754/2500], Train Loss: 0.9451, Train Accuracy: 58.61%, Test Loss: 0.9186, Test Accuracy: 59.49%\n",
      "Epoch [755/2500], Train Loss: 0.9595, Train Accuracy: 57.75%, Test Loss: 0.9303, Test Accuracy: 58.23%\n",
      "Epoch [756/2500], Train Loss: 0.9503, Train Accuracy: 58.89%, Test Loss: 0.9229, Test Accuracy: 59.49%\n",
      "Epoch [757/2500], Train Loss: 0.9529, Train Accuracy: 59.32%, Test Loss: 0.9239, Test Accuracy: 59.49%\n",
      "Epoch [758/2500], Train Loss: 0.9325, Train Accuracy: 60.03%, Test Loss: 0.9217, Test Accuracy: 59.49%\n",
      "Epoch [759/2500], Train Loss: 0.9384, Train Accuracy: 58.04%, Test Loss: 0.9201, Test Accuracy: 62.03%\n",
      "Epoch [760/2500], Train Loss: 0.9364, Train Accuracy: 59.74%, Test Loss: 0.9208, Test Accuracy: 63.29%\n",
      "Epoch [761/2500], Train Loss: 0.9387, Train Accuracy: 59.32%, Test Loss: 0.9311, Test Accuracy: 63.29%\n",
      "Epoch [762/2500], Train Loss: 0.9437, Train Accuracy: 58.89%, Test Loss: 0.9154, Test Accuracy: 60.76%\n",
      "Epoch [763/2500], Train Loss: 0.9419, Train Accuracy: 58.46%, Test Loss: 0.9179, Test Accuracy: 59.49%\n",
      "Epoch [764/2500], Train Loss: 0.9380, Train Accuracy: 58.18%, Test Loss: 0.9149, Test Accuracy: 60.76%\n",
      "Epoch [765/2500], Train Loss: 0.9503, Train Accuracy: 57.75%, Test Loss: 0.9160, Test Accuracy: 60.76%\n",
      "Epoch [766/2500], Train Loss: 0.9270, Train Accuracy: 58.89%, Test Loss: 0.9155, Test Accuracy: 62.03%\n",
      "Epoch [767/2500], Train Loss: 0.9345, Train Accuracy: 60.03%, Test Loss: 0.9076, Test Accuracy: 60.76%\n",
      "Epoch [768/2500], Train Loss: 0.9416, Train Accuracy: 58.75%, Test Loss: 0.9092, Test Accuracy: 60.76%\n",
      "Epoch [769/2500], Train Loss: 0.9424, Train Accuracy: 58.04%, Test Loss: 0.9157, Test Accuracy: 58.23%\n",
      "Epoch [770/2500], Train Loss: 0.9298, Train Accuracy: 59.32%, Test Loss: 0.9111, Test Accuracy: 59.49%\n",
      "Epoch [771/2500], Train Loss: 0.9594, Train Accuracy: 58.89%, Test Loss: 0.9123, Test Accuracy: 60.76%\n",
      "Epoch [772/2500], Train Loss: 0.9440, Train Accuracy: 58.75%, Test Loss: 0.9202, Test Accuracy: 60.76%\n",
      "Epoch [773/2500], Train Loss: 0.9481, Train Accuracy: 58.04%, Test Loss: 0.9139, Test Accuracy: 60.76%\n",
      "Epoch [774/2500], Train Loss: 0.9365, Train Accuracy: 59.60%, Test Loss: 0.9138, Test Accuracy: 60.76%\n",
      "Epoch [775/2500], Train Loss: 0.9293, Train Accuracy: 59.46%, Test Loss: 0.9069, Test Accuracy: 60.76%\n",
      "Epoch [776/2500], Train Loss: 0.9252, Train Accuracy: 59.89%, Test Loss: 0.9069, Test Accuracy: 60.76%\n",
      "Epoch [777/2500], Train Loss: 0.9359, Train Accuracy: 57.75%, Test Loss: 0.9076, Test Accuracy: 60.76%\n",
      "Epoch [778/2500], Train Loss: 0.9468, Train Accuracy: 58.32%, Test Loss: 0.9137, Test Accuracy: 63.29%\n",
      "Epoch [779/2500], Train Loss: 0.9439, Train Accuracy: 59.89%, Test Loss: 0.9071, Test Accuracy: 60.76%\n",
      "Epoch [780/2500], Train Loss: 0.9346, Train Accuracy: 58.18%, Test Loss: 0.9169, Test Accuracy: 64.56%\n",
      "Epoch [781/2500], Train Loss: 0.9547, Train Accuracy: 58.46%, Test Loss: 0.9180, Test Accuracy: 64.56%\n",
      "Epoch [782/2500], Train Loss: 0.9497, Train Accuracy: 58.18%, Test Loss: 0.9117, Test Accuracy: 64.56%\n",
      "Epoch [783/2500], Train Loss: 0.9376, Train Accuracy: 59.89%, Test Loss: 0.9090, Test Accuracy: 62.03%\n",
      "Epoch [784/2500], Train Loss: 0.9253, Train Accuracy: 59.03%, Test Loss: 0.9103, Test Accuracy: 62.03%\n",
      "Epoch [785/2500], Train Loss: 0.9348, Train Accuracy: 59.46%, Test Loss: 0.9082, Test Accuracy: 62.03%\n",
      "Epoch [786/2500], Train Loss: 0.9335, Train Accuracy: 58.04%, Test Loss: 0.9109, Test Accuracy: 62.03%\n",
      "Epoch [787/2500], Train Loss: 0.9451, Train Accuracy: 59.60%, Test Loss: 0.9097, Test Accuracy: 62.03%\n",
      "Epoch [788/2500], Train Loss: 0.9359, Train Accuracy: 58.04%, Test Loss: 0.9067, Test Accuracy: 62.03%\n",
      "Epoch [789/2500], Train Loss: 0.9333, Train Accuracy: 59.60%, Test Loss: 0.9020, Test Accuracy: 63.29%\n",
      "Epoch [790/2500], Train Loss: 0.9374, Train Accuracy: 59.46%, Test Loss: 0.9043, Test Accuracy: 63.29%\n",
      "Epoch [791/2500], Train Loss: 0.9247, Train Accuracy: 58.46%, Test Loss: 0.9057, Test Accuracy: 62.03%\n",
      "Epoch [792/2500], Train Loss: 0.9264, Train Accuracy: 59.46%, Test Loss: 0.9065, Test Accuracy: 62.03%\n",
      "Epoch [793/2500], Train Loss: 0.9502, Train Accuracy: 59.46%, Test Loss: 0.9091, Test Accuracy: 62.03%\n",
      "Epoch [794/2500], Train Loss: 0.9353, Train Accuracy: 59.03%, Test Loss: 0.9109, Test Accuracy: 62.03%\n",
      "Epoch [795/2500], Train Loss: 0.9401, Train Accuracy: 58.89%, Test Loss: 0.9049, Test Accuracy: 62.03%\n",
      "Epoch [796/2500], Train Loss: 0.9365, Train Accuracy: 58.75%, Test Loss: 0.8977, Test Accuracy: 64.56%\n",
      "Epoch [797/2500], Train Loss: 0.9377, Train Accuracy: 58.75%, Test Loss: 0.8953, Test Accuracy: 63.29%\n",
      "Epoch [798/2500], Train Loss: 0.9427, Train Accuracy: 59.60%, Test Loss: 0.8984, Test Accuracy: 64.56%\n",
      "Epoch [799/2500], Train Loss: 0.9376, Train Accuracy: 58.61%, Test Loss: 0.8970, Test Accuracy: 63.29%\n",
      "Epoch [800/2500], Train Loss: 0.9533, Train Accuracy: 59.74%, Test Loss: 0.8961, Test Accuracy: 64.56%\n",
      "Epoch [801/2500], Train Loss: 0.9212, Train Accuracy: 59.89%, Test Loss: 0.8919, Test Accuracy: 63.29%\n",
      "Epoch [802/2500], Train Loss: 0.9449, Train Accuracy: 59.03%, Test Loss: 0.8933, Test Accuracy: 63.29%\n",
      "Epoch [803/2500], Train Loss: 0.9272, Train Accuracy: 58.61%, Test Loss: 0.8976, Test Accuracy: 62.03%\n",
      "Epoch [804/2500], Train Loss: 0.9332, Train Accuracy: 59.60%, Test Loss: 0.9150, Test Accuracy: 62.03%\n",
      "Epoch [805/2500], Train Loss: 0.9365, Train Accuracy: 58.46%, Test Loss: 0.8993, Test Accuracy: 62.03%\n",
      "Epoch [806/2500], Train Loss: 0.9411, Train Accuracy: 58.89%, Test Loss: 0.9078, Test Accuracy: 62.03%\n",
      "Epoch [807/2500], Train Loss: 0.9269, Train Accuracy: 58.61%, Test Loss: 0.8950, Test Accuracy: 62.03%\n",
      "Epoch [808/2500], Train Loss: 0.9315, Train Accuracy: 58.89%, Test Loss: 0.8969, Test Accuracy: 63.29%\n",
      "Epoch [809/2500], Train Loss: 0.9342, Train Accuracy: 59.46%, Test Loss: 0.9070, Test Accuracy: 63.29%\n",
      "Epoch [810/2500], Train Loss: 0.9216, Train Accuracy: 59.03%, Test Loss: 0.9013, Test Accuracy: 63.29%\n",
      "Epoch [811/2500], Train Loss: 0.9409, Train Accuracy: 58.46%, Test Loss: 0.9066, Test Accuracy: 63.29%\n",
      "Epoch [812/2500], Train Loss: 0.9287, Train Accuracy: 58.46%, Test Loss: 0.9073, Test Accuracy: 63.29%\n",
      "Epoch [813/2500], Train Loss: 0.9352, Train Accuracy: 57.89%, Test Loss: 0.9123, Test Accuracy: 62.03%\n",
      "Epoch [814/2500], Train Loss: 0.9482, Train Accuracy: 59.32%, Test Loss: 0.9059, Test Accuracy: 63.29%\n",
      "Epoch [815/2500], Train Loss: 0.9400, Train Accuracy: 58.61%, Test Loss: 0.9135, Test Accuracy: 60.76%\n",
      "Epoch [816/2500], Train Loss: 0.9243, Train Accuracy: 59.60%, Test Loss: 0.9082, Test Accuracy: 63.29%\n",
      "Epoch [817/2500], Train Loss: 0.9224, Train Accuracy: 59.89%, Test Loss: 0.9143, Test Accuracy: 62.03%\n",
      "Epoch [818/2500], Train Loss: 0.9230, Train Accuracy: 58.18%, Test Loss: 0.8979, Test Accuracy: 62.03%\n",
      "Epoch [819/2500], Train Loss: 0.9317, Train Accuracy: 59.60%, Test Loss: 0.8952, Test Accuracy: 63.29%\n",
      "Epoch [820/2500], Train Loss: 0.9367, Train Accuracy: 58.61%, Test Loss: 0.9079, Test Accuracy: 62.03%\n",
      "Epoch [821/2500], Train Loss: 0.9254, Train Accuracy: 60.31%, Test Loss: 0.9079, Test Accuracy: 63.29%\n",
      "Epoch [822/2500], Train Loss: 0.9220, Train Accuracy: 59.46%, Test Loss: 0.9077, Test Accuracy: 62.03%\n",
      "Epoch [823/2500], Train Loss: 0.9354, Train Accuracy: 59.32%, Test Loss: 0.9019, Test Accuracy: 62.03%\n",
      "Epoch [824/2500], Train Loss: 0.9468, Train Accuracy: 59.17%, Test Loss: 0.9001, Test Accuracy: 59.49%\n",
      "Epoch [825/2500], Train Loss: 0.9382, Train Accuracy: 58.61%, Test Loss: 0.9078, Test Accuracy: 59.49%\n",
      "Epoch [826/2500], Train Loss: 0.9282, Train Accuracy: 59.17%, Test Loss: 0.9102, Test Accuracy: 62.03%\n",
      "Epoch [827/2500], Train Loss: 0.9387, Train Accuracy: 58.75%, Test Loss: 0.9111, Test Accuracy: 62.03%\n",
      "Epoch [828/2500], Train Loss: 0.9160, Train Accuracy: 59.60%, Test Loss: 0.9099, Test Accuracy: 60.76%\n",
      "Epoch [829/2500], Train Loss: 0.9357, Train Accuracy: 59.32%, Test Loss: 0.9143, Test Accuracy: 62.03%\n",
      "Epoch [830/2500], Train Loss: 0.9244, Train Accuracy: 60.46%, Test Loss: 0.9308, Test Accuracy: 62.03%\n",
      "Epoch [831/2500], Train Loss: 0.9309, Train Accuracy: 59.03%, Test Loss: 0.9219, Test Accuracy: 62.03%\n",
      "Epoch [832/2500], Train Loss: 0.9389, Train Accuracy: 58.75%, Test Loss: 0.9182, Test Accuracy: 62.03%\n",
      "Epoch [833/2500], Train Loss: 0.9209, Train Accuracy: 59.17%, Test Loss: 0.9142, Test Accuracy: 60.76%\n",
      "Epoch [834/2500], Train Loss: 0.9253, Train Accuracy: 59.46%, Test Loss: 0.9154, Test Accuracy: 60.76%\n",
      "Epoch [835/2500], Train Loss: 0.9400, Train Accuracy: 58.89%, Test Loss: 0.9104, Test Accuracy: 62.03%\n",
      "Epoch [836/2500], Train Loss: 0.9234, Train Accuracy: 58.61%, Test Loss: 0.9144, Test Accuracy: 63.29%\n",
      "Epoch [837/2500], Train Loss: 0.9327, Train Accuracy: 59.03%, Test Loss: 0.9154, Test Accuracy: 62.03%\n",
      "Epoch [838/2500], Train Loss: 0.9127, Train Accuracy: 61.74%, Test Loss: 0.9234, Test Accuracy: 60.76%\n",
      "Epoch [839/2500], Train Loss: 0.9334, Train Accuracy: 59.60%, Test Loss: 0.9119, Test Accuracy: 62.03%\n",
      "Epoch [840/2500], Train Loss: 0.9377, Train Accuracy: 58.89%, Test Loss: 0.9292, Test Accuracy: 60.76%\n",
      "Epoch [841/2500], Train Loss: 0.9050, Train Accuracy: 59.32%, Test Loss: 0.9117, Test Accuracy: 64.56%\n",
      "Epoch [842/2500], Train Loss: 0.9208, Train Accuracy: 58.46%, Test Loss: 0.9154, Test Accuracy: 62.03%\n",
      "Epoch [843/2500], Train Loss: 0.9212, Train Accuracy: 59.46%, Test Loss: 0.8964, Test Accuracy: 60.76%\n",
      "Epoch [844/2500], Train Loss: 0.9277, Train Accuracy: 57.47%, Test Loss: 0.8948, Test Accuracy: 62.03%\n",
      "Epoch [845/2500], Train Loss: 0.9287, Train Accuracy: 59.17%, Test Loss: 0.9075, Test Accuracy: 60.76%\n",
      "Epoch [846/2500], Train Loss: 0.9302, Train Accuracy: 59.60%, Test Loss: 0.9096, Test Accuracy: 60.76%\n",
      "Epoch [847/2500], Train Loss: 0.9160, Train Accuracy: 59.89%, Test Loss: 0.9136, Test Accuracy: 59.49%\n",
      "Epoch [848/2500], Train Loss: 0.9443, Train Accuracy: 56.90%, Test Loss: 0.9168, Test Accuracy: 59.49%\n",
      "Epoch [849/2500], Train Loss: 0.9178, Train Accuracy: 60.17%, Test Loss: 0.9029, Test Accuracy: 62.03%\n",
      "Epoch [850/2500], Train Loss: 0.9338, Train Accuracy: 58.89%, Test Loss: 0.8980, Test Accuracy: 62.03%\n",
      "Epoch [851/2500], Train Loss: 0.9366, Train Accuracy: 59.60%, Test Loss: 0.8959, Test Accuracy: 63.29%\n",
      "Epoch [852/2500], Train Loss: 0.9279, Train Accuracy: 61.17%, Test Loss: 0.8892, Test Accuracy: 62.03%\n",
      "Epoch [853/2500], Train Loss: 0.9408, Train Accuracy: 58.61%, Test Loss: 0.8902, Test Accuracy: 63.29%\n",
      "Epoch [854/2500], Train Loss: 0.9229, Train Accuracy: 60.17%, Test Loss: 0.8954, Test Accuracy: 63.29%\n",
      "Epoch [855/2500], Train Loss: 0.9304, Train Accuracy: 57.89%, Test Loss: 0.9117, Test Accuracy: 63.29%\n",
      "Epoch [856/2500], Train Loss: 0.9191, Train Accuracy: 58.75%, Test Loss: 0.8988, Test Accuracy: 64.56%\n",
      "Epoch [857/2500], Train Loss: 0.9238, Train Accuracy: 59.03%, Test Loss: 0.9090, Test Accuracy: 62.03%\n",
      "Epoch [858/2500], Train Loss: 0.9099, Train Accuracy: 59.46%, Test Loss: 0.9152, Test Accuracy: 62.03%\n",
      "Epoch [859/2500], Train Loss: 0.9372, Train Accuracy: 59.60%, Test Loss: 0.9100, Test Accuracy: 62.03%\n",
      "Epoch [860/2500], Train Loss: 0.9315, Train Accuracy: 59.32%, Test Loss: 0.9068, Test Accuracy: 62.03%\n",
      "Epoch [861/2500], Train Loss: 0.9180, Train Accuracy: 59.60%, Test Loss: 0.9052, Test Accuracy: 63.29%\n",
      "Epoch [862/2500], Train Loss: 0.9444, Train Accuracy: 60.46%, Test Loss: 0.9098, Test Accuracy: 63.29%\n",
      "Epoch [863/2500], Train Loss: 0.9236, Train Accuracy: 59.89%, Test Loss: 0.9143, Test Accuracy: 62.03%\n",
      "Epoch [864/2500], Train Loss: 0.9116, Train Accuracy: 59.03%, Test Loss: 0.9120, Test Accuracy: 60.76%\n",
      "Epoch [865/2500], Train Loss: 0.9299, Train Accuracy: 59.03%, Test Loss: 0.9050, Test Accuracy: 63.29%\n",
      "Epoch [866/2500], Train Loss: 0.9260, Train Accuracy: 58.89%, Test Loss: 0.8969, Test Accuracy: 63.29%\n",
      "Epoch [867/2500], Train Loss: 0.9480, Train Accuracy: 59.60%, Test Loss: 0.8923, Test Accuracy: 60.76%\n",
      "Epoch [868/2500], Train Loss: 0.9344, Train Accuracy: 58.61%, Test Loss: 0.9052, Test Accuracy: 63.29%\n",
      "Epoch [869/2500], Train Loss: 0.9290, Train Accuracy: 59.32%, Test Loss: 0.9087, Test Accuracy: 59.49%\n",
      "Epoch [870/2500], Train Loss: 0.9201, Train Accuracy: 58.89%, Test Loss: 0.9161, Test Accuracy: 59.49%\n",
      "Epoch [871/2500], Train Loss: 0.9286, Train Accuracy: 59.89%, Test Loss: 0.9069, Test Accuracy: 60.76%\n",
      "Epoch [872/2500], Train Loss: 0.9333, Train Accuracy: 58.75%, Test Loss: 0.9039, Test Accuracy: 60.76%\n",
      "Epoch [873/2500], Train Loss: 0.9341, Train Accuracy: 59.32%, Test Loss: 0.9101, Test Accuracy: 60.76%\n",
      "Epoch [874/2500], Train Loss: 0.9208, Train Accuracy: 60.17%, Test Loss: 0.9006, Test Accuracy: 63.29%\n",
      "Epoch [875/2500], Train Loss: 0.9286, Train Accuracy: 59.60%, Test Loss: 0.9071, Test Accuracy: 59.49%\n",
      "Epoch [876/2500], Train Loss: 0.9191, Train Accuracy: 59.60%, Test Loss: 0.9007, Test Accuracy: 62.03%\n",
      "Epoch [877/2500], Train Loss: 0.9415, Train Accuracy: 59.17%, Test Loss: 0.9046, Test Accuracy: 60.76%\n",
      "Epoch [878/2500], Train Loss: 0.9104, Train Accuracy: 59.60%, Test Loss: 0.9007, Test Accuracy: 62.03%\n",
      "Epoch [879/2500], Train Loss: 0.9340, Train Accuracy: 60.88%, Test Loss: 0.9073, Test Accuracy: 60.76%\n",
      "Epoch [880/2500], Train Loss: 0.9476, Train Accuracy: 59.60%, Test Loss: 0.9138, Test Accuracy: 62.03%\n",
      "Epoch [881/2500], Train Loss: 0.9112, Train Accuracy: 60.03%, Test Loss: 0.9109, Test Accuracy: 62.03%\n",
      "Epoch [882/2500], Train Loss: 0.9181, Train Accuracy: 59.32%, Test Loss: 0.9038, Test Accuracy: 63.29%\n",
      "Epoch [883/2500], Train Loss: 0.9130, Train Accuracy: 59.17%, Test Loss: 0.9141, Test Accuracy: 64.56%\n",
      "Epoch [884/2500], Train Loss: 0.9280, Train Accuracy: 59.60%, Test Loss: 0.9110, Test Accuracy: 63.29%\n",
      "Epoch [885/2500], Train Loss: 0.9237, Train Accuracy: 60.03%, Test Loss: 0.9121, Test Accuracy: 62.03%\n",
      "Epoch [886/2500], Train Loss: 0.9286, Train Accuracy: 60.60%, Test Loss: 0.9084, Test Accuracy: 64.56%\n",
      "Epoch [887/2500], Train Loss: 0.9230, Train Accuracy: 60.17%, Test Loss: 0.9040, Test Accuracy: 62.03%\n",
      "Epoch [888/2500], Train Loss: 0.9283, Train Accuracy: 58.75%, Test Loss: 0.8993, Test Accuracy: 62.03%\n",
      "Epoch [889/2500], Train Loss: 0.9115, Train Accuracy: 59.74%, Test Loss: 0.9017, Test Accuracy: 63.29%\n",
      "Epoch [890/2500], Train Loss: 0.9430, Train Accuracy: 59.03%, Test Loss: 0.9013, Test Accuracy: 63.29%\n",
      "Epoch [891/2500], Train Loss: 0.9143, Train Accuracy: 60.31%, Test Loss: 0.9043, Test Accuracy: 64.56%\n",
      "Epoch [892/2500], Train Loss: 0.9270, Train Accuracy: 58.46%, Test Loss: 0.9015, Test Accuracy: 62.03%\n",
      "Epoch [893/2500], Train Loss: 0.9149, Train Accuracy: 59.03%, Test Loss: 0.9071, Test Accuracy: 64.56%\n",
      "Epoch [894/2500], Train Loss: 0.9257, Train Accuracy: 59.46%, Test Loss: 0.9071, Test Accuracy: 64.56%\n",
      "Epoch [895/2500], Train Loss: 0.9226, Train Accuracy: 60.17%, Test Loss: 0.9094, Test Accuracy: 64.56%\n",
      "Epoch [896/2500], Train Loss: 0.9295, Train Accuracy: 59.74%, Test Loss: 0.9049, Test Accuracy: 63.29%\n",
      "Epoch [897/2500], Train Loss: 0.9135, Train Accuracy: 59.46%, Test Loss: 0.9162, Test Accuracy: 64.56%\n",
      "Epoch [898/2500], Train Loss: 0.9158, Train Accuracy: 59.74%, Test Loss: 0.9098, Test Accuracy: 62.03%\n",
      "Epoch [899/2500], Train Loss: 0.9186, Train Accuracy: 60.03%, Test Loss: 0.9051, Test Accuracy: 62.03%\n",
      "Epoch [900/2500], Train Loss: 0.9176, Train Accuracy: 59.17%, Test Loss: 0.9057, Test Accuracy: 63.29%\n",
      "Epoch [901/2500], Train Loss: 0.9160, Train Accuracy: 60.74%, Test Loss: 0.8946, Test Accuracy: 60.76%\n",
      "Epoch [902/2500], Train Loss: 0.9286, Train Accuracy: 59.03%, Test Loss: 0.8882, Test Accuracy: 60.76%\n",
      "Epoch [903/2500], Train Loss: 0.9093, Train Accuracy: 60.31%, Test Loss: 0.8962, Test Accuracy: 60.76%\n",
      "Epoch [904/2500], Train Loss: 0.9171, Train Accuracy: 60.31%, Test Loss: 0.9012, Test Accuracy: 60.76%\n",
      "Epoch [905/2500], Train Loss: 0.9220, Train Accuracy: 60.03%, Test Loss: 0.8929, Test Accuracy: 62.03%\n",
      "Epoch [906/2500], Train Loss: 0.9091, Train Accuracy: 60.03%, Test Loss: 0.8956, Test Accuracy: 62.03%\n",
      "Epoch [907/2500], Train Loss: 0.9156, Train Accuracy: 59.74%, Test Loss: 0.9026, Test Accuracy: 60.76%\n",
      "Epoch [908/2500], Train Loss: 0.9078, Train Accuracy: 59.46%, Test Loss: 0.9020, Test Accuracy: 62.03%\n",
      "Epoch [909/2500], Train Loss: 0.9216, Train Accuracy: 59.60%, Test Loss: 0.8927, Test Accuracy: 60.76%\n",
      "Epoch [910/2500], Train Loss: 0.9229, Train Accuracy: 59.89%, Test Loss: 0.8970, Test Accuracy: 63.29%\n",
      "Epoch [911/2500], Train Loss: 0.9101, Train Accuracy: 60.17%, Test Loss: 0.8987, Test Accuracy: 62.03%\n",
      "Epoch [912/2500], Train Loss: 0.9188, Train Accuracy: 60.74%, Test Loss: 0.9088, Test Accuracy: 63.29%\n",
      "Epoch [913/2500], Train Loss: 0.9349, Train Accuracy: 57.18%, Test Loss: 0.8955, Test Accuracy: 63.29%\n",
      "Epoch [914/2500], Train Loss: 0.9280, Train Accuracy: 58.32%, Test Loss: 0.8941, Test Accuracy: 63.29%\n",
      "Epoch [915/2500], Train Loss: 0.9228, Train Accuracy: 60.88%, Test Loss: 0.8810, Test Accuracy: 65.82%\n",
      "Epoch [916/2500], Train Loss: 0.9200, Train Accuracy: 58.75%, Test Loss: 0.8880, Test Accuracy: 64.56%\n",
      "Epoch [917/2500], Train Loss: 0.9061, Train Accuracy: 58.32%, Test Loss: 0.9019, Test Accuracy: 64.56%\n",
      "Epoch [918/2500], Train Loss: 0.9314, Train Accuracy: 60.03%, Test Loss: 0.8991, Test Accuracy: 65.82%\n",
      "Epoch [919/2500], Train Loss: 0.9097, Train Accuracy: 61.45%, Test Loss: 0.9105, Test Accuracy: 64.56%\n",
      "Epoch [920/2500], Train Loss: 0.9109, Train Accuracy: 59.17%, Test Loss: 0.9053, Test Accuracy: 64.56%\n",
      "Epoch [921/2500], Train Loss: 0.9128, Train Accuracy: 58.89%, Test Loss: 0.9056, Test Accuracy: 63.29%\n",
      "Epoch [922/2500], Train Loss: 0.9198, Train Accuracy: 59.03%, Test Loss: 0.8999, Test Accuracy: 64.56%\n",
      "Epoch [923/2500], Train Loss: 0.9230, Train Accuracy: 59.17%, Test Loss: 0.8928, Test Accuracy: 65.82%\n",
      "Epoch [924/2500], Train Loss: 0.9096, Train Accuracy: 60.46%, Test Loss: 0.8970, Test Accuracy: 64.56%\n",
      "Epoch [925/2500], Train Loss: 0.9320, Train Accuracy: 60.31%, Test Loss: 0.8947, Test Accuracy: 65.82%\n",
      "Epoch [926/2500], Train Loss: 0.9328, Train Accuracy: 58.04%, Test Loss: 0.9102, Test Accuracy: 65.82%\n",
      "Epoch [927/2500], Train Loss: 0.9251, Train Accuracy: 59.74%, Test Loss: 0.8896, Test Accuracy: 65.82%\n",
      "Epoch [928/2500], Train Loss: 0.9058, Train Accuracy: 59.17%, Test Loss: 0.8938, Test Accuracy: 64.56%\n",
      "Epoch [929/2500], Train Loss: 0.9240, Train Accuracy: 60.03%, Test Loss: 0.8831, Test Accuracy: 64.56%\n",
      "Epoch [930/2500], Train Loss: 0.9350, Train Accuracy: 58.32%, Test Loss: 0.8744, Test Accuracy: 63.29%\n",
      "Epoch [931/2500], Train Loss: 0.9239, Train Accuracy: 59.32%, Test Loss: 0.8904, Test Accuracy: 63.29%\n",
      "Epoch [932/2500], Train Loss: 0.9174, Train Accuracy: 60.60%, Test Loss: 0.8845, Test Accuracy: 63.29%\n",
      "Epoch [933/2500], Train Loss: 0.9202, Train Accuracy: 58.89%, Test Loss: 0.8936, Test Accuracy: 63.29%\n",
      "Epoch [934/2500], Train Loss: 0.9347, Train Accuracy: 59.17%, Test Loss: 0.8921, Test Accuracy: 63.29%\n",
      "Epoch [935/2500], Train Loss: 0.9224, Train Accuracy: 59.74%, Test Loss: 0.8867, Test Accuracy: 63.29%\n",
      "Epoch [936/2500], Train Loss: 0.9178, Train Accuracy: 58.61%, Test Loss: 0.8944, Test Accuracy: 63.29%\n",
      "Epoch [937/2500], Train Loss: 0.9301, Train Accuracy: 59.74%, Test Loss: 0.8974, Test Accuracy: 63.29%\n",
      "Epoch [938/2500], Train Loss: 0.9293, Train Accuracy: 58.61%, Test Loss: 0.8912, Test Accuracy: 62.03%\n",
      "Epoch [939/2500], Train Loss: 0.9395, Train Accuracy: 59.17%, Test Loss: 0.8948, Test Accuracy: 62.03%\n",
      "Epoch [940/2500], Train Loss: 0.9195, Train Accuracy: 60.60%, Test Loss: 0.8953, Test Accuracy: 63.29%\n",
      "Epoch [941/2500], Train Loss: 0.9385, Train Accuracy: 60.17%, Test Loss: 0.8912, Test Accuracy: 63.29%\n",
      "Epoch [942/2500], Train Loss: 0.9262, Train Accuracy: 60.31%, Test Loss: 0.8952, Test Accuracy: 63.29%\n",
      "Epoch [943/2500], Train Loss: 0.9122, Train Accuracy: 60.17%, Test Loss: 0.8994, Test Accuracy: 63.29%\n",
      "Epoch [944/2500], Train Loss: 0.9106, Train Accuracy: 59.32%, Test Loss: 0.9050, Test Accuracy: 63.29%\n",
      "Epoch [945/2500], Train Loss: 0.9146, Train Accuracy: 59.60%, Test Loss: 0.9055, Test Accuracy: 62.03%\n",
      "Epoch [946/2500], Train Loss: 0.9232, Train Accuracy: 59.60%, Test Loss: 0.8958, Test Accuracy: 63.29%\n",
      "Epoch [947/2500], Train Loss: 0.9185, Train Accuracy: 59.46%, Test Loss: 0.8992, Test Accuracy: 63.29%\n",
      "Epoch [948/2500], Train Loss: 0.9219, Train Accuracy: 59.32%, Test Loss: 0.9089, Test Accuracy: 63.29%\n",
      "Epoch [949/2500], Train Loss: 0.9181, Train Accuracy: 59.74%, Test Loss: 0.9083, Test Accuracy: 62.03%\n",
      "Epoch [950/2500], Train Loss: 0.9140, Train Accuracy: 60.31%, Test Loss: 0.9026, Test Accuracy: 63.29%\n",
      "Epoch [951/2500], Train Loss: 0.9074, Train Accuracy: 61.02%, Test Loss: 0.9074, Test Accuracy: 63.29%\n",
      "Epoch [952/2500], Train Loss: 0.9191, Train Accuracy: 59.32%, Test Loss: 0.9093, Test Accuracy: 62.03%\n",
      "Epoch [953/2500], Train Loss: 0.9258, Train Accuracy: 59.74%, Test Loss: 0.9149, Test Accuracy: 63.29%\n",
      "Epoch [954/2500], Train Loss: 0.9472, Train Accuracy: 58.61%, Test Loss: 0.9115, Test Accuracy: 62.03%\n",
      "Epoch [955/2500], Train Loss: 0.9323, Train Accuracy: 59.74%, Test Loss: 0.8928, Test Accuracy: 62.03%\n",
      "Epoch [956/2500], Train Loss: 0.9232, Train Accuracy: 59.03%, Test Loss: 0.8813, Test Accuracy: 60.76%\n",
      "Epoch [957/2500], Train Loss: 0.9169, Train Accuracy: 59.32%, Test Loss: 0.8887, Test Accuracy: 60.76%\n",
      "Epoch [958/2500], Train Loss: 0.9408, Train Accuracy: 59.03%, Test Loss: 0.8957, Test Accuracy: 63.29%\n",
      "Epoch [959/2500], Train Loss: 0.9267, Train Accuracy: 60.60%, Test Loss: 0.9029, Test Accuracy: 60.76%\n",
      "Epoch [960/2500], Train Loss: 0.9084, Train Accuracy: 59.32%, Test Loss: 0.8937, Test Accuracy: 62.03%\n",
      "Epoch [961/2500], Train Loss: 0.9273, Train Accuracy: 59.17%, Test Loss: 0.8966, Test Accuracy: 62.03%\n",
      "Epoch [962/2500], Train Loss: 0.9109, Train Accuracy: 60.17%, Test Loss: 0.8952, Test Accuracy: 62.03%\n",
      "Epoch [963/2500], Train Loss: 0.9086, Train Accuracy: 60.03%, Test Loss: 0.8895, Test Accuracy: 62.03%\n",
      "Epoch [964/2500], Train Loss: 0.9090, Train Accuracy: 59.60%, Test Loss: 0.9023, Test Accuracy: 60.76%\n",
      "Epoch [965/2500], Train Loss: 0.9298, Train Accuracy: 59.89%, Test Loss: 0.8970, Test Accuracy: 62.03%\n",
      "Epoch [966/2500], Train Loss: 0.9196, Train Accuracy: 59.74%, Test Loss: 0.9069, Test Accuracy: 62.03%\n",
      "Epoch [967/2500], Train Loss: 0.9104, Train Accuracy: 60.03%, Test Loss: 0.8933, Test Accuracy: 60.76%\n",
      "Epoch [968/2500], Train Loss: 0.9294, Train Accuracy: 59.60%, Test Loss: 0.8885, Test Accuracy: 60.76%\n",
      "Epoch [969/2500], Train Loss: 0.9101, Train Accuracy: 59.74%, Test Loss: 0.8741, Test Accuracy: 62.03%\n",
      "Epoch [970/2500], Train Loss: 0.9121, Train Accuracy: 58.75%, Test Loss: 0.8862, Test Accuracy: 62.03%\n",
      "Epoch [971/2500], Train Loss: 0.9082, Train Accuracy: 60.17%, Test Loss: 0.8766, Test Accuracy: 62.03%\n",
      "Epoch [972/2500], Train Loss: 0.9194, Train Accuracy: 59.89%, Test Loss: 0.8920, Test Accuracy: 62.03%\n",
      "Epoch [973/2500], Train Loss: 0.8981, Train Accuracy: 59.46%, Test Loss: 0.8969, Test Accuracy: 62.03%\n",
      "Epoch [974/2500], Train Loss: 0.9199, Train Accuracy: 58.89%, Test Loss: 0.9040, Test Accuracy: 60.76%\n",
      "Epoch [975/2500], Train Loss: 0.9094, Train Accuracy: 60.74%, Test Loss: 0.9015, Test Accuracy: 62.03%\n",
      "Epoch [976/2500], Train Loss: 0.9100, Train Accuracy: 58.46%, Test Loss: 0.8957, Test Accuracy: 60.76%\n",
      "Epoch [977/2500], Train Loss: 0.9188, Train Accuracy: 59.32%, Test Loss: 0.8870, Test Accuracy: 60.76%\n",
      "Epoch [978/2500], Train Loss: 0.8990, Train Accuracy: 59.32%, Test Loss: 0.8879, Test Accuracy: 60.76%\n",
      "Epoch [979/2500], Train Loss: 0.9211, Train Accuracy: 58.75%, Test Loss: 0.8909, Test Accuracy: 60.76%\n",
      "Epoch [980/2500], Train Loss: 0.9124, Train Accuracy: 59.17%, Test Loss: 0.9006, Test Accuracy: 62.03%\n",
      "Epoch [981/2500], Train Loss: 0.9063, Train Accuracy: 60.60%, Test Loss: 0.8951, Test Accuracy: 62.03%\n",
      "Epoch [982/2500], Train Loss: 0.9072, Train Accuracy: 61.17%, Test Loss: 0.8881, Test Accuracy: 62.03%\n",
      "Epoch [983/2500], Train Loss: 0.9064, Train Accuracy: 59.89%, Test Loss: 0.8937, Test Accuracy: 63.29%\n",
      "Epoch [984/2500], Train Loss: 0.9203, Train Accuracy: 59.32%, Test Loss: 0.8975, Test Accuracy: 64.56%\n",
      "Epoch [985/2500], Train Loss: 0.9178, Train Accuracy: 59.17%, Test Loss: 0.8997, Test Accuracy: 64.56%\n",
      "Epoch [986/2500], Train Loss: 0.9266, Train Accuracy: 58.75%, Test Loss: 0.8873, Test Accuracy: 62.03%\n",
      "Epoch [987/2500], Train Loss: 0.9082, Train Accuracy: 59.60%, Test Loss: 0.8848, Test Accuracy: 62.03%\n",
      "Epoch [988/2500], Train Loss: 0.9023, Train Accuracy: 58.46%, Test Loss: 0.8847, Test Accuracy: 62.03%\n",
      "Epoch [989/2500], Train Loss: 0.9208, Train Accuracy: 59.46%, Test Loss: 0.8989, Test Accuracy: 62.03%\n",
      "Epoch [990/2500], Train Loss: 0.9177, Train Accuracy: 59.89%, Test Loss: 0.8916, Test Accuracy: 62.03%\n",
      "Epoch [991/2500], Train Loss: 0.9159, Train Accuracy: 59.32%, Test Loss: 0.9034, Test Accuracy: 63.29%\n",
      "Epoch [992/2500], Train Loss: 0.8994, Train Accuracy: 60.60%, Test Loss: 0.9035, Test Accuracy: 62.03%\n",
      "Epoch [993/2500], Train Loss: 0.9124, Train Accuracy: 61.02%, Test Loss: 0.8958, Test Accuracy: 62.03%\n",
      "Epoch [994/2500], Train Loss: 0.8928, Train Accuracy: 61.17%, Test Loss: 0.8914, Test Accuracy: 62.03%\n",
      "Epoch [995/2500], Train Loss: 0.9103, Train Accuracy: 58.32%, Test Loss: 0.8883, Test Accuracy: 62.03%\n",
      "Epoch [996/2500], Train Loss: 0.9169, Train Accuracy: 59.32%, Test Loss: 0.8923, Test Accuracy: 63.29%\n",
      "Epoch [997/2500], Train Loss: 0.9104, Train Accuracy: 58.32%, Test Loss: 0.8882, Test Accuracy: 60.76%\n",
      "Epoch [998/2500], Train Loss: 0.9114, Train Accuracy: 60.17%, Test Loss: 0.8938, Test Accuracy: 64.56%\n",
      "Epoch [999/2500], Train Loss: 0.9208, Train Accuracy: 58.89%, Test Loss: 0.8945, Test Accuracy: 63.29%\n",
      "Epoch [1000/2500], Train Loss: 0.8972, Train Accuracy: 60.60%, Test Loss: 0.8934, Test Accuracy: 63.29%\n",
      "Epoch [1001/2500], Train Loss: 0.9167, Train Accuracy: 57.04%, Test Loss: 0.9015, Test Accuracy: 63.29%\n",
      "Epoch [1002/2500], Train Loss: 0.9135, Train Accuracy: 59.46%, Test Loss: 0.8976, Test Accuracy: 62.03%\n",
      "Epoch [1003/2500], Train Loss: 0.9406, Train Accuracy: 59.03%, Test Loss: 0.9002, Test Accuracy: 62.03%\n",
      "Epoch [1004/2500], Train Loss: 0.8973, Train Accuracy: 60.31%, Test Loss: 0.9196, Test Accuracy: 64.56%\n",
      "Epoch [1005/2500], Train Loss: 0.9236, Train Accuracy: 60.31%, Test Loss: 0.8968, Test Accuracy: 64.56%\n",
      "Epoch [1006/2500], Train Loss: 0.9170, Train Accuracy: 60.17%, Test Loss: 0.8972, Test Accuracy: 64.56%\n",
      "Epoch [1007/2500], Train Loss: 0.9266, Train Accuracy: 58.46%, Test Loss: 0.9012, Test Accuracy: 63.29%\n",
      "Epoch [1008/2500], Train Loss: 0.9200, Train Accuracy: 61.02%, Test Loss: 0.8892, Test Accuracy: 64.56%\n",
      "Epoch [1009/2500], Train Loss: 0.9118, Train Accuracy: 58.89%, Test Loss: 0.8940, Test Accuracy: 64.56%\n",
      "Epoch [1010/2500], Train Loss: 0.9331, Train Accuracy: 59.03%, Test Loss: 0.8889, Test Accuracy: 63.29%\n",
      "Epoch [1011/2500], Train Loss: 0.9034, Train Accuracy: 60.88%, Test Loss: 0.8839, Test Accuracy: 64.56%\n",
      "Epoch [1012/2500], Train Loss: 0.9269, Train Accuracy: 59.74%, Test Loss: 0.9021, Test Accuracy: 63.29%\n",
      "Epoch [1013/2500], Train Loss: 0.9208, Train Accuracy: 59.60%, Test Loss: 0.8939, Test Accuracy: 64.56%\n",
      "Epoch [1014/2500], Train Loss: 0.8995, Train Accuracy: 59.17%, Test Loss: 0.9005, Test Accuracy: 64.56%\n",
      "Epoch [1015/2500], Train Loss: 0.9036, Train Accuracy: 60.17%, Test Loss: 0.8912, Test Accuracy: 64.56%\n",
      "Epoch [1016/2500], Train Loss: 0.8941, Train Accuracy: 61.31%, Test Loss: 0.8921, Test Accuracy: 64.56%\n",
      "Epoch [1017/2500], Train Loss: 0.9215, Train Accuracy: 59.89%, Test Loss: 0.8924, Test Accuracy: 64.56%\n",
      "Epoch [1018/2500], Train Loss: 0.9221, Train Accuracy: 58.46%, Test Loss: 0.9003, Test Accuracy: 65.82%\n",
      "Epoch [1019/2500], Train Loss: 0.9253, Train Accuracy: 59.89%, Test Loss: 0.8952, Test Accuracy: 64.56%\n",
      "Epoch [1020/2500], Train Loss: 0.9305, Train Accuracy: 58.61%, Test Loss: 0.8913, Test Accuracy: 64.56%\n",
      "Epoch [1021/2500], Train Loss: 0.9290, Train Accuracy: 58.89%, Test Loss: 0.8921, Test Accuracy: 64.56%\n",
      "Epoch [1022/2500], Train Loss: 0.9138, Train Accuracy: 59.17%, Test Loss: 0.8990, Test Accuracy: 64.56%\n",
      "Epoch [1023/2500], Train Loss: 0.9144, Train Accuracy: 59.03%, Test Loss: 0.8932, Test Accuracy: 64.56%\n",
      "Epoch [1024/2500], Train Loss: 0.9248, Train Accuracy: 59.32%, Test Loss: 0.8930, Test Accuracy: 62.03%\n",
      "Epoch [1025/2500], Train Loss: 0.9069, Train Accuracy: 60.88%, Test Loss: 0.9139, Test Accuracy: 63.29%\n",
      "Epoch [1026/2500], Train Loss: 0.9067, Train Accuracy: 60.03%, Test Loss: 0.8970, Test Accuracy: 65.82%\n",
      "Epoch [1027/2500], Train Loss: 0.9208, Train Accuracy: 60.17%, Test Loss: 0.8972, Test Accuracy: 64.56%\n",
      "Epoch [1028/2500], Train Loss: 0.9037, Train Accuracy: 59.89%, Test Loss: 0.8940, Test Accuracy: 65.82%\n",
      "Epoch [1029/2500], Train Loss: 0.9038, Train Accuracy: 59.60%, Test Loss: 0.8930, Test Accuracy: 65.82%\n",
      "Epoch [1030/2500], Train Loss: 0.8982, Train Accuracy: 59.32%, Test Loss: 0.8893, Test Accuracy: 64.56%\n",
      "Epoch [1031/2500], Train Loss: 0.9185, Train Accuracy: 60.03%, Test Loss: 0.8902, Test Accuracy: 65.82%\n",
      "Epoch [1032/2500], Train Loss: 0.9185, Train Accuracy: 59.89%, Test Loss: 0.8969, Test Accuracy: 65.82%\n",
      "Epoch [1033/2500], Train Loss: 0.9072, Train Accuracy: 60.60%, Test Loss: 0.8944, Test Accuracy: 62.03%\n",
      "Epoch [1034/2500], Train Loss: 0.9175, Train Accuracy: 59.46%, Test Loss: 0.8948, Test Accuracy: 63.29%\n",
      "Epoch [1035/2500], Train Loss: 0.9094, Train Accuracy: 60.03%, Test Loss: 0.8972, Test Accuracy: 63.29%\n",
      "Epoch [1036/2500], Train Loss: 0.9014, Train Accuracy: 58.46%, Test Loss: 0.9038, Test Accuracy: 62.03%\n",
      "Epoch [1037/2500], Train Loss: 0.9055, Train Accuracy: 59.03%, Test Loss: 0.9031, Test Accuracy: 62.03%\n",
      "Epoch [1038/2500], Train Loss: 0.9087, Train Accuracy: 59.46%, Test Loss: 0.8951, Test Accuracy: 63.29%\n",
      "Epoch [1039/2500], Train Loss: 0.8969, Train Accuracy: 60.31%, Test Loss: 0.8872, Test Accuracy: 64.56%\n",
      "Epoch [1040/2500], Train Loss: 0.8911, Train Accuracy: 60.03%, Test Loss: 0.8944, Test Accuracy: 65.82%\n",
      "Epoch [1041/2500], Train Loss: 0.9041, Train Accuracy: 58.89%, Test Loss: 0.8964, Test Accuracy: 64.56%\n",
      "Epoch [1042/2500], Train Loss: 0.9058, Train Accuracy: 58.89%, Test Loss: 0.8956, Test Accuracy: 63.29%\n",
      "Epoch [1043/2500], Train Loss: 0.9134, Train Accuracy: 59.32%, Test Loss: 0.8997, Test Accuracy: 63.29%\n",
      "Epoch [1044/2500], Train Loss: 0.8831, Train Accuracy: 60.31%, Test Loss: 0.9060, Test Accuracy: 63.29%\n",
      "Epoch [1045/2500], Train Loss: 0.8952, Train Accuracy: 62.16%, Test Loss: 0.8944, Test Accuracy: 63.29%\n",
      "Epoch [1046/2500], Train Loss: 0.9158, Train Accuracy: 59.89%, Test Loss: 0.8920, Test Accuracy: 63.29%\n",
      "Epoch [1047/2500], Train Loss: 0.9180, Train Accuracy: 59.32%, Test Loss: 0.8970, Test Accuracy: 64.56%\n",
      "Epoch [1048/2500], Train Loss: 0.9057, Train Accuracy: 59.89%, Test Loss: 0.8946, Test Accuracy: 65.82%\n",
      "Epoch [1049/2500], Train Loss: 0.8999, Train Accuracy: 59.74%, Test Loss: 0.8937, Test Accuracy: 65.82%\n",
      "Epoch [1050/2500], Train Loss: 0.9011, Train Accuracy: 59.74%, Test Loss: 0.9018, Test Accuracy: 64.56%\n",
      "Epoch [1051/2500], Train Loss: 0.9086, Train Accuracy: 59.17%, Test Loss: 0.9019, Test Accuracy: 64.56%\n",
      "Epoch [1052/2500], Train Loss: 0.8938, Train Accuracy: 59.89%, Test Loss: 0.9080, Test Accuracy: 63.29%\n",
      "Epoch [1053/2500], Train Loss: 0.9069, Train Accuracy: 59.60%, Test Loss: 0.9035, Test Accuracy: 64.56%\n",
      "Epoch [1054/2500], Train Loss: 0.8959, Train Accuracy: 61.02%, Test Loss: 0.9016, Test Accuracy: 64.56%\n",
      "Epoch [1055/2500], Train Loss: 0.9217, Train Accuracy: 58.46%, Test Loss: 0.8967, Test Accuracy: 64.56%\n",
      "Epoch [1056/2500], Train Loss: 0.9124, Train Accuracy: 58.75%, Test Loss: 0.8993, Test Accuracy: 64.56%\n",
      "Epoch [1057/2500], Train Loss: 0.9096, Train Accuracy: 58.89%, Test Loss: 0.8923, Test Accuracy: 64.56%\n",
      "Epoch [1058/2500], Train Loss: 0.8877, Train Accuracy: 61.17%, Test Loss: 0.8977, Test Accuracy: 63.29%\n",
      "Epoch [1059/2500], Train Loss: 0.8868, Train Accuracy: 60.17%, Test Loss: 0.8986, Test Accuracy: 64.56%\n",
      "Epoch [1060/2500], Train Loss: 0.9136, Train Accuracy: 60.31%, Test Loss: 0.8971, Test Accuracy: 62.03%\n",
      "Epoch [1061/2500], Train Loss: 0.9145, Train Accuracy: 60.31%, Test Loss: 0.8911, Test Accuracy: 63.29%\n",
      "Epoch [1062/2500], Train Loss: 0.8925, Train Accuracy: 59.17%, Test Loss: 0.9016, Test Accuracy: 62.03%\n",
      "Epoch [1063/2500], Train Loss: 0.9046, Train Accuracy: 59.74%, Test Loss: 0.9038, Test Accuracy: 62.03%\n",
      "Epoch [1064/2500], Train Loss: 0.9165, Train Accuracy: 60.31%, Test Loss: 0.8984, Test Accuracy: 62.03%\n",
      "Epoch [1065/2500], Train Loss: 0.9167, Train Accuracy: 60.03%, Test Loss: 0.8975, Test Accuracy: 63.29%\n",
      "Epoch [1066/2500], Train Loss: 0.9062, Train Accuracy: 61.31%, Test Loss: 0.8958, Test Accuracy: 64.56%\n",
      "Epoch [1067/2500], Train Loss: 0.9149, Train Accuracy: 58.18%, Test Loss: 0.9114, Test Accuracy: 62.03%\n",
      "Epoch [1068/2500], Train Loss: 0.9210, Train Accuracy: 58.75%, Test Loss: 0.9058, Test Accuracy: 62.03%\n",
      "Epoch [1069/2500], Train Loss: 0.9005, Train Accuracy: 59.74%, Test Loss: 0.9046, Test Accuracy: 62.03%\n",
      "Epoch [1070/2500], Train Loss: 0.9018, Train Accuracy: 60.74%, Test Loss: 0.9094, Test Accuracy: 62.03%\n",
      "Epoch [1071/2500], Train Loss: 0.9037, Train Accuracy: 60.74%, Test Loss: 0.9007, Test Accuracy: 64.56%\n",
      "Epoch [1072/2500], Train Loss: 0.8955, Train Accuracy: 60.88%, Test Loss: 0.9075, Test Accuracy: 62.03%\n",
      "Epoch [1073/2500], Train Loss: 0.9167, Train Accuracy: 59.17%, Test Loss: 0.9067, Test Accuracy: 62.03%\n",
      "Epoch [1074/2500], Train Loss: 0.9008, Train Accuracy: 59.89%, Test Loss: 0.9034, Test Accuracy: 63.29%\n",
      "Epoch [1075/2500], Train Loss: 0.9096, Train Accuracy: 59.46%, Test Loss: 0.9066, Test Accuracy: 62.03%\n",
      "Epoch [1076/2500], Train Loss: 0.9343, Train Accuracy: 59.17%, Test Loss: 0.9142, Test Accuracy: 62.03%\n",
      "Epoch [1077/2500], Train Loss: 0.9039, Train Accuracy: 58.61%, Test Loss: 0.8978, Test Accuracy: 63.29%\n",
      "Epoch [1078/2500], Train Loss: 0.9166, Train Accuracy: 59.60%, Test Loss: 0.9092, Test Accuracy: 60.76%\n",
      "Epoch [1079/2500], Train Loss: 0.8993, Train Accuracy: 59.74%, Test Loss: 0.9038, Test Accuracy: 59.49%\n",
      "Epoch [1080/2500], Train Loss: 0.8916, Train Accuracy: 60.88%, Test Loss: 0.8978, Test Accuracy: 60.76%\n",
      "Epoch [1081/2500], Train Loss: 0.9271, Train Accuracy: 58.18%, Test Loss: 0.9001, Test Accuracy: 60.76%\n",
      "Epoch [1082/2500], Train Loss: 0.9005, Train Accuracy: 61.31%, Test Loss: 0.9004, Test Accuracy: 60.76%\n",
      "Epoch [1083/2500], Train Loss: 0.9145, Train Accuracy: 59.17%, Test Loss: 0.9101, Test Accuracy: 60.76%\n",
      "Epoch [1084/2500], Train Loss: 0.9012, Train Accuracy: 59.60%, Test Loss: 0.8934, Test Accuracy: 60.76%\n",
      "Epoch [1085/2500], Train Loss: 0.9001, Train Accuracy: 60.60%, Test Loss: 0.8953, Test Accuracy: 59.49%\n",
      "Epoch [1086/2500], Train Loss: 0.9183, Train Accuracy: 59.60%, Test Loss: 0.9088, Test Accuracy: 60.76%\n",
      "Epoch [1087/2500], Train Loss: 0.9089, Train Accuracy: 60.03%, Test Loss: 0.9082, Test Accuracy: 63.29%\n",
      "Epoch [1088/2500], Train Loss: 0.8938, Train Accuracy: 60.17%, Test Loss: 0.9073, Test Accuracy: 62.03%\n",
      "Epoch [1089/2500], Train Loss: 0.8973, Train Accuracy: 59.60%, Test Loss: 0.9001, Test Accuracy: 63.29%\n",
      "Epoch [1090/2500], Train Loss: 0.8894, Train Accuracy: 61.17%, Test Loss: 0.8944, Test Accuracy: 64.56%\n",
      "Epoch [1091/2500], Train Loss: 0.9077, Train Accuracy: 59.46%, Test Loss: 0.8985, Test Accuracy: 64.56%\n",
      "Epoch [1092/2500], Train Loss: 0.9071, Train Accuracy: 59.74%, Test Loss: 0.8898, Test Accuracy: 63.29%\n",
      "Epoch [1093/2500], Train Loss: 0.8966, Train Accuracy: 60.46%, Test Loss: 0.8890, Test Accuracy: 63.29%\n",
      "Epoch [1094/2500], Train Loss: 0.9026, Train Accuracy: 60.60%, Test Loss: 0.8889, Test Accuracy: 63.29%\n",
      "Epoch [1095/2500], Train Loss: 0.9084, Train Accuracy: 59.89%, Test Loss: 0.8913, Test Accuracy: 63.29%\n",
      "Epoch [1096/2500], Train Loss: 0.8994, Train Accuracy: 61.17%, Test Loss: 0.8994, Test Accuracy: 63.29%\n",
      "Epoch [1097/2500], Train Loss: 0.8979, Train Accuracy: 60.17%, Test Loss: 0.9045, Test Accuracy: 62.03%\n",
      "Epoch [1098/2500], Train Loss: 0.9049, Train Accuracy: 60.88%, Test Loss: 0.8994, Test Accuracy: 60.76%\n",
      "Epoch [1099/2500], Train Loss: 0.9033, Train Accuracy: 59.60%, Test Loss: 0.8950, Test Accuracy: 62.03%\n",
      "Epoch [1100/2500], Train Loss: 0.8990, Train Accuracy: 60.88%, Test Loss: 0.8929, Test Accuracy: 60.76%\n",
      "Epoch [1101/2500], Train Loss: 0.9171, Train Accuracy: 59.60%, Test Loss: 0.8973, Test Accuracy: 62.03%\n",
      "Epoch [1102/2500], Train Loss: 0.8885, Train Accuracy: 60.46%, Test Loss: 0.9016, Test Accuracy: 63.29%\n",
      "Epoch [1103/2500], Train Loss: 0.8925, Train Accuracy: 61.17%, Test Loss: 0.8961, Test Accuracy: 63.29%\n",
      "Epoch [1104/2500], Train Loss: 0.8956, Train Accuracy: 60.46%, Test Loss: 0.8906, Test Accuracy: 62.03%\n",
      "Epoch [1105/2500], Train Loss: 0.8913, Train Accuracy: 60.46%, Test Loss: 0.8966, Test Accuracy: 63.29%\n",
      "Epoch [1106/2500], Train Loss: 0.8973, Train Accuracy: 59.17%, Test Loss: 0.8983, Test Accuracy: 63.29%\n",
      "Epoch [1107/2500], Train Loss: 0.9126, Train Accuracy: 59.03%, Test Loss: 0.9011, Test Accuracy: 63.29%\n",
      "Epoch [1108/2500], Train Loss: 0.9044, Train Accuracy: 59.60%, Test Loss: 0.8978, Test Accuracy: 62.03%\n",
      "Epoch [1109/2500], Train Loss: 0.9169, Train Accuracy: 59.46%, Test Loss: 0.8966, Test Accuracy: 62.03%\n",
      "Epoch [1110/2500], Train Loss: 0.8908, Train Accuracy: 60.88%, Test Loss: 0.8990, Test Accuracy: 63.29%\n",
      "Epoch [1111/2500], Train Loss: 0.9097, Train Accuracy: 59.60%, Test Loss: 0.8858, Test Accuracy: 60.76%\n",
      "Epoch [1112/2500], Train Loss: 0.9037, Train Accuracy: 58.46%, Test Loss: 0.8955, Test Accuracy: 64.56%\n",
      "Epoch [1113/2500], Train Loss: 0.9170, Train Accuracy: 59.89%, Test Loss: 0.9051, Test Accuracy: 64.56%\n",
      "Epoch [1114/2500], Train Loss: 0.9182, Train Accuracy: 58.61%, Test Loss: 0.9000, Test Accuracy: 64.56%\n",
      "Epoch [1115/2500], Train Loss: 0.9118, Train Accuracy: 60.31%, Test Loss: 0.9022, Test Accuracy: 64.56%\n",
      "Epoch [1116/2500], Train Loss: 0.9032, Train Accuracy: 61.17%, Test Loss: 0.8883, Test Accuracy: 64.56%\n",
      "Epoch [1117/2500], Train Loss: 0.9039, Train Accuracy: 59.03%, Test Loss: 0.8933, Test Accuracy: 65.82%\n",
      "Epoch [1118/2500], Train Loss: 0.9147, Train Accuracy: 60.03%, Test Loss: 0.9002, Test Accuracy: 64.56%\n",
      "Epoch [1119/2500], Train Loss: 0.9090, Train Accuracy: 59.74%, Test Loss: 0.9014, Test Accuracy: 64.56%\n",
      "Epoch [1120/2500], Train Loss: 0.9121, Train Accuracy: 59.32%, Test Loss: 0.9039, Test Accuracy: 64.56%\n",
      "Epoch [1121/2500], Train Loss: 0.8992, Train Accuracy: 59.03%, Test Loss: 0.8961, Test Accuracy: 64.56%\n",
      "Epoch [1122/2500], Train Loss: 0.9029, Train Accuracy: 57.89%, Test Loss: 0.8934, Test Accuracy: 64.56%\n",
      "Epoch [1123/2500], Train Loss: 0.9078, Train Accuracy: 60.31%, Test Loss: 0.8926, Test Accuracy: 64.56%\n",
      "Epoch [1124/2500], Train Loss: 0.9093, Train Accuracy: 57.89%, Test Loss: 0.8959, Test Accuracy: 65.82%\n",
      "Epoch [1125/2500], Train Loss: 0.9031, Train Accuracy: 59.74%, Test Loss: 0.8925, Test Accuracy: 64.56%\n",
      "Epoch [1126/2500], Train Loss: 0.9020, Train Accuracy: 58.75%, Test Loss: 0.8937, Test Accuracy: 63.29%\n",
      "Epoch [1127/2500], Train Loss: 0.9119, Train Accuracy: 60.31%, Test Loss: 0.8993, Test Accuracy: 63.29%\n",
      "Epoch [1128/2500], Train Loss: 0.8954, Train Accuracy: 59.32%, Test Loss: 0.8992, Test Accuracy: 63.29%\n",
      "Epoch [1129/2500], Train Loss: 0.8837, Train Accuracy: 60.17%, Test Loss: 0.8980, Test Accuracy: 63.29%\n",
      "Epoch [1130/2500], Train Loss: 0.9131, Train Accuracy: 59.32%, Test Loss: 0.8963, Test Accuracy: 64.56%\n",
      "Epoch [1131/2500], Train Loss: 0.9012, Train Accuracy: 59.60%, Test Loss: 0.8964, Test Accuracy: 65.82%\n",
      "Epoch [1132/2500], Train Loss: 0.9105, Train Accuracy: 60.03%, Test Loss: 0.8976, Test Accuracy: 63.29%\n",
      "Epoch [1133/2500], Train Loss: 0.9047, Train Accuracy: 58.75%, Test Loss: 0.8998, Test Accuracy: 64.56%\n",
      "Epoch [1134/2500], Train Loss: 0.9097, Train Accuracy: 59.17%, Test Loss: 0.8968, Test Accuracy: 64.56%\n",
      "Epoch [1135/2500], Train Loss: 0.8962, Train Accuracy: 59.74%, Test Loss: 0.8980, Test Accuracy: 64.56%\n",
      "Epoch [1136/2500], Train Loss: 0.9093, Train Accuracy: 60.60%, Test Loss: 0.8962, Test Accuracy: 63.29%\n",
      "Epoch [1137/2500], Train Loss: 0.9064, Train Accuracy: 59.17%, Test Loss: 0.8915, Test Accuracy: 63.29%\n",
      "Epoch [1138/2500], Train Loss: 0.8936, Train Accuracy: 59.74%, Test Loss: 0.8873, Test Accuracy: 65.82%\n",
      "Epoch [1139/2500], Train Loss: 0.8934, Train Accuracy: 59.89%, Test Loss: 0.8858, Test Accuracy: 64.56%\n",
      "Epoch [1140/2500], Train Loss: 0.8987, Train Accuracy: 59.60%, Test Loss: 0.8778, Test Accuracy: 65.82%\n",
      "Epoch [1141/2500], Train Loss: 0.9007, Train Accuracy: 60.60%, Test Loss: 0.8936, Test Accuracy: 64.56%\n",
      "Epoch [1142/2500], Train Loss: 0.8994, Train Accuracy: 59.32%, Test Loss: 0.8931, Test Accuracy: 64.56%\n",
      "Epoch [1143/2500], Train Loss: 0.8744, Train Accuracy: 60.74%, Test Loss: 0.8871, Test Accuracy: 63.29%\n",
      "Epoch [1144/2500], Train Loss: 0.9075, Train Accuracy: 61.17%, Test Loss: 0.8994, Test Accuracy: 63.29%\n",
      "Epoch [1145/2500], Train Loss: 0.8926, Train Accuracy: 61.02%, Test Loss: 0.8824, Test Accuracy: 64.56%\n",
      "Epoch [1146/2500], Train Loss: 0.9129, Train Accuracy: 58.32%, Test Loss: 0.8872, Test Accuracy: 65.82%\n",
      "Epoch [1147/2500], Train Loss: 0.9077, Train Accuracy: 60.46%, Test Loss: 0.8900, Test Accuracy: 65.82%\n",
      "Epoch [1148/2500], Train Loss: 0.9023, Train Accuracy: 60.46%, Test Loss: 0.8838, Test Accuracy: 64.56%\n",
      "Epoch [1149/2500], Train Loss: 0.9089, Train Accuracy: 61.02%, Test Loss: 0.8959, Test Accuracy: 64.56%\n",
      "Epoch [1150/2500], Train Loss: 0.8882, Train Accuracy: 61.17%, Test Loss: 0.8891, Test Accuracy: 64.56%\n",
      "Epoch [1151/2500], Train Loss: 0.8895, Train Accuracy: 59.74%, Test Loss: 0.8901, Test Accuracy: 64.56%\n",
      "Epoch [1152/2500], Train Loss: 0.8765, Train Accuracy: 61.74%, Test Loss: 0.8895, Test Accuracy: 64.56%\n",
      "Epoch [1153/2500], Train Loss: 0.8894, Train Accuracy: 61.59%, Test Loss: 0.8957, Test Accuracy: 64.56%\n",
      "Epoch [1154/2500], Train Loss: 0.8983, Train Accuracy: 59.89%, Test Loss: 0.9009, Test Accuracy: 63.29%\n",
      "Epoch [1155/2500], Train Loss: 0.9245, Train Accuracy: 59.89%, Test Loss: 0.8852, Test Accuracy: 63.29%\n",
      "Epoch [1156/2500], Train Loss: 0.9040, Train Accuracy: 61.02%, Test Loss: 0.8849, Test Accuracy: 63.29%\n",
      "Epoch [1157/2500], Train Loss: 0.9013, Train Accuracy: 59.03%, Test Loss: 0.8721, Test Accuracy: 65.82%\n",
      "Epoch [1158/2500], Train Loss: 0.8929, Train Accuracy: 59.74%, Test Loss: 0.8668, Test Accuracy: 65.82%\n",
      "Epoch [1159/2500], Train Loss: 0.8957, Train Accuracy: 60.17%, Test Loss: 0.8711, Test Accuracy: 63.29%\n",
      "Epoch [1160/2500], Train Loss: 0.9105, Train Accuracy: 61.17%, Test Loss: 0.8793, Test Accuracy: 65.82%\n",
      "Epoch [1161/2500], Train Loss: 0.8973, Train Accuracy: 59.32%, Test Loss: 0.8832, Test Accuracy: 65.82%\n",
      "Epoch [1162/2500], Train Loss: 0.9024, Train Accuracy: 61.02%, Test Loss: 0.8834, Test Accuracy: 64.56%\n",
      "Epoch [1163/2500], Train Loss: 0.9090, Train Accuracy: 58.61%, Test Loss: 0.8895, Test Accuracy: 65.82%\n",
      "Epoch [1164/2500], Train Loss: 0.9093, Train Accuracy: 58.46%, Test Loss: 0.8893, Test Accuracy: 65.82%\n",
      "Epoch [1165/2500], Train Loss: 0.8745, Train Accuracy: 59.89%, Test Loss: 0.8824, Test Accuracy: 64.56%\n",
      "Epoch [1166/2500], Train Loss: 0.8824, Train Accuracy: 60.31%, Test Loss: 0.8816, Test Accuracy: 63.29%\n",
      "Epoch [1167/2500], Train Loss: 0.9110, Train Accuracy: 59.03%, Test Loss: 0.8800, Test Accuracy: 63.29%\n",
      "Epoch [1168/2500], Train Loss: 0.9056, Train Accuracy: 60.31%, Test Loss: 0.8795, Test Accuracy: 63.29%\n",
      "Epoch [1169/2500], Train Loss: 0.8950, Train Accuracy: 59.32%, Test Loss: 0.8896, Test Accuracy: 64.56%\n",
      "Epoch [1170/2500], Train Loss: 0.9007, Train Accuracy: 60.17%, Test Loss: 0.8823, Test Accuracy: 63.29%\n",
      "Epoch [1171/2500], Train Loss: 0.8944, Train Accuracy: 59.46%, Test Loss: 0.8841, Test Accuracy: 63.29%\n",
      "Epoch [1172/2500], Train Loss: 0.8919, Train Accuracy: 59.60%, Test Loss: 0.8856, Test Accuracy: 63.29%\n",
      "Epoch [1173/2500], Train Loss: 0.8732, Train Accuracy: 61.17%, Test Loss: 0.8906, Test Accuracy: 63.29%\n",
      "Epoch [1174/2500], Train Loss: 0.9192, Train Accuracy: 59.17%, Test Loss: 0.8888, Test Accuracy: 63.29%\n",
      "Epoch [1175/2500], Train Loss: 0.8807, Train Accuracy: 59.89%, Test Loss: 0.8789, Test Accuracy: 63.29%\n",
      "Epoch [1176/2500], Train Loss: 0.8991, Train Accuracy: 58.75%, Test Loss: 0.8663, Test Accuracy: 63.29%\n",
      "Epoch [1177/2500], Train Loss: 0.8873, Train Accuracy: 61.31%, Test Loss: 0.8798, Test Accuracy: 63.29%\n",
      "Epoch [1178/2500], Train Loss: 0.9076, Train Accuracy: 60.31%, Test Loss: 0.8801, Test Accuracy: 64.56%\n",
      "Epoch [1179/2500], Train Loss: 0.9060, Train Accuracy: 60.31%, Test Loss: 0.8731, Test Accuracy: 63.29%\n",
      "Epoch [1180/2500], Train Loss: 0.9034, Train Accuracy: 59.32%, Test Loss: 0.8672, Test Accuracy: 64.56%\n",
      "Epoch [1181/2500], Train Loss: 0.8900, Train Accuracy: 60.31%, Test Loss: 0.8743, Test Accuracy: 62.03%\n",
      "Epoch [1182/2500], Train Loss: 0.8883, Train Accuracy: 59.89%, Test Loss: 0.8854, Test Accuracy: 63.29%\n",
      "Epoch [1183/2500], Train Loss: 0.8824, Train Accuracy: 61.45%, Test Loss: 0.8933, Test Accuracy: 64.56%\n",
      "Epoch [1184/2500], Train Loss: 0.8842, Train Accuracy: 60.74%, Test Loss: 0.8896, Test Accuracy: 65.82%\n",
      "Epoch [1185/2500], Train Loss: 0.8949, Train Accuracy: 61.02%, Test Loss: 0.8885, Test Accuracy: 65.82%\n",
      "Epoch [1186/2500], Train Loss: 0.9112, Train Accuracy: 59.46%, Test Loss: 0.8894, Test Accuracy: 65.82%\n",
      "Epoch [1187/2500], Train Loss: 0.8936, Train Accuracy: 58.61%, Test Loss: 0.8925, Test Accuracy: 65.82%\n",
      "Epoch [1188/2500], Train Loss: 0.8735, Train Accuracy: 60.88%, Test Loss: 0.8916, Test Accuracy: 64.56%\n",
      "Epoch [1189/2500], Train Loss: 0.8936, Train Accuracy: 60.17%, Test Loss: 0.8901, Test Accuracy: 64.56%\n",
      "Epoch [1190/2500], Train Loss: 0.8886, Train Accuracy: 60.31%, Test Loss: 0.8904, Test Accuracy: 62.03%\n",
      "Epoch [1191/2500], Train Loss: 0.8846, Train Accuracy: 60.60%, Test Loss: 0.8902, Test Accuracy: 62.03%\n",
      "Epoch [1192/2500], Train Loss: 0.9035, Train Accuracy: 59.46%, Test Loss: 0.8941, Test Accuracy: 62.03%\n",
      "Epoch [1193/2500], Train Loss: 0.8845, Train Accuracy: 60.74%, Test Loss: 0.8940, Test Accuracy: 62.03%\n",
      "Epoch [1194/2500], Train Loss: 0.8905, Train Accuracy: 62.30%, Test Loss: 0.8914, Test Accuracy: 64.56%\n",
      "Epoch [1195/2500], Train Loss: 0.8943, Train Accuracy: 60.60%, Test Loss: 0.8963, Test Accuracy: 63.29%\n",
      "Epoch [1196/2500], Train Loss: 0.8947, Train Accuracy: 59.32%, Test Loss: 0.8946, Test Accuracy: 63.29%\n",
      "Epoch [1197/2500], Train Loss: 0.8969, Train Accuracy: 60.74%, Test Loss: 0.8930, Test Accuracy: 64.56%\n",
      "Epoch [1198/2500], Train Loss: 0.9026, Train Accuracy: 59.03%, Test Loss: 0.8952, Test Accuracy: 64.56%\n",
      "Epoch [1199/2500], Train Loss: 0.9008, Train Accuracy: 60.17%, Test Loss: 0.8868, Test Accuracy: 64.56%\n",
      "Epoch [1200/2500], Train Loss: 0.8909, Train Accuracy: 61.31%, Test Loss: 0.8936, Test Accuracy: 63.29%\n",
      "Epoch [1201/2500], Train Loss: 0.8989, Train Accuracy: 60.46%, Test Loss: 0.8952, Test Accuracy: 64.56%\n",
      "Epoch [1202/2500], Train Loss: 0.8917, Train Accuracy: 59.60%, Test Loss: 0.8950, Test Accuracy: 64.56%\n",
      "Epoch [1203/2500], Train Loss: 0.8902, Train Accuracy: 61.74%, Test Loss: 0.8927, Test Accuracy: 63.29%\n",
      "Epoch [1204/2500], Train Loss: 0.8981, Train Accuracy: 61.02%, Test Loss: 0.8966, Test Accuracy: 64.56%\n",
      "Epoch [1205/2500], Train Loss: 0.9117, Train Accuracy: 59.89%, Test Loss: 0.8945, Test Accuracy: 65.82%\n",
      "Epoch [1206/2500], Train Loss: 0.8902, Train Accuracy: 61.59%, Test Loss: 0.8956, Test Accuracy: 64.56%\n",
      "Epoch [1207/2500], Train Loss: 0.9075, Train Accuracy: 60.31%, Test Loss: 0.8857, Test Accuracy: 64.56%\n",
      "Epoch [1208/2500], Train Loss: 0.9115, Train Accuracy: 59.46%, Test Loss: 0.8874, Test Accuracy: 63.29%\n",
      "Epoch [1209/2500], Train Loss: 0.9045, Train Accuracy: 59.74%, Test Loss: 0.8894, Test Accuracy: 63.29%\n",
      "Epoch [1210/2500], Train Loss: 0.8862, Train Accuracy: 60.03%, Test Loss: 0.8979, Test Accuracy: 65.82%\n",
      "Epoch [1211/2500], Train Loss: 0.8866, Train Accuracy: 61.02%, Test Loss: 0.8935, Test Accuracy: 65.82%\n",
      "Epoch [1212/2500], Train Loss: 0.8962, Train Accuracy: 59.60%, Test Loss: 0.8972, Test Accuracy: 65.82%\n",
      "Epoch [1213/2500], Train Loss: 0.9092, Train Accuracy: 60.74%, Test Loss: 0.8904, Test Accuracy: 65.82%\n",
      "Epoch [1214/2500], Train Loss: 0.8848, Train Accuracy: 59.60%, Test Loss: 0.8919, Test Accuracy: 65.82%\n",
      "Epoch [1215/2500], Train Loss: 0.9188, Train Accuracy: 59.17%, Test Loss: 0.8885, Test Accuracy: 64.56%\n",
      "Epoch [1216/2500], Train Loss: 0.8791, Train Accuracy: 60.31%, Test Loss: 0.8863, Test Accuracy: 64.56%\n",
      "Epoch [1217/2500], Train Loss: 0.8837, Train Accuracy: 61.17%, Test Loss: 0.8860, Test Accuracy: 65.82%\n",
      "Epoch [1218/2500], Train Loss: 0.8804, Train Accuracy: 61.17%, Test Loss: 0.8889, Test Accuracy: 65.82%\n",
      "Epoch [1219/2500], Train Loss: 0.8892, Train Accuracy: 60.31%, Test Loss: 0.8882, Test Accuracy: 65.82%\n",
      "Epoch [1220/2500], Train Loss: 0.8905, Train Accuracy: 60.88%, Test Loss: 0.8857, Test Accuracy: 64.56%\n",
      "Epoch [1221/2500], Train Loss: 0.8869, Train Accuracy: 59.32%, Test Loss: 0.8873, Test Accuracy: 65.82%\n",
      "Epoch [1222/2500], Train Loss: 0.8921, Train Accuracy: 60.74%, Test Loss: 0.8920, Test Accuracy: 65.82%\n",
      "Epoch [1223/2500], Train Loss: 0.8810, Train Accuracy: 60.03%, Test Loss: 0.8943, Test Accuracy: 65.82%\n",
      "Epoch [1224/2500], Train Loss: 0.8946, Train Accuracy: 60.46%, Test Loss: 0.8914, Test Accuracy: 65.82%\n",
      "Epoch [1225/2500], Train Loss: 0.8848, Train Accuracy: 61.02%, Test Loss: 0.8914, Test Accuracy: 63.29%\n",
      "Epoch [1226/2500], Train Loss: 0.8973, Train Accuracy: 60.03%, Test Loss: 0.8795, Test Accuracy: 65.82%\n",
      "Epoch [1227/2500], Train Loss: 0.9133, Train Accuracy: 59.32%, Test Loss: 0.8697, Test Accuracy: 64.56%\n",
      "Epoch [1228/2500], Train Loss: 0.8926, Train Accuracy: 60.46%, Test Loss: 0.8908, Test Accuracy: 64.56%\n",
      "Epoch [1229/2500], Train Loss: 0.8813, Train Accuracy: 61.74%, Test Loss: 0.8866, Test Accuracy: 64.56%\n",
      "Epoch [1230/2500], Train Loss: 0.8935, Train Accuracy: 60.74%, Test Loss: 0.8885, Test Accuracy: 64.56%\n",
      "Epoch [1231/2500], Train Loss: 0.8782, Train Accuracy: 61.45%, Test Loss: 0.8944, Test Accuracy: 63.29%\n",
      "Epoch [1232/2500], Train Loss: 0.9142, Train Accuracy: 58.18%, Test Loss: 0.8883, Test Accuracy: 64.56%\n",
      "Epoch [1233/2500], Train Loss: 0.8845, Train Accuracy: 60.31%, Test Loss: 0.8887, Test Accuracy: 64.56%\n",
      "Epoch [1234/2500], Train Loss: 0.9017, Train Accuracy: 59.89%, Test Loss: 0.8894, Test Accuracy: 62.03%\n",
      "Epoch [1235/2500], Train Loss: 0.8841, Train Accuracy: 59.89%, Test Loss: 0.8834, Test Accuracy: 62.03%\n",
      "Epoch [1236/2500], Train Loss: 0.8817, Train Accuracy: 60.31%, Test Loss: 0.8784, Test Accuracy: 64.56%\n",
      "Epoch [1237/2500], Train Loss: 0.8715, Train Accuracy: 60.74%, Test Loss: 0.8859, Test Accuracy: 64.56%\n",
      "Epoch [1238/2500], Train Loss: 0.8755, Train Accuracy: 59.46%, Test Loss: 0.8810, Test Accuracy: 63.29%\n",
      "Epoch [1239/2500], Train Loss: 0.8821, Train Accuracy: 59.74%, Test Loss: 0.8838, Test Accuracy: 62.03%\n",
      "Epoch [1240/2500], Train Loss: 0.8782, Train Accuracy: 61.17%, Test Loss: 0.8759, Test Accuracy: 62.03%\n",
      "Epoch [1241/2500], Train Loss: 0.8843, Train Accuracy: 60.03%, Test Loss: 0.8697, Test Accuracy: 64.56%\n",
      "Epoch [1242/2500], Train Loss: 0.9071, Train Accuracy: 59.60%, Test Loss: 0.8767, Test Accuracy: 63.29%\n",
      "Epoch [1243/2500], Train Loss: 0.8857, Train Accuracy: 61.59%, Test Loss: 0.8777, Test Accuracy: 64.56%\n",
      "Epoch [1244/2500], Train Loss: 0.9100, Train Accuracy: 59.17%, Test Loss: 0.8785, Test Accuracy: 64.56%\n",
      "Epoch [1245/2500], Train Loss: 0.8946, Train Accuracy: 58.32%, Test Loss: 0.8792, Test Accuracy: 64.56%\n",
      "Epoch [1246/2500], Train Loss: 0.8840, Train Accuracy: 59.46%, Test Loss: 0.8746, Test Accuracy: 64.56%\n",
      "Epoch [1247/2500], Train Loss: 0.8776, Train Accuracy: 60.46%, Test Loss: 0.8831, Test Accuracy: 64.56%\n",
      "Epoch [1248/2500], Train Loss: 0.8708, Train Accuracy: 61.59%, Test Loss: 0.8812, Test Accuracy: 63.29%\n",
      "Epoch [1249/2500], Train Loss: 0.8807, Train Accuracy: 62.45%, Test Loss: 0.8825, Test Accuracy: 65.82%\n",
      "Epoch [1250/2500], Train Loss: 0.8975, Train Accuracy: 59.32%, Test Loss: 0.8754, Test Accuracy: 65.82%\n",
      "Epoch [1251/2500], Train Loss: 0.8829, Train Accuracy: 60.46%, Test Loss: 0.8776, Test Accuracy: 65.82%\n",
      "Epoch [1252/2500], Train Loss: 0.8916, Train Accuracy: 60.74%, Test Loss: 0.8809, Test Accuracy: 65.82%\n",
      "Epoch [1253/2500], Train Loss: 0.9021, Train Accuracy: 60.31%, Test Loss: 0.8832, Test Accuracy: 65.82%\n",
      "Epoch [1254/2500], Train Loss: 0.8946, Train Accuracy: 60.17%, Test Loss: 0.8785, Test Accuracy: 64.56%\n",
      "Epoch [1255/2500], Train Loss: 0.9080, Train Accuracy: 60.46%, Test Loss: 0.8784, Test Accuracy: 64.56%\n",
      "Epoch [1256/2500], Train Loss: 0.8845, Train Accuracy: 61.74%, Test Loss: 0.8845, Test Accuracy: 65.82%\n",
      "Epoch [1257/2500], Train Loss: 0.8995, Train Accuracy: 60.88%, Test Loss: 0.8855, Test Accuracy: 64.56%\n",
      "Epoch [1258/2500], Train Loss: 0.8872, Train Accuracy: 60.31%, Test Loss: 0.8808, Test Accuracy: 65.82%\n",
      "Epoch [1259/2500], Train Loss: 0.8766, Train Accuracy: 61.02%, Test Loss: 0.8768, Test Accuracy: 63.29%\n",
      "Epoch [1260/2500], Train Loss: 0.8785, Train Accuracy: 60.88%, Test Loss: 0.8657, Test Accuracy: 63.29%\n",
      "Epoch [1261/2500], Train Loss: 0.8920, Train Accuracy: 60.46%, Test Loss: 0.8664, Test Accuracy: 64.56%\n",
      "Epoch [1262/2500], Train Loss: 0.8697, Train Accuracy: 61.17%, Test Loss: 0.8726, Test Accuracy: 64.56%\n",
      "Epoch [1263/2500], Train Loss: 0.8850, Train Accuracy: 60.03%, Test Loss: 0.8875, Test Accuracy: 65.82%\n",
      "Epoch [1264/2500], Train Loss: 0.8805, Train Accuracy: 58.75%, Test Loss: 0.8846, Test Accuracy: 63.29%\n",
      "Epoch [1265/2500], Train Loss: 0.8940, Train Accuracy: 60.03%, Test Loss: 0.8867, Test Accuracy: 63.29%\n",
      "Epoch [1266/2500], Train Loss: 0.8891, Train Accuracy: 61.02%, Test Loss: 0.8917, Test Accuracy: 63.29%\n",
      "Epoch [1267/2500], Train Loss: 0.8939, Train Accuracy: 58.75%, Test Loss: 0.8942, Test Accuracy: 64.56%\n",
      "Epoch [1268/2500], Train Loss: 0.8955, Train Accuracy: 59.74%, Test Loss: 0.8870, Test Accuracy: 65.82%\n",
      "Epoch [1269/2500], Train Loss: 0.8923, Train Accuracy: 59.89%, Test Loss: 0.8897, Test Accuracy: 63.29%\n",
      "Epoch [1270/2500], Train Loss: 0.8645, Train Accuracy: 61.31%, Test Loss: 0.8798, Test Accuracy: 63.29%\n",
      "Epoch [1271/2500], Train Loss: 0.8955, Train Accuracy: 59.74%, Test Loss: 0.8766, Test Accuracy: 64.56%\n",
      "Epoch [1272/2500], Train Loss: 0.8731, Train Accuracy: 59.89%, Test Loss: 0.8652, Test Accuracy: 63.29%\n",
      "Epoch [1273/2500], Train Loss: 0.8981, Train Accuracy: 60.03%, Test Loss: 0.8716, Test Accuracy: 64.56%\n",
      "Epoch [1274/2500], Train Loss: 0.9058, Train Accuracy: 59.74%, Test Loss: 0.8817, Test Accuracy: 65.82%\n",
      "Epoch [1275/2500], Train Loss: 0.8942, Train Accuracy: 60.31%, Test Loss: 0.8784, Test Accuracy: 65.82%\n",
      "Epoch [1276/2500], Train Loss: 0.8672, Train Accuracy: 61.31%, Test Loss: 0.8805, Test Accuracy: 65.82%\n",
      "Epoch [1277/2500], Train Loss: 0.8749, Train Accuracy: 60.46%, Test Loss: 0.8858, Test Accuracy: 65.82%\n",
      "Epoch [1278/2500], Train Loss: 0.8772, Train Accuracy: 61.45%, Test Loss: 0.8873, Test Accuracy: 65.82%\n",
      "Epoch [1279/2500], Train Loss: 0.8933, Train Accuracy: 60.17%, Test Loss: 0.8876, Test Accuracy: 64.56%\n",
      "Epoch [1280/2500], Train Loss: 0.8818, Train Accuracy: 60.46%, Test Loss: 0.8836, Test Accuracy: 64.56%\n",
      "Epoch [1281/2500], Train Loss: 0.8795, Train Accuracy: 59.89%, Test Loss: 0.8832, Test Accuracy: 65.82%\n",
      "Epoch [1282/2500], Train Loss: 0.8848, Train Accuracy: 59.46%, Test Loss: 0.8896, Test Accuracy: 65.82%\n",
      "Epoch [1283/2500], Train Loss: 0.8845, Train Accuracy: 61.02%, Test Loss: 0.8874, Test Accuracy: 65.82%\n",
      "Epoch [1284/2500], Train Loss: 0.8818, Train Accuracy: 60.74%, Test Loss: 0.9014, Test Accuracy: 64.56%\n",
      "Epoch [1285/2500], Train Loss: 0.8820, Train Accuracy: 61.17%, Test Loss: 0.9017, Test Accuracy: 64.56%\n",
      "Epoch [1286/2500], Train Loss: 0.8917, Train Accuracy: 60.31%, Test Loss: 0.8927, Test Accuracy: 64.56%\n",
      "Epoch [1287/2500], Train Loss: 0.8963, Train Accuracy: 59.32%, Test Loss: 0.8913, Test Accuracy: 64.56%\n",
      "Epoch [1288/2500], Train Loss: 0.8836, Train Accuracy: 60.88%, Test Loss: 0.8857, Test Accuracy: 64.56%\n",
      "Epoch [1289/2500], Train Loss: 0.8900, Train Accuracy: 59.60%, Test Loss: 0.8815, Test Accuracy: 63.29%\n",
      "Epoch [1290/2500], Train Loss: 0.8838, Train Accuracy: 60.31%, Test Loss: 0.8697, Test Accuracy: 63.29%\n",
      "Epoch [1291/2500], Train Loss: 0.9030, Train Accuracy: 60.17%, Test Loss: 0.8786, Test Accuracy: 65.82%\n",
      "Epoch [1292/2500], Train Loss: 0.8826, Train Accuracy: 58.89%, Test Loss: 0.8744, Test Accuracy: 64.56%\n",
      "Epoch [1293/2500], Train Loss: 0.8846, Train Accuracy: 61.74%, Test Loss: 0.8840, Test Accuracy: 65.82%\n",
      "Epoch [1294/2500], Train Loss: 0.8917, Train Accuracy: 60.74%, Test Loss: 0.8790, Test Accuracy: 65.82%\n",
      "Epoch [1295/2500], Train Loss: 0.8922, Train Accuracy: 59.17%, Test Loss: 0.8873, Test Accuracy: 64.56%\n",
      "Epoch [1296/2500], Train Loss: 0.8867, Train Accuracy: 59.60%, Test Loss: 0.8835, Test Accuracy: 64.56%\n",
      "Epoch [1297/2500], Train Loss: 0.8952, Train Accuracy: 60.17%, Test Loss: 0.8751, Test Accuracy: 64.56%\n",
      "Epoch [1298/2500], Train Loss: 0.8900, Train Accuracy: 60.03%, Test Loss: 0.8766, Test Accuracy: 64.56%\n",
      "Epoch [1299/2500], Train Loss: 0.8720, Train Accuracy: 60.74%, Test Loss: 0.8769, Test Accuracy: 65.82%\n",
      "Epoch [1300/2500], Train Loss: 0.8739, Train Accuracy: 60.60%, Test Loss: 0.8609, Test Accuracy: 63.29%\n",
      "Epoch [1301/2500], Train Loss: 0.8799, Train Accuracy: 60.03%, Test Loss: 0.8640, Test Accuracy: 65.82%\n",
      "Epoch [1302/2500], Train Loss: 0.8849, Train Accuracy: 59.32%, Test Loss: 0.8704, Test Accuracy: 64.56%\n",
      "Epoch [1303/2500], Train Loss: 0.8787, Train Accuracy: 60.31%, Test Loss: 0.8814, Test Accuracy: 63.29%\n",
      "Epoch [1304/2500], Train Loss: 0.8776, Train Accuracy: 61.45%, Test Loss: 0.8812, Test Accuracy: 63.29%\n",
      "Epoch [1305/2500], Train Loss: 0.8866, Train Accuracy: 59.32%, Test Loss: 0.8888, Test Accuracy: 63.29%\n",
      "Epoch [1306/2500], Train Loss: 0.8869, Train Accuracy: 60.74%, Test Loss: 0.8869, Test Accuracy: 64.56%\n",
      "Epoch [1307/2500], Train Loss: 0.8659, Train Accuracy: 62.45%, Test Loss: 0.8800, Test Accuracy: 64.56%\n",
      "Epoch [1308/2500], Train Loss: 0.8905, Train Accuracy: 61.02%, Test Loss: 0.8824, Test Accuracy: 67.09%\n",
      "Epoch [1309/2500], Train Loss: 0.8849, Train Accuracy: 60.17%, Test Loss: 0.8808, Test Accuracy: 64.56%\n",
      "Epoch [1310/2500], Train Loss: 0.8866, Train Accuracy: 60.60%, Test Loss: 0.8695, Test Accuracy: 63.29%\n",
      "Epoch [1311/2500], Train Loss: 0.8925, Train Accuracy: 60.17%, Test Loss: 0.8754, Test Accuracy: 64.56%\n",
      "Epoch [1312/2500], Train Loss: 0.8659, Train Accuracy: 61.74%, Test Loss: 0.8663, Test Accuracy: 63.29%\n",
      "Epoch [1313/2500], Train Loss: 0.9005, Train Accuracy: 59.17%, Test Loss: 0.8788, Test Accuracy: 64.56%\n",
      "Epoch [1314/2500], Train Loss: 0.9040, Train Accuracy: 60.60%, Test Loss: 0.8820, Test Accuracy: 64.56%\n",
      "Epoch [1315/2500], Train Loss: 0.8817, Train Accuracy: 59.74%, Test Loss: 0.8813, Test Accuracy: 64.56%\n",
      "Epoch [1316/2500], Train Loss: 0.8925, Train Accuracy: 59.46%, Test Loss: 0.8756, Test Accuracy: 63.29%\n",
      "Epoch [1317/2500], Train Loss: 0.8761, Train Accuracy: 61.59%, Test Loss: 0.8758, Test Accuracy: 64.56%\n",
      "Epoch [1318/2500], Train Loss: 0.8870, Train Accuracy: 60.17%, Test Loss: 0.8834, Test Accuracy: 64.56%\n",
      "Epoch [1319/2500], Train Loss: 0.8744, Train Accuracy: 60.03%, Test Loss: 0.8843, Test Accuracy: 64.56%\n",
      "Epoch [1320/2500], Train Loss: 0.8971, Train Accuracy: 59.89%, Test Loss: 0.8711, Test Accuracy: 63.29%\n",
      "Epoch [1321/2500], Train Loss: 0.8912, Train Accuracy: 60.60%, Test Loss: 0.8785, Test Accuracy: 65.82%\n",
      "Epoch [1322/2500], Train Loss: 0.9039, Train Accuracy: 59.32%, Test Loss: 0.8782, Test Accuracy: 62.03%\n",
      "Epoch [1323/2500], Train Loss: 0.9034, Train Accuracy: 60.17%, Test Loss: 0.8863, Test Accuracy: 62.03%\n",
      "Epoch [1324/2500], Train Loss: 0.9069, Train Accuracy: 60.31%, Test Loss: 0.8770, Test Accuracy: 64.56%\n",
      "Epoch [1325/2500], Train Loss: 0.8737, Train Accuracy: 61.02%, Test Loss: 0.8809, Test Accuracy: 64.56%\n",
      "Epoch [1326/2500], Train Loss: 0.8764, Train Accuracy: 61.17%, Test Loss: 0.8811, Test Accuracy: 64.56%\n",
      "Epoch [1327/2500], Train Loss: 0.8677, Train Accuracy: 61.45%, Test Loss: 0.8848, Test Accuracy: 64.56%\n",
      "Epoch [1328/2500], Train Loss: 0.8742, Train Accuracy: 61.88%, Test Loss: 0.8906, Test Accuracy: 63.29%\n",
      "Epoch [1329/2500], Train Loss: 0.8850, Train Accuracy: 60.60%, Test Loss: 0.8827, Test Accuracy: 63.29%\n",
      "Epoch [1330/2500], Train Loss: 0.8940, Train Accuracy: 59.46%, Test Loss: 0.8652, Test Accuracy: 63.29%\n",
      "Epoch [1331/2500], Train Loss: 0.8631, Train Accuracy: 58.89%, Test Loss: 0.8623, Test Accuracy: 63.29%\n",
      "Epoch [1332/2500], Train Loss: 0.9069, Train Accuracy: 60.31%, Test Loss: 0.8602, Test Accuracy: 64.56%\n",
      "Epoch [1333/2500], Train Loss: 0.8920, Train Accuracy: 60.46%, Test Loss: 0.8652, Test Accuracy: 65.82%\n",
      "Epoch [1334/2500], Train Loss: 0.8772, Train Accuracy: 60.31%, Test Loss: 0.8910, Test Accuracy: 64.56%\n",
      "Epoch [1335/2500], Train Loss: 0.8861, Train Accuracy: 60.88%, Test Loss: 0.8664, Test Accuracy: 63.29%\n",
      "Epoch [1336/2500], Train Loss: 0.8865, Train Accuracy: 62.30%, Test Loss: 0.8851, Test Accuracy: 64.56%\n",
      "Epoch [1337/2500], Train Loss: 0.8993, Train Accuracy: 57.89%, Test Loss: 0.8904, Test Accuracy: 65.82%\n",
      "Epoch [1338/2500], Train Loss: 0.8880, Train Accuracy: 60.60%, Test Loss: 0.8881, Test Accuracy: 64.56%\n",
      "Epoch [1339/2500], Train Loss: 0.8777, Train Accuracy: 60.60%, Test Loss: 0.8912, Test Accuracy: 64.56%\n",
      "Epoch [1340/2500], Train Loss: 0.8893, Train Accuracy: 61.88%, Test Loss: 0.8880, Test Accuracy: 64.56%\n",
      "Epoch [1341/2500], Train Loss: 0.8894, Train Accuracy: 61.17%, Test Loss: 0.8909, Test Accuracy: 63.29%\n",
      "Epoch [1342/2500], Train Loss: 0.8991, Train Accuracy: 58.75%, Test Loss: 0.8891, Test Accuracy: 64.56%\n",
      "Epoch [1343/2500], Train Loss: 0.8820, Train Accuracy: 61.31%, Test Loss: 0.8917, Test Accuracy: 64.56%\n",
      "Epoch [1344/2500], Train Loss: 0.8761, Train Accuracy: 60.60%, Test Loss: 0.8836, Test Accuracy: 63.29%\n",
      "Epoch [1345/2500], Train Loss: 0.8989, Train Accuracy: 59.60%, Test Loss: 0.8864, Test Accuracy: 65.82%\n",
      "Epoch [1346/2500], Train Loss: 0.8679, Train Accuracy: 61.45%, Test Loss: 0.8833, Test Accuracy: 62.03%\n",
      "Epoch [1347/2500], Train Loss: 0.8868, Train Accuracy: 59.89%, Test Loss: 0.8814, Test Accuracy: 64.56%\n",
      "Epoch [1348/2500], Train Loss: 0.8919, Train Accuracy: 58.46%, Test Loss: 0.8844, Test Accuracy: 63.29%\n",
      "Epoch [1349/2500], Train Loss: 0.8833, Train Accuracy: 60.60%, Test Loss: 0.8830, Test Accuracy: 63.29%\n",
      "Epoch [1350/2500], Train Loss: 0.8871, Train Accuracy: 59.17%, Test Loss: 0.8960, Test Accuracy: 64.56%\n",
      "Epoch [1351/2500], Train Loss: 0.8761, Train Accuracy: 60.74%, Test Loss: 0.8959, Test Accuracy: 64.56%\n",
      "Epoch [1352/2500], Train Loss: 0.8771, Train Accuracy: 60.46%, Test Loss: 0.8935, Test Accuracy: 64.56%\n",
      "Epoch [1353/2500], Train Loss: 0.8653, Train Accuracy: 60.60%, Test Loss: 0.8866, Test Accuracy: 64.56%\n",
      "Epoch [1354/2500], Train Loss: 0.8920, Train Accuracy: 59.46%, Test Loss: 0.8894, Test Accuracy: 64.56%\n",
      "Epoch [1355/2500], Train Loss: 0.8534, Train Accuracy: 62.02%, Test Loss: 0.8902, Test Accuracy: 64.56%\n",
      "Epoch [1356/2500], Train Loss: 0.8626, Train Accuracy: 61.45%, Test Loss: 0.8887, Test Accuracy: 64.56%\n",
      "Epoch [1357/2500], Train Loss: 0.8905, Train Accuracy: 58.75%, Test Loss: 0.8871, Test Accuracy: 63.29%\n",
      "Epoch [1358/2500], Train Loss: 0.8730, Train Accuracy: 60.17%, Test Loss: 0.8844, Test Accuracy: 63.29%\n",
      "Epoch [1359/2500], Train Loss: 0.8805, Train Accuracy: 60.46%, Test Loss: 0.8901, Test Accuracy: 65.82%\n",
      "Epoch [1360/2500], Train Loss: 0.8603, Train Accuracy: 59.74%, Test Loss: 0.8884, Test Accuracy: 62.03%\n",
      "Epoch [1361/2500], Train Loss: 0.8761, Train Accuracy: 61.31%, Test Loss: 0.8598, Test Accuracy: 63.29%\n",
      "Epoch [1362/2500], Train Loss: 0.8773, Train Accuracy: 61.45%, Test Loss: 0.8588, Test Accuracy: 63.29%\n",
      "Epoch [1363/2500], Train Loss: 0.8981, Train Accuracy: 60.03%, Test Loss: 0.8572, Test Accuracy: 63.29%\n",
      "Epoch [1364/2500], Train Loss: 0.8709, Train Accuracy: 60.60%, Test Loss: 0.8476, Test Accuracy: 62.03%\n",
      "Epoch [1365/2500], Train Loss: 0.9035, Train Accuracy: 60.46%, Test Loss: 0.8590, Test Accuracy: 62.03%\n",
      "Epoch [1366/2500], Train Loss: 0.8681, Train Accuracy: 61.59%, Test Loss: 0.8744, Test Accuracy: 62.03%\n",
      "Epoch [1367/2500], Train Loss: 0.8761, Train Accuracy: 61.17%, Test Loss: 0.8692, Test Accuracy: 64.56%\n",
      "Epoch [1368/2500], Train Loss: 0.8661, Train Accuracy: 62.30%, Test Loss: 0.8623, Test Accuracy: 63.29%\n",
      "Epoch [1369/2500], Train Loss: 0.8750, Train Accuracy: 60.03%, Test Loss: 0.8766, Test Accuracy: 64.56%\n",
      "Epoch [1370/2500], Train Loss: 0.8920, Train Accuracy: 60.17%, Test Loss: 0.8805, Test Accuracy: 63.29%\n",
      "Epoch [1371/2500], Train Loss: 0.8753, Train Accuracy: 60.17%, Test Loss: 0.8833, Test Accuracy: 63.29%\n",
      "Epoch [1372/2500], Train Loss: 0.8967, Train Accuracy: 60.46%, Test Loss: 0.8752, Test Accuracy: 63.29%\n",
      "Epoch [1373/2500], Train Loss: 0.8651, Train Accuracy: 62.16%, Test Loss: 0.8785, Test Accuracy: 63.29%\n",
      "Epoch [1374/2500], Train Loss: 0.8793, Train Accuracy: 60.74%, Test Loss: 0.8744, Test Accuracy: 64.56%\n",
      "Epoch [1375/2500], Train Loss: 0.9055, Train Accuracy: 59.46%, Test Loss: 0.8801, Test Accuracy: 62.03%\n",
      "Epoch [1376/2500], Train Loss: 0.8759, Train Accuracy: 61.31%, Test Loss: 0.8854, Test Accuracy: 63.29%\n",
      "Epoch [1377/2500], Train Loss: 0.8630, Train Accuracy: 60.74%, Test Loss: 0.8872, Test Accuracy: 64.56%\n",
      "Epoch [1378/2500], Train Loss: 0.8784, Train Accuracy: 59.89%, Test Loss: 0.8817, Test Accuracy: 63.29%\n",
      "Epoch [1379/2500], Train Loss: 0.8841, Train Accuracy: 60.74%, Test Loss: 0.8821, Test Accuracy: 62.03%\n",
      "Epoch [1380/2500], Train Loss: 0.8639, Train Accuracy: 61.02%, Test Loss: 0.8803, Test Accuracy: 63.29%\n",
      "Epoch [1381/2500], Train Loss: 0.8768, Train Accuracy: 60.17%, Test Loss: 0.8721, Test Accuracy: 64.56%\n",
      "Epoch [1382/2500], Train Loss: 0.8722, Train Accuracy: 60.03%, Test Loss: 0.8554, Test Accuracy: 63.29%\n",
      "Epoch [1383/2500], Train Loss: 0.8557, Train Accuracy: 61.59%, Test Loss: 0.8571, Test Accuracy: 64.56%\n",
      "Epoch [1384/2500], Train Loss: 0.8770, Train Accuracy: 61.45%, Test Loss: 0.8604, Test Accuracy: 64.56%\n",
      "Epoch [1385/2500], Train Loss: 0.8914, Train Accuracy: 59.46%, Test Loss: 0.8732, Test Accuracy: 62.03%\n",
      "Epoch [1386/2500], Train Loss: 0.8787, Train Accuracy: 60.46%, Test Loss: 0.8730, Test Accuracy: 63.29%\n",
      "Epoch [1387/2500], Train Loss: 0.8901, Train Accuracy: 60.17%, Test Loss: 0.8737, Test Accuracy: 64.56%\n",
      "Epoch [1388/2500], Train Loss: 0.8651, Train Accuracy: 60.03%, Test Loss: 0.8715, Test Accuracy: 65.82%\n",
      "Epoch [1389/2500], Train Loss: 0.8862, Train Accuracy: 61.31%, Test Loss: 0.8727, Test Accuracy: 64.56%\n",
      "Epoch [1390/2500], Train Loss: 0.8799, Train Accuracy: 60.31%, Test Loss: 0.8660, Test Accuracy: 63.29%\n",
      "Epoch [1391/2500], Train Loss: 0.8711, Train Accuracy: 62.59%, Test Loss: 0.8722, Test Accuracy: 67.09%\n",
      "Epoch [1392/2500], Train Loss: 0.8743, Train Accuracy: 61.88%, Test Loss: 0.8739, Test Accuracy: 64.56%\n",
      "Epoch [1393/2500], Train Loss: 0.8654, Train Accuracy: 61.31%, Test Loss: 0.8589, Test Accuracy: 64.56%\n",
      "Epoch [1394/2500], Train Loss: 0.8643, Train Accuracy: 61.74%, Test Loss: 0.8610, Test Accuracy: 63.29%\n",
      "Epoch [1395/2500], Train Loss: 0.8808, Train Accuracy: 59.46%, Test Loss: 0.8591, Test Accuracy: 63.29%\n",
      "Epoch [1396/2500], Train Loss: 0.8558, Train Accuracy: 61.31%, Test Loss: 0.8626, Test Accuracy: 64.56%\n",
      "Epoch [1397/2500], Train Loss: 0.8779, Train Accuracy: 62.02%, Test Loss: 0.8612, Test Accuracy: 64.56%\n",
      "Epoch [1398/2500], Train Loss: 0.8562, Train Accuracy: 61.31%, Test Loss: 0.8761, Test Accuracy: 67.09%\n",
      "Epoch [1399/2500], Train Loss: 0.8863, Train Accuracy: 60.74%, Test Loss: 0.8636, Test Accuracy: 67.09%\n",
      "Epoch [1400/2500], Train Loss: 0.8841, Train Accuracy: 61.02%, Test Loss: 0.8673, Test Accuracy: 64.56%\n",
      "Epoch [1401/2500], Train Loss: 0.8766, Train Accuracy: 58.46%, Test Loss: 0.8772, Test Accuracy: 65.82%\n",
      "Epoch [1402/2500], Train Loss: 0.8737, Train Accuracy: 61.59%, Test Loss: 0.8717, Test Accuracy: 65.82%\n",
      "Epoch [1403/2500], Train Loss: 0.8652, Train Accuracy: 60.74%, Test Loss: 0.8717, Test Accuracy: 64.56%\n",
      "Epoch [1404/2500], Train Loss: 0.8508, Train Accuracy: 62.45%, Test Loss: 0.8777, Test Accuracy: 64.56%\n",
      "Epoch [1405/2500], Train Loss: 0.8738, Train Accuracy: 61.02%, Test Loss: 0.8765, Test Accuracy: 64.56%\n",
      "Epoch [1406/2500], Train Loss: 0.8623, Train Accuracy: 60.74%, Test Loss: 0.8616, Test Accuracy: 63.29%\n",
      "Epoch [1407/2500], Train Loss: 0.8683, Train Accuracy: 61.45%, Test Loss: 0.8602, Test Accuracy: 63.29%\n",
      "Epoch [1408/2500], Train Loss: 0.8775, Train Accuracy: 60.31%, Test Loss: 0.8764, Test Accuracy: 64.56%\n",
      "Epoch [1409/2500], Train Loss: 0.8762, Train Accuracy: 61.59%, Test Loss: 0.8709, Test Accuracy: 64.56%\n",
      "Epoch [1410/2500], Train Loss: 0.8618, Train Accuracy: 61.59%, Test Loss: 0.8744, Test Accuracy: 63.29%\n",
      "Epoch [1411/2500], Train Loss: 0.8600, Train Accuracy: 61.88%, Test Loss: 0.8769, Test Accuracy: 64.56%\n",
      "Epoch [1412/2500], Train Loss: 0.8633, Train Accuracy: 61.17%, Test Loss: 0.8715, Test Accuracy: 64.56%\n",
      "Epoch [1413/2500], Train Loss: 0.8780, Train Accuracy: 59.89%, Test Loss: 0.8744, Test Accuracy: 64.56%\n",
      "Epoch [1414/2500], Train Loss: 0.8521, Train Accuracy: 62.02%, Test Loss: 0.8763, Test Accuracy: 67.09%\n",
      "Epoch [1415/2500], Train Loss: 0.8876, Train Accuracy: 60.46%, Test Loss: 0.8735, Test Accuracy: 65.82%\n",
      "Epoch [1416/2500], Train Loss: 0.8668, Train Accuracy: 61.59%, Test Loss: 0.8759, Test Accuracy: 64.56%\n",
      "Epoch [1417/2500], Train Loss: 0.8659, Train Accuracy: 61.31%, Test Loss: 0.8765, Test Accuracy: 63.29%\n",
      "Epoch [1418/2500], Train Loss: 0.8660, Train Accuracy: 60.31%, Test Loss: 0.8763, Test Accuracy: 64.56%\n",
      "Epoch [1419/2500], Train Loss: 0.8606, Train Accuracy: 60.31%, Test Loss: 0.8729, Test Accuracy: 64.56%\n",
      "Epoch [1420/2500], Train Loss: 0.8573, Train Accuracy: 61.31%, Test Loss: 0.8671, Test Accuracy: 64.56%\n",
      "Epoch [1421/2500], Train Loss: 0.8668, Train Accuracy: 60.17%, Test Loss: 0.8648, Test Accuracy: 65.82%\n",
      "Epoch [1422/2500], Train Loss: 0.8720, Train Accuracy: 61.31%, Test Loss: 0.8700, Test Accuracy: 67.09%\n",
      "Epoch [1423/2500], Train Loss: 0.8717, Train Accuracy: 60.03%, Test Loss: 0.8804, Test Accuracy: 65.82%\n",
      "Epoch [1424/2500], Train Loss: 0.8660, Train Accuracy: 61.17%, Test Loss: 0.8746, Test Accuracy: 65.82%\n",
      "Epoch [1425/2500], Train Loss: 0.8888, Train Accuracy: 60.31%, Test Loss: 0.8816, Test Accuracy: 65.82%\n",
      "Epoch [1426/2500], Train Loss: 0.8855, Train Accuracy: 59.17%, Test Loss: 0.8778, Test Accuracy: 65.82%\n",
      "Epoch [1427/2500], Train Loss: 0.8793, Train Accuracy: 58.89%, Test Loss: 0.8778, Test Accuracy: 65.82%\n",
      "Epoch [1428/2500], Train Loss: 0.8899, Train Accuracy: 60.60%, Test Loss: 0.8851, Test Accuracy: 64.56%\n",
      "Epoch [1429/2500], Train Loss: 0.8582, Train Accuracy: 60.46%, Test Loss: 0.8757, Test Accuracy: 65.82%\n",
      "Epoch [1430/2500], Train Loss: 0.8559, Train Accuracy: 61.31%, Test Loss: 0.8799, Test Accuracy: 65.82%\n",
      "Epoch [1431/2500], Train Loss: 0.8816, Train Accuracy: 59.89%, Test Loss: 0.8800, Test Accuracy: 65.82%\n",
      "Epoch [1432/2500], Train Loss: 0.8859, Train Accuracy: 60.88%, Test Loss: 0.8747, Test Accuracy: 65.82%\n",
      "Epoch [1433/2500], Train Loss: 0.8857, Train Accuracy: 59.46%, Test Loss: 0.8736, Test Accuracy: 64.56%\n",
      "Epoch [1434/2500], Train Loss: 0.8598, Train Accuracy: 62.30%, Test Loss: 0.8708, Test Accuracy: 64.56%\n",
      "Epoch [1435/2500], Train Loss: 0.9031, Train Accuracy: 59.32%, Test Loss: 0.8743, Test Accuracy: 63.29%\n",
      "Epoch [1436/2500], Train Loss: 0.8561, Train Accuracy: 62.73%, Test Loss: 0.8809, Test Accuracy: 63.29%\n",
      "Epoch [1437/2500], Train Loss: 0.8673, Train Accuracy: 60.74%, Test Loss: 0.8779, Test Accuracy: 64.56%\n",
      "Epoch [1438/2500], Train Loss: 0.8725, Train Accuracy: 61.74%, Test Loss: 0.8784, Test Accuracy: 63.29%\n",
      "Epoch [1439/2500], Train Loss: 0.8681, Train Accuracy: 59.89%, Test Loss: 0.8807, Test Accuracy: 63.29%\n",
      "Epoch [1440/2500], Train Loss: 0.8699, Train Accuracy: 61.02%, Test Loss: 0.8792, Test Accuracy: 64.56%\n",
      "Epoch [1441/2500], Train Loss: 0.8626, Train Accuracy: 62.16%, Test Loss: 0.8807, Test Accuracy: 64.56%\n",
      "Epoch [1442/2500], Train Loss: 0.8876, Train Accuracy: 59.17%, Test Loss: 0.8876, Test Accuracy: 64.56%\n",
      "Epoch [1443/2500], Train Loss: 0.8741, Train Accuracy: 63.16%, Test Loss: 0.8831, Test Accuracy: 63.29%\n",
      "Epoch [1444/2500], Train Loss: 0.8553, Train Accuracy: 61.31%, Test Loss: 0.8896, Test Accuracy: 63.29%\n",
      "Epoch [1445/2500], Train Loss: 0.8902, Train Accuracy: 60.60%, Test Loss: 0.8886, Test Accuracy: 63.29%\n",
      "Epoch [1446/2500], Train Loss: 0.8676, Train Accuracy: 61.59%, Test Loss: 0.8832, Test Accuracy: 63.29%\n",
      "Epoch [1447/2500], Train Loss: 0.8729, Train Accuracy: 61.59%, Test Loss: 0.8925, Test Accuracy: 62.03%\n",
      "Epoch [1448/2500], Train Loss: 0.8771, Train Accuracy: 59.74%, Test Loss: 0.8878, Test Accuracy: 63.29%\n",
      "Epoch [1449/2500], Train Loss: 0.8603, Train Accuracy: 60.74%, Test Loss: 0.8825, Test Accuracy: 63.29%\n",
      "Epoch [1450/2500], Train Loss: 0.8627, Train Accuracy: 60.46%, Test Loss: 0.8839, Test Accuracy: 64.56%\n",
      "Epoch [1451/2500], Train Loss: 0.8695, Train Accuracy: 61.31%, Test Loss: 0.8841, Test Accuracy: 64.56%\n",
      "Epoch [1452/2500], Train Loss: 0.8475, Train Accuracy: 60.74%, Test Loss: 0.8829, Test Accuracy: 64.56%\n",
      "Epoch [1453/2500], Train Loss: 0.8690, Train Accuracy: 61.74%, Test Loss: 0.8805, Test Accuracy: 64.56%\n",
      "Epoch [1454/2500], Train Loss: 0.8648, Train Accuracy: 62.59%, Test Loss: 0.8795, Test Accuracy: 64.56%\n",
      "Epoch [1455/2500], Train Loss: 0.8751, Train Accuracy: 61.17%, Test Loss: 0.8827, Test Accuracy: 62.03%\n",
      "Epoch [1456/2500], Train Loss: 0.8589, Train Accuracy: 60.74%, Test Loss: 0.8799, Test Accuracy: 62.03%\n",
      "Epoch [1457/2500], Train Loss: 0.8817, Train Accuracy: 59.60%, Test Loss: 0.8631, Test Accuracy: 62.03%\n",
      "Epoch [1458/2500], Train Loss: 0.8663, Train Accuracy: 61.59%, Test Loss: 0.8614, Test Accuracy: 63.29%\n",
      "Epoch [1459/2500], Train Loss: 0.8788, Train Accuracy: 61.59%, Test Loss: 0.8798, Test Accuracy: 64.56%\n",
      "Epoch [1460/2500], Train Loss: 0.8673, Train Accuracy: 60.17%, Test Loss: 0.8793, Test Accuracy: 63.29%\n",
      "Epoch [1461/2500], Train Loss: 0.8695, Train Accuracy: 60.17%, Test Loss: 0.8843, Test Accuracy: 63.29%\n",
      "Epoch [1462/2500], Train Loss: 0.8779, Train Accuracy: 60.46%, Test Loss: 0.8648, Test Accuracy: 63.29%\n",
      "Epoch [1463/2500], Train Loss: 0.8636, Train Accuracy: 61.59%, Test Loss: 0.8662, Test Accuracy: 63.29%\n",
      "Epoch [1464/2500], Train Loss: 0.8673, Train Accuracy: 58.46%, Test Loss: 0.8778, Test Accuracy: 63.29%\n",
      "Epoch [1465/2500], Train Loss: 0.8711, Train Accuracy: 61.31%, Test Loss: 0.8848, Test Accuracy: 65.82%\n",
      "Epoch [1466/2500], Train Loss: 0.8725, Train Accuracy: 60.88%, Test Loss: 0.8825, Test Accuracy: 64.56%\n",
      "Epoch [1467/2500], Train Loss: 0.8827, Train Accuracy: 59.74%, Test Loss: 0.8851, Test Accuracy: 64.56%\n",
      "Epoch [1468/2500], Train Loss: 0.8896, Train Accuracy: 60.74%, Test Loss: 0.8892, Test Accuracy: 68.35%\n",
      "Epoch [1469/2500], Train Loss: 0.8810, Train Accuracy: 60.60%, Test Loss: 0.8812, Test Accuracy: 65.82%\n",
      "Epoch [1470/2500], Train Loss: 0.8615, Train Accuracy: 61.31%, Test Loss: 0.8877, Test Accuracy: 65.82%\n",
      "Epoch [1471/2500], Train Loss: 0.8385, Train Accuracy: 61.45%, Test Loss: 0.8954, Test Accuracy: 64.56%\n",
      "Epoch [1472/2500], Train Loss: 0.8661, Train Accuracy: 61.02%, Test Loss: 0.8872, Test Accuracy: 65.82%\n",
      "Epoch [1473/2500], Train Loss: 0.8630, Train Accuracy: 61.88%, Test Loss: 0.8840, Test Accuracy: 65.82%\n",
      "Epoch [1474/2500], Train Loss: 0.8692, Train Accuracy: 61.31%, Test Loss: 0.8823, Test Accuracy: 65.82%\n",
      "Epoch [1475/2500], Train Loss: 0.8596, Train Accuracy: 62.59%, Test Loss: 0.8826, Test Accuracy: 65.82%\n",
      "Epoch [1476/2500], Train Loss: 0.8662, Train Accuracy: 61.45%, Test Loss: 0.8831, Test Accuracy: 65.82%\n",
      "Epoch [1477/2500], Train Loss: 0.8706, Train Accuracy: 59.89%, Test Loss: 0.8782, Test Accuracy: 65.82%\n",
      "Epoch [1478/2500], Train Loss: 0.8764, Train Accuracy: 59.46%, Test Loss: 0.8782, Test Accuracy: 65.82%\n",
      "Epoch [1479/2500], Train Loss: 0.8552, Train Accuracy: 61.59%, Test Loss: 0.8792, Test Accuracy: 65.82%\n",
      "Epoch [1480/2500], Train Loss: 0.8705, Train Accuracy: 61.88%, Test Loss: 0.8816, Test Accuracy: 64.56%\n",
      "Epoch [1481/2500], Train Loss: 0.8598, Train Accuracy: 60.46%, Test Loss: 0.8782, Test Accuracy: 65.82%\n",
      "Epoch [1482/2500], Train Loss: 0.8725, Train Accuracy: 62.16%, Test Loss: 0.8721, Test Accuracy: 64.56%\n",
      "Epoch [1483/2500], Train Loss: 0.8646, Train Accuracy: 60.46%, Test Loss: 0.8721, Test Accuracy: 63.29%\n",
      "Epoch [1484/2500], Train Loss: 0.8659, Train Accuracy: 62.02%, Test Loss: 0.8633, Test Accuracy: 63.29%\n",
      "Epoch [1485/2500], Train Loss: 0.8581, Train Accuracy: 61.02%, Test Loss: 0.8707, Test Accuracy: 64.56%\n",
      "Epoch [1486/2500], Train Loss: 0.8743, Train Accuracy: 61.45%, Test Loss: 0.8577, Test Accuracy: 64.56%\n",
      "Epoch [1487/2500], Train Loss: 0.8689, Train Accuracy: 60.17%, Test Loss: 0.8656, Test Accuracy: 64.56%\n",
      "Epoch [1488/2500], Train Loss: 0.8701, Train Accuracy: 61.17%, Test Loss: 0.8701, Test Accuracy: 65.82%\n",
      "Epoch [1489/2500], Train Loss: 0.8571, Train Accuracy: 62.45%, Test Loss: 0.8540, Test Accuracy: 64.56%\n",
      "Epoch [1490/2500], Train Loss: 0.8813, Train Accuracy: 59.60%, Test Loss: 0.8649, Test Accuracy: 67.09%\n",
      "Epoch [1491/2500], Train Loss: 0.8849, Train Accuracy: 59.89%, Test Loss: 0.8683, Test Accuracy: 65.82%\n",
      "Epoch [1492/2500], Train Loss: 0.8708, Train Accuracy: 60.74%, Test Loss: 0.8759, Test Accuracy: 65.82%\n",
      "Epoch [1493/2500], Train Loss: 0.8779, Train Accuracy: 61.88%, Test Loss: 0.8731, Test Accuracy: 64.56%\n",
      "Epoch [1494/2500], Train Loss: 0.8691, Train Accuracy: 61.17%, Test Loss: 0.8854, Test Accuracy: 67.09%\n",
      "Epoch [1495/2500], Train Loss: 0.8719, Train Accuracy: 60.74%, Test Loss: 0.8869, Test Accuracy: 67.09%\n",
      "Epoch [1496/2500], Train Loss: 0.8502, Train Accuracy: 60.46%, Test Loss: 0.8870, Test Accuracy: 65.82%\n",
      "Epoch [1497/2500], Train Loss: 0.8604, Train Accuracy: 60.88%, Test Loss: 0.8895, Test Accuracy: 67.09%\n",
      "Epoch [1498/2500], Train Loss: 0.8672, Train Accuracy: 61.17%, Test Loss: 0.8770, Test Accuracy: 65.82%\n",
      "Epoch [1499/2500], Train Loss: 0.8755, Train Accuracy: 60.03%, Test Loss: 0.8787, Test Accuracy: 65.82%\n",
      "Epoch [1500/2500], Train Loss: 0.8683, Train Accuracy: 61.02%, Test Loss: 0.8756, Test Accuracy: 63.29%\n",
      "Epoch [1501/2500], Train Loss: 0.8782, Train Accuracy: 60.88%, Test Loss: 0.8855, Test Accuracy: 65.82%\n",
      "Epoch [1502/2500], Train Loss: 0.8605, Train Accuracy: 61.45%, Test Loss: 0.8764, Test Accuracy: 64.56%\n",
      "Epoch [1503/2500], Train Loss: 0.8603, Train Accuracy: 59.74%, Test Loss: 0.8780, Test Accuracy: 65.82%\n",
      "Epoch [1504/2500], Train Loss: 0.8656, Train Accuracy: 60.88%, Test Loss: 0.8786, Test Accuracy: 65.82%\n",
      "Epoch [1505/2500], Train Loss: 0.8531, Train Accuracy: 63.16%, Test Loss: 0.8763, Test Accuracy: 64.56%\n",
      "Epoch [1506/2500], Train Loss: 0.8584, Train Accuracy: 62.59%, Test Loss: 0.8675, Test Accuracy: 65.82%\n",
      "Epoch [1507/2500], Train Loss: 0.8650, Train Accuracy: 62.45%, Test Loss: 0.8705, Test Accuracy: 65.82%\n",
      "Epoch [1508/2500], Train Loss: 0.8645, Train Accuracy: 61.17%, Test Loss: 0.8768, Test Accuracy: 64.56%\n",
      "Epoch [1509/2500], Train Loss: 0.8757, Train Accuracy: 59.17%, Test Loss: 0.8832, Test Accuracy: 63.29%\n",
      "Epoch [1510/2500], Train Loss: 0.8748, Train Accuracy: 60.03%, Test Loss: 0.8824, Test Accuracy: 64.56%\n",
      "Epoch [1511/2500], Train Loss: 0.8454, Train Accuracy: 64.44%, Test Loss: 0.8820, Test Accuracy: 63.29%\n",
      "Epoch [1512/2500], Train Loss: 0.8644, Train Accuracy: 60.74%, Test Loss: 0.8819, Test Accuracy: 62.03%\n",
      "Epoch [1513/2500], Train Loss: 0.8562, Train Accuracy: 61.17%, Test Loss: 0.8776, Test Accuracy: 63.29%\n",
      "Epoch [1514/2500], Train Loss: 0.8727, Train Accuracy: 61.02%, Test Loss: 0.8812, Test Accuracy: 63.29%\n",
      "Epoch [1515/2500], Train Loss: 0.8667, Train Accuracy: 61.17%, Test Loss: 0.8800, Test Accuracy: 63.29%\n",
      "Epoch [1516/2500], Train Loss: 0.8746, Train Accuracy: 60.17%, Test Loss: 0.8741, Test Accuracy: 63.29%\n",
      "Epoch [1517/2500], Train Loss: 0.8636, Train Accuracy: 58.89%, Test Loss: 0.8695, Test Accuracy: 63.29%\n",
      "Epoch [1518/2500], Train Loss: 0.8587, Train Accuracy: 61.59%, Test Loss: 0.8792, Test Accuracy: 64.56%\n",
      "Epoch [1519/2500], Train Loss: 0.8669, Train Accuracy: 61.88%, Test Loss: 0.8758, Test Accuracy: 64.56%\n",
      "Epoch [1520/2500], Train Loss: 0.8554, Train Accuracy: 61.59%, Test Loss: 0.8880, Test Accuracy: 64.56%\n",
      "Epoch [1521/2500], Train Loss: 0.8778, Train Accuracy: 60.88%, Test Loss: 0.8837, Test Accuracy: 65.82%\n",
      "Epoch [1522/2500], Train Loss: 0.8662, Train Accuracy: 61.31%, Test Loss: 0.8772, Test Accuracy: 64.56%\n",
      "Epoch [1523/2500], Train Loss: 0.8599, Train Accuracy: 59.46%, Test Loss: 0.8757, Test Accuracy: 65.82%\n",
      "Epoch [1524/2500], Train Loss: 0.8849, Train Accuracy: 59.46%, Test Loss: 0.8751, Test Accuracy: 63.29%\n",
      "Epoch [1525/2500], Train Loss: 0.8614, Train Accuracy: 60.17%, Test Loss: 0.8760, Test Accuracy: 63.29%\n",
      "Epoch [1526/2500], Train Loss: 0.8812, Train Accuracy: 62.30%, Test Loss: 0.8670, Test Accuracy: 64.56%\n",
      "Epoch [1527/2500], Train Loss: 0.8432, Train Accuracy: 61.88%, Test Loss: 0.8650, Test Accuracy: 63.29%\n",
      "Epoch [1528/2500], Train Loss: 0.8611, Train Accuracy: 60.46%, Test Loss: 0.8674, Test Accuracy: 63.29%\n",
      "Epoch [1529/2500], Train Loss: 0.8532, Train Accuracy: 61.45%, Test Loss: 0.8828, Test Accuracy: 62.03%\n",
      "Epoch [1530/2500], Train Loss: 0.8737, Train Accuracy: 60.60%, Test Loss: 0.8671, Test Accuracy: 64.56%\n",
      "Epoch [1531/2500], Train Loss: 0.8518, Train Accuracy: 60.74%, Test Loss: 0.8601, Test Accuracy: 64.56%\n",
      "Epoch [1532/2500], Train Loss: 0.8650, Train Accuracy: 61.02%, Test Loss: 0.8652, Test Accuracy: 64.56%\n",
      "Epoch [1533/2500], Train Loss: 0.8654, Train Accuracy: 61.02%, Test Loss: 0.8676, Test Accuracy: 63.29%\n",
      "Epoch [1534/2500], Train Loss: 0.8455, Train Accuracy: 61.88%, Test Loss: 0.8714, Test Accuracy: 64.56%\n",
      "Epoch [1535/2500], Train Loss: 0.8717, Train Accuracy: 60.60%, Test Loss: 0.8598, Test Accuracy: 62.03%\n",
      "Epoch [1536/2500], Train Loss: 0.8863, Train Accuracy: 61.45%, Test Loss: 0.8668, Test Accuracy: 64.56%\n",
      "Epoch [1537/2500], Train Loss: 0.8795, Train Accuracy: 59.89%, Test Loss: 0.8710, Test Accuracy: 64.56%\n",
      "Epoch [1538/2500], Train Loss: 0.8795, Train Accuracy: 58.61%, Test Loss: 0.8777, Test Accuracy: 65.82%\n",
      "Epoch [1539/2500], Train Loss: 0.8528, Train Accuracy: 61.45%, Test Loss: 0.8734, Test Accuracy: 64.56%\n",
      "Epoch [1540/2500], Train Loss: 0.8667, Train Accuracy: 62.45%, Test Loss: 0.8773, Test Accuracy: 63.29%\n",
      "Epoch [1541/2500], Train Loss: 0.8552, Train Accuracy: 61.45%, Test Loss: 0.8691, Test Accuracy: 64.56%\n",
      "Epoch [1542/2500], Train Loss: 0.8718, Train Accuracy: 61.74%, Test Loss: 0.8754, Test Accuracy: 64.56%\n",
      "Epoch [1543/2500], Train Loss: 0.8683, Train Accuracy: 60.31%, Test Loss: 0.8788, Test Accuracy: 65.82%\n",
      "Epoch [1544/2500], Train Loss: 0.8670, Train Accuracy: 60.03%, Test Loss: 0.8777, Test Accuracy: 64.56%\n",
      "Epoch [1545/2500], Train Loss: 0.8808, Train Accuracy: 61.02%, Test Loss: 0.8738, Test Accuracy: 63.29%\n",
      "Epoch [1546/2500], Train Loss: 0.8617, Train Accuracy: 60.88%, Test Loss: 0.8766, Test Accuracy: 62.03%\n",
      "Epoch [1547/2500], Train Loss: 0.8493, Train Accuracy: 61.74%, Test Loss: 0.8774, Test Accuracy: 63.29%\n",
      "Epoch [1548/2500], Train Loss: 0.8812, Train Accuracy: 59.89%, Test Loss: 0.8678, Test Accuracy: 64.56%\n",
      "Epoch [1549/2500], Train Loss: 0.8634, Train Accuracy: 61.59%, Test Loss: 0.8786, Test Accuracy: 63.29%\n",
      "Epoch [1550/2500], Train Loss: 0.8628, Train Accuracy: 61.45%, Test Loss: 0.8807, Test Accuracy: 64.56%\n",
      "Epoch [1551/2500], Train Loss: 0.8645, Train Accuracy: 62.73%, Test Loss: 0.8798, Test Accuracy: 64.56%\n",
      "Epoch [1552/2500], Train Loss: 0.8647, Train Accuracy: 62.16%, Test Loss: 0.8796, Test Accuracy: 65.82%\n",
      "Epoch [1553/2500], Train Loss: 0.8659, Train Accuracy: 61.59%, Test Loss: 0.8775, Test Accuracy: 65.82%\n",
      "Epoch [1554/2500], Train Loss: 0.8550, Train Accuracy: 60.31%, Test Loss: 0.8732, Test Accuracy: 65.82%\n",
      "Epoch [1555/2500], Train Loss: 0.8421, Train Accuracy: 61.59%, Test Loss: 0.8765, Test Accuracy: 65.82%\n",
      "Epoch [1556/2500], Train Loss: 0.8526, Train Accuracy: 61.88%, Test Loss: 0.8791, Test Accuracy: 65.82%\n",
      "Epoch [1557/2500], Train Loss: 0.8548, Train Accuracy: 61.31%, Test Loss: 0.8764, Test Accuracy: 64.56%\n",
      "Epoch [1558/2500], Train Loss: 0.8735, Train Accuracy: 61.02%, Test Loss: 0.8852, Test Accuracy: 67.09%\n",
      "Epoch [1559/2500], Train Loss: 0.8559, Train Accuracy: 61.02%, Test Loss: 0.8750, Test Accuracy: 64.56%\n",
      "Epoch [1560/2500], Train Loss: 0.8493, Train Accuracy: 61.31%, Test Loss: 0.8736, Test Accuracy: 63.29%\n",
      "Epoch [1561/2500], Train Loss: 0.8526, Train Accuracy: 61.74%, Test Loss: 0.8704, Test Accuracy: 65.82%\n",
      "Epoch [1562/2500], Train Loss: 0.8650, Train Accuracy: 60.46%, Test Loss: 0.8711, Test Accuracy: 63.29%\n",
      "Epoch [1563/2500], Train Loss: 0.8733, Train Accuracy: 61.31%, Test Loss: 0.8727, Test Accuracy: 64.56%\n",
      "Epoch [1564/2500], Train Loss: 0.8672, Train Accuracy: 60.60%, Test Loss: 0.8755, Test Accuracy: 65.82%\n",
      "Epoch [1565/2500], Train Loss: 0.8579, Train Accuracy: 60.17%, Test Loss: 0.8726, Test Accuracy: 65.82%\n",
      "Epoch [1566/2500], Train Loss: 0.8606, Train Accuracy: 60.60%, Test Loss: 0.8690, Test Accuracy: 64.56%\n",
      "Epoch [1567/2500], Train Loss: 0.8489, Train Accuracy: 61.31%, Test Loss: 0.8699, Test Accuracy: 67.09%\n",
      "Epoch [1568/2500], Train Loss: 0.8686, Train Accuracy: 60.60%, Test Loss: 0.8666, Test Accuracy: 67.09%\n",
      "Epoch [1569/2500], Train Loss: 0.8574, Train Accuracy: 61.02%, Test Loss: 0.8522, Test Accuracy: 64.56%\n",
      "Epoch [1570/2500], Train Loss: 0.8592, Train Accuracy: 60.60%, Test Loss: 0.8688, Test Accuracy: 64.56%\n",
      "Epoch [1571/2500], Train Loss: 0.8536, Train Accuracy: 60.74%, Test Loss: 0.8699, Test Accuracy: 64.56%\n",
      "Epoch [1572/2500], Train Loss: 0.8540, Train Accuracy: 63.02%, Test Loss: 0.8685, Test Accuracy: 64.56%\n",
      "Epoch [1573/2500], Train Loss: 0.8723, Train Accuracy: 62.73%, Test Loss: 0.8709, Test Accuracy: 64.56%\n",
      "Epoch [1574/2500], Train Loss: 0.8590, Train Accuracy: 60.46%, Test Loss: 0.8655, Test Accuracy: 65.82%\n",
      "Epoch [1575/2500], Train Loss: 0.8485, Train Accuracy: 62.45%, Test Loss: 0.8607, Test Accuracy: 65.82%\n",
      "Epoch [1576/2500], Train Loss: 0.8682, Train Accuracy: 60.17%, Test Loss: 0.8697, Test Accuracy: 67.09%\n",
      "Epoch [1577/2500], Train Loss: 0.8589, Train Accuracy: 60.17%, Test Loss: 0.8734, Test Accuracy: 65.82%\n",
      "Epoch [1578/2500], Train Loss: 0.8564, Train Accuracy: 61.59%, Test Loss: 0.8714, Test Accuracy: 65.82%\n",
      "Epoch [1579/2500], Train Loss: 0.8528, Train Accuracy: 61.59%, Test Loss: 0.8673, Test Accuracy: 64.56%\n",
      "Epoch [1580/2500], Train Loss: 0.8469, Train Accuracy: 60.74%, Test Loss: 0.8636, Test Accuracy: 64.56%\n",
      "Epoch [1581/2500], Train Loss: 0.8523, Train Accuracy: 62.02%, Test Loss: 0.8639, Test Accuracy: 64.56%\n",
      "Epoch [1582/2500], Train Loss: 0.8632, Train Accuracy: 61.74%, Test Loss: 0.8745, Test Accuracy: 65.82%\n",
      "Epoch [1583/2500], Train Loss: 0.8683, Train Accuracy: 62.16%, Test Loss: 0.8738, Test Accuracy: 67.09%\n",
      "Epoch [1584/2500], Train Loss: 0.8554, Train Accuracy: 60.03%, Test Loss: 0.8710, Test Accuracy: 65.82%\n",
      "Epoch [1585/2500], Train Loss: 0.8520, Train Accuracy: 61.88%, Test Loss: 0.8721, Test Accuracy: 65.82%\n",
      "Epoch [1586/2500], Train Loss: 0.8783, Train Accuracy: 61.02%, Test Loss: 0.8741, Test Accuracy: 65.82%\n",
      "Epoch [1587/2500], Train Loss: 0.8734, Train Accuracy: 60.03%, Test Loss: 0.8760, Test Accuracy: 67.09%\n",
      "Epoch [1588/2500], Train Loss: 0.8677, Train Accuracy: 60.74%, Test Loss: 0.8669, Test Accuracy: 67.09%\n",
      "Epoch [1589/2500], Train Loss: 0.8552, Train Accuracy: 60.60%, Test Loss: 0.8586, Test Accuracy: 67.09%\n",
      "Epoch [1590/2500], Train Loss: 0.8608, Train Accuracy: 62.59%, Test Loss: 0.8540, Test Accuracy: 64.56%\n",
      "Epoch [1591/2500], Train Loss: 0.8655, Train Accuracy: 59.74%, Test Loss: 0.8616, Test Accuracy: 65.82%\n",
      "Epoch [1592/2500], Train Loss: 0.8622, Train Accuracy: 60.17%, Test Loss: 0.8611, Test Accuracy: 65.82%\n",
      "Epoch [1593/2500], Train Loss: 0.8618, Train Accuracy: 58.89%, Test Loss: 0.8590, Test Accuracy: 65.82%\n",
      "Epoch [1594/2500], Train Loss: 0.8653, Train Accuracy: 60.31%, Test Loss: 0.8588, Test Accuracy: 64.56%\n",
      "Epoch [1595/2500], Train Loss: 0.8550, Train Accuracy: 62.87%, Test Loss: 0.8593, Test Accuracy: 65.82%\n",
      "Epoch [1596/2500], Train Loss: 0.8741, Train Accuracy: 63.73%, Test Loss: 0.8547, Test Accuracy: 65.82%\n",
      "Epoch [1597/2500], Train Loss: 0.8453, Train Accuracy: 61.74%, Test Loss: 0.8569, Test Accuracy: 65.82%\n",
      "Epoch [1598/2500], Train Loss: 0.8672, Train Accuracy: 60.60%, Test Loss: 0.8584, Test Accuracy: 65.82%\n",
      "Epoch [1599/2500], Train Loss: 0.8528, Train Accuracy: 61.02%, Test Loss: 0.8669, Test Accuracy: 64.56%\n",
      "Epoch [1600/2500], Train Loss: 0.8552, Train Accuracy: 61.02%, Test Loss: 0.8714, Test Accuracy: 63.29%\n",
      "Epoch [1601/2500], Train Loss: 0.8630, Train Accuracy: 61.17%, Test Loss: 0.8674, Test Accuracy: 65.82%\n",
      "Epoch [1602/2500], Train Loss: 0.8422, Train Accuracy: 61.45%, Test Loss: 0.8611, Test Accuracy: 64.56%\n",
      "Epoch [1603/2500], Train Loss: 0.8593, Train Accuracy: 60.17%, Test Loss: 0.8651, Test Accuracy: 67.09%\n",
      "Epoch [1604/2500], Train Loss: 0.8532, Train Accuracy: 62.16%, Test Loss: 0.8658, Test Accuracy: 65.82%\n",
      "Epoch [1605/2500], Train Loss: 0.8514, Train Accuracy: 61.88%, Test Loss: 0.8612, Test Accuracy: 67.09%\n",
      "Epoch [1606/2500], Train Loss: 0.8577, Train Accuracy: 61.17%, Test Loss: 0.8657, Test Accuracy: 64.56%\n",
      "Epoch [1607/2500], Train Loss: 0.8631, Train Accuracy: 62.02%, Test Loss: 0.8694, Test Accuracy: 65.82%\n",
      "Epoch [1608/2500], Train Loss: 0.8643, Train Accuracy: 59.46%, Test Loss: 0.8654, Test Accuracy: 65.82%\n",
      "Epoch [1609/2500], Train Loss: 0.8787, Train Accuracy: 60.03%, Test Loss: 0.8655, Test Accuracy: 64.56%\n",
      "Epoch [1610/2500], Train Loss: 0.8728, Train Accuracy: 59.89%, Test Loss: 0.8623, Test Accuracy: 65.82%\n",
      "Epoch [1611/2500], Train Loss: 0.8528, Train Accuracy: 62.02%, Test Loss: 0.8667, Test Accuracy: 65.82%\n",
      "Epoch [1612/2500], Train Loss: 0.8612, Train Accuracy: 61.88%, Test Loss: 0.8616, Test Accuracy: 67.09%\n",
      "Epoch [1613/2500], Train Loss: 0.8560, Train Accuracy: 61.74%, Test Loss: 0.8655, Test Accuracy: 67.09%\n",
      "Epoch [1614/2500], Train Loss: 0.8589, Train Accuracy: 60.17%, Test Loss: 0.8543, Test Accuracy: 67.09%\n",
      "Epoch [1615/2500], Train Loss: 0.8748, Train Accuracy: 60.60%, Test Loss: 0.8590, Test Accuracy: 65.82%\n",
      "Epoch [1616/2500], Train Loss: 0.8666, Train Accuracy: 61.59%, Test Loss: 0.8497, Test Accuracy: 67.09%\n",
      "Epoch [1617/2500], Train Loss: 0.8495, Train Accuracy: 62.87%, Test Loss: 0.8425, Test Accuracy: 65.82%\n",
      "Epoch [1618/2500], Train Loss: 0.8788, Train Accuracy: 60.88%, Test Loss: 0.8544, Test Accuracy: 65.82%\n",
      "Epoch [1619/2500], Train Loss: 0.8656, Train Accuracy: 59.60%, Test Loss: 0.8565, Test Accuracy: 64.56%\n",
      "Epoch [1620/2500], Train Loss: 0.8662, Train Accuracy: 61.17%, Test Loss: 0.8547, Test Accuracy: 65.82%\n",
      "Epoch [1621/2500], Train Loss: 0.8550, Train Accuracy: 62.59%, Test Loss: 0.8698, Test Accuracy: 64.56%\n",
      "Epoch [1622/2500], Train Loss: 0.8404, Train Accuracy: 61.74%, Test Loss: 0.8813, Test Accuracy: 64.56%\n",
      "Epoch [1623/2500], Train Loss: 0.8590, Train Accuracy: 60.03%, Test Loss: 0.8718, Test Accuracy: 65.82%\n",
      "Epoch [1624/2500], Train Loss: 0.8587, Train Accuracy: 61.31%, Test Loss: 0.8579, Test Accuracy: 64.56%\n",
      "Epoch [1625/2500], Train Loss: 0.8537, Train Accuracy: 61.45%, Test Loss: 0.8619, Test Accuracy: 64.56%\n",
      "Epoch [1626/2500], Train Loss: 0.8592, Train Accuracy: 60.60%, Test Loss: 0.8582, Test Accuracy: 64.56%\n",
      "Epoch [1627/2500], Train Loss: 0.8386, Train Accuracy: 61.74%, Test Loss: 0.8634, Test Accuracy: 65.82%\n",
      "Epoch [1628/2500], Train Loss: 0.8563, Train Accuracy: 61.74%, Test Loss: 0.8675, Test Accuracy: 65.82%\n",
      "Epoch [1629/2500], Train Loss: 0.8524, Train Accuracy: 61.45%, Test Loss: 0.8585, Test Accuracy: 65.82%\n",
      "Epoch [1630/2500], Train Loss: 0.8600, Train Accuracy: 62.30%, Test Loss: 0.8677, Test Accuracy: 64.56%\n",
      "Epoch [1631/2500], Train Loss: 0.8670, Train Accuracy: 60.60%, Test Loss: 0.8631, Test Accuracy: 64.56%\n",
      "Epoch [1632/2500], Train Loss: 0.8565, Train Accuracy: 61.88%, Test Loss: 0.8738, Test Accuracy: 64.56%\n",
      "Epoch [1633/2500], Train Loss: 0.8469, Train Accuracy: 62.02%, Test Loss: 0.8740, Test Accuracy: 64.56%\n",
      "Epoch [1634/2500], Train Loss: 0.8525, Train Accuracy: 61.59%, Test Loss: 0.8674, Test Accuracy: 64.56%\n",
      "Epoch [1635/2500], Train Loss: 0.8422, Train Accuracy: 61.59%, Test Loss: 0.8721, Test Accuracy: 64.56%\n",
      "Epoch [1636/2500], Train Loss: 0.8554, Train Accuracy: 61.17%, Test Loss: 0.8662, Test Accuracy: 64.56%\n",
      "Epoch [1637/2500], Train Loss: 0.8523, Train Accuracy: 60.74%, Test Loss: 0.8619, Test Accuracy: 64.56%\n",
      "Epoch [1638/2500], Train Loss: 0.8656, Train Accuracy: 59.46%, Test Loss: 0.8726, Test Accuracy: 65.82%\n",
      "Epoch [1639/2500], Train Loss: 0.8621, Train Accuracy: 60.60%, Test Loss: 0.8568, Test Accuracy: 65.82%\n",
      "Epoch [1640/2500], Train Loss: 0.8571, Train Accuracy: 61.74%, Test Loss: 0.8659, Test Accuracy: 67.09%\n",
      "Epoch [1641/2500], Train Loss: 0.8497, Train Accuracy: 63.16%, Test Loss: 0.8700, Test Accuracy: 65.82%\n",
      "Epoch [1642/2500], Train Loss: 0.8612, Train Accuracy: 60.88%, Test Loss: 0.8704, Test Accuracy: 65.82%\n",
      "Epoch [1643/2500], Train Loss: 0.8531, Train Accuracy: 61.59%, Test Loss: 0.8551, Test Accuracy: 64.56%\n",
      "Epoch [1644/2500], Train Loss: 0.8481, Train Accuracy: 61.45%, Test Loss: 0.8508, Test Accuracy: 64.56%\n",
      "Epoch [1645/2500], Train Loss: 0.8518, Train Accuracy: 61.88%, Test Loss: 0.8674, Test Accuracy: 64.56%\n",
      "Epoch [1646/2500], Train Loss: 0.8611, Train Accuracy: 61.59%, Test Loss: 0.8790, Test Accuracy: 65.82%\n",
      "Epoch [1647/2500], Train Loss: 0.8498, Train Accuracy: 60.03%, Test Loss: 0.8598, Test Accuracy: 65.82%\n",
      "Epoch [1648/2500], Train Loss: 0.8480, Train Accuracy: 61.02%, Test Loss: 0.8625, Test Accuracy: 65.82%\n",
      "Epoch [1649/2500], Train Loss: 0.8473, Train Accuracy: 61.88%, Test Loss: 0.8711, Test Accuracy: 65.82%\n",
      "Epoch [1650/2500], Train Loss: 0.8698, Train Accuracy: 60.17%, Test Loss: 0.8669, Test Accuracy: 67.09%\n",
      "Epoch [1651/2500], Train Loss: 0.8546, Train Accuracy: 62.16%, Test Loss: 0.8703, Test Accuracy: 65.82%\n",
      "Epoch [1652/2500], Train Loss: 0.8499, Train Accuracy: 62.16%, Test Loss: 0.8607, Test Accuracy: 65.82%\n",
      "Epoch [1653/2500], Train Loss: 0.8373, Train Accuracy: 62.02%, Test Loss: 0.8587, Test Accuracy: 65.82%\n",
      "Epoch [1654/2500], Train Loss: 0.8515, Train Accuracy: 61.17%, Test Loss: 0.8604, Test Accuracy: 67.09%\n",
      "Epoch [1655/2500], Train Loss: 0.8335, Train Accuracy: 63.30%, Test Loss: 0.8545, Test Accuracy: 65.82%\n",
      "Epoch [1656/2500], Train Loss: 0.8534, Train Accuracy: 63.16%, Test Loss: 0.8639, Test Accuracy: 64.56%\n",
      "Epoch [1657/2500], Train Loss: 0.8528, Train Accuracy: 63.02%, Test Loss: 0.8641, Test Accuracy: 64.56%\n",
      "Epoch [1658/2500], Train Loss: 0.8535, Train Accuracy: 61.02%, Test Loss: 0.8665, Test Accuracy: 65.82%\n",
      "Epoch [1659/2500], Train Loss: 0.8570, Train Accuracy: 60.17%, Test Loss: 0.8542, Test Accuracy: 64.56%\n",
      "Epoch [1660/2500], Train Loss: 0.8512, Train Accuracy: 61.17%, Test Loss: 0.8621, Test Accuracy: 64.56%\n",
      "Epoch [1661/2500], Train Loss: 0.8513, Train Accuracy: 62.16%, Test Loss: 0.8565, Test Accuracy: 64.56%\n",
      "Epoch [1662/2500], Train Loss: 0.8512, Train Accuracy: 60.74%, Test Loss: 0.8527, Test Accuracy: 64.56%\n",
      "Epoch [1663/2500], Train Loss: 0.8396, Train Accuracy: 62.16%, Test Loss: 0.8555, Test Accuracy: 64.56%\n",
      "Epoch [1664/2500], Train Loss: 0.8607, Train Accuracy: 59.89%, Test Loss: 0.8588, Test Accuracy: 64.56%\n",
      "Epoch [1665/2500], Train Loss: 0.8487, Train Accuracy: 60.74%, Test Loss: 0.8682, Test Accuracy: 64.56%\n",
      "Epoch [1666/2500], Train Loss: 0.8383, Train Accuracy: 63.16%, Test Loss: 0.8615, Test Accuracy: 63.29%\n",
      "Epoch [1667/2500], Train Loss: 0.8516, Train Accuracy: 62.02%, Test Loss: 0.8440, Test Accuracy: 64.56%\n",
      "Epoch [1668/2500], Train Loss: 0.8580, Train Accuracy: 61.74%, Test Loss: 0.8539, Test Accuracy: 65.82%\n",
      "Epoch [1669/2500], Train Loss: 0.8548, Train Accuracy: 61.88%, Test Loss: 0.8543, Test Accuracy: 65.82%\n",
      "Epoch [1670/2500], Train Loss: 0.8483, Train Accuracy: 60.88%, Test Loss: 0.8521, Test Accuracy: 64.56%\n",
      "Epoch [1671/2500], Train Loss: 0.8568, Train Accuracy: 60.46%, Test Loss: 0.8534, Test Accuracy: 64.56%\n",
      "Epoch [1672/2500], Train Loss: 0.8590, Train Accuracy: 60.46%, Test Loss: 0.8521, Test Accuracy: 63.29%\n",
      "Epoch [1673/2500], Train Loss: 0.8750, Train Accuracy: 61.74%, Test Loss: 0.8559, Test Accuracy: 64.56%\n",
      "Epoch [1674/2500], Train Loss: 0.8418, Train Accuracy: 61.88%, Test Loss: 0.8546, Test Accuracy: 64.56%\n",
      "Epoch [1675/2500], Train Loss: 0.8573, Train Accuracy: 61.31%, Test Loss: 0.8526, Test Accuracy: 64.56%\n",
      "Epoch [1676/2500], Train Loss: 0.8582, Train Accuracy: 60.17%, Test Loss: 0.8608, Test Accuracy: 64.56%\n",
      "Epoch [1677/2500], Train Loss: 0.8432, Train Accuracy: 61.17%, Test Loss: 0.8510, Test Accuracy: 63.29%\n",
      "Epoch [1678/2500], Train Loss: 0.8503, Train Accuracy: 60.46%, Test Loss: 0.8611, Test Accuracy: 64.56%\n",
      "Epoch [1679/2500], Train Loss: 0.8598, Train Accuracy: 59.74%, Test Loss: 0.8662, Test Accuracy: 64.56%\n",
      "Epoch [1680/2500], Train Loss: 0.8538, Train Accuracy: 61.74%, Test Loss: 0.8492, Test Accuracy: 63.29%\n",
      "Epoch [1681/2500], Train Loss: 0.8565, Train Accuracy: 61.45%, Test Loss: 0.8488, Test Accuracy: 63.29%\n",
      "Epoch [1682/2500], Train Loss: 0.8397, Train Accuracy: 62.45%, Test Loss: 0.8593, Test Accuracy: 63.29%\n",
      "Epoch [1683/2500], Train Loss: 0.8624, Train Accuracy: 59.60%, Test Loss: 0.8647, Test Accuracy: 64.56%\n",
      "Epoch [1684/2500], Train Loss: 0.8512, Train Accuracy: 61.88%, Test Loss: 0.8635, Test Accuracy: 63.29%\n",
      "Epoch [1685/2500], Train Loss: 0.8623, Train Accuracy: 60.74%, Test Loss: 0.8613, Test Accuracy: 63.29%\n",
      "Epoch [1686/2500], Train Loss: 0.8517, Train Accuracy: 62.73%, Test Loss: 0.8556, Test Accuracy: 64.56%\n",
      "Epoch [1687/2500], Train Loss: 0.8629, Train Accuracy: 60.88%, Test Loss: 0.8560, Test Accuracy: 63.29%\n",
      "Epoch [1688/2500], Train Loss: 0.8601, Train Accuracy: 61.31%, Test Loss: 0.8571, Test Accuracy: 64.56%\n",
      "Epoch [1689/2500], Train Loss: 0.8650, Train Accuracy: 60.74%, Test Loss: 0.8548, Test Accuracy: 63.29%\n",
      "Epoch [1690/2500], Train Loss: 0.8506, Train Accuracy: 62.02%, Test Loss: 0.8528, Test Accuracy: 63.29%\n",
      "Epoch [1691/2500], Train Loss: 0.8594, Train Accuracy: 61.45%, Test Loss: 0.8523, Test Accuracy: 64.56%\n",
      "Epoch [1692/2500], Train Loss: 0.8322, Train Accuracy: 62.45%, Test Loss: 0.8582, Test Accuracy: 65.82%\n",
      "Epoch [1693/2500], Train Loss: 0.8468, Train Accuracy: 61.74%, Test Loss: 0.8524, Test Accuracy: 64.56%\n",
      "Epoch [1694/2500], Train Loss: 0.8556, Train Accuracy: 61.31%, Test Loss: 0.8613, Test Accuracy: 65.82%\n",
      "Epoch [1695/2500], Train Loss: 0.8569, Train Accuracy: 61.74%, Test Loss: 0.8608, Test Accuracy: 65.82%\n",
      "Epoch [1696/2500], Train Loss: 0.8532, Train Accuracy: 62.16%, Test Loss: 0.8600, Test Accuracy: 64.56%\n",
      "Epoch [1697/2500], Train Loss: 0.8613, Train Accuracy: 60.74%, Test Loss: 0.8579, Test Accuracy: 64.56%\n",
      "Epoch [1698/2500], Train Loss: 0.8402, Train Accuracy: 62.45%, Test Loss: 0.8552, Test Accuracy: 64.56%\n",
      "Epoch [1699/2500], Train Loss: 0.8451, Train Accuracy: 60.88%, Test Loss: 0.8446, Test Accuracy: 64.56%\n",
      "Epoch [1700/2500], Train Loss: 0.8487, Train Accuracy: 60.60%, Test Loss: 0.8438, Test Accuracy: 64.56%\n",
      "Epoch [1701/2500], Train Loss: 0.8544, Train Accuracy: 59.74%, Test Loss: 0.8431, Test Accuracy: 64.56%\n",
      "Epoch [1702/2500], Train Loss: 0.8472, Train Accuracy: 61.02%, Test Loss: 0.8457, Test Accuracy: 65.82%\n",
      "Epoch [1703/2500], Train Loss: 0.8583, Train Accuracy: 62.59%, Test Loss: 0.8504, Test Accuracy: 65.82%\n",
      "Epoch [1704/2500], Train Loss: 0.8357, Train Accuracy: 62.73%, Test Loss: 0.8448, Test Accuracy: 67.09%\n",
      "Epoch [1705/2500], Train Loss: 0.8670, Train Accuracy: 60.17%, Test Loss: 0.8482, Test Accuracy: 65.82%\n",
      "Epoch [1706/2500], Train Loss: 0.8464, Train Accuracy: 62.02%, Test Loss: 0.8509, Test Accuracy: 64.56%\n",
      "Epoch [1707/2500], Train Loss: 0.8206, Train Accuracy: 63.58%, Test Loss: 0.8441, Test Accuracy: 64.56%\n",
      "Epoch [1708/2500], Train Loss: 0.8509, Train Accuracy: 61.02%, Test Loss: 0.8465, Test Accuracy: 64.56%\n",
      "Epoch [1709/2500], Train Loss: 0.8580, Train Accuracy: 61.45%, Test Loss: 0.8484, Test Accuracy: 64.56%\n",
      "Epoch [1710/2500], Train Loss: 0.8448, Train Accuracy: 60.46%, Test Loss: 0.8485, Test Accuracy: 64.56%\n",
      "Epoch [1711/2500], Train Loss: 0.8501, Train Accuracy: 61.88%, Test Loss: 0.8474, Test Accuracy: 64.56%\n",
      "Epoch [1712/2500], Train Loss: 0.8525, Train Accuracy: 61.59%, Test Loss: 0.8532, Test Accuracy: 64.56%\n",
      "Epoch [1713/2500], Train Loss: 0.8483, Train Accuracy: 60.60%, Test Loss: 0.8538, Test Accuracy: 65.82%\n",
      "Epoch [1714/2500], Train Loss: 0.8566, Train Accuracy: 62.87%, Test Loss: 0.8538, Test Accuracy: 64.56%\n",
      "Epoch [1715/2500], Train Loss: 0.8463, Train Accuracy: 62.02%, Test Loss: 0.8669, Test Accuracy: 65.82%\n",
      "Epoch [1716/2500], Train Loss: 0.8775, Train Accuracy: 62.16%, Test Loss: 0.8681, Test Accuracy: 63.29%\n",
      "Epoch [1717/2500], Train Loss: 0.8421, Train Accuracy: 61.17%, Test Loss: 0.8511, Test Accuracy: 65.82%\n",
      "Epoch [1718/2500], Train Loss: 0.8540, Train Accuracy: 61.02%, Test Loss: 0.8594, Test Accuracy: 65.82%\n",
      "Epoch [1719/2500], Train Loss: 0.8438, Train Accuracy: 63.02%, Test Loss: 0.8651, Test Accuracy: 64.56%\n",
      "Epoch [1720/2500], Train Loss: 0.8550, Train Accuracy: 59.89%, Test Loss: 0.8602, Test Accuracy: 63.29%\n",
      "Epoch [1721/2500], Train Loss: 0.8530, Train Accuracy: 62.02%, Test Loss: 0.8760, Test Accuracy: 65.82%\n",
      "Epoch [1722/2500], Train Loss: 0.8505, Train Accuracy: 61.59%, Test Loss: 0.8750, Test Accuracy: 64.56%\n",
      "Epoch [1723/2500], Train Loss: 0.8602, Train Accuracy: 62.02%, Test Loss: 0.8780, Test Accuracy: 65.82%\n",
      "Epoch [1724/2500], Train Loss: 0.8461, Train Accuracy: 61.02%, Test Loss: 0.8650, Test Accuracy: 64.56%\n",
      "Epoch [1725/2500], Train Loss: 0.8337, Train Accuracy: 62.16%, Test Loss: 0.8623, Test Accuracy: 64.56%\n",
      "Epoch [1726/2500], Train Loss: 0.8579, Train Accuracy: 59.46%, Test Loss: 0.8723, Test Accuracy: 64.56%\n",
      "Epoch [1727/2500], Train Loss: 0.8524, Train Accuracy: 61.74%, Test Loss: 0.8677, Test Accuracy: 64.56%\n",
      "Epoch [1728/2500], Train Loss: 0.8278, Train Accuracy: 63.30%, Test Loss: 0.8551, Test Accuracy: 63.29%\n",
      "Epoch [1729/2500], Train Loss: 0.8369, Train Accuracy: 62.87%, Test Loss: 0.8557, Test Accuracy: 64.56%\n",
      "Epoch [1730/2500], Train Loss: 0.8461, Train Accuracy: 61.59%, Test Loss: 0.8628, Test Accuracy: 64.56%\n",
      "Epoch [1731/2500], Train Loss: 0.8449, Train Accuracy: 61.02%, Test Loss: 0.8633, Test Accuracy: 64.56%\n",
      "Epoch [1732/2500], Train Loss: 0.8542, Train Accuracy: 60.88%, Test Loss: 0.8510, Test Accuracy: 65.82%\n",
      "Epoch [1733/2500], Train Loss: 0.8444, Train Accuracy: 62.87%, Test Loss: 0.8509, Test Accuracy: 64.56%\n",
      "Epoch [1734/2500], Train Loss: 0.8574, Train Accuracy: 60.46%, Test Loss: 0.8499, Test Accuracy: 64.56%\n",
      "Epoch [1735/2500], Train Loss: 0.8709, Train Accuracy: 61.88%, Test Loss: 0.8563, Test Accuracy: 65.82%\n",
      "Epoch [1736/2500], Train Loss: 0.8773, Train Accuracy: 60.88%, Test Loss: 0.8399, Test Accuracy: 65.82%\n",
      "Epoch [1737/2500], Train Loss: 0.8467, Train Accuracy: 62.16%, Test Loss: 0.8383, Test Accuracy: 64.56%\n",
      "Epoch [1738/2500], Train Loss: 0.8542, Train Accuracy: 60.74%, Test Loss: 0.8379, Test Accuracy: 64.56%\n",
      "Epoch [1739/2500], Train Loss: 0.8389, Train Accuracy: 61.45%, Test Loss: 0.8450, Test Accuracy: 67.09%\n",
      "Epoch [1740/2500], Train Loss: 0.8505, Train Accuracy: 62.16%, Test Loss: 0.8407, Test Accuracy: 65.82%\n",
      "Epoch [1741/2500], Train Loss: 0.8368, Train Accuracy: 61.59%, Test Loss: 0.8397, Test Accuracy: 67.09%\n",
      "Epoch [1742/2500], Train Loss: 0.8571, Train Accuracy: 61.45%, Test Loss: 0.8384, Test Accuracy: 65.82%\n",
      "Epoch [1743/2500], Train Loss: 0.8515, Train Accuracy: 59.32%, Test Loss: 0.8440, Test Accuracy: 64.56%\n",
      "Epoch [1744/2500], Train Loss: 0.8354, Train Accuracy: 61.88%, Test Loss: 0.8480, Test Accuracy: 65.82%\n",
      "Epoch [1745/2500], Train Loss: 0.8277, Train Accuracy: 64.01%, Test Loss: 0.8494, Test Accuracy: 65.82%\n",
      "Epoch [1746/2500], Train Loss: 0.8674, Train Accuracy: 60.74%, Test Loss: 0.8559, Test Accuracy: 65.82%\n",
      "Epoch [1747/2500], Train Loss: 0.8401, Train Accuracy: 61.59%, Test Loss: 0.8579, Test Accuracy: 65.82%\n",
      "Epoch [1748/2500], Train Loss: 0.8243, Train Accuracy: 62.73%, Test Loss: 0.8701, Test Accuracy: 65.82%\n",
      "Epoch [1749/2500], Train Loss: 0.8353, Train Accuracy: 62.02%, Test Loss: 0.8673, Test Accuracy: 64.56%\n",
      "Epoch [1750/2500], Train Loss: 0.8619, Train Accuracy: 60.46%, Test Loss: 0.8587, Test Accuracy: 64.56%\n",
      "Epoch [1751/2500], Train Loss: 0.8614, Train Accuracy: 61.45%, Test Loss: 0.8598, Test Accuracy: 65.82%\n",
      "Epoch [1752/2500], Train Loss: 0.8271, Train Accuracy: 62.02%, Test Loss: 0.8636, Test Accuracy: 64.56%\n",
      "Epoch [1753/2500], Train Loss: 0.8365, Train Accuracy: 61.59%, Test Loss: 0.8444, Test Accuracy: 63.29%\n",
      "Epoch [1754/2500], Train Loss: 0.8583, Train Accuracy: 61.74%, Test Loss: 0.8603, Test Accuracy: 64.56%\n",
      "Epoch [1755/2500], Train Loss: 0.8240, Train Accuracy: 62.45%, Test Loss: 0.8593, Test Accuracy: 65.82%\n",
      "Epoch [1756/2500], Train Loss: 0.8498, Train Accuracy: 61.59%, Test Loss: 0.8670, Test Accuracy: 64.56%\n",
      "Epoch [1757/2500], Train Loss: 0.8435, Train Accuracy: 61.74%, Test Loss: 0.8632, Test Accuracy: 64.56%\n",
      "Epoch [1758/2500], Train Loss: 0.8512, Train Accuracy: 62.73%, Test Loss: 0.8550, Test Accuracy: 64.56%\n",
      "Epoch [1759/2500], Train Loss: 0.8400, Train Accuracy: 61.02%, Test Loss: 0.8604, Test Accuracy: 64.56%\n",
      "Epoch [1760/2500], Train Loss: 0.8418, Train Accuracy: 62.45%, Test Loss: 0.8615, Test Accuracy: 64.56%\n",
      "Epoch [1761/2500], Train Loss: 0.8373, Train Accuracy: 63.44%, Test Loss: 0.8485, Test Accuracy: 64.56%\n",
      "Epoch [1762/2500], Train Loss: 0.8336, Train Accuracy: 61.17%, Test Loss: 0.8493, Test Accuracy: 64.56%\n",
      "Epoch [1763/2500], Train Loss: 0.8470, Train Accuracy: 60.74%, Test Loss: 0.8497, Test Accuracy: 64.56%\n",
      "Epoch [1764/2500], Train Loss: 0.8481, Train Accuracy: 61.88%, Test Loss: 0.8540, Test Accuracy: 64.56%\n",
      "Epoch [1765/2500], Train Loss: 0.8479, Train Accuracy: 59.89%, Test Loss: 0.8633, Test Accuracy: 65.82%\n",
      "Epoch [1766/2500], Train Loss: 0.8355, Train Accuracy: 61.59%, Test Loss: 0.8562, Test Accuracy: 64.56%\n",
      "Epoch [1767/2500], Train Loss: 0.8445, Train Accuracy: 60.03%, Test Loss: 0.8621, Test Accuracy: 65.82%\n",
      "Epoch [1768/2500], Train Loss: 0.8325, Train Accuracy: 62.59%, Test Loss: 0.8633, Test Accuracy: 65.82%\n",
      "Epoch [1769/2500], Train Loss: 0.8296, Train Accuracy: 60.46%, Test Loss: 0.8628, Test Accuracy: 65.82%\n",
      "Epoch [1770/2500], Train Loss: 0.8531, Train Accuracy: 62.02%, Test Loss: 0.8621, Test Accuracy: 65.82%\n",
      "Epoch [1771/2500], Train Loss: 0.8409, Train Accuracy: 60.88%, Test Loss: 0.8683, Test Accuracy: 64.56%\n",
      "Epoch [1772/2500], Train Loss: 0.8495, Train Accuracy: 61.74%, Test Loss: 0.8418, Test Accuracy: 65.82%\n",
      "Epoch [1773/2500], Train Loss: 0.8518, Train Accuracy: 59.74%, Test Loss: 0.8459, Test Accuracy: 67.09%\n",
      "Epoch [1774/2500], Train Loss: 0.8476, Train Accuracy: 61.45%, Test Loss: 0.8509, Test Accuracy: 65.82%\n",
      "Epoch [1775/2500], Train Loss: 0.8443, Train Accuracy: 61.59%, Test Loss: 0.8472, Test Accuracy: 65.82%\n",
      "Epoch [1776/2500], Train Loss: 0.8597, Train Accuracy: 61.31%, Test Loss: 0.8516, Test Accuracy: 68.35%\n",
      "Epoch [1777/2500], Train Loss: 0.8404, Train Accuracy: 62.59%, Test Loss: 0.8438, Test Accuracy: 65.82%\n",
      "Epoch [1778/2500], Train Loss: 0.8444, Train Accuracy: 61.45%, Test Loss: 0.8411, Test Accuracy: 64.56%\n",
      "Epoch [1779/2500], Train Loss: 0.8319, Train Accuracy: 61.45%, Test Loss: 0.8510, Test Accuracy: 65.82%\n",
      "Epoch [1780/2500], Train Loss: 0.8682, Train Accuracy: 59.74%, Test Loss: 0.8522, Test Accuracy: 64.56%\n",
      "Epoch [1781/2500], Train Loss: 0.8384, Train Accuracy: 63.02%, Test Loss: 0.8514, Test Accuracy: 64.56%\n",
      "Epoch [1782/2500], Train Loss: 0.8278, Train Accuracy: 61.88%, Test Loss: 0.8552, Test Accuracy: 64.56%\n",
      "Epoch [1783/2500], Train Loss: 0.8545, Train Accuracy: 61.31%, Test Loss: 0.8636, Test Accuracy: 63.29%\n",
      "Epoch [1784/2500], Train Loss: 0.8332, Train Accuracy: 62.45%, Test Loss: 0.8608, Test Accuracy: 65.82%\n",
      "Epoch [1785/2500], Train Loss: 0.8590, Train Accuracy: 61.59%, Test Loss: 0.8651, Test Accuracy: 64.56%\n",
      "Epoch [1786/2500], Train Loss: 0.8532, Train Accuracy: 60.74%, Test Loss: 0.8679, Test Accuracy: 65.82%\n",
      "Epoch [1787/2500], Train Loss: 0.8315, Train Accuracy: 62.73%, Test Loss: 0.8677, Test Accuracy: 67.09%\n",
      "Epoch [1788/2500], Train Loss: 0.8553, Train Accuracy: 61.45%, Test Loss: 0.8658, Test Accuracy: 68.35%\n",
      "Epoch [1789/2500], Train Loss: 0.8348, Train Accuracy: 62.73%, Test Loss: 0.8644, Test Accuracy: 67.09%\n",
      "Epoch [1790/2500], Train Loss: 0.8555, Train Accuracy: 61.45%, Test Loss: 0.8620, Test Accuracy: 67.09%\n",
      "Epoch [1791/2500], Train Loss: 0.8384, Train Accuracy: 62.02%, Test Loss: 0.8554, Test Accuracy: 64.56%\n",
      "Epoch [1792/2500], Train Loss: 0.8506, Train Accuracy: 61.59%, Test Loss: 0.8617, Test Accuracy: 65.82%\n",
      "Epoch [1793/2500], Train Loss: 0.8529, Train Accuracy: 60.74%, Test Loss: 0.8675, Test Accuracy: 65.82%\n",
      "Epoch [1794/2500], Train Loss: 0.8510, Train Accuracy: 62.16%, Test Loss: 0.8733, Test Accuracy: 64.56%\n",
      "Epoch [1795/2500], Train Loss: 0.8399, Train Accuracy: 61.74%, Test Loss: 0.8648, Test Accuracy: 65.82%\n",
      "Epoch [1796/2500], Train Loss: 0.8447, Train Accuracy: 62.02%, Test Loss: 0.8562, Test Accuracy: 65.82%\n",
      "Epoch [1797/2500], Train Loss: 0.8382, Train Accuracy: 63.02%, Test Loss: 0.8621, Test Accuracy: 67.09%\n",
      "Epoch [1798/2500], Train Loss: 0.8374, Train Accuracy: 62.16%, Test Loss: 0.8547, Test Accuracy: 65.82%\n",
      "Epoch [1799/2500], Train Loss: 0.8175, Train Accuracy: 63.02%, Test Loss: 0.8573, Test Accuracy: 65.82%\n",
      "Epoch [1800/2500], Train Loss: 0.8616, Train Accuracy: 61.45%, Test Loss: 0.8647, Test Accuracy: 67.09%\n",
      "Epoch [1801/2500], Train Loss: 0.8293, Train Accuracy: 61.45%, Test Loss: 0.8751, Test Accuracy: 65.82%\n",
      "Epoch [1802/2500], Train Loss: 0.8196, Train Accuracy: 63.16%, Test Loss: 0.8689, Test Accuracy: 65.82%\n",
      "Epoch [1803/2500], Train Loss: 0.8503, Train Accuracy: 61.74%, Test Loss: 0.8719, Test Accuracy: 65.82%\n",
      "Epoch [1804/2500], Train Loss: 0.8342, Train Accuracy: 61.02%, Test Loss: 0.8707, Test Accuracy: 64.56%\n",
      "Epoch [1805/2500], Train Loss: 0.8359, Train Accuracy: 63.16%, Test Loss: 0.8705, Test Accuracy: 64.56%\n",
      "Epoch [1806/2500], Train Loss: 0.8401, Train Accuracy: 61.74%, Test Loss: 0.8680, Test Accuracy: 64.56%\n",
      "Epoch [1807/2500], Train Loss: 0.8399, Train Accuracy: 64.44%, Test Loss: 0.8693, Test Accuracy: 64.56%\n",
      "Epoch [1808/2500], Train Loss: 0.8426, Train Accuracy: 62.73%, Test Loss: 0.8668, Test Accuracy: 65.82%\n",
      "Epoch [1809/2500], Train Loss: 0.8591, Train Accuracy: 62.30%, Test Loss: 0.8576, Test Accuracy: 65.82%\n",
      "Epoch [1810/2500], Train Loss: 0.8450, Train Accuracy: 61.59%, Test Loss: 0.8598, Test Accuracy: 67.09%\n",
      "Epoch [1811/2500], Train Loss: 0.8324, Train Accuracy: 61.02%, Test Loss: 0.8648, Test Accuracy: 67.09%\n",
      "Epoch [1812/2500], Train Loss: 0.8402, Train Accuracy: 62.59%, Test Loss: 0.8640, Test Accuracy: 65.82%\n",
      "Epoch [1813/2500], Train Loss: 0.8321, Train Accuracy: 61.88%, Test Loss: 0.8679, Test Accuracy: 67.09%\n",
      "Epoch [1814/2500], Train Loss: 0.8497, Train Accuracy: 62.30%, Test Loss: 0.8655, Test Accuracy: 65.82%\n",
      "Epoch [1815/2500], Train Loss: 0.8470, Train Accuracy: 62.73%, Test Loss: 0.8690, Test Accuracy: 65.82%\n",
      "Epoch [1816/2500], Train Loss: 0.8393, Train Accuracy: 61.88%, Test Loss: 0.8631, Test Accuracy: 67.09%\n",
      "Epoch [1817/2500], Train Loss: 0.8563, Train Accuracy: 61.59%, Test Loss: 0.8713, Test Accuracy: 65.82%\n",
      "Epoch [1818/2500], Train Loss: 0.8367, Train Accuracy: 62.87%, Test Loss: 0.8585, Test Accuracy: 65.82%\n",
      "Epoch [1819/2500], Train Loss: 0.8302, Train Accuracy: 61.74%, Test Loss: 0.8649, Test Accuracy: 65.82%\n",
      "Epoch [1820/2500], Train Loss: 0.8219, Train Accuracy: 62.16%, Test Loss: 0.8606, Test Accuracy: 65.82%\n",
      "Epoch [1821/2500], Train Loss: 0.8356, Train Accuracy: 62.30%, Test Loss: 0.8523, Test Accuracy: 67.09%\n",
      "Epoch [1822/2500], Train Loss: 0.8549, Train Accuracy: 62.45%, Test Loss: 0.8464, Test Accuracy: 67.09%\n",
      "Epoch [1823/2500], Train Loss: 0.8398, Train Accuracy: 62.02%, Test Loss: 0.8527, Test Accuracy: 65.82%\n",
      "Epoch [1824/2500], Train Loss: 0.8244, Train Accuracy: 61.45%, Test Loss: 0.8675, Test Accuracy: 63.29%\n",
      "Epoch [1825/2500], Train Loss: 0.8458, Train Accuracy: 60.74%, Test Loss: 0.8595, Test Accuracy: 67.09%\n",
      "Epoch [1826/2500], Train Loss: 0.8332, Train Accuracy: 62.59%, Test Loss: 0.8617, Test Accuracy: 64.56%\n",
      "Epoch [1827/2500], Train Loss: 0.8318, Train Accuracy: 62.59%, Test Loss: 0.8494, Test Accuracy: 65.82%\n",
      "Epoch [1828/2500], Train Loss: 0.8153, Train Accuracy: 63.16%, Test Loss: 0.8674, Test Accuracy: 62.03%\n",
      "Epoch [1829/2500], Train Loss: 0.8178, Train Accuracy: 63.87%, Test Loss: 0.8518, Test Accuracy: 63.29%\n",
      "Epoch [1830/2500], Train Loss: 0.8427, Train Accuracy: 62.16%, Test Loss: 0.8557, Test Accuracy: 63.29%\n",
      "Epoch [1831/2500], Train Loss: 0.8308, Train Accuracy: 61.45%, Test Loss: 0.8579, Test Accuracy: 64.56%\n",
      "Epoch [1832/2500], Train Loss: 0.8517, Train Accuracy: 61.02%, Test Loss: 0.8568, Test Accuracy: 64.56%\n",
      "Epoch [1833/2500], Train Loss: 0.8522, Train Accuracy: 60.31%, Test Loss: 0.8473, Test Accuracy: 64.56%\n",
      "Epoch [1834/2500], Train Loss: 0.8410, Train Accuracy: 61.74%, Test Loss: 0.8564, Test Accuracy: 63.29%\n",
      "Epoch [1835/2500], Train Loss: 0.8362, Train Accuracy: 62.30%, Test Loss: 0.8565, Test Accuracy: 65.82%\n",
      "Epoch [1836/2500], Train Loss: 0.8597, Train Accuracy: 61.31%, Test Loss: 0.8529, Test Accuracy: 65.82%\n",
      "Epoch [1837/2500], Train Loss: 0.8202, Train Accuracy: 62.16%, Test Loss: 0.8464, Test Accuracy: 63.29%\n",
      "Epoch [1838/2500], Train Loss: 0.8428, Train Accuracy: 62.59%, Test Loss: 0.8419, Test Accuracy: 64.56%\n",
      "Epoch [1839/2500], Train Loss: 0.8363, Train Accuracy: 61.02%, Test Loss: 0.8547, Test Accuracy: 63.29%\n",
      "Epoch [1840/2500], Train Loss: 0.8255, Train Accuracy: 61.17%, Test Loss: 0.8596, Test Accuracy: 60.76%\n",
      "Epoch [1841/2500], Train Loss: 0.8421, Train Accuracy: 62.30%, Test Loss: 0.8543, Test Accuracy: 64.56%\n",
      "Epoch [1842/2500], Train Loss: 0.8253, Train Accuracy: 63.02%, Test Loss: 0.8598, Test Accuracy: 63.29%\n",
      "Epoch [1843/2500], Train Loss: 0.8502, Train Accuracy: 62.87%, Test Loss: 0.8583, Test Accuracy: 63.29%\n",
      "Epoch [1844/2500], Train Loss: 0.8234, Train Accuracy: 61.59%, Test Loss: 0.8397, Test Accuracy: 63.29%\n",
      "Epoch [1845/2500], Train Loss: 0.8336, Train Accuracy: 61.74%, Test Loss: 0.8628, Test Accuracy: 63.29%\n",
      "Epoch [1846/2500], Train Loss: 0.8351, Train Accuracy: 60.60%, Test Loss: 0.8585, Test Accuracy: 63.29%\n",
      "Epoch [1847/2500], Train Loss: 0.8463, Train Accuracy: 59.32%, Test Loss: 0.8604, Test Accuracy: 64.56%\n",
      "Epoch [1848/2500], Train Loss: 0.8412, Train Accuracy: 62.87%, Test Loss: 0.8724, Test Accuracy: 63.29%\n",
      "Epoch [1849/2500], Train Loss: 0.8609, Train Accuracy: 60.31%, Test Loss: 0.8652, Test Accuracy: 63.29%\n",
      "Epoch [1850/2500], Train Loss: 0.8411, Train Accuracy: 61.45%, Test Loss: 0.8646, Test Accuracy: 63.29%\n",
      "Epoch [1851/2500], Train Loss: 0.8592, Train Accuracy: 60.03%, Test Loss: 0.8550, Test Accuracy: 65.82%\n",
      "Epoch [1852/2500], Train Loss: 0.8457, Train Accuracy: 62.73%, Test Loss: 0.8654, Test Accuracy: 64.56%\n",
      "Epoch [1853/2500], Train Loss: 0.8446, Train Accuracy: 62.87%, Test Loss: 0.8635, Test Accuracy: 64.56%\n",
      "Epoch [1854/2500], Train Loss: 0.8435, Train Accuracy: 60.74%, Test Loss: 0.8427, Test Accuracy: 62.03%\n",
      "Epoch [1855/2500], Train Loss: 0.8318, Train Accuracy: 62.16%, Test Loss: 0.8599, Test Accuracy: 67.09%\n",
      "Epoch [1856/2500], Train Loss: 0.8454, Train Accuracy: 61.45%, Test Loss: 0.8740, Test Accuracy: 64.56%\n",
      "Epoch [1857/2500], Train Loss: 0.8567, Train Accuracy: 60.31%, Test Loss: 0.8558, Test Accuracy: 64.56%\n",
      "Epoch [1858/2500], Train Loss: 0.8573, Train Accuracy: 62.45%, Test Loss: 0.8516, Test Accuracy: 60.76%\n",
      "Epoch [1859/2500], Train Loss: 0.8367, Train Accuracy: 60.60%, Test Loss: 0.8461, Test Accuracy: 62.03%\n",
      "Epoch [1860/2500], Train Loss: 0.8324, Train Accuracy: 62.02%, Test Loss: 0.8462, Test Accuracy: 62.03%\n",
      "Epoch [1861/2500], Train Loss: 0.8199, Train Accuracy: 63.44%, Test Loss: 0.8591, Test Accuracy: 63.29%\n",
      "Epoch [1862/2500], Train Loss: 0.8485, Train Accuracy: 62.16%, Test Loss: 0.8587, Test Accuracy: 64.56%\n",
      "Epoch [1863/2500], Train Loss: 0.8303, Train Accuracy: 62.87%, Test Loss: 0.8679, Test Accuracy: 64.56%\n",
      "Epoch [1864/2500], Train Loss: 0.8353, Train Accuracy: 62.45%, Test Loss: 0.8630, Test Accuracy: 64.56%\n",
      "Epoch [1865/2500], Train Loss: 0.8513, Train Accuracy: 61.59%, Test Loss: 0.8733, Test Accuracy: 64.56%\n",
      "Epoch [1866/2500], Train Loss: 0.8514, Train Accuracy: 62.45%, Test Loss: 0.8685, Test Accuracy: 63.29%\n",
      "Epoch [1867/2500], Train Loss: 0.8580, Train Accuracy: 62.16%, Test Loss: 0.8541, Test Accuracy: 65.82%\n",
      "Epoch [1868/2500], Train Loss: 0.8383, Train Accuracy: 60.74%, Test Loss: 0.8435, Test Accuracy: 62.03%\n",
      "Epoch [1869/2500], Train Loss: 0.8275, Train Accuracy: 64.44%, Test Loss: 0.8463, Test Accuracy: 63.29%\n",
      "Epoch [1870/2500], Train Loss: 0.8185, Train Accuracy: 63.02%, Test Loss: 0.8491, Test Accuracy: 67.09%\n",
      "Epoch [1871/2500], Train Loss: 0.8378, Train Accuracy: 61.59%, Test Loss: 0.8511, Test Accuracy: 64.56%\n",
      "Epoch [1872/2500], Train Loss: 0.8403, Train Accuracy: 62.45%, Test Loss: 0.8518, Test Accuracy: 64.56%\n",
      "Epoch [1873/2500], Train Loss: 0.8355, Train Accuracy: 63.58%, Test Loss: 0.8537, Test Accuracy: 62.03%\n",
      "Epoch [1874/2500], Train Loss: 0.8414, Train Accuracy: 62.73%, Test Loss: 0.8499, Test Accuracy: 63.29%\n",
      "Epoch [1875/2500], Train Loss: 0.8284, Train Accuracy: 64.44%, Test Loss: 0.8492, Test Accuracy: 63.29%\n",
      "Epoch [1876/2500], Train Loss: 0.8488, Train Accuracy: 64.15%, Test Loss: 0.8450, Test Accuracy: 64.56%\n",
      "Epoch [1877/2500], Train Loss: 0.8555, Train Accuracy: 61.02%, Test Loss: 0.8573, Test Accuracy: 65.82%\n",
      "Epoch [1878/2500], Train Loss: 0.8354, Train Accuracy: 62.73%, Test Loss: 0.8567, Test Accuracy: 65.82%\n",
      "Epoch [1879/2500], Train Loss: 0.8422, Train Accuracy: 61.74%, Test Loss: 0.8537, Test Accuracy: 63.29%\n",
      "Epoch [1880/2500], Train Loss: 0.8484, Train Accuracy: 61.45%, Test Loss: 0.8450, Test Accuracy: 60.76%\n",
      "Epoch [1881/2500], Train Loss: 0.8312, Train Accuracy: 62.16%, Test Loss: 0.8471, Test Accuracy: 64.56%\n",
      "Epoch [1882/2500], Train Loss: 0.8326, Train Accuracy: 61.17%, Test Loss: 0.8449, Test Accuracy: 64.56%\n",
      "Epoch [1883/2500], Train Loss: 0.8274, Train Accuracy: 62.16%, Test Loss: 0.8525, Test Accuracy: 64.56%\n",
      "Epoch [1884/2500], Train Loss: 0.8368, Train Accuracy: 64.01%, Test Loss: 0.8477, Test Accuracy: 63.29%\n",
      "Epoch [1885/2500], Train Loss: 0.8217, Train Accuracy: 64.01%, Test Loss: 0.8333, Test Accuracy: 63.29%\n",
      "Epoch [1886/2500], Train Loss: 0.8519, Train Accuracy: 61.17%, Test Loss: 0.8432, Test Accuracy: 64.56%\n",
      "Epoch [1887/2500], Train Loss: 0.8496, Train Accuracy: 62.30%, Test Loss: 0.8295, Test Accuracy: 64.56%\n",
      "Epoch [1888/2500], Train Loss: 0.8396, Train Accuracy: 61.45%, Test Loss: 0.8379, Test Accuracy: 67.09%\n",
      "Epoch [1889/2500], Train Loss: 0.8337, Train Accuracy: 62.45%, Test Loss: 0.8427, Test Accuracy: 64.56%\n",
      "Epoch [1890/2500], Train Loss: 0.8282, Train Accuracy: 61.88%, Test Loss: 0.8341, Test Accuracy: 65.82%\n",
      "Epoch [1891/2500], Train Loss: 0.8537, Train Accuracy: 61.88%, Test Loss: 0.8484, Test Accuracy: 65.82%\n",
      "Epoch [1892/2500], Train Loss: 0.8385, Train Accuracy: 61.31%, Test Loss: 0.8577, Test Accuracy: 64.56%\n",
      "Epoch [1893/2500], Train Loss: 0.8201, Train Accuracy: 62.02%, Test Loss: 0.8459, Test Accuracy: 64.56%\n",
      "Epoch [1894/2500], Train Loss: 0.8345, Train Accuracy: 60.60%, Test Loss: 0.8423, Test Accuracy: 65.82%\n",
      "Epoch [1895/2500], Train Loss: 0.8312, Train Accuracy: 61.74%, Test Loss: 0.8417, Test Accuracy: 65.82%\n",
      "Epoch [1896/2500], Train Loss: 0.8198, Train Accuracy: 64.15%, Test Loss: 0.8338, Test Accuracy: 64.56%\n",
      "Epoch [1897/2500], Train Loss: 0.8465, Train Accuracy: 62.45%, Test Loss: 0.8459, Test Accuracy: 64.56%\n",
      "Epoch [1898/2500], Train Loss: 0.8439, Train Accuracy: 63.87%, Test Loss: 0.8459, Test Accuracy: 64.56%\n",
      "Epoch [1899/2500], Train Loss: 0.8299, Train Accuracy: 63.02%, Test Loss: 0.8587, Test Accuracy: 64.56%\n",
      "Epoch [1900/2500], Train Loss: 0.8085, Train Accuracy: 63.44%, Test Loss: 0.8547, Test Accuracy: 65.82%\n",
      "Epoch [1901/2500], Train Loss: 0.8274, Train Accuracy: 61.31%, Test Loss: 0.8558, Test Accuracy: 67.09%\n",
      "Epoch [1902/2500], Train Loss: 0.8374, Train Accuracy: 62.02%, Test Loss: 0.8502, Test Accuracy: 65.82%\n",
      "Epoch [1903/2500], Train Loss: 0.8321, Train Accuracy: 60.03%, Test Loss: 0.8462, Test Accuracy: 64.56%\n",
      "Epoch [1904/2500], Train Loss: 0.8323, Train Accuracy: 62.16%, Test Loss: 0.8547, Test Accuracy: 64.56%\n",
      "Epoch [1905/2500], Train Loss: 0.8260, Train Accuracy: 63.02%, Test Loss: 0.8514, Test Accuracy: 64.56%\n",
      "Epoch [1906/2500], Train Loss: 0.8275, Train Accuracy: 62.87%, Test Loss: 0.8488, Test Accuracy: 64.56%\n",
      "Epoch [1907/2500], Train Loss: 0.8251, Train Accuracy: 61.59%, Test Loss: 0.8603, Test Accuracy: 67.09%\n",
      "Epoch [1908/2500], Train Loss: 0.8377, Train Accuracy: 60.74%, Test Loss: 0.8684, Test Accuracy: 65.82%\n",
      "Epoch [1909/2500], Train Loss: 0.8159, Train Accuracy: 61.74%, Test Loss: 0.8549, Test Accuracy: 64.56%\n",
      "Epoch [1910/2500], Train Loss: 0.8436, Train Accuracy: 63.16%, Test Loss: 0.8424, Test Accuracy: 65.82%\n",
      "Epoch [1911/2500], Train Loss: 0.8532, Train Accuracy: 60.88%, Test Loss: 0.8500, Test Accuracy: 64.56%\n",
      "Epoch [1912/2500], Train Loss: 0.8324, Train Accuracy: 62.16%, Test Loss: 0.8465, Test Accuracy: 65.82%\n",
      "Epoch [1913/2500], Train Loss: 0.8433, Train Accuracy: 62.73%, Test Loss: 0.8354, Test Accuracy: 67.09%\n",
      "Epoch [1914/2500], Train Loss: 0.8457, Train Accuracy: 60.88%, Test Loss: 0.8450, Test Accuracy: 64.56%\n",
      "Epoch [1915/2500], Train Loss: 0.8369, Train Accuracy: 60.88%, Test Loss: 0.8421, Test Accuracy: 65.82%\n",
      "Epoch [1916/2500], Train Loss: 0.8438, Train Accuracy: 61.88%, Test Loss: 0.8497, Test Accuracy: 65.82%\n",
      "Epoch [1917/2500], Train Loss: 0.8319, Train Accuracy: 62.73%, Test Loss: 0.8557, Test Accuracy: 67.09%\n",
      "Epoch [1918/2500], Train Loss: 0.8258, Train Accuracy: 63.58%, Test Loss: 0.8510, Test Accuracy: 67.09%\n",
      "Epoch [1919/2500], Train Loss: 0.8390, Train Accuracy: 63.02%, Test Loss: 0.8480, Test Accuracy: 67.09%\n",
      "Epoch [1920/2500], Train Loss: 0.8565, Train Accuracy: 62.45%, Test Loss: 0.8436, Test Accuracy: 65.82%\n",
      "Epoch [1921/2500], Train Loss: 0.8330, Train Accuracy: 61.59%, Test Loss: 0.8460, Test Accuracy: 67.09%\n",
      "Epoch [1922/2500], Train Loss: 0.8302, Train Accuracy: 61.88%, Test Loss: 0.8495, Test Accuracy: 65.82%\n",
      "Epoch [1923/2500], Train Loss: 0.8362, Train Accuracy: 61.17%, Test Loss: 0.8545, Test Accuracy: 65.82%\n",
      "Epoch [1924/2500], Train Loss: 0.8332, Train Accuracy: 61.31%, Test Loss: 0.8519, Test Accuracy: 67.09%\n",
      "Epoch [1925/2500], Train Loss: 0.8243, Train Accuracy: 63.58%, Test Loss: 0.8429, Test Accuracy: 64.56%\n",
      "Epoch [1926/2500], Train Loss: 0.8307, Train Accuracy: 60.31%, Test Loss: 0.8434, Test Accuracy: 65.82%\n",
      "Epoch [1927/2500], Train Loss: 0.8362, Train Accuracy: 62.30%, Test Loss: 0.8366, Test Accuracy: 65.82%\n",
      "Epoch [1928/2500], Train Loss: 0.8267, Train Accuracy: 61.31%, Test Loss: 0.8387, Test Accuracy: 67.09%\n",
      "Epoch [1929/2500], Train Loss: 0.8229, Train Accuracy: 62.45%, Test Loss: 0.8367, Test Accuracy: 65.82%\n",
      "Epoch [1930/2500], Train Loss: 0.8404, Train Accuracy: 61.59%, Test Loss: 0.8399, Test Accuracy: 67.09%\n",
      "Epoch [1931/2500], Train Loss: 0.8414, Train Accuracy: 61.17%, Test Loss: 0.8382, Test Accuracy: 65.82%\n",
      "Epoch [1932/2500], Train Loss: 0.8339, Train Accuracy: 61.59%, Test Loss: 0.8450, Test Accuracy: 64.56%\n",
      "Epoch [1933/2500], Train Loss: 0.8218, Train Accuracy: 61.74%, Test Loss: 0.8478, Test Accuracy: 64.56%\n",
      "Epoch [1934/2500], Train Loss: 0.8184, Train Accuracy: 62.02%, Test Loss: 0.8516, Test Accuracy: 67.09%\n",
      "Epoch [1935/2500], Train Loss: 0.8482, Train Accuracy: 61.74%, Test Loss: 0.8400, Test Accuracy: 64.56%\n",
      "Epoch [1936/2500], Train Loss: 0.8381, Train Accuracy: 61.02%, Test Loss: 0.8391, Test Accuracy: 64.56%\n",
      "Epoch [1937/2500], Train Loss: 0.8159, Train Accuracy: 62.02%, Test Loss: 0.8401, Test Accuracy: 67.09%\n",
      "Epoch [1938/2500], Train Loss: 0.8372, Train Accuracy: 61.74%, Test Loss: 0.8504, Test Accuracy: 67.09%\n",
      "Epoch [1939/2500], Train Loss: 0.8449, Train Accuracy: 61.59%, Test Loss: 0.8629, Test Accuracy: 67.09%\n",
      "Epoch [1940/2500], Train Loss: 0.8162, Train Accuracy: 63.16%, Test Loss: 0.8618, Test Accuracy: 65.82%\n",
      "Epoch [1941/2500], Train Loss: 0.8288, Train Accuracy: 62.45%, Test Loss: 0.8596, Test Accuracy: 65.82%\n",
      "Epoch [1942/2500], Train Loss: 0.8383, Train Accuracy: 62.87%, Test Loss: 0.8533, Test Accuracy: 65.82%\n",
      "Epoch [1943/2500], Train Loss: 0.8318, Train Accuracy: 62.87%, Test Loss: 0.8536, Test Accuracy: 64.56%\n",
      "Epoch [1944/2500], Train Loss: 0.8309, Train Accuracy: 62.45%, Test Loss: 0.8536, Test Accuracy: 67.09%\n",
      "Epoch [1945/2500], Train Loss: 0.8364, Train Accuracy: 61.45%, Test Loss: 0.8489, Test Accuracy: 64.56%\n",
      "Epoch [1946/2500], Train Loss: 0.8279, Train Accuracy: 61.59%, Test Loss: 0.8533, Test Accuracy: 64.56%\n",
      "Epoch [1947/2500], Train Loss: 0.8347, Train Accuracy: 61.74%, Test Loss: 0.8600, Test Accuracy: 64.56%\n",
      "Epoch [1948/2500], Train Loss: 0.8404, Train Accuracy: 62.45%, Test Loss: 0.8564, Test Accuracy: 64.56%\n",
      "Epoch [1949/2500], Train Loss: 0.8215, Train Accuracy: 63.73%, Test Loss: 0.8561, Test Accuracy: 64.56%\n",
      "Epoch [1950/2500], Train Loss: 0.8046, Train Accuracy: 63.30%, Test Loss: 0.8512, Test Accuracy: 67.09%\n",
      "Epoch [1951/2500], Train Loss: 0.8243, Train Accuracy: 62.73%, Test Loss: 0.8585, Test Accuracy: 64.56%\n",
      "Epoch [1952/2500], Train Loss: 0.8339, Train Accuracy: 62.30%, Test Loss: 0.8471, Test Accuracy: 64.56%\n",
      "Epoch [1953/2500], Train Loss: 0.8403, Train Accuracy: 61.59%, Test Loss: 0.8549, Test Accuracy: 67.09%\n",
      "Epoch [1954/2500], Train Loss: 0.8278, Train Accuracy: 63.87%, Test Loss: 0.8500, Test Accuracy: 65.82%\n",
      "Epoch [1955/2500], Train Loss: 0.8263, Train Accuracy: 63.87%, Test Loss: 0.8563, Test Accuracy: 65.82%\n",
      "Epoch [1956/2500], Train Loss: 0.8382, Train Accuracy: 61.45%, Test Loss: 0.8504, Test Accuracy: 65.82%\n",
      "Epoch [1957/2500], Train Loss: 0.8079, Train Accuracy: 63.44%, Test Loss: 0.8588, Test Accuracy: 67.09%\n",
      "Epoch [1958/2500], Train Loss: 0.8161, Train Accuracy: 62.02%, Test Loss: 0.8455, Test Accuracy: 64.56%\n",
      "Epoch [1959/2500], Train Loss: 0.8377, Train Accuracy: 60.46%, Test Loss: 0.8621, Test Accuracy: 67.09%\n",
      "Epoch [1960/2500], Train Loss: 0.8220, Train Accuracy: 62.16%, Test Loss: 0.8468, Test Accuracy: 68.35%\n",
      "Epoch [1961/2500], Train Loss: 0.8396, Train Accuracy: 62.87%, Test Loss: 0.8513, Test Accuracy: 67.09%\n",
      "Epoch [1962/2500], Train Loss: 0.8401, Train Accuracy: 59.17%, Test Loss: 0.8456, Test Accuracy: 65.82%\n",
      "Epoch [1963/2500], Train Loss: 0.8295, Train Accuracy: 62.30%, Test Loss: 0.8347, Test Accuracy: 64.56%\n",
      "Epoch [1964/2500], Train Loss: 0.8261, Train Accuracy: 62.30%, Test Loss: 0.8330, Test Accuracy: 64.56%\n",
      "Epoch [1965/2500], Train Loss: 0.8403, Train Accuracy: 60.17%, Test Loss: 0.8472, Test Accuracy: 64.56%\n",
      "Epoch [1966/2500], Train Loss: 0.8410, Train Accuracy: 61.59%, Test Loss: 0.8520, Test Accuracy: 63.29%\n",
      "Epoch [1967/2500], Train Loss: 0.8525, Train Accuracy: 60.74%, Test Loss: 0.8458, Test Accuracy: 67.09%\n",
      "Epoch [1968/2500], Train Loss: 0.8256, Train Accuracy: 64.01%, Test Loss: 0.8475, Test Accuracy: 63.29%\n",
      "Epoch [1969/2500], Train Loss: 0.8487, Train Accuracy: 60.60%, Test Loss: 0.8502, Test Accuracy: 65.82%\n",
      "Epoch [1970/2500], Train Loss: 0.8328, Train Accuracy: 61.74%, Test Loss: 0.8583, Test Accuracy: 63.29%\n",
      "Epoch [1971/2500], Train Loss: 0.8322, Train Accuracy: 62.16%, Test Loss: 0.8572, Test Accuracy: 64.56%\n",
      "Epoch [1972/2500], Train Loss: 0.8290, Train Accuracy: 63.73%, Test Loss: 0.8621, Test Accuracy: 68.35%\n",
      "Epoch [1973/2500], Train Loss: 0.8348, Train Accuracy: 61.74%, Test Loss: 0.8437, Test Accuracy: 68.35%\n",
      "Epoch [1974/2500], Train Loss: 0.8192, Train Accuracy: 64.30%, Test Loss: 0.8518, Test Accuracy: 65.82%\n",
      "Epoch [1975/2500], Train Loss: 0.8434, Train Accuracy: 62.87%, Test Loss: 0.8552, Test Accuracy: 64.56%\n",
      "Epoch [1976/2500], Train Loss: 0.8391, Train Accuracy: 62.87%, Test Loss: 0.8593, Test Accuracy: 64.56%\n",
      "Epoch [1977/2500], Train Loss: 0.8250, Train Accuracy: 62.02%, Test Loss: 0.8574, Test Accuracy: 65.82%\n",
      "Epoch [1978/2500], Train Loss: 0.8398, Train Accuracy: 62.45%, Test Loss: 0.8480, Test Accuracy: 64.56%\n",
      "Epoch [1979/2500], Train Loss: 0.8433, Train Accuracy: 61.88%, Test Loss: 0.8497, Test Accuracy: 67.09%\n",
      "Epoch [1980/2500], Train Loss: 0.8144, Train Accuracy: 63.58%, Test Loss: 0.8481, Test Accuracy: 65.82%\n",
      "Epoch [1981/2500], Train Loss: 0.8389, Train Accuracy: 63.02%, Test Loss: 0.8431, Test Accuracy: 64.56%\n",
      "Epoch [1982/2500], Train Loss: 0.8295, Train Accuracy: 63.16%, Test Loss: 0.8534, Test Accuracy: 64.56%\n",
      "Epoch [1983/2500], Train Loss: 0.8280, Train Accuracy: 62.16%, Test Loss: 0.8501, Test Accuracy: 62.03%\n",
      "Epoch [1984/2500], Train Loss: 0.8241, Train Accuracy: 63.02%, Test Loss: 0.8574, Test Accuracy: 64.56%\n",
      "Epoch [1985/2500], Train Loss: 0.8304, Train Accuracy: 61.02%, Test Loss: 0.8512, Test Accuracy: 65.82%\n",
      "Epoch [1986/2500], Train Loss: 0.8250, Train Accuracy: 61.02%, Test Loss: 0.8519, Test Accuracy: 65.82%\n",
      "Epoch [1987/2500], Train Loss: 0.8380, Train Accuracy: 60.88%, Test Loss: 0.8442, Test Accuracy: 64.56%\n",
      "Epoch [1988/2500], Train Loss: 0.8128, Train Accuracy: 63.58%, Test Loss: 0.8521, Test Accuracy: 63.29%\n",
      "Epoch [1989/2500], Train Loss: 0.8387, Train Accuracy: 61.31%, Test Loss: 0.8589, Test Accuracy: 64.56%\n",
      "Epoch [1990/2500], Train Loss: 0.8359, Train Accuracy: 60.03%, Test Loss: 0.8529, Test Accuracy: 65.82%\n",
      "Epoch [1991/2500], Train Loss: 0.8108, Train Accuracy: 64.86%, Test Loss: 0.8332, Test Accuracy: 64.56%\n",
      "Epoch [1992/2500], Train Loss: 0.8360, Train Accuracy: 62.59%, Test Loss: 0.8460, Test Accuracy: 65.82%\n",
      "Epoch [1993/2500], Train Loss: 0.8259, Train Accuracy: 60.74%, Test Loss: 0.8434, Test Accuracy: 67.09%\n",
      "Epoch [1994/2500], Train Loss: 0.8244, Train Accuracy: 61.45%, Test Loss: 0.8496, Test Accuracy: 63.29%\n",
      "Epoch [1995/2500], Train Loss: 0.8222, Train Accuracy: 63.02%, Test Loss: 0.8473, Test Accuracy: 65.82%\n",
      "Epoch [1996/2500], Train Loss: 0.8426, Train Accuracy: 62.87%, Test Loss: 0.8442, Test Accuracy: 64.56%\n",
      "Epoch [1997/2500], Train Loss: 0.8455, Train Accuracy: 60.88%, Test Loss: 0.8489, Test Accuracy: 63.29%\n",
      "Epoch [1998/2500], Train Loss: 0.8317, Train Accuracy: 62.02%, Test Loss: 0.8422, Test Accuracy: 64.56%\n",
      "Epoch [1999/2500], Train Loss: 0.8394, Train Accuracy: 62.59%, Test Loss: 0.8501, Test Accuracy: 64.56%\n",
      "Epoch [2000/2500], Train Loss: 0.8297, Train Accuracy: 62.16%, Test Loss: 0.8336, Test Accuracy: 64.56%\n",
      "Epoch [2001/2500], Train Loss: 0.8486, Train Accuracy: 60.46%, Test Loss: 0.8346, Test Accuracy: 64.56%\n",
      "Epoch [2002/2500], Train Loss: 0.8183, Train Accuracy: 62.16%, Test Loss: 0.8233, Test Accuracy: 64.56%\n",
      "Epoch [2003/2500], Train Loss: 0.8285, Train Accuracy: 63.02%, Test Loss: 0.8468, Test Accuracy: 64.56%\n",
      "Epoch [2004/2500], Train Loss: 0.8213, Train Accuracy: 64.01%, Test Loss: 0.8319, Test Accuracy: 65.82%\n",
      "Epoch [2005/2500], Train Loss: 0.8443, Train Accuracy: 61.88%, Test Loss: 0.8396, Test Accuracy: 65.82%\n",
      "Epoch [2006/2500], Train Loss: 0.8283, Train Accuracy: 62.02%, Test Loss: 0.8343, Test Accuracy: 65.82%\n",
      "Epoch [2007/2500], Train Loss: 0.8367, Train Accuracy: 61.59%, Test Loss: 0.8372, Test Accuracy: 64.56%\n",
      "Epoch [2008/2500], Train Loss: 0.8130, Train Accuracy: 63.73%, Test Loss: 0.8219, Test Accuracy: 67.09%\n",
      "Epoch [2009/2500], Train Loss: 0.8216, Train Accuracy: 63.30%, Test Loss: 0.8390, Test Accuracy: 65.82%\n",
      "Epoch [2010/2500], Train Loss: 0.8393, Train Accuracy: 60.46%, Test Loss: 0.8300, Test Accuracy: 65.82%\n",
      "Epoch [2011/2500], Train Loss: 0.8356, Train Accuracy: 60.88%, Test Loss: 0.8235, Test Accuracy: 65.82%\n",
      "Epoch [2012/2500], Train Loss: 0.8575, Train Accuracy: 61.17%, Test Loss: 0.8465, Test Accuracy: 64.56%\n",
      "Epoch [2013/2500], Train Loss: 0.8389, Train Accuracy: 61.31%, Test Loss: 0.8515, Test Accuracy: 65.82%\n",
      "Epoch [2014/2500], Train Loss: 0.8325, Train Accuracy: 63.16%, Test Loss: 0.8262, Test Accuracy: 65.82%\n",
      "Epoch [2015/2500], Train Loss: 0.8272, Train Accuracy: 64.01%, Test Loss: 0.8440, Test Accuracy: 64.56%\n",
      "Epoch [2016/2500], Train Loss: 0.8367, Train Accuracy: 62.02%, Test Loss: 0.8287, Test Accuracy: 67.09%\n",
      "Epoch [2017/2500], Train Loss: 0.8287, Train Accuracy: 62.45%, Test Loss: 0.8251, Test Accuracy: 64.56%\n",
      "Epoch [2018/2500], Train Loss: 0.8239, Train Accuracy: 63.87%, Test Loss: 0.8305, Test Accuracy: 63.29%\n",
      "Epoch [2019/2500], Train Loss: 0.8215, Train Accuracy: 62.02%, Test Loss: 0.8284, Test Accuracy: 65.82%\n",
      "Epoch [2020/2500], Train Loss: 0.8482, Train Accuracy: 61.74%, Test Loss: 0.8332, Test Accuracy: 63.29%\n",
      "Epoch [2021/2500], Train Loss: 0.8237, Train Accuracy: 62.02%, Test Loss: 0.8328, Test Accuracy: 64.56%\n",
      "Epoch [2022/2500], Train Loss: 0.8465, Train Accuracy: 61.02%, Test Loss: 0.8419, Test Accuracy: 65.82%\n",
      "Epoch [2023/2500], Train Loss: 0.8157, Train Accuracy: 61.74%, Test Loss: 0.8295, Test Accuracy: 65.82%\n",
      "Epoch [2024/2500], Train Loss: 0.8307, Train Accuracy: 63.02%, Test Loss: 0.8350, Test Accuracy: 63.29%\n",
      "Epoch [2025/2500], Train Loss: 0.8239, Train Accuracy: 61.74%, Test Loss: 0.8381, Test Accuracy: 64.56%\n",
      "Epoch [2026/2500], Train Loss: 0.8320, Train Accuracy: 61.45%, Test Loss: 0.8432, Test Accuracy: 63.29%\n",
      "Epoch [2027/2500], Train Loss: 0.8209, Train Accuracy: 62.16%, Test Loss: 0.8353, Test Accuracy: 65.82%\n",
      "Epoch [2028/2500], Train Loss: 0.8094, Train Accuracy: 63.02%, Test Loss: 0.8307, Test Accuracy: 65.82%\n",
      "Epoch [2029/2500], Train Loss: 0.8375, Train Accuracy: 63.02%, Test Loss: 0.8377, Test Accuracy: 65.82%\n",
      "Epoch [2030/2500], Train Loss: 0.8265, Train Accuracy: 62.30%, Test Loss: 0.8388, Test Accuracy: 65.82%\n",
      "Epoch [2031/2500], Train Loss: 0.8338, Train Accuracy: 63.16%, Test Loss: 0.8498, Test Accuracy: 65.82%\n",
      "Epoch [2032/2500], Train Loss: 0.8328, Train Accuracy: 61.45%, Test Loss: 0.8403, Test Accuracy: 65.82%\n",
      "Epoch [2033/2500], Train Loss: 0.8306, Train Accuracy: 61.17%, Test Loss: 0.8306, Test Accuracy: 68.35%\n",
      "Epoch [2034/2500], Train Loss: 0.8289, Train Accuracy: 62.59%, Test Loss: 0.8299, Test Accuracy: 68.35%\n",
      "Epoch [2035/2500], Train Loss: 0.8208, Train Accuracy: 62.59%, Test Loss: 0.8306, Test Accuracy: 64.56%\n",
      "Epoch [2036/2500], Train Loss: 0.8252, Train Accuracy: 62.45%, Test Loss: 0.8161, Test Accuracy: 67.09%\n",
      "Epoch [2037/2500], Train Loss: 0.8210, Train Accuracy: 62.02%, Test Loss: 0.8353, Test Accuracy: 65.82%\n",
      "Epoch [2038/2500], Train Loss: 0.8383, Train Accuracy: 62.87%, Test Loss: 0.8357, Test Accuracy: 67.09%\n",
      "Epoch [2039/2500], Train Loss: 0.8311, Train Accuracy: 62.02%, Test Loss: 0.8327, Test Accuracy: 68.35%\n",
      "Epoch [2040/2500], Train Loss: 0.8250, Train Accuracy: 62.87%, Test Loss: 0.8355, Test Accuracy: 68.35%\n",
      "Epoch [2041/2500], Train Loss: 0.8286, Train Accuracy: 60.88%, Test Loss: 0.8416, Test Accuracy: 67.09%\n",
      "Epoch [2042/2500], Train Loss: 0.8167, Train Accuracy: 63.58%, Test Loss: 0.8270, Test Accuracy: 68.35%\n",
      "Epoch [2043/2500], Train Loss: 0.8104, Train Accuracy: 62.30%, Test Loss: 0.8218, Test Accuracy: 68.35%\n",
      "Epoch [2044/2500], Train Loss: 0.8195, Train Accuracy: 63.30%, Test Loss: 0.8414, Test Accuracy: 68.35%\n",
      "Epoch [2045/2500], Train Loss: 0.8267, Train Accuracy: 62.45%, Test Loss: 0.8468, Test Accuracy: 68.35%\n",
      "Epoch [2046/2500], Train Loss: 0.8308, Train Accuracy: 61.31%, Test Loss: 0.8388, Test Accuracy: 67.09%\n",
      "Epoch [2047/2500], Train Loss: 0.8365, Train Accuracy: 61.45%, Test Loss: 0.8514, Test Accuracy: 68.35%\n",
      "Epoch [2048/2500], Train Loss: 0.8370, Train Accuracy: 62.30%, Test Loss: 0.8341, Test Accuracy: 67.09%\n",
      "Epoch [2049/2500], Train Loss: 0.8221, Train Accuracy: 62.30%, Test Loss: 0.8336, Test Accuracy: 65.82%\n",
      "Epoch [2050/2500], Train Loss: 0.8168, Train Accuracy: 62.02%, Test Loss: 0.8292, Test Accuracy: 64.56%\n",
      "Epoch [2051/2500], Train Loss: 0.8449, Train Accuracy: 62.16%, Test Loss: 0.8389, Test Accuracy: 65.82%\n",
      "Epoch [2052/2500], Train Loss: 0.8282, Train Accuracy: 62.87%, Test Loss: 0.8483, Test Accuracy: 65.82%\n",
      "Epoch [2053/2500], Train Loss: 0.8245, Train Accuracy: 63.30%, Test Loss: 0.8389, Test Accuracy: 64.56%\n",
      "Epoch [2054/2500], Train Loss: 0.8191, Train Accuracy: 64.15%, Test Loss: 0.8304, Test Accuracy: 64.56%\n",
      "Epoch [2055/2500], Train Loss: 0.8384, Train Accuracy: 61.88%, Test Loss: 0.8231, Test Accuracy: 64.56%\n",
      "Epoch [2056/2500], Train Loss: 0.8367, Train Accuracy: 62.30%, Test Loss: 0.8229, Test Accuracy: 64.56%\n",
      "Epoch [2057/2500], Train Loss: 0.8430, Train Accuracy: 61.45%, Test Loss: 0.8310, Test Accuracy: 65.82%\n",
      "Epoch [2058/2500], Train Loss: 0.8172, Train Accuracy: 63.44%, Test Loss: 0.8445, Test Accuracy: 64.56%\n",
      "Epoch [2059/2500], Train Loss: 0.8274, Train Accuracy: 61.59%, Test Loss: 0.8448, Test Accuracy: 64.56%\n",
      "Epoch [2060/2500], Train Loss: 0.8452, Train Accuracy: 62.02%, Test Loss: 0.8455, Test Accuracy: 64.56%\n",
      "Epoch [2061/2500], Train Loss: 0.8391, Train Accuracy: 60.31%, Test Loss: 0.8505, Test Accuracy: 65.82%\n",
      "Epoch [2062/2500], Train Loss: 0.8349, Train Accuracy: 62.16%, Test Loss: 0.8464, Test Accuracy: 63.29%\n",
      "Epoch [2063/2500], Train Loss: 0.8247, Train Accuracy: 61.88%, Test Loss: 0.8432, Test Accuracy: 67.09%\n",
      "Epoch [2064/2500], Train Loss: 0.8224, Train Accuracy: 62.59%, Test Loss: 0.8372, Test Accuracy: 65.82%\n",
      "Epoch [2065/2500], Train Loss: 0.8375, Train Accuracy: 61.17%, Test Loss: 0.8454, Test Accuracy: 63.29%\n",
      "Epoch [2066/2500], Train Loss: 0.8208, Train Accuracy: 62.87%, Test Loss: 0.8474, Test Accuracy: 64.56%\n",
      "Epoch [2067/2500], Train Loss: 0.8312, Train Accuracy: 63.02%, Test Loss: 0.8531, Test Accuracy: 65.82%\n",
      "Epoch [2068/2500], Train Loss: 0.8296, Train Accuracy: 62.16%, Test Loss: 0.8556, Test Accuracy: 64.56%\n",
      "Epoch [2069/2500], Train Loss: 0.8323, Train Accuracy: 61.45%, Test Loss: 0.8467, Test Accuracy: 65.82%\n",
      "Epoch [2070/2500], Train Loss: 0.8222, Train Accuracy: 63.02%, Test Loss: 0.8457, Test Accuracy: 67.09%\n",
      "Epoch [2071/2500], Train Loss: 0.8308, Train Accuracy: 61.31%, Test Loss: 0.8345, Test Accuracy: 65.82%\n",
      "Epoch [2072/2500], Train Loss: 0.8203, Train Accuracy: 63.58%, Test Loss: 0.8436, Test Accuracy: 64.56%\n",
      "Epoch [2073/2500], Train Loss: 0.8174, Train Accuracy: 63.73%, Test Loss: 0.8441, Test Accuracy: 64.56%\n",
      "Epoch [2074/2500], Train Loss: 0.8105, Train Accuracy: 63.73%, Test Loss: 0.8361, Test Accuracy: 65.82%\n",
      "Epoch [2075/2500], Train Loss: 0.8293, Train Accuracy: 60.60%, Test Loss: 0.8300, Test Accuracy: 64.56%\n",
      "Epoch [2076/2500], Train Loss: 0.8362, Train Accuracy: 61.59%, Test Loss: 0.8178, Test Accuracy: 67.09%\n",
      "Epoch [2077/2500], Train Loss: 0.8337, Train Accuracy: 62.45%, Test Loss: 0.8108, Test Accuracy: 65.82%\n",
      "Epoch [2078/2500], Train Loss: 0.8148, Train Accuracy: 64.01%, Test Loss: 0.8257, Test Accuracy: 65.82%\n",
      "Epoch [2079/2500], Train Loss: 0.8459, Train Accuracy: 61.59%, Test Loss: 0.8156, Test Accuracy: 67.09%\n",
      "Epoch [2080/2500], Train Loss: 0.8401, Train Accuracy: 62.02%, Test Loss: 0.8268, Test Accuracy: 67.09%\n",
      "Epoch [2081/2500], Train Loss: 0.8174, Train Accuracy: 63.02%, Test Loss: 0.8496, Test Accuracy: 65.82%\n",
      "Epoch [2082/2500], Train Loss: 0.8242, Train Accuracy: 63.16%, Test Loss: 0.8466, Test Accuracy: 65.82%\n",
      "Epoch [2083/2500], Train Loss: 0.8254, Train Accuracy: 62.73%, Test Loss: 0.8509, Test Accuracy: 65.82%\n",
      "Epoch [2084/2500], Train Loss: 0.8281, Train Accuracy: 62.45%, Test Loss: 0.8359, Test Accuracy: 65.82%\n",
      "Epoch [2085/2500], Train Loss: 0.8203, Train Accuracy: 62.73%, Test Loss: 0.8383, Test Accuracy: 67.09%\n",
      "Epoch [2086/2500], Train Loss: 0.8241, Train Accuracy: 63.02%, Test Loss: 0.8340, Test Accuracy: 68.35%\n",
      "Epoch [2087/2500], Train Loss: 0.8350, Train Accuracy: 62.30%, Test Loss: 0.8180, Test Accuracy: 63.29%\n",
      "Epoch [2088/2500], Train Loss: 0.8246, Train Accuracy: 61.74%, Test Loss: 0.8154, Test Accuracy: 65.82%\n",
      "Epoch [2089/2500], Train Loss: 0.8080, Train Accuracy: 63.02%, Test Loss: 0.8300, Test Accuracy: 64.56%\n",
      "Epoch [2090/2500], Train Loss: 0.8413, Train Accuracy: 62.87%, Test Loss: 0.8403, Test Accuracy: 65.82%\n",
      "Epoch [2091/2500], Train Loss: 0.8151, Train Accuracy: 61.74%, Test Loss: 0.8401, Test Accuracy: 67.09%\n",
      "Epoch [2092/2500], Train Loss: 0.8108, Train Accuracy: 62.59%, Test Loss: 0.8260, Test Accuracy: 67.09%\n",
      "Epoch [2093/2500], Train Loss: 0.8140, Train Accuracy: 62.59%, Test Loss: 0.8306, Test Accuracy: 67.09%\n",
      "Epoch [2094/2500], Train Loss: 0.8309, Train Accuracy: 62.02%, Test Loss: 0.8228, Test Accuracy: 63.29%\n",
      "Epoch [2095/2500], Train Loss: 0.8003, Train Accuracy: 63.30%, Test Loss: 0.8341, Test Accuracy: 64.56%\n",
      "Epoch [2096/2500], Train Loss: 0.8242, Train Accuracy: 63.58%, Test Loss: 0.8322, Test Accuracy: 63.29%\n",
      "Epoch [2097/2500], Train Loss: 0.8383, Train Accuracy: 63.02%, Test Loss: 0.8334, Test Accuracy: 64.56%\n",
      "Epoch [2098/2500], Train Loss: 0.8228, Train Accuracy: 62.16%, Test Loss: 0.8246, Test Accuracy: 65.82%\n",
      "Epoch [2099/2500], Train Loss: 0.8218, Train Accuracy: 62.73%, Test Loss: 0.8291, Test Accuracy: 64.56%\n",
      "Epoch [2100/2500], Train Loss: 0.8275, Train Accuracy: 62.02%, Test Loss: 0.8322, Test Accuracy: 63.29%\n",
      "Epoch [2101/2500], Train Loss: 0.8239, Train Accuracy: 62.45%, Test Loss: 0.8329, Test Accuracy: 64.56%\n",
      "Epoch [2102/2500], Train Loss: 0.8183, Train Accuracy: 65.15%, Test Loss: 0.8318, Test Accuracy: 63.29%\n",
      "Epoch [2103/2500], Train Loss: 0.8350, Train Accuracy: 61.31%, Test Loss: 0.8309, Test Accuracy: 64.56%\n",
      "Epoch [2104/2500], Train Loss: 0.8369, Train Accuracy: 59.60%, Test Loss: 0.8235, Test Accuracy: 65.82%\n",
      "Epoch [2105/2500], Train Loss: 0.8405, Train Accuracy: 60.60%, Test Loss: 0.8321, Test Accuracy: 65.82%\n",
      "Epoch [2106/2500], Train Loss: 0.8390, Train Accuracy: 62.87%, Test Loss: 0.8422, Test Accuracy: 63.29%\n",
      "Epoch [2107/2500], Train Loss: 0.8281, Train Accuracy: 63.16%, Test Loss: 0.8348, Test Accuracy: 64.56%\n",
      "Epoch [2108/2500], Train Loss: 0.8205, Train Accuracy: 62.73%, Test Loss: 0.8345, Test Accuracy: 64.56%\n",
      "Epoch [2109/2500], Train Loss: 0.8131, Train Accuracy: 62.02%, Test Loss: 0.8372, Test Accuracy: 65.82%\n",
      "Epoch [2110/2500], Train Loss: 0.8227, Train Accuracy: 62.16%, Test Loss: 0.8310, Test Accuracy: 65.82%\n",
      "Epoch [2111/2500], Train Loss: 0.8261, Train Accuracy: 62.87%, Test Loss: 0.8419, Test Accuracy: 64.56%\n",
      "Epoch [2112/2500], Train Loss: 0.8340, Train Accuracy: 63.30%, Test Loss: 0.8356, Test Accuracy: 67.09%\n",
      "Epoch [2113/2500], Train Loss: 0.8269, Train Accuracy: 61.31%, Test Loss: 0.8294, Test Accuracy: 67.09%\n",
      "Epoch [2114/2500], Train Loss: 0.8220, Train Accuracy: 61.02%, Test Loss: 0.8453, Test Accuracy: 65.82%\n",
      "Epoch [2115/2500], Train Loss: 0.8291, Train Accuracy: 61.74%, Test Loss: 0.8616, Test Accuracy: 67.09%\n",
      "Epoch [2116/2500], Train Loss: 0.8231, Train Accuracy: 62.87%, Test Loss: 0.8519, Test Accuracy: 67.09%\n",
      "Epoch [2117/2500], Train Loss: 0.8182, Train Accuracy: 61.02%, Test Loss: 0.8369, Test Accuracy: 65.82%\n",
      "Epoch [2118/2500], Train Loss: 0.8057, Train Accuracy: 63.44%, Test Loss: 0.8344, Test Accuracy: 64.56%\n",
      "Epoch [2119/2500], Train Loss: 0.8218, Train Accuracy: 63.44%, Test Loss: 0.8428, Test Accuracy: 65.82%\n",
      "Epoch [2120/2500], Train Loss: 0.8260, Train Accuracy: 62.73%, Test Loss: 0.8462, Test Accuracy: 64.56%\n",
      "Epoch [2121/2500], Train Loss: 0.8414, Train Accuracy: 62.02%, Test Loss: 0.8461, Test Accuracy: 65.82%\n",
      "Epoch [2122/2500], Train Loss: 0.8224, Train Accuracy: 62.59%, Test Loss: 0.8335, Test Accuracy: 65.82%\n",
      "Epoch [2123/2500], Train Loss: 0.8152, Train Accuracy: 61.88%, Test Loss: 0.8358, Test Accuracy: 64.56%\n",
      "Epoch [2124/2500], Train Loss: 0.8300, Train Accuracy: 62.02%, Test Loss: 0.8311, Test Accuracy: 65.82%\n",
      "Epoch [2125/2500], Train Loss: 0.8211, Train Accuracy: 62.73%, Test Loss: 0.8456, Test Accuracy: 67.09%\n",
      "Epoch [2126/2500], Train Loss: 0.8238, Train Accuracy: 62.30%, Test Loss: 0.8659, Test Accuracy: 67.09%\n",
      "Epoch [2127/2500], Train Loss: 0.8173, Train Accuracy: 62.73%, Test Loss: 0.8518, Test Accuracy: 65.82%\n",
      "Epoch [2128/2500], Train Loss: 0.8302, Train Accuracy: 62.87%, Test Loss: 0.8461, Test Accuracy: 65.82%\n",
      "Epoch [2129/2500], Train Loss: 0.8094, Train Accuracy: 63.58%, Test Loss: 0.8268, Test Accuracy: 65.82%\n",
      "Epoch [2130/2500], Train Loss: 0.8307, Train Accuracy: 63.73%, Test Loss: 0.8378, Test Accuracy: 65.82%\n",
      "Epoch [2131/2500], Train Loss: 0.8291, Train Accuracy: 62.30%, Test Loss: 0.8611, Test Accuracy: 65.82%\n",
      "Epoch [2132/2500], Train Loss: 0.8071, Train Accuracy: 64.01%, Test Loss: 0.8540, Test Accuracy: 65.82%\n",
      "Epoch [2133/2500], Train Loss: 0.8287, Train Accuracy: 63.16%, Test Loss: 0.8465, Test Accuracy: 67.09%\n",
      "Epoch [2134/2500], Train Loss: 0.8374, Train Accuracy: 61.74%, Test Loss: 0.8598, Test Accuracy: 65.82%\n",
      "Epoch [2135/2500], Train Loss: 0.8327, Train Accuracy: 63.30%, Test Loss: 0.8498, Test Accuracy: 67.09%\n",
      "Epoch [2136/2500], Train Loss: 0.8211, Train Accuracy: 63.87%, Test Loss: 0.8516, Test Accuracy: 64.56%\n",
      "Epoch [2137/2500], Train Loss: 0.8213, Train Accuracy: 62.45%, Test Loss: 0.8431, Test Accuracy: 64.56%\n",
      "Epoch [2138/2500], Train Loss: 0.8322, Train Accuracy: 61.45%, Test Loss: 0.8447, Test Accuracy: 64.56%\n",
      "Epoch [2139/2500], Train Loss: 0.8202, Train Accuracy: 62.59%, Test Loss: 0.8464, Test Accuracy: 67.09%\n",
      "Epoch [2140/2500], Train Loss: 0.8258, Train Accuracy: 62.16%, Test Loss: 0.8681, Test Accuracy: 64.56%\n",
      "Epoch [2141/2500], Train Loss: 0.8104, Train Accuracy: 61.88%, Test Loss: 0.8512, Test Accuracy: 64.56%\n",
      "Epoch [2142/2500], Train Loss: 0.8196, Train Accuracy: 61.31%, Test Loss: 0.8624, Test Accuracy: 64.56%\n",
      "Epoch [2143/2500], Train Loss: 0.8281, Train Accuracy: 62.16%, Test Loss: 0.8523, Test Accuracy: 65.82%\n",
      "Epoch [2144/2500], Train Loss: 0.8361, Train Accuracy: 62.30%, Test Loss: 0.8412, Test Accuracy: 64.56%\n",
      "Epoch [2145/2500], Train Loss: 0.8296, Train Accuracy: 63.02%, Test Loss: 0.8418, Test Accuracy: 64.56%\n",
      "Epoch [2146/2500], Train Loss: 0.8321, Train Accuracy: 61.59%, Test Loss: 0.8474, Test Accuracy: 64.56%\n",
      "Epoch [2147/2500], Train Loss: 0.8259, Train Accuracy: 62.30%, Test Loss: 0.8379, Test Accuracy: 64.56%\n",
      "Epoch [2148/2500], Train Loss: 0.8084, Train Accuracy: 64.86%, Test Loss: 0.8513, Test Accuracy: 64.56%\n",
      "Epoch [2149/2500], Train Loss: 0.8247, Train Accuracy: 64.01%, Test Loss: 0.8371, Test Accuracy: 63.29%\n",
      "Epoch [2150/2500], Train Loss: 0.8141, Train Accuracy: 63.87%, Test Loss: 0.8578, Test Accuracy: 64.56%\n",
      "Epoch [2151/2500], Train Loss: 0.8150, Train Accuracy: 63.73%, Test Loss: 0.8560, Test Accuracy: 65.82%\n",
      "Epoch [2152/2500], Train Loss: 0.8325, Train Accuracy: 62.87%, Test Loss: 0.8459, Test Accuracy: 65.82%\n",
      "Epoch [2153/2500], Train Loss: 0.8010, Train Accuracy: 64.01%, Test Loss: 0.8361, Test Accuracy: 65.82%\n",
      "Epoch [2154/2500], Train Loss: 0.8219, Train Accuracy: 61.59%, Test Loss: 0.8412, Test Accuracy: 65.82%\n",
      "Epoch [2155/2500], Train Loss: 0.8156, Train Accuracy: 62.73%, Test Loss: 0.8538, Test Accuracy: 65.82%\n",
      "Epoch [2156/2500], Train Loss: 0.8289, Train Accuracy: 61.59%, Test Loss: 0.8435, Test Accuracy: 65.82%\n",
      "Epoch [2157/2500], Train Loss: 0.8119, Train Accuracy: 65.01%, Test Loss: 0.8484, Test Accuracy: 64.56%\n",
      "Epoch [2158/2500], Train Loss: 0.8043, Train Accuracy: 64.58%, Test Loss: 0.8560, Test Accuracy: 64.56%\n",
      "Epoch [2159/2500], Train Loss: 0.8146, Train Accuracy: 63.44%, Test Loss: 0.8579, Test Accuracy: 65.82%\n",
      "Epoch [2160/2500], Train Loss: 0.8078, Train Accuracy: 62.73%, Test Loss: 0.8500, Test Accuracy: 65.82%\n",
      "Epoch [2161/2500], Train Loss: 0.8213, Train Accuracy: 62.45%, Test Loss: 0.8489, Test Accuracy: 65.82%\n",
      "Epoch [2162/2500], Train Loss: 0.8130, Train Accuracy: 63.58%, Test Loss: 0.8616, Test Accuracy: 65.82%\n",
      "Epoch [2163/2500], Train Loss: 0.8185, Train Accuracy: 62.87%, Test Loss: 0.8643, Test Accuracy: 65.82%\n",
      "Epoch [2164/2500], Train Loss: 0.8233, Train Accuracy: 62.59%, Test Loss: 0.8410, Test Accuracy: 65.82%\n",
      "Epoch [2165/2500], Train Loss: 0.7934, Train Accuracy: 64.30%, Test Loss: 0.8331, Test Accuracy: 67.09%\n",
      "Epoch [2166/2500], Train Loss: 0.8144, Train Accuracy: 61.88%, Test Loss: 0.8542, Test Accuracy: 64.56%\n",
      "Epoch [2167/2500], Train Loss: 0.8276, Train Accuracy: 62.45%, Test Loss: 0.8561, Test Accuracy: 64.56%\n",
      "Epoch [2168/2500], Train Loss: 0.8202, Train Accuracy: 63.44%, Test Loss: 0.8608, Test Accuracy: 64.56%\n",
      "Epoch [2169/2500], Train Loss: 0.8397, Train Accuracy: 61.59%, Test Loss: 0.8568, Test Accuracy: 64.56%\n",
      "Epoch [2170/2500], Train Loss: 0.8335, Train Accuracy: 61.88%, Test Loss: 0.8568, Test Accuracy: 64.56%\n",
      "Epoch [2171/2500], Train Loss: 0.8077, Train Accuracy: 63.73%, Test Loss: 0.8228, Test Accuracy: 65.82%\n",
      "Epoch [2172/2500], Train Loss: 0.8305, Train Accuracy: 62.16%, Test Loss: 0.8175, Test Accuracy: 64.56%\n",
      "Epoch [2173/2500], Train Loss: 0.8082, Train Accuracy: 62.59%, Test Loss: 0.8154, Test Accuracy: 63.29%\n",
      "Epoch [2174/2500], Train Loss: 0.8037, Train Accuracy: 62.59%, Test Loss: 0.8353, Test Accuracy: 63.29%\n",
      "Epoch [2175/2500], Train Loss: 0.8200, Train Accuracy: 61.45%, Test Loss: 0.8431, Test Accuracy: 63.29%\n",
      "Epoch [2176/2500], Train Loss: 0.8231, Train Accuracy: 64.30%, Test Loss: 0.8469, Test Accuracy: 64.56%\n",
      "Epoch [2177/2500], Train Loss: 0.8124, Train Accuracy: 62.45%, Test Loss: 0.8511, Test Accuracy: 64.56%\n",
      "Epoch [2178/2500], Train Loss: 0.8064, Train Accuracy: 65.01%, Test Loss: 0.8538, Test Accuracy: 65.82%\n",
      "Epoch [2179/2500], Train Loss: 0.8250, Train Accuracy: 62.30%, Test Loss: 0.8542, Test Accuracy: 65.82%\n",
      "Epoch [2180/2500], Train Loss: 0.8299, Train Accuracy: 63.16%, Test Loss: 0.8554, Test Accuracy: 64.56%\n",
      "Epoch [2181/2500], Train Loss: 0.8276, Train Accuracy: 64.30%, Test Loss: 0.8465, Test Accuracy: 64.56%\n",
      "Epoch [2182/2500], Train Loss: 0.8271, Train Accuracy: 62.73%, Test Loss: 0.8434, Test Accuracy: 65.82%\n",
      "Epoch [2183/2500], Train Loss: 0.8330, Train Accuracy: 62.16%, Test Loss: 0.8567, Test Accuracy: 63.29%\n",
      "Epoch [2184/2500], Train Loss: 0.8183, Train Accuracy: 62.73%, Test Loss: 0.8423, Test Accuracy: 64.56%\n",
      "Epoch [2185/2500], Train Loss: 0.8304, Train Accuracy: 62.30%, Test Loss: 0.8349, Test Accuracy: 64.56%\n",
      "Epoch [2186/2500], Train Loss: 0.8215, Train Accuracy: 62.73%, Test Loss: 0.8397, Test Accuracy: 64.56%\n",
      "Epoch [2187/2500], Train Loss: 0.8088, Train Accuracy: 63.58%, Test Loss: 0.8342, Test Accuracy: 65.82%\n",
      "Epoch [2188/2500], Train Loss: 0.8238, Train Accuracy: 61.59%, Test Loss: 0.8397, Test Accuracy: 64.56%\n",
      "Epoch [2189/2500], Train Loss: 0.8113, Train Accuracy: 63.16%, Test Loss: 0.8279, Test Accuracy: 64.56%\n",
      "Epoch [2190/2500], Train Loss: 0.7998, Train Accuracy: 64.44%, Test Loss: 0.8283, Test Accuracy: 67.09%\n",
      "Epoch [2191/2500], Train Loss: 0.8107, Train Accuracy: 63.02%, Test Loss: 0.8276, Test Accuracy: 64.56%\n",
      "Epoch [2192/2500], Train Loss: 0.8211, Train Accuracy: 60.74%, Test Loss: 0.8361, Test Accuracy: 64.56%\n",
      "Epoch [2193/2500], Train Loss: 0.8176, Train Accuracy: 64.01%, Test Loss: 0.8349, Test Accuracy: 64.56%\n",
      "Epoch [2194/2500], Train Loss: 0.8149, Train Accuracy: 63.87%, Test Loss: 0.8227, Test Accuracy: 63.29%\n",
      "Epoch [2195/2500], Train Loss: 0.8062, Train Accuracy: 62.45%, Test Loss: 0.8307, Test Accuracy: 64.56%\n",
      "Epoch [2196/2500], Train Loss: 0.8306, Train Accuracy: 61.31%, Test Loss: 0.8245, Test Accuracy: 64.56%\n",
      "Epoch [2197/2500], Train Loss: 0.8372, Train Accuracy: 63.73%, Test Loss: 0.8309, Test Accuracy: 64.56%\n",
      "Epoch [2198/2500], Train Loss: 0.8146, Train Accuracy: 62.30%, Test Loss: 0.8430, Test Accuracy: 64.56%\n",
      "Epoch [2199/2500], Train Loss: 0.8284, Train Accuracy: 63.16%, Test Loss: 0.8307, Test Accuracy: 63.29%\n",
      "Epoch [2200/2500], Train Loss: 0.8359, Train Accuracy: 61.45%, Test Loss: 0.8447, Test Accuracy: 63.29%\n",
      "Epoch [2201/2500], Train Loss: 0.8207, Train Accuracy: 63.87%, Test Loss: 0.8528, Test Accuracy: 62.03%\n",
      "Epoch [2202/2500], Train Loss: 0.8252, Train Accuracy: 64.30%, Test Loss: 0.8646, Test Accuracy: 64.56%\n",
      "Epoch [2203/2500], Train Loss: 0.8229, Train Accuracy: 61.74%, Test Loss: 0.8341, Test Accuracy: 63.29%\n",
      "Epoch [2204/2500], Train Loss: 0.8444, Train Accuracy: 60.03%, Test Loss: 0.8448, Test Accuracy: 64.56%\n",
      "Epoch [2205/2500], Train Loss: 0.8239, Train Accuracy: 62.59%, Test Loss: 0.8409, Test Accuracy: 64.56%\n",
      "Epoch [2206/2500], Train Loss: 0.8150, Train Accuracy: 61.59%, Test Loss: 0.8342, Test Accuracy: 64.56%\n",
      "Epoch [2207/2500], Train Loss: 0.8116, Train Accuracy: 64.44%, Test Loss: 0.8475, Test Accuracy: 63.29%\n",
      "Epoch [2208/2500], Train Loss: 0.8222, Train Accuracy: 61.17%, Test Loss: 0.8281, Test Accuracy: 64.56%\n",
      "Epoch [2209/2500], Train Loss: 0.8196, Train Accuracy: 61.17%, Test Loss: 0.8417, Test Accuracy: 64.56%\n",
      "Epoch [2210/2500], Train Loss: 0.8399, Train Accuracy: 62.30%, Test Loss: 0.8417, Test Accuracy: 65.82%\n",
      "Epoch [2211/2500], Train Loss: 0.8145, Train Accuracy: 62.87%, Test Loss: 0.8242, Test Accuracy: 65.82%\n",
      "Epoch [2212/2500], Train Loss: 0.8097, Train Accuracy: 62.45%, Test Loss: 0.8336, Test Accuracy: 65.82%\n",
      "Epoch [2213/2500], Train Loss: 0.8012, Train Accuracy: 63.73%, Test Loss: 0.8328, Test Accuracy: 65.82%\n",
      "Epoch [2214/2500], Train Loss: 0.8033, Train Accuracy: 62.59%, Test Loss: 0.8300, Test Accuracy: 65.82%\n",
      "Epoch [2215/2500], Train Loss: 0.8026, Train Accuracy: 64.30%, Test Loss: 0.8386, Test Accuracy: 65.82%\n",
      "Epoch [2216/2500], Train Loss: 0.8133, Train Accuracy: 63.30%, Test Loss: 0.8419, Test Accuracy: 67.09%\n",
      "Epoch [2217/2500], Train Loss: 0.8199, Train Accuracy: 63.58%, Test Loss: 0.8561, Test Accuracy: 63.29%\n",
      "Epoch [2218/2500], Train Loss: 0.8132, Train Accuracy: 63.02%, Test Loss: 0.8271, Test Accuracy: 64.56%\n",
      "Epoch [2219/2500], Train Loss: 0.8130, Train Accuracy: 62.30%, Test Loss: 0.8205, Test Accuracy: 64.56%\n",
      "Epoch [2220/2500], Train Loss: 0.7922, Train Accuracy: 66.00%, Test Loss: 0.8457, Test Accuracy: 65.82%\n",
      "Epoch [2221/2500], Train Loss: 0.8110, Train Accuracy: 62.30%, Test Loss: 0.8547, Test Accuracy: 64.56%\n",
      "Epoch [2222/2500], Train Loss: 0.8165, Train Accuracy: 62.87%, Test Loss: 0.8455, Test Accuracy: 65.82%\n",
      "Epoch [2223/2500], Train Loss: 0.8200, Train Accuracy: 62.87%, Test Loss: 0.8446, Test Accuracy: 65.82%\n",
      "Epoch [2224/2500], Train Loss: 0.8049, Train Accuracy: 62.73%, Test Loss: 0.8524, Test Accuracy: 64.56%\n",
      "Epoch [2225/2500], Train Loss: 0.8121, Train Accuracy: 64.01%, Test Loss: 0.8396, Test Accuracy: 65.82%\n",
      "Epoch [2226/2500], Train Loss: 0.7983, Train Accuracy: 63.44%, Test Loss: 0.8470, Test Accuracy: 64.56%\n",
      "Epoch [2227/2500], Train Loss: 0.8088, Train Accuracy: 65.01%, Test Loss: 0.8497, Test Accuracy: 64.56%\n",
      "Epoch [2228/2500], Train Loss: 0.8282, Train Accuracy: 61.59%, Test Loss: 0.8538, Test Accuracy: 63.29%\n",
      "Epoch [2229/2500], Train Loss: 0.8174, Train Accuracy: 63.58%, Test Loss: 0.8532, Test Accuracy: 63.29%\n",
      "Epoch [2230/2500], Train Loss: 0.8243, Train Accuracy: 64.58%, Test Loss: 0.8390, Test Accuracy: 64.56%\n",
      "Epoch [2231/2500], Train Loss: 0.8069, Train Accuracy: 61.88%, Test Loss: 0.8121, Test Accuracy: 64.56%\n",
      "Epoch [2232/2500], Train Loss: 0.8170, Train Accuracy: 62.45%, Test Loss: 0.8096, Test Accuracy: 65.82%\n",
      "Epoch [2233/2500], Train Loss: 0.8216, Train Accuracy: 62.02%, Test Loss: 0.8338, Test Accuracy: 64.56%\n",
      "Epoch [2234/2500], Train Loss: 0.8099, Train Accuracy: 63.58%, Test Loss: 0.8402, Test Accuracy: 63.29%\n",
      "Epoch [2235/2500], Train Loss: 0.8261, Train Accuracy: 62.45%, Test Loss: 0.8541, Test Accuracy: 63.29%\n",
      "Epoch [2236/2500], Train Loss: 0.8027, Train Accuracy: 64.72%, Test Loss: 0.8448, Test Accuracy: 67.09%\n",
      "Epoch [2237/2500], Train Loss: 0.8129, Train Accuracy: 63.58%, Test Loss: 0.8500, Test Accuracy: 64.56%\n",
      "Epoch [2238/2500], Train Loss: 0.8128, Train Accuracy: 63.16%, Test Loss: 0.8308, Test Accuracy: 65.82%\n",
      "Epoch [2239/2500], Train Loss: 0.8181, Train Accuracy: 63.16%, Test Loss: 0.8414, Test Accuracy: 65.82%\n",
      "Epoch [2240/2500], Train Loss: 0.8186, Train Accuracy: 63.87%, Test Loss: 0.8311, Test Accuracy: 63.29%\n",
      "Epoch [2241/2500], Train Loss: 0.8010, Train Accuracy: 63.87%, Test Loss: 0.8499, Test Accuracy: 64.56%\n",
      "Epoch [2242/2500], Train Loss: 0.8230, Train Accuracy: 62.30%, Test Loss: 0.8369, Test Accuracy: 65.82%\n",
      "Epoch [2243/2500], Train Loss: 0.8282, Train Accuracy: 63.02%, Test Loss: 0.8454, Test Accuracy: 64.56%\n",
      "Epoch [2244/2500], Train Loss: 0.8048, Train Accuracy: 63.58%, Test Loss: 0.8590, Test Accuracy: 64.56%\n",
      "Epoch [2245/2500], Train Loss: 0.8125, Train Accuracy: 61.88%, Test Loss: 0.8413, Test Accuracy: 64.56%\n",
      "Epoch [2246/2500], Train Loss: 0.8230, Train Accuracy: 62.59%, Test Loss: 0.8420, Test Accuracy: 64.56%\n",
      "Epoch [2247/2500], Train Loss: 0.8349, Train Accuracy: 63.30%, Test Loss: 0.8525, Test Accuracy: 64.56%\n",
      "Epoch [2248/2500], Train Loss: 0.8092, Train Accuracy: 64.30%, Test Loss: 0.8273, Test Accuracy: 64.56%\n",
      "Epoch [2249/2500], Train Loss: 0.8323, Train Accuracy: 61.88%, Test Loss: 0.8185, Test Accuracy: 64.56%\n",
      "Epoch [2250/2500], Train Loss: 0.8131, Train Accuracy: 63.44%, Test Loss: 0.8456, Test Accuracy: 64.56%\n",
      "Epoch [2251/2500], Train Loss: 0.8047, Train Accuracy: 63.58%, Test Loss: 0.8252, Test Accuracy: 64.56%\n",
      "Epoch [2252/2500], Train Loss: 0.8085, Train Accuracy: 62.73%, Test Loss: 0.8384, Test Accuracy: 64.56%\n",
      "Epoch [2253/2500], Train Loss: 0.8204, Train Accuracy: 63.16%, Test Loss: 0.8401, Test Accuracy: 65.82%\n",
      "Epoch [2254/2500], Train Loss: 0.8209, Train Accuracy: 62.87%, Test Loss: 0.8407, Test Accuracy: 64.56%\n",
      "Epoch [2255/2500], Train Loss: 0.8315, Train Accuracy: 63.16%, Test Loss: 0.8448, Test Accuracy: 64.56%\n",
      "Epoch [2256/2500], Train Loss: 0.8224, Train Accuracy: 63.30%, Test Loss: 0.8529, Test Accuracy: 64.56%\n",
      "Epoch [2257/2500], Train Loss: 0.8030, Train Accuracy: 62.73%, Test Loss: 0.8366, Test Accuracy: 64.56%\n",
      "Epoch [2258/2500], Train Loss: 0.8438, Train Accuracy: 62.30%, Test Loss: 0.8280, Test Accuracy: 64.56%\n",
      "Epoch [2259/2500], Train Loss: 0.8137, Train Accuracy: 62.16%, Test Loss: 0.8317, Test Accuracy: 64.56%\n",
      "Epoch [2260/2500], Train Loss: 0.8102, Train Accuracy: 62.73%, Test Loss: 0.8270, Test Accuracy: 63.29%\n",
      "Epoch [2261/2500], Train Loss: 0.8161, Train Accuracy: 62.45%, Test Loss: 0.8339, Test Accuracy: 64.56%\n",
      "Epoch [2262/2500], Train Loss: 0.8125, Train Accuracy: 63.16%, Test Loss: 0.8257, Test Accuracy: 64.56%\n",
      "Epoch [2263/2500], Train Loss: 0.8110, Train Accuracy: 61.31%, Test Loss: 0.8477, Test Accuracy: 64.56%\n",
      "Epoch [2264/2500], Train Loss: 0.8255, Train Accuracy: 63.16%, Test Loss: 0.8421, Test Accuracy: 64.56%\n",
      "Epoch [2265/2500], Train Loss: 0.8182, Train Accuracy: 64.15%, Test Loss: 0.8448, Test Accuracy: 67.09%\n",
      "Epoch [2266/2500], Train Loss: 0.8043, Train Accuracy: 63.16%, Test Loss: 0.8407, Test Accuracy: 64.56%\n",
      "Epoch [2267/2500], Train Loss: 0.8011, Train Accuracy: 63.44%, Test Loss: 0.8406, Test Accuracy: 64.56%\n",
      "Epoch [2268/2500], Train Loss: 0.8113, Train Accuracy: 63.44%, Test Loss: 0.8493, Test Accuracy: 65.82%\n",
      "Epoch [2269/2500], Train Loss: 0.8194, Train Accuracy: 62.16%, Test Loss: 0.8471, Test Accuracy: 64.56%\n",
      "Epoch [2270/2500], Train Loss: 0.8282, Train Accuracy: 63.16%, Test Loss: 0.8363, Test Accuracy: 64.56%\n",
      "Epoch [2271/2500], Train Loss: 0.7921, Train Accuracy: 64.58%, Test Loss: 0.8172, Test Accuracy: 67.09%\n",
      "Epoch [2272/2500], Train Loss: 0.8114, Train Accuracy: 63.30%, Test Loss: 0.8305, Test Accuracy: 64.56%\n",
      "Epoch [2273/2500], Train Loss: 0.8098, Train Accuracy: 62.30%, Test Loss: 0.8317, Test Accuracy: 64.56%\n",
      "Epoch [2274/2500], Train Loss: 0.8186, Train Accuracy: 62.30%, Test Loss: 0.8213, Test Accuracy: 64.56%\n",
      "Epoch [2275/2500], Train Loss: 0.8165, Train Accuracy: 63.87%, Test Loss: 0.8428, Test Accuracy: 65.82%\n",
      "Epoch [2276/2500], Train Loss: 0.8189, Train Accuracy: 63.02%, Test Loss: 0.8436, Test Accuracy: 64.56%\n",
      "Epoch [2277/2500], Train Loss: 0.8252, Train Accuracy: 62.30%, Test Loss: 0.8314, Test Accuracy: 64.56%\n",
      "Epoch [2278/2500], Train Loss: 0.8077, Train Accuracy: 63.87%, Test Loss: 0.8430, Test Accuracy: 64.56%\n",
      "Epoch [2279/2500], Train Loss: 0.8242, Train Accuracy: 63.58%, Test Loss: 0.8424, Test Accuracy: 64.56%\n",
      "Epoch [2280/2500], Train Loss: 0.8074, Train Accuracy: 63.30%, Test Loss: 0.8429, Test Accuracy: 64.56%\n",
      "Epoch [2281/2500], Train Loss: 0.8087, Train Accuracy: 63.30%, Test Loss: 0.8239, Test Accuracy: 64.56%\n",
      "Epoch [2282/2500], Train Loss: 0.8229, Train Accuracy: 63.87%, Test Loss: 0.8352, Test Accuracy: 67.09%\n",
      "Epoch [2283/2500], Train Loss: 0.8152, Train Accuracy: 63.30%, Test Loss: 0.8488, Test Accuracy: 64.56%\n",
      "Epoch [2284/2500], Train Loss: 0.8173, Train Accuracy: 62.87%, Test Loss: 0.8444, Test Accuracy: 64.56%\n",
      "Epoch [2285/2500], Train Loss: 0.8089, Train Accuracy: 62.16%, Test Loss: 0.8095, Test Accuracy: 64.56%\n",
      "Epoch [2286/2500], Train Loss: 0.8385, Train Accuracy: 63.58%, Test Loss: 0.8347, Test Accuracy: 64.56%\n",
      "Epoch [2287/2500], Train Loss: 0.8001, Train Accuracy: 62.45%, Test Loss: 0.8551, Test Accuracy: 64.56%\n",
      "Epoch [2288/2500], Train Loss: 0.7936, Train Accuracy: 65.15%, Test Loss: 0.8549, Test Accuracy: 65.82%\n",
      "Epoch [2289/2500], Train Loss: 0.8092, Train Accuracy: 62.87%, Test Loss: 0.8660, Test Accuracy: 64.56%\n",
      "Epoch [2290/2500], Train Loss: 0.8232, Train Accuracy: 64.44%, Test Loss: 0.8632, Test Accuracy: 65.82%\n",
      "Epoch [2291/2500], Train Loss: 0.8079, Train Accuracy: 62.30%, Test Loss: 0.8586, Test Accuracy: 64.56%\n",
      "Epoch [2292/2500], Train Loss: 0.8358, Train Accuracy: 61.17%, Test Loss: 0.8670, Test Accuracy: 63.29%\n",
      "Epoch [2293/2500], Train Loss: 0.8001, Train Accuracy: 63.44%, Test Loss: 0.8469, Test Accuracy: 64.56%\n",
      "Epoch [2294/2500], Train Loss: 0.8106, Train Accuracy: 62.02%, Test Loss: 0.8453, Test Accuracy: 63.29%\n",
      "Epoch [2295/2500], Train Loss: 0.8187, Train Accuracy: 62.87%, Test Loss: 0.8397, Test Accuracy: 63.29%\n",
      "Epoch [2296/2500], Train Loss: 0.8152, Train Accuracy: 62.87%, Test Loss: 0.8310, Test Accuracy: 63.29%\n",
      "Epoch [2297/2500], Train Loss: 0.8209, Train Accuracy: 62.45%, Test Loss: 0.8231, Test Accuracy: 64.56%\n",
      "Epoch [2298/2500], Train Loss: 0.8052, Train Accuracy: 64.44%, Test Loss: 0.8305, Test Accuracy: 64.56%\n",
      "Epoch [2299/2500], Train Loss: 0.8134, Train Accuracy: 63.58%, Test Loss: 0.8292, Test Accuracy: 64.56%\n",
      "Epoch [2300/2500], Train Loss: 0.8335, Train Accuracy: 62.45%, Test Loss: 0.8320, Test Accuracy: 64.56%\n",
      "Epoch [2301/2500], Train Loss: 0.8279, Train Accuracy: 62.73%, Test Loss: 0.8355, Test Accuracy: 63.29%\n",
      "Epoch [2302/2500], Train Loss: 0.8266, Train Accuracy: 61.88%, Test Loss: 0.8322, Test Accuracy: 64.56%\n",
      "Epoch [2303/2500], Train Loss: 0.7913, Train Accuracy: 63.44%, Test Loss: 0.8257, Test Accuracy: 63.29%\n",
      "Epoch [2304/2500], Train Loss: 0.8041, Train Accuracy: 63.02%, Test Loss: 0.8209, Test Accuracy: 64.56%\n",
      "Epoch [2305/2500], Train Loss: 0.7911, Train Accuracy: 64.58%, Test Loss: 0.8226, Test Accuracy: 64.56%\n",
      "Epoch [2306/2500], Train Loss: 0.8128, Train Accuracy: 63.02%, Test Loss: 0.8304, Test Accuracy: 64.56%\n",
      "Epoch [2307/2500], Train Loss: 0.8261, Train Accuracy: 61.31%, Test Loss: 0.8393, Test Accuracy: 63.29%\n",
      "Epoch [2308/2500], Train Loss: 0.7897, Train Accuracy: 66.00%, Test Loss: 0.8360, Test Accuracy: 64.56%\n",
      "Epoch [2309/2500], Train Loss: 0.8257, Train Accuracy: 60.74%, Test Loss: 0.8335, Test Accuracy: 64.56%\n",
      "Epoch [2310/2500], Train Loss: 0.8121, Train Accuracy: 62.87%, Test Loss: 0.8356, Test Accuracy: 63.29%\n",
      "Epoch [2311/2500], Train Loss: 0.8088, Train Accuracy: 63.87%, Test Loss: 0.8416, Test Accuracy: 63.29%\n",
      "Epoch [2312/2500], Train Loss: 0.8109, Train Accuracy: 61.88%, Test Loss: 0.8350, Test Accuracy: 64.56%\n",
      "Epoch [2313/2500], Train Loss: 0.8223, Train Accuracy: 62.45%, Test Loss: 0.8196, Test Accuracy: 64.56%\n",
      "Epoch [2314/2500], Train Loss: 0.8308, Train Accuracy: 62.16%, Test Loss: 0.8417, Test Accuracy: 64.56%\n",
      "Epoch [2315/2500], Train Loss: 0.8245, Train Accuracy: 63.30%, Test Loss: 0.8453, Test Accuracy: 64.56%\n",
      "Epoch [2316/2500], Train Loss: 0.8194, Train Accuracy: 62.59%, Test Loss: 0.8422, Test Accuracy: 64.56%\n",
      "Epoch [2317/2500], Train Loss: 0.8150, Train Accuracy: 62.16%, Test Loss: 0.8579, Test Accuracy: 64.56%\n",
      "Epoch [2318/2500], Train Loss: 0.8216, Train Accuracy: 62.30%, Test Loss: 0.8447, Test Accuracy: 64.56%\n",
      "Epoch [2319/2500], Train Loss: 0.8032, Train Accuracy: 65.15%, Test Loss: 0.8350, Test Accuracy: 63.29%\n",
      "Epoch [2320/2500], Train Loss: 0.8079, Train Accuracy: 62.16%, Test Loss: 0.8498, Test Accuracy: 64.56%\n",
      "Epoch [2321/2500], Train Loss: 0.8242, Train Accuracy: 63.58%, Test Loss: 0.8495, Test Accuracy: 63.29%\n",
      "Epoch [2322/2500], Train Loss: 0.8178, Train Accuracy: 64.15%, Test Loss: 0.8336, Test Accuracy: 64.56%\n",
      "Epoch [2323/2500], Train Loss: 0.8022, Train Accuracy: 61.17%, Test Loss: 0.8350, Test Accuracy: 64.56%\n",
      "Epoch [2324/2500], Train Loss: 0.8016, Train Accuracy: 63.44%, Test Loss: 0.8508, Test Accuracy: 64.56%\n",
      "Epoch [2325/2500], Train Loss: 0.8028, Train Accuracy: 63.73%, Test Loss: 0.8398, Test Accuracy: 64.56%\n",
      "Epoch [2326/2500], Train Loss: 0.8111, Train Accuracy: 62.73%, Test Loss: 0.8558, Test Accuracy: 63.29%\n",
      "Epoch [2327/2500], Train Loss: 0.8224, Train Accuracy: 63.44%, Test Loss: 0.8444, Test Accuracy: 64.56%\n",
      "Epoch [2328/2500], Train Loss: 0.8323, Train Accuracy: 62.87%, Test Loss: 0.8440, Test Accuracy: 64.56%\n",
      "Epoch [2329/2500], Train Loss: 0.8291, Train Accuracy: 61.59%, Test Loss: 0.8523, Test Accuracy: 64.56%\n",
      "Epoch [2330/2500], Train Loss: 0.8316, Train Accuracy: 62.45%, Test Loss: 0.8305, Test Accuracy: 64.56%\n",
      "Epoch [2331/2500], Train Loss: 0.8151, Train Accuracy: 62.87%, Test Loss: 0.8388, Test Accuracy: 64.56%\n",
      "Epoch [2332/2500], Train Loss: 0.8105, Train Accuracy: 62.16%, Test Loss: 0.8453, Test Accuracy: 64.56%\n",
      "Epoch [2333/2500], Train Loss: 0.8064, Train Accuracy: 63.44%, Test Loss: 0.8240, Test Accuracy: 64.56%\n",
      "Epoch [2334/2500], Train Loss: 0.8013, Train Accuracy: 63.58%, Test Loss: 0.8267, Test Accuracy: 63.29%\n",
      "Epoch [2335/2500], Train Loss: 0.8149, Train Accuracy: 64.01%, Test Loss: 0.8238, Test Accuracy: 63.29%\n",
      "Epoch [2336/2500], Train Loss: 0.8171, Train Accuracy: 61.45%, Test Loss: 0.8116, Test Accuracy: 64.56%\n",
      "Epoch [2337/2500], Train Loss: 0.8042, Train Accuracy: 64.01%, Test Loss: 0.8168, Test Accuracy: 64.56%\n",
      "Epoch [2338/2500], Train Loss: 0.8309, Train Accuracy: 61.45%, Test Loss: 0.8339, Test Accuracy: 64.56%\n",
      "Epoch [2339/2500], Train Loss: 0.7981, Train Accuracy: 64.01%, Test Loss: 0.8457, Test Accuracy: 64.56%\n",
      "Epoch [2340/2500], Train Loss: 0.8151, Train Accuracy: 63.58%, Test Loss: 0.8478, Test Accuracy: 63.29%\n",
      "Epoch [2341/2500], Train Loss: 0.7998, Train Accuracy: 64.15%, Test Loss: 0.8487, Test Accuracy: 64.56%\n",
      "Epoch [2342/2500], Train Loss: 0.7947, Train Accuracy: 65.29%, Test Loss: 0.8323, Test Accuracy: 64.56%\n",
      "Epoch [2343/2500], Train Loss: 0.8178, Train Accuracy: 63.73%, Test Loss: 0.8335, Test Accuracy: 64.56%\n",
      "Epoch [2344/2500], Train Loss: 0.8135, Train Accuracy: 62.87%, Test Loss: 0.8371, Test Accuracy: 64.56%\n",
      "Epoch [2345/2500], Train Loss: 0.8135, Train Accuracy: 63.73%, Test Loss: 0.8305, Test Accuracy: 63.29%\n",
      "Epoch [2346/2500], Train Loss: 0.8190, Train Accuracy: 62.16%, Test Loss: 0.8470, Test Accuracy: 65.82%\n",
      "Epoch [2347/2500], Train Loss: 0.8239, Train Accuracy: 61.31%, Test Loss: 0.8233, Test Accuracy: 64.56%\n",
      "Epoch [2348/2500], Train Loss: 0.8107, Train Accuracy: 62.87%, Test Loss: 0.8416, Test Accuracy: 64.56%\n",
      "Epoch [2349/2500], Train Loss: 0.8091, Train Accuracy: 64.01%, Test Loss: 0.8331, Test Accuracy: 64.56%\n",
      "Epoch [2350/2500], Train Loss: 0.8102, Train Accuracy: 63.16%, Test Loss: 0.8430, Test Accuracy: 64.56%\n",
      "Epoch [2351/2500], Train Loss: 0.8206, Train Accuracy: 64.30%, Test Loss: 0.8409, Test Accuracy: 64.56%\n",
      "Epoch [2352/2500], Train Loss: 0.8173, Train Accuracy: 63.58%, Test Loss: 0.8477, Test Accuracy: 64.56%\n",
      "Epoch [2353/2500], Train Loss: 0.8133, Train Accuracy: 63.44%, Test Loss: 0.8425, Test Accuracy: 65.82%\n",
      "Epoch [2354/2500], Train Loss: 0.8253, Train Accuracy: 62.87%, Test Loss: 0.8503, Test Accuracy: 64.56%\n",
      "Epoch [2355/2500], Train Loss: 0.8064, Train Accuracy: 63.44%, Test Loss: 0.8395, Test Accuracy: 64.56%\n",
      "Epoch [2356/2500], Train Loss: 0.7992, Train Accuracy: 64.44%, Test Loss: 0.8492, Test Accuracy: 64.56%\n",
      "Epoch [2357/2500], Train Loss: 0.8114, Train Accuracy: 63.87%, Test Loss: 0.8457, Test Accuracy: 64.56%\n",
      "Epoch [2358/2500], Train Loss: 0.8015, Train Accuracy: 63.58%, Test Loss: 0.8296, Test Accuracy: 64.56%\n",
      "Epoch [2359/2500], Train Loss: 0.7977, Train Accuracy: 64.72%, Test Loss: 0.8412, Test Accuracy: 64.56%\n",
      "Epoch [2360/2500], Train Loss: 0.8059, Train Accuracy: 62.30%, Test Loss: 0.8426, Test Accuracy: 65.82%\n",
      "Epoch [2361/2500], Train Loss: 0.8123, Train Accuracy: 62.87%, Test Loss: 0.8534, Test Accuracy: 64.56%\n",
      "Epoch [2362/2500], Train Loss: 0.8033, Train Accuracy: 65.58%, Test Loss: 0.8459, Test Accuracy: 64.56%\n",
      "Epoch [2363/2500], Train Loss: 0.7881, Train Accuracy: 63.16%, Test Loss: 0.8462, Test Accuracy: 64.56%\n",
      "Epoch [2364/2500], Train Loss: 0.8232, Train Accuracy: 62.59%, Test Loss: 0.8480, Test Accuracy: 64.56%\n",
      "Epoch [2365/2500], Train Loss: 0.8144, Train Accuracy: 62.45%, Test Loss: 0.8467, Test Accuracy: 64.56%\n",
      "Epoch [2366/2500], Train Loss: 0.7978, Train Accuracy: 64.44%, Test Loss: 0.8366, Test Accuracy: 64.56%\n",
      "Epoch [2367/2500], Train Loss: 0.8033, Train Accuracy: 64.30%, Test Loss: 0.8304, Test Accuracy: 64.56%\n",
      "Epoch [2368/2500], Train Loss: 0.8017, Train Accuracy: 63.73%, Test Loss: 0.8393, Test Accuracy: 64.56%\n",
      "Epoch [2369/2500], Train Loss: 0.8190, Train Accuracy: 61.17%, Test Loss: 0.8467, Test Accuracy: 64.56%\n",
      "Epoch [2370/2500], Train Loss: 0.8170, Train Accuracy: 63.30%, Test Loss: 0.8347, Test Accuracy: 64.56%\n",
      "Epoch [2371/2500], Train Loss: 0.8119, Train Accuracy: 61.74%, Test Loss: 0.8440, Test Accuracy: 65.82%\n",
      "Epoch [2372/2500], Train Loss: 0.8159, Train Accuracy: 62.45%, Test Loss: 0.8277, Test Accuracy: 64.56%\n",
      "Epoch [2373/2500], Train Loss: 0.8065, Train Accuracy: 64.44%, Test Loss: 0.8135, Test Accuracy: 64.56%\n",
      "Epoch [2374/2500], Train Loss: 0.8126, Train Accuracy: 62.87%, Test Loss: 0.8197, Test Accuracy: 64.56%\n",
      "Epoch [2375/2500], Train Loss: 0.8200, Train Accuracy: 63.44%, Test Loss: 0.8283, Test Accuracy: 64.56%\n",
      "Epoch [2376/2500], Train Loss: 0.8097, Train Accuracy: 64.30%, Test Loss: 0.8262, Test Accuracy: 64.56%\n",
      "Epoch [2377/2500], Train Loss: 0.8034, Train Accuracy: 63.16%, Test Loss: 0.8321, Test Accuracy: 64.56%\n",
      "Epoch [2378/2500], Train Loss: 0.8155, Train Accuracy: 63.16%, Test Loss: 0.8042, Test Accuracy: 64.56%\n",
      "Epoch [2379/2500], Train Loss: 0.8289, Train Accuracy: 62.02%, Test Loss: 0.8100, Test Accuracy: 63.29%\n",
      "Epoch [2380/2500], Train Loss: 0.8196, Train Accuracy: 63.30%, Test Loss: 0.8406, Test Accuracy: 64.56%\n",
      "Epoch [2381/2500], Train Loss: 0.8254, Train Accuracy: 61.45%, Test Loss: 0.8359, Test Accuracy: 64.56%\n",
      "Epoch [2382/2500], Train Loss: 0.8269, Train Accuracy: 62.30%, Test Loss: 0.8339, Test Accuracy: 65.82%\n",
      "Epoch [2383/2500], Train Loss: 0.8129, Train Accuracy: 63.02%, Test Loss: 0.8286, Test Accuracy: 65.82%\n",
      "Epoch [2384/2500], Train Loss: 0.7924, Train Accuracy: 66.29%, Test Loss: 0.8553, Test Accuracy: 63.29%\n",
      "Epoch [2385/2500], Train Loss: 0.8139, Train Accuracy: 63.44%, Test Loss: 0.8413, Test Accuracy: 64.56%\n",
      "Epoch [2386/2500], Train Loss: 0.7943, Train Accuracy: 63.87%, Test Loss: 0.8370, Test Accuracy: 64.56%\n",
      "Epoch [2387/2500], Train Loss: 0.7944, Train Accuracy: 63.30%, Test Loss: 0.8415, Test Accuracy: 64.56%\n",
      "Epoch [2388/2500], Train Loss: 0.8167, Train Accuracy: 63.16%, Test Loss: 0.8293, Test Accuracy: 64.56%\n",
      "Epoch [2389/2500], Train Loss: 0.8026, Train Accuracy: 64.01%, Test Loss: 0.8344, Test Accuracy: 64.56%\n",
      "Epoch [2390/2500], Train Loss: 0.8133, Train Accuracy: 62.59%, Test Loss: 0.8305, Test Accuracy: 64.56%\n",
      "Epoch [2391/2500], Train Loss: 0.8249, Train Accuracy: 62.02%, Test Loss: 0.8370, Test Accuracy: 63.29%\n",
      "Epoch [2392/2500], Train Loss: 0.8095, Train Accuracy: 60.03%, Test Loss: 0.8318, Test Accuracy: 63.29%\n",
      "Epoch [2393/2500], Train Loss: 0.7952, Train Accuracy: 64.15%, Test Loss: 0.8356, Test Accuracy: 65.82%\n",
      "Epoch [2394/2500], Train Loss: 0.8257, Train Accuracy: 61.59%, Test Loss: 0.8279, Test Accuracy: 64.56%\n",
      "Epoch [2395/2500], Train Loss: 0.8193, Train Accuracy: 64.15%, Test Loss: 0.8386, Test Accuracy: 64.56%\n",
      "Epoch [2396/2500], Train Loss: 0.8049, Train Accuracy: 64.72%, Test Loss: 0.8267, Test Accuracy: 64.56%\n",
      "Epoch [2397/2500], Train Loss: 0.8363, Train Accuracy: 62.02%, Test Loss: 0.8097, Test Accuracy: 64.56%\n",
      "Epoch [2398/2500], Train Loss: 0.8094, Train Accuracy: 63.30%, Test Loss: 0.8124, Test Accuracy: 64.56%\n",
      "Epoch [2399/2500], Train Loss: 0.7895, Train Accuracy: 64.58%, Test Loss: 0.8345, Test Accuracy: 65.82%\n",
      "Epoch [2400/2500], Train Loss: 0.8035, Train Accuracy: 64.15%, Test Loss: 0.8149, Test Accuracy: 65.82%\n",
      "Epoch [2401/2500], Train Loss: 0.8000, Train Accuracy: 63.44%, Test Loss: 0.8281, Test Accuracy: 65.82%\n",
      "Epoch [2402/2500], Train Loss: 0.8344, Train Accuracy: 61.45%, Test Loss: 0.8294, Test Accuracy: 64.56%\n",
      "Epoch [2403/2500], Train Loss: 0.8032, Train Accuracy: 63.73%, Test Loss: 0.8153, Test Accuracy: 65.82%\n",
      "Epoch [2404/2500], Train Loss: 0.8120, Train Accuracy: 63.16%, Test Loss: 0.8255, Test Accuracy: 65.82%\n",
      "Epoch [2405/2500], Train Loss: 0.8039, Train Accuracy: 63.02%, Test Loss: 0.8390, Test Accuracy: 65.82%\n",
      "Epoch [2406/2500], Train Loss: 0.8354, Train Accuracy: 61.02%, Test Loss: 0.8358, Test Accuracy: 64.56%\n",
      "Epoch [2407/2500], Train Loss: 0.8094, Train Accuracy: 63.44%, Test Loss: 0.8199, Test Accuracy: 64.56%\n",
      "Epoch [2408/2500], Train Loss: 0.8038, Train Accuracy: 62.45%, Test Loss: 0.8067, Test Accuracy: 65.82%\n",
      "Epoch [2409/2500], Train Loss: 0.8116, Train Accuracy: 64.44%, Test Loss: 0.8126, Test Accuracy: 64.56%\n",
      "Epoch [2410/2500], Train Loss: 0.8146, Train Accuracy: 62.59%, Test Loss: 0.8391, Test Accuracy: 64.56%\n",
      "Epoch [2411/2500], Train Loss: 0.8020, Train Accuracy: 65.29%, Test Loss: 0.8014, Test Accuracy: 64.56%\n",
      "Epoch [2412/2500], Train Loss: 0.8221, Train Accuracy: 62.87%, Test Loss: 0.8314, Test Accuracy: 63.29%\n",
      "Epoch [2413/2500], Train Loss: 0.8096, Train Accuracy: 61.31%, Test Loss: 0.8245, Test Accuracy: 64.56%\n",
      "Epoch [2414/2500], Train Loss: 0.8122, Train Accuracy: 63.30%, Test Loss: 0.8248, Test Accuracy: 63.29%\n",
      "Epoch [2415/2500], Train Loss: 0.8127, Train Accuracy: 63.02%, Test Loss: 0.8181, Test Accuracy: 64.56%\n",
      "Epoch [2416/2500], Train Loss: 0.8160, Train Accuracy: 64.15%, Test Loss: 0.8311, Test Accuracy: 64.56%\n",
      "Epoch [2417/2500], Train Loss: 0.7928, Train Accuracy: 63.30%, Test Loss: 0.8272, Test Accuracy: 64.56%\n",
      "Epoch [2418/2500], Train Loss: 0.8153, Train Accuracy: 61.31%, Test Loss: 0.8507, Test Accuracy: 64.56%\n",
      "Epoch [2419/2500], Train Loss: 0.8038, Train Accuracy: 63.58%, Test Loss: 0.8300, Test Accuracy: 64.56%\n",
      "Epoch [2420/2500], Train Loss: 0.8039, Train Accuracy: 63.16%, Test Loss: 0.8442, Test Accuracy: 65.82%\n",
      "Epoch [2421/2500], Train Loss: 0.8058, Train Accuracy: 62.45%, Test Loss: 0.8413, Test Accuracy: 64.56%\n",
      "Epoch [2422/2500], Train Loss: 0.8286, Train Accuracy: 64.44%, Test Loss: 0.8311, Test Accuracy: 64.56%\n",
      "Epoch [2423/2500], Train Loss: 0.8018, Train Accuracy: 63.58%, Test Loss: 0.8152, Test Accuracy: 64.56%\n",
      "Epoch [2424/2500], Train Loss: 0.8040, Train Accuracy: 62.02%, Test Loss: 0.8328, Test Accuracy: 64.56%\n",
      "Epoch [2425/2500], Train Loss: 0.8208, Train Accuracy: 62.16%, Test Loss: 0.8503, Test Accuracy: 63.29%\n",
      "Epoch [2426/2500], Train Loss: 0.8155, Train Accuracy: 63.02%, Test Loss: 0.8359, Test Accuracy: 64.56%\n",
      "Epoch [2427/2500], Train Loss: 0.8106, Train Accuracy: 63.30%, Test Loss: 0.8334, Test Accuracy: 64.56%\n",
      "Epoch [2428/2500], Train Loss: 0.8099, Train Accuracy: 63.30%, Test Loss: 0.8438, Test Accuracy: 64.56%\n",
      "Epoch [2429/2500], Train Loss: 0.8284, Train Accuracy: 63.02%, Test Loss: 0.8265, Test Accuracy: 64.56%\n",
      "Epoch [2430/2500], Train Loss: 0.8016, Train Accuracy: 64.15%, Test Loss: 0.8287, Test Accuracy: 64.56%\n",
      "Epoch [2431/2500], Train Loss: 0.7907, Train Accuracy: 64.30%, Test Loss: 0.8275, Test Accuracy: 65.82%\n",
      "Epoch [2432/2500], Train Loss: 0.8120, Train Accuracy: 63.02%, Test Loss: 0.8300, Test Accuracy: 64.56%\n",
      "Epoch [2433/2500], Train Loss: 0.8145, Train Accuracy: 62.59%, Test Loss: 0.8246, Test Accuracy: 64.56%\n",
      "Epoch [2434/2500], Train Loss: 0.8237, Train Accuracy: 63.16%, Test Loss: 0.8309, Test Accuracy: 64.56%\n",
      "Epoch [2435/2500], Train Loss: 0.8055, Train Accuracy: 64.01%, Test Loss: 0.8472, Test Accuracy: 64.56%\n",
      "Epoch [2436/2500], Train Loss: 0.7869, Train Accuracy: 64.58%, Test Loss: 0.8413, Test Accuracy: 64.56%\n",
      "Epoch [2437/2500], Train Loss: 0.8045, Train Accuracy: 62.73%, Test Loss: 0.8357, Test Accuracy: 64.56%\n",
      "Epoch [2438/2500], Train Loss: 0.8098, Train Accuracy: 63.73%, Test Loss: 0.8253, Test Accuracy: 64.56%\n",
      "Epoch [2439/2500], Train Loss: 0.7902, Train Accuracy: 65.29%, Test Loss: 0.8241, Test Accuracy: 64.56%\n",
      "Epoch [2440/2500], Train Loss: 0.8179, Train Accuracy: 63.30%, Test Loss: 0.8335, Test Accuracy: 63.29%\n",
      "Epoch [2441/2500], Train Loss: 0.7962, Train Accuracy: 64.30%, Test Loss: 0.8338, Test Accuracy: 64.56%\n",
      "Epoch [2442/2500], Train Loss: 0.8155, Train Accuracy: 62.59%, Test Loss: 0.8533, Test Accuracy: 63.29%\n",
      "Epoch [2443/2500], Train Loss: 0.8055, Train Accuracy: 64.01%, Test Loss: 0.8359, Test Accuracy: 64.56%\n",
      "Epoch [2444/2500], Train Loss: 0.8146, Train Accuracy: 62.73%, Test Loss: 0.8379, Test Accuracy: 64.56%\n",
      "Epoch [2445/2500], Train Loss: 0.8049, Train Accuracy: 63.73%, Test Loss: 0.8599, Test Accuracy: 62.03%\n",
      "Epoch [2446/2500], Train Loss: 0.8192, Train Accuracy: 62.73%, Test Loss: 0.8386, Test Accuracy: 65.82%\n",
      "Epoch [2447/2500], Train Loss: 0.8017, Train Accuracy: 63.44%, Test Loss: 0.8540, Test Accuracy: 65.82%\n",
      "Epoch [2448/2500], Train Loss: 0.8076, Train Accuracy: 63.58%, Test Loss: 0.8470, Test Accuracy: 63.29%\n",
      "Epoch [2449/2500], Train Loss: 0.8148, Train Accuracy: 62.59%, Test Loss: 0.8398, Test Accuracy: 64.56%\n",
      "Epoch [2450/2500], Train Loss: 0.8108, Train Accuracy: 63.30%, Test Loss: 0.8314, Test Accuracy: 65.82%\n",
      "Epoch [2451/2500], Train Loss: 0.8156, Train Accuracy: 61.88%, Test Loss: 0.8301, Test Accuracy: 64.56%\n",
      "Epoch [2452/2500], Train Loss: 0.8014, Train Accuracy: 65.58%, Test Loss: 0.8464, Test Accuracy: 64.56%\n",
      "Epoch [2453/2500], Train Loss: 0.8035, Train Accuracy: 63.16%, Test Loss: 0.8475, Test Accuracy: 64.56%\n",
      "Epoch [2454/2500], Train Loss: 0.8009, Train Accuracy: 62.87%, Test Loss: 0.8228, Test Accuracy: 64.56%\n",
      "Epoch [2455/2500], Train Loss: 0.8108, Train Accuracy: 64.86%, Test Loss: 0.8113, Test Accuracy: 63.29%\n",
      "Epoch [2456/2500], Train Loss: 0.7978, Train Accuracy: 63.73%, Test Loss: 0.8202, Test Accuracy: 64.56%\n",
      "Epoch [2457/2500], Train Loss: 0.7970, Train Accuracy: 64.58%, Test Loss: 0.8067, Test Accuracy: 64.56%\n",
      "Epoch [2458/2500], Train Loss: 0.8110, Train Accuracy: 63.58%, Test Loss: 0.8406, Test Accuracy: 65.82%\n",
      "Epoch [2459/2500], Train Loss: 0.7950, Train Accuracy: 64.01%, Test Loss: 0.8256, Test Accuracy: 64.56%\n",
      "Epoch [2460/2500], Train Loss: 0.8173, Train Accuracy: 62.73%, Test Loss: 0.8272, Test Accuracy: 65.82%\n",
      "Epoch [2461/2500], Train Loss: 0.8102, Train Accuracy: 61.59%, Test Loss: 0.8345, Test Accuracy: 64.56%\n",
      "Epoch [2462/2500], Train Loss: 0.8001, Train Accuracy: 63.73%, Test Loss: 0.8334, Test Accuracy: 63.29%\n",
      "Epoch [2463/2500], Train Loss: 0.8167, Train Accuracy: 62.87%, Test Loss: 0.8373, Test Accuracy: 63.29%\n",
      "Epoch [2464/2500], Train Loss: 0.8094, Train Accuracy: 61.88%, Test Loss: 0.8390, Test Accuracy: 65.82%\n",
      "Epoch [2465/2500], Train Loss: 0.7937, Train Accuracy: 63.58%, Test Loss: 0.8528, Test Accuracy: 64.56%\n",
      "Epoch [2466/2500], Train Loss: 0.8093, Train Accuracy: 64.58%, Test Loss: 0.8329, Test Accuracy: 63.29%\n",
      "Epoch [2467/2500], Train Loss: 0.8105, Train Accuracy: 64.44%, Test Loss: 0.8541, Test Accuracy: 64.56%\n",
      "Epoch [2468/2500], Train Loss: 0.7997, Train Accuracy: 62.59%, Test Loss: 0.8356, Test Accuracy: 64.56%\n",
      "Epoch [2469/2500], Train Loss: 0.8050, Train Accuracy: 63.44%, Test Loss: 0.8218, Test Accuracy: 64.56%\n",
      "Epoch [2470/2500], Train Loss: 0.7995, Train Accuracy: 64.01%, Test Loss: 0.8207, Test Accuracy: 65.82%\n",
      "Epoch [2471/2500], Train Loss: 0.7911, Train Accuracy: 64.01%, Test Loss: 0.8266, Test Accuracy: 64.56%\n",
      "Epoch [2472/2500], Train Loss: 0.8032, Train Accuracy: 63.73%, Test Loss: 0.8359, Test Accuracy: 65.82%\n",
      "Epoch [2473/2500], Train Loss: 0.8126, Train Accuracy: 62.73%, Test Loss: 0.8167, Test Accuracy: 65.82%\n",
      "Epoch [2474/2500], Train Loss: 0.8021, Train Accuracy: 63.02%, Test Loss: 0.8118, Test Accuracy: 64.56%\n",
      "Epoch [2475/2500], Train Loss: 0.8218, Train Accuracy: 63.44%, Test Loss: 0.8156, Test Accuracy: 65.82%\n",
      "Epoch [2476/2500], Train Loss: 0.7982, Train Accuracy: 63.44%, Test Loss: 0.8240, Test Accuracy: 64.56%\n",
      "Epoch [2477/2500], Train Loss: 0.8178, Train Accuracy: 61.88%, Test Loss: 0.8391, Test Accuracy: 64.56%\n",
      "Epoch [2478/2500], Train Loss: 0.7975, Train Accuracy: 63.16%, Test Loss: 0.8206, Test Accuracy: 64.56%\n",
      "Epoch [2479/2500], Train Loss: 0.8015, Train Accuracy: 63.58%, Test Loss: 0.8366, Test Accuracy: 64.56%\n",
      "Epoch [2480/2500], Train Loss: 0.7821, Train Accuracy: 64.72%, Test Loss: 0.8145, Test Accuracy: 63.29%\n",
      "Epoch [2481/2500], Train Loss: 0.8004, Train Accuracy: 64.30%, Test Loss: 0.8214, Test Accuracy: 64.56%\n",
      "Epoch [2482/2500], Train Loss: 0.7974, Train Accuracy: 61.88%, Test Loss: 0.8248, Test Accuracy: 64.56%\n",
      "Epoch [2483/2500], Train Loss: 0.8170, Train Accuracy: 62.73%, Test Loss: 0.8277, Test Accuracy: 64.56%\n",
      "Epoch [2484/2500], Train Loss: 0.8080, Train Accuracy: 63.02%, Test Loss: 0.8360, Test Accuracy: 64.56%\n",
      "Epoch [2485/2500], Train Loss: 0.7989, Train Accuracy: 65.58%, Test Loss: 0.8256, Test Accuracy: 64.56%\n",
      "Epoch [2486/2500], Train Loss: 0.8058, Train Accuracy: 63.58%, Test Loss: 0.8430, Test Accuracy: 64.56%\n",
      "Epoch [2487/2500], Train Loss: 0.8150, Train Accuracy: 62.59%, Test Loss: 0.8445, Test Accuracy: 64.56%\n",
      "Epoch [2488/2500], Train Loss: 0.8039, Train Accuracy: 63.58%, Test Loss: 0.8367, Test Accuracy: 65.82%\n",
      "Epoch [2489/2500], Train Loss: 0.8087, Train Accuracy: 62.16%, Test Loss: 0.8560, Test Accuracy: 65.82%\n",
      "Epoch [2490/2500], Train Loss: 0.8087, Train Accuracy: 63.58%, Test Loss: 0.8402, Test Accuracy: 65.82%\n",
      "Epoch [2491/2500], Train Loss: 0.8089, Train Accuracy: 62.87%, Test Loss: 0.8329, Test Accuracy: 65.82%\n",
      "Epoch [2492/2500], Train Loss: 0.7898, Train Accuracy: 65.29%, Test Loss: 0.8230, Test Accuracy: 65.82%\n",
      "Epoch [2493/2500], Train Loss: 0.8187, Train Accuracy: 65.01%, Test Loss: 0.8221, Test Accuracy: 64.56%\n",
      "Epoch [2494/2500], Train Loss: 0.8024, Train Accuracy: 62.73%, Test Loss: 0.8370, Test Accuracy: 64.56%\n",
      "Epoch [2495/2500], Train Loss: 0.7922, Train Accuracy: 63.30%, Test Loss: 0.8386, Test Accuracy: 65.82%\n",
      "Epoch [2496/2500], Train Loss: 0.7849, Train Accuracy: 64.15%, Test Loss: 0.8369, Test Accuracy: 64.56%\n",
      "Epoch [2497/2500], Train Loss: 0.7956, Train Accuracy: 64.01%, Test Loss: 0.8537, Test Accuracy: 64.56%\n",
      "Epoch [2498/2500], Train Loss: 0.8080, Train Accuracy: 63.02%, Test Loss: 0.8332, Test Accuracy: 64.56%\n",
      "Epoch [2499/2500], Train Loss: 0.8227, Train Accuracy: 62.87%, Test Loss: 0.8369, Test Accuracy: 64.56%\n",
      "Epoch [2500/2500], Train Loss: 0.7786, Train Accuracy: 63.16%, Test Loss: 0.8449, Test Accuracy: 65.82%\n",
      "model_cnn2dlstm_att saved as model_cnn2dlstm_att_4class_best.pth\n",
      "\n",
      "Metrics for model_cnn2dlstm_att saved as model_cnn2dlstm_att_metrics_4class.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "input_size = (1, 19, 10)\n",
    "num_classes = len(set(y_train))\n",
    "\n",
    "# Loop through each model in the model_list\n",
    "for model_name, model_class in model_2D.items():\n",
    "    print(f\"Training {model_name}\")\n",
    "\n",
    "    # Initialize the model and move it to the device\n",
    "    model = model_class(input_size=input_size, num_classes=num_classes).to(DEVICE)\n",
    "    optimizer = SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Metrics storage\n",
    "    metrics = {\n",
    "        \"epoch\": [],\n",
    "        \"train_loss\": [],\n",
    "        \"train_accuracy\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_accuracy\": []\n",
    "    }\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for inputs, labels in train_loader2:  # Assume train_loader is already defined\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)  # Move to device\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Calculate training accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "        # Model Evaluation (on the test set)\n",
    "        model.eval()\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader2:  # Assume test_loader is already defined\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "        avg_val_loss = running_val_loss / len(test_loader)\n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "        # Print metrics for each epoch\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Test Loss: {avg_val_loss:.4f}, Test Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "        # Save metrics to dictionary\n",
    "        metrics[\"epoch\"].append(epoch + 1)\n",
    "        metrics[\"train_loss\"].append(avg_train_loss)\n",
    "        metrics[\"train_accuracy\"].append(train_accuracy)\n",
    "        metrics[\"test_loss\"].append(avg_val_loss)\n",
    "        metrics[\"test_accuracy\"].append(val_accuracy)\n",
    "\n",
    "    # Save the model (optional)\n",
    "    torch.save(model.state_dict(), f\"{model_name}_{mapping_object}_best.pth\")\n",
    "    print(f\"{model_name} saved as {model_name}_{mapping_object}_best.pth\\n\")\n",
    "\n",
    "    # Save the metrics to a CSV file\n",
    "    df = pd.DataFrame(metrics)\n",
    "    df.to_csv(f\"{model_name}_{mapping_object}_metrics.csv\", index=False)\n",
    "    print(f\"Metrics for {model_name} saved as {model_name}_metrics_{mapping_object}.csv\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model import cnn_model_multiscale\n",
    "\n",
    "cnn1d_multibranch = cnn_model_multiscale.MultiBranchCNN1D\n",
    "cnn1d_multibranchattlstm = cnn_model_multiscale.MultiBranchCNN1DATTLSTM\n",
    "\n",
    "model_1D_md = {'model_multibranch_cnn1d': cnn1d_multibranch, 'model_multibranch_cnn1d_lstm': cnn1d_multibranchattlstm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model_multibranch_cnn1d\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 2D (unbatched) or 3D (batched) input to conv1d, but got input of size: [1, 1, 1, 181]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Initialize the model and move it to the device\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m model_class(input_size\u001b[38;5;241m=\u001b[39minput_size, num_classes\u001b[38;5;241m=\u001b[39mnum_classes)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     12\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m SGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Metrics storage\u001b[39;00m\n",
      "File \u001b[1;32md:\\IFRI\\Mapping_3Kab\\Rev_Modelling_Sen2\\Model\\cnn_model_multiscale.py:34\u001b[0m, in \u001b[0;36mMultiBranchCNN1D.__init__\u001b[1;34m(self, input_size, num_classes)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout3 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.3\u001b[39m)  \n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Fully connected layers (same as original)\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m flattened_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_flattened_size(input_size)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(flattened_size, \u001b[38;5;241m256\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_fc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.5\u001b[39m) \n",
      "File \u001b[1;32md:\\IFRI\\Mapping_3Kab\\Rev_Modelling_Sen2\\Model\\cnn_model_multiscale.py:42\u001b[0m, in \u001b[0;36mMultiBranchCNN1D._calculate_flattened_size\u001b[1;34m(self, input_length)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_calculate_flattened_size\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_length):\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# Helper function to calculate the output size after all convolution and pooling layers\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, input_length)  \u001b[38;5;66;03m# Dummy input with batch size 1, 1 channel\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(x)  \u001b[38;5;66;03m# Forward pass through the model to get the size after all layers\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mnumel()\n",
      "File \u001b[1;32md:\\IFRI\\Mapping_3Kab\\Rev_Modelling_Sen2\\Model\\cnn_model_multiscale.py:49\u001b[0m, in \u001b[0;36mMultiBranchCNN1D.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     46\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Add the channel dimension (batch_size, 1, input_size)\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Pass input through each of the 5 convolution branches\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m branch2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)\n\u001b[0;32m     50\u001b[0m branch3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x)\n\u001b[0;32m     51\u001b[0m branch5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv5(x)\n",
      "File \u001b[1;32mc:\\Users\\sanji\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sanji\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sanji\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32mc:\\Users\\sanji\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    307\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 2D (unbatched) or 3D (batched) input to conv1d, but got input of size: [1, 1, 1, 181]"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD, Adam\n",
    "\n",
    "input_size = X_train_tensor.shape[1]\n",
    "num_classes = len(set(y_train))\n",
    "\n",
    "# Loop through each model in the model_list\n",
    "for model_name, model_class in model_1D_md.items():\n",
    "    print(f\"Training {model_name}\")\n",
    "\n",
    "    # Initialize the model and move it to the device\n",
    "    model = model_class(input_size=input_size, num_classes=num_classes).to(DEVICE)\n",
    "    optimizer = SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Metrics storage\n",
    "    metrics = {\n",
    "        \"epoch\": [],\n",
    "        \"train_loss\": [],\n",
    "        \"train_accuracy\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_accuracy\": []\n",
    "    }\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for inputs, labels in train_loader:  \n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)  \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Calculate training accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "        # Model Evaluation (on the test set)\n",
    "        model.eval()\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:  # Assume test_loader is already defined\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "        avg_val_loss = running_val_loss / len(test_loader)\n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "        # Print metrics for each epoch\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Test Loss: {avg_val_loss:.4f}, Test Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "        # Save metrics to dictionary\n",
    "        metrics[\"epoch\"].append(epoch + 1)\n",
    "        metrics[\"train_loss\"].append(avg_train_loss)\n",
    "        metrics[\"train_accuracy\"].append(train_accuracy)\n",
    "        metrics[\"test_loss\"].append(avg_val_loss)\n",
    "        metrics[\"test_accuracy\"].append(val_accuracy)\n",
    "\n",
    "    # Save the model (optional)\n",
    "    torch.save(model.state_dict(), f\"{model_name}_{mapping_object}_best.pth\")\n",
    "    print(f\"{model_name} saved as {model_name}_{mapping_object}_best.pth\\n\")\n",
    "\n",
    "    # Save the metrics to a CSV file\n",
    "    df = pd.DataFrame(metrics)\n",
    "    df.to_csv(f\"{model_name}_{mapping_object}_metrics.csv\", index=False)\n",
    "    print(f\"Metrics for {model_name} saved as {model_name}_{mapping_object}_metrics.csv\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
